{
    "title": "自然语言处理训练营", 
    "description": "自然语言处理", 
    "followers": [
        "https://www.zhihu.com/people/wuhq", 
        "https://www.zhihu.com/people/yi-jing-62", 
        "https://www.zhihu.com/people/xi-fan-79-12", 
        "https://www.zhihu.com/people/meng-zhang-yu-49", 
        "https://www.zhihu.com/people/landant", 
        "https://www.zhihu.com/people/zhang-lin-63-66", 
        "https://www.zhihu.com/people/ruby-16-30", 
        "https://www.zhihu.com/people/huang-yi-26-55", 
        "https://www.zhihu.com/people/wang-yu-hao-10", 
        "https://www.zhihu.com/people/bai-15-11", 
        "https://www.zhihu.com/people/flqzdzxx", 
        "https://www.zhihu.com/people/mi-mi-mi-jasmine", 
        "https://www.zhihu.com/people/shi-nan-39-30", 
        "https://www.zhihu.com/people/liang-yi-zhao-70", 
        "https://www.zhihu.com/people/darknight-58", 
        "https://www.zhihu.com/people/hassan-82-49", 
        "https://www.zhihu.com/people/jiang-bin-41-73", 
        "https://www.zhihu.com/people/mao-mao-1-5-50", 
        "https://www.zhihu.com/people/super-grizzly", 
        "https://www.zhihu.com/people/mi-mang-de-zha-ming", 
        "https://www.zhihu.com/people/xu-yuan-bo-60", 
        "https://www.zhihu.com/people/cheng-zheng-wei-79", 
        "https://www.zhihu.com/people/mr-lin-82-68", 
        "https://www.zhihu.com/people/qianws", 
        "https://www.zhihu.com/people/sdclzzg", 
        "https://www.zhihu.com/people/li-kangning", 
        "https://www.zhihu.com/people/phaldon-ph", 
        "https://www.zhihu.com/people/biggang-43-51", 
        "https://www.zhihu.com/people/pi-pi-xia-23-75", 
        "https://www.zhihu.com/people/13903679273", 
        "https://www.zhihu.com/people/ke-da-ke-xiao-5", 
        "https://www.zhihu.com/people/pearlbai-de-gan", 
        "https://www.zhihu.com/people/huang-hao-30-15", 
        "https://www.zhihu.com/people/pechow.zheng", 
        "https://www.zhihu.com/people/bunny-77-89", 
        "https://www.zhihu.com/people/csuclm", 
        "https://www.zhihu.com/people/ma-lin-98-35", 
        "https://www.zhihu.com/people/jiang-ye-ting-feng", 
        "https://www.zhihu.com/people/chenkai-64", 
        "https://www.zhihu.com/people/xiao-guai-shou-43-11", 
        "https://www.zhihu.com/people/PeiyuZhuang", 
        "https://www.zhihu.com/people/kent-clerk", 
        "https://www.zhihu.com/people/wo-he-wo-de-jiao-ao-3", 
        "https://www.zhihu.com/people/lin-fei-xin-xi-ji-zhu-gang", 
        "https://www.zhihu.com/people/mao-dou-66-95", 
        "https://www.zhihu.com/people/zhang-qi-85-98", 
        "https://www.zhihu.com/people/yue-feng-52", 
        "https://www.zhihu.com/people/lu-zhi-56-55", 
        "https://www.zhihu.com/people/dou-dou-86-16-46", 
        "https://www.zhihu.com/people/top-network", 
        "https://www.zhihu.com/people/liu-yu-15-51-5", 
        "https://www.zhihu.com/people/da-da-da-ying-zi-16", 
        "https://www.zhihu.com/people/chengzhang511", 
        "https://www.zhihu.com/people/skim-76", 
        "https://www.zhihu.com/people/yang-67-97-18", 
        "https://www.zhihu.com/people/suan-tian-xiao-huang-gua", 
        "https://www.zhihu.com/people/redgdmom", 
        "https://www.zhihu.com/people/zdb-73", 
        "https://www.zhihu.com/people/wang-ne-ne", 
        "https://www.zhihu.com/people/li-wen-qi-14-93", 
        "https://www.zhihu.com/people/bigegos", 
        "https://www.zhihu.com/people/programmer_song", 
        "https://www.zhihu.com/people/liu15373782979", 
        "https://www.zhihu.com/people/gong-jun-min-74", 
        "https://www.zhihu.com/people/song-jin-wen-31", 
        "https://www.zhihu.com/people/tian-lan-se-26", 
        "https://www.zhihu.com/people/ban-seng-ban-fo", 
        "https://www.zhihu.com/people/mu-ma-ren-53-58", 
        "https://www.zhihu.com/people/tong-chuan-35", 
        "https://www.zhihu.com/people/lin-rong-jian", 
        "https://www.zhihu.com/people/huanghuispan", 
        "https://www.zhihu.com/people/liu-xin-11-19-20", 
        "https://www.zhihu.com/people/zhi-ma-kai-hua-8-98", 
        "https://www.zhihu.com/people/markbell_cn", 
        "https://www.zhihu.com/people/jin-ping-guo-24", 
        "https://www.zhihu.com/people/yi-ling-90-61", 
        "https://www.zhihu.com/people/jia-zheng-ru-24", 
        "https://www.zhihu.com/people/qiang-jia-wei-jiawei-qiang", 
        "https://www.zhihu.com/people/xiao-qing-yuan-you-bu-yi-gui", 
        "https://www.zhihu.com/people/genghanqiang", 
        "https://www.zhihu.com/people/yan-yan-07-23", 
        "https://www.zhihu.com/people/chen-xie-lang", 
        "https://www.zhihu.com/people/liu-wu-88-64", 
        "https://www.zhihu.com/people/ai-ni-de-kang", 
        "https://www.zhihu.com/people/le-zai-qi-zhong-56-41", 
        "https://www.zhihu.com/people/only-94-35", 
        "https://www.zhihu.com/people/lens-56", 
        "https://www.zhihu.com/people/qxk19920201", 
        "https://www.zhihu.com/people/chengshimin", 
        "https://www.zhihu.com/people/shi-jia-ying", 
        "https://www.zhihu.com/people/ada-30-23", 
        "https://www.zhihu.com/people/shi-ji-suan-ming-shi", 
        "https://www.zhihu.com/people/bao12323", 
        "https://www.zhihu.com/people/bing-11-13", 
        "https://www.zhihu.com/people/hector-13-3", 
        "https://www.zhihu.com/people/wu-tong-peng-76", 
        "https://www.zhihu.com/people/vincentchen0716", 
        "https://www.zhihu.com/people/txxxrr", 
        "https://www.zhihu.com/people/mi-mi-82-42-26", 
        "https://www.zhihu.com/people/liuhanyuan", 
        "https://www.zhihu.com/people/samurai3701", 
        "https://www.zhihu.com/people/wangkaka-71", 
        "https://www.zhihu.com/people/duyiqi", 
        "https://www.zhihu.com/people/qsqsxbz", 
        "https://www.zhihu.com/people/hao-ge-75-66", 
        "https://www.zhihu.com/people/dong-tian-2-13", 
        "https://www.zhihu.com/people/zephyrer", 
        "https://www.zhihu.com/people/lu-ren-jia-7-19", 
        "https://www.zhihu.com/people/dean-yang-53", 
        "https://www.zhihu.com/people/liu-xiao-yong-80-42", 
        "https://www.zhihu.com/people/wang-su-yuan-92", 
        "https://www.zhihu.com/people/skateice", 
        "https://www.zhihu.com/people/wang-lang-96-64", 
        "https://www.zhihu.com/people/liu-xiao-yun-75-22", 
        "https://www.zhihu.com/people/geogre-wu", 
        "https://www.zhihu.com/people/yujun-chen-17", 
        "https://www.zhihu.com/people/shi-cheng-61-20", 
        "https://www.zhihu.com/people/hu-yan-yu-52", 
        "https://www.zhihu.com/people/emily-29-54-92", 
        "https://www.zhihu.com/people/bjck", 
        "https://www.zhihu.com/people/jgt664888795", 
        "https://www.zhihu.com/people/tian-lai-ovila", 
        "https://www.zhihu.com/people/liu-xiao-jia-09", 
        "https://www.zhihu.com/people/zhang-zheng-fu", 
        "https://www.zhihu.com/people/joy-59-69", 
        "https://www.zhihu.com/people/liu-xun-24-64", 
        "https://www.zhihu.com/people/xiapengfei", 
        "https://www.zhihu.com/people/cai-gen-jin-yan", 
        "https://www.zhihu.com/people/elvira-15-87", 
        "https://www.zhihu.com/people/Chi-YeungLaw", 
        "https://www.zhihu.com/people/niceworld-49-6", 
        "https://www.zhihu.com/people/shakenlz", 
        "https://www.zhihu.com/people/shen-lan-54-73", 
        "https://www.zhihu.com/people/Melanie19", 
        "https://www.zhihu.com/people/zhang-yi-nan-24-22", 
        "https://www.zhihu.com/people/feng-ling-de-xing-fu-shi-guang", 
        "https://www.zhihu.com/people/fu-yi-16-87", 
        "https://www.zhihu.com/people/xiao-jie-32", 
        "https://www.zhihu.com/people/vadingujiaqi", 
        "https://www.zhihu.com/people/399-29", 
        "https://www.zhihu.com/people/sarah-melody", 
        "https://www.zhihu.com/people/a-piece-of-bread", 
        "https://www.zhihu.com/people/wang-lao-shi-48-58", 
        "https://www.zhihu.com/people/huang-li-an", 
        "https://www.zhihu.com/people/liu-wu-hao-93-87", 
        "https://www.zhihu.com/people/hu-xi-ting-70", 
        "https://www.zhihu.com/people/snnan", 
        "https://www.zhihu.com/people/yach-4-2", 
        "https://www.zhihu.com/people/charles-37-78", 
        "https://www.zhihu.com/people/zheng-zai-jian-fei-de-xiong", 
        "https://www.zhihu.com/people/reccoon", 
        "https://www.zhihu.com/people/zzy-64-81", 
        "https://www.zhihu.com/people/wu-chi-yu-34", 
        "https://www.zhihu.com/people/wang-zi-yu-89-13", 
        "https://www.zhihu.com/people/tang-xiao-liang-72", 
        "https://www.zhihu.com/people/heyang-36", 
        "https://www.zhihu.com/people/lain01", 
        "https://www.zhihu.com/people/xiao-jian-38-77", 
        "https://www.zhihu.com/people/yang-pei-wen-22", 
        "https://www.zhihu.com/people/liu-xiao-yao-12", 
        "https://www.zhihu.com/people/xtdx", 
        "https://www.zhihu.com/people/vico-68-37-93", 
        "https://www.zhihu.com/people/maxwunj", 
        "https://www.zhihu.com/people/zhairui", 
        "https://www.zhihu.com/people/shao-wei-39-21", 
        "https://www.zhihu.com/people/renee-46-43", 
        "https://www.zhihu.com/people/sora-8-81", 
        "https://www.zhihu.com/people/lin-zhen-kun-4", 
        "https://www.zhihu.com/people/feiduan", 
        "https://www.zhihu.com/people/xiao-hua-44-23", 
        "https://www.zhihu.com/people/hello-53-20", 
        "https://www.zhihu.com/people/zhang-zhi-yuan-61-64", 
        "https://www.zhihu.com/people/li-jia-lei-56-75", 
        "https://www.zhihu.com/people/wang-tian-yuan-77", 
        "https://www.zhihu.com/people/an-ran-57", 
        "https://www.zhihu.com/people/zhu-xu-xu-25", 
        "https://www.zhihu.com/people/wait4hope", 
        "https://www.zhihu.com/people/la-bi-xiao-xin-xin", 
        "https://www.zhihu.com/people/inextime", 
        "https://www.zhihu.com/people/chloe-88-51-33", 
        "https://www.zhihu.com/people/rolinston", 
        "https://www.zhihu.com/people/zhou-hao-wen", 
        "https://www.zhihu.com/people/yue-wu-shuang-24", 
        "https://www.zhihu.com/people/xianlong-chen", 
        "https://www.zhihu.com/people/ThisisSamChan", 
        "https://www.zhihu.com/people/ma-zhong-hua-2513", 
        "https://www.zhihu.com/people/transcloud", 
        "https://www.zhihu.com/people/queen_red", 
        "https://www.zhihu.com/people/gu-yu-71-65", 
        "https://www.zhihu.com/people/yuanran", 
        "https://www.zhihu.com/people/polarlm", 
        "https://www.zhihu.com/people/wang-liao-52", 
        "https://www.zhihu.com/people/shi-yu-fan-46-53", 
        "https://www.zhihu.com/people/li-peng-41-64", 
        "https://www.zhihu.com/people/li-meng-72-3-77", 
        "https://www.zhihu.com/people/zhanglanhui", 
        "https://www.zhihu.com/people/tian-long-55-47", 
        "https://www.zhihu.com/people/xiao-zheng-xiao-ge", 
        "https://www.zhihu.com/people/nomatter", 
        "https://www.zhihu.com/people/panovr", 
        "https://www.zhihu.com/people/li-xing-4", 
        "https://www.zhihu.com/people/hu-shu-huai", 
        "https://www.zhihu.com/people/artic-21", 
        "https://www.zhihu.com/people/zhangyuting", 
        "https://www.zhihu.com/people/wang-le-46-35", 
        "https://www.zhihu.com/people/kent-6-21", 
        "https://www.zhihu.com/people/zzz-53-27", 
        "https://www.zhihu.com/people/freedom_forever", 
        "https://www.zhihu.com/people/alexander-44-93", 
        "https://www.zhihu.com/people/yuan-wei-xi-hong-shi", 
        "https://www.zhihu.com/people/wang-jie-44-97", 
        "https://www.zhihu.com/people/shi-shi-san-28", 
        "https://www.zhihu.com/people/fang-yu-yuan-29", 
        "https://www.zhihu.com/people/jeromexu-56", 
        "https://www.zhihu.com/people/xiao-xiao-luo-26", 
        "https://www.zhihu.com/people/yang-60-6-83", 
        "https://www.zhihu.com/people/wei-jin-jie-32", 
        "https://www.zhihu.com/people/xiao-zi-mo-29", 
        "https://www.zhihu.com/people/leng-gao-de-huo-shan-da-mo-wang", 
        "https://www.zhihu.com/people/hu-yong-83", 
        "https://www.zhihu.com/people/liu-fei-94-95", 
        "https://www.zhihu.com/people/jia-xue-feng", 
        "https://www.zhihu.com/people/johnny-lee-48", 
        "https://www.zhihu.com/people/yi-er-san-84-97", 
        "https://www.zhihu.com/people/tan-xin-xue-yuan", 
        "https://www.zhihu.com/people/ykonhla", 
        "https://www.zhihu.com/people/ink-90-64", 
        "https://www.zhihu.com/people/xie-samson", 
        "https://www.zhihu.com/people/iyaiyaaa", 
        "https://www.zhihu.com/people/richard-hu-45", 
        "https://www.zhihu.com/people/tong-piao-62", 
        "https://www.zhihu.com/people/tan-xiao-yang-95", 
        "https://www.zhihu.com/people/jia-bing-66-48", 
        "https://www.zhihu.com/people/yan-jun-80-45", 
        "https://www.zhihu.com/people/15828181406"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/74555825", 
            "userName": "李文哲", 
            "userLink": "https://www.zhihu.com/people/740cde3d3ba93d33fc59b31f49b2b03b", 
            "upvote": 20, 
            "title": "第一周：DTW，它的效率优化以及其他拓展思路", 
            "content": "<blockquote><b>论文</b>： Searching and Mining Trillions of Time Series Subsequences under Dynamic Time Warping， KDD 2012 (Best Paper Award) <br/><b>作者</b>：Thanawin Rakthanmanon, Bilson Campana, Abdullah Mueen, Gustavo Batista                   </blockquote><p>欢迎互相讨论，评论！ </p><p><b>Table of Contents:</b></p><p>1. Best Summaries of This Week<br/>2. List of All the Summaries<br/>3. Other Ideas &amp; Applications</p><h2><b>Best Summaries of This Week</b></h2><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/73376698\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/equation_ipico.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic2.zhimg.com/equation_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">skateice：关于对Dynamic Time Warping的读后感</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic2.zhimg.com/equation_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72696761\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-6cd505ac8345efe6d823c7a5c3e8d2ed_180x120.jpg\" data-image-width=\"450\" data-image-height=\"253\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic2.zhimg.com/v2-6cd505ac8345efe6d823c7a5c3e8d2ed_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">Johnny Lee：囧尼的论文阅读笔记-1</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic2.zhimg.com/v2-6cd505ac8345efe6d823c7a5c3e8d2ed_180x120.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72704388\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">bradning：我对2012年KDD Best Paper论文的解读</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\"/></span></span></a><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//www.toutiao.com/i6711274314705928712/\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">基于动态规划DTW算法加速衡量两个不同的时间序列的相似性</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>www.toutiao.com</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//blog.csdn.net/cfdoge/article/details/94604091\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">Searching and Mining Trillions of Time Series Subsequences under Dynamic Time Warping 总结</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>blog.csdn.net</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/73292069\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-578c357e5566f2d7f1f73a18fbeb35af_180x120.jpg\" data-image-width=\"1280\" data-image-height=\"720\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic4.zhimg.com/v2-578c357e5566f2d7f1f73a18fbeb35af_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">李萌：对DTW在亿万级别时间序列下优化的理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic4.zhimg.com/v2-578c357e5566f2d7f1f73a18fbeb35af_180x120.jpg\"/></span></span></a><p class=\"ztext-empty-paragraph\"><br/></p><h2>List of All the Summaries (Default Order by IDs)</h2><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/73376698\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/equation_ipico.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic2.zhimg.com/equation_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">skateice：关于对Dynamic Time Warping的读后感</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic2.zhimg.com/equation_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//jozeelin.github.io/2019/07/03/UCR-DTW%25E5%2592%258CUCR-ED%25E6%25A8%25A1%25E5%259E%258B%25E8%25AF%25A6%25E8%25A7%25A3/\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-42d1fa3ef3a4dd2c5f52ae120bf6c65d_180x120.jpg\" data-image-width=\"615\" data-image-height=\"282\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic2.zhimg.com/v2-42d1fa3ef3a4dd2c5f52ae120bf6c65d_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">UCR-DTW和UCR-ED模型详解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>jozeelin.github.io</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic2.zhimg.com/v2-42d1fa3ef3a4dd2c5f52ae120bf6c65d_180x120.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72244293\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/equation_ipico.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic2.zhimg.com/equation_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">13472722199：DTW的时间序列检索和挖掘加速思想的理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic2.zhimg.com/equation_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/71710867\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/equation_ipico.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic1.zhimg.com/equation_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">xtdx：《searching and mining trillions of time series subsquences under dynamic time warping》的学习</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic1.zhimg.com/equation_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/71551263\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/equation_ipico.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic2.zhimg.com/equation_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">Chiang：UCR-DTW 基于UCR优化的动态时间归整算法</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic2.zhimg.com/equation_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72696761\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-6cd505ac8345efe6d823c7a5c3e8d2ed_180x120.jpg\" data-image-width=\"450\" data-image-height=\"253\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic2.zhimg.com/v2-6cd505ac8345efe6d823c7a5c3e8d2ed_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">Johnny Lee：囧尼的论文阅读笔记-1</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic2.zhimg.com/v2-6cd505ac8345efe6d823c7a5c3e8d2ed_180x120.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/73385867?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=627481841943318528\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-33a7e68689455f07f5d6340503a78963_180x120.jpg\" data-image-width=\"1588\" data-image-height=\"348\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic4.zhimg.com/v2-33a7e68689455f07f5d6340503a78963_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">羽战：对于《基于DTW的万亿级时间序列子序列搜索和挖掘》的理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic4.zhimg.com/v2-33a7e68689455f07f5d6340503a78963_180x120.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72685847\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">johnsonwag：DTW 时间规整算法的理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/73558715\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-58dac14c5accb406ff7a87c2e9b5434a_ipico.jpg\" data-image-width=\"618\" data-image-height=\"723\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic3.zhimg.com/v2-58dac14c5accb406ff7a87c2e9b5434a_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">跑跑跑：Review DTW</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic3.zhimg.com/v2-58dac14c5accb406ff7a87c2e9b5434a_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/71927793\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/equation_ipico.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic3.zhimg.com/equation_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">ChrisCao：对Searching and Mining Trillions of Time Series Subsequences under Dynamic Time Warping的理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic3.zhimg.com/equation_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72751220\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/equation_ipico.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic3.zhimg.com/equation_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">KT.Flash：NLP论文学习1</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic3.zhimg.com/equation_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72704388\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">bradning：我对2012年KDD Best Paper论文的解读</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72519177\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">曾昭源：对Dynamic Time Warping（DWT）及其优化的理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72135444\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">Dong：动态时间规整学习笔记</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72230393\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-db972849262477a44d368af299159bb9_180x120.jpg\" data-image-width=\"1084\" data-image-height=\"272\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic2.zhimg.com/v2-db972849262477a44d368af299159bb9_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">Godning：《基于DTW算法的海量时间子序列搜索与挖掘》的理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic2.zhimg.com/v2-db972849262477a44d368af299159bb9_180x120.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72729236\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/equation_ipico.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic1.zhimg.com/equation_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">我爱吃西瓜123：动态时间规划下的时间序列数据的挖掘和分析</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic1.zhimg.com/equation_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/73490986\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-f9bccb191246cd2455fefdc552cac10f_180x120.jpg\" data-image-width=\"600\" data-image-height=\"313\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic4.zhimg.com/v2-f9bccb191246cd2455fefdc552cac10f_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">yanliu：初见DTW</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic4.zhimg.com/v2-f9bccb191246cd2455fefdc552cac10f_180x120.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/73482026\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-6cd51664f415795535e83f869fa9c655_180x120.jpg\" data-image-width=\"1200\" data-image-height=\"500\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic2.zhimg.com/v2-6cd51664f415795535e83f869fa9c655_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">金贵涛：动态时间规整下数万亿时间序列的搜索与挖掘——论文理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic2.zhimg.com/v2-6cd51664f415795535e83f869fa9c655_180x120.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//www.toutiao.com/i6711274314705928712/\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">基于动态规划DTW算法加速衡量两个不同的时间序列的相似性</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>www.toutiao.com</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72525469\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">前面：（论文阅读理解）基于DTW万亿级时序序列搜索与挖掘（原名放不下标题。。。）</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72425659\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-780aef756779b6c1a187c0e951c943df_180x120.jpg\" data-image-width=\"993\" data-image-height=\"342\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic4.zhimg.com/v2-780aef756779b6c1a187c0e951c943df_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">跨界工程师：基于DTW算法时间序列搜索子序列论文的理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic4.zhimg.com/v2-780aef756779b6c1a187c0e951c943df_180x120.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/73366011\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-2a72b7a85cfff135dee77668766ff7c3_180x120.jpg\" data-image-width=\"970\" data-image-height=\"108\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic4.zhimg.com/v2-2a72b7a85cfff135dee77668766ff7c3_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">Vico：DTW(Dynamic Time Warping)动态时间规整运算优化</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic4.zhimg.com/v2-2a72b7a85cfff135dee77668766ff7c3_180x120.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//blog.csdn.net/github_38243220/article/details/96089480\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">https://blog.csdn.net/github_38243220/article/details/96089480</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>blog.csdn.net</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//blog.csdn.net/cfdoge/article/details/94604091\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">https://blog.csdn.net/cfdoge/article/details/94604091</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>blog.csdn.net</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72453060\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/equation_ipico.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic3.zhimg.com/equation_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">williamrose：动态时间规整下搜索和挖掘数万亿个时间序列子序列</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic3.zhimg.com/equation_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72500011\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">tinyfisher：论文理解：The UCR Suite of DTW</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72542499?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=1077337851766644736\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">小重山：基于时间规整算法下的搜索挖掘大数量级的时间子序列</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72542821\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">licheeng：DTW算法初步理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/71820324\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/equation_ipico.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic3.zhimg.com/equation_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">Natsuki：DTW算法及快速计算技巧介绍</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic3.zhimg.com/equation_ipico.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/72512010\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-468e57ccc80fe08ec3179b364755a2f7_180x120.jpg\" data-image-width=\"440\" data-image-height=\"224\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic4.zhimg.com/v2-468e57ccc80fe08ec3179b364755a2f7_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">Allan：动态时间弯曲与时间序列相似性搜索</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic4.zhimg.com/v2-468e57ccc80fe08ec3179b364755a2f7_180x120.jpg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/73474793\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">freya：序列匹配 - DTW（ Dynamic Time Wrapping）- 粗读</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg\"/></span></span></a><a target=\"_blank\" href=\"https://zhuanlan.zhihu.com/p/73292069\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-578c357e5566f2d7f1f73a18fbeb35af_180x120.jpg\" data-image-width=\"1280\" data-image-height=\"720\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic4.zhimg.com/v2-578c357e5566f2d7f1f73a18fbeb35af_180x120.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">李萌：对DTW在亿万级别时间序列下优化的理解</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>zhuanlan.zhihu.com</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--horizontal\" alt=\"图标\" src=\"https://pic4.zhimg.com/v2-578c357e5566f2d7f1f73a18fbeb35af_180x120.jpg\"/></span></span></a><p class=\"ztext-empty-paragraph\"><br/></p><h2>Some Other Related Work</h2><p>DTW是一个极其简单又高效的算法，可以应用在几乎任何关于时序相关的数据。 下面给出了几个其他有趣的工作。 </p><p><b>A.  利用DTW计算短文本之间的相似度</b></p><p>文本的相似度对于任何NLP工作来说尤其重要，而且我们可以把文本相似度计算看做是单词匹配的过程，这样自然就可以联想起Alignment， 也就是DTW可以发挥的空间。 下面一个文章介绍如何使用DTW来计算短文本之间相似度，供参考。但论文里的算法并不是目前主流算法，或许我们可以针对短文本提出更好的DTW算法？</p><p>Liu, Xiaoying, Yiming Zhou, and Ruoshi Zheng. &#34;Sentence similarity based on dynamic time warping.&#34; In<i>International Conference on Semantic Computing (ICSC 2007)</i>, pp. 250-256. IEEE, 2007.</p><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//ieeexplore.ieee.org/stamp/stamp.jsp%3Farnumber%3D4338356\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">Sentence Similarity based on Dynamic Time Warping</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>ieeexplore.ieee.org</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><p class=\"ztext-empty-paragraph\"><br/></p><p><b>B. 利用DTW识别手势</b></p><p>手势识别已经成为比较流行的技术了，包括在Tablet PC, 各类手机上都很常见。对于这类问题最简单的方法其实就是使用DTW。 提前把一些标准的模板存放在库里面，然后新的手势进入系统之后再匹配就可以了。人机交互里有个经典的工作叫做 &#34;$1 Recognizer&#34;,  可以基于不到100行代码即可以实现一个可以商用的在Tablet上的手势识别。 </p><p>Wobbrock, J.O., Wilson, A.D. and Li, Y., 2007, October. Gestures without libraries, toolkits or training: a $1 recognizer for user interface prototypes. In<i>Proceedings of the 20th annual ACM symposium on User interface software and technology</i>(pp. 159-168). ACM.</p><a target=\"_blank\" href=\"https://link.zhihu.com/?target=http%3A//faculty.washington.edu/wobbrock/pubs/uist-07.01.pdf\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">http://faculty.washington.edu/wobbrock/pubs/uist-07.01.pdf</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>faculty.washington.edu</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><a target=\"_blank\" href=\"https://link.zhihu.com/?target=http%3A//depts.washington.edu/ilab/proj/dollar/index.html\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-04f279efbf7bdec2310a24c08431f48b_ipico.jpg\" data-image-width=\"697\" data-image-height=\"643\" class=\"LinkCard LinkCard--hasImage\"><span class=\"LinkCard-backdrop\" style=\"background-image:url(https://pic4.zhimg.com/v2-04f279efbf7bdec2310a24c08431f48b_ipico.jpg)\"></span><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">$1 Recognizer</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>depts.washington.edu</span></span><span class=\"LinkCard-imageCell\"><img class=\"LinkCard-image LinkCard-image--square\" alt=\"图标\" src=\"https://pic4.zhimg.com/v2-04f279efbf7bdec2310a24c08431f48b_ipico.jpg\"/></span></span></a><p class=\"ztext-empty-paragraph\"><br/></p><p><b>C. 利用DTW来做Speaker Verification或者简单的语言识别</b></p><p>对于IOT领域，语音识别或者说话人识别任务尤其重要。但这些任务区别于传统的语音识别，因为任务本身是圈定在一个有限范围的。例如，一个智能设备它能识别的命令是有限的，而且基本都是提前定义好。 另外，说话人识别里，一个家庭成员数量也比较有限。 对于这类的问题，我们完全可以通过模板匹配的方式来解决，当然可以使用DTW算法来计算说话人相似度，语音的相似度等等。 </p><p>Muda, Lindasalwa, Mumtaj Begam, and Irraivan Elamvazuthi. &#34;Voice recognition algorithms using mel frequency cepstral coefficient (MFCC) and dynamic time warping (DTW) techniques.&#34; <i>arXiv preprint arXiv:1003.4083</i> (2010).</p><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1003.4083.pdf%25C3%25A6%25E2%2580%2593%25E2%2580%25A1%25C3%25A4%25C2%25BB%25C2%25B6%25C3%25AF%25C2%25BC%25C5%2592%25C3%25A5%25E2%2580%259D%25C2%25AF%25C3%25A4%25C2%25B8%25E2%2582%25AC%25C3%25A7%25C5%2593%25E2%2580%25B9%25C3%25A8%25C2%25B5%25C2%25B7%25C3%25A6%2520%25C2%25A5%25C3%25A5%2520%25E2%2580%259C%25C3%25A4%25C2%25BA%25C2%25BA%25C3%25A7%25C5%25A1%25E2%2580%259E%25C3%25A6%25CB%259C%25C2%25AFFFT%25C3%25AF%25C2%25BC%25C5%2592%25C3%25A4%25C2%25BD%25E2%2580%25A0%25C3%25A6%25CB%259C%25C2%25AF%25C3%25AF%25C2%25BC%25C5%2592%25C3%25A6%25CB%2586%25E2%2580%2598%25C3%25A4%25C2%25B8%2520%25C3%25A6%25E2%2580%25B0%25E2%2580%259C%25C3%25A7%25C2%25AE%25E2%2580%2594%25C3%25A5%25C2%25B0%2520%25C3%25A8%25C2%25AF%25E2%2580%25A2%25C3%25A5%25E2%2580%2599%25C5%2592%25C3%25A5%25C2%25AE%25C5%25BE%25C3%25A7%25C5%25BD%25C2%25B0FFT%25C3%25A7%25C2%25AE%25E2%2580%2594%25C3%25A6%25C2%25B3%25E2%2580%25A2%25C3%25AF%25C2%25BC%25C5%2592%25C3%25A6%25C5%2593%25E2%2580%25B0%25C3%25A9%25E2%2580%259A%25C2%25A3%25C3%25A9%25E2%2580%25A1%25C5%2592%25C3%25A6%25C5%2593%25E2%2580%25B0%25C3%25A5%25E2%2580%25BA%25C2%25BE%25C3%25A4%25C2%25B9%25C2%25A6%25C3%25A9%25C2%25A6%25E2%2580%25A0%25C3%25A3%25E2%2582%25AC%25E2%2580%259A%25C3%25A5%25C2%25B8%25C5%2592%25C3%25A6%25C5%2593%25E2%2580%25BA%25C3%25A6%25CB%2586%25E2%2580%2598%25C3%25A5%2520%25C2%25AF%25C3%25A4%25C2%25BB%25C2%25A5%25C3%25A5%25C5%2593%25C2%25A8%25C3%25A4%25C2%25B8%25E2%2582%25AC%25C3%25A4%25C2%25B8%25C2%25AA%25C3%25A6%25C5%2593%25CB%2586%25C3%25A5%25E2%2580%25A0%25E2%2580%25A6%25C3%25A5%25C2%25BC%25E2%2582%25AC%25C3%25A5%2520%25E2%2580%2598%25C3%25A5%25E2%2580%25A1%25C2%25BA%25C3%25A6%2520%25C2%25A5%25C3%25AF%25C2%25BC%25C5%2592%25C3%25A7%25E2%2580%259E%25C2%25B6%25C3%25A5%2520%25C5%25BD%25C3%25A5%25C2%25BC%25E2%2582%25AC%25C3%25A5%25C2%25A7%25E2%2580%25B9%25C3%25A7%25C2%25A0%25E2%2580%259D%25C3%25A7%25C2%25A9%25C2%25B6%25C3%25A9%25C2%25A9%25C2%25AC%25C3%25A5%25C2%25B0%25E2%2580%259D%25C3%25A7%25C2%25A7%25E2%2580%2598%25C3%25A5%25C2%25A4%25C2%25AB%25C3%25A6%25C2%25A8%25C2%25A1%25C3%25A5%25C5%25BE%25E2%2580%25B9%25C3%25AF%25C2%25BC%25C5%2592%25C3%25A5%25C2%25B8%25C5%2592%25C3%25A6%25C5%2593%25E2%2580%25BA%25C3%25A6%25E2%2580%25B0%25C2%25BE%25C3%25A5%25CB%2586%25C2%25B0%25C3%25A8%25C2%25A7%25C2%25A3%25C3%25A5%25E2%2580%25A0%25C2%25B3%25C3%25A6%25E2%2580%2593%25C2%25B9%25C3%25A6%25C2%25A1%25CB%2586%25C3%25A3%25E2%2582%25AC%25E2%2580%259A%25C3%25A8%25C2%25BF%25E2%2584%25A2%25C3%25A7%25C2%25AF%25E2%2580%25A1%25C3%25A8%25C2%25AE%25C2%25BA%25C3%25A6%25E2%2580%2593%25E2%2580%25A1%25C3%25A6%25CB%259C%25C2%25AFMFCC%25C3%25A7%25C5%25A1%25E2%2580%259E%25C3%25A4%25C2%25B8%25E2%2582%25AC%25C3%25A4%25C2%25B8%25C2%25AA%25C3%25A5%25C2%25BE%25CB%2586%25C3%25A5%25C2%25A5%25C2%25BD%25C3%25A7%25C5%25A1%25E2%2580%259E%25C3%25A8%25C2%25B5%25C2%25B7%25C3%25A7%25E2%2580%259A%25C2%25B9%25C3%25A5%2520%25E2%2580%2594%25C3%25AF%25C2%25BC%25C5%25B8\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">https://arxiv.org/pdf/1003.4083.pdf%C3%A6%E2%80%93%E2%80%A1%C3%A4%C2%BB%C2%B6%C3%AF%C2%BC%C5%92%C3%A5%E2%80%9D%C2%AF%C3%A4%C2%B8%E2%82%AC%C3%A7%C5%93%E2%80%B9%C3%A8%C2%B5%C2%B7%C3%A6%20%C2%A5%C3%A5%20%E2%80%9C%C3%A4%C2%BA%C2%BA%C3%A7%C5%A1%E2%80%9E%C3%A6%CB%9C%C2%AFFFT%C3%AF%C2%BC%C5%92%C3%A4%C2%BD%E2%80%A0%C3%A6%CB%9C%C2%AF%C3%AF%C2%BC%C5%92%C3%A6%CB%86%E2%80%98%C3%A4%C2%B8%20%C3%A6%E2%80%B0%E2%80%9C%C3%A7%C2%AE%E2%80%94%C3%A5%C2%B0%20%C3%A8%C2%AF%E2%80%A2%C3%A5%E2%80%99%C5%92%C3%A5%C2%AE%C5%BE%C3%A7%C5%BD%C2%B0FFT%C3%A7%C2%AE%E2%80%94%C3%A6%C2%B3%E2%80%A2%C3%AF%C2%BC%C5%92%C3%A6%C5%93%E2%80%B0%C3%A9%E2%80%9A%C2%A3%C3%A9%E2%80%A1%C5%92%C3%A6%C5%93%E2%80%B0%C3%A5%E2%80%BA%C2%BE%C3%A4%C2%B9%C2%A6%C3%A9%C2%A6%E2%80%A0%C3%A3%E2%82%AC%E2%80%9A%C3%A5%C2%B8%C5%92%C3%A6%C5%93%E2%80%BA%C3%A6%CB%86%E2%80%98%C3%A5%20%C2%AF%C3%A4%C2%BB%C2%A5%C3%A5%C5%93%C2%A8%C3%A4%C2%B8%E2%82%AC%C3%A4%C2%B8%C2%AA%C3%A6%C5%93%CB%86%C3%A5%E2%80%A0%E2%80%A6%C3%A5%C2%BC%E2%82%AC%C3%A5%20%E2%80%98%C3%A5%E2%80%A1%C2%BA%C3%A6%20%C2%A5%C3%AF%C2%BC%C5%92%C3%A7%E2%80%9E%C2%B6%C3%A5%20%C5%BD%C3%A5%C2%BC%E2%82%AC%C3%A5%C2%A7%E2%80%B9%C3%A7%C2%A0%E2%80%9D%C3%A7%C2%A9%C2%B6%C3%A9%C2%A9%C2%AC%C3%A5%C2%B0%E2%80%9D%C3%A7%C2%A7%E2%80%98%C3%A5%C2%A4%C2%AB%C3%A6%C2%A8%C2%A1%C3%A5%C5%BE%E2%80%B9%C3%AF%C2%BC%C5%92%C3%A5%C2%B8%C5%92%C3%A6%C5%93%E2%80%BA%C3%A6%E2%80%B0%C2%BE%C3%A5%CB%86%C2%B0%C3%A8%C2%A7%C2%A3%C3%A5%E2%80%A0%C2%B3%C3%A6%E2%80%93%C2%B9%C3%A6%C2%A1%CB%86%C3%A3%E2%82%AC%E2%80%9A%C3%A8%C2%BF%E2%84%A2%C3%A7%C2%AF%E2%80%A1%C3%A8%C2%AE%C2%BA%C3%A6%E2%80%93%E2%80%A1%C3%A6%CB%9C%C2%AFMFCC%C3%A7%C5%A1%E2%80%9E%C3%A4%C2%B8%E2%82%AC%C3%A4%C2%B8%C2%AA%C3%A5%C2%BE%CB%86%C3%A5%C2%A5%C2%BD%C3%A7%C5%A1%E2%80%9E%C3%A8%C2%B5%C2%B7%C3%A7%E2%80%9A%C2%B9%C3%A5%20%E2%80%94%C3%AF%C2%BC%C5%B8</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>arxiv.org</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><p class=\"ztext-empty-paragraph\"><br/></p><p><b>D.  在DTW中使用Mahalanobis距离</b></p><p>通常情况下，DTW计算中使用欧式距离。但对于某一个时间节点特征为向量的情况，我们完全可以试图去学习Distance Metric, 比如Mahalanobis距离。 对于多维度的特征问题，一个时序可以表示成一个矩阵。对于学习Mahalanobis距离，我们需要一些样本数据，使得能够去构建损失函数比如Hinge Loss。 </p><p>Garreau, D., Lajugie, R., Arlot, S. and Bach, F., 2014. Metric learning for temporal sequence alignment. In<i>Advances in neural information processing systems</i>(pp. 1817-1825).</p><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1409.3136.pdf\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">https://arxiv.org/pdf/1409.3136.pdf</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>arxiv.org</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><p class=\"ztext-empty-paragraph\"><br/></p><p><b>E. DTW不是一个严格意义上的Metric</b></p><p>DTW虽然它有效，但他并不是严格意义上的Metric，因为它不满足&#34;Triangle Inequality&#34;。 也就是对于距离来说，它必须要满足一个条件: <img src=\"https://www.zhihu.com/equation?tex=d%28x%2C+y%29+%2B+d%28y%2C+z%29+%5Cgeq+d%28x%2C+z%29\" alt=\"d(x, y) + d(y, z) \\geq d(x, z)\" eeimg=\"1\"/> 。 然而DTW不具备这个特点，也就意味着DTW不是一个metric。 如果一个距离计算不是一个metric， 它将会失去很多metric space上享有的优势，而且不能成为Kernel （不满足positive semidefinite)。 那如何改造DTW使得满足这些条件呢？ 下面文章给出了一个答案。</p><p>Cuturi, M., 2011. Fast global alignment kernels. In<i>Proceedings of the 28th international conference on machine learning (ICML-11)</i>(pp. 929-936).</p><a target=\"_blank\" href=\"https://link.zhihu.com/?target=http%3A//www.icml-2011.org/papers/489_icmlpaper.pdf\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">http://www.icml-2011.org/papers/489_icmlpaper.pdf</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>www.icml-2011.org</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><p class=\"ztext-empty-paragraph\"><br/></p><p><b>F. DTW是一个Non-differential 算法，如何结合Neural Network？ </b></p><p>DTW本质上是一个动态规划的算法，而且动态规划算法本身是Non-differential的。 也就意味着这些operator没有办法适用于其他的模型比如neural network， 因为不能够参与梯度的计算比如反向传到法。所以有些人会去研究如何让DP算法具备differential特点呢？ 这就意味着在DP算法基础上定义一些differential operator。 下面文章讲述了如何解决这个问题。 </p><p>Mensch, A. and Blondel, M., 2018. Differentiable dynamic programming for structured prediction and attention.<i>arXiv preprint arXiv:1802.03676</i>.</p><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1802.03676.pdf\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">https://arxiv.org/pdf/1802.03676.pdf</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>arxiv.org</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><p>Cuturi, M. and Blondel, M., 2017, August. Soft-DTW: a differentiable loss function for time-series. In <i>Proceedings of the 34th International Conference on Machine Learning-Volume 70</i> (pp. 894-903). JMLR. org.</p><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1703.01541.pdf\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">https://arxiv.org/pdf/1703.01541.pdf</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>arxiv.org</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><p class=\"ztext-empty-paragraph\"><br/></p><p><b>G. DTW结合深度学习的应用</b></p><p>实际上DTW可以结合深度学习来一起使用，并不一定作为深度学习中的某一个layer， 而是先通过深度学习把数据映射到低维空间之后，再使用DTW算法来识别。 可以使用Hinge Loss, Triple Loss这些损失函数。 </p><p>Trigeorgis, G., Nicolaou, M.A., Zafeiriou, S. and Schuller, B.W., 2016. Deep canonical time warping. In<i>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</i>(pp. 5110-5118).</p><a target=\"_blank\" href=\"https://link.zhihu.com/?target=https%3A//ibug.doc.ic.ac.uk/media/uploads/documents/0005.pdf\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"LinkCard LinkCard--noImage\"><span class=\"LinkCard-content\"><span class=\"LinkCard-text\"><span class=\"LinkCard-title\" data-text=\"true\">https://ibug.doc.ic.ac.uk/media/uploads/documents/0005.pdf</span><span class=\"LinkCard-meta\"><span style=\"display:inline-flex;align-items:center\">​<svg class=\"Zi Zi--InsertLink\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"17\" height=\"17\"><path d=\"M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z\" fill-rule=\"evenodd\"></path></svg></span>ibug.doc.ic.ac.uk</span></span><span class=\"LinkCard-imageCell\"><div class=\"LinkCard-image LinkCard-image--default\"><svg class=\"Zi Zi--Browser\" fill=\"currentColor\" viewBox=\"0 0 24 24\" width=\"32\" height=\"32\"><path d=\"M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z\"></path></svg></div></span></span></a><p class=\"ztext-empty-paragraph\"><br/></p><p>All the learning materials coming from the camp,  copyright reserved for all the members from the camp. If you have any questions regarding the contents,  pls leave the comments,  Thanks!   </p>", 
            "topic": [
                {
                    "tagLink": "https://www.zhihu.com/topic/19559450", 
                    "tag": "机器学习"
                }, 
                {
                    "tagLink": "https://www.zhihu.com/topic/19551275", 
                    "tag": "人工智能"
                }, 
                {
                    "tagLink": "https://www.zhihu.com/topic/19560026", 
                    "tag": "自然语言处理"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/72370235", 
            "userName": "李文哲", 
            "userLink": "https://www.zhihu.com/people/740cde3d3ba93d33fc59b31f49b2b03b", 
            "upvote": 198, 
            "title": "机器学习中的MLE、MAP、贝叶斯估计", 
            "content": "<p>即使学过机器学习的人，对机器学习中的<b>MLE(极大似然估计)、MAP(最大后验估计)以及贝叶斯估计(Bayesian)</b>仍有可能一知半解。对于一个基础模型，通常都可以从这三个角度去建模，比如对于逻辑回归（Logistics Regression）来说：</p><blockquote><b>MLE</b>: Logistics Regression <b>MAP</b>: Regularized Logistics Regression  <b>Bayesian</b>: Bayesian Logistic Regression </blockquote><p>本文结合实际例子，以通俗易懂的方式去讲解这三者之间的本质区别，希望帮助读者扫清理解中的障碍。  </p><p><b>先导知识点： 假设空间（Hypothesis Space）</b></p><p>什么叫假设空间呢？我们可以这样理解。机器学习包含很多种算法，比如线性回归、支持向量机、神经网络、决策树、GDBT等等。我们在建模的时候，第一步就是要选择一个特定的算法比如“支持向量机”。<b>一旦选择了一个算法，就相当于我们选择了一个假设空间。</b>在一个假设空间里，我们通常会有无数种不同的解（或者可以理解成模型），<b>一个优化算法（比如梯度下降法）做的事情就是从中选择最好的一个解或者多个解/模型</b>，当然优化过程要依赖于样本数据。举个例子，如果我们选择用支持向量机，那相当于我们可选的解/模型集中在上半部分（蓝色点）。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b16dfc4f554c08953a569537d385b47c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"694\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b16dfc4f554c08953a569537d385b47c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;694&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"694\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b16dfc4f554c08953a569537d385b47c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b16dfc4f554c08953a569537d385b47c_b.jpg\"/></figure><p>                             （这个画的不精确，只是用来说明大概意思.....）</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>一个具体“toy”问题</b></p><blockquote>“ 张三遇到了一个数学难题，想寻求别人帮助。通过一番思考之后发现自己的朋友在清华计算机系当老师。于是，他决定找清华计算机系学生帮忙。那张三用什么样的<b>策略</b>去寻求帮助呢？</blockquote><p>在这里，“清华计算机系”是一个假设空间。在这个假设空间里，每一位学生可以看做是一个模型（的实例化）。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a3b55df7dd1c3820ed71bfd523639281_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"749\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-a3b55df7dd1c3820ed71bfd523639281_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;749&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"749\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-a3b55df7dd1c3820ed71bfd523639281_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a3b55df7dd1c3820ed71bfd523639281_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>对于张三来说，他有<b>三种不同的策略</b>可以选择。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>第一种策略 : MLE</b></p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>第一种策略就是从系里选出过往成绩最好的学生，并让他去解答这个难题</b>。比如我们可以选择过去三次考试中成绩最优秀的学生。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-84f78b244648499f4cb2b8e822a4aaf8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"777\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-84f78b244648499f4cb2b8e822a4aaf8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;777&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"777\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-84f78b244648499f4cb2b8e822a4aaf8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-84f78b244648499f4cb2b8e822a4aaf8_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>一般的学习流程分为“学习过程”和“预测过程”。第一种策略的方案可以用下面的图来表示。</b>在这里，<b>学习过程相当于从所有系的学生中挑选出成绩最好的学生。</b>所以，这里的“学生过往成绩单”就是我们已知的<b>训练数据</b> <b>D</b>， 选出成绩最好的学生（计算历史平均分数，并选出最高的），这个过程就是MLE。一旦我们找到了成绩最好的学生，就可以进入预测环节。<b>在预测环节中，我们就可以让他回答张三手里的难题 x&#39;, 之后就可以得到他给出的解答</b> <b>y&#39;。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-00cb106cc90035cbe62d2801740aff11_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"554\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-00cb106cc90035cbe62d2801740aff11_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;554&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"554\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-00cb106cc90035cbe62d2801740aff11_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-00cb106cc90035cbe62d2801740aff11_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>第二种策略：MAP</b></p><p class=\"ztext-empty-paragraph\"><br/></p><p>跟第一种策略的不同点在于，<b>第二种策略中我们听取了老师的建议</b>，老师就是张三的朋友。这位老师给出了自己的观点：<i>“小明和小花的成绩中可能存在一些水分”。</i>当我们按照成绩的高低给学生排序，假设前两名依次为小明和小花，如果我们不考虑这位老师的评价，则我们肯定把小明作为目标对象。然而，既然老师已经对小明和小花做了一些负面的评价，那这个时候，<b>我们很有可能最后选择的是班级里的第三名</b>，而不是小明或者小花。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-323bb1ba7d4008a6f9927d3f255c994e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"782\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-323bb1ba7d4008a6f9927d3f255c994e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;782&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"782\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-323bb1ba7d4008a6f9927d3f255c994e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-323bb1ba7d4008a6f9927d3f255c994e_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>我们把第二种策略的过程也用一个图来描述。与上面的图相比，<b>唯一的区别在于这里多出了老师的评价，我们称之为 Prior。</b> 也就是说我们根据学生以往的成绩并结合老师评价，选择了一位我们认为最优秀的学生（可以看成是模型）。之后就可以让他去回答张老师的难题 x&#39;，并得到他的解答 y&#39;。整个过程类似于MAP的估计以及预测。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ee3f8aab92ad7e87d2b0b31a110e306f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"611\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-ee3f8aab92ad7e87d2b0b31a110e306f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;611&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"611\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-ee3f8aab92ad7e87d2b0b31a110e306f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ee3f8aab92ad7e87d2b0b31a110e306f_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>到这里，有些读者可能会有一些疑惑：“<i>老师的评价(Prior)跟学生过往的成绩（Observation）是怎么结合在一起的？”</i>。 为了回答这个问题，我们不得不引出一个非常著名的定理，叫做<b>贝叶斯定理，</b>如下图所示。左边的项是MAP需要优化的部分，通过贝叶斯定理这个项可以分解成MLE（第一种策略）和Prior，也就是老师的评价。在这里，分母是常数项（Constant），所以不用考虑。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1c8e255badf138e54dcd7632b7b3c8c8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"399\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-1c8e255badf138e54dcd7632b7b3c8c8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;399&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"399\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-1c8e255badf138e54dcd7632b7b3c8c8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-1c8e255badf138e54dcd7632b7b3c8c8_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>第三种策略 - Bayesian</b></p><p>最后，我们来介绍第三种策略。这种策略应该很多人也可以想象得到，<b>其实就是让所有人都去参与回答张三的难题，但最后我们通过一些加权平均的方式获得最终的答案。</b>比如有三个学生，而且我们对这三个学生情况没有任何了解。通过提问，第一个学生回答的答案是A，第二个学生回答的答案也是A，但第三个学生回答的是B。在这种情况下，我们基本可以把A作为标准答案。接着再考虑一个稍微复杂的情况，假设我们通过以往他们的表现得知第三个学生曾经多次获得过全国奥赛的金牌，那这个时候该怎么办？ 很显然，<b>在这种情况下，我们给予第三个学生的话语权肯定要高于其他两位学生</b>。</p><p>我们把上面的这种思路应用到张三的问题上，其实相当于我们让所有计算机系的学生参与回答这个问题，之后把他们的答案进行汇总并得出最终的答案。如果我们知道每一位学生的话语权（权重），这个汇总的过程是确定性（deterministic)。 但每一位学生的话语权（权重）怎么得到呢？ <b>这就是贝叶斯估计做的事情！</b></p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-04debf65bb9bbcd70702c736a82903b4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"747\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-04debf65bb9bbcd70702c736a82903b4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;747&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"747\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-04debf65bb9bbcd70702c736a82903b4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-04debf65bb9bbcd70702c736a82903b4_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>我们用下面的一幅图来讲述贝叶斯估计和预测的整个过程。跟MAP类似，我们已知每一位学生过去三次考试考试成绩（D）以及老师的评价（Prior）。 但跟MAP不同的是，<b>我们这里的目标不再是- “选出最优秀的学生”，而是通过观测数据（D）去获得每一位学生的发言权（权重），</b>而且这些权重全部加起来要等于1， 相当于是一个valid分布(distribution)。</p><p>总结起来，在第三种策略之下，<b>给定过去考试成绩(</b>D<b>)和老师的评价（</b>Prior<b>）, 我们的目标是估计学生权重的分布，</b>也称之为<b>Posterior Distribution</b>。 那这个分布具体怎么去估计呢？ 这部分就是贝叶斯估计做的事情，有很多种方法可以做这件事情，比如MCMC, Variational Method等等，但这并不是本文章的重点，所以不在这里进一步解释，有兴趣的读者可以关注之后关于贝叶斯的专栏文章。从直观的角度思考，因为我们知道每一位学生过往的成绩，所以我们很容易了解到他们的能力水平进而估计出每一位学生的话语权（权重）。</p><p><b>一旦我们获得了这个分布（也就是每一位学生的权重），接下来就可以通过类似于加权平均的方式做预测了，那些权重高的学生话语权自然就越大。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-66e9d36d134db39f70fd06228eec7f86_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"544\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-66e9d36d134db39f70fd06228eec7f86_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;544&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"544\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-66e9d36d134db39f70fd06228eec7f86_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-66e9d36d134db39f70fd06228eec7f86_b.jpg\"/></figure><p>以上是对MLE, MAP以及贝叶斯估计的基本讲解。下面我们试图去回答两个常见的问题。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>Q:  随着我们观测到越来越多的数据，MAP估计逐步逼近MLE，这句话怎么理解？</b></p><p>我们接着使用之前MAP（第二种策略）的例子。在这里，我们对原来的问题稍作改变。在之前的例子里我们假设能够得到每一位学生<b>过去三次考试中的成绩。</b>但在这里，我们进一步假定可以获得每一位学生过去<b>100次考试中的成绩。</b></p><p>那这样的修改会带来什么样的变化呢？ 如果仔细想一想，其实也很容易想得到。我们设想一下这样的两种场景。假设我们知道某一位学生过去三次的考试成绩比较优异，但老师却告诉我们这位学生能力其实不怎么样，那这时候我们很可能就去相信老师了，毕竟仅仅通过三次考试的成绩很难对一个学生有全面的了解。但相反，假设我们了解到这位学生<b>在过去100次考试中全部获得了班里第一名</b>，但同时老师又告诉我们这位学生的能力其实不怎么样，那这时候我们会有什么样的反应？ 两三次考试或许可以算做是运气，但连续100次都是第一名这件事情很难再跟运气画等号吧？ 我们甚至可能会去怀疑老师的品德，是不是故意污蔑人家？</p><p>这就是说，当我们观测到的数据越来越多的时候，我们从数据中获取的信息的置信度是越高的，相反老师提供的反馈（Prior）的重要性就会逐渐降低。理想情况下，当我们拥有无穷多的数据样本时，MAP会逼近MLE估计，道理都是一样的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3903a0643d5b1e08958223d97d1ff00a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"600\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-3903a0643d5b1e08958223d97d1ff00a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;600&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"600\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-3903a0643d5b1e08958223d97d1ff00a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-3903a0643d5b1e08958223d97d1ff00a_b.jpg\"/></figure><p><b>Q:  为什么贝叶斯估计会比MLE, MAP难？</b></p><p>回顾一下，MLE 和MAP都是在寻找一个最优秀的学生。贝叶斯估计则是在估计每一位学生的权重。第一种情况下，为了寻找最优秀的学生，我们只需知道学生之间的“相对”优秀程度。这个怎么理解呢？ 比如一个班里有三个学生A,B,C，我们知道学生A比B优秀，同时知道B比C优秀，那这时候就可以推断出学生A是最优秀的，我们并不需要明确知道A的成绩是多少，B的成绩是多少.....</p><p><b>但在贝叶斯估计模式下，我们必须要知道每一个学生的绝对权重</b>，因为最后我们获得的答案是所有学生给出的答案的加权平均，而且所有学生的权重加起来要保证等于1(任何一个分布的积分和必须要等于1）。 假设我们知道每一位学生的能力值，a1, a2,.... an，这个能作为权重吗？ 显然不能。为了获得权重，有一种最简单的方法就是先求和，然后再求权重。比如先计算 a1+...+an = S,  再用a1/S 作为权重。这貌似看起来也不难啊，只不过多做了一个加法操作？ </p><p>我们很容易看出这个加法操作的时间复杂度是O(n)，依赖于总体学生的数量。如果我们的假设空间只有几百名学生，这个是不成问题的。 但实际中，比如我们假设我们的模型用的是支持向量机，然后把假设空间里的每一个可行解比喻成学生，那这个假设空间里有多少个学生呢？ 是无数个！！， 也就是说需要对无穷多个数做这种加法操作。 当然，这种加法操作会以积分(integeral)的方式存在，但问题是这种积分通常没有一个closed-form的解，你必须要去近似地估计才可以，这就是MCMC或者Variational方法做的事情，不在这里多做解释。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>本文几点重要的Take-aways：</b></p><ul><li>每一个模型定义了一个假设空间，一般假设空间都包含无穷的可行解；</li><li>MLE不考虑先验（prior)，MAP和贝叶斯估计则考虑先验（prior）；</li><li>MLE、MAP是选择相对最好的一个模型（point estimation）， 贝叶斯方法则是通过观测数据来估计后验分布(posterior distribution)，并通过后验分布做群体决策，所以后者的目标并不是在去选择某一个最好的模型；</li><li>当样本个数无穷多的时候，MAP理论上会逼近MLE；</li><li>贝叶斯估计复杂度大，通常用MCMC等近似算法来近似</li></ul><p>最后贴一张总结的图:</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-321e2cb34e3fcde5c375a1fe24dffc64_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"790\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-321e2cb34e3fcde5c375a1fe24dffc64_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;790&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"790\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-321e2cb34e3fcde5c375a1fe24dffc64_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-321e2cb34e3fcde5c375a1fe24dffc64_b.jpg\"/></figure><p></p><p></p>", 
            "topic": [
                {
                    "tagLink": "https://www.zhihu.com/topic/19559450", 
                    "tag": "机器学习"
                }, 
                {
                    "tagLink": "https://www.zhihu.com/topic/19551275", 
                    "tag": "人工智能"
                }, 
                {
                    "tagLink": "https://www.zhihu.com/topic/19560026", 
                    "tag": "自然语言处理"
                }
            ], 
            "comments": [
                {
                    "userName": "手谈有乐", 
                    "userLink": "https://www.zhihu.com/people/b06588891e99ef28c8fa45ff8531a48d", 
                    "content": "<p>学习了，很清晰</p><a class=\"comment_sticker\" href=\"https://pic4.zhimg.com/v2-ba306425d0a7aee2c7260381f1bf7b97.gif\" data-width=\"\" data-height=\"\">[欢呼]</a>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "陈宇", 
                    "userLink": "https://www.zhihu.com/people/20a50a1dbbc12b2f67a7b67d72b96d31", 
                    "content": "根据文章可以认为：MAP=MLE*PRIOR，如果我把先验设得很低，即使样本有几千万，后验依然低于似然吧？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>是估计结果逼近似然，不是loss值逼近似然</p>", 
                            "likes": 0, 
                            "replyToAuthor": "陈宇"
                        }, 
                        {
                            "userName": "陈宇", 
                            "userLink": "https://www.zhihu.com/people/20a50a1dbbc12b2f67a7b67d72b96d31", 
                            "content": "明白了，多谢", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "暮光", 
                    "userLink": "https://www.zhihu.com/people/fe885cd46b46c63cc0f135dcaeb74726", 
                    "content": "<a class=\"comment_sticker\" href=\"https://pic4.zhimg.com/v2-db92f653a2ec17ea3ff309d6d56e8507.gif\" data-sticker-id=\"980770591112015872\"> [吃瓜]</a>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "梦里花落知多少", 
                    "userLink": "https://www.zhihu.com/people/b2828616e6811f144a49cb4421e16ea3", 
                    "content": "<p>文哲老师棒! 讲的真好</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "Zheng Vincent", 
                    "userLink": "https://www.zhihu.com/people/792016afd149fb0377208b62b9be092c", 
                    "content": "<p>讲的确实好！ 看李航老师书的第一章，提到了贝叶斯学习，但是怎么预测的部分讲的很不清楚，只给出了p(x|D)的计算方式，没有给出p(y|x)的计算方式，看了你的文章终于对MLE、MAP、贝叶斯估计有了一些认识。</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "手谈有乐", 
                    "userLink": "https://www.zhihu.com/people/b06588891e99ef28c8fa45ff8531a48d", 
                    "content": "<p>学习了，很清晰</p><a class=\"comment_sticker\" href=\"https://pic4.zhimg.com/v2-ba306425d0a7aee2c7260381f1bf7b97.gif\" data-width=\"\" data-height=\"\">[欢呼]</a>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "陈宇", 
                    "userLink": "https://www.zhihu.com/people/20a50a1dbbc12b2f67a7b67d72b96d31", 
                    "content": "根据文章可以认为：MAP=MLE*PRIOR，如果我把先验设得很低，即使样本有几千万，后验依然低于似然吧？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>是估计结果逼近似然，不是loss值逼近似然</p>", 
                            "likes": 0, 
                            "replyToAuthor": "陈宇"
                        }, 
                        {
                            "userName": "陈宇", 
                            "userLink": "https://www.zhihu.com/people/20a50a1dbbc12b2f67a7b67d72b96d31", 
                            "content": "明白了，多谢", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "暮光", 
                    "userLink": "https://www.zhihu.com/people/fe885cd46b46c63cc0f135dcaeb74726", 
                    "content": "<a class=\"comment_sticker\" href=\"https://pic4.zhimg.com/v2-db92f653a2ec17ea3ff309d6d56e8507.gif\" data-sticker-id=\"980770591112015872\"> [吃瓜]</a>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "梦里花落知多少", 
                    "userLink": "https://www.zhihu.com/people/b2828616e6811f144a49cb4421e16ea3", 
                    "content": "<p>文哲老师棒! 讲的真好</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "Zheng Vincent", 
                    "userLink": "https://www.zhihu.com/people/792016afd149fb0377208b62b9be092c", 
                    "content": "<p>讲的确实好！ 看李航老师书的第一章，提到了贝叶斯学习，但是怎么预测的部分讲的很不清楚，只给出了p(x|D)的计算方式，没有给出p(y|x)的计算方式，看了你的文章终于对MLE、MAP、贝叶斯估计有了一些认识。</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/72262071", 
            "userName": "李文哲", 
            "userLink": "https://www.zhihu.com/people/740cde3d3ba93d33fc59b31f49b2b03b", 
            "upvote": 6, 
            "title": "机器翻译之 - IBM Model 1的介绍", 
            "content": "<p>本文利用贝叶斯chain rule 对IBM model1模型进行了目标函数的推导与代码层面的一些实现，仅为学习时记录，理解不到位情况还请批评指正</p><blockquote>本文作为自然语言处理训练营的学习材料，原文来自于课程助教陈老师的专栏：<a href=\"https://zhuanlan.zhihu.com/p/72160554\" class=\"internal\"><span class=\"invisible\">https://</span><span class=\"visible\">zhuanlan.zhihu.com/p/72</span><span class=\"invisible\">160554</span><span class=\"ellipsis\"></span></a>  。  </blockquote><h2>一.重要概念说明</h2><p>1.<b>alignment</b>:在平行文本中，我们将一种语言中的单词与另一种语言中的单词的对齐叫做alignment(eg:das-&gt;the,Haus-&gt;house,ist-&gt;is,klein-&gt;small)，alignment只是对应关系，并不是概率值</p><p>2.<b>alignment function</b>:将i位置的一种语言单词，映射到另一语言单词位置j的函数叫alignment function <img src=\"https://www.zhihu.com/equation?tex=a+%3A+%7B1+%E2%86%92+1%2C+2+%E2%86%92+2%2C+3+%E2%86%92+3%2C+4+%E2%86%92+4%7D\" alt=\"a : {1 → 1, 2 → 2, 3 → 3, 4 → 4}\" eeimg=\"1\"/> .在python中通常用dict来表示对应关系，如(das,Haus,ist,klein) : (the,house,is,small)。这里值得注意的问题是，alignment仅为对应关系，并非翻译概率。</p><p>3.<b>IBM model1</b>:该模型是以统计alinment下语言1翻译为语言2的概率。IBM Model 1 采用最简单的假设：假设每个alignment所发生的概率相同。</p><p>以法文翻译为英文为例，如果法文单词有I个，对应翻译的英文单词有J个，则有 <img src=\"https://www.zhihu.com/equation?tex=I%5EJ\" alt=\"I^J\" eeimg=\"1\"/> 种（可能的对应关系，实际上有些法文是没有对应英文翻译的，（法文我不太了解，但是中文的话，以”了”,”吗”,”的”等字，其实翻译不出来英文的）算上没有对应关系的可能，则有 <img src=\"https://www.zhihu.com/equation?tex=%28I%2B1%29%5EJ\" alt=\"(I+1)^J\" eeimg=\"1\"/> 种可能。以下是model1中重要的元素声明：</p><p>a) 外来句子（法文）: 以<img src=\"https://www.zhihu.com/equation?tex=f%3D%28f_1%2Cf_2%2C...f_%7Bl_f%7D%29\" alt=\"f=(f_1,f_2,...f_{l_f})\" eeimg=\"1\"/> 表示，长度为 <img src=\"https://www.zhihu.com/equation?tex=l_f\" alt=\"l_f\" eeimg=\"1\"/></p><p>b) 英文句子（英文）: 以 <img src=\"https://www.zhihu.com/equation?tex=e%3D%28e1%2Ce2%2C%E2%80%A6%2Ce_%7Bl_e%7D%29\" alt=\"e=(e1,e2,…,e_{l_e})\" eeimg=\"1\"/> 表示，长度为 <img src=\"https://www.zhihu.com/equation?tex=l_e\" alt=\"l_e\" eeimg=\"1\"/></p><p>c) 目标函数： <img src=\"https://www.zhihu.com/equation?tex=P%28a%7Ce%2Cf%29\" alt=\"P(a|e,f)\" eeimg=\"1\"/> ，表示通过法语和英语为条件，找出其alignment。</p><p>d) 参数估计：EM算法，最大化期望算法，通过概率模型中寻找参数最大似然估计或者最大 后验估计的算法，其中概率模型依赖于无法观测的隐性变量。最大期望算法经过两个步骤交替进行计算，第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值；第二步是最大化（M），最大化在E步上求得的最大似然值来计算参数的值。M步上找到的参数估计值被用于下一个E步计算中，这个过程不断交替进行，使参数不断接近最大似然值。</p><h2>二．IBM model目标函数推导：</h2><p>在IBM model中，因为引入了alignment这个概念，因此，整个翻译过程都是通过在alignment关系下，最大化外语单词翻译为目标语言单词的概率。</p><p>1.<b>目标函数推导</b>：有了最大化外语单词翻译为目标语言单词的概率这个目标，该问题的目标函数为：<img src=\"https://www.zhihu.com/equation?tex=p%28a%7Ce%2C+f%29\" alt=\"p(a|e, f)\" eeimg=\"1\"/> ，由贝叶斯定理，可将这个条件概率转换为 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7Bp%28e%2C+a%7Cf%29%7D%7Bp%28e%7Cf%29%7D\" alt=\"\\frac{p(e, a|f)}{p(e|f)}\" eeimg=\"1\"/> .目标变为了计算 <img src=\"https://www.zhihu.com/equation?tex=P%28e%2Ca%7Cf%29\" alt=\"P(e,a|f)\" eeimg=\"1\"/>和 <img src=\"https://www.zhihu.com/equation?tex=P%28e%7Cf%29\" alt=\"P(e|f)\" eeimg=\"1\"/> 。结合noisy channel model，IBM模型注意到翻译模型中的一个隐含变量信息，及即句子中词语的对位信息：alignment a。于是有： <img src=\"https://www.zhihu.com/equation?tex=p%28e%7Cf%29+%3D+%5Csum_%7Ba%7D%5E%7B%7D%7Bp%28e%2C+a%7Cf%29%7D\" alt=\"p(e|f) = \\sum_{a}^{}{p(e, a|f)}\" eeimg=\"1\"/> ，所以我们重点应该是计算分母，我们将整个步骤划分为计算分母和计算整个目标函数上</p><p>（a）计算分母 <img src=\"https://www.zhihu.com/equation?tex=P%28e%7Cf%29\" alt=\"P(e|f)\" eeimg=\"1\"/> ，如下：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D++p%28e%7Cf%29+%26%3D+%5Csum_%7Ba%7D%5E%7B%7D%7Bp%28e%2C+a%7Cf%29%7D+%5C%5C+%26%3D%5Csum_%7Ba%281%29%3D0%7D%5E%7Bl_f%7D%7B%7D+...+%5Csum_%7Ba%28l_e%29%3D0%7D%5E%7Bl_f%7D%7Bp%28e%2Ca%7Cf%29%7D+%5C%5C++%26%3D%5Csum_%7Ba%281%29%3D0%7D%5E%7Bl_f%7D%7B%7D+...+%5Csum_%7Ba%28l_e%29%3D0%7D%5E%7Bl_f%7D%7B%5Cfrac%7B%5Cepsilon%7D%7B%28l_f+%2B+1%29%5E%7Bl_e%7D%7D%5Cprod_%7Bj%3D1%7D%5E%7Bl_e%7D%7Bt%28e_j%7Cf_%7Ba%28j%29%7D%29%7D%7D+%5C%5C++%26%3D%5Cfrac%7B%5Cepsilon%7D%7B%28l_f+%2B+1%29%5E%7Bl_e%7D%7D%5Csum_%7Ba%281%29%3D0%7D%5E%7Bl_f%7D%7B%7D+...+%5Csum_%7Ba%28l_e%29%3D0%7D%5E%7Bl_f%7D%7B%7D+%5Cprod_%7Bj%3D1%7D%5E%7Bl_e%7D%7Bt%28e_j%7Cf_%7Ba%28j%29%7D%29%7D+%5C%5C++%26%3D%5Cfrac%7B%5Cepsilon%7D%7B%28l_f+%2B+1%29%5E%7Bl_e%7D%7D%5Cprod_%7Bj%3D1%7D%5E%7Bl_e%7D%5Csum_%7Bi%3D0%7D%5E%7Bl_f%7D%7Bt%28e_j%7Cf_%7Bi%7D%29%7D++%5Cend%7Baligned%7D\" alt=\"\\begin{aligned}  p(e|f) &amp;= \\sum_{a}^{}{p(e, a|f)} \\\\ &amp;=\\sum_{a(1)=0}^{l_f}{} ... \\sum_{a(l_e)=0}^{l_f}{p(e,a|f)} \\\\  &amp;=\\sum_{a(1)=0}^{l_f}{} ... \\sum_{a(l_e)=0}^{l_f}{\\frac{\\epsilon}{(l_f + 1)^{l_e}}\\prod_{j=1}^{l_e}{t(e_j|f_{a(j)})}} \\\\  &amp;=\\frac{\\epsilon}{(l_f + 1)^{l_e}}\\sum_{a(1)=0}^{l_f}{} ... \\sum_{a(l_e)=0}^{l_f}{} \\prod_{j=1}^{l_e}{t(e_j|f_{a(j)})} \\\\  &amp;=\\frac{\\epsilon}{(l_f + 1)^{l_e}}\\prod_{j=1}^{l_e}\\sum_{i=0}^{l_f}{t(e_j|f_{i})}  \\end{aligned}\" eeimg=\"1\"/></p><p>由于在IBM model1中假设每个alignment所发生的概率相同，因此这里将整个条件概率按每个外语单词展开，因为每个外语单词都和每一个目标语言单词有对应概率，因此 <img src=\"https://www.zhihu.com/equation?tex=P%28a%7Ce_j%2Cf_i%29%3D%5Cfrac%7B%5Cepsilon%7D%7Bl_f%2B1%7D\" alt=\"P(a|e_j,f_i)=\\frac{\\epsilon}{l_f+1}\" eeimg=\"1\"/> ，<img src=\"https://www.zhihu.com/equation?tex=%5Cepsilon\" alt=\"\\epsilon\" eeimg=\"1\"/> 是常数项。将平行句子对，按外语单词与目标语言单词分别展开，则可得到两层累加关系。</p><p>（b）计算目标函数，如下：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+p%28a%7Ce%2C+f%29+%26%3D+%5Cfrac%7Bp%28e%2C+a%7Cf%29%7D%7Bp%28e%7Cf%29%7D+%5C%5C+%26%3D%5Cfrac%7B%5Cfrac%7B%5Cepsilon%7D%7B%28l_f+%2B+1%29%5E%7Bl_e%7D%7D%5Cprod_%7Bj%3D1%7D%5E%7Bl_e%7D%7Bt%28e_j%7Cf_%7Ba%28j%29%7D%29%7D%7D+%7B%5Cfrac%7B%5Cepsilon%7D%7B%28l_f+%2B+1%29%5E%7Bl_e%7D%7D%5Cprod_%7Bj%3D1%7D%5E%7Bl_e%7D%5Csum_%7Bi%3D0%7D%5E%7Bl_f%7D%7Bt%28e_j%7Cf_%7Bi%7D%29%7D%7D+%5C%5C+%26%3D%5Cprod_%7Bj%3D1%7D%5E%7Bl_e%7D%7B%5Cfrac%7Bt%28e_j%7Cf_%7Ba%28j%29%7D%29%7D%7B%5Csum_%7Bi%3D0%7D%5E%7Bl_f%7D%7Bt%28e_j%7Cf_%7Bi%7D%29%7D%7D%7D+%5Cend%7Baligned%7D\" alt=\"\\begin{aligned} p(a|e, f) &amp;= \\frac{p(e, a|f)}{p(e|f)} \\\\ &amp;=\\frac{\\frac{\\epsilon}{(l_f + 1)^{l_e}}\\prod_{j=1}^{l_e}{t(e_j|f_{a(j)})}} {\\frac{\\epsilon}{(l_f + 1)^{l_e}}\\prod_{j=1}^{l_e}\\sum_{i=0}^{l_f}{t(e_j|f_{i})}} \\\\ &amp;=\\prod_{j=1}^{l_e}{\\frac{t(e_j|f_{a(j)})}{\\sum_{i=0}^{l_f}{t(e_j|f_{i})}}} \\end{aligned}\" eeimg=\"1\"/></p><p>由推导式可看出最终得到的 <img src=\"https://www.zhihu.com/equation?tex=t%28e_j%7Cf_i%29\" alt=\"t(e_j|f_i)\" eeimg=\"1\"/> 就是i位置外语对应j位置目标语言的alignment下，外语单词 <img src=\"https://www.zhihu.com/equation?tex=f_i\" alt=\"f_i\" eeimg=\"1\"/> 翻译为目标语言单词 <img src=\"https://www.zhihu.com/equation?tex=e_i\" alt=\"e_i\" eeimg=\"1\"/> 的概率，且每个位置上的概率 <img src=\"https://www.zhihu.com/equation?tex=t%28e_j%7Cf_%7Bi%7D%29\" alt=\"t(e_j|f_{i})\" eeimg=\"1\"/> 都是参数的一部分。</p><p>2.估计参数：定义 <img src=\"https://www.zhihu.com/equation?tex=c%28e%2C+f%29\" alt=\"c(e, f)\" eeimg=\"1\"/> 为目标单词e与训练数据中的外语单词f对齐的次数。定义 <img src=\"https://www.zhihu.com/equation?tex=c%28e%29\" alt=\"c(e)\" eeimg=\"1\"/>为单词 e与任何f语言单词对齐的次数。有如下式子：</p><p><img src=\"https://www.zhihu.com/equation?tex=c%28e%7Cf%3B+e%2C+f%29+%3D+%5Csum_%7Ba%7D%5E%7B%7D%7Bp%28e%2C+a%7Cf%29%7D%5Csum_%7Bj%3D1%7D%5E%7Bl_e%7D%5Cdelta%28e%2Ce_j%29%5Cdelta%28f%2Cf_%7Ba%28i%29%7D%29\" alt=\"c(e|f; e, f) = \\sum_{a}^{}{p(e, a|f)}\\sum_{j=1}^{l_e}\\delta(e,e_j)\\delta(f,f_{a(i)})\" eeimg=\"1\"/></p><p>带入前半式子的值后可得 <img src=\"https://www.zhihu.com/equation?tex=c%28e%7Cf%3B+e%2C+f%29+%3D+%5Cfrac%7Bt%28e%7Cf%7B%7D%29%7D%7B%5Csum_%7Bi%3D0%7D%5E%7Bl_f%7D%7Bt%28e%7Cf_i%29%7D%7D%5Csum_%7Bj%3D1%7D%5E%7Bl_e%7D%5Cdelta%28e%2Ce_j%29%5Cdelta%28f%2Cf_%7Ba%28i%29%7D%29\" alt=\"c(e|f; e, f) = \\frac{t(e|f{})}{\\sum_{i=0}^{l_f}{t(e|f_i)}}\\sum_{j=1}^{l_e}\\delta(e,e_j)\\delta(f,f_{a(i)})\" eeimg=\"1\"/> .</p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=%5Cdelta%28e%2Ce_j%29\" alt=\"\\delta(e,e_j)\" eeimg=\"1\"/> 表示 <img src=\"https://www.zhihu.com/equation?tex=e_j\" alt=\"e_j\" eeimg=\"1\"/> 单词在句子E中的count数（期望次数）； <img src=\"https://www.zhihu.com/equation?tex=%5Cdelta%28f%2Cf_%7Ba%28i%29%7D%29\" alt=\"\\delta(f,f_{a(i)})\" eeimg=\"1\"/> 表示 <img src=\"https://www.zhihu.com/equation?tex=f_j\" alt=\"f_j\" eeimg=\"1\"/> 单词在F句子中的count数（期望次数）。</p><p>最终可按照如下式子估计整个模型的参数：</p><p><img src=\"https://www.zhihu.com/equation?tex=t%28e%7Cf+%3B+e%2C+f%29+%3D%5Cfrac%7B%5Csum_%7B%28e%2Cf%29%7D%7Bc%28e%7Cf+%3B+e%2C+f%29%7D%7D%7B%5Csum_%7B%28e%29%7D%5Csum_%7B%28e%2Cf%29%7Dc%28e%7Cf+%3B+e%2C+f%29%7D\" alt=\"t(e|f ; e, f) =\\frac{\\sum_{(e,f)}{c(e|f ; e, f)}}{\\sum_{(e)}\\sum_{(e,f)}c(e|f ; e, f)}\" eeimg=\"1\"/> ，分母是一个normalize项</p><h2>三.利用EM模型估计整个模型参数</h2><p>整个目标是通过EM算法学习IBM model中的transition prob参数，通过EM算法，可以在迭代统计平行语料的过程中，不断计算概率 <img src=\"https://www.zhihu.com/equation?tex=t%28e%7Cf%29\" alt=\"t(e|f)\" eeimg=\"1\"/> 的似然概率，并更新到参数中，以达到学习整个参数中最大alignment对应最大概率的目的，我们看看伪代码：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9577e8d37507461ec3bbaf1ba762497e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1982\" data-rawheight=\"1226\" class=\"origin_image zh-lightbox-thumb\" width=\"1982\" data-original=\"https://pic3.zhimg.com/v2-9577e8d37507461ec3bbaf1ba762497e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1982&#39; height=&#39;1226&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1982\" data-rawheight=\"1226\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1982\" data-original=\"https://pic3.zhimg.com/v2-9577e8d37507461ec3bbaf1ba762497e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9577e8d37507461ec3bbaf1ba762497e_b.jpg\"/></figure><p>1.Initialize <img src=\"https://www.zhihu.com/equation?tex=t%28f%7Ce%29\" alt=\"t(f|e)\" eeimg=\"1\"/> （伪代码对应1行）：此步为初始化参数步骤，参数即源语言的过程是放在循环中的，这里外层循环表示迭代计算次数，这里设置的20，total表示在语料中每个单词出现的期望次数（这里期望次数其实是计算出的期望值，在本例中，因为是通过 <img src=\"https://www.zhihu.com/equation?tex=t%28e%7Cf+%3B+e%2C+f%29+%3D%5Cfrac%7B%5Csum_%7B%28e%2Cf%29%7D%7Bc%28e%7Cf+%3B+e%2C+f%29%7D%7D%7B%5Csum_%7B%28e%29%7D%5Csum_%7B%28e%2Cf%29%7Dc%28e%7Cf+%3B+e%2C+f%29%7D\" alt=\"t(e|f ; e, f) =\\frac{\\sum_{(e,f)}{c(e|f ; e, f)}}{\\sum_{(e)}\\sum_{(e,f)}c(e|f ; e, f)}\" eeimg=\"1\"/> 计算出来的，所以因此可能是小数）sTotal表示句子中每个单词对应的期望次数，因此我们只有先计算sTotal期望，再计算整个语料库的total期望。</p><p>2.EM-E步（伪代码对应6-20行）：此步计算期望，需要通过 <img src=\"https://www.zhihu.com/equation?tex=%5Csum_%7B%28e%2Cf%29%7D%7Bc%28e%7Cf+%3B+e%2C+f%29%7D\" alt=\"\\sum_{(e,f)}{c(e|f ; e, f)}\" eeimg=\"1\"/> 式子计算期望</p><p>3.EM-M步（伪代码对应22-26）：此步最大化期望，更新现有的参数。 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Csum_%7B%28e%2Cf%29%7D%7Bc%28e%7Cf+%3B+e%2C+f%29%7D%7D%7B%5Csum_%7B%28e%29%7D%5Csum_%7B%28e%2Cf%29%7Dc%28e%7Cf+%3B+e%2C+f%29%7D\" alt=\"\\frac{\\sum_{(e,f)}{c(e|f ; e, f)}}{\\sum_{(e)}\\sum_{(e,f)}c(e|f ; e, f)}\" eeimg=\"1\"/></p>", 
            "topic": [
                {
                    "tagLink": "https://www.zhihu.com/topic/19559450", 
                    "tag": "机器学习"
                }, 
                {
                    "tagLink": "https://www.zhihu.com/topic/19560026", 
                    "tag": "自然语言处理"
                }, 
                {
                    "tagLink": "https://www.zhihu.com/topic/19551275", 
                    "tag": "人工智能"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>好直观，统计机器翻译还是厉害啊</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }
    ]
}

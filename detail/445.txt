{
    "title": "有三AI学院-AI基础入门", 
    "description": "这里是为了给入行AI的同学准备的专栏，涵盖linux，python，c++等基础知识", 
    "followers": [
        "https://www.zhihu.com/people/er-ting-20", 
        "https://www.zhihu.com/people/hao-xiao-peng-65", 
        "https://www.zhihu.com/people/li-yi-33-62", 
        "https://www.zhihu.com/people/liwei-21", 
        "https://www.zhihu.com/people/keith-24-31", 
        "https://www.zhihu.com/people/lei-xiao-yu-49", 
        "https://www.zhihu.com/people/xiao-sheng-ge-ge-35", 
        "https://www.zhihu.com/people/innerpeace-24-25-99", 
        "https://www.zhihu.com/people/alphe-long", 
        "https://www.zhihu.com/people/kede-98", 
        "https://www.zhihu.com/people/liu-si-zhe-40", 
        "https://www.zhihu.com/people/wang-a-fei-37", 
        "https://www.zhihu.com/people/xiao-zhang-84-54", 
        "https://www.zhihu.com/people/superior-10", 
        "https://www.zhihu.com/people/fang10", 
        "https://www.zhihu.com/people/yao-sheng-yuan", 
        "https://www.zhihu.com/people/marcus-95-55", 
        "https://www.zhihu.com/people/fenglongyu", 
        "https://www.zhihu.com/people/hao-ba-97-38", 
        "https://www.zhihu.com/people/jcong-waiting", 
        "https://www.zhihu.com/people/ai-777777", 
        "https://www.zhihu.com/people/heaui-45", 
        "https://www.zhihu.com/people/sj-newbee", 
        "https://www.zhihu.com/people/chen-jian-yu-36-7", 
        "https://www.zhihu.com/people/O-sen-26", 
        "https://www.zhihu.com/people/sunhold", 
        "https://www.zhihu.com/people/reeseli-67", 
        "https://www.zhihu.com/people/endless-12-73", 
        "https://www.zhihu.com/people/xiang-dang-qiang-zhuang-de-mao", 
        "https://www.zhihu.com/people/zi-luo-lan-87-28", 
        "https://www.zhihu.com/people/xiao-ma-jia-55-39", 
        "https://www.zhihu.com/people/jinxihexi0411", 
        "https://www.zhihu.com/people/cai-gen-jin-yan", 
        "https://www.zhihu.com/people/hai-luo-fu-25", 
        "https://www.zhihu.com/people/iduido", 
        "https://www.zhihu.com/people/bigenius", 
        "https://www.zhihu.com/people/duan-xing-99", 
        "https://www.zhihu.com/people/a-piece-of-bread", 
        "https://www.zhihu.com/people/xiao-xiao-xie-luo-98-2", 
        "https://www.zhihu.com/people/qu-ge-ming-du-zhe-yao-lei", 
        "https://www.zhihu.com/people/guan-su-zi-1", 
        "https://www.zhihu.com/people/chen-mei-ling-96", 
        "https://www.zhihu.com/people/wu-xing-27-60-5", 
        "https://www.zhihu.com/people/wei-li-feng-80", 
        "https://www.zhihu.com/people/wang-shen-si-78", 
        "https://www.zhihu.com/people/Yuandian-Dai", 
        "https://www.zhihu.com/people/lin-wei-lau", 
        "https://www.zhihu.com/people/xiao-lou-yiye-ting-feng-yu-11", 
        "https://www.zhihu.com/people/19ji-suan-ji-kao-yan", 
        "https://www.zhihu.com/people/dai-mei-lin", 
        "https://www.zhihu.com/people/niceworld-49-6", 
        "https://www.zhihu.com/people/zui-meng-xian-lin-72", 
        "https://www.zhihu.com/people/qian-ren-jian-45", 
        "https://www.zhihu.com/people/dong-ri-96", 
        "https://www.zhihu.com/people/sm1les", 
        "https://www.zhihu.com/people/wsp_tcl", 
        "https://www.zhihu.com/people/fzugsr", 
        "https://www.zhihu.com/people/li-hong-bo-24-22", 
        "https://www.zhihu.com/people/wang-guo-yin-93", 
        "https://www.zhihu.com/people/xie-lu-60-97", 
        "https://www.zhihu.com/people/yue-yukii", 
        "https://www.zhihu.com/people/ieloag_suineg", 
        "https://www.zhihu.com/people/heyang-36", 
        "https://www.zhihu.com/people/tang-peng-hao-66", 
        "https://www.zhihu.com/people/yzhan-67", 
        "https://www.zhihu.com/people/jeffreylee-75", 
        "https://www.zhihu.com/people/dian-sheng-zhi-9", 
        "https://www.zhihu.com/people/mathematical-72", 
        "https://www.zhihu.com/people/nan-yang-wu-hao", 
        "https://www.zhihu.com/people/long-he-6-26", 
        "https://www.zhihu.com/people/er-jin-zhi-de-yi-43", 
        "https://www.zhihu.com/people/qian-qian-87-69-18", 
        "https://www.zhihu.com/people/yu-ren-72-70", 
        "https://www.zhihu.com/people/chen-bo-86-42", 
        "https://www.zhihu.com/people/flee-56", 
        "https://www.zhihu.com/people/ma-xing-yu-72-30", 
        "https://www.zhihu.com/people/jen-62-52", 
        "https://www.zhihu.com/people/jack-61-23", 
        "https://www.zhihu.com/people/archer-hour", 
        "https://www.zhihu.com/people/xiaomizhou94", 
        "https://www.zhihu.com/people/lemons-lee-92", 
        "https://www.zhihu.com/people/wjh2005", 
        "https://www.zhihu.com/people/123456abcdef-51", 
        "https://www.zhihu.com/people/shi-guang-ji-xian-sen", 
        "https://www.zhihu.com/people/yuan-fang-de-xiao-yu", 
        "https://www.zhihu.com/people/chai-bin-38", 
        "https://www.zhihu.com/people/ran-da-di-de-zhong-shi-xin-tu", 
        "https://www.zhihu.com/people/shi-zhi--64", 
        "https://www.zhihu.com/people/yi-nian-shi-er-yue", 
        "https://www.zhihu.com/people/allen-zhang-85-48", 
        "https://www.zhihu.com/people/ming-ou-yang", 
        "https://www.zhihu.com/people/arancia-43", 
        "https://www.zhihu.com/people/dai-wen-65", 
        "https://www.zhihu.com/people/lu-quan-hong-19", 
        "https://www.zhihu.com/people/li-hua-62-2", 
        "https://www.zhihu.com/people/yang-ou-yang-32", 
        "https://www.zhihu.com/people/alahlll", 
        "https://www.zhihu.com/people/lai-en-ha-te-24-79", 
        "https://www.zhihu.com/people/shenghsiaowong", 
        "https://www.zhihu.com/people/wzyyeah-71", 
        "https://www.zhihu.com/people/airraing", 
        "https://www.zhihu.com/people/liuwen3585", 
        "https://www.zhihu.com/people/wei-wei-96-2", 
        "https://www.zhihu.com/people/daiyizheng123", 
        "https://www.zhihu.com/people/li-ling-1-11", 
        "https://www.zhihu.com/people/lucky-45-9-77", 
        "https://www.zhihu.com/people/yunzhongke", 
        "https://www.zhihu.com/people/li-li-1-70-77", 
        "https://www.zhihu.com/people/wang-ming-yang-22-94", 
        "https://www.zhihu.com/people/yu-ren-4-38", 
        "https://www.zhihu.com/people/yang-heng-82-43", 
        "https://www.zhihu.com/people/a-fei-76-48", 
        "https://www.zhihu.com/people/she-guan-hua", 
        "https://www.zhihu.com/people/leng-shu-ling", 
        "https://www.zhihu.com/people/neil-cham", 
        "https://www.zhihu.com/people/fei-zai-tian-kong-zhong-de-yu-47", 
        "https://www.zhihu.com/people/zao-meng-xian-sheng-4-15", 
        "https://www.zhihu.com/people/jiong-xian-sen-4", 
        "https://www.zhihu.com/people/zwbckmy", 
        "https://www.zhihu.com/people/lu-bing-xu", 
        "https://www.zhihu.com/people/li-hui-71-76-33", 
        "https://www.zhihu.com/people/hu-yu-2-39", 
        "https://www.zhihu.com/people/a-di-74-41", 
        "https://www.zhihu.com/people/ding-ding-33-32-3", 
        "https://www.zhihu.com/people/fang-gao-97", 
        "https://www.zhihu.com/people/kilala-92", 
        "https://www.zhihu.com/people/caroline-54-18", 
        "https://www.zhihu.com/people/luo-zheng-bo-98", 
        "https://www.zhihu.com/people/yu-yu-yu-yu-yu-63-75", 
        "https://www.zhihu.com/people/nathan-xiong", 
        "https://www.zhihu.com/people/jingwen-cheng-59", 
        "https://www.zhihu.com/people/zhang-xiang-73-16-30", 
        "https://www.zhihu.com/people/hu-jue-yue-48", 
        "https://www.zhihu.com/people/hook-sun", 
        "https://www.zhihu.com/people/zhao-fang-ming-58", 
        "https://www.zhihu.com/people/lllljj", 
        "https://www.zhihu.com/people/weichen-38", 
        "https://www.zhihu.com/people/Dsssyc-Soku", 
        "https://www.zhihu.com/people/666233-95-78", 
        "https://www.zhihu.com/people/0400H", 
        "https://www.zhihu.com/people/wu-bing-7-30", 
        "https://www.zhihu.com/people/yellowfin", 
        "https://www.zhihu.com/people/zfyi-qun-er-zi", 
        "https://www.zhihu.com/people/vadingujiaqi", 
        "https://www.zhihu.com/people/zhao-lin-1-81", 
        "https://www.zhihu.com/people/the-sky-69-37", 
        "https://www.zhihu.com/people/anna-linda", 
        "https://www.zhihu.com/people/feng-yu-jian-cheng-71-61", 
        "https://www.zhihu.com/people/hu-song-lin-60", 
        "https://www.zhihu.com/people/bailingnan", 
        "https://www.zhihu.com/people/li-qiang-35-26", 
        "https://www.zhihu.com/people/barney-qiao", 
        "https://www.zhihu.com/people/zhangshulin-48", 
        "https://www.zhihu.com/people/po-tian-85", 
        "https://www.zhihu.com/people/yawu-99", 
        "https://www.zhihu.com/people/sang-shu-8", 
        "https://www.zhihu.com/people/godxia-49", 
        "https://www.zhihu.com/people/keenzhu-x", 
        "https://www.zhihu.com/people/tian-xing-36", 
        "https://www.zhihu.com/people/brillgold", 
        "https://www.zhihu.com/people/dijkstra", 
        "https://www.zhihu.com/people/zhang-zi-yi-31-40", 
        "https://www.zhihu.com/people/dong-feng-zao-ji", 
        "https://www.zhihu.com/people/lausing-19", 
        "https://www.zhihu.com/people/ma-dong-hui-62", 
        "https://www.zhihu.com/people/terry-xiao-37", 
        "https://www.zhihu.com/people/liu-chang-48-55", 
        "https://www.zhihu.com/people/li-wang-25-7", 
        "https://www.zhihu.com/people/hui-long-94", 
        "https://www.zhihu.com/people/tinggg-14", 
        "https://www.zhihu.com/people/xue-gan-82", 
        "https://www.zhihu.com/people/fendoudexiaoniao", 
        "https://www.zhihu.com/people/dan-dan-de-ge-79", 
        "https://www.zhihu.com/people/leo-lee-58-57", 
        "https://www.zhihu.com/people/wu-shang-45", 
        "https://www.zhihu.com/people/upupup-12-24", 
        "https://www.zhihu.com/people/li-hao-75-33-72", 
        "https://www.zhihu.com/people/yun-yun-23-45", 
        "https://www.zhihu.com/people/dun-xian-sheng-36", 
        "https://www.zhihu.com/people/xing123-43", 
        "https://www.zhihu.com/people/quxiaofeng", 
        "https://www.zhihu.com/people/zhang-mian-66", 
        "https://www.zhihu.com/people/zhu-rui-he-27", 
        "https://www.zhihu.com/people/ying-ying-ying-vue", 
        "https://www.zhihu.com/people/xiao-er-lai-ge-id", 
        "https://www.zhihu.com/people/wiser-72-93", 
        "https://www.zhihu.com/people/ji-kang-39-28", 
        "https://www.zhihu.com/people/yildhd-wang", 
        "https://www.zhihu.com/people/frankfake", 
        "https://www.zhihu.com/people/dong-sheng-91", 
        "https://www.zhihu.com/people/cui-jian-zhu-66", 
        "https://www.zhihu.com/people/jiao-bin-bin-6", 
        "https://www.zhihu.com/people/liu-xiao-yong-80-42", 
        "https://www.zhihu.com/people/yu-zi-qi", 
        "https://www.zhihu.com/people/locker87", 
        "https://www.zhihu.com/people/zgd-64", 
        "https://www.zhihu.com/people/wang-fu-lin-3", 
        "https://www.zhihu.com/people/xie-tao-47-50", 
        "https://www.zhihu.com/people/linuxcpp", 
        "https://www.zhihu.com/people/saige-24", 
        "https://www.zhihu.com/people/ai-man-yu-zhen-shi-tai-hao-liao", 
        "https://www.zhihu.com/people/kjbeestofthebest", 
        "https://www.zhihu.com/people/jangol", 
        "https://www.zhihu.com/people/long-gang-62-42", 
        "https://www.zhihu.com/people/OUSHISHIN-96-61", 
        "https://www.zhihu.com/people/peng-pai-zhong", 
        "https://www.zhihu.com/people/wang-gang-77-27", 
        "https://www.zhihu.com/people/wang-ming-66-71", 
        "https://www.zhihu.com/people/ha-ha-8-37", 
        "https://www.zhihu.com/people/wang-bao-yu-87"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/78353553", 
            "userName": "小Dream哥", 
            "userLink": "https://www.zhihu.com/people/350a747d5bc82e3c118796cc5103e083", 
            "upvote": 5, 
            "title": "每周NLP论文推荐（2）：NLP中的命名实体识别", 
            "content": "<p>NER是自然语言处理中相对比较基础的任务，但却是非常重要的任务。在NLP中，大部分的任务都需要NER的能力，例如，聊天机器人中，需要NER来提取实体完成对用户输入的理解；在信息提取任务中，需要提取相应的实体，以完成对信息的抽取。</p><p>本篇介绍NER中常用的方法，从常用的机器学习方法到深度学习的方法。</p><p>作者&amp;编辑 | 小Dream哥</p><p><b>1 早期的HMM</b></p><p>早期的一篇介绍HMM在NER中的应用，实验效果还可以。现在还有一些实体识别有用到HMM，读此文对于了解NER的发展有一定的好处。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4f4d7d79664b063c311d1194930dac1d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"747\" data-rawheight=\"357\" class=\"origin_image zh-lightbox-thumb\" width=\"747\" data-original=\"https://pic2.zhimg.com/v2-4f4d7d79664b063c311d1194930dac1d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;747&#39; height=&#39;357&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"747\" data-rawheight=\"357\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"747\" data-original=\"https://pic2.zhimg.com/v2-4f4d7d79664b063c311d1194930dac1d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4f4d7d79664b063c311d1194930dac1d_b.jpg\"/></figure><p>[1] Su, Jian , and J. Su . &#34;Named entity recognition using an HMM-based chunk tagger.&#34; Proc Acl (2002):473-480.</p><p><b>2 主流NER架构LSTM +CRF </b></p><p>随着深度学习的兴起，LSTM+CRF变成NER任务的主流方法，下面是一篇较为典型的介绍的LSTM+CRF进行NER任务的文章。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-701069b4c5281dd5074276200c5d56f9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"614\" data-rawheight=\"309\" class=\"origin_image zh-lightbox-thumb\" width=\"614\" data-original=\"https://pic2.zhimg.com/v2-701069b4c5281dd5074276200c5d56f9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;614&#39; height=&#39;309&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"614\" data-rawheight=\"309\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"614\" data-original=\"https://pic2.zhimg.com/v2-701069b4c5281dd5074276200c5d56f9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-701069b4c5281dd5074276200c5d56f9_b.jpg\"/></figure><p>[2] Huang, Zhiheng , W. Xu , and K. Yu . &#34;Bidirectional LSTM-CRF Models for Sequence Tagging.&#34; Computer Science (2015).</p><p><b>3 讨论了CNN进行NER任务</b></p><p>在NLP任务中用CNN进行特征提取一直不是主流，这篇论文在NER中引入CNN。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-066b5135cac820ee552082e96576a3d7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"542\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"542\" data-original=\"https://pic4.zhimg.com/v2-066b5135cac820ee552082e96576a3d7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;542&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"542\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"542\" data-original=\"https://pic4.zhimg.com/v2-066b5135cac820ee552082e96576a3d7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-066b5135cac820ee552082e96576a3d7_b.jpg\"/></figure><p>[3] Chiu, Jason P. C. , and E. Nichols . &#34;Named Entity Recognition with Bidirectional LSTM-CNNs.&#34; Computer Science (2015).</p><p><b>4 空洞卷积在NER中的应用</b></p><p>因为传统CNN的对长序列的输入特征提取能力偏弱，有研究者提出将Dilated Convolutions(空洞卷积)应用在NER中的想法。空洞卷积可以加大感受野，提高模型的训练和预测速度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-70156b8b2f2b62fa47ffdb649180b787_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"748\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb\" width=\"748\" data-original=\"https://pic4.zhimg.com/v2-70156b8b2f2b62fa47ffdb649180b787_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;748&#39; height=&#39;476&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"748\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"748\" data-original=\"https://pic4.zhimg.com/v2-70156b8b2f2b62fa47ffdb649180b787_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-70156b8b2f2b62fa47ffdb649180b787_b.jpg\"/></figure><p>[4] Emma Strubell Patrick Verga. Fast and Accurate Entity Recognition with Iterated Dilated Convolutions. 2017</p><p><b>5 Lattice LSTM</b></p><p>中文的NER与英文不太一样，中文NER问题很大程度上取决于分词的效果，比如实体边界和单词的边界在中文NER问题中经常是一样的。</p><p>所以在中文NER问题中，有时通常先对文本进行分词然后再预测序列中单词的类别。这样一来会导致一个问题，即在分词中造成的错误会影响到NER的结果。基于字向量的模型能够避免上述问题，但因为单纯采用字向量，导致拆开了很多并不应该拆开的词语，从而丢失了它们本身的内在信息。</p><p>此文提出一种用于中文NER的LSTM的格子模型，与传统使用字向量的模型相比，它提出的模型显式地利用了字序列之间的关系，能够很好的避免分词错误带来的影响。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-1aca35c6ca4e78790902247c44a0306a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"773\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb\" width=\"773\" data-original=\"https://pic3.zhimg.com/v2-1aca35c6ca4e78790902247c44a0306a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;773&#39; height=&#39;414&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"773\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"773\" data-original=\"https://pic3.zhimg.com/v2-1aca35c6ca4e78790902247c44a0306a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-1aca35c6ca4e78790902247c44a0306a_b.jpg\"/></figure><p>[5] Yue Zhang, Jie Yang. Chinese NER Using Lattice LSTM. 2018</p><p><b>6 实体识别与实体匹配</b></p><p>实体匹配是指将识别到的实体与知识库或者图谱中实体进行匹配与映射。因此实体匹配与识别是两个相关性非常高的任务，通过实体匹配，识别到的实体与现实中的概念相连接。这篇论文将实体匹配与识别统一起来训练，认为两个任务一起学习，能够提升两个任务的准确率。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c56740a81dbb5021b02706d680cbbce6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1461\" data-rawheight=\"505\" class=\"origin_image zh-lightbox-thumb\" width=\"1461\" data-original=\"https://pic3.zhimg.com/v2-c56740a81dbb5021b02706d680cbbce6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1461&#39; height=&#39;505&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1461\" data-rawheight=\"505\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1461\" data-original=\"https://pic3.zhimg.com/v2-c56740a81dbb5021b02706d680cbbce6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c56740a81dbb5021b02706d680cbbce6_b.jpg\"/></figure><p>[6] Pedro Henrique Martins, Zita Marinho. Joint Learning of Named Entity Recognition and Entity Linking. 2019.</p><p><b>7 引入BERT及attention</b></p><p>引入了很多新的概念到命名实体识别中，例如BERT，Attention。感兴趣的同学可以看一看，会有蛮大的收益。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b95383e5a559f6a6f134a1f42f63fc45_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1063\" data-rawheight=\"822\" class=\"origin_image zh-lightbox-thumb\" width=\"1063\" data-original=\"https://pic2.zhimg.com/v2-b95383e5a559f6a6f134a1f42f63fc45_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1063&#39; height=&#39;822&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1063\" data-rawheight=\"822\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1063\" data-original=\"https://pic2.zhimg.com/v2-b95383e5a559f6a6f134a1f42f63fc45_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b95383e5a559f6a6f134a1f42f63fc45_b.jpg\"/></figure><p>[7] Anton A. Emelyanov, Ekaterina Artemova. Multilingual Named Entity Recognition Using Pretrained Embeddings, Attention Mechanism and NCRF. arXiv preprint  arXiv:1906.09978v1 2019</p><p><b>8 AutoNER</b></p><p><b>论文提出了一个无需人工标注就可以自动标记数据并训练NER的模型--AutoNER。</b>实验表明，AutoNER训练的模型在3个数据集上均与有监督的benchmark相当。感兴趣的同学可以参考下。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-75cef1e7c508b8705ca8d6131e5be4ad_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1416\" data-rawheight=\"353\" class=\"origin_image zh-lightbox-thumb\" width=\"1416\" data-original=\"https://pic2.zhimg.com/v2-75cef1e7c508b8705ca8d6131e5be4ad_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1416&#39; height=&#39;353&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1416\" data-rawheight=\"353\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1416\" data-original=\"https://pic2.zhimg.com/v2-75cef1e7c508b8705ca8d6131e5be4ad_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-75cef1e7c508b8705ca8d6131e5be4ad_b.jpg\"/></figure><p>[8] Jingbo Shang, Liyuan Liu. Learning Named Entity Tagger using Domain-Specifific Dictionary. arXiv preprint  arXiv:1809.03599v1 2018</p><p><b>9 如何获取文章与交流</b></p><p>文章细节众多，获取文章以及阅读交流都在有三AI-NLP知识星球中进行，感兴趣可以加入，扫描下图中的二维码即可。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4477976bbabfb5273aba708b8b8bfa3e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"750\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"750\" data-original=\"https://pic3.zhimg.com/v2-4477976bbabfb5273aba708b8b8bfa3e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;750&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"750\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"750\" data-original=\"https://pic3.zhimg.com/v2-4477976bbabfb5273aba708b8b8bfa3e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4477976bbabfb5273aba708b8b8bfa3e_b.jpg\"/></figure><p><b>总结</b></p><p>以上就是关于NER的一些重要论文，下一期我们将推荐语义匹配相关的研究。</p><a href=\"https://zhuanlan.zhihu.com/p/78353011\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【每周NLP论文推荐】从头到尾，看看预训练模型的发展演变</a><a href=\"https://zhuanlan.zhihu.com/p/76968482\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】 深入浅出解析BERT原理及其表征的内容</a><a href=\"https://zhuanlan.zhihu.com/p/75893463\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】 理解NLP中网红特征抽取器Tranformer</a><a href=\"https://zhuanlan.zhihu.com/p/75412133\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】 NLP中attention的详细介绍：由来，机制及本质</a><a href=\"https://zhuanlan.zhihu.com/p/73742835\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】 NLP中应用最广泛的特征抽取模型-LSTM，虽老生常谈，却不乏新意</a><a href=\"https://zhuanlan.zhihu.com/p/72906828\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-2673353c5ef5d3b4c49f47fe62e25061_180x120.jpg\" data-image-width=\"750\" data-image-height=\"406\" class=\"internal\">小Dream哥：【NLP】 深度学习NLP开篇-循环神经网络(RNN)</a><a href=\"https://zhuanlan.zhihu.com/p/71938746\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【技术综述】深度学习在自然语言处理中的应用发展史</a><a href=\"https://zhuanlan.zhihu.com/p/71937660\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】经典分类模型-朴素贝叶斯</a><a href=\"https://zhuanlan.zhihu.com/p/70777941\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】用于序列标注问题的条件随机场（Conditional Random Field, CRF）</a><a href=\"https://zhuanlan.zhihu.com/p/69890528\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】用于语音识别、分词的隐马尔科夫模型(HMM)</a><a href=\"https://zhuanlan.zhihu.com/p/68909891\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】自然语言处理专栏上线，带你一步一步走进“人工智能技术皇冠上的明珠”。</a><p></p>", 
            "topic": [
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }, 
                {
                    "tag": "AI教程", 
                    "tagLink": "https://api.zhihu.com/topics/20182941"
                }, 
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/78353011", 
            "userName": "小Dream哥", 
            "userLink": "https://www.zhihu.com/people/350a747d5bc82e3c118796cc5103e083", 
            "upvote": 10, 
            "title": "每周NLP论文推荐（1）：从头到尾，看看预训练模型的发展演变", 
            "content": "<p>读论文是做AI的人必需要下的功夫，所以NLP也加入了专栏《每周论文推荐》。本着有三AI的一贯原则，即<b>系统性学习</b>，所以每次的论文推荐也会是成系统的，争取每次能够把一个领域内的“故事”基本说清楚。</p><p>先通过无监督学习在大规模语料上进行Pre-Training，再通过Fine-tune的方式，在一定语料上进行有监督学习，进行下游任务的学习，是NLP领域近来的以大趋势。这次论文推荐就从词向量开始，依次介绍到最新的XLnet。</p><p>作者&amp;编辑 | 小Dream哥 </p><p><b>1 词向量的提出</b></p><p>在这篇文章中，Bengio等人提出了神经语言模型(NNLM)，而它的副产品，词向量，可以实现词的分布式表征。词向量模型是一个重要的工具，可以把真实世界抽象存在的文字转换成可以进行数学公式操作的向量，对这些向量的操作，是NLP所有任务都在做的事情。NNLM提出了一种可能的获得词向量的稠密式表征的手段，具有重要意义。</p><p>[1] D&#39;informatique Et Recherche Operationnelle, Departement &amp; Bengio, Y &amp; Ejean Ducharme, R &amp; Vincent, Pascal &amp; De Recherche Mathematiques, Centre. (2001). A Neural Probabilistic Language Model.</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-fc5584fbce8cb5c360b76227e63fc5ed_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"754\" data-rawheight=\"649\" class=\"origin_image zh-lightbox-thumb\" width=\"754\" data-original=\"https://pic2.zhimg.com/v2-fc5584fbce8cb5c360b76227e63fc5ed_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;754&#39; height=&#39;649&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"754\" data-rawheight=\"649\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"754\" data-original=\"https://pic2.zhimg.com/v2-fc5584fbce8cb5c360b76227e63fc5ed_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-fc5584fbce8cb5c360b76227e63fc5ed_b.jpg\"/></figure><p><b>2 Word2vec的提出</b></p><p>这篇文章提出了一种能够真正高效获得词向量的手段，进而促进了后续NLP的快速发展。Mikolov 等研究者在这篇论文中提出了连续词袋模型CBOW和 Skip-Gram 模型，通过引入负采样等可行性的措施。使得学习高质量的词向量成为现实。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-02d6a0ca1c488e647e735e88e106fdbe_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"331\" data-rawheight=\"408\" class=\"content_image\" width=\"331\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;331&#39; height=&#39;408&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"331\" data-rawheight=\"408\" class=\"content_image lazy\" width=\"331\" data-actualsrc=\"https://pic3.zhimg.com/v2-02d6a0ca1c488e647e735e88e106fdbe_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-8ffd7101f658d880830d423cf6ad20c0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"689\" data-rawheight=\"406\" class=\"origin_image zh-lightbox-thumb\" width=\"689\" data-original=\"https://pic1.zhimg.com/v2-8ffd7101f658d880830d423cf6ad20c0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;689&#39; height=&#39;406&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"689\" data-rawheight=\"406\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"689\" data-original=\"https://pic1.zhimg.com/v2-8ffd7101f658d880830d423cf6ad20c0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-8ffd7101f658d880830d423cf6ad20c0_b.jpg\"/></figure><p>[2] Mikolov T , Sutskever I , Chen K , et al. Distributed Representations of Words and Phrases and their Compositionality[J]. Advances in Neural Information Processing Systems, 2013.</p><p><b>3 ELMo词向量的动态表征</b></p><p>训练得到的词向量表征的词语之间的信息其实有限。词向量一个难以解决的问题就是多义词的问题，例如“bank”在英文中有“河岸”和“银行”两种完全不同意思，但是在词向量中确实相同的向量来表征，这显然不合理。</p><p>ELMO的本质思想是：用事先训练好的语言模型学好一个单词的Word Embedding，此时多义词无法区分，不过这没关系。在实际使用Word Embedding的时候，单词特定的上下文就可以知道，这个时候模型可以根据上下文单词的语义去调整单词的Word Embedding表示，这样经过调整后的Word Embedding更能表达在这个上下文中的具体含义，也就能克服多义词动态表征的问题。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-96657de8de6416650f0e3f6f42416a04_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"463\" data-rawheight=\"233\" class=\"origin_image zh-lightbox-thumb\" width=\"463\" data-original=\"https://pic1.zhimg.com/v2-96657de8de6416650f0e3f6f42416a04_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;463&#39; height=&#39;233&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"463\" data-rawheight=\"233\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"463\" data-original=\"https://pic1.zhimg.com/v2-96657de8de6416650f0e3f6f42416a04_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-96657de8de6416650f0e3f6f42416a04_b.jpg\"/></figure><p>[3] Peters, Matthew E. , et al. &#34;Deep contextualized word representations.&#34; (2018).<br/></p><p><b>4 通用语言模型GPT</b></p><p>Generative Pre-Training(GPT)采用单向语言模型，用Transformer作为特征抽取器，在当时NLP领域的各项任务中都取得了非常不错的效果。</p><p>从GPT中可以看到一个明显的趋势：越来越多的将原来在下游任务中做的事情，搬到预训练时来做。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-efe9adcbbee71d12b9d69a78731d4f24_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"991\" data-rawheight=\"429\" class=\"origin_image zh-lightbox-thumb\" width=\"991\" data-original=\"https://pic1.zhimg.com/v2-efe9adcbbee71d12b9d69a78731d4f24_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;991&#39; height=&#39;429&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"991\" data-rawheight=\"429\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"991\" data-original=\"https://pic1.zhimg.com/v2-efe9adcbbee71d12b9d69a78731d4f24_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-efe9adcbbee71d12b9d69a78731d4f24_b.jpg\"/></figure><p>[4] Alec RadfordKarthik, NarasimhanTim, SalimansIlya Sutskever. (2018). Improving Language Understanding by Generative Pre-Training.</p><p><b>5 BERT的横空出世</b></p><p>谷歌推出BERT(Bidirectional Encoder Representation from Transformers)模型，刷新了几乎所有NLP任务的榜单，一时风头无两。仔细看BERT的实现，其与GPT的主要差别在于，BERT用的“双向语言模型”，它通过MASK掉预料中的部分词再重建的过程来学习预料中词语序列中的语义表示信息，同样采用Transformer作为特征抽取器。BERT的出现，因其效果太好，几乎让其他所有的NLP工作都黯然失色。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-af16fc64f8282c1896f216fed77a02c2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"492\" data-rawheight=\"489\" class=\"origin_image zh-lightbox-thumb\" width=\"492\" data-original=\"https://pic3.zhimg.com/v2-af16fc64f8282c1896f216fed77a02c2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;492&#39; height=&#39;489&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"492\" data-rawheight=\"489\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"492\" data-original=\"https://pic3.zhimg.com/v2-af16fc64f8282c1896f216fed77a02c2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-af16fc64f8282c1896f216fed77a02c2_b.jpg\"/></figure><p>[5] Devlin, Jacob , et al. &#34;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.&#34; (2018).</p><p><b>6 能写故事的GPT2.0</b></p><p>2019年2月openAI用更大的模型，规模更大质量更好的数据推出了GPT2.0，其语言生成能力令人惊叹。相比于BERT，得益于以语言模型为训练任务，GPT2.0的生成能力要更强，在文本生成领域获得很大的反响。</p><p>值得关注的一点是，GPT的创造者们认为，Finetune的过程其实式不必要的，不同的任务用不同的处理方式即可。也就是说，<b>自然语言处理中，几乎所有的事情都放在无监督中的预训练就可以了</b>。是不是听着就觉得带劲？当然，这个还需要时间来考证，至少BERT还不这么认为。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ab0aa760360cc3676c1feb8c07a5b7c9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1244\" data-rawheight=\"777\" class=\"origin_image zh-lightbox-thumb\" width=\"1244\" data-original=\"https://pic2.zhimg.com/v2-ab0aa760360cc3676c1feb8c07a5b7c9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1244&#39; height=&#39;777&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1244\" data-rawheight=\"777\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1244\" data-original=\"https://pic2.zhimg.com/v2-ab0aa760360cc3676c1feb8c07a5b7c9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ab0aa760360cc3676c1feb8c07a5b7c9_b.jpg\"/></figure><p>[6] Alec Radford,  Jeffrey Wu, Rewon Child,  David Luan,  Dario Amodei , Ilya Sutskever.(2019) Language Models are Unsupervised Multitask Learners.</p><p><b>7 GPT与BERT的结合体XLnet</b></p><p>在2019年6月，XLNet: Generalized Autoregressive Pretraining for Language Understanding诞生，其基于BERT和GPT等两类预训练模型来进行改进，分别吸取了两类模型的长处，获得的很好的效果。<br/></p><p>在XLnet中，提出了AutoRegressive (AR) 语言模型和AutoEncoding (AE)语言模型的说法，分别对应GPT和BERT，分析他们的优劣势，然后做出结合，模型的效果超过BERT，暂时占据自然语言处理头牌。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-3a280bf4f413ac9090a800eabe305418_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"846\" data-rawheight=\"672\" class=\"origin_image zh-lightbox-thumb\" width=\"846\" data-original=\"https://pic1.zhimg.com/v2-3a280bf4f413ac9090a800eabe305418_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;846&#39; height=&#39;672&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"846\" data-rawheight=\"672\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"846\" data-original=\"https://pic1.zhimg.com/v2-3a280bf4f413ac9090a800eabe305418_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-3a280bf4f413ac9090a800eabe305418_b.jpg\"/></figure><p>[7] Zhilin Yang, Zihang Dai, Yiming Yang , Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le(2019). XLNet: Generalized Autoregressive Pretraining for Language Understanding.</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>1 如何获取文章与交流</b></p><p>找到有三AI github开源项目即可获取。</p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/longpeng2008/yousan.ai\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/longpeng2008</span><span class=\"invisible\">/yousan.ai</span><span class=\"ellipsis\"></span></a></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-8b85f91a42ca34fca234e6d3283df98f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2034\" data-rawheight=\"1082\" class=\"origin_image zh-lightbox-thumb\" width=\"2034\" data-original=\"https://pic4.zhimg.com/v2-8b85f91a42ca34fca234e6d3283df98f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2034&#39; height=&#39;1082&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2034\" data-rawheight=\"1082\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2034\" data-original=\"https://pic4.zhimg.com/v2-8b85f91a42ca34fca234e6d3283df98f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-8b85f91a42ca34fca234e6d3283df98f_b.jpg\"/></figure><p>文章细节众多，阅读交流都在有三AI-NLP知识星球中进行，感兴趣可以加入，扫描下图中的二维码即可。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4477976bbabfb5273aba708b8b8bfa3e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"750\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"750\" data-original=\"https://pic3.zhimg.com/v2-4477976bbabfb5273aba708b8b8bfa3e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;750&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"750\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"750\" data-original=\"https://pic3.zhimg.com/v2-4477976bbabfb5273aba708b8b8bfa3e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4477976bbabfb5273aba708b8b8bfa3e_b.jpg\"/></figure><p><b>总结</b></p><p>这一期我们从头到尾，看了现在最火爆的预训练语言模型的发展过程，细细看过来，你能够品味到NLP这些年发展的脉络，非常有益处。后面我们的每周论文分享会从不同的自然语言处理任务来展开。</p><a href=\"https://zhuanlan.zhihu.com/p/78353553\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【每周论文推荐】 NLP中的命名实体识别</a><a href=\"https://zhuanlan.zhihu.com/p/76968482\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】 深入浅出解析BERT原理及其表征的内容</a><a href=\"https://zhuanlan.zhihu.com/p/75893463\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】 理解NLP中网红特征抽取器Tranformer</a><a href=\"https://zhuanlan.zhihu.com/p/75412133\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】 NLP中attention的详细介绍：由来，机制及本质</a><a href=\"https://zhuanlan.zhihu.com/p/73742835\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】 NLP中应用最广泛的特征抽取模型-LSTM，虽老生常谈，却不乏新意</a><a href=\"https://zhuanlan.zhihu.com/p/72906828\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-2673353c5ef5d3b4c49f47fe62e25061_180x120.jpg\" data-image-width=\"750\" data-image-height=\"406\" class=\"internal\">小Dream哥：【NLP】 深度学习NLP开篇-循环神经网络(RNN)</a><a href=\"https://zhuanlan.zhihu.com/p/71938746\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【技术综述】深度学习在自然语言处理中的应用发展史</a><a href=\"https://zhuanlan.zhihu.com/p/71937660\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】经典分类模型-朴素贝叶斯</a><a href=\"https://zhuanlan.zhihu.com/p/70777941\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】用于序列标注问题的条件随机场（Conditional Random Field, CRF）</a><a href=\"https://zhuanlan.zhihu.com/p/69890528\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】用于语音识别、分词的隐马尔科夫模型(HMM)</a><a href=\"https://zhuanlan.zhihu.com/p/68909891\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-12e028f02a12ca979b1b6e4df94ca0d6_ipico.jpg\" data-image-width=\"995\" data-image-height=\"995\" class=\"internal\">小Dream哥：【NLP】自然语言处理专栏上线，带你一步一步走进“人工智能技术皇冠上的明珠”。</a><p></p>", 
            "topic": [
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }, 
                {
                    "tag": "AI教程", 
                    "tagLink": "https://api.zhihu.com/topics/20182941"
                }, 
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/73479278", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 4, 
            "title": "【知识星球】超3万字的网络结构解读，学习必备", 
            "content": "<p>不知不觉我们<b>每日两更</b>的<b>“网络结构1000变”</b>板块已经有超过30000字的解读了，下面是该模块的汇总清单。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-89cd2d78a36f18c6b9f165b9374e658b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"524\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-89cd2d78a36f18c6b9f165b9374e658b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;524&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"524\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-89cd2d78a36f18c6b9f165b9374e658b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-89cd2d78a36f18c6b9f165b9374e658b_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7224984b64499076e14714e1fb77afa9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"953\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-7224984b64499076e14714e1fb77afa9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;953&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"953\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-7224984b64499076e14714e1fb77afa9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7224984b64499076e14714e1fb77afa9_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-2d71821f382fe7880ba828c0401b1c3a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"648\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-2d71821f382fe7880ba828c0401b1c3a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;648&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"648\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-2d71821f382fe7880ba828c0401b1c3a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-2d71821f382fe7880ba828c0401b1c3a_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-408710d5432d917c4d462f576eefc9a7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"677\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-408710d5432d917c4d462f576eefc9a7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;677&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"677\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-408710d5432d917c4d462f576eefc9a7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-408710d5432d917c4d462f576eefc9a7_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f0d8a6ae34ac98eb3a34262466c88e86_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"505\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f0d8a6ae34ac98eb3a34262466c88e86_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;505&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"505\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f0d8a6ae34ac98eb3a34262466c88e86_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f0d8a6ae34ac98eb3a34262466c88e86_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-84a320ba392e19bed21b88d55fda6cbd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"759\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-84a320ba392e19bed21b88d55fda6cbd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;759&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"759\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-84a320ba392e19bed21b88d55fda6cbd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-84a320ba392e19bed21b88d55fda6cbd_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-75154eb5b4735285b7b68fe224df00bc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"384\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-75154eb5b4735285b7b68fe224df00bc_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;384&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"384\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-75154eb5b4735285b7b68fe224df00bc_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-75154eb5b4735285b7b68fe224df00bc_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5485322fdc72f41cdbd505531ce7aca1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"431\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5485322fdc72f41cdbd505531ce7aca1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;431&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"431\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5485322fdc72f41cdbd505531ce7aca1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5485322fdc72f41cdbd505531ce7aca1_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4b5f941b0a2073f12204b29e584f6948_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"450\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-4b5f941b0a2073f12204b29e584f6948_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;450&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"450\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-4b5f941b0a2073f12204b29e584f6948_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-4b5f941b0a2073f12204b29e584f6948_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e5efcfd1cd04727ae5edd7bd04c29303_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"411\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-e5efcfd1cd04727ae5edd7bd04c29303_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;411&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"411\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-e5efcfd1cd04727ae5edd7bd04c29303_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e5efcfd1cd04727ae5edd7bd04c29303_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-dc2f7c95a1fc0b869a4863dc1369ed9a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-dc2f7c95a1fc0b869a4863dc1369ed9a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;326&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-dc2f7c95a1fc0b869a4863dc1369ed9a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-dc2f7c95a1fc0b869a4863dc1369ed9a_b.jpg\"/></figure><p>该模块的学习形式如下：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ade4115e46fde36fcc72590531e89e55_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1720\" data-rawheight=\"1624\" class=\"origin_image zh-lightbox-thumb\" width=\"1720\" data-original=\"https://pic2.zhimg.com/v2-ade4115e46fde36fcc72590531e89e55_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1720&#39; height=&#39;1624&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1720\" data-rawheight=\"1624\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1720\" data-original=\"https://pic2.zhimg.com/v2-ade4115e46fde36fcc72590531e89e55_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ade4115e46fde36fcc72590531e89e55_b.jpg\"/></figure><p><b>如果心动，就早日加入吧！学习债，越晚还的越多！</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-01e36361c94d1322e1afb254ced686f0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic1.zhimg.com/v2-01e36361c94d1322e1afb254ced686f0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;930&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic1.zhimg.com/v2-01e36361c94d1322e1afb254ced686f0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-01e36361c94d1322e1afb254ced686f0_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/78337242", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 8, 
            "title": "【每周CV论文推荐】 初学者必须精读的5篇深度学习优化相关文章", 
            "content": "<p>欢迎来到《每周CV论文推荐》。在这个专栏里，还是本着有三AI一贯的原则，专注于让大家能够<b>系统性完成学习</b>，所以我们推荐的文章也必定是同一主题的。</p><p>从事深度学习岗位，扎实的深度学习理论基础是必须掌握的，在前面我们已经给大家推荐过入门必须的模型结构相关的文章，今天给大家推荐必须精读的优化技术相关的文章。</p><p>作者&amp;编辑 | 言有三</p><h2><b>1 Xavier初始化方法</b></h2><p>早期的深层神经网络就是被卡在了初始化上，xavier是一个非常有效的初始化方法，它的来龙去脉自然是需要仔细了解。</p><p>文章引用量：6000+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;372&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_b.jpg\"/></figure><p>[1] Glorot X, Bengio Y. Understanding the difficulty of training deep feedforward neural networks[C]//Proceedings of the thirteenth international conference on artificial intelligence and statistics. 2010: 249-256.</p><h2><b>2 ReLU函数</b></h2><p>简单而不光滑的ReLU为何开始取代sigmoid等激活函数，它为何有效，不需多说，基本上一直都被问。</p><p>文章引用量：4000+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9dfd0a86a5421a495a56836feb949c88_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"560\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb\" width=\"560\" data-original=\"https://pic1.zhimg.com/v2-9dfd0a86a5421a495a56836feb949c88_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;560&#39; height=&#39;420&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"560\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"560\" data-original=\"https://pic1.zhimg.com/v2-9dfd0a86a5421a495a56836feb949c88_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-9dfd0a86a5421a495a56836feb949c88_b.jpg\"/></figure><p>[2] Glorot X, Bordes A, Bengio Y. Deep sparse rectifier neural networks[C]//Proceedings of the fourteenth international conference on artificial intelligence and statistics. 2011: 315-323.</p><h2><b>3 Dropout正则化技术</b></h2><p>Dropout是AlexNet网络成功训练必不可缺少的工程技术，也是极为强大的正则化技术，在深度学习优化技术中举足轻重。</p><p>文章引用量：13000+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-13054bdaa94c3c838dce64fb892765fc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"725\" data-rawheight=\"334\" class=\"origin_image zh-lightbox-thumb\" width=\"725\" data-original=\"https://pic1.zhimg.com/v2-13054bdaa94c3c838dce64fb892765fc_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;725&#39; height=&#39;334&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"725\" data-rawheight=\"334\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"725\" data-original=\"https://pic1.zhimg.com/v2-13054bdaa94c3c838dce64fb892765fc_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-13054bdaa94c3c838dce64fb892765fc_b.jpg\"/></figure><p>[3] Srivastava N, Hinton G, Krizhevsky A, et al. Dropout: a simple way to prevent neural networks from overfitting[J]. The journal of machine learning research, 2014, 15(1): 1929-1958.</p><h2><b>4 池化与步长</b></h2><p>池化的思想和应用早就随着卷积而诞生，但是现在我们常常用带步长的卷积去替代池化，为什么呢？它们的对比究竟如何。</p><p>文章引用量：1400+</p><p>推荐指数：✦✦✦✦✧</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-10014da3a20b5d7c0f410a20ccc0db34_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"857\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-10014da3a20b5d7c0f410a20ccc0db34_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;857&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"857\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-10014da3a20b5d7c0f410a20ccc0db34_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-10014da3a20b5d7c0f410a20ccc0db34_b.jpg\"/></figure><p>[4] Springenberg J T, Dosovitskiy A, Brox T, et al. Striving for simplicity: The all convolutional net[J]. arXiv preprint arXiv:1412.6806, 2014.</p><h2><b>5 BN的提出</b></h2><p>BN之强大，人尽皆知，不管你读过多少资料解读，这原文都是需要精读的。</p><p>文章引用量：11000+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b45c63e54e00fb9b74977065782be16d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"794\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b45c63e54e00fb9b74977065782be16d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;794&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"794\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b45c63e54e00fb9b74977065782be16d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b45c63e54e00fb9b74977065782be16d_b.jpg\"/></figure><p>[5] Ioffe S, Szegedy C. Batch normalization: Accelerating deep network training by reducing internal covariate shift[J]. arXiv preprint arXiv:1502.03167, 2015.</p><p>鉴于理论文章读起来难度要高不少，本周就只推荐5篇，深度学习优化相关的内容这还只是前菜，希望大家提前做好准备。</p><h2><b>6 如何获取文章与交流</b></h2><p>找到有三AI开源项目即可获取。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/longpeng2008/yousan.ai</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3723edcba0417e2dcf26dd3c8721a622_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"375\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-3723edcba0417e2dcf26dd3c8721a622_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;375&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"375\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-3723edcba0417e2dcf26dd3c8721a622_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-3723edcba0417e2dcf26dd3c8721a622_b.jpg\"/></figure><p>文章细节众多，阅读交流在有三AI知识星球中进行，感兴趣可以加入。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\"/></figure><p><b>总结</b></p><p>以上就是初入深度学习领域必读的理论相关的文章，下一期我们将介绍一些训练和测试数据使用技巧相关的文章。</p>", 
            "topic": [
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/76781900", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 36, 
            "title": "【每周CV论文推荐】 掌握残差网络必读的10多篇文章", 
            "content": "<p>欢迎来到《每周CV论文推荐》。在这个专栏里，还是本着有三AI一贯的原则，专注于让大家能够<b>系统性完成学习</b>，所以我们推荐的文章也必定是同一主题的。</p><p>残差网络作为当今最成功的网络结构之一，今天就给大家推荐一些必读的文章，涵盖残差网络的由来，原理及其发展变种。</p><p>作者&amp;编辑 | 言有三</p><h2><b>1 残差机制的由来</b></h2><p>残差连接的思想起源于中心化，Nicol N. Schraudolph[1]其实很早就将这样的思想拓展到了梯度的反向传播中，提出了shortcut connection技术。虽然文章不知名，但是大家还是应该了解。</p><p>文章引用量：较少</p><p>推荐指数：✦✦✦✧✧</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-706ff7a4ade7537fb024bba52e25b750_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"502\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-706ff7a4ade7537fb024bba52e25b750_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;502&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"502\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-706ff7a4ade7537fb024bba52e25b750_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-706ff7a4ade7537fb024bba52e25b750_b.jpg\"/></figure><p>[1] Schraudolph N. Accelerated gradient descent by factor-centering decomposition[J]. Technical report/IDSIA, 1998, 98.</p><h2><b>2 早期残差网络探索</b></h2><p>既然残差思想早就诞生了，不可能没有大佬注意这个问题，2012年的时候Raiko，LeCun等人就在论文[2]中更加细致地研究了shortcut connections对模型性能的影响。因为算力不够没有火起来，但这说明了大佬们是很敏感的。几年后与残差网络同时期还有一篇文章叫highway-network[3]，借鉴了来自于LSTM的控制门的思想，比残差网络复杂一点。</p><p>文章引用量：150+</p><p>推荐指数：✦✦✦✧✧</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-eaaf53e3c0ee595c2dc964bcced98410_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"384\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-eaaf53e3c0ee595c2dc964bcced98410_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;384&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"384\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-eaaf53e3c0ee595c2dc964bcced98410_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-eaaf53e3c0ee595c2dc964bcced98410_b.jpg\"/></figure><p>[2] Raiko T, Valpola H, LeCun Y. Deep learning made easier by linear transformations in perceptrons[C]//Artificial intelligence and statistics. 2012: 924-932.</p><p>[3] Srivastava R K, Greff K, Schmidhuber J. Training very deep networks[C]//Advances in neural information processing systems. 2015: 2377-2385.</p><h2><b>3 深度学习与残差网络诞生</b></h2><p>前面三篇是前菜，向前辈致敬，然后就是主菜残差网络了，不多说，才过了四年就26000多的引用量，太惊人了。</p><p>文章引用量：26000+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8c17e8f6ab54613b8f45deefa896c14a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"977\" data-rawheight=\"561\" class=\"origin_image zh-lightbox-thumb\" width=\"977\" data-original=\"https://pic3.zhimg.com/v2-8c17e8f6ab54613b8f45deefa896c14a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;977&#39; height=&#39;561&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"977\" data-rawheight=\"561\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"977\" data-original=\"https://pic3.zhimg.com/v2-8c17e8f6ab54613b8f45deefa896c14a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8c17e8f6ab54613b8f45deefa896c14a_b.jpg\"/></figure><p>[4] He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.</p><h2><b>4 ResNet深度冗余性研究</b></h2><p>在刚开始的时候大多数人认为残差网络有效是因为促进了梯度传播从而可以使用更深的模型，但是随着研究者的增加，大家并不满足于这个解释。其中非常具有代表性的一篇文章就是文[5]，它发现深层的残差网络可以看做是不同深度的浅层神经网络的ensemble，训练完一个深层网络后，在测试的时候随机去除某个网络层，并不会使得网络的性能有很大的退化，而对于VGG等网络来说则是致命的。虽然引用率依然不高，但却是非常好的工作，对之后的很多研究都有重要影响，相似的文章还有[6]。</p><p>文章引用量：290+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-cff84bf033adc41ee0da16b5740dda9c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"458\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-cff84bf033adc41ee0da16b5740dda9c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;458&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"458\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-cff84bf033adc41ee0da16b5740dda9c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-cff84bf033adc41ee0da16b5740dda9c_b.jpg\"/></figure><p>[5] Veit A, Wilber M J, Belongie S. Residual networks behave like ensembles of relatively shallow networks[C]//Advances in neural information processing systems. 2016: 550-558.</p><p>[6] Huang G, Sun Y, Liu Z, et al. Deep networks with stochastic depth[C]//European conference on computer vision. Springer, Cham, 2016: 646-661.</p><h2><b>5 ResNet结构对称性研究</b></h2><p>一些研究表明残差网络的有效性是因为其非对称的结构减缓了神经网络的退化问题，这也是对其有效性机制的一个重要研究，大家可以以此篇文章作为起点。</p><p>文章引用量：较少</p><p>推荐指数：✦✦✦✦✧</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-0615cc01d60470a5ab37c2472c284482_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-0615cc01d60470a5ab37c2472c284482_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;238&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-0615cc01d60470a5ab37c2472c284482_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-0615cc01d60470a5ab37c2472c284482_b.jpg\"/></figure><p>[7] Orhan A E, Pitkow X. Skip connections eliminate singularities[J]. arXiv preprint arXiv:1701.09175, 2017.</p><h2><b>6 预激活ResNet</b></h2><p>由于主流的卷积神经网络都是卷积+BN+激活串接的方式，因此我们一般都不会去在意它们的顺序问题。但是对于残差网络这个顺序却会有影响，这也对后面的一些研究有指导意义。</p><p>文章引用量：2000+</p><p>推荐指数：✦✦✦✦✧</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e590033dd3db01bd1f84a0f7fccfe2b8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"519\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-e590033dd3db01bd1f84a0f7fccfe2b8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;519&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"519\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-e590033dd3db01bd1f84a0f7fccfe2b8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e590033dd3db01bd1f84a0f7fccfe2b8_b.jpg\"/></figure><p>[8] He K, Zhang X, Ren S, et al. Identity mappings in deep residual networks[C]//European conference on computer vision. Springer, Cham, 2016: 630-645.</p><h2><b>7 ResNet宽度问题 </b></h2><p>宽度和深度一直都是两个重要的维度，高效的网络有时候也需要在这两者之间进行折衷。那么宽度和深度到底谁更加重要，在残差网络结构上这个问题也有两篇重要的研究。</p><p>文章引用量：2000+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e570b505eb3e13ba3560558536d95c35_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"385\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-e570b505eb3e13ba3560558536d95c35_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;385&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"385\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-e570b505eb3e13ba3560558536d95c35_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e570b505eb3e13ba3560558536d95c35_b.jpg\"/></figure><p>[9] Zagoruyko S, Komodakis N. Wide residual networks[J]. arXiv preprint arXiv:1605.07146, 2016.</p><p>[10] Xie S, Girshick R, Dollár P, et al. Aggregated residual transformations for deep neural networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 1492-1500.</p><h2><b>8 更多的连接</b></h2><p>假如进一步将残差连接的思想发挥到极致，把所有层都与其他所有层相连，就可以得到DenseNet。假如连接是双向的，就是CliqueNet。它们都是比原始的残差网络更加高效的设计，非常有用。</p><p>文章引用量：4000+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-b7891aa0c18eec73f74c86bb27d24103_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"883\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-b7891aa0c18eec73f74c86bb27d24103_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;883&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"883\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-b7891aa0c18eec73f74c86bb27d24103_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-b7891aa0c18eec73f74c86bb27d24103_b.jpg\"/></figure><p>[11] Huang G, Liu Z, Van Der Maaten L, et al. Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4700-4708.</p><p>[12] Yang Y, Zhong Z, Shen T, et al. Convolutional neural networks with alternately updated clique[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 2413-2422.</p><p>残差网络相关的文章实在是太多了，这里只能列举一个比较合适的学习路线，如果你想要了解更多，可以到有三AI知识星球交流。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-59ab75102b8ec3ba963eadce3c48360e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"946\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-59ab75102b8ec3ba963eadce3c48360e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;946&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"946\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-59ab75102b8ec3ba963eadce3c48360e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-59ab75102b8ec3ba963eadce3c48360e_b.jpg\"/></figure><h2><b>9 如何获取文章与交流</b></h2><p>找到有三AI开源项目即可获取。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/longpeng2008/yousan.ai</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bf08f393804506c55b1885a2a473052c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"499\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-bf08f393804506c55b1885a2a473052c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;499&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"499\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-bf08f393804506c55b1885a2a473052c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-bf08f393804506c55b1885a2a473052c_b.jpg\"/></figure><p>文章细节众多，阅读交流在有三AI知识星球中进行，感兴趣可以加入。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\"/></figure><h2><b>总结</b></h2><p>以上就是初学残差网络结构必读的文章，下一期我们将介绍一些训练和测试数据使用技巧相关的文章。</p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/75525100", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 29, 
            "title": "「每周论文推荐」 初入深度学习CV领域必读的几篇文章", 
            "content": "<p>很多朋友都希望我们开通论文推荐和阅读板块，那就开吧，此专栏名为《每周论文推荐》。在这个专栏里，还是本着有三AI一贯的原则，专注于让大家能够系统性完成学习，所以我们推荐的文章也必定是同一主题的。</p><p>网络模型作为深度学习的几大核心问题之一，今天就给初入深度学习CV领域的朋友推荐一些必读的文章，相信读完这些文章之后，大家对这个主题会有更深刻的体会。</p><p>作者&amp;编辑 | 言有三</p><h2><b>1 视觉机制的研究</b></h2><p>这篇文章是对视觉机制的重要研究，由现代视觉科学之父，诺贝尔生理学与医学奖获得者，加拿大神经生理学家 David Hunter Hubel 和瑞典神经科学家 Torsten Nils Wiesel所写，是CNN的启蒙。</p><p>文章引用量：13000+</p><p>推荐指数：✦✦✦✧✧</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b871cd0cdbb6115b83e42d4b01102eba_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"465\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-b871cd0cdbb6115b83e42d4b01102eba_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;465&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"465\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-b871cd0cdbb6115b83e42d4b01102eba_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b871cd0cdbb6115b83e42d4b01102eba_b.jpg\"/></figure><p>[1] Hubel D H, Wiesel T N. Receptive fields, binocular interaction and functional architecture in the cat&#39;s visual cortex[J]. The Journal of physiology, 1962, 160(1): 106-154.</p><h2><b>2 第一个图像CNN网络</b></h2><p>1980 年日本 NHK 技术研究所的研究员福島邦彦提出了Neocognitron网络，这是第一个真正意义上的多层级联神经网络，与当前的卷积神经网络结构非常相似，可以认为是<b>卷积神经网络的起源</b>。</p><p>文章引用量：3000+</p><p>推荐指数：✦✦✦✦✧</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b22377e18b4b15279eb589c65e672369_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"279\" class=\"content_image\" width=\"400\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;400&#39; height=&#39;279&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"279\" class=\"content_image lazy\" width=\"400\" data-actualsrc=\"https://pic2.zhimg.com/v2-b22377e18b4b15279eb589c65e672369_b.jpg\"/></figure><p>[2] Fukushima K. Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position[J]. Biological cybernetics, 1980, 36(4): 193-202.</p><h2><b>3 LeNet5</b></h2><p>从1989年开始纽约大学的Yann LeCun等人开始认真研究卷积神经网络，并提出了LeNets网络系列，迭代了近10年，从LeNet1直到大家最为熟悉的LeNet5诞生。这是卷积神经网络真正商用化的开始，也是反向传播理论大放异彩的开始，可称之为<b>卷积神经网络的Hello World</b>。</p><p>文章引用量：19000+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9bcfc51d04debb3f01b537114fc6f9b2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"311\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-9bcfc51d04debb3f01b537114fc6f9b2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;311&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"311\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-9bcfc51d04debb3f01b537114fc6f9b2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9bcfc51d04debb3f01b537114fc6f9b2_b.jpg\"/></figure><p>[3] LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324.</p><h2><b>4 深度学习启蒙</b></h2><p>2006年Geoffrey Everest Hinton等人在《Science》杂志上发表文章《reducing the dimensionality of data with neural networks》，提出了参数逐层初始化的DBN网络的训练，一般被认为是“深度学习”的启蒙。</p><p>文章引用量：9000+</p><p>推荐指数：✦✦✦✦✧</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7f35014c425a9db01a9a4bfff920f65e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"522\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-7f35014c425a9db01a9a4bfff920f65e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;522&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"522\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-7f35014c425a9db01a9a4bfff920f65e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-7f35014c425a9db01a9a4bfff920f65e_b.jpg\"/></figure><p>[4] Hinton G E, Salakhutdinov R R. Reducing the dimensionality of data with neural networks[J]. science, 2006, 313(5786): 504-507.</p><h2><b>5 深度学习里程碑</b></h2><p>2012年，在图像领域中具有里程碑意义的ImageNet竞赛中，Geoffrey Hinton的学生Alex Krizhevsky提出了 AlexNet，凭借若干优秀的工程技巧一举夺魁远超对手，意味着深度学习强势诞生。</p><p>文章引用量：43000+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ad2cc70d1c5d8fc58f078bb1437e4251_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"220\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-ad2cc70d1c5d8fc58f078bb1437e4251_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;220&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"220\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-ad2cc70d1c5d8fc58f078bb1437e4251_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ad2cc70d1c5d8fc58f078bb1437e4251_b.jpg\"/></figure><p>[5] Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.</p><h2><b>6 CNN可视化</b></h2><p>2013年Hinton的学生Matthew D. Zeiler和Rob Fergus 在论文“Visualizing andUnderstanding Convolutional Networks”中提出了zfnet，他们利用反卷积技术对CNN进行了可视化，详细探讨了CNN的分层抽象学习能力。</p><p>文章引用量：6000+</p><p>推荐指数：✦✦✦✦✧</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-2864c5bf6c71403f1aa7221685634d98_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"825\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-2864c5bf6c71403f1aa7221685634d98_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;825&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"825\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-2864c5bf6c71403f1aa7221685634d98_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-2864c5bf6c71403f1aa7221685634d98_b.jpg\"/></figure><p>[6] Zeiler M D, Fergus R. Visualizing and understanding convolutional networks[C]//European conference on computer vision. Springer, Cham, 2014: 818-833.</p><h2><b>7 CNN重要基准模型</b></h2><p>2014年牛津大学视觉组在论文“very deep convolutional networks for large-scale image recognition”中提出了VGGNet，分别在ImageNet的定位和分类任务中取得第一名和第二名，以简单的工程技巧成为了至今仍然被广泛使用的baseline。</p><p>文章引用量：24000+</p><p>推荐指数：✦✦✦✦✦</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-3404a0c0732249568d966a33e7900648_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"489\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-3404a0c0732249568d966a33e7900648_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;489&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"489\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-3404a0c0732249568d966a33e7900648_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-3404a0c0732249568d966a33e7900648_b.jpg\"/></figure><p>[7] Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.</p><h2><b>8 1*1卷积</b></h2><p>这只是一个将普通卷积核半径变为1的卷积方式，却影响了之后几乎所有的模型，将这个1×1的特殊卷积用于<b>通道的降维和升维</b>，已经成为模型设计不可缺少的组件。</p><p>文章引用量：4000+</p><p>推荐指数：✦✦✦✦✧</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d648ae7dcb1f57cfd89ba5c7e7de6cc0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"448\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-d648ae7dcb1f57cfd89ba5c7e7de6cc0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;448&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"448\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-d648ae7dcb1f57cfd89ba5c7e7de6cc0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d648ae7dcb1f57cfd89ba5c7e7de6cc0_b.jpg\"/></figure><p>[8] Lin M, Chen Q, Yan S. Network in network[J]. arXiv preprint arXiv:1312.4400, 2013.</p><h2><b>9 Inception机制</b></h2><p>在VGG网络不能再通过加深得到进一步性能突破的时候，Inception模型(又名GoogLeNet)使用了拥有<b>不同感受野并行的多分支Inception</b>结构，进一步加深了网络深度并成为当年的基准模型。</p><p>文章引用量：14000+</p><p>推荐指数：✦✦✦✦✧</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4f129ee50bbf5b61c63ad75c7bce54c9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1053\" data-rawheight=\"300\" class=\"origin_image zh-lightbox-thumb\" width=\"1053\" data-original=\"https://pic2.zhimg.com/v2-4f129ee50bbf5b61c63ad75c7bce54c9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1053&#39; height=&#39;300&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1053\" data-rawheight=\"300\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1053\" data-original=\"https://pic2.zhimg.com/v2-4f129ee50bbf5b61c63ad75c7bce54c9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4f129ee50bbf5b61c63ad75c7bce54c9_b.jpg\"/></figure><p>[9] Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 1-9.</p><p>除了以上文章，还有几篇文章推荐大家也去阅读，包括第一个语音CNN网络[10]，小卷积的机制研究[11]等。</p><p>[10] Waibel A, Hanazawa T, Hinton G, et al. Phoneme recognition using time-delay neural networks[J]. Backpropagation: Theory, Architectures and Applications, 1995: 35-61.</p><p>[11] Ciresan D C, Meier U, Masci J, et al. Flexible, high performance convolutional neural networks for image classification[C]//Twenty-Second International Joint Conference on Artificial Intelligence. 2011.</p><h2><b>10 如何获取文章与交流</b></h2><p>找到有三AI开源项目即可获取。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/longpeng2008/yousan.ai</code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4a5448155d2afa46471f5ee8140a40fa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"341\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-4a5448155d2afa46471f5ee8140a40fa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;341&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"341\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-4a5448155d2afa46471f5ee8140a40fa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4a5448155d2afa46471f5ee8140a40fa_b.jpg\"/></figure><h2><b>总结</b></h2><p>以上就是CNN发展早期的一些重要论文，下一期我们将推荐残差网络结构相关的研究。</p><p>文章细节众多，阅读交流在有三AI知识星球中进行，感兴趣可以加入。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9492db1f74bec41e686669dd1855815e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"347\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-9492db1f74bec41e686669dd1855815e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;347&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"347\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-9492db1f74bec41e686669dd1855815e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9492db1f74bec41e686669dd1855815e_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/63656599", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 8, 
            "title": "【完结】AI1000问以后知识星球和B站见啦", 
            "content": "<p></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a0495da16c1f2152ad8f1650c2d22a6a_b.jpg\" data-rawwidth=\"1080\" data-rawheight=\"608\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-a0495da16c1f2152ad8f1650c2d22a6a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1080\" data-rawheight=\"608\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-a0495da16c1f2152ad8f1650c2d22a6a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a0495da16c1f2152ad8f1650c2d22a6a_b.jpg\"/></figure><p>文/编辑 | 言有三</p><p><b>学习从来都是从大处着眼，小处着手。前段时间公众号开通了专栏《AI 1000问》，专门选择那些很小，容易被忽视，普通但是不简单，可以引申很多思考的问题，得到了大家的喜欢，现在已经12期了。</b></p><p><b>因为知识点无法系统性串接，而且内容更新会不定时，所以后续AI1000问就会全部并入知识星球了，欢迎继续来关注噢。</b></p><p><b>下面我们再来回顾一下之前的12个问题吧，在没有看我们公众号内容之前，你都能回答出来吗？</b></p><h2><b>第1问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4efca894ff67da2cced916715d1cfcd5_b.jpg\" data-rawwidth=\"1080\" data-rawheight=\"606\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-4efca894ff67da2cced916715d1cfcd5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;606&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1080\" data-rawheight=\"606\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-4efca894ff67da2cced916715d1cfcd5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4efca894ff67da2cced916715d1cfcd5_b.jpg\"/></figure><p>做过图像分类项目或者看过文章的小伙伴们应该都知道，在论文中进行各类方法的比较时，要求使用同样的数据集。而为了公平的比较，网络的输入大小通常都是224*224的大小，那为什么呢？你第一时间思考出答案了吗？</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031667%26idx%3D1%26sn%3D85bf87f979e3bee1db0b763cfef35900%26chksm%3D8712bd8eb0653498a9269d478e7799f43c2b5f8ac33b2e407036cbd7a6c24cafb3b4787a419c%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><h2><b>第2问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b47be5d092143c1efe2d81b0007bcf39_b.jpg\" data-rawwidth=\"1080\" data-rawheight=\"311\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b47be5d092143c1efe2d81b0007bcf39_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;311&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1080\" data-rawheight=\"311\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b47be5d092143c1efe2d81b0007bcf39_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b47be5d092143c1efe2d81b0007bcf39_b.jpg\"/></figure><p>相信大家也都知道LeNet5这个经典的卷积神经网络，它有3个全连接层，输出维度分别是120，84，10，不知道大家知不知道为什么倒数第2个全连接层的维度是84呢？这背后有一个有趣的小故事，考验论文是不是看得比别人细致，思考是不是比别人更多的机会来了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2b23b82798e5cae3c78d292d2fad19ed_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic2.zhimg.com/v2-2b23b82798e5cae3c78d292d2fad19ed_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic2.zhimg.com/v2-2b23b82798e5cae3c78d292d2fad19ed_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2b23b82798e5cae3c78d292d2fad19ed_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031677%26idx%3D1%26sn%3D014faac5820e9cc698a44948f851d151%26chksm%3D8712bd80b06534961e2c3856f8954aaea03dc7b55f0cd15c95696fc867882e5af2d423970942%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><h2><b>第3问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-70861b1f1341c892f491e67546099c25_b.jpg\" data-rawwidth=\"1080\" data-rawheight=\"720\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-70861b1f1341c892f491e67546099c25_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1080\" data-rawheight=\"720\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-70861b1f1341c892f491e67546099c25_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-70861b1f1341c892f491e67546099c25_b.jpg\"/></figure><p>做图像处理的我们应该都知道，OpenCV是我们必备的一个工具，在使用OpenCV读取图像时你应该也发现了读取出来的数组居然是BGR格式，而不是我们听的最多，用的最多的RGB格式，这是为什么呢？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f7fb57e12a0ed21a7a30a8a6cfbe82a8_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic1.zhimg.com/v2-f7fb57e12a0ed21a7a30a8a6cfbe82a8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic1.zhimg.com/v2-f7fb57e12a0ed21a7a30a8a6cfbe82a8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-f7fb57e12a0ed21a7a30a8a6cfbe82a8_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031749%26idx%3D2%26sn%3Dea968d20aa61945b07f9c6002542b02a%26chksm%3D8712ba38b065332e48bb0f1df4fcb767d1ccfabf442e2bdca85150843dc3b5a392222a08bb51%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】为什么OpenCV读取的图像格式是BGR？</a></p><h2><b>第4问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-016f643d1c969e196867db5fc3890682_b.jpg\" data-rawwidth=\"952\" data-rawheight=\"461\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"952\" data-original=\"https://pic3.zhimg.com/v2-016f643d1c969e196867db5fc3890682_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;952&#39; height=&#39;461&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"952\" data-rawheight=\"461\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"952\" data-original=\"https://pic3.zhimg.com/v2-016f643d1c969e196867db5fc3890682_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-016f643d1c969e196867db5fc3890682_b.jpg\"/></figure><p>现在说起人工智能，聊起AI，每个人或多或少都能说出一点，从历史到未来，从图灵到冯诺依曼，从SVM到CNN等等，但是如果问你是否知道机器学习和模式识别有什么区别？我相信大多数人很懵圈，这两个东西有区别吗？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d28ecaa2140763c315f53cb7a25eb99e_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic3.zhimg.com/v2-d28ecaa2140763c315f53cb7a25eb99e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic3.zhimg.com/v2-d28ecaa2140763c315f53cb7a25eb99e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d28ecaa2140763c315f53cb7a25eb99e_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031775%26idx%3D2%26sn%3D9a1b16f2a476a2b4cb15668f05f534aa%26chksm%3D8712ba22b0653334d1f5e1cbd0cfd0ce714b71a5dcba65faa7fa070a9eab0e4fad97ed16b33f%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><h2><b>第5问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d56b6c6d5f7948d6e5a64d3b7ab0c601_b.jpg\" data-rawwidth=\"1080\" data-rawheight=\"608\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-d56b6c6d5f7948d6e5a64d3b7ab0c601_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1080\" data-rawheight=\"608\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-d56b6c6d5f7948d6e5a64d3b7ab0c601_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d56b6c6d5f7948d6e5a64d3b7ab0c601_b.jpg\"/></figure><p>人脸识别一直以来都是当前生物特征识别研究的热点之一，人脸识别技术在工业界应用价值尤为突出。那么face detection、alignment、verification、identification(recognization)，你能分的清楚吗？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-19608314c178c3cc32555b4d05e5e751_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic2.zhimg.com/v2-19608314c178c3cc32555b4d05e5e751_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic2.zhimg.com/v2-19608314c178c3cc32555b4d05e5e751_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-19608314c178c3cc32555b4d05e5e751_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031805%26idx%3D2%26sn%3D039358c847479cbe46340a592f398ab9%26chksm%3D8712ba00b0653316cdb4c5f4d50756dee8cad8a0bac89b6639befa65b19dfa0473e8fd2892b4%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】人脸识别的4个方向，你还分的清楚吗？</a></p><h2><b>第6问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e4938f139cd4cc2cfbdb6c1869b5503d_b.jpg\" data-rawwidth=\"474\" data-rawheight=\"249\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"474\" data-original=\"https://pic2.zhimg.com/v2-e4938f139cd4cc2cfbdb6c1869b5503d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;474&#39; height=&#39;249&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"474\" data-rawheight=\"249\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"474\" data-original=\"https://pic2.zhimg.com/v2-e4938f139cd4cc2cfbdb6c1869b5503d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e4938f139cd4cc2cfbdb6c1869b5503d_b.jpg\"/></figure><p>我们都知道在2014年ILSVRC比赛中GoogLeNet获得了冠军，其所用模型参数不足AlexNet的1/12，但性能却比AlexNet好不少。那么为什么GoogLeNet要取一个跟作者名字没有关系，也不能直接表现出网络特点的InceptionNet作为名字呢？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-dda099ced5c7276fe98899c4c22a4e84_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic1.zhimg.com/v2-dda099ced5c7276fe98899c4c22a4e84_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic1.zhimg.com/v2-dda099ced5c7276fe98899c4c22a4e84_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-dda099ced5c7276fe98899c4c22a4e84_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031845%26idx%3D2%26sn%3D94809c1b4fa3947c4ec65bcc6b30f50d%26chksm%3D8712bad8b06533ce8523b76657d5e2accfbd854c51e01f7e56518586df2e6b114e2fd1ea6a7d%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><h2><b>第7问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c1ff2c040b94e8194a965d6960f36fbb_b.jpg\" data-rawwidth=\"616\" data-rawheight=\"267\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"616\" data-original=\"https://pic4.zhimg.com/v2-c1ff2c040b94e8194a965d6960f36fbb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;616&#39; height=&#39;267&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"616\" data-rawheight=\"267\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"616\" data-original=\"https://pic4.zhimg.com/v2-c1ff2c040b94e8194a965d6960f36fbb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c1ff2c040b94e8194a965d6960f36fbb_b.jpg\"/></figure><p>想必大家也都听过熵这个概念，也都知道softmax以及softmax loss这个概念，那么交叉熵和softmax loss有什么区别和联系呢?。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-2399b8783bebe9879e27b9f3d61546c8_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic1.zhimg.com/v2-2399b8783bebe9879e27b9f3d61546c8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic1.zhimg.com/v2-2399b8783bebe9879e27b9f3d61546c8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-2399b8783bebe9879e27b9f3d61546c8_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031874%26idx%3D2%26sn%3Db08527015711b436e7433815afac6461%26chksm%3D8712babfb06533a93cb618c111b641ffad1f36fbe178543d21a7d2fecbe105052a79d7640fa7%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><h2><b>第8问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-796229829ac96fb5d758e2f0e1366701_b.jpg\" data-rawwidth=\"565\" data-rawheight=\"397\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"565\" data-original=\"https://pic2.zhimg.com/v2-796229829ac96fb5d758e2f0e1366701_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;565&#39; height=&#39;397&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"565\" data-rawheight=\"397\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"565\" data-original=\"https://pic2.zhimg.com/v2-796229829ac96fb5d758e2f0e1366701_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-796229829ac96fb5d758e2f0e1366701_b.jpg\"/></figure><p>想必熟悉图像噪声和和图像信噪比的应该都听说过dB，一般监控摄像机的图像信噪比是50dB，信噪比的典型值一般为45-55dB，若为50dB，则图像有少量噪声，但图像质量良好；若为60dB，则图像质量优良，不出现噪声。说了这么多dB，那你知道dB的由来吗？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-92bff00a52077d4500478c1e4b5e347b_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic4.zhimg.com/v2-92bff00a52077d4500478c1e4b5e347b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic4.zhimg.com/v2-92bff00a52077d4500478c1e4b5e347b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-92bff00a52077d4500478c1e4b5e347b_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031947%26idx%3D2%26sn%3D45b77121fd7526c9e773247c41e08970%26chksm%3D8712bb76b065326005de6cfb5d1b9ff8241bdfb77a92d5ba202a79cdd487bf1d7a3f47a2abbb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】为什么信号有单位而且是dB？</a></p><h2><b>第9问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fac96fe48fdfa9c96f4ee6482c1bbc16_b.jpg\" data-rawwidth=\"1080\" data-rawheight=\"340\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fac96fe48fdfa9c96f4ee6482c1bbc16_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;340&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1080\" data-rawheight=\"340\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fac96fe48fdfa9c96f4ee6482c1bbc16_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fac96fe48fdfa9c96f4ee6482c1bbc16_b.jpg\"/></figure><p>在很多的书以及一些公开数据集中，都会将数据集分为训练集，验证集和测试集，看起来验证集和测试集并没有区别，为什么要分这两个呢？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-eb77f25f4f7e2e21b58b9e545b16d0b3_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic4.zhimg.com/v2-eb77f25f4f7e2e21b58b9e545b16d0b3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic4.zhimg.com/v2-eb77f25f4f7e2e21b58b9e545b16d0b3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-eb77f25f4f7e2e21b58b9e545b16d0b3_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032321%26idx%3D2%26sn%3D1cf20af89bbd938015e740724bf44e8b%26chksm%3D8712b8fcb06531ea894685b46dd0b09c7adc2f4cad3d8655d5b4745cf56aaa7b35d509515d26%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】训练为什么要分测试集和验证集</a></p><h2><b>第10问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6599dfaaa7c4e8a4fa7d884d89317ce9_b.jpg\" data-rawwidth=\"1080\" data-rawheight=\"335\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-6599dfaaa7c4e8a4fa7d884d89317ce9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;335&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1080\" data-rawheight=\"335\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-6599dfaaa7c4e8a4fa7d884d89317ce9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6599dfaaa7c4e8a4fa7d884d89317ce9_b.jpg\"/></figure><p>我们知道现在在构建CNN时大家喜欢用3*3的卷积，而不是早期的5*5，7*7等更大尺寸的卷积，如vgg系列网络中全部使用了3*3的卷积。那么你知道为什么这样做吗？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b2c95f5fab56c2aaac02e4451fb69f2a_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic3.zhimg.com/v2-b2c95f5fab56c2aaac02e4451fb69f2a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic3.zhimg.com/v2-b2c95f5fab56c2aaac02e4451fb69f2a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b2c95f5fab56c2aaac02e4451fb69f2a_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032331%26idx%3D1%26sn%3D5ed21f7133c759c88209c88ba75ec23d%26chksm%3D8712b8f6b06531e09ffa565b03e70121230821d5df08afdf280188b35521b43ac19b9865e3c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a></p><h2><b>第11问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-80f6f3b292a3f79f3de53c41db3c0988_b.jpg\" data-rawwidth=\"907\" data-rawheight=\"511\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"907\" data-original=\"https://pic1.zhimg.com/v2-80f6f3b292a3f79f3de53c41db3c0988_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;907&#39; height=&#39;511&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"907\" data-rawheight=\"511\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"907\" data-original=\"https://pic1.zhimg.com/v2-80f6f3b292a3f79f3de53c41db3c0988_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-80f6f3b292a3f79f3de53c41db3c0988_b.jpg\"/></figure><p>熟悉CNN应该都知道常见的卷积核都是3*3或者5*5等，也就是奇数*奇数，似乎都没看过偶数的，这是为什么呢？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-e5954d9dc6f3eef0411b41c487586826_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic3.zhimg.com/v2-e5954d9dc6f3eef0411b41c487586826_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic3.zhimg.com/v2-e5954d9dc6f3eef0411b41c487586826_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-e5954d9dc6f3eef0411b41c487586826_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032348%26idx%3D2%26sn%3De1d54163c5f20eb5e241dfe2951b6cc0%26chksm%3D8712b8e1b06531f71a20ca7d22923ac46dff2d55b4ebbeb9c3bc053c5b3ebd6fc8891885529b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】为什么CNN中的卷积核半径都是奇数？</a></p><h2><b>第12问</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7dedc2d71549ea16ca854e56b1f66097_b.jpg\" data-rawwidth=\"1080\" data-rawheight=\"809\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-7dedc2d71549ea16ca854e56b1f66097_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;809&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1080\" data-rawheight=\"809\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-7dedc2d71549ea16ca854e56b1f66097_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-7dedc2d71549ea16ca854e56b1f66097_b.jpg\"/></figure><p>大家都知道图像分割(image segmentation)是怎么回事，就是将每个像素进行分类。常常将图像分割用于抠图替换背景，但是抠图真的只是图像分割就能搞定吗？为什么还有个技术叫做image matting呢？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-16029100a4423ab8a074256e2b67ea65_b.jpg\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic2.zhimg.com/v2-16029100a4423ab8a074256e2b67ea65_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"900\" data-rawheight=\"383\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic2.zhimg.com/v2-16029100a4423ab8a074256e2b67ea65_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-16029100a4423ab8a074256e2b67ea65_b.jpg\"/></figure><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032570%26idx%3D2%26sn%3D3d8a63fd8f890a8d680872283dfa11a2%26chksm%3D8712b907b0653011cc8d1cd17aff8e07ab085fe8a29d7d2b8756e3e3d6ff703ee6e4a419e031%26token%3D520033959%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI-1000问】segmentation和matting有什么区别？</a></p><p><b><u>看了这么多，你在看我们答案之前，都能回答出几个问题呢？</u></b></p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>然后就是重要通知了！主要有两个。</b></p><p><b>1、图文版本的《AI1000问》以后将每天在知识星球更新。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\" data-rawwidth=\"690\" data-rawheight=\"374\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"690\" data-rawheight=\"374\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\"/></figure><p><b>2、视频版本的《AI1000问》以后将在bilibili同步更新。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-540e899721c27a97175fc07e7c7f08ad_b.jpg\" data-rawwidth=\"993\" data-rawheight=\"1414\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"993\" data-original=\"https://pic2.zhimg.com/v2-540e899721c27a97175fc07e7c7f08ad_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;993&#39; height=&#39;1414&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"993\" data-rawheight=\"1414\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"993\" data-original=\"https://pic2.zhimg.com/v2-540e899721c27a97175fc07e7c7f08ad_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-540e899721c27a97175fc07e7c7f08ad_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "图像识别", 
                    "tagLink": "https://api.zhihu.com/topics/19588774"
                }
            ], 
            "comments": [
                {
                    "userName": "月光神偷", 
                    "userLink": "https://www.zhihu.com/people/ac7a3705f84d5688779da6dfcc8a535d", 
                    "content": "<p>总结得真好</p><p></p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "谢谢🙏🙏，", 
                            "likes": 0, 
                            "replyToAuthor": "月光神偷"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62894764", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 14, 
            "title": "【AI-1000问】segmentation和matting有什么区别？", 
            "content": "<p></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5a1fda7f70d0b801c92434ec11927b13_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"900\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic4.zhimg.com/v2-5a1fda7f70d0b801c92434ec11927b13_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"900\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic4.zhimg.com/v2-5a1fda7f70d0b801c92434ec11927b13_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5a1fda7f70d0b801c92434ec11927b13_b.jpg\"/></figure><p>大家都知道图像分割(image segmentation)是怎么回事，就是将每个像素进行分类。常常将图像分割用于抠图替换背景，但是抠图真的只是图像分割就能搞定吗？为什么还有个技术叫做image matting呢？</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1102276054160334848\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"segmentation和matting什么区别\" data-poster=\"https://pic2.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1102276054160334848\"><img class=\"thumbnail\" src=\"https://pic2.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">segmentation和matting什么区别<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1102276054160334848</span></span></a><p><b>解答1：什么是图像分割image segmentation？</b></p><p>图像分割就是把每一个像素都分类为一个类别，比如下图。这就是我们通常意义上所说的图像分割，不管是semantic segmentation还是instance segmentation，都是如此，每一个像素有确定的类别。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6e9862f5cb89f7440e0970d145d12d61_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"860\" data-rawheight=\"636\" class=\"origin_image zh-lightbox-thumb\" width=\"860\" data-original=\"https://pic2.zhimg.com/v2-6e9862f5cb89f7440e0970d145d12d61_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;860&#39; height=&#39;636&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"860\" data-rawheight=\"636\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"860\" data-original=\"https://pic2.zhimg.com/v2-6e9862f5cb89f7440e0970d145d12d61_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6e9862f5cb89f7440e0970d145d12d61_b.jpg\"/></figure><p><b>解答2：什么是image matting呢？</b></p><p>它与图像分割不同，也是我们通常所说的抠图。我们知道photoshop里面可以抠图，有个<b>边缘羽化</b>的功能，大家如果分割完直接替换背景，可能会带来很多不自然的边缘过度，一眼就能看出来是假图。</p><p>再者说，对于细到头发丝这样的像素，仅仅是二分类的图像分割是很难完美解决的，比如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7dedc2d71549ea16ca854e56b1f66097_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"809\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-7dedc2d71549ea16ca854e56b1f66097_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;809&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"809\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-7dedc2d71549ea16ca854e56b1f66097_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-7dedc2d71549ea16ca854e56b1f66097_b.jpg\"/></figure><p>image matting要解决的问题如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-5f6e39bebd1fd7cd41a76e72f00d0726_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"100\" class=\"origin_image zh-lightbox-thumb\" width=\"498\" data-original=\"https://pic3.zhimg.com/v2-5f6e39bebd1fd7cd41a76e72f00d0726_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;498&#39; height=&#39;100&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"100\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"498\" data-original=\"https://pic3.zhimg.com/v2-5f6e39bebd1fd7cd41a76e72f00d0726_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-5f6e39bebd1fd7cd41a76e72f00d0726_b.jpg\"/></figure><p>F就是前景，B就是背景，a就是透明度，它们都是未知的，对于RGB图像的一个像素来说，就有7个未知数。而已知数就是I，只有3个，可想而知这是一个很病态的问题，具体的求解方式这里就不说了。</p><p>image segmentation是一个硬的分割问题，将每一个像素进行分类。image matting可以看作是一个软的分割问题，它估计透明度，前景和背景，是真正实用的换背景技术。</p><p>这就是两者的主要区别，image matting问题仅限于二类。对于一个前背景估计问题来说，如果你解决了image matting问题，那么image segmentation问题自然就解决了，反之则不然。</p><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a> </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a> </p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a> </p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "图像分割", 
                    "tagLink": "https://api.zhihu.com/topics/20137632"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62893017", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 25, 
            "title": "【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？", 
            "content": "<p></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0953020b9efc1c71b323b67d191b823b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"900\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic4.zhimg.com/v2-0953020b9efc1c71b323b67d191b823b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"900\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic4.zhimg.com/v2-0953020b9efc1c71b323b67d191b823b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0953020b9efc1c71b323b67d191b823b_b.jpg\"/></figure><p>为什么CNN中的卷积核一般都是奇数*奇数？</p><p>熟悉CNN应该都知道常见的卷积核都是3*3或者5*5等，也就是奇数*奇数，似乎都没看过偶数的，这是为什么呢？</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1102274411842871296\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"为什么CNN的卷积核一般都是奇数\" data-poster=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1102274411842871296\"><img class=\"thumbnail\" src=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">为什么CNN的卷积核一般都是奇数<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1102274411842871296</span></span></a><p><b>解答1：更容易padding！</b></p><p>在卷积时，我们有时候需要卷积前后的尺寸不变。这时候我们就需要用到padding。假设图像的大小，也就是被卷积对象的大小为n*n，卷积核大小为k*k，padding的幅度设为(k-1)/2时，卷积后的输出就为(n-k+2*((k-1)/2))/1+1=n，即卷积输出为n*n，保证了卷积前后尺寸不变。但是如果k是偶数的话，(k-1)/2就不是整数了。<br/></p><p><b>解答2：更容易找到卷积锚点！</b></p><p>在CNN中，进行卷积操作时一般会以卷积核模块的一个位置为基准进行滑动，这个基准通常就是卷积核模块的中心。若卷积核为奇数，卷积锚点很好找，自然就是卷积模块中心，但如果卷积核是偶数，这时候就没有办法确定了，让谁是锚点似乎都不怎么好。</p><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a>  </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a> </p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a> </p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "卷积", 
                    "tagLink": "https://api.zhihu.com/topics/19678959"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62535003", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 46, 
            "title": "【AI-1000问】为什么现在大家喜欢用3*3小卷积？", 
            "content": "<p>我们知道现在在构建CNN时大家喜欢用3*3的卷积，而不是早期的5*5，7*7等更大尺寸的卷积，如vgg系列网络中全部使用了3*3的卷积。那么你知道为什么这样做吗？</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1101245664964546560\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"为什么现在大家喜欢用3*3小卷积\" data-poster=\"https://pic4.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1101245664964546560\"><img class=\"thumbnail\" src=\"https://pic4.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">为什么现在大家喜欢用3*3小卷积<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1101245664964546560</span></span></a><p>这里既然用3*3卷积来替代更大尺寸的卷积，那么有一个前提，就是要<b>保证两者具有同样大小的输出和感受野</b>。</p><p><b>以stride=1，padding=0，两个3*3的卷积才能代替一个5*5的卷积；三个3*3的卷积才能代替一个7*7的卷积。</b></p><p>我们来看看为何，首先看一下采用5*5卷积的方案。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9da8bf28bb5459bf708645b4f9fd7922_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"526\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-9da8bf28bb5459bf708645b4f9fd7922_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;526&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"526\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-9da8bf28bb5459bf708645b4f9fd7922_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9da8bf28bb5459bf708645b4f9fd7922_b.jpg\"/></figure><p>假设图像大小为n*n，采用5*5的卷积核其输出为(n-5)/1+1=n-4。</p><p>我们再看一下采用3*3卷积的方案。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a217b06476849b986cf2e558b8f34db8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"357\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-a217b06476849b986cf2e558b8f34db8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;357&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"357\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-a217b06476849b986cf2e558b8f34db8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a217b06476849b986cf2e558b8f34db8_b.jpg\"/></figure><p>同样图像大小为n*n，第一次卷积后输出为（n-3)/1+1=n-2，第二次卷积后输出为（n-2-3）/1+1=n-4。</p><p>从上面的图可以看出，采用一个5*5卷积核和两个3*3卷积核，它们卷积后的输出是相同大小，<b>输出的每一个像素的感受野也相等</b>。</p><p>在这样的前提下，有什么好处呢？</p><p><b>1、网络层数增加了，这增加了网络的非线性表达能力。</b></p><p><b>2、参数变少了，两个3*3和一个5*5的参数比例为3×3×2/(5×5)=0.72，同样的三个3×3和一个7×7参数比例为3×3×3/(7×7)=0.55，将近一倍的压缩，这可是很大提升。</b></p><p>这就是用3*3卷积带来的最明显的两个优势。</p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a> </p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a> </p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a> </p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a> </p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a> </p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a> </p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a> </p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a> </p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a> </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a> </p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a> </p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62534577", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 4, 
            "title": "【AI-1000问】训练为什么要分测试集和验证集？", 
            "content": "<p>在很多的书以及一些公开数据集中，都会将数据集分为训练集，验证集和测试集，看起来验证集和测试集并没有区别，为什么要分这两个呢？</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1101244573849841664\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"训练为什么要分测试集和验证集？\" data-poster=\"https://pic4.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1101244573849841664\"><img class=\"thumbnail\" src=\"https://pic4.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">训练为什么要分测试集和验证集？<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1101244573849841664</span></span></a><p>验证集和测试集的定位是不同的，一个模型需要有好的泛化能力，需要同时在训练过的数据和没训练过的数据集上取得好的结果。</p><p>所以将训练集用于训练，验证集用于调参数，然后反复迭代直到满足性能。<b>验证集扮演的就是一个辅助模型增加泛化能力的作用。而测试集不同，它仅仅用于最后评估模型的性能。对于用于比赛的公开数据集，验证集会公开标注，测试集不会公开。</b></p><p>训练集和验证集一般就是从同一个数据集随机拆分，比如要训练猫脸检测，找一个公开数据集。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9d83f3a6623d4d0ed8cdee9b5d5656e8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"738\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-9d83f3a6623d4d0ed8cdee9b5d5656e8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;738&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"738\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-9d83f3a6623d4d0ed8cdee9b5d5656e8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-9d83f3a6623d4d0ed8cdee9b5d5656e8_b.jpg\"/></figure><p>但是最终评估模型好坏的时候，只用我自己拍摄的数据作为测试集，如果表现很好，那就说明模型是真好。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-caa17dbfcaa9a60da15bdce307e1ec5f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"685\" data-rawheight=\"580\" class=\"origin_image zh-lightbox-thumb\" width=\"685\" data-original=\"https://pic4.zhimg.com/v2-caa17dbfcaa9a60da15bdce307e1ec5f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;685&#39; height=&#39;580&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"685\" data-rawheight=\"580\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"685\" data-original=\"https://pic4.zhimg.com/v2-caa17dbfcaa9a60da15bdce307e1ec5f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-caa17dbfcaa9a60da15bdce307e1ec5f_b.jpg\"/></figure><p>不过平时的小任务可以不必刻意分，尤其是数据少的时候。当你训练好模型之后，就去找真实场景的数据反复测试吧，那才是测试集的奥义。</p><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a>  </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a></p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a></p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p><p></p>", 
            "topic": [
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62534373", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 4, 
            "title": "【AI-1000问】为什么信号有单位而且是dB？", 
            "content": "<p>想必熟悉图像噪声和和图像信噪比的应该都听说过dB，一般监控摄像机的图像信噪比是50dB，信噪比的典型值一般为45-55dB，若为50dB，则图像有少量噪声，但图像质量良好；若为60dB，则图像质量优良，不出现噪声。说了这么多dB，那你知道dB的由来吗？</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1101244043568300032\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"为什么信号有单位而且是dB？\" data-poster=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1101244043568300032\"><img class=\"thumbnail\" src=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">为什么信号有单位而且是dB？<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1101244043568300032</span></span></a><p>dB在我们的生活中是一个常见的单位，如果你仔细观察，肯定多次见过。在无线通讯领域，衡量一个地点的某一无线基站通信信号强度我们用dB表示；在天线技术方面，<b>dB是衡量天线性能的一个参数，名称为增益</b>。</p><p>它是指在输入功率相等的条件下，实际天线与理想天线在空间同一点处所产生的<b>信号的功率密度之比</b>，另外它还可以表示声音的大小。通过上面的举例你应该发现dB和通信的联系非常紧密。的确是的，它的由来就和通信相关，请看下面对它由来的解释。</p><p>通信工程师发现，有线通信的线路越长，信号越弱，10英里电缆的信号会衰减到1/10，20英里会衰减到1/100，30英里会衰减到1/1000......于是将这个衰减量用电话发明人Bel先生的名字进行了命名，其定义为：损失（Bel）=log10（输入功率/输出功率），然而Bel同电容中的F一样，单位显得太大，并不适用，因此加上1/10的前缀deci的首位小字母，<b>成为dB</b>。如果你把dB写成DB、db、Db，这都是都是不对的，以后一定要注意哟。</p><p>此后，该指标在图像领域被广泛用于评测图像的信噪比，最常用的就是<b>峰值信噪比PSNR (Peak Signal to NoiseRatio)</b>，它是原图像与处理图像之间均方误差(Mean Square Error)相对于(2^n-1)^2 的对数值，其中n是每个采样值的比特数，8位图像即为256。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-922c1e92e36524d7ebc2c0af8a5e4fa1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"404\" data-rawheight=\"118\" class=\"content_image\" width=\"404\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;404&#39; height=&#39;118&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"404\" data-rawheight=\"118\" class=\"content_image lazy\" width=\"404\" data-actualsrc=\"https://pic2.zhimg.com/v2-922c1e92e36524d7ebc2c0af8a5e4fa1_b.jpg\"/></figure><p>PSNR越大表示失真越小，下面展示了JPEG和JPEG2000算法在不同压缩率下的PSNR，通常PSNR大于35的图像质量会比较好。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4c0c329476f021be6534777e77bf133d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"565\" data-rawheight=\"424\" class=\"origin_image zh-lightbox-thumb\" width=\"565\" data-original=\"https://pic2.zhimg.com/v2-4c0c329476f021be6534777e77bf133d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;565&#39; height=&#39;424&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"565\" data-rawheight=\"424\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"565\" data-original=\"https://pic2.zhimg.com/v2-4c0c329476f021be6534777e77bf133d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4c0c329476f021be6534777e77bf133d_b.jpg\"/></figure><p>看出来了吧，极限就是50dB左右。</p><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a> </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a></p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a></p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "数字信号处理", 
                    "tagLink": "https://api.zhihu.com/topics/19620019"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62533623", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 20, 
            "title": "【AI-1000问】softmax loss和交叉熵有什么关系？", 
            "content": "<p>想必大家也都听过熵这个概念，也都知道softmax以及softmax loss这个概念，那么它们两个有什么区别和联系呢?</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1101242290173063168\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"softmax loss和交叉熵有什么关系\" data-poster=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1101242290173063168\"><img class=\"thumbnail\" src=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">softmax loss和交叉熵有什么关系<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1101242290173063168</span></span></a><p>softmax loss是由softmax和交叉熵(cross-entropy loss)组合而成，全称是softmax with cross-entropy loss，所以我们可以想见，它们是不同的，但是又有关系。</p><p>解答1：首先我们得知道什么是交叉熵。</p><p>在物理学有一个概念，就是<b>熵</b>，它表示一个热力学系统的无序程度。为了解决对信息的量化度量问题，香农在1948年提出了“信息熵”的概念，它使用对数函数表示对不确定性的测量。熵越高，表示能传输的信息越多，熵越少，表示传输的信息越少，我们可以直接将熵理解为信息量。</p><p>按照香农的理论，熵背后的原理是任何信息都存在冗余，并且冗余大小与信息中每个符号（数字、字母或单词）的出现概率或者说不确定性有关。概率大，出现机会多，则不确定性小，这个关系就用对数函数来表征。</p><p>为什么选择对数函数而不是其他函数呢？首先，不确定性必须是概率P的单调递降函数，假设一个系统中各个离散事件互不相关，要求其总的不确定性等于各自不确定性之和，对数函数是满足这个要求的。将不确定性f定义为log(1/p)=-log(p)，其中p是概率。</p><p>对于单个的信息源，信源的平均不确定性就是单个符号不确定性-logpi的统计平均值，信息熵的定义如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-294e6fc420675d657297682c14f12511_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"264\" data-rawheight=\"78\" class=\"content_image\" width=\"264\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;264&#39; height=&#39;78&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"264\" data-rawheight=\"78\" class=\"content_image lazy\" width=\"264\" data-actualsrc=\"https://pic2.zhimg.com/v2-294e6fc420675d657297682c14f12511_b.jpg\"/></figure><p>假设有两个概率分布p(x)和q(x)，其中p是已知的分布，q是未知的分布，则其交叉熵函数是两个分布的互信息，可以反应其相关程度。</p><p>从这里，就引出了分类任务中最常用的loss，即<b>log loss，又名交叉熵loss</b>，后面我们统一称为交叉熵loss，它的定义形式如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6cda16781b2172b61470b6599690d0f5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"72\" class=\"origin_image zh-lightbox-thumb\" width=\"480\" data-original=\"https://pic2.zhimg.com/v2-6cda16781b2172b61470b6599690d0f5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;480&#39; height=&#39;72&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"72\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"480\" data-original=\"https://pic2.zhimg.com/v2-6cda16781b2172b61470b6599690d0f5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6cda16781b2172b61470b6599690d0f5_b.jpg\"/></figure><p>n对应于样本数量，m是类别数量，yij 表示第i个样本属于分类j的标签，它是0或者1。对于单分类任务，只有一个分类的标签非零。f(xij) 表示的是样本i预测为j分类的概率。loss的大小，完全取决于分类为正确标签那一类的概率，当所有的样本都分类正确时，loss=0，否则大于0。</p><p>解答2：假如log loss中的f(xij)的表现形式是softmax概率的形式，那么交叉熵loss就是我们熟知的softmax with cross-entropy loss，简称softmax loss，所以说softmax loss只是交叉熵的一个特例。</p><p>softmax loss被广泛用于分类分割等任务，而且发展出了很多的变种，大家可以看往期文章回顾。</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649028860%26idx%3D1%26sn%3Dec1056fce8a00d14ad43cc0ac9c39b84%26chksm%3D87134681b064cf9742cd52dc5e68d585ac143fc237393e14d892c40d559621a682e467416312%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-e50dcceb9ac4324c1ccd59fe55af7f13_180x120.jpg\" data-image-width=\"488\" data-image-height=\"404\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】一文道尽softmax loss及其变种</a><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a> </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a></p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a></p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "熵", 
                    "tagLink": "https://api.zhihu.com/topics/19555892"
                }, 
                {
                    "tag": "概率论", 
                    "tagLink": "https://api.zhihu.com/topics/19670916"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62533308", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 4, 
            "title": "【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？", 
            "content": "<p>我们都知道在2014年ILSVRC 比赛中GoogLeNet获得了冠军，其所用模型参数不足AlexNet（2012年冠军）的1/12，但性能却比AlexNet好不少。我们从其论文题目《Going deeper with convolutions》中的deeper也能明白它的贡献，deeper有两层含义，一是指其引入了一种新的结构“Inception module”，二就是其直接含义——网络深度（depth）的增加。今天聊聊GoogLeNet为什么也被称为InceptionNet?</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1101241697459089408\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"InceptionNet是什么意思？\" data-poster=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1101241697459089408\"><img class=\"thumbnail\" src=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">InceptionNet是什么意思？<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1101241697459089408</span></span></a><p>大家还记得多年前，那一部超级烧脑的电影《inception》吗？如果这个名字不熟悉，那么《盗梦空间》你应该还记得吧！</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c4dadcca497f873f2d51be7093fd30cd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"599\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c4dadcca497f873f2d51be7093fd30cd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;599&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"599\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c4dadcca497f873f2d51be7093fd30cd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c4dadcca497f873f2d51be7093fd30cd_b.jpg\"/></figure><p>Dom Cobb(由莱昂纳多·迪卡普里奥饰演)与Robert Fischer(由Cillian Murphy饰演)对话时的那一句：<b>“We need to go deeper”</b>，可谓是引发高潮。讲述的就是如何在某人心中植入思想，寓意进行更深刻的感知。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e4938f139cd4cc2cfbdb6c1869b5503d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"249\" class=\"origin_image zh-lightbox-thumb\" width=\"474\" data-original=\"https://pic2.zhimg.com/v2-e4938f139cd4cc2cfbdb6c1869b5503d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;474&#39; height=&#39;249&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"249\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"474\" data-original=\"https://pic2.zhimg.com/v2-e4938f139cd4cc2cfbdb6c1869b5503d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e4938f139cd4cc2cfbdb6c1869b5503d_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>我们知道AlexNet、VGG等结构都是通过增大网络的深度（层数）来获得更好的训练效果，所以早期设计网络的时候，自然也是走这样的路线，从LeNet的7层，到AlexNet的8层，VGG的16层，19层。不过层数的增加也会带来很多负作用，比如overfit、梯度消失、梯度爆炸等。</p><p>GoogLeNet是2014年的分类比赛冠军，网络达到了22层，参数量为5M，<b>核心就是Inception模块，名字的来源主要便是上面的“inception”， 寓意一个比以前的网络都更深的网络</b>，当然这实际上还是一个多尺度，“更宽”的网络设计，结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d84084278ddb35d2d3bdf3711b85f6d8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"307\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d84084278ddb35d2d3bdf3711b85f6d8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;307&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"307\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d84084278ddb35d2d3bdf3711b85f6d8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d84084278ddb35d2d3bdf3711b85f6d8_b.jpg\"/></figure><p>因此我们也把GoogLeNet称做InceptionNet，毕竟GoogLet是第一个提出InceptionNet的。</p><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a> </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a></p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a></p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p><p></p>", 
            "topic": [
                {
                    "tag": "谷歌 (Google)", 
                    "tagLink": "https://api.zhihu.com/topics/19565870"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "macr", 
                    "userLink": "https://www.zhihu.com/people/d0dff24fc2c4f67f02c2f5b6a44ef5e1", 
                    "content": "<p>工地英语</p><a class=\"comment_sticker\" href=\"https://pic3.zhimg.com/v2-6eeb544aa5ce6be1e6a6add75e436746.gif\" data-width=\"\" data-height=\"\">[哈哈]</a>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62532501", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 13, 
            "title": "【AI-1000问】人脸的4个方向，你还分的清楚吗？", 
            "content": "<p>Face detection、alignment、verification、identification(recognization)，你能分的清楚吗？</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1101239608653791232\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"人脸的4个方向，你还分的清楚吗\" data-poster=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1101239608653791232\"><img class=\"thumbnail\" src=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">人脸的4个方向，你还分的清楚吗<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1101239608653791232</span></span></a><h2><b>1、Face detection</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0ba191d30166d4d382d3054731c1b32f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"850\" data-rawheight=\"455\" class=\"origin_image zh-lightbox-thumb\" width=\"850\" data-original=\"https://pic4.zhimg.com/v2-0ba191d30166d4d382d3054731c1b32f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;850&#39; height=&#39;455&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"850\" data-rawheight=\"455\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"850\" data-original=\"https://pic4.zhimg.com/v2-0ba191d30166d4d382d3054731c1b32f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0ba191d30166d4d382d3054731c1b32f_b.jpg\"/></figure><p>Face detection，人脸检测或者说人脸定位，其对图像中的人脸进行检测，并将结果用矩形框框出来。</p><h2><b>2、Face alignment</b></h2><p>Face alignment，人脸较准或者说人脸关键点检测。人脸关键点检测是人脸识别的重要环节，其是在人脸图像中检测出人脸器官或者外轮廓的位置，这些特征点位置主要是诸如鼻子左侧，鼻孔下侧，瞳孔位置，上嘴唇下侧等等位置，其为人脸识别等技术提供最重要的位置信息。人脸关键点的效率和准确率影响整个人脸识别系统的时效与准确性。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f73584601e3f89e35c5744869f0eade2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"344\" data-rawheight=\"261\" class=\"content_image\" width=\"344\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;344&#39; height=&#39;261&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"344\" data-rawheight=\"261\" class=\"content_image lazy\" width=\"344\" data-actualsrc=\"https://pic3.zhimg.com/v2-f73584601e3f89e35c5744869f0eade2_b.jpg\"/></figure><p>上图中红色框框就是在做Face detection，白色点点就是在做Face alignment。</p><h2><b>3、Face verification</b></h2><p>Face verification，人脸校验。其是基于pair matching的方式，所以它得到的答案是“是”或者“不是”。在具体操作的时候，给定一张测试图片，然后挨个进行pair matching，matching上了则说明测试图像与该张匹配上的人脸为同一个人的人脸。现在的大多数人脸人脸刷脸打卡系统中采用的（应该）是这种方法。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6ce8f0e13d10bd93a82a558ea4bb9b22_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"541\" data-rawheight=\"271\" class=\"origin_image zh-lightbox-thumb\" width=\"541\" data-original=\"https://pic3.zhimg.com/v2-6ce8f0e13d10bd93a82a558ea4bb9b22_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;541&#39; height=&#39;271&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"541\" data-rawheight=\"271\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"541\" data-original=\"https://pic3.zhimg.com/v2-6ce8f0e13d10bd93a82a558ea4bb9b22_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-6ce8f0e13d10bd93a82a558ea4bb9b22_b.jpg\"/></figure><h2><b>4、Face identification(recognization)</b></h2><p>Face identification(recognization)，人脸识别。如下图所示的，它要回答的是“我是谁？”。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-1c568619f30e2f616b224a7012c22f57_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"577\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb\" width=\"577\" data-original=\"https://pic4.zhimg.com/v2-1c568619f30e2f616b224a7012c22f57_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;577&#39; height=&#39;326&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"577\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"577\" data-original=\"https://pic4.zhimg.com/v2-1c568619f30e2f616b224a7012c22f57_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-1c568619f30e2f616b224a7012c22f57_b.jpg\"/></figure><p>相比于人脸校验采用的pair matching，它在识别阶段更多的是采用分类的手段。它实际上是对进行了前面两步即人脸检测、人脸校正后做的图像（人脸）分类。即人脸识别包括下面三个模块：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a7ca2bc53eb72de161e6e82edbc70dc0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"566\" data-rawheight=\"87\" class=\"origin_image zh-lightbox-thumb\" width=\"566\" data-original=\"https://pic1.zhimg.com/v2-a7ca2bc53eb72de161e6e82edbc70dc0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;566&#39; height=&#39;87&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"566\" data-rawheight=\"87\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"566\" data-original=\"https://pic1.zhimg.com/v2-a7ca2bc53eb72de161e6e82edbc70dc0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a7ca2bc53eb72de161e6e82edbc70dc0_b.jpg\"/></figure><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a> </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a></p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a></p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "人脸识别", 
                    "tagLink": "https://api.zhihu.com/topics/19559196"
                }, 
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "数据驱动下的dl", 
                    "userLink": "https://www.zhihu.com/people/514ff29f58cd0482a2bdb6c0848d805f", 
                    "content": "为什么要进行alignment", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "降低问题难度", 
                            "likes": 0, 
                            "replyToAuthor": "数据驱动下的dl"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62531068", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 9, 
            "title": "【AI-1000问】机器学习和模式识别是什么关系？", 
            "content": "<p>现在说起人工智能，聊起AI，每个人或多或少都能说出一点，从历史到未来，从图灵到冯诺依曼，从SVM到CNN等等，但是如果问你是否知道机器学习和模式识别有什么区别？我相信大多数人很懵圈，这两个东西不是一样的吗？难道还有区别！</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1101236013619322880\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"机器学习和模式识别是什么关系？\" data-poster=\"https://pic3.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1101236013619322880\"><img class=\"thumbnail\" src=\"https://pic3.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">机器学习和模式识别是什么关系？<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1101236013619322880</span></span></a><p><b>模式识别</b>就是把对象根据专家设计好的特征进行模式的<b>区分</b>和<b>认识</b>，英文单词re-cognition就是<b>再认识</b>的意思。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-241a19f8de4bd61124f92482c509db13_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1716\" data-rawheight=\"306\" class=\"origin_image zh-lightbox-thumb\" width=\"1716\" data-original=\"https://pic4.zhimg.com/v2-241a19f8de4bd61124f92482c509db13_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1716&#39; height=&#39;306&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1716\" data-rawheight=\"306\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1716\" data-original=\"https://pic4.zhimg.com/v2-241a19f8de4bd61124f92482c509db13_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-241a19f8de4bd61124f92482c509db13_b.jpg\"/></figure><p>机器学习，重点在于是无监督的<b>从数据中学习知识</b>，训练模型的过程就是学习的过程，不需要<b>专家刻意设计特征。早期的机器学习虽然也会设计一些特征，但是专家并不知道哪个特征有用，而是一股脑设计了很多的特征，最后供机器学习算法学习权重进行挑选。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bf84051ac7887fcdb0602ddf3b571930_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1346\" data-rawheight=\"364\" class=\"origin_image zh-lightbox-thumb\" width=\"1346\" data-original=\"https://pic1.zhimg.com/v2-bf84051ac7887fcdb0602ddf3b571930_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1346&#39; height=&#39;364&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1346\" data-rawheight=\"364\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1346\" data-original=\"https://pic1.zhimg.com/v2-bf84051ac7887fcdb0602ddf3b571930_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-bf84051ac7887fcdb0602ddf3b571930_b.jpg\"/></figure><p>可以看出，模式识别重点是根据已有的刻画好的明确特征，通过训练达到判别目的；机器学习侧重于在特征不明确的情况下，通过学习来确定模型。<b>当然，现在已经不需要去刻意区分它们，模式识别多是一个工业界的概念，机器学习则流行于学术界，经典书籍Pattern Recognition and Machine Learning则不区分它们，</b>模式识别可认为是早期的机器学习。</p><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a> </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a></p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a></p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "模式识别", 
                    "tagLink": "https://api.zhihu.com/topics/19564812"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62530628", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 13, 
            "title": "【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？", 
            "content": "<p>做图像处理的我们应该都知道，OpenCV是我们必备的一个工具，我们在使用OpenCV读取图像时你应该也发现了读取出来的数组居然是BGR格式，而不是我们听的最多，用的最多的RGB格式，这是为什么呢？有同学思考过这个问题吗？</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1101234746062954496\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"为什么OpenCV存储图像格式是BGR\" data-poster=\"https://pic3.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1101234746062954496\"><img class=\"thumbnail\" src=\"https://pic3.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">为什么OpenCV存储图像格式是BGR<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1101234746062954496</span></span></a><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-63e54cd82c91dd62024f12ffe46f09de_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1790\" data-rawheight=\"850\" class=\"origin_image zh-lightbox-thumb\" width=\"1790\" data-original=\"https://pic3.zhimg.com/v2-63e54cd82c91dd62024f12ffe46f09de_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1790&#39; height=&#39;850&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1790\" data-rawheight=\"850\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1790\" data-original=\"https://pic3.zhimg.com/v2-63e54cd82c91dd62024f12ffe46f09de_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-63e54cd82c91dd62024f12ffe46f09de_b.jpg\"/></figure><p>解答：OpenCV在1999年由Intel建立，当时主流的摄像头制造商和软件供应商提供的摄像头采集的图像的通道排列顺序为BGR，另外对于图片，位图BMP是最简单的，也是Windows显示图片的基本格式，其文件扩展名为*.BMP。在Windows下，任何格式的图片文件（包括视频播放）都要转化为位图才能显示出来，各种格式的图片文件也都是在位图格式的基础上采用不同的压缩算法生成的，值得注意的是位图BMP的格式就是BGR。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-05e32f08600936617b3cd0eeaaadfe00_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"996\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb\" width=\"996\" data-original=\"https://pic1.zhimg.com/v2-05e32f08600936617b3cd0eeaaadfe00_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;996&#39; height=&#39;110&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"996\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"996\" data-original=\"https://pic1.zhimg.com/v2-05e32f08600936617b3cd0eeaaadfe00_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-05e32f08600936617b3cd0eeaaadfe00_b.png\"/></figure><p>正是基于BGR在当时被广泛使用，于是早期OpenCV开发者就选择BGR颜色格式，这也就成为了一种规范一直用到现在。</p><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a> </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a></p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a></p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p><p></p>", 
            "topic": [
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }, 
                {
                    "tag": "OpenCV", 
                    "tagLink": "https://api.zhihu.com/topics/19587715"
                }, 
                {
                    "tag": "图像处理", 
                    "tagLink": "https://api.zhihu.com/topics/19556376"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/61151678", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 17, 
            "title": "【杂谈】想成为机器学习学霸？先学会做笔记吧(Evernote,BoostNote,Leanote等)", 
            "content": "<p>今天聊聊记笔记这件事儿，在学习的过程中做好总结记录是非常重要的。</p><p>作者 | 小满&amp;有三</p><p>编辑 | 小满&amp;有三</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c1beac9b8246ebb70f1365db420cb1a8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"960\" data-rawheight=\"487\" class=\"origin_image zh-lightbox-thumb\" width=\"960\" data-original=\"https://pic1.zhimg.com/v2-c1beac9b8246ebb70f1365db420cb1a8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;960&#39; height=&#39;487&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"960\" data-rawheight=\"487\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"960\" data-original=\"https://pic1.zhimg.com/v2-c1beac9b8246ebb70f1365db420cb1a8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c1beac9b8246ebb70f1365db420cb1a8_b.jpg\"/></figure><p>《人类简史》有一个有趣的现象描写：远古时期的智人是看什么就吃什么，会塞到自己吃不下为止。比如看到一颗果树，盘它，为嘛？因为你不最努力地吃，等下猩猩猴子们来了，就啥都不剩了。</p><p>如今深处互联网时代，你还是胡吃海塞式的么？咦，这个代码好厉害？这个书单好优秀？这个保存，保存，保存。。先不管啦，也许后面用得到呢？ </p><p>一方面我们面对的是信息的爆炸，另一方面是我们的基因还在驱使我们无节制的搜集。</p><p>那么，今天要聊的是作为程序员，<b>有哪些笔记工具可以提高工作效率呢？</b></p><h2><b>1 工具选择，有哪些标准</b></h2><p>如果Google是图书馆，那你会用什么来搭建你的个人书架？</p><p>古人云：工欲善其事，必先利其器</p><p>古人还云：没有标准，不成方圆</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-1fa5f72f0d6f3d0d0004f56268f4462d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"960\" data-rawheight=\"355\" class=\"origin_image zh-lightbox-thumb\" width=\"960\" data-original=\"https://pic2.zhimg.com/v2-1fa5f72f0d6f3d0d0004f56268f4462d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;960&#39; height=&#39;355&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"960\" data-rawheight=\"355\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"960\" data-original=\"https://pic2.zhimg.com/v2-1fa5f72f0d6f3d0d0004f56268f4462d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-1fa5f72f0d6f3d0d0004f56268f4462d_b.jpg\"/></figure><p>话不多说，上标准。以下我总结了身边学编程的小哥哥们和小姐姐们对云笔记app的几类需求：</p><p><b>(1). 代码可编辑且高亮</b>：这是最基本的学编程需要嘛，经常会复制代码到笔记中，如果保存的代码能够将IDE中的代码颜色也复制到笔记中，代码的“可读性”更好些。</p><p><b>(2). 跨平台使用且同步</b>：程序猿都有好几个机器，笔记本，台式机，ipad，手机，需要保持平台一致。</p><p><b>(3). markdown功能</b>：敲打在键盘上，就可分级标题，打造最美观的文章。</p><p><b>(4). 导出格式多样</b>：Word，pdf等格式，比如面试时可以直接整理打印成册。</p><p><b>(5). 成本</b>：能花最少的钱是最好不过的啦。</p><p>(6). 其他特别之处：譬如强大的搜索引擎功能，处女座小伙伴对UI的设计，等等。</p><p>一起来看看哪款笔记app最适合你吧！</p><h2><b>2 Evernote</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-34c184fe08c8698227cc706bd931975c_b.jpg\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"500\" class=\"origin_image zh-lightbox-thumb\" width=\"1024\" data-original=\"https://pic1.zhimg.com/v2-34c184fe08c8698227cc706bd931975c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1024&#39; height=&#39;500&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"500\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1024\" data-original=\"https://pic1.zhimg.com/v2-34c184fe08c8698227cc706bd931975c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-34c184fe08c8698227cc706bd931975c_b.jpg\"/><figcaption>(适用OS:Windows, Mac, Android, iOS, Web)官网：https://www.yinxiang.com/</figcaption></figure><p>印象笔记是一款拥有全球2亿用户的创新软件，作为2013年苹果设计大奖得主的app，是很多平凡人逆袭为牛人的必备神器。</p><p>目前分企业版和个人版，个人版中也分三个等级，享受不同的特权，价格与功能如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e0ae6016e714ed12884121528e64ec50_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"845\" data-rawheight=\"570\" class=\"origin_image zh-lightbox-thumb\" width=\"845\" data-original=\"https://pic1.zhimg.com/v2-e0ae6016e714ed12884121528e64ec50_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;845&#39; height=&#39;570&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"845\" data-rawheight=\"570\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"845\" data-original=\"https://pic1.zhimg.com/v2-e0ae6016e714ed12884121528e64ec50_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e0ae6016e714ed12884121528e64ec50_b.jpg\"/></figure><p>一起来了解下它有哪些爽歪歪的功能？</p><p><b>1. 支持所有设备，且自动同步，</b>支持多软件推送(微信、微博、知乎等等大部分主流媒体)，<b>一键剪藏功能</b>，收集来自PC端网页、手机端、微信公众号的信息，强大~</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-00c7e6f75bd0594e61b3bbe44e4e3b5e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"908\" class=\"origin_image zh-lightbox-thumb\" width=\"1024\" data-original=\"https://pic3.zhimg.com/v2-00c7e6f75bd0594e61b3bbe44e4e3b5e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1024&#39; height=&#39;908&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"908\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1024\" data-original=\"https://pic3.zhimg.com/v2-00c7e6f75bd0594e61b3bbe44e4e3b5e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-00c7e6f75bd0594e61b3bbe44e4e3b5e_b.jpg\"/></figure><p>2. 快速编辑，应有尽有，添加了<b>markdown功能</b>，可支持插入代码块，不过插入的代码不好看，不方便阅读，如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-3876629def0a2e1ef1fff8aa5abf207d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"257\" data-rawheight=\"173\" class=\"content_image\" width=\"257\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;257&#39; height=&#39;173&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"257\" data-rawheight=\"173\" class=\"content_image lazy\" width=\"257\" data-actualsrc=\"https://pic2.zhimg.com/v2-3876629def0a2e1ef1fff8aa5abf207d_b.jpg\"/></figure><p>大象在代码整理这块有点弱，不支持语法高亮，毕竟不是专业的代码编辑器。不过办法总是要解决的嘛，可以使用nodepad++插件(<a href=\"https://link.zhihu.com/?target=http%3A//www.notepad-plus-plus.org/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">notepad-plus-plus.org/</span><span class=\"invisible\"></span></a>)，先把代码复制到nodepad++上，然后通过如下图操作，复制到印象笔记中。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-17b655e5cd183ac2fb025cad97dcb35f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"676\" data-rawheight=\"280\" class=\"origin_image zh-lightbox-thumb\" width=\"676\" data-original=\"https://pic4.zhimg.com/v2-17b655e5cd183ac2fb025cad97dcb35f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;676&#39; height=&#39;280&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"676\" data-rawheight=\"280\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"676\" data-original=\"https://pic4.zhimg.com/v2-17b655e5cd183ac2fb025cad97dcb35f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-17b655e5cd183ac2fb025cad97dcb35f_b.jpg\"/></figure><p>效果图如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a893e06aea850cde59427c3264947de4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"835\" data-rawheight=\"456\" class=\"origin_image zh-lightbox-thumb\" width=\"835\" data-original=\"https://pic1.zhimg.com/v2-a893e06aea850cde59427c3264947de4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;835&#39; height=&#39;456&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"835\" data-rawheight=\"456\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"835\" data-original=\"https://pic1.zhimg.com/v2-a893e06aea850cde59427c3264947de4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a893e06aea850cde59427c3264947de4_b.jpg\"/></figure><p>3. <b>层级结构</b>：以<b>树形结构</b>来显示笔记本，以列表结构显示笔记，但树结构只有两级。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bb8a2b823f0bbf8ab103ad34a6e94174_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"885\" data-rawheight=\"571\" class=\"origin_image zh-lightbox-thumb\" width=\"885\" data-original=\"https://pic1.zhimg.com/v2-bb8a2b823f0bbf8ab103ad34a6e94174_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;885&#39; height=&#39;571&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"885\" data-rawheight=\"571\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"885\" data-original=\"https://pic1.zhimg.com/v2-bb8a2b823f0bbf8ab103ad34a6e94174_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-bb8a2b823f0bbf8ab103ad34a6e94174_b.jpg\"/></figure><p>4. 可导出格式有<b>html，pdf，mht，enenx</b>(印象笔记版本)，暂不支持word。</p><p>5. <b>强大的搜索功能</b>，输入搜索的关键字之后，你可以选择笔记本组、标签、来源、创建更新时间等来缩小范围，而以下的搜索方式能让你更快更准确地完成搜索。戳下面视频，可了解搜索方法。</p><p>其他功能还包括标签与待办事项，共享笔记，团队协作等不再一一讲述。</p><p>竞品：有道笔记，为知笔记（WizNote）</p><h2><b>3 OneNote</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a797dad582ed5b5a836dd664493dc6f4_b.jpg\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"200\" class=\"content_image\" width=\"400\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;400&#39; height=&#39;200&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"200\" class=\"content_image lazy\" width=\"400\" data-actualsrc=\"https://pic1.zhimg.com/v2-a797dad582ed5b5a836dd664493dc6f4_b.jpg\"/><figcaption>(适用OS:Windows, Mac, Android, iOS, Web)官网：http://www.onenote.com/</figcaption></figure><p>来自于Microsoft office家族，大厂出品，有稳定且持续的支持，微软不死，OneNote不落。已经迫不及待分享它的强大！</p><p>1. <b>跨平台且可同步</b>：OneNote最常用于笔记本电脑或台式电脑，更适合用于支持手写笔操作的ipad，可实现同步，不过OneNote在国内同步体验很不好，经常七八天同步不了。</p><p>可保存微信文稿，与印象笔记相比，网页剪藏功能不佳。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-cf68c2166700aff812f1f88210841ca8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1920\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-cf68c2166700aff812f1f88210841ca8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1920&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1920\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-cf68c2166700aff812f1f88210841ca8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-cf68c2166700aff812f1f88210841ca8_b.jpg\"/></figure><p>2. 想要OneNote<b>代码高亮</b>，可以使用<b>NoteHighlight插件</b>，免费开源项目，支持2010版本，2013为Beta版，2016为网友改进版。可以覆盖的语言如下（同款优秀的插件还有：数字笔记珍宝 OneNote Gem）：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d5c9ebd7124c06ee97661e24b8bb1c17_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"536\" data-rawheight=\"109\" class=\"origin_image zh-lightbox-thumb\" width=\"536\" data-original=\"https://pic4.zhimg.com/v2-d5c9ebd7124c06ee97661e24b8bb1c17_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;536&#39; height=&#39;109&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"536\" data-rawheight=\"109\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"536\" data-original=\"https://pic4.zhimg.com/v2-d5c9ebd7124c06ee97661e24b8bb1c17_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-d5c9ebd7124c06ee97661e24b8bb1c17_b.jpg\"/></figure><p>3. OneNote目前版本，最大的问题是<b>原生不支持MarkDown</b>，可使用插件类似于Dropbox。</p><p>4. 舒服的树状结构，有3个层级：笔记本 -&gt; 分区 -&gt; 页面，适合建立自己的个人知识体系。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-307178071def3fdb25ac615825e7b28c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"956\" data-rawheight=\"575\" class=\"origin_image zh-lightbox-thumb\" width=\"956\" data-original=\"https://pic1.zhimg.com/v2-307178071def3fdb25ac615825e7b28c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;956&#39; height=&#39;575&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"956\" data-rawheight=\"575\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"956\" data-original=\"https://pic1.zhimg.com/v2-307178071def3fdb25ac615825e7b28c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-307178071def3fdb25ac615825e7b28c_b.jpg\"/></figure><p>5. <b>导出格式多样：</b>one，pdf，xps，word，mht 。</p><p>6. <b>随意布局</b>：随心所欲的自由布局不拘格式，自由自在，因为有容器的存在，存在页面上任何地方都可以打字，特别有笔记的感觉。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e7771dba7a24a85e30dafa774ae16e64_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"428\" data-rawheight=\"221\" class=\"origin_image zh-lightbox-thumb\" width=\"428\" data-original=\"https://pic1.zhimg.com/v2-e7771dba7a24a85e30dafa774ae16e64_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;428&#39; height=&#39;221&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"428\" data-rawheight=\"221\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"428\" data-original=\"https://pic1.zhimg.com/v2-e7771dba7a24a85e30dafa774ae16e64_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e7771dba7a24a85e30dafa774ae16e64_b.jpg\"/></figure><p>7. <b>表格排版</b>：做笔记时候经常希望，<b>左边配图，右边注释，</b>例如下图中，要实现三列内容，可插入一个1x3的表格，在每一格填入你的内容。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-07f2e8f04fb9049030d2e186a44ee38d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"315\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https://pic2.zhimg.com/v2-07f2e8f04fb9049030d2e186a44ee38d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;720&#39; height=&#39;315&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"315\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"720\" data-original=\"https://pic2.zhimg.com/v2-07f2e8f04fb9049030d2e186a44ee38d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-07f2e8f04fb9049030d2e186a44ee38d_b.jpg\"/></figure><p><b>8. 云备份，及时保存</b>：个人太喜欢这个功能了，OneNote没有“保存”按钮，因为它随时都在保存，免除了不习惯ctrl+s一键保存之苦。</p><p>9. <b>图片转文字</b>，图片转文字，图片转文字！重要的还想再说一遍，图片转文字！当我们在百度文库上看到一篇文章，却苦于没有积分下载不了的时候；当我们在看PDF，却发现里面的文字复制不下来的时候——难道只能苦逼地码字？NO！将页面截图，粘贴在Onenote上，图片上右键，选择【可选文字】。于是，文字就被识别了！</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c14a3625e76cb0b75a236a0dc3bc72f4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1048\" data-rawheight=\"384\" class=\"origin_image zh-lightbox-thumb\" width=\"1048\" data-original=\"https://pic1.zhimg.com/v2-c14a3625e76cb0b75a236a0dc3bc72f4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1048&#39; height=&#39;384&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1048\" data-rawheight=\"384\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1048\" data-original=\"https://pic1.zhimg.com/v2-c14a3625e76cb0b75a236a0dc3bc72f4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c14a3625e76cb0b75a236a0dc3bc72f4_b.jpg\"/></figure><p>注意：OneNote还有一个让人很无语的“特色”：Office中带一个OneNote，Windows 操作系统中也有一个。这两个看上去很相似，但用起来有点不一样，Office中的那个功能更强。</p><h2><b>4 BoostNote</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-41400d55be7109d9d2fd0620a9d8cfe6_b.jpg\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"415\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-41400d55be7109d9d2fd0620a9d8cfe6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;415&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"415\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-41400d55be7109d9d2fd0620a9d8cfe6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-41400d55be7109d9d2fd0620a9d8cfe6_b.jpg\"/><figcaption>(适用OS: Windows, Mac, Linux ，iOS ，Android )官网：https://boostnote.io</figcaption></figure><p>BoostNote是为编码器设计的笔记应用典范，一款专门为程序员朋友量身打造的笔记软件，可离线执行。尽管不具备商业笔记app的所有功能，但他具备了一些程序员喜欢的功能：</p><p>1. BoostNote最大的用处就是帮你<b>记录无数的代码资源</b>，你甚至可以创建一个独立的项目。软件支持收藏、标签、分组、搜索、栏目切换等笔记应用应有的功能。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e0c7dd845345412ec96b287cd705dd1b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"675\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-e0c7dd845345412ec96b287cd705dd1b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;675&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"675\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-e0c7dd845345412ec96b287cd705dd1b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e0c7dd845345412ec96b287cd705dd1b_b.jpg\"/></figure><p>2. BoostNote是<b>全平台支持</b>的，但本身并不支持云同步功能，可以配合坚果云、Dropbox 使用，方便地同步你的笔记。</p><p>3. BoostNote提供了完整的Markdown支持，笔记可以以Markdown或是代码片段式导入，同时语法突出显示。</p><p>4. 结构使用三栏视图，支持分组存储笔记，让你的知识更加有条理。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a08e692f5cf9a481d26c6196df860e55_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1002\" data-rawheight=\"630\" data-thumbnail=\"https://pic2.zhimg.com/v2-a08e692f5cf9a481d26c6196df860e55_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1002\" data-original=\"https://pic2.zhimg.com/v2-a08e692f5cf9a481d26c6196df860e55_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1002&#39; height=&#39;630&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1002\" data-rawheight=\"630\" data-thumbnail=\"https://pic2.zhimg.com/v2-a08e692f5cf9a481d26c6196df860e55_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1002\" data-original=\"https://pic2.zhimg.com/v2-a08e692f5cf9a481d26c6196df860e55_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a08e692f5cf9a481d26c6196df860e55_b.gif\"/></figure><p>5. <b>开源免费</b>：BoostNote的价值同时体现在他的免费和开源。结合其功能，是计算机系学生的理想选择。</p><p>6. <b>支持Latex</b>：如果你是机器学习等热门方向的程序员小哥哥小姐姐的话，笔记一定会涉及很多公式。没错！Boostnote可以让你为所欲为地打公式！</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-be045f45b37448fd9a13d63bd22181eb_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1002\" data-rawheight=\"630\" data-thumbnail=\"https://pic4.zhimg.com/v2-be045f45b37448fd9a13d63bd22181eb_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"1002\" data-original=\"https://pic4.zhimg.com/v2-be045f45b37448fd9a13d63bd22181eb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1002&#39; height=&#39;630&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1002\" data-rawheight=\"630\" data-thumbnail=\"https://pic4.zhimg.com/v2-be045f45b37448fd9a13d63bd22181eb_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1002\" data-original=\"https://pic4.zhimg.com/v2-be045f45b37448fd9a13d63bd22181eb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-be045f45b37448fd9a13d63bd22181eb_b.gif\"/></figure><p>用户在分组下新建笔记时有<b>Markdown和Snippet两种模式</b>可选，Markdown模式下会自动支持各种MD语法以及Latex格式，而Snippet模式则会为用户提供N多种代码书写环境。</p><p>一个秘密：BoostNote提供了一个网页版的Demo，功能与客户端几乎相同，你可以在下载程序前先在网页版体验(<a href=\"https://link.zhihu.com/?target=https%3A//boostnote.io/demo/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">boostnote.io/demo/</span><span class=\"invisible\"></span></a>)。</p><p>竞品：Medley(适用OS: Windows，Mac，Linux)、TextQuiver(适用OS：Mac)</p><h2><b>5 Leanote</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2e15eb301bd30ba1eefd6211aea39b91_b.jpg\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"547\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-2e15eb301bd30ba1eefd6211aea39b91_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;547&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"547\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-2e15eb301bd30ba1eefd6211aea39b91_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2e15eb301bd30ba1eefd6211aea39b91_b.jpg\"/><figcaption>(适用OS:Windows, Mac, Android, iOS)https://leanote.com/index#</figcaption></figure><p>蚂蚁笔记 = 笔记 + 博客 + 协作 + 私有云，是一款有极客范的云笔记，由golang + mongodb开发。</p><p>如果你注重个人隐私的存在，如果你是一个技术控，希望数据能够在自己的掌控之中，不用怕“泄露”，也不用怕服务商突然终止服务或收费，那请选择LeaNote。</p><p>1. <b>代码高亮</b>：必须支持！</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-08583bd30f2354f9a7c8b2809ab3777d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-08583bd30f2354f9a7c8b2809ab3777d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-08583bd30f2354f9a7c8b2809ab3777d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-08583bd30f2354f9a7c8b2809ab3777d_b.jpg\"/></figure><p>2. <b>可跨平台使用，但是不支持网页剪报</b>，浏览网页时遇见干货只能复制粘贴，不能做到右键保存到自己的笔记本，不过复制粘贴时，文字、图片都可以完全转化为本地文件，而不会链接原始地址。</p><p>3. <b>Markdown功能</b>：必须安排！极客的最爱，让双手不离键盘，轻松提升笔记效率，同时支持Vim和Emacs。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-828c032b9c8b4c428a66e7d80e80e4eb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"387\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic4.zhimg.com/v2-828c032b9c8b4c428a66e7d80e80e4eb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;387&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"387\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic4.zhimg.com/v2-828c032b9c8b4c428a66e7d80e80e4eb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-828c032b9c8b4c428a66e7d80e80e4eb_b.jpg\"/></figure><p>4.层级结构清晰：以列表结构显示笔记。</p><p>5.专业数学公式编辑：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-68a42c3e50b4cca2fdf69eda7964961b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"757\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"757\" data-original=\"https://pic4.zhimg.com/v2-68a42c3e50b4cca2fdf69eda7964961b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;757&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"757\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"757\" data-original=\"https://pic4.zhimg.com/v2-68a42c3e50b4cca2fdf69eda7964961b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-68a42c3e50b4cca2fdf69eda7964961b_b.jpg\"/></figure><p>更多的功能，就等待大家自己去发掘吧。</p><h2>总结：</h2><p>每个方法和工具都有它的特点和存在价值，大家可以根据自己的习惯进行选择，选定后就不要离手了。好的笔记工具可以帮助我们提高工作效率，但是最重要的事情<b>还是坚持每天记笔记，经常整理笔记</b>，这样才能更好地成长。</p><blockquote>杂谈系列文章</blockquote><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032488%26idx%3D1%26sn%3Df0b97933c84f815c6f470bcb5616cec9%26chksm%3D8712b955b065304372375651ecaa3f13237dea5c00e9d1668cf0614fccde1223bd75c70f476f%26token%3D1099264503%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】AI工业界都有哪些值得参加的比赛？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032455%26idx%3D1%26sn%3Da1dec40a42f2c29ad5a9556c63a04621%26chksm%3D8712b97ab065306c34006698de90efe12b88ec8575769e38cd00124fad201eef1f1db10d5201%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】扒一扒Reddit，Medium，Quora与知乎等国内外高质量AI社区与内容平台</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032425%26idx%3D1%26sn%3D6f0ee574e5318d32b9c4a42236db2876%26chksm%3D8712b894b06531822430ac39ce5ead315d5e65ece0a182e958dbfbee7364fc60b98a23e5b10a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】天下苦公众号久矣，如何利用这几类公众号进行深度学习？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032059%26idx%3D1%26sn%3D7bd413f3e3af8d77a6ffae91ab451ce0%26chksm%3D8712bb06b06532104e62b9cb5bc3485b8be8f3ef6f5ccfbd9a8d632508632887e53a163babd7%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】GitHub机器学习/深度学习资料大全</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032306%26idx%3D1%26sn%3Dbdaeaebd630f55689b5a5eaf218c27ab%26chksm%3D8712b80fb0653119aff7156cf62b26c29e52874be5233c1c8849434e72bac023bf46dd9415ee%26token%3D169596712%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】深度学习必备，各路免费爬虫一举拿下</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031901%26idx%3D1%26sn%3D2a07245e287372b3d780a9f72273229f%26chksm%3D8712baa0b06533b6629dcd8f40434f449e0b21918d7b4c1881d2c3b4c13ff26995fdd65ba8ae%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】如何学会看arxiv.org才能不错过自己研究领域的最新论文？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032040%26idx%3D1%26sn%3D07df08efed0e7619a13a3ce803df1c02%26chksm%3D8712bb15b0653203dec8c34b716a5f1139b304d094e1e63607c3f05720f8f74786cac06c02cb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】那些酷炫的深度学习网络图怎么画出来的？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032287%26idx%3D1%26sn%3D83b7177bbc02e85da03904b4143fda75%26chksm%3D8712b822b0653134df8592675919822b9e4efc73bff347400f674852f2b41bf1fc1a475a2c1e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】想成为机器学习学霸？先学会做笔记吧</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032197%26idx%3D1%26sn%3D5abb299cc6502c2c5f4ddf015dae8e84%26chksm%3D8712b878b065316ee86073d20adff8ac1afe9ad48d1f1157b3c2a3237e71a530049b3bcde3fd%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】提升写代码效率不得不做的三件事</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032306%26idx%3D1%26sn%3Dbdaeaebd630f55689b5a5eaf218c27ab%26chksm%3D8712b80fb0653119aff7156cf62b26c29e52874be5233c1c8849434e72bac023bf46dd9415ee%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】深度学习必备，各路免费爬虫一举拿下</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031614%26idx%3D1%26sn%3D4384b5ef6a07ffe54b6bc41596929d9c%26chksm%3D8712bdc3b06534d5b986085fc05ad3d7968f149a19036f91c6f97a04b8ce74258dfc710a8e22%26token%3D1099264503%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】学深度学习的你有GPU了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031482%26idx%3D1%26sn%3D13d551c7cf91995dfc187e34732c82f9%26chksm%3D8712bd47b0653451c1f590dd850e2f4fb70217265b3c4d2f1d6c408af5ad6b377e06ee4f9965%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】白身，初识，不惑，有识，不可知，你处于深度学习工程师哪一重境界了</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030710%26idx%3D1%26sn%3D4d4d26d2f4d6c0193cbaf994a7bc5488%26chksm%3D8712be4bb065375d77258f746f7a05e22966fa5856e2f2d2d99e6cce863c3a579a1055f19fbb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】为什么你学了AI，企业却不要你</a></p><p></p><p></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "做笔记", 
                    "tagLink": "https://api.zhihu.com/topics/19809245"
                }, 
                {
                    "tag": "高效学习", 
                    "tagLink": "https://api.zhihu.com/topics/19580586"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "我们爱尾巴", 
                    "userLink": "https://www.zhihu.com/people/30a8a76189ff6395ceb4b3281b5cc52a", 
                    "content": "这些都很好，我还是选择org-mode，😂", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<a class=\"comment_sticker\" href=\"https://pic3.zhimg.com/v2-6eeb544aa5ce6be1e6a6add75e436746.gif\" data-width=\"\" data-height=\"\">[哈哈]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "我们爱尾巴"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/60546840", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 33, 
            "title": "【AI初识境】给深度学习新手开始项目时的10条建议", 
            "content": "<p>这是专栏《AI初识境》的第12篇文章。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>在成为合格的深度学习算法工程师，尤其是工业界能够实战的调参选手之前，总会踏足很多的坑。</p><p>今天就来说说那些需要掌握的基本技巧，如何避开那些新手常见的坑，以计算机视觉中的图像分类任务为例。</p><p><b>请注意，这篇文章不是教你如何调参，而是教你不要在调参之前胡搞。</b></p><p>                                                                                                                          作者&amp;编辑  | 言有三</p><h2><br/><b>1 项目开发之前应该做什么</b></h2><p><b>在你真正开始撸代码之前，送大家一句话，“磨刀不误砍柴工”。</b></p><p>拿到一个任务的时候，先不要上来就开始训模型，而是做好三件事。</p><p><b>1.1、知道你要做的任务是一个什么任务。</b></p><p>以图像分类为例，猫狗分类是一个分类任务，随便找个什么模型都能完成。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-cab22c883a6255b2e229ac727f54d7ad_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-cab22c883a6255b2e229ac727f54d7ad_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-cab22c883a6255b2e229ac727f54d7ad_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-cab22c883a6255b2e229ac727f54d7ad_b.jpg\"/></figure><p>鸟类分类也是一个分类任务，但是不简单，不是随随便便拿个模型就能搞定。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-69df96246715e9733d398e1392174f79_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"419\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-69df96246715e9733d398e1392174f79_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;419&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"419\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-69df96246715e9733d398e1392174f79_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-69df96246715e9733d398e1392174f79_b.jpg\"/></figure><p>表情识别最终也是一个分类，但是这不仅仅是一个分类问题，而是检测+分类问题。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5936fea7190e080f859bc70a7beea5e4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"550\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5936fea7190e080f859bc70a7beea5e4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;550&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"550\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5936fea7190e080f859bc70a7beea5e4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5936fea7190e080f859bc70a7beea5e4_b.jpg\"/></figure><p>产品经理们只会告诉你要实现什么功能，而不会告诉你用什么方案，对于简单任务来说这可能不需要思考，但是复杂任务一定要先充分调研认识。</p><p>你说上面的这个例子很简单，一眼就明白，那么我再举出几个例子，你是否一下子就能明白背后的核心技术？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d50425c20dc25c5717a779a24423740a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"982\" data-rawheight=\"424\" class=\"origin_image zh-lightbox-thumb\" width=\"982\" data-original=\"https://pic3.zhimg.com/v2-d50425c20dc25c5717a779a24423740a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;982&#39; height=&#39;424&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"982\" data-rawheight=\"424\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"982\" data-original=\"https://pic3.zhimg.com/v2-d50425c20dc25c5717a779a24423740a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d50425c20dc25c5717a779a24423740a_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c7976b7c87a19b605eca04810489a7a2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-c7976b7c87a19b605eca04810489a7a2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;416&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-c7976b7c87a19b605eca04810489a7a2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c7976b7c87a19b605eca04810489a7a2_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f14ebb0d23b8eb6be8e8196239e8e80b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"460\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic4.zhimg.com/v2-f14ebb0d23b8eb6be8e8196239e8e80b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;800&#39; height=&#39;460&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"460\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"800\" data-original=\"https://pic4.zhimg.com/v2-f14ebb0d23b8eb6be8e8196239e8e80b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f14ebb0d23b8eb6be8e8196239e8e80b_b.jpg\"/></figure><p><b>1.2、找到竞争对手，做好预期。</b></p><p>比如你要做一个表情识别API，要做一个美颜算法，一定要先看看你的竞争对手做的怎么样了，就算最后你做出来跟别人还差十万八千里，也不至于到最后一刻才发觉。<b>这叫知人之明和自知之明，一定要先有。</b></p><p>在这个过程中，基本上就能确定要走的路，<b>第一条路是追随模仿别人，第二条路是超越别人</b>，这两者是不一样的。</p><p>前者，只要把已有成熟的资料收集到位，经验足够丰富，必定能成功，否则就是个人能力和资源问题。这样的一条路，相信老大们会给你布置一个明确的时间节点。</p><p>比如表情识别，很成熟，那你做出来也不能比别人差太多。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a315ca7304e3d089890bdfe6543f71f5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https://pic2.zhimg.com/v2-a315ca7304e3d089890bdfe6543f71f5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;720&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"720\" data-original=\"https://pic2.zhimg.com/v2-a315ca7304e3d089890bdfe6543f71f5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a315ca7304e3d089890bdfe6543f71f5_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>如果是第二条路，那么就意味着没有参考者，或者参考者做的也不行。那么最难的是什么，就是预期能做到什么水平。</p><p><b>可能技术已经成熟了，没人做，恭喜你，赶紧搞。</b></p><p><b>可能技术比较前沿，能做技术储备，但是还无法落地。</b></p><p><b>可能根本就还做不了。</b></p><p><b>1.3、想好你需要什么样的数据，从源头上降低任务的难度。</b></p><p>在公司干了四年活，大部分项目都需要自己准备数据，不会有现成的数据可以使用，而如何准备数据，这是需要经验的。</p><p>举个最简单的例子，假如我们需要开发一个分类算法来分析一张图片中的人是不是在笑，图像可能是这样。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-e18b83dce5a4ed99a5a1e9c905f41e06_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-e18b83dce5a4ed99a5a1e9c905f41e06_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;312&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-e18b83dce5a4ed99a5a1e9c905f41e06_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-e18b83dce5a4ed99a5a1e9c905f41e06_b.jpg\"/></figure><p>你会爬取或者从数据集中拿到很多不同表情的数据然后就直接开干吗？显然那是错误的路子。</p><p>开始一个任务后我们首先就应该想怎么降低任务的难度，对于此任务，起作用的只有嘴唇这块区域，那么我们完全可以基于嘴唇区域来训练一个分类模型。</p><p>高精度成熟的人脸检测和关键点检测算法是很多的，所以你可能需要准备的训练数据是这样的。当然，如果你直接基于关键点的结果来做也是可以的，这就回到了第一个问题了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ca5ac475f5f660a6c3b7acff350fd716_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"159\" class=\"origin_image zh-lightbox-thumb\" width=\"514\" data-original=\"https://pic3.zhimg.com/v2-ca5ac475f5f660a6c3b7acff350fd716_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;514&#39; height=&#39;159&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"159\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"514\" data-original=\"https://pic3.zhimg.com/v2-ca5ac475f5f660a6c3b7acff350fd716_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ca5ac475f5f660a6c3b7acff350fd716_b.jpg\"/></figure><p>这样至少有两个好处，(1) 明显这个分类更加简单了。(2) 可以使用更小的输入图完成任务，计算代价也更低。</p><h2><b>2 训练模型从哪里开始</b></h2><p>很少有一个任务可以拿现有的模型使用，你通常是需要训练自己的模型的，那么在训练一个模型的时候，应该怎么样开始。</p><p>这里牵涉到3个问题，框架，基准模型和数据，其中任何一环都有可能有问题。</p><p><b>2.1、首先确定框架</b></p><p>没有一个深度学习任务不需要一个框架来训练，很多的时候你不得不在不同的框架之间进行切换。比如做分类分割或者检测，caffe都很好用。做风格化搞GAN，就得上tensorflow或者pytorch了，你一定要先选择一个工具，不然很可能会陷入找到了很多中github方案，这个试了遇到困难换下一个，下一个又遇到困难。</p><p>有自己最拿手的一个框架，选定项目就坚定地干，遇到了问题就去解决。</p><p>关于框架，大家可以从我们的系列文章中开始快速上手。</p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029896%26idx%3D1%26sn%3Df3f7b9cf69c514f45d1d14205f879270%26chksm%3D87134375b064ca6323354c40f3e55b02ff0d1d24f3dacfc980190d51f20ec9ec16e60c1a4741%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【Keras速成】Keras图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029887%26idx%3D1%26sn%3D645b97809c24922352a0b39f19c9ef0c%26chksm%3D87134282b064cb9441af68124d205d9c7dedcaeb09788f4d586b949584e556eddd3a72217f69%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【paddlepaddle速成】paddlepaddle图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029881%26idx%3D1%26sn%3D3c869fcee3b48d3582952ab9a0683ea6%26chksm%3D87134284b064cb924c5e7231b3f2c36ba27e3a689b067f569f2e086f62b18413bcebc5987a07%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【pytorch速成】Pytorch图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029846%26idx%3D2%26sn%3D7c2582243bcd8f8b491e8e466a21978f%26chksm%3D871342abb064cbbd0cba24b408ceda2b64a7c8b6baa07f9f8f56cd4d1233caa0b80fe357753e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【tensorflow速成】Tensorflow图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029846%26idx%3D1%26sn%3D0c343cfd0ede5c8ae1405bd6348aefad%26chksm%3D871342abb064cbbd7fe31fb3c55f23875f27e48fb8354e9855823b1701f1227c71b4eb00de50%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【caffe速成】caffe图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029904%26idx%3D1%26sn%3D0bdc6947f5ac68e7f68426b9d076b4ab%26chksm%3D8713436db064ca7b3b2a2a1d6a8d24c15069f72655e2c39e2498051fa0e56bbcf6fe9c332d5b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【mxnet速成】mxnet图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030976%26idx%3D1%26sn%3D0befc170a93d365b780c5f05b2f510a4%26chksm%3D8712bf3db065362b0aeaae82bdbac467be5697b34cac2797e2ee15cdcb97474c08640482bf07%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【cntk速成】cntk图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032012%26idx%3D1%26sn%3Df74c7084621f367adb2518ebec61ca42%26chksm%3D8712bb31b06532270b9ca9550ab48ff78adaad7d38c73645cfb8888218b8e177bebd5d401aa9%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【DL4J速成】Deeplearning4j图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031911%26idx%3D2%26sn%3Da95856836c0d8832b9e5fe49704c6313%26chksm%3D8712ba9ab065338c28d86ff10bff58bcda404bfc0efc68f0a9c0ba20a2126d917cc701c6b4ae%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【chainer速成】chainer图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032109%26idx%3D2%26sn%3Da6ff48ec0ae5d8e7a494df7e564d9ac9%26chksm%3D8712bbd0b06532c61d98c786ba1773c29c3dcf1291f9c3cd052c5643e24699eef28481e94b8e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【MatConvnet速成】MatConvnet图像分类从模型自定义到测试</a></li></ul><p><b>2.2、然后确定基准模型</b></p><p>最终工业级部署的时候，你往往需要一个效率更高的模型。但是除非你是老司机，否则不应该在还没有确定方案是否可行的时候就想自己的模型，而是应该<b>从一个绝对可靠的模型开始</b>，比如resnet18，比如mobilenet，正确地使用好它们，得到还不错的结果，将它的结果作为你自己算法要PK的对象。</p><p>关于基准模型，我们已经把最主要的模型全部解读了一遍，可以从中选择。</p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031450%26idx%3D1%26sn%3D3f7f159458e5f1621531ee107be11a98%26chksm%3D8712bd67b0653471c052e32b9d18a26f4d6a07852f56b50f6589b3baa7a46e1e44f302204a4e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】总结12大CNN主流模型架构设计思想</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D2%26sn%3Da8adb80cc4270662a087334c63a982d1%26chksm%3D8712bc72b0653564d4c0c149d51643d2df245774f8a69bc61d2d792abdd9bb191d109ff80632%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从2D卷积到3D卷积，都有什么不一样</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D2%26sn%3D90755895232f413d1594fc43a43c4830%26chksm%3D8712bcc6b06535d0d7e0ad1d9625deb2c729cb7d5f4d4164a5ce1f1ffb7bfcad652a7b2a4bbf%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】浅析RNN到LSTM</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031435%26idx%3D2%26sn%3D402ad26ffeac98d3a4710bef0e8adbfb%26chksm%3D8712bd76b0653460d4a5fd1176b87bf534085f85ae9494eb204725b3a5836588f3bf5158cc41%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】历数GAN的5大基本结构</a></li></ul><p><b>2.3、最后准备好数据</b></p><p>在前面你想好自己需要的数据了，接下来就是去采集到这些数据。完成一个项目，就是不断迭代模型和数据的过程。</p><p>刚开始的时候，你不需要数据都到位，但是要考虑好以下因素。这里我们不管数据是自己采集的还是从公开数据集中获取的。</p><p><b>(1) 准备大小合适的数据量</b>。以二分类任务为例，你不能拿500张图就开始干，没任何意义。你不能苛求一开始就有50000万数据，也不合理，万一搞失败了还浪费资源。笔者先后做过10余个分类任务，完成任务上线从3000到10万都用过，我的建议是，尽量先准备个3000数据再开干，不然就太没诚意了。</p><p><b>(2) 从简单数据开始</b>。以人脸识别为例，各种公开数据集不要混着用，分布不一致难度也不相同，你应该先专注简单的属于同一个分布的，比如找10000个正脸或者姿态小的数据，方案验证通过之后再增加难度。</p><p>很多的时候，你还要考虑覆盖各种场景(光照，背景)等。以上的这些东西，书不会告诉你，培训也没法教你，需要的是自己的积累，厚积薄发。</p><p>培养对数据的敏感性，可以从咱们的数据相关的文章开始看。</p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030010%26idx%3D1%26sn%3D76e0123bf24064c4cb1eb7acacac86fd%26chksm%3D87134307b064ca1169f6412000bd44da1852ca2854f659fb341356d2d1e61a1c883a555fb0ca%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【数据】深度学习从“数据集”开始</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029110%26idx%3D1%26sn%3D4debbbe890b48ab739fec5967868746b%26chksm%3D8713478bb064ce9da68dd57b419ddebd22884c05747abb9286c1e5bc6563702f2a1fd4bcac64%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】深度学习中的数据增强（下）</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029048%26idx%3D1%26sn%3Dec708683cb6a3c2ed048a945a7150b79%26chksm%3D871347c5b064ced3fd3d57c5c79df0087890efb10898076efb14e9ece8ddf38906dbaf33af2c%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[综述类] 一文道尽深度学习中的数据增强方法（上）</a></li></ul><h2><b>3 正确训练模型的基本常识</b></h2><p>终于讲到训练模型了，程序员干活从来不会一帆风顺，你的小模型不会这么听话，以下是一些必须要注意的事项，不管用什么框架都适用。</p><p><b>3.1 注意网络的输入大小</b></p><p>你极有可能是从finetune其他的模型开始，以图像分类为例，公开的模型大多是以224*224为尺度，而你的任务未必也需要这样。</p><p>如果你想要区分不同种类的鸟，那么因为细节在鸟的局部身体部位，你的输入恐怕是要更大一些才能提取到好的特征，比如放大一倍，用448*448，这也是论文中常用的。</p><p>如果你只是要区分不同表情，用上了上面的嘴唇数据，那224*224纯属浪费，你可能只需要一个48*48的输入就足以很高准确率完成任务。</p><p>对于图像分割和目标检测，标准又不太一样。究竟使用多大的输入，这需要你依靠经验来确定，而且还和能给你多少资源，以及自己优化模型的能力相关。</p><p><b>3.2 注意特征输出大小</b></p><p>前面说了输入，这里再说输出，包括最后一层卷积的大小和通道数等。</p><p>首先看大小，对于一个分类任务来说，最后卷积层抽象为一个k*k的特征图，然后进行池化，全连接。如果这个特征图太大，知识根本就没有抽象出来，如果太小，表征能力又可能不够。</p><p>根据不同的难度，3*3，5*5，7*7我都用过，但是没有用过9*9以上的，试过分类性能会下降，计算量还增加。imagenet竞赛的那些网络基本上都是7*7，兼顾了性能。</p><p>这个输出大小，就由<b>输入大小和网络的全局stride</b>来决定，不断遇到很多同学没有注意这个问题，结果模型性能很差的，这是基本素质。</p><p><b>3.3 正确地使用数据</b></p><p>前面已经准备了一些好的数据，别在用的时候却搞错了，对于图像分类来说有以下几个准则</p><p><b>(1) 随机打乱你的数据。</b></p><p>否则每个batch给的是同样类别的数据，不一定能保证模型学的正常。</p><p><b>(2) 在线做一些基本的数据预处理和增强。</b></p><p><b>图像缩放操作</b>，你要想好是用有变形的缩放，即统一缩放到固定大小。还是等比例缩放，即把短边缩放到一定尺度。</p><p><b>裁剪操作</b>，随机裁剪是最简单有效的数据增强方案，一开始就可以做起来，比如256*256随机裁剪224*224，不必要过于复杂。</p><p><b>镜像操作</b>，也就是mirror参数，不是所有的任务都可以翻转的，根据自己任务使用。</p><p><b>减均值和归一化操作</b>，其实这一步倒并非必要，因为网络自然可以学习到这一点。不过你做一下，通常不会有副作用。</p><p>更多的数据增强先不要急着做，因为那会增加网络优化的难度和时间。</p><p>这些操作都要在线做而不是离线准备好存入本地文件，这是很低效的。</p><p><b>3.4 正确地进行训练</b></p><p>接下来就开始训练，你可能会遇到各种与自己期望不相符的结果，其中一些很可能是你自己的错误造成的，因此有一些基本的训练参数需要注意。</p><p><b>(1) 用好学习率策略。</b></p><p>如果你没有经验，就不要一开始就使用SGD，虽然它可能取得更好的结果。直接用Adam，并且使用它的默认参数m1=0.9，m2=0.999，lr=0.001，学习率可以调整，其他两个参数基本不需要动。更多比较可以参考我们之前的文章。如果你的学习率搞的不好，很可能出现梯度爆炸或者不收敛。</p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030692%26idx%3D1%26sn%3D6322e8eec12d8a8b60f578a9ebb4b42c%26chksm%3D8712be59b065374f00dc9b3715e6453e2de5d05262ee4eac47ef5efe6d167703af67f5882029%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型训练】如何选择最适合你的学习率变更策略</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030739%26idx%3D1%26sn%3D96a2850020f99050f4440caee3b152a7%26chksm%3D8712be2eb0653738eace8cceb8923edeac0c2e96a7ae1d0ca1f942ea20ae51ff95e40829a408%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型训练】SGD的那些变种，真的比SGD强吗</a></li></ul><p><b>(2) 正确使用正则项。</b></p><p>weight decay是一个非常敏感的参数，如果你不是很有经验，从一个很小或者为0的值开始。</p><p>训练的时候可以用dropout，测试的时候是不需要用的。</p><p><b>(3) 正确使用BN层。</b></p><p>Batch Normalization是一个好东西，加快训练速度降低过拟合，但是你要注意它在训练的时候和测试的时候是不一样的。</p><p>use_global_stats这个参数在训练时是false，测试时是true，如果你没用对，那么可能训练无法进行，或者测试结果不对。</p><p>在训练过程中，你可能会遇到各种各样奇葩的问题。</p><p><b>比如网络loss不正常，怎么调都不管用。</b></p><p><b>比如训练好好的，测试就是结果不对。</b></p><p><b>bug天天有，深度学习算法工程师遇到的特别多，如果你想交流更多，就来有三AI知识星球实时提问交流吧，大咖众多，总有能解决你问题的。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;930&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_b.jpg\"/></figure><p>初识境界到此基本就结束了，这一系列是为大家奠定扎实的深度学习基础，希望学习完后大家能有收获<i>。</i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a> </p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a> </p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/61095501", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 57, 
            "title": "【完结】12大深度学习开源框架(caffe,tf,pytorch,mxnet等)快速入门项目", 
            "content": "<p></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-96ad0bac56cd5d57a4f0149051a9e0e7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-96ad0bac56cd5d57a4f0149051a9e0e7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-96ad0bac56cd5d57a4f0149051a9e0e7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-96ad0bac56cd5d57a4f0149051a9e0e7_b.jpg\"/></figure><p><b>这是一篇总结文，给大家来捋清楚12大深度学习开源框架的快速入门，这是有三AI的GitHub项目，欢迎大家star/fork。</b></p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/longpeng2008/yousan.ai\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/longpeng2008</span><span class=\"invisible\">/yousan.ai</span><span class=\"ellipsis\"></span></a></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-40b97e0ba201bd603545cdd139b34890_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"630\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-40b97e0ba201bd603545cdd139b34890_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;630&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"630\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-40b97e0ba201bd603545cdd139b34890_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-40b97e0ba201bd603545cdd139b34890_b.jpg\"/></figure><h2><b>1  概述</b></h2><h3>1.1 开源框架总览</h3><p>现如今开源生态非常完善，深度学习相关的开源框架众多，光是为人熟知的就有caffe，tensorflow，pytorch/caffe2，keras，mxnet，paddldpaddle，theano，cntk，deeplearning4j，matconvnet等。</p><p>如何选择最适合你的开源框架是一个问题。有三AI在前段时间里，给大家整理了<b>12个深度学习开源框架快速入门的教程和代码</b>，供初学者进行挑选，一个合格的深度学习算法工程师怎么着得熟悉其中的3个以上吧。</p><p>下面是各大开源框架的一个总览。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d2af0dc0108888b3eea1140d20656883_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-d2af0dc0108888b3eea1140d20656883_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-d2af0dc0108888b3eea1140d20656883_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-d2af0dc0108888b3eea1140d20656883_b.jpg\"/></figure><p>在这里我们还有一些框架没有放上来，是因为它们已经升级为大家更喜欢或者使用起来更加简单的版本，比如从torch-&gt;pytorch，从theano到lasagne。另外这些框架都支持CUDA，因此编程语言这里也没有写上cuda。</p><p>在选择开源框架时，要考虑很多原因，比如开源生态的完善性，比如自己项目的需求，比如自己熟悉的语言。当然，现在已经有很多开源框架之间进行互转的开源工具如MMDNN等，也降低了大家迁移框架的学习成本。</p><p>除此之外还有tiny-dnn，ConvNetJS，MarVin，Neon等等小众，以及CoreML等移动端框架，就不再一一介绍。</p><p>总的来说对于选择什么样的框架，有三可以给出一些建议。</p><p><b>(1) 不管怎么说，tensorflow/pytorch你都必须会，这是目前开发者最喜欢，开源项目最丰富的两个框架。</b></p><p><b>(2) 如果你要进行移动端算法的开发，那么Caffe是不能不会的。</b></p><p><b>(3) 如果你非常熟悉Matlab，matconvnet你不应该错过。</b></p><p><b>(4) 如果你追求高效轻量，那么darknet和mxnet你不能不熟悉。</b></p><p><b>(5) 如果你很懒，想写最少的代码完成任务，那么用keras吧。</b></p><p><b>(6) 如果你是java程序员，那么掌握deeplearning4j没错的。</b></p><p><b>其他的框架，也自有它的特点，大家可以自己多去用用。</b></p><h3><b>1.2 如何学习开源框架</b></h3><p>要掌握好一个开源框架，通常需要做到以下几点：</p><p>(1) 熟练掌握不同任务数据的准备和使用。</p><p>(2) 熟练掌握模型的定义。</p><p>(3) 熟练掌握训练过程和结果的可视化。</p><p>(4) 熟练掌握训练方法和测试方法。</p><p>一个框架，官方都会开放有若干的案例，最常见的案例就是以<b>MNISI数据接口+预训练模型</b>的形式，供大家快速获得结果，但是这明显还不够，学习不应该停留在跑通官方的demo上，而是要解决实际的问题。</p><p>我们要学会从<b>自定义数据读取接口，自定义网络的搭建，模型的训练，模型的可视化，模型的测试与部署等全方位</b>进行掌握。</p><p>因此，我们开设了一个《2小时快速入门开源框架系列》，以一个<b>图像分类任务为基准</b>，带领大家一步一步入门，后续会增加分割，检测等任务。</p><p>这是一个二分类任务，给大家准备了<b>500张微笑表情</b>的图片、<b>500张无表情</b>的图片，放置在git工程的data目录下，图片预览如下，已经全部缩放到60*60的大小：</p><p>这是无表情的图片：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c3fd061c8619d7a1f4287ac49d5d1a45_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"561\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c3fd061c8619d7a1f4287ac49d5d1a45_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;561&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"561\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c3fd061c8619d7a1f4287ac49d5d1a45_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c3fd061c8619d7a1f4287ac49d5d1a45_b.jpg\"/></figure><p>这是微笑表情的图片。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0ea360b00f4c838e49115b92845aec3b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"565\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0ea360b00f4c838e49115b92845aec3b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;565&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"565\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0ea360b00f4c838e49115b92845aec3b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0ea360b00f4c838e49115b92845aec3b_b.jpg\"/></figure><p>因此，我们的目标就是利用这500张图片完成好这个图像分类任务。</p><p>在下面的所有框架的学习过程中，我们都要完成下面这个流程，只有这样，才能叫做真正的完成了一个训练任务。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7fbe42b356a10e73678f74c843c6d9ad_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"137\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-7fbe42b356a10e73678f74c843c6d9ad_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;137&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"137\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-7fbe42b356a10e73678f74c843c6d9ad_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7fbe42b356a10e73678f74c843c6d9ad_b.jpg\"/></figure><p>另外，所有的框架都使用同样的一个模型，这是一个3层卷积+2层全连接的网络，由卷积+BN层+激活层组成，有的使用带步长的卷积，有的使用池化，差别不大。</p><p>输入图像，48*48*3的RGB彩色图。</p><p>第一层卷积，通道数12，卷积核3*3。</p><p>第二层卷积，通道数24，卷积核3*3。</p><p>第三层卷积，通道数48，卷积核3*3。</p><p>第一层全连接，通道数128。</p><p>第二层全连接，通道数2，即类别数。</p><p>网络结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-2360e3d6c31d76ef98e992db4da9c9a7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"1312\" class=\"origin_image zh-lightbox-thumb\" width=\"678\" data-original=\"https://pic4.zhimg.com/v2-2360e3d6c31d76ef98e992db4da9c9a7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;678&#39; height=&#39;1312&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"1312\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"678\" data-original=\"https://pic4.zhimg.com/v2-2360e3d6c31d76ef98e992db4da9c9a7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-2360e3d6c31d76ef98e992db4da9c9a7_b.jpg\"/></figure><p>这是最简单的一种网络结构，优化的时候根据不同的框架，采用了略有不同的方案。因为此处的目标不是为了比较各个框架的性能，所以没有刻意保持完全一致。</p><h2><b>2  开源框架</b></h2><p>下面我们开始对各个框架进行简述。</p><p>2.1 Caffe</p><p>github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/BVLC/caffe\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/BVLC/caffe</span><span class=\"invisible\"></span></a>。</p><p>(1) 概述：</p><p>Caffe是伯克利的贾扬清主导开发，以C++/CUDA代码为主，最早的深度学习框架之一，比TensorFlow、Mxnet、Pytorch等都更早，需要进行编译安装。支持命令行、Python和Matlab接口，单机多卡、多机多卡等都可以很方便的使用。目前master分支已经停止更新，intel分支等还在维护，caffe框架已经非常稳定。</p><p>(2)caffe的使用通常是下面的流程：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-13e4dfcd4c9394748f36dcef8faf335e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"178\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-13e4dfcd4c9394748f36dcef8faf335e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;178&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"178\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-13e4dfcd4c9394748f36dcef8faf335e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-13e4dfcd4c9394748f36dcef8faf335e_b.jpg\"/></figure><p>以上的流程相互之间是解耦合的，所以caffe的使用非常优雅简单。</p><p>(3) caffe有很明显的优点和缺点。</p><p>优点：</p><ul><li>以C++/CUDA/python代码为主，速度快，性能高。</li><li>工厂设计模式，代码结构清晰，可读性和拓展性强。</li><li>支持命令行、Python和Matlab接口，使用方便。</li><li>CPU和GPU之间切换方便，多GPU训练方便。</li><li>工具丰富，社区活跃。</li></ul><p>缺点：</p><ul><li>源代码修改门槛较高，需要实现前向反向传播，以及CUDA代码。</li><li>不支持自动求导。</li><li>不支持模型级并行，只支持数据级并行</li><li>不适合于非图像任务。</li></ul><p><b>鉴于caffe的学习有一定门槛，我给新手们提供一个自己录制的视频。</b></p><a href=\"https://link.zhihu.com/?target=https%3A//study.163.com/course/courseMain.htm%3Fshare%3D2%26shareId%3D400000000640089%26courseId%3D1006238015%26_trace_c_p_k2_%3De3f63523394c47388798148b5aff24e7\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">有三说深度学习 - 网易云课堂</a><p><b>其他框架后续也会录制，完整的系列视频在网易云上，见《有三说深度学习》。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-226589d2d7968b533eddcf0cb405c38e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-226589d2d7968b533eddcf0cb405c38e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-226589d2d7968b533eddcf0cb405c38e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-226589d2d7968b533eddcf0cb405c38e_b.jpg\"/></figure><p>同时可以看下面的快速入门文档，以及阅读相关的源代码。</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029846%26idx%3D1%26sn%3D0c343cfd0ede5c8ae1405bd6348aefad%26chksm%3D871342abb064cbbd7fe31fb3c55f23875f27e48fb8354e9855823b1701f1227c71b4eb00de50%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【caffe速成】caffe图像分类从模型自定义到测试</a><p><b>2.2 Tensorflow</b></p><p>github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/tensorflow/tensorflow\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/tensorflow/t</span><span class=\"invisible\">ensorflow</span><span class=\"ellipsis\"></span></a>。</p><p>(1) 概述</p><p>TensorFlow是Google brain推出的开源机器学习库，可用作各类深度学习相关的任务。</p><p>TensorFlow = Tensor + Flow，Tensor就是张量，代表N维数组，这与Caffe中的blob是类似的；Flow即流，代表基于数据流图的计算。</p><p>(2) 特点</p><p>TensorFlow最大的特点是计算图，即先定义好图，然后进行运算，所以所有的TensorFlow代码，都包含两部分：</p><ul><li>创建计算图，表示计算的数据流。它做了什么呢？实际上就是定义好了一些操作，你可以将它看做是Caffe中的prototxt的定义过程。</li><li>运行会话，执行图中的运算，可以看作是Caffe中的训练过程。只是TensorFlow的会话比Caffe灵活很多，由于是Python 接口，取中间结果分析，Debug等方便很多。</li></ul><p><b>目前tensorflow已经更新到2.0，由于精力原因，笔者的代码仍然以1.x版本为例。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-42e8503364c67c6ecad6a0e09975c42c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"469\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-42e8503364c67c6ecad6a0e09975c42c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;469&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"469\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-42e8503364c67c6ecad6a0e09975c42c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-42e8503364c67c6ecad6a0e09975c42c_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029846%26idx%3D2%26sn%3D7c2582243bcd8f8b491e8e466a21978f%26chksm%3D871342abb064cbbd0cba24b408ceda2b64a7c8b6baa07f9f8f56cd4d1233caa0b80fe357753e%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【tensorflow速成】Tensorflow图像分类从模型自定义到测试</a><h3><b>2.3 Pytorch</b></h3><p>github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/pytorch/pytorch\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/pytorch/pyto</span><span class=\"invisible\">rch</span><span class=\"ellipsis\"></span></a>。</p><p>(1) 概述：一句话总结Pytorch = Python + Torch。</p><p>Torch是纽约大学的一个机器学习开源框架，几年前在学术界非常流行，包括Lecun等大佬都在使用。但是由于使用的是一种绝大部分人绝对没有听过的Lua语言，导致很多人都被吓退。后来随着Python的生态越来越完善，Facebook人工智能研究院推出了Pytorch并开源。Pytorch不是简单的封装Torch 并提供Python接口，而是对Tensor以上的所有代码进行了重构，同TensorFlow一样，增加了自动求导。</p><p>后来Caffe2全部并入Pytorch，如今已经成为了非常流行的框架。很多最新的研究如风格化、GAN等大多数采用Pytorch源码。</p><p>(2) 特点</p><ul><li>动态图计算。TensorFlow从静态图发展到了动态图机制Eager Execution，pytorch则一开始就是动态图机制。动态图机制的好处就是随时随地修改，随处debug，没有类似编译的过程。</li><li>简单。相比TensorFlow1.0中Tensor、Variable、Session等概念充斥，数据读取接口频繁更新，tf.nn、tf.layers、tf.contrib各自重复，Pytorch则是从Tensor到Variable再到nn.Module，最新的Pytorch已经将Tensor和Variable合并，这分别就是从数据张量到网络的抽象层次的递进。有人调侃TensorFlow的设计是“make it complicated”，那么 Pytorch的设计就是“keep it simple”。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7c6bda0744df0ec2c47f846b5ca97ceb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"443\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-7c6bda0744df0ec2c47f846b5ca97ceb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;443&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"443\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-7c6bda0744df0ec2c47f846b5ca97ceb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-7c6bda0744df0ec2c47f846b5ca97ceb_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029881%26idx%3D1%26sn%3D3c869fcee3b48d3582952ab9a0683ea6%26chksm%3D87134284b064cb924c5e7231b3f2c36ba27e3a689b067f569f2e086f62b18413bcebc5987a07%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【pytorch速成】Pytorch图像分类从模型自定义到测试</a><h3><b>2.4 Mxnet</b></h3><p>github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/apache/incubator-mxnet\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/apache/incub</span><span class=\"invisible\">ator-mxnet</span><span class=\"ellipsis\"></span></a>。</p><p>(1) 概述</p><p>Mxnet是由李沐等人领导开发的非常灵活，扩展性很强的框架，被Amazon定为官方框架。</p><p>(2) 特点</p><p>Mxnet同时拥有命令式编程和符号式编程的特点。在命令式编程上MXNet提供张量运算，进行模型的迭代训练和更新中的控制逻辑；在声明式编程中MXNet支持符号表达式，用来描述神经网络，并利用系统提供的自动求导来训练模型。Mxnet性能非常高，推荐资源不够的同学使用。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-70bd0e737cb2e65c0cb85e0f081e6226_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-70bd0e737cb2e65c0cb85e0f081e6226_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-70bd0e737cb2e65c0cb85e0f081e6226_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-70bd0e737cb2e65c0cb85e0f081e6226_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029904%26idx%3D1%26sn%3D0bdc6947f5ac68e7f68426b9d076b4ab%26chksm%3D8713436db064ca7b3b2a2a1d6a8d24c15069f72655e2c39e2498051fa0e56bbcf6fe9c332d5b%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【mxnet速成】mxnet图像分类从模型自定义到测试</a><h3><b>2.5 Keras</b></h3><p>github网址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/keras-team/keras\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/keras-team/k</span><span class=\"invisible\">eras</span><span class=\"ellipsis\"></span></a>。</p><p>(1) 概述</p><p>Keras是一个对小白用户非常友好而简单的深度学习框架，严格来说并不是一个开源框架，而是一个高度模块化的神经网络库。</p><p>Keras在高层可以调用TensorFlow，CNTK，Theano，还有更多的库也在被陆续支持中。 Keras的特点是能够快速实现模型的搭建，是高效地进行科学研究的关键。</p><p>(2) 特点</p><ul><li>高度模块化，搭建网络非常简洁。</li><li>API很简单，具有统一的风格。</li><li>容易扩展，只需使用python添加新类和函数。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-ee0c0ec9c1675fc8dda4b55773da5d54_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"760\" data-rawheight=\"568\" class=\"origin_image zh-lightbox-thumb\" width=\"760\" data-original=\"https://pic1.zhimg.com/v2-ee0c0ec9c1675fc8dda4b55773da5d54_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;760&#39; height=&#39;568&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"760\" data-rawheight=\"568\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"760\" data-original=\"https://pic1.zhimg.com/v2-ee0c0ec9c1675fc8dda4b55773da5d54_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-ee0c0ec9c1675fc8dda4b55773da5d54_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029896%26idx%3D1%26sn%3Df3f7b9cf69c514f45d1d14205f879270%26chksm%3D87134375b064ca6323354c40f3e55b02ff0d1d24f3dacfc980190d51f20ec9ec16e60c1a4741%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【Keras速成】Keras图像分类从模型自定义到测试</a><h3><b>2.6 Paddlepaddle</b></h3><p>github网址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/PaddlePaddle/Paddle\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/PaddlePaddle</span><span class=\"invisible\">/Paddle</span><span class=\"ellipsis\"></span></a>。</p><p>(1) 概述</p><p>正所谓Google有Tensorflow，Facebook有Pytorch，Amazon有Mxnet，作为国内机器学习的先驱，百度也有PaddlePaddle，其中Paddle即Parallel Distributed Deep Learning(并行分布式深度学习)。</p><p>(2) 特点</p><p>paddlepaddle的性能也很不错，整体使用起来与tensorflow非常类似，拥有中文帮助文档，在百度内部也被用于推荐等任务。另外，配套了一个可视化框架visualdl，与tensorboard也有异曲同工之妙。国产框架不多，大家多支持啊！</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-099cbd801e1122ffdea2ebc2a54772ea_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"774\" data-rawheight=\"219\" class=\"origin_image zh-lightbox-thumb\" width=\"774\" data-original=\"https://pic3.zhimg.com/v2-099cbd801e1122ffdea2ebc2a54772ea_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;774&#39; height=&#39;219&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"774\" data-rawheight=\"219\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"774\" data-original=\"https://pic3.zhimg.com/v2-099cbd801e1122ffdea2ebc2a54772ea_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-099cbd801e1122ffdea2ebc2a54772ea_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029887%26idx%3D1%26sn%3D645b97809c24922352a0b39f19c9ef0c%26chksm%3D87134282b064cb9441af68124d205d9c7dedcaeb09788f4d586b949584e556eddd3a72217f69%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【paddlepaddle速成】paddlepaddle图像分类从模型自定义到测试</a><h3><b>2.7 CNTK</b></h3><p>github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/Microsoft/CN</span><span class=\"invisible\">TK</span><span class=\"ellipsis\"></span></a>。</p><p>(1) 概述</p><p>CNTK是微软开源的深度学习工具包，它通过有向图将神经网络描述为一系列计算步骤。在有向图中，叶节点表示输入值或网络参数，而其他节点表示其输入上的矩阵运算。 </p><p>CNTK允许用户非常轻松地实现和组合流行的模型，包括前馈DNN，卷积网络（CNN）和循环网络（RNN / LSTM）。与目前大部分框架一样，实现了自动求导，利用随机梯度下降方法进行优化。</p><p>(2)特点</p><ul><li>CNTK性能较高，按照其官方的说法，比其他的开源框架性能都更高。</li><li>适合做语音，CNTK本就是微软语音团队开源的，自然是更合适做语音任务，使用RNN等模型，以及在时空尺度分别进行卷积非常容易。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7770a68cfc508c9eac23f4c2557de3ff_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"258\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-7770a68cfc508c9eac23f4c2557de3ff_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;258&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"258\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-7770a68cfc508c9eac23f4c2557de3ff_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-7770a68cfc508c9eac23f4c2557de3ff_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030976%26idx%3D1%26sn%3D0befc170a93d365b780c5f05b2f510a4%26chksm%3D8712bf3db065362b0aeaae82bdbac467be5697b34cac2797e2ee15cdcb97474c08640482bf07%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【cntk速成】cntk图像分类从模型自定义到测试</a><h3>2.8 Matconvnet</h3><p>github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/vlfeat/matconvnet\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/vlfeat/matco</span><span class=\"invisible\">nvnet</span><span class=\"ellipsis\"></span></a>。</p><p>(1) 概述</p><p>不同于各类深度学习框架广泛使用的语言Python，MatConvnet是用matlab作为接口语言的开源深度学习库，底层语言是cuda。</p><p>(2) 特点</p><p>因为是在matlab下面，所以debug的过程非常的方便，而且本身就有很多的研究者一直都使用matlab语言，所以其实该语言的群体非常大。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c1a886039b02c13cd069b28e312e738a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"328\" data-rawheight=\"450\" class=\"content_image\" width=\"328\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;328&#39; height=&#39;450&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"328\" data-rawheight=\"450\" class=\"content_image lazy\" width=\"328\" data-actualsrc=\"https://pic3.zhimg.com/v2-c1a886039b02c13cd069b28e312e738a_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032109%26idx%3D2%26sn%3Da6ff48ec0ae5d8e7a494df7e564d9ac9%26chksm%3D8712bbd0b06532c61d98c786ba1773c29c3dcf1291f9c3cd052c5643e24699eef28481e94b8e%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【MatConvnet速成】MatConvnet图像分类从模型自定义到测试</a><h3>2.9 Deeplearning4j</h3><p>github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/deeplearning4j/deeplearning4j\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/deeplearning</span><span class=\"invisible\">4j/deeplearning4j</span><span class=\"ellipsis\"></span></a>。</p><p>(1) 概述</p><p>不同于深度学习广泛应用的语言Python，DL4J是为java和jvm编写的开源深度学习库，支持各种深度学习模型。</p><p>(2)特点</p><p>DL4J最重要的特点是支持分布式，可以在Spark和Hadoop上运行，支持分布式CPU和GPU运行。DL4J是为商业环境，而非研究所设计的，因此更加贴近某些生产环境。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5d9a142e187344667d9914441f9f4007_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"572\" data-rawheight=\"434\" class=\"origin_image zh-lightbox-thumb\" width=\"572\" data-original=\"https://pic4.zhimg.com/v2-5d9a142e187344667d9914441f9f4007_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;572&#39; height=&#39;434&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"572\" data-rawheight=\"434\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"572\" data-original=\"https://pic4.zhimg.com/v2-5d9a142e187344667d9914441f9f4007_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5d9a142e187344667d9914441f9f4007_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032012%26idx%3D1%26sn%3Df74c7084621f367adb2518ebec61ca42%26chksm%3D8712bb31b06532270b9ca9550ab48ff78adaad7d38c73645cfb8888218b8e177bebd5d401aa9%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【DL4J速成】Deeplearning4j图像分类从模型自定义到测试</a><p><br/>2.10 Chainer</p><p>github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/chainer/chainer\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/chainer/chai</span><span class=\"invisible\">ner</span><span class=\"ellipsis\"></span></a>。</p><p>(1) 概述</p><p>chainer也是一个基于python的深度学习框架，能够轻松直观地编写复杂的神经网络架构，在日本企业中应用广泛。</p><p>(2) 特点</p><p>chainer采用“Define-by-Run”方案，即通过实际的前向计算动态定义网络。更确切地说，chainer存储计算历史而不是编程逻辑，pytorch的动态图机制思想主要就来源于chainer。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-3e61edea3bb5d9236550a32e0c272933_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"798\" data-rawheight=\"436\" class=\"origin_image zh-lightbox-thumb\" width=\"798\" data-original=\"https://pic4.zhimg.com/v2-3e61edea3bb5d9236550a32e0c272933_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;798&#39; height=&#39;436&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"798\" data-rawheight=\"436\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"798\" data-original=\"https://pic4.zhimg.com/v2-3e61edea3bb5d9236550a32e0c272933_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-3e61edea3bb5d9236550a32e0c272933_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031911%26idx%3D2%26sn%3Da95856836c0d8832b9e5fe49704c6313%26chksm%3D8712ba9ab065338c28d86ff10bff58bcda404bfc0efc68f0a9c0ba20a2126d917cc701c6b4ae%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【chainer速成】chainer图像分类从模型自定义到测试</a><h3>2.11 Lasagne/Theano</h3><p>github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/Lasagne/Lasagne\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/Lasagne/Lasa</span><span class=\"invisible\">gne</span><span class=\"ellipsis\"></span></a>。</p><p>(1)概述</p><p>Lasagen其实就是封装了theano，后者是一个很老牌的框架，在2008年的时候就由Yoshua Bengio领导的蒙特利尔LISA组开源了。</p><p>(2)特点</p><p>theano的使用成本高，需要从底层开始写代码构建模型，Lasagen对其进行了封装，使得theano使用起来更简单。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-8ac8045b94ddba11faba6169dcc6832c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-8ac8045b94ddba11faba6169dcc6832c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-8ac8045b94ddba11faba6169dcc6832c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-8ac8045b94ddba11faba6169dcc6832c_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032128%26idx%3D2%26sn%3Df889e2255c0ec4960f76ad0383363849%26chksm%3D8712bbbdb06532ab136c0a485bebc5cf181f24a34bec7bab3f97f66be627e09d939b997dae90%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【Lasagne速成】Lasagne/Theano图像分类从模型自定义到测试</a><h3><b>2.12 Darknet</b></h3><p>github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/pjreddie/darknet\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/pjreddie/dar</span><span class=\"invisible\">knet</span><span class=\"ellipsis\"></span></a>。</p><p>(1) 概述</p><p>Darknet本身是Joseph Redmon为了Yolo系列开发的框架。</p><p>Joseph Redmon提出了Yolo v1，Yolo v2，Yolo v3。</p><p>(2) 特点</p><p>Darknet几乎没有依赖库，是从C和CUDA开始撰写的深度学习开源框架，支持CPU和GPU。Darknet跟caffe颇有几分相似之处，却更加轻量级，非常值得学习使用。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-26b2cba98299ea6f8bf3845c7ea51ff9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-26b2cba98299ea6f8bf3845c7ea51ff9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-26b2cba98299ea6f8bf3845c7ea51ff9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-26b2cba98299ea6f8bf3845c7ea51ff9_b.jpg\"/></figure><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D2%26sn%3Da9770ead4a9d03f0a4e75be86657453b%26chksm%3D8712bbb4b06532a27f0f02ac30ce4a18eeac1f72ac54b3c5c1b6ec13fee29f03bfc0dcaa1efd%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【darknet速成】Darknet图像分类从模型自定义到测试</a><p> 1、今天开源的这一套代码还只包含图像分类任务，后续我们会增加其他计算机视觉任务，欢迎小伙伴们前来参与，需要力量！</p><p>2、开源框架众多，使用过程中必会出现N多问题，如果你想要更多的交流，就来有三AI知识星球吧，来日方长。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "Caffe（深度学习框架）", 
                    "tagLink": "https://api.zhihu.com/topics/20019488"
                }, 
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }, 
                {
                    "tag": "PyTorch", 
                    "tagLink": "https://api.zhihu.com/topics/20075993"
                }
            ], 
            "comments": [
                {
                    "userName": "触摸到彩虹", 
                    "userLink": "https://www.zhihu.com/people/8c4b0cce2fd5349597a13dfc567d3f12", 
                    "content": "写的很好！！！", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/60845159", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 162, 
            "title": "【完结】12篇文章告诉你深度学习理论应该学到什么水平", 
            "content": "<p>专栏《AI初识境》正式完结了，在这一个专题中，我们给大家从<b>神经网络背景与基础</b>，讲到了<b>深度学习中的激活函数，池化，参数初始化，归一化，优化方法，正则项与泛化能力</b>，讲到了深度学习中的<b>评测指标，优化目标</b>，以及新手开始做训练时的<b>注意事项</b>。</p><p>消化完这12期文章后，你肯定具备了扎实的深度学习理论基础，接下来就大胆地往前走吧，下面再次回顾提炼一下主要内容。</p><p>                                                                                                                            作者&amp;编辑 | 言有三<br/></p><h2><b>1、人工智能简史</b></h2><p>按照中国古代思想家荀子在《荀子·正名篇》的说法：“所以知之在人者谓之知，知有所合谓之智。所以能之在人者谓之能，能有所合谓之能”。老人家认为，智能包含了两层含义，当然这是站在哲学的角度。</p><p>霍华德·加德纳的多元智能理论中将人类的智能分成七种能力：</p><p>(1) 语言 (Verbal/Linguistic) </p><p>(2) 逻辑 (Logical/Mathematical) </p><p>(3) 空间 (Visual/Spatial) </p><p>(4) 肢体运作 (Bodily/Kinesthetic) </p><p>(5) 音乐 (Musical/Rhythmic) </p><p>(6) 人际 (Inter-personal/Social) </p><p>(7) 内省 (Intra-personal/Introspective)</p><p>基本覆盖了现在人工智能的研究领域，包括计算机视觉，语音识别，自然语言处理等。</p><p>在这一篇文章里，会从图灵与机器智能，冯诺伊曼与类脑计算，约翰·麦卡锡（John McCarthy）、马文·闵斯基（Marvin Minsky，人工智能与认知学专家）、克劳德·香农（Claude Shannon，信息论的创始人）、艾伦·纽厄尔（Allen Newell，计算机科学家）、赫伯特·西蒙（Herbert Simon，诺贝尔经济学奖得主），塞弗里奇(Oliver Selfridge)等科学家参与的达特茅斯会议讲起。</p><p>从人工智能的启蒙，到三次浪潮的曲折和技术的成长史，值得每一个从事该行业的人阅读。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"855\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;855&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"855\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/56679585\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/v2-c838c0fedc57d7355c532d543a257aa4_180x120.jpg\" data-image-width=\"2280\" data-image-height=\"1805\" class=\"internal\">龙鹏-言有三：【AI初识境】从3次人工智能潮起潮落说起</a><h2><b>2、神经网络</b></h2><p>人工智能的研究派系分为两大阵营。</p><p><b>第一大阵营，被称为符号派。</b>他们用统计逻辑和符号系统来研究人工智能。<b>第二大阵营是统计派。</b>现在的深度学习就属于这一派，研究问题的方法就是仿造大脑。</p><p>这一篇从感受野，到MP模型，到感知机，到反向传播开始讲起，历数全连接神经网络的劣势，然后讲述卷积神经网络的特点，核心技术和优势，是学习深度学习最重要的基础。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fe210c865a491c5b51119b7d3c8eae0e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fe210c865a491c5b51119b7d3c8eae0e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fe210c865a491c5b51119b7d3c8eae0e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fe210c865a491c5b51119b7d3c8eae0e_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57004263\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-0677a0f6d88f26e186cb7262faeb8912_ipico.jpg\" data-image-width=\"800\" data-image-height=\"800\" class=\"internal\">龙鹏-言有三：【AI初识境】从头理解神经网络-内行与外行的分水岭</a><h2><b>3、图像领域的突破</b></h2><p>既然学深度学习，就必须要了解深度学习的重要进展。</p><p>在前深度学习时代，视觉机制的发现，第一个卷积神经网络Neocognitron的提出，反向传播算法的流行，促进了LeNet5和MNIST数据集的诞生。</p><p>随着新理论的成熟，大数据的积累，GPU的普世，以卷积神经网络为代表的技术在图像分类，目标检测等基础领域取得重大突破，随着AlphaGo的成功同时在业内和业外人士的心目中种下了深度学习/人工智能技术的种子，从此焕发勃勃生机。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"851\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb\" width=\"851\" data-original=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;851&#39; height=&#39;476&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"851\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"851\" data-original=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57258501\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-dc794684fce2037f11dba0a0d699a476_180x120.jpg\" data-image-width=\"851\" data-image-height=\"476\" class=\"internal\">龙鹏-言有三：【AI初识境】近20年深度学习在图像领域的重要进展节点</a><h2><b>4、激活函数</b></h2><p>深度学习的机制模仿于人脑，人脑的细胞接受刺激从而产生活动需要一定的阈值，这便是激活函数根本性的由来。</p><p>激活函数肩负着网络非线性表达能力的提升，从早期平滑的sigmoid和tanh激活函数，到后来的ReLU和各类ReLU的变种(LReLU，PReLU，RReLU，ELU，SELU，GELU等等)，Maxout，研究者一直试图让网络拥有更好的表达能力。</p><p>随着技术的发展，利用增强学习等算法从函数池中学习新的激活函数如swish等，成为了当下的研究主流，激活函数也走上了数据驱动的道路。</p><p>激活机制看似简单，实则不易，大家不妨多了解了解。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d22f63d3427b234510e0f9d50a7367ab_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"850\" data-rawheight=\"632\" class=\"origin_image zh-lightbox-thumb\" width=\"850\" data-original=\"https://pic4.zhimg.com/v2-d22f63d3427b234510e0f9d50a7367ab_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;850&#39; height=&#39;632&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"850\" data-rawheight=\"632\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"850\" data-original=\"https://pic4.zhimg.com/v2-d22f63d3427b234510e0f9d50a7367ab_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-d22f63d3427b234510e0f9d50a7367ab_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57258642\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-d77be8239bcac6884448f021ca7eba29_180x120.jpg\" data-image-width=\"602\" data-image-height=\"325\" class=\"internal\">龙鹏-言有三：【AI初识境】激活函数：从人工设计(sigmoid,relu)到自动搜索(swish)</a><h2><b>5、初始化</b></h2><p>参数初始化，一个看似很简单的问题，却实实在在地困住了神经网络的优化很久，2006年Hinton等人在science期刊上发表了论文“Reducing the dimensionality of data with neural networks”，揭开了新的训练深层神经网络算法的序幕，仍旧被认为是当前第三次人工智能热潮的纪元。</p><p>从全零初始化和随机初始化，到标准初始化，Xavier初始化，He初始化，时至今日上千层网络的训练都已经成为了现实，初始化似乎已经不再是那么重要的课题了，但是谁说就没有思考的空间了呢。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;372&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57454669\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-6cf5bc9885e71e3eb71843e5b8d9ffaa_180x120.jpg\" data-image-width=\"1592\" data-image-height=\"554\" class=\"internal\">龙鹏-言有三：【AI初识境】什么是深度学习成功的开始？参数初始化（xavier，he等）</a><h2><b>6、归一化</b></h2><p>我们总是希望所研究的统计问题能够满足固定的分布，而且这样也的确会降低问题的难度。</p><p>在深度学习中，因为网络的层数非常多，如果数据分布在某一层开始有明显的偏移，随着网络的加深这一问题会加剧，进而导致模型优化的难度增加。</p><p>归一化便是致力于解决这个问题，从数据到权重，从限定在同一样本的一个特征通道到不同样本的所有通道，各类归一化方法以简单的方式，优雅地解决了深度学习模型训练容易陷入局部解的难题，顺带提升训练速度提高泛化能力，这是一定要掌握的理论和工程技巧。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"681\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;681&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"681\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57609506\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-1aa8a8e9ff5ebb7bc4ec740ec52f503d_180x120.jpg\" data-image-width=\"1380\" data-image-height=\"870\" class=\"internal\">龙鹏-言有三：【AI初识境】深度学习模型中的Normalization，你懂了多少？</a><h2><b>7、池化</b></h2><p>大脑学习知识靠抽象，从图像中抽象知识是一个“从大到小”过滤提炼信息的过程。从视觉机制中来的pooling即池化，正是对信息进行抽象的过程。</p><p>池化增加了网络对于平移的不变性，提升了网络的泛化能力，大家已经习惯了使用均值池化mean pooling和最大池化(max pooling)，虽然可以用带步长的卷积进行替代。</p><p>尽管池化究竟起到了多大的作用开始被研究者怀疑，但是池化机制仍然是网络中必备的结构，所以你一定要熟悉它，而且基于数据驱动的池化机制值得研究。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b75c85872f6bc39cbe8701efa323d3ee_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1022\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb\" width=\"1022\" data-original=\"https://pic3.zhimg.com/v2-b75c85872f6bc39cbe8701efa323d3ee_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1022&#39; height=&#39;338&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1022\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1022\" data-original=\"https://pic3.zhimg.com/v2-b75c85872f6bc39cbe8701efa323d3ee_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b75c85872f6bc39cbe8701efa323d3ee_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/58381421\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-54d338dbb40ee32579e7806cf3488ef5_180x120.jpg\" data-image-width=\"1017\" data-image-height=\"503\" class=\"internal\">龙鹏-言有三：【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化(pooling)，到底是什么？</a><h2><b>8、最优化</b></h2><p>模型的学习需要通过优化方法才能具体实现。深度学习模型的优化是一个非凸优化问题，尽管一阶二阶方法都可以拿来解决它，但是当前随机梯度下降SGD及其各类变种仍然是首选。</p><p>从SGD开始，有的致力于提高它的优化速度如Momentum动量法和Nesterov accelerated gradient法，有的致力于让不同的参数拥有不同的学习率如Adagrad，Adadelta与Rmsprop法，有的希望大家从调参中解脱如Adam方法及其变种，有的致力于让收敛过程更加稳定如Adafactor方法和Adabound方法。</p><p>没有一个方法是完美的，训练的时候总归要试试。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b3b26baa046f4c61f75d4358f02e869d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"773\" data-rawheight=\"547\" class=\"origin_image zh-lightbox-thumb\" width=\"773\" data-original=\"https://pic2.zhimg.com/v2-b3b26baa046f4c61f75d4358f02e869d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;773&#39; height=&#39;547&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"773\" data-rawheight=\"547\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"773\" data-original=\"https://pic2.zhimg.com/v2-b3b26baa046f4c61f75d4358f02e869d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b3b26baa046f4c61f75d4358f02e869d_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57860231\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-ef9968db2cb4a05e712ef17a8b53bc71_180x120.jpg\" data-image-width=\"773\" data-image-height=\"547\" class=\"internal\">龙鹏-言有三：【AI初识境】为了围剿SGD大家这些年想过的那十几招(从momentum到Adabound)</a><h2><b>9、泛化能力</b></h2><p>如果一个模型只能在训练集上起作用，那不就成为了书呆子要其何用。</p><p>因此我们总是希望模型不仅仅是对于已知的数据(训练集)性能表现良好，对于未知的数据(测试集)也表现良好，即具有良好的泛化能力，通过添加正则项来实现。</p><p>从直接提供正则化约束的参数正则化方法如L1/L2正则化，工程上的技巧如训练提前终止和模型集成，以及隐式的正则化方法如数据增强等，研究人员在这方面投入的精力非常多，大家一定要时刻关注。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"830\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"830\" data-original=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;830&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"830\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"830\" data-original=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/58903870\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/v2-98891186659ff40f86c5fcd27cb5f624_180x120.jpg\" data-image-width=\"1168\" data-image-height=\"558\" class=\"internal\">龙鹏-言有三：【AI初识境】如何增加深度学习模型的泛化能力(L1/L2正则化，dropout，数据增强等等)</a><h2><b>10、模型评估</b></h2><p>口说无凭，用数据说话才是研究者们进行PK的正确姿态。计算机视觉的任务何其多，从分类，回归，质量评估到生成模型，这篇文章就全部都来说一遍。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5c70412d959e0594a78102fbd9daa2b3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"827\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-5c70412d959e0594a78102fbd9daa2b3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;827&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"827\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-5c70412d959e0594a78102fbd9daa2b3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5c70412d959e0594a78102fbd9daa2b3_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/59481933\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-cf839c9a3bbee4fddf4fe86782f59396_180x120.jpg\" data-image-width=\"1200\" data-image-height=\"919\" class=\"internal\">龙鹏-言有三：【AI初识境】深度学习模型评估方法，从分类，回归，质量评价到生成模型</a><h2><b>11、损失函数</b></h2><p>模型的学习需要指导，这正是损失函数的责任，它往往对模型最终表现如何影响巨大。</p><p>这一篇文章就重点总结分类问题，回归问题，生成对抗网络中使用的损失目标，为大家设计更好的优化目标奠定理论基础。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c574f0635b2f51e7ab72eacf751a5ddf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"487\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c574f0635b2f51e7ab72eacf751a5ddf_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;487&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"487\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c574f0635b2f51e7ab72eacf751a5ddf_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c574f0635b2f51e7ab72eacf751a5ddf_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/60302475\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-719f196bca887827213781b5cd65c0d1_180x120.jpg\" data-image-width=\"1884\" data-image-height=\"850\" class=\"internal\">龙鹏-言有三：【AI初识境】深度学习中常用的损失函数有哪些（覆盖分类，回归，风格化，GAN等任务）？</a><h2><b>12、如何开始训练你的模型</b></h2><p>磨刀不误砍柴工，当我们开始训练自己的模型的时候，总归要想清楚一些事儿再动手。</p><p>第一步知道你要做的任务是一个什么任务，找到竞争对手做好预期，想好你需要什么样的数据。第二步确定好框架，基准模型，准备好数据。然后才是第三步开始训练，从输入输出，数据的预处理到维持正确地训练姿势。</p><p>既然是总结出来的经验，想必总是有用的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"764\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;764&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"764\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/60546840\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-214b997ad0cf9fa313090f57579d8052_180x120.jpg\" data-image-width=\"4096\" data-image-height=\"2896\" class=\"internal\">龙鹏-言有三：【AI初识境】给深度学习新手开始项目时的10条建议</a><h2><b>总结</b></h2><p>相信经过这一个系列后，大家应该都夯实了自己的深度学习基础，从此向着更高的目标前进。</p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": [
                {
                    "userName": "杨雨林", 
                    "userLink": "https://www.zhihu.com/people/166c730319d89371b757cfea149edad8", 
                    "content": "赞", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "🤝🤝", 
                            "likes": 0, 
                            "replyToAuthor": "杨雨林"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "非常好👍", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "谢谢", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/57004263", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 10, 
            "title": "【AI初识境】从头理解神经网络-内行与外行的分水岭", 
            "content": "<p>这是专栏《AI初识境》的第2篇文章。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>这一篇，我们就说说神经网络基础，包括简单历史，核心原理与技术。</p><p>                                                                                                                          作者&amp;编辑 | 言有三</p><h2><b>1 人工智能符号派与统计派</b></h2><p>上一次我们讲述了人工智能的完整历史，自从图灵提出了“机器智能”，达特茅斯会议提出“人工智能”学科后，研究人员就开始活跃起来。</p><p>正所谓有人的地方就有江湖，人工智能的研究派系主要就是两大阵营。</p><p>第一大阵营，被称为<b>符号派</b>，他们用统计逻辑和符号系统来研究人工智能，采用自顶向下的研究思路，也就是要先看懂人工智能是什么，再去一步一步实现它。符号派用人工智能技术来证明公式，发明专家系统，代表人物有纽厄尔(Newell)、西蒙(Simon)等。</p><p>第二大阵营是<b>统计派</b>，现在的深度学习就属于这一派，这一派研究问题的方法就是仿造大脑，采用自底向上的思路。通过一个一个简单逻辑的搭建，搭建成一个足够复杂的系统后，系统就自然会有智能了。代表人物新时代的深度学习三大巨头Yoshua Bengio，Hinton、LeCun。</p><p>应该说，符号派的研究方法最早也更加直观，典型的例子是专家系统，它的缺陷也非常明显，必须先对所研究的问题有完整的理解，然后再通过知识编码，这对于达到一定复杂程度的问题来说根本不可能实现，不是所有知识都能一下子说出来原因的。就好比在图像中识别一只猫，到底怎样的一幅图片才是猫图，传统的图像描述算子就很难完全定义，保证覆盖到各类场景。</p><p>统计派的思路就更加务实，摆事实讲道理，通过统计学习的方法来归纳出知识，不再完全由人工干预，天然和大数据是契合的，这也是成功的必然性。</p><p>有学者一生站队在一派，也有的摇摆过，比如上次说到的马文·明斯基，就从最开始的统计派在第二次AI浪潮中转变成为了符号派，并成为了第二次低谷的重要推手。</p><p>anyway，现在是统计学派大放异彩的时候。</p><h2><b>2 人脑与视觉感知机制</b></h2><p>前面说了统计派是采用了模仿大脑的方式，人类花了亿万年的时间来进化，那生物的大脑究竟是如何处理视觉信息呢？</p><p>大脑的基本感知单元就是神经元，一个神经元所影响的刺激区域就叫做<b>神经元的感受野</b>，即receptive field，不同神经元感受野的大小和性质都不同。</p><p>感受野的研究来自于美国神经科学家哈特兰（Keffer Hartline）和匈牙利裔美国神经科学家库夫勒（Stephen W. Kuffler），1953年他们发现猫视网膜神经节细胞的感受野具有同心圆结构。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4afc07b5cf306083813376b147b68588_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"403\" data-rawheight=\"737\" class=\"content_image\" width=\"403\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;403&#39; height=&#39;737&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"403\" data-rawheight=\"737\" class=\"content_image lazy\" width=\"403\" data-actualsrc=\"https://pic1.zhimg.com/v2-4afc07b5cf306083813376b147b68588_b.jpg\"/></figure><p>如上图包括了两种感受野，第一种感受野<b>由作用强的中心兴奋区域和作用较弱但面积更大的周边抑制区域构成了一个同心圆结构</b>，称为On型感受野，第二类感受野是由中心抑制和周边兴奋的同心圆构成，称为Off型感受野。当刺激On型感受野中心时，细胞就兴奋，如第一列第一排的图。刺激周边时，细胞就抑制，如第一列第二排的图，Off型图则反之。</p><p>不过尽管明白了感受野，视觉感知的机制仍然没有被得到更深刻地理解，直到视觉功能柱的发现。</p><p>加拿大神经生理学家David Hunter Hubel和瑞典神经科学家Torsten Nils Wiesel在20世纪50年代和60年代开始研究视觉机制，他们将图像投射到屏幕上，将测量神经元活动的电线插入猫的大脑，通过固定猫的头部来控制视网膜上的成像，测试生物细胞对线条、直角、边缘线等图形的反应。</p><p>研究显示有些细胞对某些处在一个角度上的线条、垂直线条、直角或者明显的边缘线，都有特别的反应，这就是绝大多数视皮层细胞都具有的强烈的<b>方位选择性</b>。不仅如此，要引起这个细胞反应，直线的朝向还只能落在一个很小的角度范围里，也就是该细胞的感受野内。这样以上两个研究就统一起来了。</p><p>从1960年到1980年，两人合作了20多年，细致科学地研究了人眼视觉的机制，因此他们被认为是现代视觉科学之父，并于1981年一起获得了诺贝尔生理学与医学奖。</p><p><b>这一项研究，直接催生了David Marr的视觉分层理论，也催生了计算机视觉学科，更是卷积神经网络的发源。</b></p><h2><b>3 MP模型</b></h2><p>在生物学家，计算机科学家的共同努力下，大家摸清了人脑神经元的工作机制。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ecb1557a8a3f94d055f871e8310e02bd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"344\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-ecb1557a8a3f94d055f871e8310e02bd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;344&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"344\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-ecb1557a8a3f94d055f871e8310e02bd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ecb1557a8a3f94d055f871e8310e02bd_b.jpg\"/></figure><p>神经元之间相互连接，当某一神经元处于“兴奋”状态时，其相连神经元的电位将发生改变，若神经元电位改变量超过了一定的数值（也称为阈值），则被激活处于“兴奋状态”，向下一级连接的神经元继续传递电位改变信息。信息从一个神经元以电传导的方式跨过细胞之间的联结(即突触)，传给另一个神经元，最终使肌肉收缩或腺体分泌。</p><p>神经元通过突触的连接使数目众多的神经元组成比其他系统复杂得多的神经系统。从神经元的结构特性和生物功能可以得出结论：<b>神经元是一个多输入单输出的信息处理单元，并且对信息的处理是非线性的。</b></p><p>在这个基础上，就有科学家产生了模拟神经网络的想法。1943年McCulloch和Pitts提出了<b>MP模型</b>，这是一种基于阈值逻辑的算法创造的神经网络计算模型，由固定的结构和权重组成。</p><p>在MP模型中，某个神经元接受来自其余多个神经元的传递信号，多个输入与对应连接权重相乘后输入该神经元进行求和，再与神经元预设的阈值进行比较，最后通过激活函数产生神经元输出。每一个神经元均为多输入单输出的信息处理单元，具有空间整合特性和阈值特性。</p><p>其实MP模型就已经是感知器的原型了，只是没有真正在计算机上实现而已。</p><h2><b>4 感知机</b></h2><p>感知机（Perceptron）是Frank Rosenblatt在1957年提出的概念，其结构与MP模型类似，一般被视为最简单的人工神经网络，也作为二元线性分类器被广泛使用。通常情况下指单层的人工神经网络，以区别于多层感知机（Multilayer Perceptron）。尽管感知机结构简单，但能够学习并解决较复杂问题。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4114eba4c97bf4d0211822ae7605babc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"725\" data-rawheight=\"524\" class=\"origin_image zh-lightbox-thumb\" width=\"725\" data-original=\"https://pic1.zhimg.com/v2-4114eba4c97bf4d0211822ae7605babc_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;725&#39; height=&#39;524&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"725\" data-rawheight=\"524\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"725\" data-original=\"https://pic1.zhimg.com/v2-4114eba4c97bf4d0211822ae7605babc_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-4114eba4c97bf4d0211822ae7605babc_b.jpg\"/></figure><p>假设我们有一个n维输入的单层感知机，x1至xn为n维输入向量的各个分量，w1j至wnj为各个输入分量连接到感知机的权量（或称权值），theta为阈值，f为激活函数（又称为激励函数或传递函数），o为标量输出。理想的激活函数通常为阶跃函数或者sigmoid函数。感知机的输出是输入向量x与权重向量w求得内积后，经激活函数f所得到的标量。</p><p>单层感知器类似一个逻辑回归模型，可以做线性分类任务，但是不能做更复杂的任务。第二次AI浪潮中马文·明斯基在其著作中证明了感知器本质上是一种线性模型，只能处理线性分类问题，就连最简单的XOR（亦或）问题都无法正确解决。作为人工智能领域的开创者之一，这一声明也直接或间接促使神经网络的研究陷入了近20年的停滞。</p><h2><b>5 多层感知器与反向传播</b></h2><p>不过就算在低谷期，1974年哈佛大学的Paul Werbos仍然证明增加一个网络层，利用反向传播算法可以搞定XOR问题。到了后来Rummelhart，McClelland以及Hinton在1986年正式在多层感知器(MLP)中使用BP算法，采用Sigmoid进行非线性映射，有效解决了非线性分类和学习的问题。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-709b4b41eca8ace3a642ba7016442130_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"594\" data-rawheight=\"534\" class=\"origin_image zh-lightbox-thumb\" width=\"594\" data-original=\"https://pic1.zhimg.com/v2-709b4b41eca8ace3a642ba7016442130_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;594&#39; height=&#39;534&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"594\" data-rawheight=\"534\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"594\" data-original=\"https://pic1.zhimg.com/v2-709b4b41eca8ace3a642ba7016442130_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-709b4b41eca8ace3a642ba7016442130_b.jpg\"/></figure><p><b>多层感知机</b>（Multi-Layer Perceptron）是由单层感知机推广而来，最主要的特点是有多个神经元层。一般将MLP的第一层称为输入层，中间的层为隐藏层，最后一层为输出层。MLP并没有规定隐藏层的数量，因此可以根据实际处理需求选择合适的隐藏层层数，且对于隐藏层和输出层中每层神经元的个数也没有限制。</p><p>多层感知机的关键问题在于如何训练其中各层间的连接权值，</p><p>方法有一些不过大家最熟知的就是<b>反向传播BP算法</b>了。</p><p>反向传播算法的具体推导涉及大量的公式，实在不适合在公众里写，因此我们就不写了，大家随便找一本书都能找到资料，勤快的可以自己推导一遍。</p><p>这里给大家一个实际的案例来体会：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7385e3f91d9f2dce350c3d7a474bef6e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"726\" data-rawheight=\"426\" class=\"origin_image zh-lightbox-thumb\" width=\"726\" data-original=\"https://pic3.zhimg.com/v2-7385e3f91d9f2dce350c3d7a474bef6e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;726&#39; height=&#39;426&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"726\" data-rawheight=\"426\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"726\" data-original=\"https://pic3.zhimg.com/v2-7385e3f91d9f2dce350c3d7a474bef6e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-7385e3f91d9f2dce350c3d7a474bef6e_b.jpg\"/></figure><p>输出为y，损失函数为E。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-cd3e6c5edc63ebdc57498ddfd1126825_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"944\" data-rawheight=\"174\" class=\"origin_image zh-lightbox-thumb\" width=\"944\" data-original=\"https://pic2.zhimg.com/v2-cd3e6c5edc63ebdc57498ddfd1126825_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;944&#39; height=&#39;174&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"944\" data-rawheight=\"174\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"944\" data-original=\"https://pic2.zhimg.com/v2-cd3e6c5edc63ebdc57498ddfd1126825_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-cd3e6c5edc63ebdc57498ddfd1126825_b.jpg\"/></figure><p>假如某一时刻值如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-03f9e016259488a199cfe46dcc792de4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"684\" data-rawheight=\"114\" class=\"origin_image zh-lightbox-thumb\" width=\"684\" data-original=\"https://pic1.zhimg.com/v2-03f9e016259488a199cfe46dcc792de4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;684&#39; height=&#39;114&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"684\" data-rawheight=\"114\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"684\" data-original=\"https://pic1.zhimg.com/v2-03f9e016259488a199cfe46dcc792de4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-03f9e016259488a199cfe46dcc792de4_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-6b542b6d67434a05bd49844bb39f967b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"546\" data-rawheight=\"202\" class=\"origin_image zh-lightbox-thumb\" width=\"546\" data-original=\"https://pic4.zhimg.com/v2-6b542b6d67434a05bd49844bb39f967b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;546&#39; height=&#39;202&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"546\" data-rawheight=\"202\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"546\" data-original=\"https://pic4.zhimg.com/v2-6b542b6d67434a05bd49844bb39f967b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-6b542b6d67434a05bd49844bb39f967b_b.jpg\"/></figure><p>那么我们可以计算E对Wh1的误差传播值为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b7cd53b1a192347d491932719e576b5a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"846\" data-rawheight=\"144\" class=\"origin_image zh-lightbox-thumb\" width=\"846\" data-original=\"https://pic3.zhimg.com/v2-b7cd53b1a192347d491932719e576b5a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;846&#39; height=&#39;144&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"846\" data-rawheight=\"144\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"846\" data-original=\"https://pic3.zhimg.com/v2-b7cd53b1a192347d491932719e576b5a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b7cd53b1a192347d491932719e576b5a_b.jpg\"/></figure><p>下次更新Wh1这个参数的时候就可以采用：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-739d1353faaf24350907b7f59c0ddcd3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"260\" data-rawheight=\"108\" class=\"content_image\" width=\"260\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;260&#39; height=&#39;108&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"260\" data-rawheight=\"108\" class=\"content_image lazy\" width=\"260\" data-actualsrc=\"https://pic4.zhimg.com/v2-739d1353faaf24350907b7f59c0ddcd3_b.jpg\"/></figure><p>η就是学习率了，原理就是这样，一层一层推导下去就行了。</p><p>反向传播算法让多层感知器，或者说传统的全连接神经网络有了训练的手段，引发了神经网络的第二次热潮，虽然为期不长，毕竟当时算力和数据都很有限，但是全连接神经网络总算是正式起来了。</p><h2><b>6 全连接神经网络2大缺陷</b></h2><p>传统的BP神经网络在20世纪80年代左右流行，但是很快因为SVM等核方法的诞生而黯然失色。这是因为传统的BP神经网络有几个重大的缺陷。</p><p>(1) 首先是原理上的缺陷：BP神经网络仍然是有监督的传统机器学习方法，遵循着以下思路。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5e67c599ef0dea0aa873801d03b82ac4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"189\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5e67c599ef0dea0aa873801d03b82ac4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;189&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"189\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5e67c599ef0dea0aa873801d03b82ac4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5e67c599ef0dea0aa873801d03b82ac4_b.jpg\"/></figure><p>也就是说，不过是在最后面将SVM或者其他分类器换成神经网络，在大部分情况下其实没有什么优势，甚至增加了问题的复杂度。</p><p>提取的特征虽然是研究者们经过反复实验证明有效的特征，但仍然会一定程度上丢失了图像中的结构信息，从而丢失了一些对旋转扭曲等的不变性。而且要求输入的大小是固定的。为了学习到如偏移等微小的变化，需要有足够多的参数和足够多丰富的样本，最终学习到的权重，很可能在不同的位置处还会有非常相似的权重。</p><p>有人可能会说，直接把图像作为输入而不提取特征行不行？请接着往下看。</p><p>(2) 再一个就是结构上的缺陷：参数巨多，丢失空间信息。</p><p>全连接神经网络从BP算法提出开始，发展于90年代，那时候的计算机属于CPU时代，根本就无法撑起海量参数的计算。</p><p>如果一个隐藏层特征图像大小为100*100，输入层的特征图像大小为100*100，这意味着学习这一层需要100*100*100*100=10^8的参数。如果以32位的浮点数进行存储，就需要4*108的字节的存储量，约等于400MB的参数量。仅仅这样的一个网络层，其模型参数量已经超过了AlexNet网络的参数量，而100*100的特征图像分辨率，已经低于很多任务能够成功解决的下限。除了计算过程中需要存储的海量的参数，还有海量的计算，这些都超过了当时硬件的能力，因此大大限制了网络的大小，尤其是对于一些大的图像输入。</p><h2><b>7 为什么是卷积神经网络</b></h2><p>不管是历史局限性也好，还是神经网络有种种毛病，总之80年代后的20年间它不是主流。</p><p>不过在上个世纪90年代研究神经网络的学者们没有停止，经典的诸如LeNet5这样的网络被提出。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"320\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;320&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"320\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_b.jpg\"/></figure><p>为什么是卷积神经网络呢？首先自然是要知道什么是卷积神经网络。</p><p><b>(1)，什么是卷积？</b></p><p>卷积在工程和数学上有非常多的应用，在信号处理领域中，任意一个线性系统的输出，就是输入信号和系统激励函数的卷积。放到数字图像处理领域，卷积操作一般指图像领域的二维卷积。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a01fc54fac00223896a622a66fb6d343_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-a01fc54fac00223896a622a66fb6d343_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-a01fc54fac00223896a622a66fb6d343_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a01fc54fac00223896a622a66fb6d343_b.jpg\"/></figure><p>一个二维卷积的案例如上，在图像上滑动，取与卷积核大小相等的区域，逐像素做乘法然后相加。</p><p>例如原始图像大小是5*5，卷积核大小是3*3。首先卷积核与原始图像左上角3*3对应位置的元素相乘求和，得到的数值作为结果矩阵第一行第一列的元素值，然后卷积核向右移动一个单位（即步长stride为1），与原始图像前三行第2、3、4列所对应位置的元素分别相乘并求和，得到的数值作为结果矩阵第一行第二列的元素值，以此类推。</p><p>故卷积就是：一个核矩阵在一个原始矩阵上从上往下、从左往右扫描，每次扫描都得到一个结果，将所有结果组合到一起得到一个新的结果矩阵。</p><p>注意这里我们不区分卷积和互相关，它们的区别只在于权重算子是否进行了翻转。之所以不重视，是因为在机器学习中，卷积核是否翻转，并不影响算法学习。</p><p><b>(2)，为什么要用卷积来学习呢？</b></p><p>图像都是用方形矩阵来表达的，学习的本质就是要抽象出特征，以边缘检测为例。它就是识别数字图像中亮度变化明显的点，这些点连接起来往往是物体的边缘。</p><p>传统的边缘检测常用的方法包括一阶和二阶导数法，本质上都是利用一个卷积核在原图上进行滑动，只是其中各个位置的系数不同，比如3*3的sobel算子计算x方向的梯度幅度，使用的就是下面的卷积核算子。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9554b8ee595b006ddcaff17dc8a72126_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"230\" data-rawheight=\"152\" class=\"content_image\" width=\"230\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;230&#39; height=&#39;152&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"230\" data-rawheight=\"152\" class=\"content_image lazy\" width=\"230\" data-actualsrc=\"https://pic3.zhimg.com/v2-9554b8ee595b006ddcaff17dc8a72126_b.jpg\"/></figure><p>如果要用sobel算子完成一次完整的边缘检测，就要同时检测x方向和y方向，然后进行融合。这就是两个通道的卷积，先用两个卷积核进行通道内的信息提取，再进行通道间的信息融合。</p><p><b>这就是卷积提取特征的本质，而所有基于卷积神经网络来学习的图像算法，都是通过不断的卷积来进行特征的抽象，直到实现网络的目标。</b></p><p><b>(3)，卷积神经网络的优势在哪？</b></p><p>前面说了全连接神经网络的原理和结构上的缺陷，而这正好是卷积的优势。</p><p>(1) 首先是学习原理上的改进，卷积神经网络不再是有监督学习了，不需要从图像中提取特征，而是直接从原始图像数据进行学习，这样可以最大程度的防止信息在还没有进入网络之前就丢失。</p><p>(2) 另一方面是学习方式的改进。前面说了全连接神经网络一层的结果是与上一层的节点全部连接的，100×100的图像，如果隐藏层也是同样大小（100*100个）的神经元，光是一层网络，就已经有 10^8 个参数。要优化和存储这样的参数量，是无法想象的，所以经典的神经网络，基本上隐藏层在一两层左右。而卷积神经网络某一层的结点，只与上一层的一个图像块相连。</p><p>用于产生同一个图像中各个空间位置像素的卷积核是同一个，这就是所谓的<b>权值共享</b>。对于与全连接层同样多的隐藏层，假如每个神经元只和输入10×10的局部patch相连接，且卷积核移动步长为10，则参数为：100×100×10×10，降低了2个数量级。</p><p>又能更好的学习，参数又低，卷积神经网络当然是可以成功了。</p><h2><b>8 卷积神经网络的核心基础概念</b></h2><p>在卷积神经网络中，有几个重要的基本概念是需要注意的，这在网络结构的设计中至关重要。</p><p>(1) 感受野</p><p>直观上讲，感受野就是视觉感受区域的大小。在卷积神经网络中，感受野是CNN中的某一层输出结果的一个元素对应输入层的一个映射，即feature map上的一个点所对应的输入图上的区域，具体示例如下图所示。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-cb31879eec0cd5c5cf2e9d22c02256b6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"665\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-cb31879eec0cd5c5cf2e9d22c02256b6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;665&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"665\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-cb31879eec0cd5c5cf2e9d22c02256b6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-cb31879eec0cd5c5cf2e9d22c02256b6_b.jpg\"/></figure><p>如果一个神经元的大小是受到上层N*N的神经元的区域的影响，那么就可以说，该神经元的感受野是N*N，因为它反映了N*N区域的信息。在上图conv2中的像素点5，是由conv1的2*2的区域计算得来，而该2*2区域，又是由raw image中5*5的区域计算而来，所以，该像素的感受野是5*5。可以看出感受野越大，得到的全局信息越多。在物体分割，目标检测中这是非常重要的一个参数。</p><p>(2) 池化</p><p>有了感受野再来解释池化（pooling）也很简单，上图的raw image到conv1，再到conv2，图像越来越小。每过一级就相当于一次降采样，这就是池化。池化可以通过步长不为1的卷积实现，也可以通过pool直接插值采样实现，本质上没有区别，只是权重不同。</p><p>通过卷积获得了特征之后，下一步则是用这些特征去做分类。理论上讲，人们可以把所有解析出来的特征关联到一个分类器，例如softmax分类器，但计算量非常大，并且极易出现过度拟合（over-fitting）。而池化层则可以对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征。</p><p>一般而言池化操作的池化窗口都是不重叠的，所以池化窗口的大小等于步长stride。如下图所示，采用一个大小为2*2的池化窗口，max pooling是在每一个区域中寻找最大值，这里的stride=2，最终在原特征图中提取主要特征得到右图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c36f8f93011e6ec784e853c71c1c22ab_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c36f8f93011e6ec784e853c71c1c22ab_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;312&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c36f8f93011e6ec784e853c71c1c22ab_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c36f8f93011e6ec784e853c71c1c22ab_b.jpg\"/></figure><p>除此之外，还有卷积核的大小，卷积的步长，通道的边界填充值等等，都是很好理解的基本概念，有一些以后会进行更加详细的剖析。</p><p>这一次就说到这，希望大家从此对神经网络和卷积神经网络(CNN)的基础概念不再有疑问。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/57258501", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 17, 
            "title": "【AI初识境】近20年深度学习在图像领域的重要进展节点", 
            "content": "<p>这是专栏《AI初识境》的第3篇文章。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>这是本系列的最后一篇非技术文章，我们总结一下深度学习技术在图像领域的重要历史性节点，本来打算语音，自然语言处理一起的，文章太长以后再谈。</p><p>                                                                                                                         作者&amp;编辑 | 言有三</p><h2><b>1 前深度学习时代</b></h2><p>从早期的全连接神经网络到卷积神经网络CNN，跨度超过半个世纪，我们在上一期文章中进行过回顾，大家感兴趣的可以回过头去看。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a><br/></p><p>几个重要的节点是：</p><p>1943年：MP模型的提出。</p><p>1960～1980年：视觉机制的发现。</p><p>1979年：Neocognitron的提出，卷积神经网络的萌芽。</p><p>1986年：反向传播算法被用于神经网络的优化并开始流行，同期动量算法提出被用于加速SGD。</p><p>1990年：TDNN模型，卷积神经网络被用于语音识别。</p><p>1992年：Max-pooling被提出，此后成为卷积神经网络标准组件。</p><p>1997年：LSTM被提出，促进了语音，自然语言处理等领域等发展。</p><p>1998年：LeNet5和MNIST数据集被提出和整理，两者可以说各自是卷积神经网络和图像数据集的“Hello World”，总会被拿出来说一说。</p><p>所谓深度学习，是以人工神经网络为基本架构的特征学习方法，涵盖监督学习，无监督学习，半监督学习，增强学习等，模型结构以<b>卷积神经网络</b>为代表，它不仅被用于图像，也被用于语音，自然语言处理等各种领域。</p><h2><b>2 深度学习时代</b></h2><p>以2006年为分水岭，下面尽量挑重点的，在学术界和工业界有重大意义，同时又广为人知的来说。</p><p>2006年Hinton等人在science期刊上发表了论文“Reducing the dimensionality of data with neural networks”，揭开了新的训练深层神经网络算法的序幕。利用无监督的RBM网络来进行预训练，进行图像的降维，取得比PCA更好的结果，<b>通常这被认为是深度学习兴起的开篇</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c78308031a3a18690a409148f67c7117_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"908\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c78308031a3a18690a409148f67c7117_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;908&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"908\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c78308031a3a18690a409148f67c7117_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c78308031a3a18690a409148f67c7117_b.jpg\"/></figure><p>2006年，<b>NVIDIA推出CUDA</b>，GPU被用于训练卷积神经网络，是当时的CPU的训练速度的四倍。到现在，GPU是研发强大算法必备的条件，这也是大公司屡屡取得突破而小公司只能亦步亦趋跟随的一个很重要的原因。NVIDIA的GeForce系列，搞深度学习的谁还没有呢？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-3f605d32a0b4fd6aed37c65326d34eff_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"437\" class=\"origin_image zh-lightbox-thumb\" width=\"700\" data-original=\"https://pic4.zhimg.com/v2-3f605d32a0b4fd6aed37c65326d34eff_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;700&#39; height=&#39;437&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"437\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"700\" data-original=\"https://pic4.zhimg.com/v2-3f605d32a0b4fd6aed37c65326d34eff_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-3f605d32a0b4fd6aed37c65326d34eff_b.jpg\"/></figure><p>2006～2009年，在图像MNIST数据集，语音TIMIT数据集以及一些垂直领域的小比赛比如TRECVID也取得了不错的进展，但是还算不上突破性的，所以也不怎么为人所知。</p><p>2009年，<b>CIFAR10和CIFAR100数据集</b>被整理。由于MNIST是一个灰度图像数据集，而大部分现实的任务为彩色图像，所以Alex Krizhevsky等学者从TinyImage数据集中整理出了CIFAR10和CIFAR100。与MNIST一样CIFAR10数据集也有60000张图像，不过图像为彩色。图像大小是32×32，分为10个类，每类6000张图。其中50000张用于训练，另外10000用于测试。CIFAR100则分为100个类，每一类600张图像。</p><p>这两个数据集与MNIST一样，在评测方法时非常常见。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7c9444f4d2c203bcac727151372dcfb1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"476\" data-rawheight=\"368\" class=\"origin_image zh-lightbox-thumb\" width=\"476\" data-original=\"https://pic2.zhimg.com/v2-7c9444f4d2c203bcac727151372dcfb1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;476&#39; height=&#39;368&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"476\" data-rawheight=\"368\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"476\" data-original=\"https://pic2.zhimg.com/v2-7c9444f4d2c203bcac727151372dcfb1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7c9444f4d2c203bcac727151372dcfb1_b.jpg\"/></figure><p>2009年，<b>ImageNet数据集</b>被整理，并于次年开始每年举办一次比赛。ImageNet 数据集总共有1400多万幅图片，涵盖2万多个类别，为计算机视觉领域做出了巨大的贡献，至今我们仍然使用着Imagenet来评估算法，以及预训练其他任务的模型。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-2ff685afa60895a1f87b429436592e97_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"799\" data-rawheight=\"300\" class=\"origin_image zh-lightbox-thumb\" width=\"799\" data-original=\"https://pic4.zhimg.com/v2-2ff685afa60895a1f87b429436592e97_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;799&#39; height=&#39;300&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"799\" data-rawheight=\"300\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"799\" data-original=\"https://pic4.zhimg.com/v2-2ff685afa60895a1f87b429436592e97_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-2ff685afa60895a1f87b429436592e97_b.jpg\"/></figure><p>2009年前后几年时间，属于<b>融汇贯通各种技术，数据和装备</b>，典型的蓄力阶段，辅以小数据集和若干比赛的突破。</p><p>2011年，CNN以0.56%的错误率赢得了IJCNN 2011比赛并超过了人眼，这是一场交通标志的识别比赛，研究者开始对深度学习在自动驾驶中的应用前景展现出浓厚的兴趣，毕竟在上个世纪90年代无人车的研究就已经开始了。现在无人车是非常大的一个应用前景。</p><p>2011年，Glorot等人提出<b>ReLU激活函数</b>，有效地抑制了深层网络的梯度消失问题，现在最好的激活函数都是来自于ReLU家族，简单而有效。</p><p>2012年，经典书籍<b>《大数据时代》</b>出版，作者维克托•迈尔•舍恩伯格在书中指出大数据时代来了，<b>我们应该放弃对因果关系的追求，而关注相关关系，从“为什么”开始转变到“是什么”</b>，这不就是统计学习人工智能学派的基础工具深度学习最擅长做的吗。</p><p>也就是从那个时候开始，人们大喊，大数据来了，一时之间，数据科学家，数据挖掘工程师成为热门。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3e0ad997d7f3fbb33e81252b9a4b2d86_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"360\" data-rawheight=\"499\" class=\"content_image\" width=\"360\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;360&#39; height=&#39;499&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"360\" data-rawheight=\"499\" class=\"content_image lazy\" width=\"360\" data-actualsrc=\"https://pic3.zhimg.com/v2-3e0ad997d7f3fbb33e81252b9a4b2d86_b.jpg\"/></figure><p>2012年，Hinton的学生Alex Krizhevsky提出<b>AlexNet网络</b>，以低于第2名10%的错误率赢得了ImageNet竞赛。当时Alex Krizhevsky使用了两块显卡GTX580，花了6天时间才训练出AlexNet，我相信如果有更多的资源，AlexNet一定是一个更好的AlexNet。</p><p>2013年Hinton的学生Zeiler和Fergus在研究中利用反卷积技术引入了神经网络的可视化，提出了zfnet，对网络的中间特征层进行了可视化，为研究人员检验不同特征激活及其与输入空间的关系成为了可能，慢慢地大家也开始都关注起深度学习的作用机制。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-aed1bf5281df91a73e6b9514b43b68fd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"665\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-aed1bf5281df91a73e6b9514b43b68fd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;665&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"665\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-aed1bf5281df91a73e6b9514b43b68fd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-aed1bf5281df91a73e6b9514b43b68fd_b.jpg\"/></figure><p>2013年，Ross Girshick等人提出了<b>目标检测模型RCNN</b>，开创了CNN用于目标检测的基准之一。随后研究者针对该系列提出Fast RCNN，Faster RCNN等等。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a577f29a87fb3cc2a2525ab5e39b4f77_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"398\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-a577f29a87fb3cc2a2525ab5e39b4f77_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;398&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"398\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-a577f29a87fb3cc2a2525ab5e39b4f77_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a577f29a87fb3cc2a2525ab5e39b4f77_b.jpg\"/></figure><p>2014年，<b>GoogLeNet和VGGNet</b>分别被提出，获得ImageNet分类赛的冠亚军。VGGNet很好的展示了如何在先前网络架构的基础上通过简单地增加网络层数和深度就可以提高网络的性能，GoogleNet模型架构则提出了Inception结构，拓宽神经的宽度，成为了计算效率较高的深层模型基准之一。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-422ab6f83cd2c37a99cb9e7527d8dd7a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"876\" data-rawheight=\"431\" class=\"origin_image zh-lightbox-thumb\" width=\"876\" data-original=\"https://pic3.zhimg.com/v2-422ab6f83cd2c37a99cb9e7527d8dd7a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;876&#39; height=&#39;431&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"876\" data-rawheight=\"431\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"876\" data-original=\"https://pic3.zhimg.com/v2-422ab6f83cd2c37a99cb9e7527d8dd7a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-422ab6f83cd2c37a99cb9e7527d8dd7a_b.jpg\"/></figure><p>2014年，无监督学习网络<b>GAN</b>横空出世，独立成了一个新的研究方向，被LeCun誉为下一代深度学习，此后GAN在各大领域，尤其是图像领域不断“建功立业”，并与各类CNN网络结构进行了融合。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d7cac881fb79e0a3962bdc68add7f950_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"471\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d7cac881fb79e0a3962bdc68add7f950_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;471&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"471\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d7cac881fb79e0a3962bdc68add7f950_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d7cac881fb79e0a3962bdc68add7f950_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>2015年，<b>ResNet</b>获得了ImageNet2012分类任务冠军，以3.57%的错误率表现超过了人类的识别水平，并以152层的网络架构创造了新的模型记录，自此残差连接在CNN的设计中随处可见。</p><p>2015年，<b>全卷积网络Fully Convolutional Networks</b>被提出用于图像分割，自此图像分割领域也即迎来大爆发。</p><p>2014年，Google启动<b>AlphaGo</b>的研究，2015年10月AlphaGo击败欧洲围棋冠军樊麾成为第一个无需让子即可击败围棋职业棋手的计算机围棋程序。2016年3月，AlphaGo在一场世界瞩目的比赛中4:1击败顶尖职业棋手李世石，2017年5月23至27日在乌镇围棋峰会上，AlphaGo和世界第一棋手柯洁比试全胜。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e9812539fdcb812ee56b8d64b6e88d15_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"851\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb\" width=\"851\" data-original=\"https://pic2.zhimg.com/v2-e9812539fdcb812ee56b8d64b6e88d15_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;851&#39; height=&#39;476&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"851\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"851\" data-original=\"https://pic2.zhimg.com/v2-e9812539fdcb812ee56b8d64b6e88d15_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e9812539fdcb812ee56b8d64b6e88d15_b.jpg\"/></figure><p><b>AlphaGo的成功，对人工智能的普及工作意义非常深远</b>，让不仅是从业者，外行人也开始领略到人工智能的强大，而背后就有卷积神经网络的功劳。</p><p>此后便是卷积神经网络在计算机视觉各大领域攻城略地，无往而不胜。关于都有哪些方向，可以参考这个。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a> </p><p>而各种各样的卷积神经网络架构被提出，可参见我们之前的一个总结。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031450%26idx%3D1%26sn%3D3f7f159458e5f1621531ee107be11a98%26chksm%3D8712bd67b0653471c052e32b9d18a26f4d6a07852f56b50f6589b3baa7a46e1e44f302204a4e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】总结12大CNN主流模型架构设计思想</a></p><p>从上面的这些历史可以看出，很多重要的研究其实都是同一时期出现，而最后为人所知虽然有先后的顺序，但是金子迟早会发光。</p><p>这也不仅让我们要思考，接下来几年里大放异彩的，是现在哪些刚刚初出茅庐却还没有名噪天下的东西呢？</p><p class=\"ztext-empty-paragraph\"><br/></p><p>重要的节点通常都承前启后，不管是作为谈资，还是设身处地地站在当时的节点来思考一番，都是受益良多的。</p><p>本文是有史以来罕见的短文，一是为了给大家留出更多的思考空间，另一方面也是希望大家认真去翻翻我们以前的文章，信息量很大。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }, 
                {
                    "tag": "图像处理", 
                    "tagLink": "https://api.zhihu.com/topics/19556376"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/58188430", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 33, 
            "title": "【AI-1000问】为什么深度学习图像分类的输入多是224*224", 
            "content": "<h2><b>写在前边的通知</b></h2><p>大家好，今天这又是一个新专栏了，名叫《有三AI 1000问》，顾名思义，就是以问题为主了！</p><p>那我们这个新专栏会有什么特色呢？主要从<b>内容选择，目标受众，创作风格</b>三个方面来讲述。</p><p><b>1、内容选择</b></p><p>因为我们有综述专栏，有各种垂直领域的非常详细的文章，所以从内容选择上，我们这一个专栏不会选择那些“大”问题，不会选择需要长篇分析的问题，也不会选择需要很强的实践操作的问题。</p><p>内容选择的标准是：</p><ul><li>技术相关</li><li>足够聚焦</li><li>容易被忽视</li><li>普通但是不简单</li><li>可以引申很多思考</li></ul><p>不会入选的内容比如：“目标检测的最新进展”，“tensorflow的最新API”，“Mask RCNN文章阅读”等等之类的文章。</p><p>会入选的内容比如：“为什么图像分类输入大小多是224*224”，“为什么卷积神经网络要使用池化”。</p><p><b>2、目标受众</b></p><p>我认为未来机器学习技术/AI技术是每一个人都可以掌握，使用的技术，因此，我们这一个专栏不再只是面向从事相关工作的朋友，不会像其他专栏的文章那样对基础要求高。</p><p>目标受众包括：</p><ul><li>AI领域从业技术人员</li><li>其他计算机领域从业人员</li><li>AI技术业余爱好者</li></ul><p><b>3、创作风格</b></p><p>这一个专栏以引导思考，普及知识为主，希望减轻阅读负担，因此不会像其他系列文章那样清晰地划分段落，也会适当地降低内容的深度。</p><p>创作风格是：</p><ul><li>不严格划分小节</li><li>平衡内容深度和可阅读性</li></ul><p>好了，具体内容就参考我们的第一期吧，希望你喜欢。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a8b5fefe6eda2d847523ed4cf91bac48_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"900\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic1.zhimg.com/v2-a8b5fefe6eda2d847523ed4cf91bac48_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"900\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic1.zhimg.com/v2-a8b5fefe6eda2d847523ed4cf91bac48_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a8b5fefe6eda2d847523ed4cf91bac48_b.jpg\"/></figure><p>为什么深度学习图像分类里的图片的输入大小都是224*224呢？</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1101246860030787584\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"为什么图像分类输入大小多是224\" data-poster=\"https://pic3.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1101246860030787584\"><img class=\"thumbnail\" src=\"https://pic3.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">为什么图像分类输入大小多是224<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1101246860030787584</span></span></a><p>做过图像分类项目或者看过文章的小伙伴们应该都知道，在论文中进行各类方法的比较时，要求使用同样的数据集。而为了公平的比较，网络的输入大小通常都是224*224的大小，那为什么呢？有同学思考过这个问题吗？</p><p>我们都知道，一个图像分类模型，在图像中经历了下面的流程。</p><p>从输入image-&gt;卷积和池化-&gt;最后一层的feature map-&gt;全连接层-&gt;损失函数层softmax loss。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4d2442d441786ff9dde2343dcfe7c3a6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"942\" data-rawheight=\"301\" class=\"origin_image zh-lightbox-thumb\" width=\"942\" data-original=\"https://pic3.zhimg.com/v2-4d2442d441786ff9dde2343dcfe7c3a6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;942&#39; height=&#39;301&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"942\" data-rawheight=\"301\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"942\" data-original=\"https://pic3.zhimg.com/v2-4d2442d441786ff9dde2343dcfe7c3a6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4d2442d441786ff9dde2343dcfe7c3a6_b.jpg\"/></figure><p>从输入到最后一个卷积特征feature map，就是进行信息抽象的过程，然后就经过全连接层/全局池化层的变换进行分类了，这个feature map的大小，可以是3*3，5*5，7*7等等。</p><p>解答1：在这些尺寸中，如果尺寸太小，那么信息就丢失太严重，如果尺寸太大，信息的抽象层次不够高，计算量也更大，所以7*7的大小是一个最好的平衡。</p><p>另一方面，图像从大分辨率降低到小分辨率，降低倍数通常是2的指数次方，所以图像的输入一定是7*2的指数次方。以ImageNet为代表的大多数分类数据集，图像的长宽在300分辨率左右。</p><p>解答2：所以要找一个7*2的指数次方，并且在300左右的，其中7*2的4次方=7*16=112，7*2的5次方等于7*32=224，7*2的6次方=448，与300最接近的就是224了。</p><p>这就是最重要的原因了，当然了对于实际的项目来说，有的不需要这么大的分辨率，比如手写数字识别MNIST就用32*32，有的要更大，比如细粒度分类。</p><p>今天的问题就到这里了，不知道，你有没有留意过<b>不同的输入大小对分类器性能的影响呢</b>？</p><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a> </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a></p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a></p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "图像识别", 
                    "tagLink": "https://api.zhihu.com/topics/19588774"
                }
            ], 
            "comments": [
                {
                    "userName": "王小二", 
                    "userLink": "https://www.zhihu.com/people/f6667623cf045e112fc9a30f995a9742", 
                    "content": "因为imagenet的数据集是这个分辨率[捂脸]", 
                    "likes": 3, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "哈哈哈😄", 
                            "likes": 0, 
                            "replyToAuthor": "王小二"
                        }
                    ]
                }, 
                {
                    "userName": "刘庆杰", 
                    "userLink": "https://www.zhihu.com/people/a516680e361a6aa85c155a64c9bedc32", 
                    "content": "<p>牵强？</p>", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "欢迎各抒己见", 
                            "likes": 0, 
                            "replyToAuthor": "刘庆杰"
                        }
                    ]
                }, 
                {
                    "userName": "jolinavy", 
                    "userLink": "https://www.zhihu.com/people/d4cc47b9949b5318949518f869c95152", 
                    "content": "你好，我是小白。请问如果不是224*224的分辨率，比它大的分辨率意味着要损失像素吗？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "不会的", 
                            "likes": 0, 
                            "replyToAuthor": "jolinavy"
                        }
                    ]
                }, 
                {
                    "userName": "奉奉奉", 
                    "userLink": "https://www.zhihu.com/people/ab3cafc7eb8d8e04b31623b4c4fd35c4", 
                    "content": "<p>我觉得其实是因为，有好几个著名的网络（例如VGG等）在ImageNet上训练，ImageNet数据是224×224的，所以这些网络的输入尺寸也是224×224。如果想迁移学习来提取特征，把分辨率调成224×224比较方便。</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "为什么著名网络这么选择呢？😬", 
                            "likes": 0, 
                            "replyToAuthor": "奉奉奉"
                        }, 
                        {
                            "userName": "奉奉奉", 
                            "userLink": "https://www.zhihu.com/people/ab3cafc7eb8d8e04b31623b4c4fd35c4", 
                            "content": "<p>嗯，我又想了想，觉得你说得有道理</p>", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "double22", 
                    "userLink": "https://www.zhihu.com/people/69e0dd3776f87ae0790ea9fad45eef04", 
                    "content": "7*7是个很好平衡，怎么理解", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "就是不大不小，作为卷积最后的特征抽象合适", 
                            "likes": 0, 
                            "replyToAuthor": "double22"
                        }
                    ]
                }, 
                {
                    "userName": "吴振彬", 
                    "userLink": "https://www.zhihu.com/people/448677cb0b2b50802220f2ebc652b1ac", 
                    "content": "不是说多个小的卷积核叠加在一起相比一个大的理论上连通性不变，但是降低参数个数与复杂度吗[好奇]只要用ReLU这种不怕梯度消失的激活函数，卷积核不是越小越好吗（最小3*3）", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "是的呢", 
                            "likes": 0, 
                            "replyToAuthor": "吴振彬"
                        }, 
                        {
                            "userName": "吴振彬", 
                            "userLink": "https://www.zhihu.com/people/448677cb0b2b50802220f2ebc652b1ac", 
                            "content": "那感觉这个7的解读有点过度解读的意思啊", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "徐仁干", 
                    "userLink": "https://www.zhihu.com/people/c3cc4f650f6e6904a540476950bdea0d", 
                    "content": "为什么是7*2的指数次方，7是哪儿来的？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "lna", 
                            "userLink": "https://www.zhihu.com/people/ff8f380e049ebbc5447834251d2a4b57", 
                            "content": "<p>7是最后的特征图大小，非卷积核大小，你可以反着推导到224x224。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "徐仁干"
                        }, 
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "同道", 
                            "likes": 0, 
                            "replyToAuthor": "lna"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/58188998", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 11, 
            "title": "【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？", 
            "content": "<p></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c9ff8d9faac5d29f2b88de55a0d1a886_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"900\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic3.zhimg.com/v2-c9ff8d9faac5d29f2b88de55a0d1a886_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;383&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"900\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic3.zhimg.com/v2-c9ff8d9faac5d29f2b88de55a0d1a886_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c9ff8d9faac5d29f2b88de55a0d1a886_b.jpg\"/></figure><p>为什么LeNet5倒数第二个全连接层维度为84？</p><a class=\"video-box\" href=\"https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1101247327242682368\" target=\"_blank\" data-video-id=\"\" data-video-playable=\"true\" data-name=\"为何LeNet5倒数第二fc层维度为84\" data-poster=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\" data-lens-id=\"1101247327242682368\"><img class=\"thumbnail\" src=\"https://pic1.zhimg.com/v2-d9b84c1d62eb65d6736293c907521900.png\"/><span class=\"content\"><span class=\"title\">为何LeNet5倒数第二fc层维度为84<span class=\"z-ico-extern-gray\"></span><span class=\"z-ico-extern-blue\"></span></span><span class=\"url\"><span class=\"z-ico-video\"></span>https://www.zhihu.com/video/1101247327242682368</span></span></a><p>相信大家也都知道LeNet5这个经典的卷积神经网络，它有3个全连接层，输出维度分别是120，84，10，不知道大家知不知道为什么倒数第2个全连接层的维度是84呢？</p><p>LeNet5的网络结构如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"320\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;320&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"320\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_b.jpg\"/></figure><p>作为一个用于手写数字识别的网络，它的最后输出是1*10的向量，而倒数第2层却不是我们熟悉的4096，1024，512这样的2的指数次幂的维度，而是84，那这是为什么呢。</p><p>解答：因为在计算机中字符的编码是ASCII编码，这些图是用7*12大小的位图表示的，也就是高宽比为7:12，如下图，选择这个大小可以用于对每一个像素点的值进行估计。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-af732b11d8167f1da34a38672b3f7600_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"858\" data-rawheight=\"446\" class=\"origin_image zh-lightbox-thumb\" width=\"858\" data-original=\"https://pic1.zhimg.com/v2-af732b11d8167f1da34a38672b3f7600_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;858&#39; height=&#39;446&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"858\" data-rawheight=\"446\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"858\" data-original=\"https://pic1.zhimg.com/v2-af732b11d8167f1da34a38672b3f7600_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-af732b11d8167f1da34a38672b3f7600_b.jpg\"/></figure><p>就这么简单，不过既然来了就多说两句吧。</p><p>上图显示了ASCII中的96个可打印字符，其中32是空格，不可见。</p><p>另外0～31以及127是控制字符/通信字符，控制字符如：LF（换行）、CR（回车）、DEL（删除）等；通信字符如：SOH（文头）、EOT（文尾）、ACK（确认）等，这两类字符是不可打印的。</p><p>是不是很粗暴的设定，居然跟位图的大小有关。通常我们现在设定全连接层的维度都会是2的指数次幂或者最终分类数，不知道你有没有见过一些其他的设定？不妨留言交流。</p><blockquote>往期AI1000问</blockquote><p>第一期：<a href=\"https://zhuanlan.zhihu.com/p/58188430\" class=\"internal\">【AI-1000问】为什么深度学习图像分类的输入多是224*224</a></p><p>第二期：<a href=\"https://zhuanlan.zhihu.com/p/58188998\" class=\"internal\">【AI-1000问】为什么LeNet5倒数第二个全连接层维度为84？</a></p><p>第三期：<a href=\"https://zhuanlan.zhihu.com/p/62530628\" class=\"internal\">【AI-1000问】为什么OpenCV存储的图像格式是BGR呢？</a></p><p>第四期：<a href=\"https://zhuanlan.zhihu.com/p/62531068\" class=\"internal\">【AI-1000问】机器学习和模式识别是什么关系？</a></p><p>第五期：<a href=\"https://zhuanlan.zhihu.com/p/62532501\" class=\"internal\">【AI-1000问】人脸的4个方向，你还分的清楚吗？</a></p><p>第六期：<a href=\"https://zhuanlan.zhihu.com/p/62533308\" class=\"internal\">【AI-1000问】你知道为什么GoogLeNet也被称为InceptionNet吗？</a></p><p>第七期：<a href=\"https://zhuanlan.zhihu.com/p/62533623\" class=\"internal\">【AI-1000问】softmax loss和交叉熵有什么关系？</a></p><p>第八期：<a href=\"https://zhuanlan.zhihu.com/p/62534373\" class=\"internal\">【AI-1000问】为什么信号有单位而且是dB？</a></p><p>第九期：<a href=\"https://zhuanlan.zhihu.com/p/62534577\" class=\"internal\">【AI-1000问】训练为什么要分测试集和验证集？</a></p><p>第十期：<a href=\"https://zhuanlan.zhihu.com/p/62535003\" class=\"internal\">【AI-1000问】为什么现在大家喜欢用3*3小卷积？</a> </p><p>第十一期：<a href=\"https://zhuanlan.zhihu.com/p/62893017\" class=\"internal\">【AI-1000问】为什么CNN中的卷积核一般都是奇数*奇数？</a></p><p>第十二期：<a href=\"https://zhuanlan.zhihu.com/p/62894764\" class=\"internal\">【AI-1000问】segmentation和matting有什么区别？</a></p><blockquote>此后的AI1000问，请移步知识星球《有三AI》</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-11d10b43893cde9fa4ddd94937e0f35a_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "图像识别", 
                    "tagLink": "https://api.zhihu.com/topics/19588774"
                }
            ], 
            "comments": [
                {
                    "userName": "litan", 
                    "userLink": "https://www.zhihu.com/people/adaa81a7dbbae1ef2c1ac4e6d03acf91", 
                    "content": "<p>什么是位图啊？</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "bmp", 
                            "likes": 0, 
                            "replyToAuthor": "litan"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/56679585", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 6, 
            "title": "【AI初识境】从3次人工智能潮起潮落说起", 
            "content": "<p>专栏《AI白身境》已经完结，今天开始这个系列的第二个专栏《AI初识境》。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>第一篇，我们就来说说人工智能的简单历史，通常来说业界公认包括三个重要的历史阶段。</p><p>                                                                                                                           作者&amp;编辑 | 言有三</p><h2><b>1 什么是智能</b></h2><p>智能，即Intelligence，那什么是智能呢？按照中国古代思想家荀子在《荀子·正名篇》的说法：“所以知之在人者谓之知，知有所合谓之智。所以能之在人者谓之能，能有所合谓之能”。</p><p>其中的“智”指进行认识活动的某些心理特点，“能”则指进行实际活动的某些心理特点。我的理解就是，<b>能是智的具体表达形式</b>，当然也有学者将智和能作为一个整体的，《论衡·实知篇》中就认为<b>人才就是具有一定智能水平的人</b>。</p><p>更加科学的定义是在霍华德·加德纳的多元智能理论中，它将人类的智能分成七种能力：</p><ul><li>(1) 语言 (Verbal/Linguistic) </li><li>(2) 逻辑 (Logical/Mathematical) </li><li>(3) 空间 (Visual/Spatial) </li><li>(4) 肢体运作 (Bodily/Kinesthetic) </li><li>(5) 音乐 (Musical/Rhythmic) </li><li>(6) 人际 (Inter-personal/Social) </li><li>(7) 内省 (Intra-personal/Introspective)</li></ul><p>这基本覆盖了现在人工智能的研究领域，包括计算机视觉，语音识别，自然语言处理等。</p><p>从生物学上来说智能体是有两种的，有生命的和没有生命的，人显然就是有生命的，而人工智能，自然研究的是没有生命体的，但是能够表现出生命体的智能的，因此才叫<b>“人工”</b>智能，或者理解为人造智能吧。<br/></p><h2><b>2 图灵与机器智能</b></h2><p>科技发展到一个节点后，就有人思考如何用真正的生命体外的东西来模拟人类的智能，从模拟大脑的运作方式开始显然是最合适的。</p><p>在1943年的时候麦卡洛克-皮茨(MuCulloch和Pitts)就提出了MP模型，即最早的基于阈值逻辑的神经网络模型，用于模拟人脑神经元，它已经是感知器的原型了，开创了人工神经网络研究的时代。</p><p>当然，人工智能是一个比神经网络更广的范畴，它的理论先驱代表性人物是天才科学家<b>图灵</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-30e665b9e199b0d65f7bc8943d43edcf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"595\" class=\"origin_image zh-lightbox-thumb\" width=\"474\" data-original=\"https://pic4.zhimg.com/v2-30e665b9e199b0d65f7bc8943d43edcf_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;474&#39; height=&#39;595&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"595\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"474\" data-original=\"https://pic4.zhimg.com/v2-30e665b9e199b0d65f7bc8943d43edcf_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-30e665b9e199b0d65f7bc8943d43edcf_b.jpg\"/></figure><p>艾伦·图灵在1950年的论文《Computing Machinery and Intelligence》中提出了图灵测试，在图灵测试中，人类测试者与一台机器被隔开，一个人类测试员通过文字向被测试者随意提问。进行多次测试后，如果测试者不能确定出被测试者是人还是机器，那么这台机器就通过了测试，并被认为具有人类智能，它在数十年间被当作机器智能的测试标准，深刻影响了人工智能的发展。</p><p>当然图灵测试不需要限于对话，其他的一些人类活动也可以。目前在很多的领域里机器已经通过图灵测试，比如下棋。</p><p>很多学者认为，图灵在1948年的时候在英国国家物理实验室内部做过的一个题为“智能机器”的报告是更早的机器智能的源头，在这个报告中提出了“embodied intelligence”和 “disembobied intelligence”，即肉体智能和无肉体智能。肉体智能指的是需要身体来完成活动的，比如人形机器人，而无肉体智能则可以脱离形体，比如下棋，进行语言对话等。但是由于报告是保密的，因此我们还是认为1950年的图灵测试是真正意义上提出机器智能概念。</p><p>为了纪念图灵的贡献，美国计算机协会在1966年设立了图灵奖，这成为了计算机科学领域的“诺贝尔奖”，图灵也被称为计算机科学之父、人工智能之父。</p><h2><b>3 冯诺伊曼与类脑计算</b></h2><p>图灵提出了机器智能的概念，那怎么实现呢？现在大家都知道了，使用计算机，或者更通用的说法是电脑。</p><p>冯·诺依曼（John von Neumann）正是计算机之父。在智能这个研究课题上，图灵走理论路线，而冯·诺伊曼更偏重工程路线，它们在普林斯顿大学期间有接触，比图灵大10岁的冯诺伊曼对前者还有一定的知遇之恩。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c8c8674e7cb6e3bf651ae8c86b2c2193_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"651\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic4.zhimg.com/v2-c8c8674e7cb6e3bf651ae8c86b2c2193_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;651&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"651\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic4.zhimg.com/v2-c8c8674e7cb6e3bf651ae8c86b2c2193_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c8c8674e7cb6e3bf651ae8c86b2c2193_b.jpg\"/></figure><p>冯诺伊曼的贡献很多，这里我们只说其在计算机方面的贡献，它对世界上第一台电子计算机<b>ENIAC</b>（电子数字积分计算机）的设计提出过建议，这体现在1945年他牵头起草的EDVAC（Electronic Discrete Variable Automatic Computer）中，翻译过来是“存储程序通用电子计算机方案”。这对计算机的设计有决定性的影响，特别是计算机的结构，包括<b>存储程序以及二进制编码</b>等。这个报告中最核心的概念是“存储程序(Stored Program)”，老冯将其原创给予了图灵，认为存储程序其实就是通用图灵机，可见老冯不止是研究做得好，人品更是棒。</p><p>所谓存储程序：就是把运算程序存在机器的存储器中，程序设计员只需要在存储器中寻找运算指令，机器就会自行完成计算，这样，就不必对每个问题都重新编程，从而加快了程序设计的流程。</p><p>当然在EDVAC中还包括了<b>随机寻址</b>以及<b>寄存器</b>等原创思想。鉴于冯·诺依曼在发明电子计算机中所起的关键性作用，他被誉为“计算机之父”。冯诺伊曼的研究被整理在《计算机和人脑》中，感兴趣的读者可以去读中译本。</p><h2><b>4 达特茅斯会议</b></h2><p>图灵和冯·诺伊曼为机器智能奠基，而人工智能正式成为一个学科被广泛研究，应该起源于1956年的<b>达特茅斯会议</b>，会议的参与者包括了达特茅斯学院的<b>约翰·麦卡锡</b>（John McCarthy）、哈佛大学的<b>马文·闵斯基</b>（Marvin Minsky，人工智能与认知学专家）、贝尔电话实验室的<b>克劳德·香农</b>（Claude Shannon，信息论的创始人）、<b>艾伦·纽厄尔</b>（Allen Newell，计算机科学家）、<b>赫伯特·西蒙</b>（Herbert Simon，诺贝尔经济学奖得主），塞弗里奇(Oliver Selfridge)等科学家，在两个多月的会议中它们讨论了用机器来模仿人类学习以及其他方面的智能这个课题。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-811ae4d7848c985cf2af48a7387ea75f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"834\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-811ae4d7848c985cf2af48a7387ea75f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;834&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"834\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-811ae4d7848c985cf2af48a7387ea75f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-811ae4d7848c985cf2af48a7387ea75f_b.jpg\"/></figure><p>虽然会议最后没有什么实质性的结论，但是会议正式提出了一个新学科， 即<b>“Artificial Intelligence”</b>，翻译过来就是人工智能。可以说一个学科的正式诞生，才是为公众所知的开始。</p><p>我们再来说一下参会的这些人和人工智能的关系。</p><p>1. 约翰·麦卡锡(John McCarthy)，开发了程序语言Lisp(List Processing language)，成为第一个最流行的AI研究程序语言，他还提出了计算机分时(time-sharing)的概念。正是约翰·麦卡锡提出了“Artificial Intelligence”这个概念(虽然他自己老年说是听来的但是最后也无法证实来源)，因此也被称为“人工智能之父”(我觉得人工智能之母更加合适，毕竟图灵才是思想之源，而麦卡锡同志是一个养育者)，他在1971年获得了图灵奖。</p><p>2. 马文·闵斯基，他在1951年24岁的时候和迪恩·埃德蒙(Dean Edmunds)在普林斯顿大学建立了第一个神经网络机器SNARC(Stochastic Neural Analog ReinforcementCalculator)，这是第一个人工神经网络，用3000个真空管模拟出40个神经元的神经信号传递，由于他的一系列奠基贡献，在1969年获得了图灵奖。</p><p>3. 克劳德·香农(Claude Shannon)，在1950年发表了《Programming a Computer for Playing Chess》，这篇论文第一次开始关注计算机象棋程序的开发。作为信息科学领域的鼻祖，与图灵并驾齐驱的香农自然是不需要图灵奖了，毕竟还有通讯领域的最高奖香农奖。</p><p>4. 赫伯特·西蒙(Herbert Simon)和艾伦·纽厄尔(Allen Newell)，他们在1956年开发了&#34;LogicTheorist&#34;，是世界上第一个AI项目，证明了在罗素和怀特海的数学教科书《数学原理》第二章的52个定理中的38个，并找到了比教材中更加优美的证明，这开创了名为“搜索推理”的方法，这是人工智能的符号派的代表性成果。他们在1975年一起获得了图灵奖。</p><p>之后研究AI的一些科学家也获得了图灵奖，1994年Edward Feigenbaum)和Raj Reddy、2010年Leslie Valiant、2011年Judea Pearl。正是有了这些科学家的头脑风暴，才有了今天的这门学科，改变了人类的生活方式，向他们致敬。</p><h2><b>5 第一次浪潮(1956-1974)</b></h2><p>在人工智能学科诞生后，赫伯特·西蒙(Herbert Simon)乐观地预测20年内诞生完全智能的机器，当然这没有发生，但是带来了第一个人工智能的研究热潮。</p><p>1963年，美国国防部高级研究计划局(DARPA)给麻省理工学院、卡内基梅隆大学的人工智能研究組投入了200万美元的研究经费，开启了Project MAC(Mathematics and Computation)，这个项目是麻省理工学院计算机科学与人工智能实验室的前身，培养了最早期的计算机科学与人工智能人才，也有了一些成果。</p><p>在1964～1966年间约瑟夫·维森班(loseph Weizenbaum )开发了ELIZA，这是第一个自然语言对话程序，通过简单的模式匹配和对话规则进行任何主题的英文对话。不过他开发程序只是为了证明机器与人的交流很肤浅，后来成为了批判人工智能研究大军的一员。</p><p>早稻田大学在1967年到1972年间则发明了第一个人形机器人Wabot-1，不仅可以进行简单的对话，还能够完成在室内走动和抓取物体的动作，这就涉及到了计算机视觉的研究。并且在1980年更新到了二代版本Wabot-2，增加了阅读乐谱和演奏普通难度的电子琴的功能。研发该机器人的加藤一郎也被赋予<b>“人形机器人之父”</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a54901ecdeda9c7081778b9182adc6e2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"450\" data-rawheight=\"677\" class=\"origin_image zh-lightbox-thumb\" width=\"450\" data-original=\"https://pic3.zhimg.com/v2-a54901ecdeda9c7081778b9182adc6e2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;450&#39; height=&#39;677&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"450\" data-rawheight=\"677\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"450\" data-original=\"https://pic3.zhimg.com/v2-a54901ecdeda9c7081778b9182adc6e2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a54901ecdeda9c7081778b9182adc6e2_b.jpg\"/></figure><p>从70年代开始，由于计算能力有限，而科学家一开始的预测又过于乐观，导致研究和期望产生了巨大的落差，公众热情和投资削减，70年代中期进入第一次人工智能的研究进入低谷。<br/></p><h2><b>6 第二次浪潮(1980-1987)</b></h2><p><b>专家系统和人工神经网络</b>的兴起，带来了第二波浪潮。</p><p>所谓专家系统，即基于特定的规则来回答特定领域的问题的程序，在1964年费根鲍姆(Edward Feigenbaum)等人在斯坦福大学研究了第一个专家系统DENDRAL，能够自动做决策，解决有机化学问题，因此他也被成为<b>“专家系统之父”</b>。</p><p>在1970年，斯坦福大学的科学家们开发了专家系统MYCIN，通过600多条人工编写的规则识别引发严重传染病的细菌，推荐抗生素。</p><p>在1980年，卡内基梅隆大学开发了XCON程序，这是一套基于规则开发的专家系统，帮助迪吉多公司的客户自动选择计算机组件，为其每年节省了4000万美元。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c4928cbe02258589e809337672205282_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"308\" data-rawheight=\"608\" class=\"content_image\" width=\"308\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;308&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"308\" data-rawheight=\"608\" class=\"content_image lazy\" width=\"308\" data-actualsrc=\"https://pic3.zhimg.com/v2-c4928cbe02258589e809337672205282_b.jpg\"/></figure><p>在巨大的商业价值的刺激下，工业界又兴起了对人工智能的热情。在这样的背景下，1982年日本通商产业省启动了“第五代计算机”计划，期望通过大规模的并行计算来建造通用人工智能平台，不过10年间耗资500亿日元后还是未能达到预期目标。休伊特(Carl Hewitt)认为大部分五代机的工作只是试着用逻辑程序去解决其他手段已经解决的问题。</p><p>1984在年度AAAI会议上，罗杰·单克(Roger Schank)和马文·明斯基(Marvin Minsky) 发出警告，认为“Al寒冬”已经来临，Al泡沫很快就会破灭，与此同时AI投资与研究资金也减少，正如70年代出现的事情一样。</p><p>但是另一方面，深度学习的前身，人工神经网络却取得了革命性的进展，在1986年戴维·鲁梅哈特(David Rumelhart)，杰弗里·辛顿(Geoffrey Hinton) 等人推广了由保罗·韦尔博斯(Paul Werbos) 发明的<b>反向传播算法(BP算法)</b>，使得大规模神经网络训练成为可能。反向传播算法的出现，使得神经网络隐藏层可以学习到数据输入的有效表达，这就是神经网络乃至深度学习的核心思想。那时候的神经网络就好比上个世纪90年代的互联网，是一种时尚潮流。</p><p>虽然因为当时的计算机性能的限制，未能取得工业级的应用，但是这一次的蓄力，为第三次的兴起和爆发奠定了基础。</p><h2><b>7 第二次浪潮后的蓄力</b></h2><p>在第二次低谷之后，科学家们显然更加理智，当然也是因为其他学科暂时吸引了他们的注意力，包括<b>统计学习理论，支持向量机，概率图模型</b>等，这些方法带来了传统的机器学习方法的理论研究和应用，虽然机器学习在1957年就被阿瑟·萨缪尔(Arthur Samuel)提出。</p><p>在这一段时间里，统计学习类的机器学习算法就是人工智能的代表，但是由于它本身是一门数据驱动的应用学科，没有达到人工智能那样的广泛，因此大家不再叫人工智能，也降低了对它的期望，利用这些方法来做一些更加实际的问题，研究和应用方向也覆盖了计算机视觉到语音等等。</p><p>不过，在以SVM为代表的传统机器学习方法数十年间光芒的背后，却仍然有一股力量在蓄力。</p><p>在1980年neocognitron被提出，这是第一个真正意义上的级联卷积神经网络，虽然具体的卷积方式和今天的CNN还有一定的区别。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-48516ae2dfd99c8bd928a4c71c3010fb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"612\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-48516ae2dfd99c8bd928a4c71c3010fb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;612&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"612\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-48516ae2dfd99c8bd928a4c71c3010fb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-48516ae2dfd99c8bd928a4c71c3010fb_b.jpg\"/></figure><p>同一时期RNN也被提出并使用。</p><p>1989年Yann LeCun与AT&amp;T贝尔实验室的其它研究人员将反向传播算法应用于多层神经网络，并在1998年提出了稳定可商业应用的卷积神经网络模型LeNet-5，成为了深层卷积神经网络模型的<b>“Hello World”</b>。虽然它不是第一次使用卷积神经网络，但是它的出现意味着将神经网络商用的可能性被验证。</p><p>1997年赛普·霍克赖特(Sepp Hochrei ter))和于尔根·施密德胡伯(JurgenSchmidhuber)提出了LSTM(长短期记忆)，用于识别手写笔迹和语音。</p><p>2001年斯皮尔伯格拍摄的电影《人工智能》上映，这是一部非常具有里程碑意义的人工智能启蒙电影，所以我也将其放在这里讲述。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-620c94bdae5a11369ab7d246afece001_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"337\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-620c94bdae5a11369ab7d246afece001_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;337&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"337\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-620c94bdae5a11369ab7d246afece001_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-620c94bdae5a11369ab7d246afece001_b.jpg\"/></figure><p>2006年杰弗里·辛顿(Geoffrey Hinton)等人在science期刊上发表了论文“Reducing the dimensionality of data with neural networks”，揭开了新的训练深层神经网络算法的序幕，通常这被认为是第三次浪潮的发源，但其实彼时还远远没有引起学界的重视，至少工业界几乎全然不知。</p><p>很快斯坦福的李飞飞等人开始研究Image Net项目，这是一个大型的开源数据库，在2009年正式发布，超过1000万数据，两万多个类别。2010年Image Net大规模视觉识别挑战赛(ILSVCR)开始举办，从此揭开了计算机视觉研究的新序幕。</p><h2><b>8 第三次浪潮</b></h2><p>虽然2006年Hinton在science上发表的文章有足够的学术意义，但是第三次浪潮的兴起还是要从工业界发生的具有足够震撼力的标志性事件开始算起。</p><p>验证新技术是否足够好的最好方法就是和其他方法以及人类进行PK。</p><p>2011年IBM开发的自然语言问答计算机<b>“沃森”</b>在益智类综艺节目“危险边缘”中击败两名前人类冠军。前两轮与对手打平，而最后一集沃森打败了最高奖金得主布拉德·鲁特尔和连胜纪录保持者肯·詹宁斯，人们惊呼，机器也会思考了吗？</p><p>2012年，在计算机视觉领域的竞赛Image Net中，新一代卷积神经网络<b>AlexNet</b>，以提升10%的错误率的进步力压第二名以SIFT+FV, LBP+FV, GIST+FV, CSIFT+FV等组合特征的算法。从此人类设计的特征再也不是机器自主学习特征的对手。虽然在此之前语音识别以及取得了足够大的进展，但是彼时语音识别仍然未能商用而没有那么被人所知。</p><p>2016年Google的<b>AlphaGo</b>以4:1的成绩战胜了世界围棋冠军李世石。一年后，AlphaGoMaster与人类实时排名第一的棋手柯洁对决，最终连胜三盘。而新一代AlphaGo Zero利用自我对抗迅速自学围棋，并以100：0的成绩完胜前代版本。自此AI下棋再无敌手。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-80464ac3b359389638f10d7a74165de9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"719\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-80464ac3b359389638f10d7a74165de9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;719&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"719\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-80464ac3b359389638f10d7a74165de9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-80464ac3b359389638f10d7a74165de9_b.jpg\"/></figure><p>此后，以深度学习为代表的技术，引领了当下的热潮。此所谓第三次潮起，会不会潮落不知道，我知道的是现在正在潮中。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55999328", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 12, 
            "title": "【完结】听完这12次分享，你应该完成了AI小白的蜕变", 
            "content": "<p>专栏《AI白身境》正式完结了，在这一个专题中，我们给大家从<b>Linux的基本知识</b>，讲到了深度学习中必备的<b>数学基础</b>，从基本工具<b>VIM和编译命令</b>，讲到了常用的库<b>OpenCV</b>，从AI在工业界的各个<b>研究方向，应用方向</b>，讲到了AI领域的<b>代表性人物</b>，虽然知识本身的难度不高，但是覆盖范围非常广泛，这一次我们来重新回顾一下。</p><p>                                                                                                                                      作者 | 言有三<br/>                                                                                                                                      编辑 | 言有三</p><h2><b>01 为什么要用Linux</b></h2><p>我刚从学校步入职场的时候，也经历过一段从Windows转向Linux的时期，虽然在大学很早的时候就用过Linux，但是毕竟</p><p>所在专业不是计算机等专业，因此Linux并非刚需。</p><p>但是，如果要正式进入AI行业发展，Linux就是必备的操作系统，“软”兵器，Windows基本上可以彻底放弃。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-727b04c43ac89fd2ab50affe21d9f7f5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-727b04c43ac89fd2ab50affe21d9f7f5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-727b04c43ac89fd2ab50affe21d9f7f5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-727b04c43ac89fd2ab50affe21d9f7f5_b.jpg\"/></figure><p>我们简单阐述了Linux固有的一些优点和Windows的缺陷，原文在此。</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a><h2><b>02 Linux基本工具</b></h2><p>Linux下一个熟练的工程师，会比Windows下工作效率高很多，主要得益于若干工具，比如<b>shell、vim和git</b>。</p><p>shell命令是Linux的操作基础，也是学习使用Linux的开始，而慢慢熟悉高级的shell命令在将来的工作中会带来很大的效率提升。</p><p>vim是Linux下最常用的编辑器，从小白到高手都可以使用，而它的列编辑，查找替换，自动补全等功能都是效率的保证，或许从visual studio等环境切换过来的同学刚开始会有些许不适应，但是时间久了就会越来越明白VIM的好。</p><p>git是程序员必备的素养，慢慢学会维护几个自己的代码库，等到将来出问题的时候就明白了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-523f990a99608457cb80d52cb3090aee_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1004\" data-rawheight=\"504\" class=\"origin_image zh-lightbox-thumb\" width=\"1004\" data-original=\"https://pic3.zhimg.com/v2-523f990a99608457cb80d52cb3090aee_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1004&#39; height=&#39;504&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1004\" data-rawheight=\"504\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1004\" data-original=\"https://pic3.zhimg.com/v2-523f990a99608457cb80d52cb3090aee_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-523f990a99608457cb80d52cb3090aee_b.jpg\"/></figure><p>原文在此：</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a><h2><b>03 python基础</b></h2><p>在编程界，现在没有什么语言比python更火，尤其在机器学习届，python可谓是一骑绝尘。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ca283a1569b33866e23829648e439e26_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"404\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ca283a1569b33866e23829648e439e26_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;404&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"404\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ca283a1569b33866e23829648e439e26_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ca283a1569b33866e23829648e439e26_b.jpg\"/></figure><p>学习python需要掌握好基础的语法包括函数，类设计，掌握大量的开源矩阵库<b>Numpy</b>等，图像基础库<b>OpenCV</b>等，以及可视化工具包<b>matplotlib</b>，前后端框架<b>Flask</b>等，原文在此：</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a><h2><b>04 图像基础</b></h2><p>咱们暂时还是一个计算机视觉号，所以数字图像基础是必备的。从数字图像的表示，包括<b>位数，彩色空间，分辨率</b>，数字图像的基本属性，包括<b>直方图，对比度清晰度</b>等，都是未来进军深度学习计算机视觉处理的基石。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-293380f77330075f78632126bf0f1759_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"469\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-293380f77330075f78632126bf0f1759_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;469&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"469\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-293380f77330075f78632126bf0f1759_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-293380f77330075f78632126bf0f1759_b.jpg\"/></figure><p>原文在此：</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a><h2><b>05 OpenCV基础</b></h2><p>如果说图像处理领域有什么库是绕不过去的，那一定是OpenCV，这一个开源计算机视觉库堪称最优秀的计算机视觉库，不仅可以学术和商业免费使用，而且跨平台，高性能。需要掌握的基础内容包括：如何部署，基本数据结构的熟悉与使用，基本模块的了解。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-5da9c3e04aadecb3f0dcc310c38f6b0a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"598\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-5da9c3e04aadecb3f0dcc310c38f6b0a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;598&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"598\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-5da9c3e04aadecb3f0dcc310c38f6b0a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-5da9c3e04aadecb3f0dcc310c38f6b0a_b.jpg\"/></figure><p>以后我们还会专门开一系列课来讲OpenCV，现在先做一个铺垫和科普。</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a><h2><b>06 Linux编译基础</b></h2><p>python是脚本语言，而当前大量的AI算法都部署在移动端嵌入式平台，需要使用c/c++/java语言，而<b>g++，CMake和Makefile</b>正是Linux下编译C系代码的工具。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f40b0dc23de885ff837e5c9a96d8b478_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"900\" data-rawheight=\"500\" class=\"origin_image zh-lightbox-thumb\" width=\"900\" data-original=\"https://pic1.zhimg.com/v2-f40b0dc23de885ff837e5c9a96d8b478_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;900&#39; height=&#39;500&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"900\" data-rawheight=\"500\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"900\" data-original=\"https://pic1.zhimg.com/v2-f40b0dc23de885ff837e5c9a96d8b478_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-f40b0dc23de885ff837e5c9a96d8b478_b.jpg\"/></figure><p>原文在此：</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a><h2><b>07 爬虫基础</b></h2><p>深度学习最重要的是什么，可能很多人的答案就是一个好的<b>数据集</b>。但是通常情况下我们并没有大量的数据，因此有必要掌握一定的爬虫知识，学会自己从头开始准备建立数据集。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-74347b29ae99ad3b7ff3bc96dc2b37b2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"488\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-74347b29ae99ad3b7ff3bc96dc2b37b2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;488&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"488\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-74347b29ae99ad3b7ff3bc96dc2b37b2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-74347b29ae99ad3b7ff3bc96dc2b37b2_b.jpg\"/></figure><p>从前端网页的简单基础，到python爬虫库的基本使用，原文在此：</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a><h2><b>08 数据可视化</b></h2><p>爬取完数据之后就应该进行处理了，一个很常用的手段是<b>数据可视化</b>。在深度学习项目中，常需要的数据可视化操作包括原始<b>图片数据的可视化，损失和精度的可视化</b>等。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b51c8f5323ab8ccb6135940fc3bfefec_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"556\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b51c8f5323ab8ccb6135940fc3bfefec_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;556&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"556\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b51c8f5323ab8ccb6135940fc3bfefec_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b51c8f5323ab8ccb6135940fc3bfefec_b.jpg\"/></figure><p>熟练掌握<b>低维，高维数据</b>的可视化是必备的基础，同时也要了解一些好用的可视化框架以提高工作效率，原文在此：</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a><h2><b>09 数学基础</b></h2><p>没有数学基础，永远只能在门外徘徊。从<b>线性代数，概率论与统计学到微积分和最优化，都是需要掌握的</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b011f3b1a2e8a772f639be3060e82601_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b011f3b1a2e8a772f639be3060e82601_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b011f3b1a2e8a772f639be3060e82601_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b011f3b1a2e8a772f639be3060e82601_b.jpg\"/></figure><p>数学的学习是一个非常漫长的过程，不要急于求成，也不要在一开始就被吓退，对于大部分的工程人员来说，要求并不高，每个人都可以学会，原文在此：</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a><p><b>10 计算机视觉研究方向</b></p><p>在前面这些基础都掌握好了，就差不多可以入行了，首先就要好好了解一下<b>计算机视觉的各大研究方向及其特点</b>。</p><p>从<b>图像分类，分割，目标检测，跟踪，到图像滤波与降噪，增强，风格化，三维重建，图像检索，GANs</b>，相信总有你喜欢的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-620ca67207ebbac823e9f22878a4aa08_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"498\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-620ca67207ebbac823e9f22878a4aa08_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;498&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"498\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-620ca67207ebbac823e9f22878a4aa08_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-620ca67207ebbac823e9f22878a4aa08_b.jpg\"/></figure><p>原文在此：</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a><h2><b>11 AI的应用方向</b></h2><p>我们学习，最终总是为了求职得到满意的工作，尤其是AI已经渗入到了我们生活的方方面面。从<b>自动驾驶汽车、图像美颜，到聊天机器人，金融支付</b>等，因此好好了解下当前AI在各大领域的应用没错的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-152bec589c9a19f6fbd71a238f33f727_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-152bec589c9a19f6fbd71a238f33f727_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;540&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-152bec589c9a19f6fbd71a238f33f727_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-152bec589c9a19f6fbd71a238f33f727_b.jpg\"/></figure><p>原文在此：</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】AI+，都加在哪些应用领域了</a><h2><b>12 认识学术大咖</b></h2><p>最后的最后，要想真正融入行业圈子，紧跟技术发展，就必须要时刻了解<b>大佬们</b>的状态，他们就是行业发展的风向标。</p><p>不管是学术界还是工业界，不管是老师傅还是青年才俊，让我们一起见贤思齐吧。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-75476f07eb3ddb0ad70e0fd9e19db831_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"798\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-75476f07eb3ddb0ad70e0fd9e19db831_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;798&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"798\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-75476f07eb3ddb0ad70e0fd9e19db831_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-75476f07eb3ddb0ad70e0fd9e19db831_b.jpg\"/></figure><p>原文在此：</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a><p>希望经历过这一个系列后，还没有入门，以及正准备入门的小伙伴们，能够真正系统性地入门AI这个大家庭。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ec79e17392a6614d09ada00726ce0a8b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic4.zhimg.com/v2-ec79e17392a6614d09ada00726ce0a8b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic4.zhimg.com/v2-ec79e17392a6614d09ada00726ce0a8b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ec79e17392a6614d09ada00726ce0a8b_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032128%26idx%3D1%26sn%3D370dc70426d199790677ab55ca7234f4%26chksm%3D8712bbbdb06532ab5fad5706b0dfc81f8bc92b07be2e3a1b67a611e041fbbc105e2c90f1c1dd%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><p></p>", 
            "topic": [
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }
            ], 
            "comments": [
                {
                    "userName": "王二的石锅拌饭", 
                    "userLink": "https://www.zhihu.com/people/247726b78109b760cc18c1b04bcc4b11", 
                    "content": "好文啊，必须热评", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "🤝🤝🤝谢谢喜欢", 
                            "likes": 0, 
                            "replyToAuthor": "王二的石锅拌饭"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55949415", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 41, 
            "title": "【AI白身境】究竟谁是paper之王，全球前10的计算机科学家在做什么", 
            "content": "<p>今天是新专栏《AI白身境》的第十二篇，也是最后一篇了，作为最后一篇，我的想法是激励大家见贤思齐。</p><p>本来想写篇必须关注的大佬，但是实在是太难写了，人太多也容易引起争议，那就用最权威的资料来，学术界公认的h-index排名。</p><p>所谓H-index，就是high citations，简单来说就是论文被引用的频次。</p><p>                                                                                                                                    作者 | 言有三<br/>                                                                                                                                    编辑 | 言有三</p><h2><b>01 H-index排名前十的计算机科学家</b></h2><p>下图是2018年计算机科学领域的H-index排名前十，相信从中就是小白们也能看到不少熟悉的名字。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-6ae0ae0fa71c4125945080d2cd795af3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"448\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-6ae0ae0fa71c4125945080d2cd795af3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;448&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"448\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-6ae0ae0fa71c4125945080d2cd795af3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-6ae0ae0fa71c4125945080d2cd795af3_b.jpg\"/></figure><p>完整名单见 <i><a href=\"https://link.zhihu.com/?target=http%3A//www.iro.umontreal.ca/~bengioy/citation-rate-CS-1sept2018.html%3Futm_source%3Dwechat_session%26utm_medium%3Dsocial%26utm_oi%3D635845013939032064\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">iro.umontreal.ca/~bengi</span><span class=\"invisible\">oy/citation-rate-CS-1sept2018.html?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=635845013939032064</span><span class=\"ellipsis\"></span></a></i></p><p>H-index排名越高说明论文被人引用的越频繁，在学术界来说这就意味着影响力。下面我们来了解一下排名前十的大佬们都是谁，做过什么。</p><p>1，Yoshua Bengio，加拿大计算机科学家，深度学习三巨头之一，LeNet5作者之一，花书《Deep learning》作者之一，一直呆在学术界。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5a238307258a287fa93e3ce6dd07f027_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"633\" data-rawheight=\"386\" class=\"origin_image zh-lightbox-thumb\" width=\"633\" data-original=\"https://pic4.zhimg.com/v2-5a238307258a287fa93e3ce6dd07f027_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;633&#39; height=&#39;386&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"633\" data-rawheight=\"386\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"633\" data-original=\"https://pic4.zhimg.com/v2-5a238307258a287fa93e3ce6dd07f027_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5a238307258a287fa93e3ce6dd07f027_b.jpg\"/></figure><p>代表性文章：</p><p>[1] LÉcun, Yann, et al. “Gradient-Based Learning Applied to Document Recognition.” Proceedings of the IEEE, vol. 86, no. 11, 1998, pp. 2278–2324.</p><p>[2] Bengio Y, Courville A C, Vincent P, et al. Representation Learning: A Review and New Perspectives[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35(8): 1798-1828.</p><p>2，Geoffrey Hinton，加拿大认知心理学家和计算机科学家，深度学习三巨头之一，反向传播算法提出者之一，2006年在science期刊发表深层网络逐层初始化训练方法，揭开深度学习世纪新序幕，其弟子Alex Krizhevsky提出AlexNet网络。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8f302269a1b26316fea7b0f65c6c769a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"719\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8f302269a1b26316fea7b0f65c6c769a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;719&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"719\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8f302269a1b26316fea7b0f65c6c769a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8f302269a1b26316fea7b0f65c6c769a_b.jpg\"/></figure><p>代表性文章：</p><p>[1] Rumelhart D E , Hinton G E , Williams R J . Learning internal representations by error propagation[M]// Neurocomputing: foundations of research. MIT Press, 1988.</p><p>[2] Hinton G E, Salakhutdinov R. Reducing the dimensionality of data with neural networks.[J]. Science, 2006, 313(5786): 504-507.</p><p>[3] Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep Convolutional Neural Networks[C]// NIPS. Curran Associates Inc. 2012.</p><p>3，Yann LeCun，法国计算机科学家，深度学习三巨头之一，Facebook首席人工智能科学家，LeNet5网络第一作者，深度学习综述《Deep learning》作者之一。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-fa7edfa5c41de7fdf2210548d7ef5a98_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"671\" data-rawheight=\"359\" class=\"origin_image zh-lightbox-thumb\" width=\"671\" data-original=\"https://pic1.zhimg.com/v2-fa7edfa5c41de7fdf2210548d7ef5a98_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;671&#39; height=&#39;359&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"671\" data-rawheight=\"359\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"671\" data-original=\"https://pic1.zhimg.com/v2-fa7edfa5c41de7fdf2210548d7ef5a98_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-fa7edfa5c41de7fdf2210548d7ef5a98_b.jpg\"/></figure><p>代表性文章：</p><p>[1] LeCun Y, Bengio Y, Hinton G. Deep learning[J]. nature, 2015, 521(7553): 436.</p><p>[2] LÉcun, Yann, et al. “Gradient-Based Learning Applied to Document Recognition.” Proceedings of the IEEE, vol. 86, no. 11, 1998, pp. 2278–2324.</p><p>至此三巨头都出现了，不愧是三巨头，它们之间也有着千丝万缕的合作，从上面同时出现在LeNet5和深度学习花书的Yoshua Bengio和Yann LeCun就可以看出，两人年纪也相当，而Hinton其实已经是两者的老师级别。</p><p>4，Andrew Zisserman，英国计算机科学家，牛津大学教授，计算机视觉研究员，经典书《Multiple View Geometryin Computer Vision》作者，VGG网络作者之一，Pascal Visual Object Classes (VOC) Challenge发起者之一，Deep Mind研究员。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ea67917b718955fa9c5faea4080cdf13_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"550\" data-rawheight=\"413\" class=\"origin_image zh-lightbox-thumb\" width=\"550\" data-original=\"https://pic4.zhimg.com/v2-ea67917b718955fa9c5faea4080cdf13_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;550&#39; height=&#39;413&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"550\" data-rawheight=\"413\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"550\" data-original=\"https://pic4.zhimg.com/v2-ea67917b718955fa9c5faea4080cdf13_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ea67917b718955fa9c5faea4080cdf13_b.jpg\"/></figure><p>代表性文章：</p><p>[1] Simonyan K, Zisserman A. Very Deep Convolutional Networks for Large-Scale Image Recognition[J]. international conference on learning representations, 2015.</p><p>[2] Everingham M, Van Gool L, Williams C K, et al. The Pascal Visual Object Classes (VOC) Challenge[J]. International Journal of Computer Vision, 2010, 88(2): 303-338.</p><p>[3] Jaderberg M, Simonyan K, Zisserman A, et al. Spatial transformer networks[J]. neural information processing systems, 2015: 2017-2025.</p><p>5，David Haussler，美国生物信息学家，霍华德休斯医学研究所研究员、生物分子工程教授等，人类基因组计划竞赛中组装了第一个人类基因组序列。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-65f85486c23e908b49d3234d9ee42b72_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"620\" data-rawheight=\"620\" class=\"origin_image zh-lightbox-thumb\" width=\"620\" data-original=\"https://pic3.zhimg.com/v2-65f85486c23e908b49d3234d9ee42b72_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;620&#39; height=&#39;620&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"620\" data-rawheight=\"620\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"620\" data-original=\"https://pic3.zhimg.com/v2-65f85486c23e908b49d3234d9ee42b72_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-65f85486c23e908b49d3234d9ee42b72_b.jpg\"/></figure><p>代表性文章：</p><p>[1] Lander E S, Linton L, Birren B, et al. Initial sequencing and analysis of the human genome.[J]. Nature, 2001, 409(6822): 860-921.</p><p>6，Trevor Darrell，加州大学伯克利分教授，伯克利人工智能研究（BAIR）实验室的联合主任，Caffe，RCNN作者之一，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6423960f8600016fa2288ca43512ce56_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"528\" data-rawheight=\"342\" class=\"origin_image zh-lightbox-thumb\" width=\"528\" data-original=\"https://pic3.zhimg.com/v2-6423960f8600016fa2288ca43512ce56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;528&#39; height=&#39;342&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"528\" data-rawheight=\"342\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"528\" data-original=\"https://pic3.zhimg.com/v2-6423960f8600016fa2288ca43512ce56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-6423960f8600016fa2288ca43512ce56_b.jpg\"/></figure><p>代表性文章：</p><p>[1] Jia Y, Shelhamer E, Donahue J, et al. Caffe: Convolutional Architecture for Fast Feature Embedding[J]. acm multimedia, 2014: 675-678.</p><p>[2] Girshick R B, Donahue J, Darrell T, et al. Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation[J]. computer vision and pattern recognition, 2014: 580-587.</p><p>7，StephenP.Boyd，三星工程教授，斯坦福大学信息系统实验室电气工程教授，凸优化书籍《Convex optimization》作者。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a8af04d87090ccf005afe3f352a6c3ea_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"789\" data-rawheight=\"798\" class=\"origin_image zh-lightbox-thumb\" width=\"789\" data-original=\"https://pic3.zhimg.com/v2-a8af04d87090ccf005afe3f352a6c3ea_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;789&#39; height=&#39;798&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"789\" data-rawheight=\"798\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"789\" data-original=\"https://pic3.zhimg.com/v2-a8af04d87090ccf005afe3f352a6c3ea_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a8af04d87090ccf005afe3f352a6c3ea_b.jpg\"/></figure><p>代表性文章：</p><p>[1] Stephen Boyd L V, Stephen Boyd L V. Convex optimization[J]. IEEE Transactions on Automatic Control, 2006, 51(11):1859-1859.</p><p>[2] Candes E J, Wakin M B, Boyd S P. Enhancing Sparsity by Reweighted l(1) Minimization[J]. Journal of Fourier Analysis &amp; Applications, 2007, 14(5):877-905.</p><p>8，Michael I. Jordan，美国科学家、加州大学伯克利分校教授。机器学习领域的领军人物之一，2016年《科学》杂志评定的世界上最具影响力的计算机科学家。Latent Dirichlet Allocation模型作者。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-8c7c157dec26152a6ee57ea8ffd2e594_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"115\" data-rawheight=\"156\" class=\"content_image\" width=\"115\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;115&#39; height=&#39;156&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"115\" data-rawheight=\"156\" class=\"content_image lazy\" width=\"115\" data-actualsrc=\"https://pic1.zhimg.com/v2-8c7c157dec26152a6ee57ea8ffd2e594_b.jpg\"/></figure><p>代表性文章：</p><p>[1] Blei D M, Ng A Y, Jordan M I. Latent dirichlet allocation[J]. Journal of Machine Learning Research, 2012, 3:993-1022.</p><p>9，Christopher Manning，斯坦福大学人工智能实验室主任，语言学和计算机科学家。书籍《Introduction to information retrieval》，《Foundations of Statistical Natural Language Processing》作者。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b8f3d60bd88da451ca630e71ca685815_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b8f3d60bd88da451ca630e71ca685815_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1080&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b8f3d60bd88da451ca630e71ca685815_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b8f3d60bd88da451ca630e71ca685815_b.jpg\"/></figure><p>代表性文章：</p><p>[1] Manning C D. Foundations of statistical natural language processing[M]// Foundations of Statistical Natural Language Processing. 1999.</p><p>[2] Larson R R. Introduction to Information Retrieval[J]. Journal of the Association for Information Science and Technology, 2010, 61(4): 852-853.</p><p>10，Herbert A Simon，诺贝尔经济学奖，图灵奖等获得者，书籍《The Sciences of the Artificial》，《Human Problem Solving》作者，也是唯一一个已经不在世近二十年的科学家，却还能在过去一年的论文引用前十中占据一席，可见影响力之大。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e6822e7b97f6e35e907711c23306824b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"268\" data-rawheight=\"400\" class=\"content_image\" width=\"268\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;268&#39; height=&#39;400&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"268\" data-rawheight=\"400\" class=\"content_image lazy\" width=\"268\" data-actualsrc=\"https://pic4.zhimg.com/v2-e6822e7b97f6e35e907711c23306824b_b.jpg\"/></figure><p>代表论文：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f1685b055b1726e675220194a157252a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"912\" data-rawheight=\"586\" class=\"origin_image zh-lightbox-thumb\" width=\"912\" data-original=\"https://pic3.zhimg.com/v2-f1685b055b1726e675220194a157252a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;912&#39; height=&#39;586&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"912\" data-rawheight=\"586\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"912\" data-original=\"https://pic3.zhimg.com/v2-f1685b055b1726e675220194a157252a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f1685b055b1726e675220194a157252a_b.jpg\"/></figure><p>除了上面的10位，计算机科学领域还有很多世界级的研究人员值得我们去关注的，比如花书作者之一和生成对抗网络的提出者Ian Goodfellow等，不再过多介绍。</p><h2><b>02 深度学习领域的优秀青年华人</b></h2><p>如果说世界级科学家离我们太遥远，那么身边优秀的华人是不是需要好好关注？下面介绍几个优秀的80后青年华人，都是非常有代表性的人物，对深度学习有突破性的学术贡献或开源框架作者。</p><p>1，何恺明，本科就读于清华大学，博士毕业于香港中文大学多媒体实验室，曾在微软亚洲研究院担任实习生，目前在Facebook人工智能实验室（FAIR）担任研究科学家。他是Resnet、Mask R-CNN第一作者，也是首位获计算机视觉领域三大国际会议之一CVPR“最佳论文奖”的中国学者。另外他也获得了CVPR 2016和ICCV 2017（Marr Prize）的最佳论文奖，并获得了ICCV 2017最佳学生论文奖，CVPR 2018的PAMI年轻学者奖，这就是别人隔壁家的小明和学霸。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-fd23530c5c9bdc06b21d4f5448174399_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"572\" data-rawheight=\"317\" class=\"origin_image zh-lightbox-thumb\" width=\"572\" data-original=\"https://pic2.zhimg.com/v2-fd23530c5c9bdc06b21d4f5448174399_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;572&#39; height=&#39;317&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"572\" data-rawheight=\"317\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"572\" data-original=\"https://pic2.zhimg.com/v2-fd23530c5c9bdc06b21d4f5448174399_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-fd23530c5c9bdc06b21d4f5448174399_b.jpg\"/></figure><p>代表性文章：</p><p>[1] He K , Zhang X , Ren S , et al. Deep Residual Learning for Image Recognition[J]. 2015.</p><p>[2] He K, Gkioxari G, Dollar P, et al. Mask R-CNN[J]. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2017, PP(99):1-1.</p><p>2，贾扬青，深度学习框架Caffe之父。本科和硕士研究生就读于清华大学，博士毕业于加州大学伯克利分校，曾在新加坡国立大学、微软亚洲研究院、NEC美国实验室、Google Brain工作，现任Facebook研究科学家，负责前沿AI平台的开发以及前沿的深度学习研究。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f9efd01c9eb51f960cf757b324130a9b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"200\" data-rawheight=\"280\" class=\"content_image\" width=\"200\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;200&#39; height=&#39;280&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"200\" data-rawheight=\"280\" class=\"content_image lazy\" width=\"200\" data-actualsrc=\"https://pic4.zhimg.com/v2-f9efd01c9eb51f960cf757b324130a9b_b.jpg\"/></figure><p>代表性文章：</p><p>[1] Jia Y , Shelhamer E , Donahue J , et al. Caffe: Convolutional Architecture for Fast Feature Embedding[J]. 2014.</p><p>[2] Decaf: A deep convolutional activation feature for generic visual recognition</p><p>如果说何凯明是学术界的青年扛把子，那么贾扬清就是工业界的青年扛把子了，他还有知乎账号，冒过几个泡。</p><p>3，李沐，2008年本科毕业于上海交通大学计算机系，CMU博士毕业，深度学习开源框架MXNet作者之一，曾在微软亚洲研究院担任实习生，在亚马逊就职。沐神有一本在线书籍《动手学深度学习》，另外现在有很多的群，算是做深度学习的普及工作贡献了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-577faac85b1114673043dc52730dd8e5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"650\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic2.zhimg.com/v2-577faac85b1114673043dc52730dd8e5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;650&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"650\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic2.zhimg.com/v2-577faac85b1114673043dc52730dd8e5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-577faac85b1114673043dc52730dd8e5_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>代表性文章：</p><p>[1] Li M , Liu Z , Smola A J , et al. DiFacto - Distributed Factorization Machines[C]// Acm International Conference on Web Search &amp; Data Mining. ACM, 2016.</p><p>4、陈天奇，本科毕业于上海交通大学ACM班，华盛顿大学计算机系博士生。深度学习编译器TVM，SVDFeature，XGBoost，cxxnet等作者，MxNet，DMLC发起人之一。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4c09f8350b96d0e732575aa56073114c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"241\" data-rawheight=\"242\" class=\"content_image\" width=\"241\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;241&#39; height=&#39;242&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"241\" data-rawheight=\"242\" class=\"content_image lazy\" width=\"241\" data-actualsrc=\"https://pic1.zhimg.com/v2-4c09f8350b96d0e732575aa56073114c_b.jpg\"/></figure><p>代表性文章：</p><p>[1] MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems<br/>Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao, Bing Xu, Chiyuan Zhang, Zheng Zhang <br/>LearningSys at Neural Information Processing Systems 2015 </p><p>[2] TVM: An Automated End-to-End Optimizing Compiler for Deep Learning<br/>Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan, Meghan Cowan, Haichen Shen, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin, Arvind Krishnamurthy </p><p>5、韩松，本科毕业于清华大学后，博士毕业于斯坦福大学，深鉴科技联合创始人之一，2016年ICLR最佳论文deep compression论文一作。就放深鉴科技四个创始人的照片吧，都是青年才俊。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-98a694ce7515082161be20921d5762ae_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"389\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-98a694ce7515082161be20921d5762ae_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;389&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"389\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-98a694ce7515082161be20921d5762ae_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-98a694ce7515082161be20921d5762ae_b.jpg\"/></figure><p>代表性文章：</p><p>[1] Han S , Kang J , Mao H , et al. ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA[J]. 2016.</p><p>[2] Han S, Mao H, Dally W J, et al. Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding[J]. international conference on learning representations, 2016.</p><p>AI领域不管是老前辈还是后起之秀真的太多了，写这一篇文章的目地不仅是给初学者们作一个简单的介绍，更是自勉。就算不能成为他们那样牛逼的人，也要有一颗见贤思齐，不断提升自己的斗志。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }, 
                {
                    "tag": "计算机科学", 
                    "tagLink": "https://api.zhihu.com/topics/19580349"
                }
            ], 
            "comments": [
                {
                    "userName": "oozz", 
                    "userLink": "https://www.zhihu.com/people/0e01e7a2fb3d0a8536468bfe874620d0", 
                    "content": "跟了", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "哈哈，跟住！", 
                            "likes": 0, 
                            "replyToAuthor": "oozz"
                        }
                    ]
                }, 
                {
                    "userName": "青蛙", 
                    "userLink": "https://www.zhihu.com/people/2f7bae8a0ffa954d2e493219e0b7a0e9", 
                    "content": "<p>我也很喜欢MXNet 的开发者之一 张弛源，浙大毕业的，MIT的phd, 现在在Google Brain.</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "[赞同]", 
                            "likes": 0, 
                            "replyToAuthor": "青蛙"
                        }
                    ]
                }, 
                {
                    "userName": "青蛙", 
                    "userLink": "https://www.zhihu.com/people/2f7bae8a0ffa954d2e493219e0b7a0e9", 
                    "content": "<p>西瓜书作者呢？还有吴恩达，李飞飞到底牛在哪里</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "只能写10个，写不完[捂脸]", 
                            "likes": 0, 
                            "replyToAuthor": "青蛙"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55695460", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 56, 
            "title": "【AI白身境】一文览尽计算机视觉研究方向", 
            "content": "<p>今天是新专栏《AI白身境》的第10篇，所谓白身，就是什么都不会，还没有进入角色。</p><p>相信看了前面的几篇文章后很多朋友已经等不及快速入行了，今天就来介绍一下<b>计算机视觉的各大研究方向及其特点</b>。</p><p>所谓计算机视觉，即compute vision，就是通过用计算机来模拟人的视觉工作原理，来获取和完成一系列图像信息处理的机器。计算机视觉属于机器学习在视觉领域的应用，是一个多学科交叉的研究领域，涉及数学，物理，生物，计算机工程等多个学科，由此也可以想象到计算机视觉的研究范围非常广，也是图像，语音，自然语言处理领域中从业人数最多的。</p><p>                                                                                                                                     作者 | 言有三<br/>                                                                                                                                     编辑 | 言有三</p><h2><b>01 图像分类</b></h2><blockquote><b>1.1 基本概念</b></blockquote><p>图像分类是计算机视觉中最基础的一个任务，也是几乎所有的基准模型进行比较的任务，从最开始比较简单的10分类的灰度图像手写数字识别mnist，到后来更大一点的10分类的cifar10和100分类的cifar100，到后来的imagenet，图像分类任务伴随着数据库的增长，一步一步提升到了今天的水平。</p><p>现在在imagenet这样的超过1000万图像，2万类的数据集中，计算机的图像分类水准已经超过了人类。</p><p>图像分类，顾名思义，就是一个模式分类问题，它的目标是将不同的图像，划分到不同的类别，实现最小的分类误差。</p><p>总体来说，对于二分类的问题，图像分类可以分为<b>跨物种语义级图像分类，子类细粒度图像分类，以及实例级图像分类</b>三大类别。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-620ca67207ebbac823e9f22878a4aa08_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"498\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-620ca67207ebbac823e9f22878a4aa08_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;498&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"498\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-620ca67207ebbac823e9f22878a4aa08_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-620ca67207ebbac823e9f22878a4aa08_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">传统机器学习方法：</code></pre></div><p>通过各种经典的特征算子+经典分类器组合学习，比如HoG+SVM。</p><div class=\"highlight\"><pre><code class=\"language-text\">深度学习方法：</code></pre></div><p>各种分类网络，最为大家熟知的就是ImageNet竞赛了。</p><p>2012年Alexnet诞生，意味着GPU训练时代的来临。</p><p>Alexnet是第一个真正意义上的深度网络，与LeNet5的5层相比，它的层数增加了3 层，网络的参数量也大大增加，输入也从32变成了224。</p><p>2014年VGG诞生，它共包含参数约为550M。全部使用3*3*的卷积核*和2*2的最大池化核，简化了卷积神经网络的结构。VGG很好的展示了如何在先前网络架构的基础上通过增加网络层数和深度来提高网络的性能，网络虽然简单，但是却异常的有效，在今天VGG仍然被很多的任务选为基准模型。</p><p>同一年GoogleNet诞生，也被成为Inception Model，它的核心是Inception Module。一个经典的inception 结构，包括有四个成分，1*1卷积，3*3 卷积， 5*5 卷积，3*3 最大池化，最后对运算结果进行通道上组合，可以得到图像更好的表征。自此，深度学习模型的分类准确率已经达到了人类的水平(5%~10%)。 </p><p>2015年，ResNet被提出。ResNet以 3.57%的错误率表现超过了人类的识别水平，并以152层的网络架构创造了新的模型记录。由于resnet采用了跨层连接的方式，它成功的缓解了深层神经网络中的梯度消散问题，为上千层的网络训练提供了可能。</p><p>2016年ResNeXt诞生，101层的ResNeXt可以达到ResNet152 的精确度，却在复杂度上只有后者的一半，核心思想为分组卷积。即首先将输入通道进行分组，经过若干并行分支的非线性变换，最后合并。</p><p>在resnet基础上，密集连接的densenet将前馈过程中将每一层与其他的层都连接起来。对于每一层网络来说，前面所有网络的特征图都被作为输入，同时其特征图也都被其他网络层作为输入所利用。 </p><p>2017年，也是imagenet图像分类比赛的最后一年，senet获得了冠军。这个结构，仅仅使用了“特征重标定”的策略来对特征进行处理，也就是通过学习获取每个特征通道的重要程度，根据重要性去抑制或者提升相应的特征。 </p><blockquote><b>1.2 方向特点</b></blockquote><p>图像分类的比赛基本落幕，也接近算法的极限。但是在实际的应用中却面临着比比赛中更加复杂，比如<b>样本不均衡，分类界面模糊，未知类别</b>等。如果想了解更多，请查看往期文章。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030111%26idx%3D1%26sn%3D77e67f92dbf172bcf5bac96576864782%26chksm%3D871343a2b064cab4e05f5380345b51dc8f14e8f09d0c789e9218df828445685bc2cacfc378da%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】你真的了解图像分类吗？</a> </p><p class=\"ztext-empty-paragraph\"><br/></p><h2>02 <b>目标检测</b></h2><blockquote><b>2.1 基本概念</b></blockquote><p>分类任务给出的是整张图片的内容描述，而目标检测任务则关注图片中特定的目标。</p><p>检测任务包含两个子任务，其一是这一目标的类别信息和概率，它是一个分类任务。其二是目标的具体位置信息，这是一个定位任务。 </p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-568d583daf02c79cb94932841e7852ef_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"690\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-568d583daf02c79cb94932841e7852ef_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;690&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"690\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-568d583daf02c79cb94932841e7852ef_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-568d583daf02c79cb94932841e7852ef_b.jpg\"/></figure><p>与计算机视觉领域里大部分的算法一样，目标检测也经历了从<b>传统的人工设计特征和浅层分类器的思路（以）</b>，到大数据时代使用<b>深度神经网络进行特征学习的思路</b>。</p><p>在传统方法时代，很多的任务不是一次性解决，而是需要多个步骤的。而深度学习时代，很多的任务都是采用End-To-End的方案，即输入一张图，输出最终想要的结果，算法细节和学习过程全部丢给了神经网络，这一点在物体检测这个领域，体现得尤为明显。</p><p>不管是清晰地分步骤处理，还是深度学习的end-to-end的方法，目标检测算法一定会有3个模块。<b>第一个是检测窗口的选择，第二个是图像特征的提取，第三个是分类器的设计。</b> </p><blockquote><b>2.2 方法分类</b></blockquote><div class=\"highlight\"><pre><code class=\"language-text\">传统机器学习方法：</code></pre></div><p>以保罗·维奥拉和迈克尔·琼斯于2001年提出的维奥拉-琼斯目标检测框架为代表，这是第一篇基于Haar+Adaboost的检测方法，也是首次把检测做到实时的框架，此方法在opencv中被实现为cvHaarDetectObjects()，是opencv中最为人熟知的目标检测方法。速度非常快，检测召回率相对如今的算法较低。</p><div class=\"highlight\"><pre><code class=\"language-text\">深度学习方法：</code></pre></div><p>仍然要解决区域选择、提取特征、分类回归三个问题。但是在演变过程中，却发展出了multi-stage和one-stage的方法。其中multi-stage方法，是分步骤完成上面的任务，甚至可能需要单独训练各个网络。而one-stage则是一步到位。</p><p>RCNN的框架是multi-stage方法的典型代表。它使用了Selective search先生成候选区域再检测，候选窗口的数量被控制在了2000个左右。选择了这些图像框之后，就可以将对应的框进行resize操作，然后送入CNN中进行训练。由于CNN非常强大的非线性表征能力，可以对每一个区域进行很好的特征表达，CNN最后的输出，使用多个分类器进行分类判断。该方法将PASCAL VOC上的检测率从 35.1% 提升到了53.7%，其意义与Alexnet在2012年取得分类任务的大突破是相当的，对目标检测领域影响深远。  </p><p>随后Fast R-CNN提出RoIPooling从整图对应的卷积特征图选取区域特征，解决了重复提取特征的问题。Faster R-CNN则提出Region Proposal, anchors把一张图片划分成n*n个区域，每个区域给出9个不同ratio和scale的proposal，解决了重复提取候选proposal的问题。 RCNN系列在工业届应用非常广泛，因此从事目标检测的同学必须掌握。 </p><p>除了multi-stage方法，还有one-stage方法。以YOLO为代表的方法，没有显式的候选框提取过程。它首先将图片resize到固定尺寸，将输入图片划分成一个7x7的网格，每个网格预测2个边框，对每一个网络进行分类和定位。YOLO方法也经过了许多版本的发展，从YOLO v2到YOLO v3。YOLO的做法是速度快，但是会有许多漏检，尤其是小的目标。所以SSD就在 YOLO的基础上添加了Faster R-CNN的Anchor 概念，并融合不同卷积层的特征做出预测。虽然YOLO和SSD系列的方法没有了region proposal的提取，速度更快，但是必定会损失信息和精度。</p><p>如果想了解更多，可以去阅读我们的往期文章。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030461%26idx%3D2%26sn%3D2c501bc4ea6a1eef6c11f81b464d0eef%26chksm%3D87134140b064c8568c6f518ee159e37cbf1d23ce8ff77a1aa3e2a675c6060ab2ef16f7b3c5d2%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】一文道尽R-CNN系列目标检测</a><br/><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030461%26idx%3D1%26sn%3D1ac88e15db361ebaefe8db609c48ae94%26chksm%3D87134140b064c85672c3de4b623d8b9471fae188f28fcac5dc1345795e1a9fc578ee2644a15c%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】万字长文详解Faster&amp;nbsp;RCNN源代码</a> <br/></p><blockquote><b>2.3 方向特点</b></blockquote><p>目标检测方向有一些固有的难题，比如<b>小脸，遮挡，大姿态</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-b655faed0267250717b826ededb9d8e3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"501\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-b655faed0267250717b826ededb9d8e3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;501&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"501\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-b655faed0267250717b826ededb9d8e3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-b655faed0267250717b826ededb9d8e3_b.jpg\"/></figure><p>而在方法上，<b>多尺度与级联网络的设计，难样本的挖掘，多任务loss</b>等都是比较大的研究小方向，咱们也写过一些文章，感兴趣的朋友可以去翻。 </p><h2><b>03 图像分割</b></h2><blockquote><b>3.1 基础概念</b></blockquote><p>图像分割属于图像处理领域最高层次的图像理解范畴。所谓图像分割就是把图像分割成具有相似的颜色或纹理特性的若干子区域，并使它们对应不同的物体或物体的不同部分的技术。这些子区域，组成图像的完备子集，又相互之间不重叠。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-168fcae3f07cc281b80dd9aafb64a529_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"860\" data-rawheight=\"636\" class=\"origin_image zh-lightbox-thumb\" width=\"860\" data-original=\"https://pic2.zhimg.com/v2-168fcae3f07cc281b80dd9aafb64a529_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;860&#39; height=&#39;636&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"860\" data-rawheight=\"636\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"860\" data-original=\"https://pic2.zhimg.com/v2-168fcae3f07cc281b80dd9aafb64a529_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-168fcae3f07cc281b80dd9aafb64a529_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d310e25316882325f6ab80f17d8feb54_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d310e25316882325f6ab80f17d8feb54_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;540&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d310e25316882325f6ab80f17d8feb54_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d310e25316882325f6ab80f17d8feb54_b.jpg\"/></figure><p>在图像处理中，研究者往往只对图像中的某些区域感兴趣，在此基础上才有可能对目标进行更深层次的处理与分析，包括对象的数学模型表示、几何形状参数提取、统计特征提取、目标识别等。</p><div class=\"highlight\"><pre><code class=\"language-text\">传统方法：</code></pre></div><p>图像分割问题最早来自于一些文本的分割，医学图像分割。在文本图像分割中，我们需要切割出字符，常见的问题包括指纹识别，车牌识别；由于这一类问题比较简单，因为基于阈值和聚类的方法被经常使用。</p><p>基于阈值和聚类的方法虽然简单，但因此也经常失效。以graphcut为代表的方法，是传统图像分割里面鲁棒性最好的方法。Graphcut的基本思路，就是建立一张图，其中以图像像素或者超像素作为图像顶点，然后移除一些边，使得各个子图不相连从而实现分割。图割方法优化的目标是找到一个切割，使得移除边的和权重最小。</p><div class=\"highlight\"><pre><code class=\"language-text\">深度学习方法：</code></pre></div><p>全卷积神经网络(Fully connected Network)是第一个将卷积神经网络正式用于图像分割问题的网络。 </p><p>一个用于分类任务的深度神经网络通过卷积来不断抽象学习，实现分辨率的降低，最后从一个较小的featuremap或者最后的特征向量，这个featuremap通常为5*5或者7*7等大小。而图像分割任务需要恢复与原尺度大小一样的图片，所以，需要从这个featuremap恢复原始图片尺寸，这是一个上采样的过程。由于这个过程与反卷积是正好对应的逆操作，所以我们通常称其为反卷积。</p><p>实际上并没有反卷积这样的操作，在现在的深度学习框架中，反卷积通常有几种实现方式，一个是双线性插值为代表的插值法，一个是<b>转置卷积</b>。 </p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4a790ca7f92ada4abf370fbc1b8c3d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-4a790ca7f92ada4abf370fbc1b8c3d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-4a790ca7f92ada4abf370fbc1b8c3d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4a790ca7f92ada4abf370fbc1b8c3d49_b.jpg\"/></figure><blockquote><b>3.2 方向特点</b></blockquote><p>在基于深度学习的图像分割中，有一些比较关键的技术，包括<b>反卷积的使用，多尺度特征融合，crf等后处理</b>方法。</p><div class=\"highlight\"><pre><code class=\"language-text\">多尺度与上下文信息：</code></pre></div><p>多尺度的信息融合可以从特征图，还可以直接采用多尺度的输入图像，不过这两者本质上没有太多的差异。使用金字塔的池化方案可实现不同尺度的感受野，它能够起到将局部区域上下文信息与全局上下文信息结合的效果。对于图像分割任务，全局上下文信息通常是与整体轮廓相关的信息，而局部上下文信息则是图像的细节纹理，要想对多尺度的目标很好的完成分割，这两部分信息都是必须的。  </p><div class=\"highlight\"><pre><code class=\"language-text\">CRF：</code></pre></div><p>由于经典的cnn是局部的方法，即感受野是局部而不是整个图像。另一方面，cnn具有空间变换不变性，这也降低了分割的边缘定位精度。针对cnn的这两个缺陷，crf可以进行很好的弥补。crf是一种非局部的方法，它可以融合context信息，Deeplab系列就使用了cnn加上全连接的crf的方式。</p><p>另一方面，前面我们说的图像分割，是属于硬分割，即每一个像素都以绝对的概率属于某一类，最终概率最大的那一类，就是我们所要的类别。但是，这样的分割会带来一些问题，就是边缘不够细腻，当后期要进行融合时，边缘过渡不自然。此时，就需要用到image matting技术。</p><p>更多请查看往期文章：</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029723%26idx%3D1%26sn%3D555a2d45fa210a1c5c5c703de54899a4%26chksm%3D87134226b064cb30f070ea5a2368f1c5bb6679d0f13e7e84b3f6374be33c549ce81a665d6e25%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】闲聊图像分割这件事儿</a> </p><h2><b>04 目标跟踪</b></h2><blockquote><b>4.1 基本概念</b></blockquote><p>目标跟踪，指的其实就是视频中运动目标的跟踪，跟踪的结果通常就是一个框。目标跟踪是视频监控系统中不可缺少的环节。 </p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-bc6371c1cf2f989ecfa3896791472053_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"385\" data-rawheight=\"289\" data-thumbnail=\"https://pic4.zhimg.com/v2-bc6371c1cf2f989ecfa3896791472053_b.jpg\" class=\"content_image\" width=\"385\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;385&#39; height=&#39;289&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"385\" data-rawheight=\"289\" data-thumbnail=\"https://pic4.zhimg.com/v2-bc6371c1cf2f989ecfa3896791472053_b.jpg\" class=\"content_image lazy\" width=\"385\" data-actualsrc=\"https://pic4.zhimg.com/v2-bc6371c1cf2f989ecfa3896791472053_b.gif\"/></figure><p>根据目标跟踪方法建模方式的不同，可以分为<b>生成式模型方法与判别式模型方法</b>。</p><p>生成式模型跟踪算法以均值漂移目标跟踪方法和粒子滤波目标跟踪方法为代表，判别式模型跟踪算法以相关滤波目标跟踪方法和深度学习目标跟踪方法为代表。</p><div class=\"highlight\"><pre><code class=\"language-text\">生成类方法：</code></pre></div><p>在原始影像帧中对目标按指定的方法建立目标模型，然后在跟踪处理帧中搜索对比与目标模型相似度最高的区域作为目标区域进行跟踪。算法主要对目标本身特征进行描述，对目标特征刻画较为细致，但忽略背景信息的影响。在目标发生变化或者遮挡等情况下易导致失跟现象。</p><div class=\"highlight\"><pre><code class=\"language-text\">判别类方法：</code></pre></div><p>通过对原始影像帧，对目标及背景信息进行区分建立判别模型，通过对后续影像帧搜索目标进行判别是目标或背景信息进而完成目标跟踪。 </p><p>判别类方法与生成类方法的根本不同在于判别类方法考虑背景信息与目标信息区分来进行判别模型的建立，由于判别类方法将背景与目标进行区分，因此该类方法在目标跟踪时的表现通常更为鲁棒，目前已经成为目标跟踪的主流跟踪方式。判别类方法包括相关滤波，深度学习方法。</p><blockquote><b>4.2 方向特点</b></blockquote><p>目标跟踪有一些难点：</p><p>(1) 目标表征表达问题，虽然深度学习方法具有很强的目标表征能力，但是仍然容易受相似环境的干扰。</p><p>(2) 目标快速运动，由于很多跟踪的物体都是高速运动，因此既要考虑较大的搜索空间，也要在保持实时性的前提下减小计算量。</p><p>(3) 变形，多尺度以及遮挡问题，当目标发生很大的形变或者临时被遮挡如何保持跟踪并且在目标重新出现时恢复跟踪。</p><h2><b>05 图像滤波与降噪</b></h2><blockquote><b>5.1 基本概念</b></blockquote><p>现实中的数字图像在数字化和传输过程中常受到成像设备与外部环境噪声干扰等影响，称为含噪图像或噪声图像。减少数字图像中噪声的过程称为图像降噪，有时候又称为图像去噪。 </p><p>降噪可以应用于图像增强和美颜等领域。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-57ece0bf94084a8f957dafedb9ee5239_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"400\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-57ece0bf94084a8f957dafedb9ee5239_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;400&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"400\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-57ece0bf94084a8f957dafedb9ee5239_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-57ece0bf94084a8f957dafedb9ee5239_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">传统方法：</code></pre></div><p>传统降噪算法根据降噪的原理不同可分为基于邻域像素特征的方法，基于频域变换的方法，和基于特定模型的方法。</p><p>基于空域像素特征的方法，是通过分析在一定大小的窗口内，中心像素与其他相邻像素之间在灰度空间的直接联系，来获取新的中心像素值的方法，因此往往都会存在一个典型的输入参数，即滤波半径r。此滤波半径可能被用于在该局部窗口内计算像素的相似性，也可能是一些高斯或拉普拉斯算子的计算窗口。在邻域滤波方法里面，最具有代表性的滤波方法有以下几种：算术均值滤波与高斯滤波，统计中值滤波，双边滤波，非局部平均滤波方法，BM3D算法。</p><div class=\"highlight\"><pre><code class=\"language-text\">深度学习方法：</code></pre></div><p>在2012年，随着Alexnet的出现，深度学习做去噪的工作取得了一些进展，可以达到和BM3D差不多的水平。对于仿真的噪声和固定的噪声，深度学习已经可以很好的去除，达到或超过传统领域里最好的算法。</p><p>利用卷积神经网络去除噪声的原理很简单，输入是一张有噪声的图，标签是一张无噪声的图，输出是一张降噪后的图，损失函数是无噪声groundtruth与网络输出的L2距离，网络通常就是与图像分割算法一样的网络，卷积+与之对称的反卷积。</p><blockquote><b>5.2 方向特点</b></blockquote><p>降噪的研究聚焦在真实数据的去噪声，因为真实世界的噪声不符合高斯加性噪声的假设，而且是依赖于信息本身的。不过，真实噪声图像和相应的无噪声图像获取是非常困难，慢慢的也有了一些benchmark，大家以后关注我们就知道了。</p><h2><b>06 图像增强</b></h2><blockquote><b>6.1 基本概念</b></blockquote><p>图像增强，即增强图像中的有用信息，改善图像的视觉效果。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-f13c3679357c343959216e21ccc26235_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"691\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-f13c3679357c343959216e21ccc26235_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;691&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"691\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-f13c3679357c343959216e21ccc26235_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-f13c3679357c343959216e21ccc26235_b.jpg\"/></figure><p>图像增强实际上包含了很多的内容，上面的降噪也属于其中，只是因为降噪多了美颜这一个应用单独拿出来说一下。</p><p><b>对比度增强</b>，用于扩大图像中不同物体特征之间的差别，抑制不感兴趣的特征，可用于改善图像的识别效果，满足某些特殊分析。</p><p><b>超分辨</b>，使图像变得更加清晰，可以用于视频的传输先进行降采样，再进行升采样，即降低了传输成本，又增加了视觉效果。</p><p><b>图像修复</b>，重建图像和视频中丢失或损坏的部分，也被称为图像插值或视频插值，主要是替换一些小区域和瑕疵，如photoshop中的印章工具。随着发展，已经从原先针对划痕、污点等的修复到现在对图像、视频中文字、物体等的移除，比如水印等。</p><div class=\"highlight\"><pre><code class=\"language-text\">传统方法：</code></pre></div><p>传统的方法就是一个预定义好的非线性变换，主要有三大类方法，一类是点操作，一类是直方图操作，一类是Retinex理论。</p><p>点操作也被称为直接对比度增强，将每个像素独立操作，包括对数变化，指数变化，负图像，阈值化等。我们熟知的gamma变换如下，可以进行不同形状的映射。</p><p>直方图操作也被称为间接对比度增强，包括直方图均衡，直方图匹配等。直方图均衡化通常用来增加图像的全局对比度，尤其是当图像中主体和背景对比度相当接近的时候。直方图均衡化的效果就是让直方图更均衡的分布，这种方法对于背景和前景都太亮或者太暗的图像非常有用，通常是曝光过度或者曝光不足的图片。</p><p>Retinex理论，即颜色恒常知觉的计算理论，Retinex是一个合成词，它的构成是retina（视网膜）+cortex（皮层），它将图像认为是reflectance和illumination的点乘，理论基础是在不同的照明条件下，物体的色彩不受光照非均性的影响是恒定的，而物体的颜色是由物体对长波、中波和短波光线的反射能力决定的而不是由反射光强度的绝对值决定。</p><div class=\"highlight\"><pre><code class=\"language-text\">深度学习方法：</code></pre></div><p>以增强对比度为例，深度学习方法使用了CNN来进行非线性变换的学习，而且通常不仅仅局限在对比度增强，经常会同时学习到降噪。深度学习的方法有两种，一种是采用成对的图片训练，比如pix2pix，learning in the dark，缺点是没有普适性，只能对所实验的数据集有用。一种是不需要成对图片训练，只需要好图，比如WESPE，常配合GAN使用。</p><blockquote><b>6.2 方向特点</b></blockquote><p>一个图像增强任务，传统方法需要分别进行降噪，颜色校正，对比度增强等各种操作，而深度学习算法的好处就是end-to-end输出，将整个流程丢给了网络。目前图像增强相对于前面的一些方向还是一个蓝海，覆盖的方向和应用非常广，有精力的朋友可以好好研究。</p><h2><b>07 风格化</b></h2><blockquote><b>7.1 基本概念</b></blockquote><p>图像风格化之所以引起我们的注意，完全是因为2015年的一个研究，可以将任意的图像转换为梵高的画作风格。 也是得益于深度学习技术的发展，传统的方法做不到这么好的效果。而随着美图秀秀，天天P图等app层出不穷的滤镜，风格化已经成为了单独的一个研究领域。 </p><p>图像风格化是一个综述性的技术应用，为了简单起见，就理解为艺术类滤镜把，它指通过算法，将数码相机拍摄的照片，变成绘画、素描等艺术类的非数码相机效果，是后期程度最深的操作，将彻底改变相片的风格。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ff2df554820116240baa5400f9f940c1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"736\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-ff2df554820116240baa5400f9f940c1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;736&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"736\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-ff2df554820116240baa5400f9f940c1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ff2df554820116240baa5400f9f940c1_b.jpg\"/></figure><blockquote><b>深度学习方法：</b></blockquote><p>以A Neural Algorithm of Artistic Style 论文发表为起始，Prisma滤镜为典型代表。虽然风格迁移技术的发展日新月异，但是最革命性的还是该文章的方法，这是德国图宾根大学的研究，它通过分析某种风格的艺术图片，能将图片内容进行分离重组，形成任意风格的艺术作品，最开始的时候需要将近一个小时来处理。</p><p>就是把一幅图作为底图，从另外一幅画抽取艺术风格，重新合成新的艺术画，可以参考上面的图。</p><p>研究者认为，图片可以由<b>内容层（Content）与风格层（Style）两个图层描述</b>，相互分离开。在图像处理中经常将图像分为粗糙层与细节层，即前者描述图像的整体信息，后者描述图像的细节信息，具体可以通过高斯金字塔来得到。</p><p>卷积神经网络的各个神经元可以看做是一个图像滤波器，而输出层是由输入图像的不同滤波器的组合，深度由浅到深，内容越来越抽象。 </p><p>底层信息重建，则可以得到细节，而从高层信息重建，则得到图像的”风格“。因此，可以选择两幅图像，一幅构建内容信息，一幅构建风格信息，分别进行Content重建与Style 重建。通过将内容与风格组合，可以得到新的视觉信息更加有意思的图像，如计算机油画，这就是它的基本原理。方法的核心在于损失函数的设计，包括<b>内容损失和风格损失</b>。 </p><p>内容损失在像素空间，要求风格化后的图能够保证内容的完整性。风格损失使用vgg特征空间的gram矩阵，这样就有了较高的抽象层级，实践结果表明可以很好的捕捉风格。</p><blockquote><b>7.2 方向特点</b></blockquote><p>如今风格化方法在很多地方都有应用，比如大家熟悉的变脸等。方法也演变成了几个方向；</p><p>（1）单模型单风格，即一个网络只能做一种风格化。</p><p>（2）单模型多风格，即一个网络可以实现多种风格，比（1）实用的多。</p><p>（3）单模型任意风格，即一个网络可以任意风格，视输入图像而定，这是最好的，更多的研究我们以后会开专题。</p><h2><b>08 三维重建</b></h2><blockquote><b>8.1 基本概念</b></blockquote><p>什么是三维重建呢？广义上来说，是建立真实世界的三维模型。随着软硬件的成熟，在电影，游戏，安防，地图等领域，三维重建技术的应用越来越多。目前获取三维模型的方法主要包括三种，<b>手工建模，仪器采集与基于图像的建模</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-fc285b7a560964d6645278f6023e91b8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"317\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-fc285b7a560964d6645278f6023e91b8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;317&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"317\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-fc285b7a560964d6645278f6023e91b8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-fc285b7a560964d6645278f6023e91b8_b.jpg\"/></figure><p>(1) 手工建模作为最早的三维建模手段，现在仍然是最广泛地在电影，动漫行业中应用。顶顶大名的3DMax就是典型代表，当然了，它需要专业人士来完成。</p><p>(2) 由于手工建模耗费大量的人力，三维成像仪器也得到了长期的研究和发展。基于结构光（structured light）和激光扫描技术的三维成像仪是其中的典型代表。这些基于仪器采集的三维模型，精度可达毫米级，是物体的真实三维数据，也正好用来为基于图像的建模方法提供评价数据库。由于仪器的成本太高，一般的用户是用不上了。</p><p>(3) 基于图像的建模技术（image based modeling），顾名思义，是指通过若干幅二维图像，来恢复图像或场景的三维结构，这些年得到了广泛的研究。</p><p>我们这里说的三维重建，就特指<b>基于图像的三维重建方法</b>，而且为了缩小范围，只说人脸图像，并简单介绍其中核心的3DMM模型。</p><div class=\"highlight\"><pre><code class=\"language-text\">3DMM模型：</code></pre></div><p>人脸三维重建方法非常多，有基于一个通用的人脸模型，然后在此基础上进行变形优化，会牵涉到一些模板匹配，插值等技术。有基于立体匹配（各种基于双目，多目立体视觉匹配）的方法，通过照相机模型与配准多幅图像，坐标系转换，获取真实的三维坐标，然后进行渲染。有采用一系列的人脸作为基，将人脸用这些基进行线性组合的方法，即Morphable models方法。</p><p>其中，能够融会贯通不同传统方法和深度学习方法的，就是3<b>D Morphable Models系列</b>方法，从传统方法研究到深度学习。</p><p>它的思想就是一幅人脸可以由其他许多幅人脸加权相加而来，学过线性代数的就很容易理解这个正交基的概念。我们所处的三维空间，每一点(x,y,z)，实际上都是由三维空间三个方向的基量，(1,0,0)，(0,1,0)，(0,0,1)加权相加所得，只是权重分别为x,y,z。</p><p>转换到三维空间，道理也一样。每一个三维的人脸，可以由一个数据库中的<b>所有人脸组成的基向量空间中进行表示</b>，而求解任意三维人脸的模型，实际上等价于求解各个基向量的系数的问题。</p><p>每一张人脸可以表示为：</p><p>形状向量Shape Vector：S=(X1,Y1,Z1,X2,Y2,Z2,...,Yn,Zn)</p><p>纹理向量Texture Vector：T=(R1,G1,B1,R2,G2,B2,...,Rn,Bn)</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-bd30e122650b09c1df8182116b84ac55_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"257\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-bd30e122650b09c1df8182116b84ac55_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;257&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"257\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-bd30e122650b09c1df8182116b84ac55_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-bd30e122650b09c1df8182116b84ac55_b.jpg\"/></figure><p> 而一张任意的人脸，其等价的描述如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-0ccc11429ce0d5e9f8296be3f516b4d0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"866\" data-rawheight=\"184\" class=\"origin_image zh-lightbox-thumb\" width=\"866\" data-original=\"https://pic1.zhimg.com/v2-0ccc11429ce0d5e9f8296be3f516b4d0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;866&#39; height=&#39;184&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"866\" data-rawheight=\"184\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"866\" data-original=\"https://pic1.zhimg.com/v2-0ccc11429ce0d5e9f8296be3f516b4d0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-0ccc11429ce0d5e9f8296be3f516b4d0_b.jpg\"/></figure><p>其中第一项Si，Ti是形状和纹理的平均值，而si，ti则都是Si，Ti减去各自平均值后的协方差矩阵的特征向量。 基于3DMM的方法，都是在求解α，β这一些系数，当然现在还会有表情，光照等系数，但是原理都是通用的。</p><p>原理就说到这里，我们以后会专门讲述。</p><blockquote><b>8.2 方向特点</b></blockquote><p>人脸的三维建模有一些独特的特点。</p><p>（1）预处理技术非常多，人脸检测与特征点定位，人脸配准等都是现在研究已经比较成熟的方法。利用现有的人脸识别与分割技术，可以缩小三维人脸重建过程中需要处理的图像区域，而在有了可靠的关键点位置信息的前提下，可以建立稀疏的匹配，大大提升模型处理的速度。</p><p>（2）人脸共性多。正常人脸都是一个鼻子两只眼睛一个嘴巴两只耳朵，从上到下从左到右顺序都不变，所以可以首先建立人脸的参数化模型，实际上这也是很多方法所采用的思路。</p><p>人脸三维重建也有一些困难。</p><p>（1）人脸生理结构和几何形状非常复杂，没有简单的数学曲面模型来拟合。</p><p>（2）光照变化大。同一张脸放到不同的光照条件下，获取的图像灰度值可能大不一样的，这些都会影响深度信息的重建。</p><p>（3）特征点和纹理不明显。图像处理最需要的就是明显的特征，而光滑的人脸除了特征关键点，很难在脸部提取稠密的有代表性的角点特征。这个特点，使得那些采用人脸配准然后求取三维坐标的方法面临着巨大的困难。</p><h2><b>09 图像检索</b></h2><blockquote><b>9.1 基本概念</b></blockquote><p>图像检索的研究从20世纪70年代就已经开始，在早期是基于文本的图像检索技术（Text-based Image Retrieval，简称TBIR），利用文本来描述图像的特征，如绘画作品的作者、年代、流派、尺寸等。随着计算机视觉技术的发展，90年代开始出现了对图像的内容语义，如图像的颜色、纹理、布局等进行分析和检索的图像检索技术，也就是<b>基于内容的图像检索</b>（Content-based Image Retrieval，简称CBIR）技术，本小节的图像检索就特指基于内容的图像检索。</p><p>基于内容的图像检索也经历了传统方法和深度学习方法两个主要阶段，传统的基于内容的图像检索通常包括以下流程：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-b1ade3093e5175c081ec337aad18e1db_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"328\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-b1ade3093e5175c081ec337aad18e1db_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;328&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"328\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-b1ade3093e5175c081ec337aad18e1db_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-b1ade3093e5175c081ec337aad18e1db_b.jpg\"/></figure><p>预处理，通常包括一些图像归一化，图像增强等操作。特征提取，即提取一些非常鲁棒的图像特征，比如SIFT，HoG等特征。特征库就是要查询的库，库中不存储图像而是存储特征，每一次检索图像完成特征提取之后，就在特征库中进行匹配和相似度计算。索引就是在某种相似性度量准则下计算查询向量到特征库中各个特征的相似性大小，最后按相似性大小进行高效的排序并顺序输出对应的图片。</p><p><b>图像检索的中最复杂的一步就是检索</b>，在这一步完成验证过程。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-135ddc5f5c7f1edc2ec5e00df9585fdf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"755\" data-rawheight=\"246\" class=\"origin_image zh-lightbox-thumb\" width=\"755\" data-original=\"https://pic4.zhimg.com/v2-135ddc5f5c7f1edc2ec5e00df9585fdf_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;755&#39; height=&#39;246&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"755\" data-rawheight=\"246\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"755\" data-original=\"https://pic4.zhimg.com/v2-135ddc5f5c7f1edc2ec5e00df9585fdf_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-135ddc5f5c7f1edc2ec5e00df9585fdf_b.jpg\"/></figure><p>最简单的方法就是暴力(brute-force) 搜索方法(又称线性扫描)，即逐个与数据库中的每个点进行相似性计算然后进行排序，这种简单粗暴的方式虽然很容易实现，但是会随着数据库的大小以及特征维度的增加其搜索代价也会逐步的增加，从而限制在数据量小的小规模图像数据库，在大规模图像库上这种暴力搜索的方式不仅消耗巨大的计算资源，而且单次查询的响应时间会随着数据样本的增加以及特征维度的增加而增加，为了降低搜索的空间的空间复杂度与时间复杂度，研究者们提出了很多高效的检索技术，其中最成功的大家也最熟悉到方法<b>是基于哈希的图像检索方法</b>。</p><p>深度学习在图像检索里面的作用就是<b>把表征样本的特征学习好</b>，就够了。</p><blockquote><b>9.2 方向特点</b></blockquote><p>图像检索系统具有非常大的商业价值，从搜索引擎的以图搜图，到人脸验证和识别系统，到一些搜索排序系统(比如基于美学的摄影图库)。由于图像特征的学习是一个通用的研究方向，因此更多的在于设计高效的检索系统。 </p><h2><b>10 GAN</b></h2><blockquote><b>10.1 基本概念</b></blockquote><p>GAN，即Generative adversarial net，被誉为新的深度学习，涉及的研究非常多，可以单列为一个方向，一个经典的网络结构如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-bf50d580d656914a6970d5b5ab8a036a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1054\" data-rawheight=\"446\" class=\"origin_image zh-lightbox-thumb\" width=\"1054\" data-original=\"https://pic3.zhimg.com/v2-bf50d580d656914a6970d5b5ab8a036a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1054&#39; height=&#39;446&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1054\" data-rawheight=\"446\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1054\" data-original=\"https://pic3.zhimg.com/v2-bf50d580d656914a6970d5b5ab8a036a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-bf50d580d656914a6970d5b5ab8a036a_b.jpg\"/></figure><p>GAN的原理很简单，它包括两个网络，一个生成网络，不断生成数据分布。一个判别网络，判断生成的数据是否为真实数据。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c59dc8ad0c3d52e9369243d774939a8c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"366\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c59dc8ad0c3d52e9369243d774939a8c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;366&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"366\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c59dc8ad0c3d52e9369243d774939a8c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c59dc8ad0c3d52e9369243d774939a8c_b.jpg\"/></figure><p>上图是原理展示，黑色虚线是真实分布，绿色实线是生成模型的学习过程，蓝色虚线是判别模型的学习过程，两者相互对抗，共同学习到最优状态。</p><p>关于GAN的基础，我们以前已经写过相关的内容，大家去看就可以了。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029396%26idx%3D1%26sn%3D2d92874e0b94dd2174d216ce1da4f1ce%26chksm%3D87134569b064cc7f5f2476fdc87df968b353c2eae24f6820a5af2ee983ca49be55d34588c19e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】有三说GANs（上）</a> </p><blockquote><b>10.2 方向特点</b></blockquote><p>作为新兴和热门方向，GAN包含的研究方向非常的广，包括GAN的应用，GAN的优化目标，GAN的模型发展，GAN的训练技巧，GAN的理论分析，GAN的可视化等等，以后等着我们的分享即可。 </p><p>深度学习彻底点燃和推进了计算机视觉各大领域的研究，这是个可以投以终身的行业，希望你会喜欢。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }, 
                {
                    "tag": "图像处理", 
                    "tagLink": "https://api.zhihu.com/topics/19556376"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "陈大宝", 
                    "userLink": "https://www.zhihu.com/people/967eac0a5a0780b7603da0051278abda", 
                    "content": "(´-ω-`)有点老哦，现在你说的很多方法都已经out of date了", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "对，这个就是一个通用介绍", 
                            "likes": 0, 
                            "replyToAuthor": "陈大宝"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "也不算针对小白的，友好度不高啊", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "因为内容太多了，所以是精炼的介绍", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "呼啦啦呼啦啦", 
                    "userLink": "https://www.zhihu.com/people/6c098f3b15594583563d6a4ff41537cd", 
                    "content": "[赞]真的棒", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55873832", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 9, 
            "title": "【AI白身境】AI+，都加在哪些应用领域了", 
            "content": "<p>今天是新专栏<b>《AI白身境》</b>的第十一篇，所谓白身，就是什么都不会，还没有进入角色。</p><p>要说现在什么最火，那都不用说，肯定是AI。AI已经渗入到了我们生活的方方面面。除了大家熟知的自动驾驶汽车、图像美颜，聊天机器人等，还有许多方面都应用到了AI，今天我就和大家聊下AI当前在各大领域的应用。</p><p>                                                                                                                         作者 | 汤兴旺 言有三</p><p>                                                                                                                         编辑 | 汤兴旺 言有三</p><h2><b>01 AI+交通</b></h2><p>既然要说AI+交通，那就不得不提自动驾驶了，自动驾驶作为AI与制造业的一大产物，目前各大主机厂和IT公司都想在自动驾驶领域分一杯羹。另外值得注意的是领导人在2019年1月21日的中央党校的一个研讨班的开班仪式上强调要加快“自动驾驶的立法”，这说明什么，应该不需要我多言。自动驾驶在未来绝对是最热门的领域之一，当然自动驾驶发展的怎么样，必须要看AI能发展到什么程度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e9230e3abd70a655c0a8d14ba2892be5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"866\" data-rawheight=\"509\" class=\"origin_image zh-lightbox-thumb\" width=\"866\" data-original=\"https://pic2.zhimg.com/v2-e9230e3abd70a655c0a8d14ba2892be5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;866&#39; height=&#39;509&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"866\" data-rawheight=\"509\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"866\" data-original=\"https://pic2.zhimg.com/v2-e9230e3abd70a655c0a8d14ba2892be5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e9230e3abd70a655c0a8d14ba2892be5_b.jpg\"/></figure><p>上图是2018年央视春晚珠海分会场，由百度Apollo无人车领衔的百余辆无人车精彩亮相的画面。是不是很震撼。</p><p>当前自动驾驶技术的关键还是在环境感知、决策规划和控制这三个方面。而要想环境感知有更好的发展，以深度学习为代表的 AI 技术如计算机视觉等非常重要。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>02 AI+医疗</b></h2><p>根据美国著名市场调研机构Tractica的数据显示，预计到2025年，医疗机构将为人工智能支付超过340亿美元，2018年为21亿美元。这说明医疗卫生行业对AI的迫切需要！</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-447645414d8c4ad29220d605c6b1104a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"426\" data-rawheight=\"301\" class=\"origin_image zh-lightbox-thumb\" width=\"426\" data-original=\"https://pic3.zhimg.com/v2-447645414d8c4ad29220d605c6b1104a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;426&#39; height=&#39;301&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"426\" data-rawheight=\"301\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"426\" data-original=\"https://pic3.zhimg.com/v2-447645414d8c4ad29220d605c6b1104a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-447645414d8c4ad29220d605c6b1104a_b.jpg\"/></figure><p>医疗卫生行业对AI的迫切需求主要在以下几个方面：</p><p>1、医学数据分析需求</p><p>AI能通过患者数据训练的深度学习诊疗模型，快速筛选出适合患者的药物和治疗方案，追踪和预测个体疾病的进程。</p><p>2、远程医疗</p><p>人工智能的影响不仅在医院内部的临床诊疗工作，还将提升院外服务的可及性。一旦患者离开医院，医生可能难以确保患者遵守规定的治疗计划或监测慢性健康状况，AI能够弥合时间和空间距离，实现信息的高效传输和共享，这将帮助医生及时了解患者的健康状况。</p><p>3、促进医疗行为规范化</p><p>引入医疗AI工具，在诊疗流程中能督促医生按照临床诊疗规范执行医疗方法，这将大大减少不规范行为给患者带来的安全威胁。</p><p>4、新药开发</p><p>新药研发的目标是找到可调控机体生物学功能的实体物质，如小分子、大分子或生物活体等；然而优质靶点的寻找很难，而且一旦出现一个获得临床验证的新靶点，叠罗汉式的实验前仆后继并不鲜见，研发成本会是疯狂增加。为了解决这个问题，现在我们可以将人工智能的相关技术应用于疾病的靶点预测、高通量数据的分析以及系统生物学的建模过程中。</p><h2><b>03 AI+金融 </b></h2><p>当前人工智能的应用已广泛渗透到金融行业中，且日渐成熟，并推动银行、保险、资本市场三大金融行业的深刻变革。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a2ec4016f210bc13dd60b8aebc90f027_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"394\" data-rawheight=\"80\" class=\"content_image\" width=\"394\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;394&#39; height=&#39;80&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"394\" data-rawheight=\"80\" class=\"content_image lazy\" width=\"394\" data-actualsrc=\"https://pic4.zhimg.com/v2-a2ec4016f210bc13dd60b8aebc90f027_b.jpg\"/></figure><p>AI在金融方面的应用主要集中在以下几个方面：</p><p><b>1、信用评分</b></p><p>以往的多数信用评分模型，大多数是使用金融机构的交易与支付数据，并运用回归、决策树、统计分析等工具来生成信用评分。现在，银行等金融机构日益使用新型的非结构化与半结构化的数据来源(如社交媒体、手机和短信)来捕捉借款人的信用，并用人工智能来评估消费者行为和支付意愿等定性因素，使筛选借款人的速度更快、成本更低。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b2af06fa546006792f407809dfc89224_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"670\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b2af06fa546006792f407809dfc89224_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;670&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"670\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b2af06fa546006792f407809dfc89224_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b2af06fa546006792f407809dfc89224_b.jpg\"/></figure><p><b>2.金融AI机器人</b></p><p>金融AI机器人是用于帮助客户处理问题的虚拟助手，其使用NLP自然语言与客户交互，并使用机器学习算法来优化。当前许多金融服务公司在其移动应用程序或公司里面都引入了AI机器人。下图就是日本瑞穗银行的机器人顾问。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-77812e5032c3c487dadabacc270e40f8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"241\" class=\"origin_image zh-lightbox-thumb\" width=\"498\" data-original=\"https://pic1.zhimg.com/v2-77812e5032c3c487dadabacc270e40f8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;498&#39; height=&#39;241&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"241\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"498\" data-original=\"https://pic1.zhimg.com/v2-77812e5032c3c487dadabacc270e40f8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-77812e5032c3c487dadabacc270e40f8_b.jpg\"/></figure><p>当前在金融业AI应用还有很多，如优化金融资本、模型风险管理与压力测试、投资组合管理等方面。可以说AI促进金融业更加智能化，更好的为公众服务。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>04 AI+教育</b></h2><p>在人工智能风潮的引领下，AI+教育的浪潮如火如荼，国内的各大教育机构如新东方、英语流利说都迅速在AI领域跑马圈地，试图用人工智能变革传统的教育体系。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a5074df19078893151792ab7659eba10_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"648\" data-rawheight=\"182\" class=\"origin_image zh-lightbox-thumb\" width=\"648\" data-original=\"https://pic1.zhimg.com/v2-a5074df19078893151792ab7659eba10_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;648&#39; height=&#39;182&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"648\" data-rawheight=\"182\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"648\" data-original=\"https://pic1.zhimg.com/v2-a5074df19078893151792ab7659eba10_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a5074df19078893151792ab7659eba10_b.jpg\"/></figure><p>在AI+教育做的最多的应该就是英语流利说了，他们有个口号就是“用AI替代真人老师”。下图是英语流利说的英语水平测试：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-109f3d094ce81ff5a024bc21accf3ea3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"976\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-109f3d094ce81ff5a024bc21accf3ea3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;976&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"976\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-109f3d094ce81ff5a024bc21accf3ea3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-109f3d094ce81ff5a024bc21accf3ea3_b.jpg\"/></figure><p>据介绍其可以精准定位用户英语水平，然后量身定制系统课程。有兴趣的可以测一下水平，这个是免费的。</p><p>在AI+教育领域还有个比较好的应用——魔镜系统。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-96049c700ce89ea43576ed1fdf89a991_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"530\" data-rawheight=\"353\" class=\"origin_image zh-lightbox-thumb\" width=\"530\" data-original=\"https://pic2.zhimg.com/v2-96049c700ce89ea43576ed1fdf89a991_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;530&#39; height=&#39;353&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"530\" data-rawheight=\"353\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"530\" data-original=\"https://pic2.zhimg.com/v2-96049c700ce89ea43576ed1fdf89a991_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-96049c700ce89ea43576ed1fdf89a991_b.jpg\"/></figure><p>魔镜系统是好未来自主研发的人工智能教学辅助系统。该系统可以借助摄像头捕捉学生上课时的举手、练习、听课、发言等课堂状态和面部情绪变化数据，生成专属于每一个学生的学习报告。其提供的多维度量化数据，能够真实反映出学生学习过程中的每个阶段、每种状态，帮助老师基于科学数据而调整、优化教学方案，帮助学生更好地提升专注度，实现更高效的学习，同时也可以使每一个孩子都得到充分的关注；另外它能利用表情动作识别，可以产出孩子整堂课专注度曲线以及学习状态小视频，父母即使不去陪读也可以轻松了解孩子在课堂的学习状态。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>05 AI+农业</b></h2><p>要提到农业与AI，大家可能有点不可思议，AI这么高科技的东西能应用到农业吗？哈哈，当然能，而且AI与农业的结合可以说效果显著。现在靠天吃饭的农业正在发生巨大转变，人工智能可以使农场品更安全、更营养、更值钱。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a411471f889eaf43d8ffb8232ae45ff7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"635\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb\" width=\"635\" data-original=\"https://pic4.zhimg.com/v2-a411471f889eaf43d8ffb8232ae45ff7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;635&#39; height=&#39;420&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"635\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"635\" data-original=\"https://pic4.zhimg.com/v2-a411471f889eaf43d8ffb8232ae45ff7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a411471f889eaf43d8ffb8232ae45ff7_b.jpg\"/></figure><p>在2018年6月7日的云栖大会·上海峰会上，阿里云正式发布ET农业大脑。其目标是希望将人工智能与农业深入结合，目前已应用于生猪养殖、苹果及甜瓜种植，已具备数字档案生成、全生命周期管理、智能农事分析、全链路溯源等功能。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>06 AI+新零售</b></h2><p>大家应该都听过新零售这个词，按照阿里的解释，新零售就是以消费者体验为中心的数据驱动的泛零售形态。说简单点实际上就是AI与我们平时见到的零售相结合。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4f65ab30a32642a48d75785b4f8171da_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"332\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic3.zhimg.com/v2-4f65ab30a32642a48d75785b4f8171da_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;332&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"332\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic3.zhimg.com/v2-4f65ab30a32642a48d75785b4f8171da_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4f65ab30a32642a48d75785b4f8171da_b.jpg\"/></figure><p>说到新零售就不得不提阿里旗下的盒马鲜生了，其是阿里巴巴对线下超市完全重构的新零售业态。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a003a89073e1c0c1dbd811f33fa0cf97_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"609\" data-rawheight=\"244\" class=\"origin_image zh-lightbox-thumb\" width=\"609\" data-original=\"https://pic4.zhimg.com/v2-a003a89073e1c0c1dbd811f33fa0cf97_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;609&#39; height=&#39;244&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"609\" data-rawheight=\"244\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"609\" data-original=\"https://pic4.zhimg.com/v2-a003a89073e1c0c1dbd811f33fa0cf97_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a003a89073e1c0c1dbd811f33fa0cf97_b.jpg\"/></figure><p>阿里巴巴能够为盒马鲜生的消费者提供会员服务，用户可以使用淘宝或支付宝账户注册，以便消费者从最近的商店查看和购买商品。盒马未来可以跟踪消费者购买行为，借助大数据做出个性化的建议。</p><p>除了盒马鲜生，阿里的淘咖啡也是一个新零售的典型。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-8331a2ec1dcade0613832a0a961e441f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-8331a2ec1dcade0613832a0a961e441f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-8331a2ec1dcade0613832a0a961e441f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-8331a2ec1dcade0613832a0a961e441f_b.jpg\"/></figure><p>用户首次进店后需通过手机淘宝扫码获得电子入场码，通过认证闸机后可以开始购物。最后离开时，用户必须经过两道门，第一道门感应到用户的离店需求时自动开启，经过几秒结算时间后开启第二道门，顾客可离店。</p><p>淘咖啡在技术上主要采用生物特征自主感知和学习系统、结算意图识别和交易系统、目标检测与追踪系统来追踪消费者在店内的行为及运动轨迹。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>07 AI+家居</b></h2><p>智能家居可以说是近年来最热门的话题之一。随着科技的发展，从感应采光调节室内光线的智能灯到输入指令就可自动扫地的机器人，从记录食物新鲜程度的冰箱到能识别指纹和人脸的门锁，曾经只能在科幻大片中见到的场景正渐渐成为现实。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-748af53d82afef56cf88117b1873db04_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"359\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-748af53d82afef56cf88117b1873db04_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;359&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"359\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-748af53d82afef56cf88117b1873db04_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-748af53d82afef56cf88117b1873db04_b.jpg\"/></figure><p>上图是电影《钢铁侠》中无所不能的智能管家Jarvis，而扎克伯格受此启发设计出了类似的AI系统来控制智能家居，也命令为Jarvis，在Jarvis的帮助下，扎克伯克可以用手机和电脑来调节空调温度、室内灯光明暗，还能烤面包，从网上搜索歌曲自动播放。另外Jarvis 系统识别访客的功能也非常好，扎克伯格在自己家门口安装了多个摄像头，从不同角度拍摄家门口的画面。当访客靠近时，Jarvis 系统会马上识别到门口有人，然后激活程序，对访客的面部细节进行探测，接着会在 Facebook人脸数据库中找到对应的目标，并根据扎克伯格的日程表及访客名单来判断对方是否为不速之客，确认后才会打开门，并告知扎克伯格客人已经到了。哈哈你是不是也想要有一个这样的智能家居！</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>08 AI+体育</b></h2><p>在体育领域，人们开始对AI格外关注应该是在2016年李世石和谷歌围棋AI“AlphaGo”的比赛，根据媒体报道，比赛的第一天吸引了全球共计1亿人次观看，这应该是AI在体育领域第一次大规模的爆发。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-89e442bcd4f65a10ea46a1bb2badd09b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"543\" data-rawheight=\"302\" class=\"origin_image zh-lightbox-thumb\" width=\"543\" data-original=\"https://pic4.zhimg.com/v2-89e442bcd4f65a10ea46a1bb2badd09b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;543&#39; height=&#39;302&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"543\" data-rawheight=\"302\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"543\" data-original=\"https://pic4.zhimg.com/v2-89e442bcd4f65a10ea46a1bb2badd09b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-89e442bcd4f65a10ea46a1bb2badd09b_b.jpg\"/></figure><p>现在体育行业有许多方面都涉及了AI技术。下面和大家介绍一些体育方面的AI，如下：</p><p><b>1、比赛精彩视频引入AI技术</b></p><p>在2018年俄罗斯世界杯开赛前夕，IBM和美国福克斯体育（Fox Sports）合作制作一个AI平台。IBM的解决方案包括分析视觉、音频、文本数据，福克斯体育将利用IBM沃森媒体的功能来进行自动高级元数据标记以及快速筛选新的和存档视频片段，以识别比赛时刻并生成实时的精彩视频。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-70b2206ee994a55789bc329e61e02755_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"583\" data-rawheight=\"384\" class=\"origin_image zh-lightbox-thumb\" width=\"583\" data-original=\"https://pic2.zhimg.com/v2-70b2206ee994a55789bc329e61e02755_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;583&#39; height=&#39;384&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"583\" data-rawheight=\"384\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"583\" data-original=\"https://pic2.zhimg.com/v2-70b2206ee994a55789bc329e61e02755_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-70b2206ee994a55789bc329e61e02755_b.jpg\"/></figure><p>现在在腾讯体育的NBA直播比赛中同样也有这样的AI技术，他们利用IBM AI Vision视觉大脑来快速完成对精彩瞬间的剪辑。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-03288cbdd6d2b5f6db93ca6347ce9ae4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"950\" data-rawheight=\"532\" class=\"origin_image zh-lightbox-thumb\" width=\"950\" data-original=\"https://pic1.zhimg.com/v2-03288cbdd6d2b5f6db93ca6347ce9ae4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;950&#39; height=&#39;532&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"950\" data-rawheight=\"532\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"950\" data-original=\"https://pic1.zhimg.com/v2-03288cbdd6d2b5f6db93ca6347ce9ae4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-03288cbdd6d2b5f6db93ca6347ce9ae4_b.jpg\"/></figure><p><b>2、AI裁判</b></p><p>国际体操联合会当前和日本通信技术公司富士通（Fujitsu）合作，计划把AI技术引进东京奥运会的打分系统，利用3D传感器接收的数据并结合AI分析鞍马和自由体操等体操项目，让AI分担一部分裁判工作。AI技术的引入，在一定程度上，能够使评分系统更加公正。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-7b40f6ad7dc35ab602312a7fefb82140_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"366\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic1.zhimg.com/v2-7b40f6ad7dc35ab602312a7fefb82140_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;366&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"366\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic1.zhimg.com/v2-7b40f6ad7dc35ab602312a7fefb82140_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-7b40f6ad7dc35ab602312a7fefb82140_b.jpg\"/></figure><p><b>3、智能运动鞋</b></p><p>在2019年的1月16日，耐克发布了新款运动鞋Nike Adapt BB。这双篮球鞋可不一般，是一双智能篮球鞋，它可以自系鞋带，还能与智能手机应用程序配合使用以调整合脚度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e94df41c52b6609faf919b2cbb49dab4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"713\" data-rawheight=\"242\" class=\"origin_image zh-lightbox-thumb\" width=\"713\" data-original=\"https://pic1.zhimg.com/v2-e94df41c52b6609faf919b2cbb49dab4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;713&#39; height=&#39;242&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"713\" data-rawheight=\"242\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"713\" data-original=\"https://pic1.zhimg.com/v2-e94df41c52b6609faf919b2cbb49dab4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e94df41c52b6609faf919b2cbb49dab4_b.jpg\"/></figure><p>AI在体育方面的应用还有很多，相信在未来，大数据和人工智能将是推动体育产业发展的最重要的角色之一。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>09 AI+电竞</b></h2><p>最近几年随着英雄联盟、王者荣耀、绝地求生等游戏大火，电子竞技也变的火爆起来。现在似乎每个小孩都会玩王者荣耀。哈哈，你曾经被“小学生”坑过不！这就是现在电子游戏的火爆程度。现在随着AI技术的发展，许多游戏也都引入了AI，下面将介绍下AI在游戏中的应用。</p><p><b>1、王者荣耀AI“绝悟”</b></p><p>“绝悟”的首次露面是在2018KPL秋季赛的总决赛上（12月22日），当时“绝悟”与前KPL职业选手和职业解说组成的人类战队（平均水平超过99%玩家）进行5V5的水平测试，并取得胜利。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-3c67da0f255fb37b73f2db2d26c60cbd_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"598\" data-rawheight=\"336\" data-thumbnail=\"https://pic2.zhimg.com/v2-3c67da0f255fb37b73f2db2d26c60cbd_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"598\" data-original=\"https://pic2.zhimg.com/v2-3c67da0f255fb37b73f2db2d26c60cbd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;598&#39; height=&#39;336&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"598\" data-rawheight=\"336\" data-thumbnail=\"https://pic2.zhimg.com/v2-3c67da0f255fb37b73f2db2d26c60cbd_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"598\" data-original=\"https://pic2.zhimg.com/v2-3c67da0f255fb37b73f2db2d26c60cbd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-3c67da0f255fb37b73f2db2d26c60cbd_b.gif\"/></figure><p>这次“绝悟”的出现，不仅仅只是KPL秋季赛总决赛的惊鸿一瞥，更标志着我们对“AI+电竞”的全新探索。</p><p><b>2、星际争霸2AI“AlphaStar”</b></p><p>AlphaStar是谷歌的子公司Deepmind在游戏领域推出的一款对战型游戏AI作品。在2019年1月24日，AlphaStar与《星际争霸2》的两位职业选手TLO和MaNa对战，都取得了5:0的骄人战绩。据了解，目前的AlphaStar已经十分成熟了，它相当于拥有200年《星际争霸 2》游戏经验的玩家。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-74ef53dacf39d3e0a8a3f48286fe495a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"662\" data-rawheight=\"373\" class=\"origin_image zh-lightbox-thumb\" width=\"662\" data-original=\"https://pic3.zhimg.com/v2-74ef53dacf39d3e0a8a3f48286fe495a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;662&#39; height=&#39;373&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"662\" data-rawheight=\"373\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"662\" data-original=\"https://pic3.zhimg.com/v2-74ef53dacf39d3e0a8a3f48286fe495a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-74ef53dacf39d3e0a8a3f48286fe495a_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>10 AI+直播</b></h2><p>你曾想过AI与直播这两个新的东西碰到一起会产生怎样的火花吗？下面请看AI在直播中的应用。</p><p><b>1、AI+直播内容审核</b></p><p>直播平台利用深度学习算法，通过模拟人脑神经网络，构建具有高层次表现力的模型，能够对高复杂度数据形成良好的解读。这样在审核违法内容时能有效节省人工复审的工作，大大的提高了工作效率。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-59516deb034eee02d38daf034f66b022_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"545\" data-rawheight=\"263\" class=\"origin_image zh-lightbox-thumb\" width=\"545\" data-original=\"https://pic3.zhimg.com/v2-59516deb034eee02d38daf034f66b022_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;545&#39; height=&#39;263&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"545\" data-rawheight=\"263\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"545\" data-original=\"https://pic3.zhimg.com/v2-59516deb034eee02d38daf034f66b022_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-59516deb034eee02d38daf034f66b022_b.jpg\"/></figure><p><b>2、AI+直播个性化推荐</b></p><p>现在许多直播平台把AI技术实际运用到了直播之中，利用其进行内容分析，并作出智能优化，为观众提供更加优质的内容。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-224b053ed8093f93937e8da068238ba7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"682\" data-rawheight=\"95\" class=\"origin_image zh-lightbox-thumb\" width=\"682\" data-original=\"https://pic4.zhimg.com/v2-224b053ed8093f93937e8da068238ba7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;682&#39; height=&#39;95&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"682\" data-rawheight=\"95\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"682\" data-original=\"https://pic4.zhimg.com/v2-224b053ed8093f93937e8da068238ba7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-224b053ed8093f93937e8da068238ba7_b.jpg\"/></figure><p>就比如拿目前最受欢迎的游戏之一绝地求生来说，虎牙直播运用AI技术建立了全新的观看模式，自动分析直播内容，让玩家更加直观的找到想看的内容。比如：决赛圈、单排、双排等功能。</p><p>AI与产业结合实际上才刚刚开始，每个科技公司都在圈地，对于我们来说，最重要的或许就是在扎实的基础上不断创新，不断跟上潮流！</p><p><i>下期预告：下一期我们会介绍AI领域值得关注的研究者，如果你有建议，欢迎留言，我们会及时采纳的。</i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }, 
                {
                    "tag": "自动驾驶", 
                    "tagLink": "https://api.zhihu.com/topics/19635352"
                }, 
                {
                    "tag": "游戏AI", 
                    "tagLink": "https://api.zhihu.com/topics/20190693"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55566549", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 13, 
            "title": "【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分", 
            "content": "<p>今天是新专栏《AI白身境》的第九篇，所谓白身，就是什么都不会，还没有进入角色。</p><p>咱们这个系列接近尾声了，今天来讲一个非常重要的话题，也是很多的小伙伴们关心的问题。要从事AI行业，吃这碗饭，至少应该先储备一些什么样的数学基础再开始。</p><p>下面从<b>线性代数，概率论与统计学，微积分和最优化3个方向说起</b>，配合简单案例，希望给大家做一个抛砖引玉，看完之后能够真正花时间去系统性补全各个方向的知识，笔者也还在努力。</p><p>                                                                                                                          作者&amp;编辑 | 言有三</p><h2><b>01 线性代数</b></h2><p><b>1.1 向量</b></p><p>什么是数学？顾名思义，一门研究“数”的学问。学术点说，线性代数是一个数学分支，来源于希腊语μαθηματικός（mathematikós），意思是<b>“学问的基础”</b>。</p><p>数学不好，就不要谈学问了，只能算知识（自己瞎加的，欢迎喷）。</p><p>按照维基百科定义：数学是利用符号语言研究数量、结构、变化以及空间等概念的一门学科，从某种角度看属于形式科学的一种。所以一看见数学，我们就想起符号，方程式，简单点比如这个。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fc35aa409c7cd16abf3a0589466d2b2a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"504\" data-rawheight=\"208\" class=\"origin_image zh-lightbox-thumb\" width=\"504\" data-original=\"https://pic3.zhimg.com/v2-fc35aa409c7cd16abf3a0589466d2b2a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;504&#39; height=&#39;208&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"504\" data-rawheight=\"208\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"504\" data-original=\"https://pic3.zhimg.com/v2-fc35aa409c7cd16abf3a0589466d2b2a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fc35aa409c7cd16abf3a0589466d2b2a_b.jpg\"/></figure><p>复杂的比如这个</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-cf655d3b17ad91431c290b32fb004986_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"163\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-cf655d3b17ad91431c290b32fb004986_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;163&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"163\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-cf655d3b17ad91431c290b32fb004986_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-cf655d3b17ad91431c290b32fb004986_b.jpg\"/></figure><p>代数是数学的一个分支，它的研究对象是向量，涵盖线、面和子空间，起源于对二维和三维直角坐标系的研究。</p><p>我们都知道欧式空间，任何一个向量(x,y,z)可以由三个方向的基组成</p><div class=\"highlight\"><pre><code class=\"language-text\">(x,y,z) = x(1,0,0)+y(0,1,0)+z(0,0,1)</code></pre></div><p>它的维度是3，拓展至n就成为n维空间，这N维，相互是独立的，也就是任何一个都不能由其他的几维生成，这叫<b>线性无关</b>，很重要。</p><p><b>2.2 线性回归问题</b></p><p>用向量表示问题有什么用呢？</p><p>假如基友今天约你去吃饭，没有说好谁买单，而根据之前的惯例你们从来不AA，今天你刚交了房租，没钱了，那么该不该去呢？我们可以先回归一下他主动买单的概率，先看一下和哪些变量有关，把它串成向量。</p><div class=\"highlight\"><pre><code class=\"language-text\">X=(刚发工资，刚交女朋友，刚分手，要离开北京，有事要我帮忙，无聊了，过生日，就是想请我吃饭，炒比特币赚了，炒比特币亏了，想蹭饭吃)，共11维，结果用Y表示</code></pre></div><p>Y=1，表示朋友付款，Y=-1，表示不付款</p><p>好，我们再来分析下：</p><div class=\"highlight\"><pre><code class=\"language-text\">和Y=1正相关的维度： 要离开北京，有事要我帮忙，过生日，就是想请我吃饭，炒比特币赚了\n和Y=-1正相关的维度：想蹭饭吃\n暂时关系不明朗的维度：刚发工资，刚交女朋友，刚分手，无聊了，炒比特币亏了</code></pre></div><p>好，拿出纸笔，今天是2019年1月22日，据我所知，这货就是一个典型的死宅摩羯工作狂</p><div class=\"highlight\"><pre><code class=\"language-text\">刚发工资=0，时候没到\n刚交女朋友=0，不可能\n刚分手=0，没得选\n要离开北京=0，不像\n有事要我帮忙=0，我能帮上什么忙\n无聊了=1，估计是\n过生日=0，不对\n就是想请我吃饭=0，不可能\n炒比特币赚了=？，不知道\n炒比特币亏了=？，不知道\n想蹭饭吃=？，不知道</code></pre></div><p>这下麻烦了，有这么多选项未知，假如我们用一个权重矩阵来分析，即y=WX，W是行向量，X是列向量</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a67e85af88dc76acc6465f2d74a83283_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"404\" data-rawheight=\"292\" class=\"content_image\" width=\"404\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;404&#39; height=&#39;292&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"404\" data-rawheight=\"292\" class=\"content_image lazy\" width=\"404\" data-actualsrc=\"https://pic4.zhimg.com/v2-a67e85af88dc76acc6465f2d74a83283_b.jpg\"/></figure><p>X1到xn就是前面那些维度。现在等于</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-de248610d300a565354a7cc10c742b11_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"908\" data-rawheight=\"122\" class=\"origin_image zh-lightbox-thumb\" width=\"908\" data-original=\"https://pic2.zhimg.com/v2-de248610d300a565354a7cc10c742b11_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;908&#39; height=&#39;122&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"908\" data-rawheight=\"122\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"908\" data-original=\"https://pic2.zhimg.com/v2-de248610d300a565354a7cc10c742b11_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-de248610d300a565354a7cc10c742b11_b.jpg\"/></figure><p>假如我们不学习参数，令所有的wi与y=1正相关的系数为1，与y=-1正相关为-1，关系不明的随机置为0.001和-0.001，那么就有下面的式子</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-dfce5c95503093dd019433d4a33da9e5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"62\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-dfce5c95503093dd019433d4a33da9e5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;62&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"62\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-dfce5c95503093dd019433d4a33da9e5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-dfce5c95503093dd019433d4a33da9e5_b.jpg\"/></figure><p>还是3个未知数，问题并没有得到解决。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7dd3ed73c0dbee6b4039800334ad3957_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"650\" class=\"origin_image zh-lightbox-thumb\" width=\"700\" data-original=\"https://pic4.zhimg.com/v2-7dd3ed73c0dbee6b4039800334ad3957_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;700&#39; height=&#39;650&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"650\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"700\" data-original=\"https://pic4.zhimg.com/v2-7dd3ed73c0dbee6b4039800334ad3957_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-7dd3ed73c0dbee6b4039800334ad3957_b.jpg\"/></figure><p>不过我们还是可以得到一些东西：</p><ul><li>我们的模型还没有得到训练，现在的权重是手工设定的，这是不合理的，应该先抓比如1万个样本来填一下报告，把X和Y都填上。当然，要保证准确性，不能在报告中填了说自己会请客（y=1），实际吃起来就呵呵呵😄。这样就是标签打错了，肯定学不到东西。<br/></li><li>从X来看，这个朋友还是可以的，与y=1正相关的变量更多，但是，未必！因为现在X的维度太低了，比如这个朋友是不是本来就是小气鬼或者本来就喜欢请人吃饭，比如是来我家附近吃还是他家附近吃，比如他吃饭带不带女孩等等。<br/></li><li>上面提到了一些随机性，比如权重W的随机性，0.001或者-0.001，X本身的噪声α，β，γ。<br/></li></ul><p>是不是很复杂，现实问题本来就很复杂嘛。不过如果你没有经济问题，那就可以简单点，不管这个模型，只问你今天想不想吃饭，是就去，不想吃就不去。</p><p>线性代数就说这么多，后面想好好学，一定要好好修行线性代数和矩阵分析，咱们以后再说，书单如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-f789fef0b9bfbd167fc5d06b29977f15_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"559\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-f789fef0b9bfbd167fc5d06b29977f15_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;559&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"559\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-f789fef0b9bfbd167fc5d06b29977f15_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-f789fef0b9bfbd167fc5d06b29977f15_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-80f4d960d1ce8bbfe346cc2096b9ee89_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"588\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-80f4d960d1ce8bbfe346cc2096b9ee89_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;588&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"588\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-80f4d960d1ce8bbfe346cc2096b9ee89_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-80f4d960d1ce8bbfe346cc2096b9ee89_b.jpg\"/></figure><p>以下是一些关键词，如果都熟练了解了第一阶段也就OK了。</p><blockquote>标量，向量，特征向量，张量，点积，叉积，线性回归，矩阵，秩，线性无关与线性相关，范数， 奇异值分解，行列式，主成分分析，欧氏空间，希尔伯特空间。</blockquote><h2>02 <b>概率论与统计学</b></h2><p><b>2.1 概率论</b></p><p>概率大家都知道吧，研究的是随机性事件。大家应该都曾经饱受<b>贝叶斯公式</b>的折磨。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-83fcb331972f0a5ab06f05bdff8b5d7f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"630\" data-rawheight=\"198\" class=\"origin_image zh-lightbox-thumb\" width=\"630\" data-original=\"https://pic4.zhimg.com/v2-83fcb331972f0a5ab06f05bdff8b5d7f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;630&#39; height=&#39;198&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"630\" data-rawheight=\"198\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"630\" data-original=\"https://pic4.zhimg.com/v2-83fcb331972f0a5ab06f05bdff8b5d7f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-83fcb331972f0a5ab06f05bdff8b5d7f_b.jpg\"/></figure><p>概率论中有以下几个概念，还是以之前的吃饭问题，朋友主动叫我吃饭为事件X，也叫观测数据，他请客了事件为Y，有以下几个概率，其中P(A|B)是指在事件B发生的情况下事件A发生的概率。</p><div class=\"highlight\"><pre><code class=\"language-text\">(1) X的先验概率，即朋友主动喊我吃饭的概率p(X)，与Y无关。\n(2) Y的先验概率p(Y)：即单纯的统计以往所有吃饭时朋友请客的概率p(Y)，与X无关。\n(3) 后验概率p(Y|X)：就是给出观测数据X所得到的条件概率，即朋友喊我吃饭，并且会请客的概率。</code></pre></div><p>anyway，饭我们吃完了，现在回家，结果未来的女朋友打来电话问去干嘛了，气氛有点严肃，原来是吹牛皮过程中没有看微信漏掉了很多信息。只好说去应酬了，妹子不满意问你还有钱吃饭，谁请客。我说不吃白不吃啊，朋友请。</p><p>妹子又问，谁主动提出吃饭的！</p><p>正好，那不就是要算后验概率p(X|Y)吗？也就是饭吃了，谁提议的。</p><p>于是故作聪明让妹子猜，还给了一个提示可以用贝叶斯公式，并且已知p(Y)=0.2，p(X)=0.8，再加上上面算出来的p(Y|X)</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fc64760dab8f8e0b08fa414fc90d9e8a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"118\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fc64760dab8f8e0b08fa414fc90d9e8a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;118&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"118\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fc64760dab8f8e0b08fa414fc90d9e8a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fc64760dab8f8e0b08fa414fc90d9e8a_b.jpg\"/></figure><p>好了又回到了这个问题，3个未知变量。</p><p>不过没关系，我们可以先用它们的数学期望来替换掉，数学期望就是一个平均统计。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-1fabcb6181249e4bdc9bbd9ec9876b23_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"862\" data-rawheight=\"112\" class=\"origin_image zh-lightbox-thumb\" width=\"862\" data-original=\"https://pic4.zhimg.com/v2-1fabcb6181249e4bdc9bbd9ec9876b23_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;862&#39; height=&#39;112&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"862\" data-rawheight=\"112\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"862\" data-original=\"https://pic4.zhimg.com/v2-1fabcb6181249e4bdc9bbd9ec9876b23_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-1fabcb6181249e4bdc9bbd9ec9876b23_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-84f1c185f9307f8d43fd86f085181d87_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"77\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-84f1c185f9307f8d43fd86f085181d87_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;77&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"77\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-84f1c185f9307f8d43fd86f085181d87_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-84f1c185f9307f8d43fd86f085181d87_b.jpg\"/></figure><p>这说明什么？说明这一次吃饭，是朋友先动的嘴的概率p(X|Y)=0.002，那么今天99.8%是自己跑出去蹭吃吹牛皮了。</p><p>接下来的问题就是搓衣板是跪还是不跪，贝叶斯公式解决不了。</p><p>事情结束后，要想好好搞下去，肯定是要学好概率论和统计学习的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a05181cf4793be8191cad9dff9ba16d7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"569\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-a05181cf4793be8191cad9dff9ba16d7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;569&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"569\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-a05181cf4793be8191cad9dff9ba16d7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a05181cf4793be8191cad9dff9ba16d7_b.jpg\"/></figure><p>同样，有一些关键词要掌握。</p><blockquote>不确定性，随机变量，大数定律，联合分布，边缘分布，条件概率，贝叶斯公式，概率密度，墒与交叉墒，期望，最大似然估计，正态分布/高斯分布，伯努利分布，泊松分布，概率论与统计推断，马尔可夫链，判别模型，生成模型。</blockquote><p>有意思的是：概率论还有一些东西是有点违背认知的，比如生日悖论。</p><p>一个班上如果有23个人，那么至少有两个人的生日是在同一天的概率要大于50％，对于60或者更多的人，这种概率要大于99%。大家都是上过学的少年，你在班上遇到过同一天生日的吗？</p><p><b>2.2 传统机器学习算法基础</b></p><p>传统机器学习算法本来不应该放在这里说，但是因为其中有一部分算法用到了概率论，所以也提一句。</p><p>有很多人在知乎上问，<b>搞深度学习还需要传统机器学习基础吗？</b>当然要！且不说这个传统机器学习算法仍然在大量使用，光是因为它经典，就值得学习一下，依旧推荐一本书。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5bf8259f4ed582cc63947f0a3c1dd343_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"562\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-5bf8259f4ed582cc63947f0a3c1dd343_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;562&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"562\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-5bf8259f4ed582cc63947f0a3c1dd343_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5bf8259f4ed582cc63947f0a3c1dd343_b.jpg\"/></figure><p>机器学习完成的任务就是一个模式识别任务，<b>机器学习和模式识别</b>这两个概念实际上等价，只是历史原因说法不同。</p><p>一个模式识别任务就是类似于识别这个图是不是猫，这封邮件是不是垃圾邮件，这个人脸是不是你本人之类的高级的任务。</p><p>传统的机器学习算法有两大模型，<b>一个是判别模型，一个是生成模型</b>，我们以前讲过，大家可以去看。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029396%26idx%3D1%26sn%3D2d92874e0b94dd2174d216ce1da4f1ce%26chksm%3D87134569b064cc7f5f2476fdc87df968b353c2eae24f6820a5af2ee983ca49be55d34588c19e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】有三说GANs（上）</a> </p><p>传统机器学习算法就不展开了，太多。</p><h2><b>03 微积分与最优化</b></h2><p><b>3.1  导数</b></p><p>机器学习就是要学出一个模型，得到参数嘛，本质上就是优化一个数学方程，而且通常是离散的问题，这个时候大杀器就是微积分了。</p><p>微积分是什么，根据维基百科：</p><p>微积分学（Calculus，拉丁语意为计数用的小石头）曾经指无穷小的计算，就是一门<b>研究变化</b>的学问，更学术点说就是研究<b>函数的局部变化率</b>，如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-13fa504ce3c65135d0ede6124707f3e5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"444\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb\" width=\"444\" data-original=\"https://pic2.zhimg.com/v2-13fa504ce3c65135d0ede6124707f3e5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;444&#39; height=&#39;188&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"444\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"444\" data-original=\"https://pic2.zhimg.com/v2-13fa504ce3c65135d0ede6124707f3e5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-13fa504ce3c65135d0ede6124707f3e5_b.jpg\"/></figure><p>可知，在不同的X处它的导数是不相等的。如果遇到了一个导数为0的点，它很有可能就是最大值或者最小值，如下面的x=0点取得最小值y=0。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-1631c11193ce171c22840b71e96b13f9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"400\" class=\"content_image\" width=\"400\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;400&#39; height=&#39;400&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"400\" class=\"content_image lazy\" width=\"400\" data-actualsrc=\"https://pic2.zhimg.com/v2-1631c11193ce171c22840b71e96b13f9_b.jpg\"/></figure><p>导数反映了y的变化趋势，比如这个方程x&gt;0时，导数大于0，则y随着x的增加而增加。x&lt;0时，导数小于0，则y随着x的增加而减小。</p><p>所以看导数，我们就得到了目标y的变化趋势，而深度学习或者说机器学习中需要优化的目标就是一个Y，也称之为<b>目标函数，价值函数，损失函数</b>等等。通常我们定义好一个目标函数，当它达到极大值或者极小值就实现了我们的期望。</p><p>不过还有个问题，就是导数等于0，一定是极值点吗？未必，比如鞍点。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-17811e58779a98b0f5d27007afaf3694_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"978\" data-rawheight=\"813\" class=\"origin_image zh-lightbox-thumb\" width=\"978\" data-original=\"https://pic1.zhimg.com/v2-17811e58779a98b0f5d27007afaf3694_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;978&#39; height=&#39;813&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"978\" data-rawheight=\"813\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"978\" data-original=\"https://pic1.zhimg.com/v2-17811e58779a98b0f5d27007afaf3694_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-17811e58779a98b0f5d27007afaf3694_b.jpg\"/></figure><p>上面的小红点就是鞍点，在这个曲面上，它在某些方向的导数等于0，但是显然它不是极值点，不是极大也不是极小，正因如此，给后面的优化埋下了一个坑。</p><p>如果你真的微积分也忘了，就需要补了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e7dec3ee42073e6eff573acb08b08890_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"529\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-e7dec3ee42073e6eff573acb08b08890_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;529&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"529\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-e7dec3ee42073e6eff573acb08b08890_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e7dec3ee42073e6eff573acb08b08890_b.jpg\"/></figure><p><b>3.2  数值微分</b></p><p>前面说了，机器学习就是要求解目标的极值，极大值极小值是等价的不需要纠结，通常我们求<b>极小值</b>。</p><p>上面的函数我们轻轻松松就求解出了导数，从而得到了唯一的极值，这叫做<b>解析解</b>，答案很唯一，用数学方程就能手算出来。</p><p>但是实际要优化的神经网络上百万个参数，是不可能求出解析解的，只能求<b>数值近似解，就是用数值微分的方法去逼近。</b></p><p>数值微分的核心思想就是<b>用离散方法近似计算函数的导数值或偏导数值</b>，相信同学们在课程中都学过。</p><p>向前差商公式：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a8e6c9b99fe128bd38490ba65a03bb11_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"442\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb\" width=\"442\" data-original=\"https://pic2.zhimg.com/v2-a8e6c9b99fe128bd38490ba65a03bb11_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;442&#39; height=&#39;128&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"442\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"442\" data-original=\"https://pic2.zhimg.com/v2-a8e6c9b99fe128bd38490ba65a03bb11_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a8e6c9b99fe128bd38490ba65a03bb11_b.jpg\"/></figure><p>向后差商公式：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-717686553c71605b450a3c2fa678cd8e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"408\" data-rawheight=\"138\" class=\"content_image\" width=\"408\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;408&#39; height=&#39;138&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"408\" data-rawheight=\"138\" class=\"content_image lazy\" width=\"408\" data-actualsrc=\"https://pic3.zhimg.com/v2-717686553c71605b450a3c2fa678cd8e_b.jpg\"/></figure><p>中心差商公式：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b28cc3d85cdd0104eed3ad4ea10ce079_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"454\" data-rawheight=\"120\" class=\"origin_image zh-lightbox-thumb\" width=\"454\" data-original=\"https://pic2.zhimg.com/v2-b28cc3d85cdd0104eed3ad4ea10ce079_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;454&#39; height=&#39;120&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"454\" data-rawheight=\"120\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"454\" data-original=\"https://pic2.zhimg.com/v2-b28cc3d85cdd0104eed3ad4ea10ce079_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b28cc3d85cdd0104eed3ad4ea10ce079_b.jpg\"/></figure><p>有了感觉咱们接着说</p><p>那么，一般情况下要求解任意函数极值的方法是什么呢？在深度学习中就是<b>梯度下降法</b>。</p><p>梯度下降法可以说是最广泛使用的最优化方法，在目标函数是凸函数的时候可以得到全局解。虽然神经网络的优化函数通常都不会是凸函数，但是它仍然可以取得不错的结果。</p><p>梯度下降法的核心思想就是(公式比较多，就截图了)：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d4582b52b983874ffc0bde873ab245f2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"267\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-d4582b52b983874ffc0bde873ab245f2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;267&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"267\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-d4582b52b983874ffc0bde873ab245f2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d4582b52b983874ffc0bde873ab245f2_b.jpg\"/></figure><p><b>这一套对所有的函数f(x)都通用，所以以导数的反方向进行搜索，就能够减小f(x)，而且这个方向还是减小f(x)的最快的方向，这就是所谓的梯度下降法，也被称为“最速下降法”，参数更新方法如下。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-642f2298f755cad44bca50ac2e583803_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1078\" data-rawheight=\"66\" class=\"origin_image zh-lightbox-thumb\" width=\"1078\" data-original=\"https://pic4.zhimg.com/v2-642f2298f755cad44bca50ac2e583803_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1078&#39; height=&#39;66&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1078\" data-rawheight=\"66\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1078\" data-original=\"https://pic4.zhimg.com/v2-642f2298f755cad44bca50ac2e583803_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-642f2298f755cad44bca50ac2e583803_b.jpg\"/></figure><p>关于微积分和最优化，咱们就点到为止了，不然就超出了白身境系列的要求。要补这方面的知识，就比较多了，建议先找花书中的对应章节看看，找找感觉再说。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d0e73ccd44801c73d46ec452471a74b8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"848\" data-rawheight=\"1228\" class=\"origin_image zh-lightbox-thumb\" width=\"848\" data-original=\"https://pic1.zhimg.com/v2-d0e73ccd44801c73d46ec452471a74b8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;848&#39; height=&#39;1228&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"848\" data-rawheight=\"1228\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"848\" data-original=\"https://pic1.zhimg.com/v2-d0e73ccd44801c73d46ec452471a74b8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d0e73ccd44801c73d46ec452471a74b8_b.jpg\"/></figure><p>最优化的方法还有很多，目前在神经网络优化中常用的是一阶优化方法，不过二阶优化方法也慢慢被研究起来，最后还是给出一些关键词去掌握。</p><p>导数，偏导数，线性规划，二次规划，动态规划，Hessian matrix，损失函数，正则项，一阶优化方法(梯度下降法)，二阶优化方法(牛顿法)等等。</p><p>好嘞，掌握了这些，就大胆往前走，不用怕了。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p></p><p></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "概率论", 
                    "tagLink": "https://api.zhihu.com/topics/19670916"
                }, 
                {
                    "tag": "微积分", 
                    "tagLink": "https://api.zhihu.com/topics/19558728"
                }, 
                {
                    "tag": "线性代数", 
                    "tagLink": "https://api.zhihu.com/topics/19577698"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55422235", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 32, 
            "title": "【AI白身境】深度学习中的数据可视化", 
            "content": "<p>今天是新专栏《AI白身境》的第八篇，所谓白身，就是什么都不会，还没有进入角色。</p><p>上一节我们已经讲述了如何用爬虫爬取数据，那爬取完数据之后就应该是进行处理了，一个很常用的手段是数据可视化。</p><p>通过数据可视化，可以更加直观地表征数据，在深度学习项目中，常需要的数据可视化操作包括原始<b>图片数据的可视化，损失和精度的可视化</b>等。</p><p>                                                                                                                         作者 | 言有三 臧小满 <br/>                                                                                                                         编辑 | 言有三 臧小满</p><h2><b>01 什么是数据可视化？</b></h2><p>每每提到数据可视化，大家脑中可能会浮现很各种图表、西装革履的分析师、科幻大片中酷炫的仪表。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d0c1bb00c983a32e59957b40ff116726_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"375\" class=\"origin_image zh-lightbox-thumb\" width=\"700\" data-original=\"https://pic3.zhimg.com/v2-d0c1bb00c983a32e59957b40ff116726_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;700&#39; height=&#39;375&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"375\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"700\" data-original=\"https://pic3.zhimg.com/v2-d0c1bb00c983a32e59957b40ff116726_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d0c1bb00c983a32e59957b40ff116726_b.jpg\"/></figure><p>其实不用那么复杂，数据可视化早就融合进你我的生活，地铁线路图、公交时刻表，天气预报中的气象地图等都是很常见的。</p><p>为什么要进行可视化？</p><p>因为<b>人是视觉动物，对于图像的敏感度</b>要比对纯数字的敏感度高的多。</p><p><b>人类对图像的处理速度比文本快6万倍，同时人类右脑记忆图像的速度比左脑记忆抽象文字快100万倍</b>。数据可视化正是利用人类天生技能来增强数据处理和组织效率。</p><p>举个简单的例子，计划买一套房产作为投资, 想要了解“去年上海房价哪里涨幅最大”，现以图作答, 把去年的增长率体现在图上，以20%作为分界, 增长超过20%的标红色, 超过越多则越大, 不足的标记成蓝色, 如下图，可以很快get到哪个区域的大幅度涨幅。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ba46651fd79ecebbf7d73c7cc7fca6a1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"602\" data-rawheight=\"329\" class=\"origin_image zh-lightbox-thumb\" width=\"602\" data-original=\"https://pic2.zhimg.com/v2-ba46651fd79ecebbf7d73c7cc7fca6a1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;602&#39; height=&#39;329&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"602\" data-rawheight=\"329\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"602\" data-original=\"https://pic2.zhimg.com/v2-ba46651fd79ecebbf7d73c7cc7fca6a1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ba46651fd79ecebbf7d73c7cc7fca6a1_b.jpg\"/></figure><p>可视化将数字抽象成了更方便我们观察和感受的图表，因此需要熟悉使用。</p><h2><b>02 低维数据可视化</b></h2><p>数据有不同的维度，我们最常接触的就是一维，二维的数据，在机器学习任务中，包括损失函数等统计指标。</p><p><b>2.1 散点图</b></p><p>散点图，常用于分析离散数据的分布。比如我们有一个数据集，里面的图片有不同的大小，我们可以利用x，y轴分别对应图片的宽高，从而画出图片尺度的空间分布情况。越密集的地方，说明该尺度类型的图越多，如下图所示。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1ac38ad4d8999cfc11b6c54668c2386c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-1ac38ad4d8999cfc11b6c54668c2386c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-1ac38ad4d8999cfc11b6c54668c2386c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-1ac38ad4d8999cfc11b6c54668c2386c_b.jpg\"/></figure><p><b>2.2 折线图</b></p><p>折线图是用于分析变量随另一个变量的变化关系，我们平常接触最多的loss曲线图，accuracy曲线图就是这一种，可以看指标随着训练过程的变化判断收敛情况，从而推测模型训练的好坏，折线图被广泛应用于各类分析，如下图所示。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c244e446d68a7a8e826c37cd539b0695_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c244e446d68a7a8e826c37cd539b0695_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c244e446d68a7a8e826c37cd539b0695_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c244e446d68a7a8e826c37cd539b0695_b.jpg\"/></figure><p><b>2.3 直方图，饼状图</b></p><p>这两种图，都常用于统计数据的分布比例以及响应幅度，比如一幅图片的亮度分布情况，不同网络层的参数量，计算时间代价。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ba820dae4bac8f6454a3eba01e42f7b6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ba820dae4bac8f6454a3eba01e42f7b6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ba820dae4bac8f6454a3eba01e42f7b6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ba820dae4bac8f6454a3eba01e42f7b6_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a69bf7f632697c391363dbcb19a895f4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-a69bf7f632697c391363dbcb19a895f4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-a69bf7f632697c391363dbcb19a895f4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a69bf7f632697c391363dbcb19a895f4_b.jpg\"/></figure><p>这几种图，适合对有时序变化的一维向量，有统计分布的一维向量，或者二维图像的尺度等信息进行可视化。</p><h2><b>03 高维数据可视化</b></h2><p>在机器学习任务中，数据通常是用成百上千维的向量表示，而超过3维的向量，就已经超过了人类的可视化认知，因此通常需要对数据进行降维。</p><p>数据降维方法可以分为<b>线性方法和非线性方法</b>。其中线性方法包括<b>PCA和LDA</b>，而非线性方法有保留局部特征、基于全局特征等方法，以<b>t-SNE</b>为代表。下面我们主要介绍PCA和t-SNE方法。</p><p><b>3.1  PCA降维</b></p><p>PCA，全称是Principal components analysis，这是一种分析、简化数据集的技术。PCA常用于减少数据集的维数，同时保持数据集中对方差贡献最大的特征，原理是<b>保留低阶主成分，忽略高阶主成分，因为低阶成分保留了数据最多的信息</b>。</p><p>假定X是原始数据，Y是降维后的数据，W是变换矩阵，Y=XW。假如我们需要降到3 维以便于我们可视化，那就取Y的前三个主成分作为原始属性X的代表。</p><p>我们采用Google开源的网页版数据可视化工具Embedding Projector来进行可视化，链接如下：</p><p><u><i><a href=\"https://link.zhihu.com/?target=http%3A//projector.tensorflow.org/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">projector.tensorflow.org</span><span class=\"invisible\">/</span><span class=\"ellipsis\"></span></a></i></u></p><p>选择MNIST作为可视化例子，它的原始维度为10000×784，即10000张28×28的图像。</p><p>利用这个工具我们进行PCA的可视化，降低到3个维度后，我们可以选择某个数字进行可视化。下图就是数字9的分布，可以看到，总共有1009个样本，数据的分布在物理空间上具有一定的聚类特性。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a70b25493d6dc638d00c85658e4bafa2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"564\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-a70b25493d6dc638d00c85658e4bafa2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;564&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"564\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-a70b25493d6dc638d00c85658e4bafa2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a70b25493d6dc638d00c85658e4bafa2_b.jpg\"/></figure><p>还可以用不同的颜色查看全体数据的分布，从这里可以更好的看出不同类的分布规律。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b51c8f5323ab8ccb6135940fc3bfefec_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"556\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b51c8f5323ab8ccb6135940fc3bfefec_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;556&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"556\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b51c8f5323ab8ccb6135940fc3bfefec_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b51c8f5323ab8ccb6135940fc3bfefec_b.jpg\"/></figure><p><b>3.2  t-SNE降维</b></p><p>SNE全称是Stochastic Neighbor Embedding，它将<b>数据点之间高维的欧氏距离转换为表示相似度的条件概率</b>，目标是将高维数据映射到低维后，尽量保持数据点之间的空间结构，从而那些在高维空间里距离较远的点，在低维空间中依然保持较远的距离。</p><p><b>t-SNE即t-distributed stochastic neighbor embedding，t-SNE用联合概率分布替代了SNE中的条件概率分布</b>，解决了SNE的不对称问题。通过引入t分布，解决了同类别之间簇的拥挤问题。</p><p>t-SNE方法实质上是一种聚类的方法，对于一个空间中的点，周围的其他点都是它的“邻居”，方法就是要试图使所有点具有相同数量的“邻居”。</p><p>t-SNE经过学习收敛后，通过投影到2维或者3维的空间中可以判断一个数据集有没有很好的可分性，即是否同类之间间隔小，异类之间间隔大。如果在低维空间中具有可分性，则数据是可分的，如果不具有可分性，可能是数据不可分，也可能仅仅是因为不能投影到低维空间。</p><p>下图是t-SNE可视化结果图，可以看出，数字都有很明显的聚类效果。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f7d16f32ad3b7b9364cf1b957f4ad938_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"924\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-f7d16f32ad3b7b9364cf1b957f4ad938_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;924&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"924\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-f7d16f32ad3b7b9364cf1b957f4ad938_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-f7d16f32ad3b7b9364cf1b957f4ad938_b.jpg\"/></figure><p>在进行一个机器学习任务之前，通过可视化来对数据集进行更深刻的认识，有助于预估任务的难度，在遇到困难后也会更加容易找到解决方案。</p><h2><b>04 python数据可视化项目</b></h2><p>考虑到python是第一大机器学习编程语言，同时开源项目居多，所以我们只关心python相关的工具，而且python也基本可以满足需求。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ba727539923e4f4f2049fa3168ddf8a3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"768\" data-rawheight=\"566\" class=\"origin_image zh-lightbox-thumb\" width=\"768\" data-original=\"https://pic4.zhimg.com/v2-ba727539923e4f4f2049fa3168ddf8a3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;768&#39; height=&#39;566&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"768\" data-rawheight=\"566\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"768\" data-original=\"https://pic4.zhimg.com/v2-ba727539923e4f4f2049fa3168ddf8a3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ba727539923e4f4f2049fa3168ddf8a3_b.jpg\"/></figure><p>可视化的项目太多了，下面基于python和GitHub的数据，随便推荐几款。</p><p>1. tensorboard和tensorboardX，想必不需要多做介绍，后者大家可能不熟悉，被开发用来支持chainer, mxnet, numpy，4000+star。</p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/lanpa/tensorboardX\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/lanpa/tensor</span><span class=\"invisible\">boardX</span><span class=\"ellipsis\"></span></a></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-779baa116cde5d3b26fbb7ad1ddbfdc3_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"367\" data-thumbnail=\"https://pic4.zhimg.com/v2-779baa116cde5d3b26fbb7ad1ddbfdc3_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-779baa116cde5d3b26fbb7ad1ddbfdc3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;367&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"367\" data-thumbnail=\"https://pic4.zhimg.com/v2-779baa116cde5d3b26fbb7ad1ddbfdc3_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-779baa116cde5d3b26fbb7ad1ddbfdc3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-779baa116cde5d3b26fbb7ad1ddbfdc3_b.gif\"/></figure><p>2. visdom，支持numpy和torch的工具，常用于pytorch数据可视化，很强大，5000+star。</p><p><i><a href=\"https://link.zhihu.com/?target=https%3A//github.com/facebookresearch/visdom\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/facebookrese</span><span class=\"invisible\">arch/visdom</span><span class=\"ellipsis\"></span></a></i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-8789942fc2d762ffad5117a4c3b8ade9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"632\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-8789942fc2d762ffad5117a4c3b8ade9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;632&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"632\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-8789942fc2d762ffad5117a4c3b8ade9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-8789942fc2d762ffad5117a4c3b8ade9_b.jpg\"/></figure><p>3. seaborn：一款基于matplotlib的工具，简单来说，就是有更高的API，画出的图也好看，5000+star，主要处理低维数据。</p><p><i><a href=\"https://link.zhihu.com/?target=https%3A//github.com/mwaskom/seaborn\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/mwaskom/seab</span><span class=\"invisible\">orn</span><span class=\"ellipsis\"></span></a></i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e9c347ae40c509f4d532222fd744e465_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"198\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-e9c347ae40c509f4d532222fd744e465_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;198&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"198\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-e9c347ae40c509f4d532222fd744e465_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e9c347ae40c509f4d532222fd744e465_b.jpg\"/></figure><p>4. holoviews：很酷炫的工具，与season差不多，1000+star。</p><p><i><a href=\"https://link.zhihu.com/?target=https%3A//github.com/ioam/holoviews\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/ioam/holovie</span><span class=\"invisible\">ws</span><span class=\"ellipsis\"></span></a></i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4aec6fa78430150c150e0009aa2afa62_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"690\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-4aec6fa78430150c150e0009aa2afa62_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;690&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"690\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-4aec6fa78430150c150e0009aa2afa62_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4aec6fa78430150c150e0009aa2afa62_b.jpg\"/></figure><p>5. missingno：一款缺失数据可视化工具，非常适合分析数据集的完整性，1000+star。</p><p><i><a href=\"https://link.zhihu.com/?target=https%3A//github.com/ResidentMario/missingno\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/ResidentMari</span><span class=\"invisible\">o/missingno</span><span class=\"ellipsis\"></span></a></i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-9d5ad7153950d9916908e997552e82d7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"413\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-9d5ad7153950d9916908e997552e82d7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;413&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"413\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-9d5ad7153950d9916908e997552e82d7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-9d5ad7153950d9916908e997552e82d7_b.jpg\"/></figure><p>就这么多，以后再集中讲可视化工具。</p><p><b>总结</b></p><p>数据可视化抽象了数据本身真正的价值，熟练掌握可视化对于分析数据的特征和深度学习模型的性能是必要的技能。</p><p><i>下期预告：下一期我们讲入行AI必备的数学基础，如果你有建议，欢迎留言，我们会及时采纳的。</i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "数据可视化", 
                    "tagLink": "https://api.zhihu.com/topics/19593576"
                }, 
                {
                    "tag": "Python", 
                    "tagLink": "https://api.zhihu.com/topics/19552832"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55209730", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 4, 
            "title": "【AI白身境】学深度学习你不得不知的爬虫基础", 
            "content": "<p>今天是新专栏<b>《AI白身境》</b>的第七篇，所谓白身，就是什么都不会，还没有进入角色。</p><p>对于深度学习，一个好的数据集可以说非常重要的，但是通常情况下我们并没有大量的数据，因此我们有必要掌握一定的爬虫知识，从而更好的准备训练数据集。</p><p>                                                                                                                        作者 | 汤兴旺 言有三</p><p>                                                                                                                        编辑 | 汤兴旺 言有三</p><h2><b>01 前端网页基础</b></h2><p>在介绍爬虫之前我们先说下网页基础，理解前端网页的一些基础知识对于学习爬虫是很有必要的，它是爬虫的基础之一。</p><p><b>1.1 网页构成</b></p><p>通常情况下我们看到的网页由三部分组成，分别是HTML、CSS和JavaScript，接下来我分别介绍它们。</p><p><b>1.1.1 HTML</b></p><p>HTML，全称Hyper Text Markup Language，也就是“超文本链接标示语言”。但它不是一种编程语言，而是一种标记语言。我们通常看到的网页就是HTML使用标记标签来描述的。在HTML中，通常不同类型的文字通过不同类型的标签来表示。如图片用img标签表示，视频用video标签表示，段落用p标签表示。</p><p>现在我们看下网易云音乐的源代码，如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5c4c6072705f9e44706cf619f6ce8364_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"797\" data-rawheight=\"578\" class=\"origin_image zh-lightbox-thumb\" width=\"797\" data-original=\"https://pic1.zhimg.com/v2-5c4c6072705f9e44706cf619f6ce8364_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;797&#39; height=&#39;578&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"797\" data-rawheight=\"578\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"797\" data-original=\"https://pic1.zhimg.com/v2-5c4c6072705f9e44706cf619f6ce8364_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5c4c6072705f9e44706cf619f6ce8364_b.jpg\"/></figure><p>获取这个网页的源代码很简单，打开网页后，按下F12键就会出现这个源代码了。通过观察这个HTML我们会发现整个网页就是由各种标签嵌套组合而成的，从而形成了整个网页的架构。</p><p><b>1.1.2 CSS</b></p><p>从上面的介绍我们知道HTML定义了网页的架构，可以认为是一个框架，但若只有HTML，那么这样的网页就太简陋了，为了让我们的网页更加好看点，我们就需要用CSS。</p><p>CSS，全称Cascading Style Sheets，即层叠样式表。“层叠”是指当在HTML中引用了数个样式文件，并且样式发生冲突时，浏览器能依据层叠顺序处理。“样式”指网页中文字大小、颜色、元素间距、排列等格式。我们来看看网易云音乐的CSS，如下所示。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a50a5f08d905404bf51b389c5ffd4d1d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"564\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-a50a5f08d905404bf51b389c5ffd4d1d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;564&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"564\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-a50a5f08d905404bf51b389c5ffd4d1d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a50a5f08d905404bf51b389c5ffd4d1d_b.jpg\"/></figure><p><b>1.1.3 JavaScript</b></p><p>上面介绍的HTML和CSS只能展现一种静态信息，缺乏交互性。但我们在网页里通常会看到一些交互和动画效果，如提示框、轮播图等，这些动态信息通常就是通过JavaScript完成的。它的出现使得用户与信息之间不只是一种浏览与显示的关系，而是实现了一种实时、动态、交互的页面功能。</p><p>这就是网页构成的一些基本知识，你掌握了吗？</p><p><b>1.2 URL</b></p><p>爬虫最主要的处理对象是什么？那毫无疑问肯定是URL，爬虫的实质就是根据URL地址取得所需要的文件内容，然后对它进行进一步的处理。所以说准确理解URL也是理解网络爬虫的基础之一。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-9bd274ee634d7fa7396c4ed2568a35d3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"364\" data-rawheight=\"130\" class=\"content_image\" width=\"364\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;364&#39; height=&#39;130&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"364\" data-rawheight=\"130\" class=\"content_image lazy\" width=\"364\" data-actualsrc=\"https://pic4.zhimg.com/v2-9bd274ee634d7fa7396c4ed2568a35d3_b.jpg\"/></figure><p>URL，全称是Uniform Resource Locator,通俗地说，URL是Internet上描述信息资源的字符串，主要用在各种WWW客户程序和服务器程序上。URL也有它特定的格式，其格式由三部分组成，如下：</p><p>1.第一部分是协议(或称为服务方式)。</p><p>2.第二部分是存有该资源的主机IP地址(有时也包括端口号)。</p><p>3.第三部分是主机资源的具体地址，如目录和文件名等。</p><p>通常第一部分和第二部分用“://”符号隔开，第二部分和第三部分用“/”符号隔开。另外第一部分和第二部分是不可缺少的，第三部分有时可以省略。 </p><p>我们通过一个URL的一个小例子来解释下上面的三部分，下面是NBA中国官方网站湖人队网页的URL：</p><p><a href=\"https://link.zhihu.com/?target=http%3A//china.nba.com/lakers/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">china.nba.com/lakers/</span><span class=\"invisible\"></span></a></p><p>http这个是协议，也就是HTTP超文本传输协议，它是URL的第一部分；<a href=\"https://link.zhihu.com/?target=http%3A//china.nba.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">china.nba.com</span><span class=\"invisible\"></span></a>这个是网站名，由服务器名和域名构成，它是URL的第二部分；lakers就是存放网页的根目录，是URL的第三部分。</p><p>这就是URL的一些基础知识，希望大家深刻理解。<br/></p><p>通过上面的介绍，相信你对网页的基础知识也有了大致的了解，下面我们开始学习爬虫相关库的一些基础知识。<br/></p><h2><b>02 python爬虫库</b></h2><p>了解了网页的一些基础知识后，我们继续来学习下python爬虫的一些库，通过前面第三篇文章《AI白身境学习AI必备的python基础》我们都知道python有许多库，如NumPy，matplotlib等，针对爬虫它有个自带的库urllib。</p><p><b>2.1 urllib介绍                        </b></p><p>urllib是python自带的一个主要用来爬虫的标准库，无需安装可以直接用，它能完成如下任务：网页请求、响应获取、代理和cookie设置、异常处理和URL解析，可以说要想学会爬虫，必须要学会它。</p><p><b>2.2 urllib基础用法</b></p><p>我们已经知道urllib能完成网页请求、响应获取等许多任务，现在我来介绍下它的基本用法。</p><p><b>2.2.1 发起GET/POST请求</b></p><p>在用urllib实现GET和POST之前，我们先解释下什么是GET？什么是POST？它们的区别又是啥？</p><p>GET和POST实际上就是HTTP请求的两种基本方法，通常GET是从指定的资源请求数据，而POST是向指定的资源提交要被处理的数据。我们再看看它的区别是啥，请看下面表格：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-77efc54a2bc2a78ce3b0708b0cbb44a0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"687\" data-rawheight=\"405\" class=\"origin_image zh-lightbox-thumb\" width=\"687\" data-original=\"https://pic1.zhimg.com/v2-77efc54a2bc2a78ce3b0708b0cbb44a0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;687&#39; height=&#39;405&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"687\" data-rawheight=\"405\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"687\" data-original=\"https://pic1.zhimg.com/v2-77efc54a2bc2a78ce3b0708b0cbb44a0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-77efc54a2bc2a78ce3b0708b0cbb44a0_b.jpg\"/></figure><p>哈哈，你现在看到这些肯定很闷逼。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e03e996fc4a231e031ae3688357ad9bb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"300\" data-rawheight=\"300\" class=\"content_image\" width=\"300\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;300&#39; height=&#39;300&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"300\" data-rawheight=\"300\" class=\"content_image lazy\" width=\"300\" data-actualsrc=\"https://pic4.zhimg.com/v2-e03e996fc4a231e031ae3688357ad9bb_b.jpg\"/></figure><p>我们从头（HTTP)来分析下，我们已经知道HTTP是基于TCP/IP的关于数据如何在万维网中如何通信的协议。HTTP的底层是TCP/IP，所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP连接，GET和POST能做的事情是一样的。</p><p><b>那它们的区别体现在哪呢？对于GET方式的请求，浏览器会把http header和data一并发送出去；而对于POST，浏览器先发送header，服务器响应后，浏览器再发送data。</b></p><p>也就是说，在大万维网世界中，TCP就像汽车，我们用TCP来运输数据，HTTP给汽车运输设定了好几个运输方式，有GET, POST等。GET只需要汽车跑一趟就把货送到了，而POST得跑两趟，第一趟，先去和服务器打个招呼“嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。</p><p>你现在明白它们的区别了吗？我们再看看urllib是如何使用这两个方法的。</p><p>在urllib中有个request这个模块，它主要是来负责构造和发起网络请求。它有个urlopen()访问方法，默认的访问方法是GET，我们在urlopen()方法中传入字符串格式的url地址后，此方法会访问目标网址，然后返回访问的结果。请看下面的实例：</p><div class=\"highlight\"><pre><code class=\"language-text\">from urllib import request\nurl = &#34;https://zhuanlan.zhihu.com/p/20751612&#34;\nhtml = request.urlopen(url).read().decode(&#34;utf-8&#34;)\nprint(html)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-258cd9d442cc36875387e0e6fbf40b52_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"80\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-258cd9d442cc36875387e0e6fbf40b52_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;80&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"80\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-258cd9d442cc36875387e0e6fbf40b52_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-258cd9d442cc36875387e0e6fbf40b52_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-90686f9c72be49bf54f60740cf9f8a72_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-90686f9c72be49bf54f60740cf9f8a72_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;414&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-90686f9c72be49bf54f60740cf9f8a72_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-90686f9c72be49bf54f60740cf9f8a72_b.jpg\"/></figure><p>urlopen()方法请求返回的对象类型为HTTPResponse对象。</p><div class=\"highlight\"><pre><code class=\"language-text\">from urllib import request\nurl = &#34;https://zhuanlan.zhihu.com/p/20751612&#34;\nhtml = request.urlopen(url)\nprint(type(html))</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7f78e80b7a979485e592ce8313121c0a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"185\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-7f78e80b7a979485e592ce8313121c0a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;185&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"185\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-7f78e80b7a979485e592ce8313121c0a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-7f78e80b7a979485e592ce8313121c0a_b.jpg\"/></figure><p>返回的状态为200，即返回数据。</p><div class=\"highlight\"><pre><code class=\"language-text\">print(html.status)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0cbfbf4ad60a75edc1e0c0aa2ca528a3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"187\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-0cbfbf4ad60a75edc1e0c0aa2ca528a3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;187&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"187\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-0cbfbf4ad60a75edc1e0c0aa2ca528a3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0cbfbf4ad60a75edc1e0c0aa2ca528a3_b.jpg\"/></figure><p>返回的数据会是bytes的二进制格式，所以需要decode()一下，转换成字符串格式。</p><div class=\"highlight\"><pre><code class=\"language-text\">print(html.read().decode(&#34;utf-8&#34;)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-70b93ee6a13370e06d7e7be880718025_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"433\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-70b93ee6a13370e06d7e7be880718025_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;433&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"433\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-70b93ee6a13370e06d7e7be880718025_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-70b93ee6a13370e06d7e7be880718025_b.jpg\"/></figure><p>这就是GET方式的一个最基本的运用，对于POST方法的实现其实和GET差不多，只不过多了一个data参数。即若添加data参数，就是以POST请求方式进行，如果没有data参数就是GET请求方式，请看下面一个POST案例。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d3f39b638191bfc0ae05c9cba66daea5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"139\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-d3f39b638191bfc0ae05c9cba66daea5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;139&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"139\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-d3f39b638191bfc0ae05c9cba66daea5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d3f39b638191bfc0ae05c9cba66daea5_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-2d754aef29bd8e6bd400d7bb95496f7b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"437\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-2d754aef29bd8e6bd400d7bb95496f7b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;437&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"437\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-2d754aef29bd8e6bd400d7bb95496f7b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-2d754aef29bd8e6bd400d7bb95496f7b_b.jpg\"/></figure><p>这里通过使用<a href=\"https://link.zhihu.com/?target=http%3A//httpbin.org/post\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">httpbin.org/post</span><span class=\"invisible\"></span></a>网站演示（该网站可以作为练习如何使用urllib的一个站点使用，能够模拟各种请求操作)完成了一次POST请求。</p><p>通过上面的介绍我相信你对urllib的基础知识有了一个比较深刻的了解，但这远远不够，需要我们在实践中不断丰富我们的知识库，另外，urllib只是爬虫一个最基础的库，务必掌握，其他一些高端的库根据需要可以自行学会。</p><p>到目前为止我们还没有进行爬一些张图片或者视频的实验。下面我们看看如何来爬一些图片。</p><h2><b>03 爬虫小实验</b></h2><p>在本节我将介绍如何对知乎上某个专栏的一些图片进行爬虫。</p><p>话不多说，直接上这个小实验的代码（写在pachong.py文件中）如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">from urllib import request\nfrom bs4 import BeautifulSoup\nimport re\nimport time\nurl = &#34;https://zhuanlan.zhihu.com/p/20751612&#34;\nhtml = request.urlopen(url).read().decode(&#34;utf-8&#34;)\nsoup = BeautifulSoup(html,&#34;html.parser&#34;)\nlinks = soup.find_all(&#34;img&#34;,&#34;origin_image zh-lightbox-thumb&#34;,src = re.compile(r&#39;.jpg$&#39;))\npath = r&#34;/home/tangxingwang/paichong_picture&#34;\nfor link in links:\n    print(link.attrs[&#39;src&#39;])\n    request.urlretrieve(link.attrs[&#34;src&#34;],path+&#39;\\%s.jpg&#39; % time.time())  </code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c845d09c0cdb7c4aa8f96ef388118170_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"289\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-c845d09c0cdb7c4aa8f96ef388118170_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;289&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"289\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-c845d09c0cdb7c4aa8f96ef388118170_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c845d09c0cdb7c4aa8f96ef388118170_b.jpg\"/></figure><p>在本实例中，我们用Beautiful Soup结合正则表达式的方式来提取符合要求的链接，链接要求是在img标签中，class=origin_image zh-lightbox-thumb，而且链接是.jpg结尾。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-81de2b059d521e4e5d493f179f91fd2f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"430\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-81de2b059d521e4e5d493f179f91fd2f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;430&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"430\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-81de2b059d521e4e5d493f179f91fd2f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-81de2b059d521e4e5d493f179f91fd2f_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">soup = BeautifulSoup(html,&#34;html.parser&#34;)\nlinks = soup.find_all(&#34;img&#34;,&#34;origin_image zh-lightbox-thumb&#34;,src = re.compile(r&#39;.jpg$&#39;))</code></pre></div><p>提取出所有链接后，使用request.urlretrieve来将所有链接保存到本地</p><p>在终端执行上面程序代码即可爬取图片</p><div class=\"highlight\"><pre><code class=\"language-text\">python3  pachong.py</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-cd4bda5b875c5bcd9c14ae7299056302_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-cd4bda5b875c5bcd9c14ae7299056302_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;188&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-cd4bda5b875c5bcd9c14ae7299056302_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-cd4bda5b875c5bcd9c14ae7299056302_b.jpg\"/></figure><h2><b>04 github爬虫工程</b></h2><p>接下来我们看看github上一些优秀的爬虫工程。</p><p><b>4.1 github图片爬虫工程</b></p><p>在github上有许多优秀的图片爬虫项目，我们选择一个对百度图片爬虫的工程详细解释下。下面是这个工程项目的github链接：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/kong36088/BaiduImageSpider\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/kong36088/Ba</span><span class=\"invisible\">iduImageSpider</span><span class=\"ellipsis\"></span></a></p><p>我们将其clone下来后，有下图所示的一些文件：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d736cccae2ba3aa5a12c167f9a2447e1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"231\" data-rawheight=\"86\" class=\"content_image\" width=\"231\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;231&#39; height=&#39;86&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"231\" data-rawheight=\"86\" class=\"content_image lazy\" width=\"231\" data-actualsrc=\"https://pic2.zhimg.com/v2-d736cccae2ba3aa5a12c167f9a2447e1_b.jpg\"/></figure><p>接下来我们打开index.py这个文件，按照自己的需求修改自己的下面这一行代码</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0907d0a6873babb382aeac983d124fa5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"173\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-0907d0a6873babb382aeac983d124fa5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;173&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"173\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-0907d0a6873babb382aeac983d124fa5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-0907d0a6873babb382aeac983d124fa5_b.jpg\"/></figure><p>我把索引改成了科比，总数为1页，然后运行下面代码</p><div class=\"highlight\"><pre><code class=\"language-text\">python3 index.py</code></pre></div><p>执行python3 index.py后你会发现有大量的图片在下载,如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-8d86b5d931709875a0432ec7a7243d37_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-8d86b5d931709875a0432ec7a7243d37_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-8d86b5d931709875a0432ec7a7243d37_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-8d86b5d931709875a0432ec7a7243d37_b.jpg\"/></figure><p>我们再看下文件的变化，你会现在的文件比我们之前clone下来的多了个科比文件夹，如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-619b6e7a6257c5afdb052a087ee188a1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"89\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-619b6e7a6257c5afdb052a087ee188a1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;89&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"89\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-619b6e7a6257c5afdb052a087ee188a1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-619b6e7a6257c5afdb052a087ee188a1_b.jpg\"/></figure><p>打开科比这个文件夹，你会发现有许多科比的照片。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9d0d9904699ea39b46bc28ca4540dd24_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"435\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-9d0d9904699ea39b46bc28ca4540dd24_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;435&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"435\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-9d0d9904699ea39b46bc28ca4540dd24_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-9d0d9904699ea39b46bc28ca4540dd24_b.jpg\"/></figure><p>关于对百度图片爬虫就讲解到这，github上还有大量这样的项目，如下：</p><p>1.该github工程是关于对知乎里面某个问题下所有的图片进行爬虫。下面是链接：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/ladingwu/python_zhihu\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/ladingwu/pyt</span><span class=\"invisible\">hon_zhihu</span><span class=\"ellipsis\"></span></a></p><p>2.该github工程是关于对微博某个用户相册里面所有的图片进行爬虫。下面是链接：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/lincanbin/Sina-Weibo-Album-Downloader\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/lincanbin/Si</span><span class=\"invisible\">na-Weibo-Album-Downloader</span><span class=\"ellipsis\"></span></a></p><p>3.该github工程是关于对花瓣里面旅游模块图片进行爬虫，下面是链接</p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/darrenfantasy/image_crawler/tree/master/Huaban\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/darrenfantas</span><span class=\"invisible\">y/image_crawler/tree/master/Huaban</span><span class=\"ellipsis\"></span></a></p><p>4.该github工程是关于对google image进行爬虫。下面是链接：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Ehco1996/Python-crawler/tree/master/Google-Image\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/Ehco1996/Pyt</span><span class=\"invisible\">hon-crawler/tree/master/Google-Image</span><span class=\"ellipsis\"></span></a></p><p>这就是github上一些关于图片爬虫的工程，当然github上关于图片爬虫的工程还有很多，有需要可以自己search再学习学习。</p><p><b>4.2 github视频爬虫工程</b></p><p>说完图片的一些工程，我们再看看github上一些比较好的视频工程。下面这个链接是关于对抖音视频进行爬虫的一个项目。链接如下：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/loadchange/amemv-crawler\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/loadchange/a</span><span class=\"invisible\">memv-crawler</span><span class=\"ellipsis\"></span></a></p><p>clone下来有如下文件<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c37e60c83aa4d3ac7976aaa29410bf70_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"95\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c37e60c83aa4d3ac7976aaa29410bf70_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;95&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"95\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c37e60c83aa4d3ac7976aaa29410bf70_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c37e60c83aa4d3ac7976aaa29410bf70_b.jpg\"/></figure><p>现在打开文件`share-url.txt`,把你想要下载的抖音号分享链接编辑进去，以逗号/空格/tab/表格鍵/回车符分隔都行，可以多行。</p><p>样式如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4faeec44ead70ad13717dbb92bbd097f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"159\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-4faeec44ead70ad13717dbb92bbd097f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;159&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"159\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-4faeec44ead70ad13717dbb92bbd097f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4faeec44ead70ad13717dbb92bbd097f_b.jpg\"/></figure><p>然后在终端执行 下面代码即可下载</p><p>python3 amemv-video-ripper.py</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-2d5f106a62894c193628b26d801dc412_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-2d5f106a62894c193628b26d801dc412_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;416&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-2d5f106a62894c193628b26d801dc412_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-2d5f106a62894c193628b26d801dc412_b.jpg\"/></figure><p>下载后的视频保存在download文件件里面，里面有各个抖音号的小视频<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8d1dea89d085512eb376904c749bb06a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"98\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8d1dea89d085512eb376904c749bb06a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;98&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"98\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8d1dea89d085512eb376904c749bb06a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8d1dea89d085512eb376904c749bb06a_b.jpg\"/></figure><p>在github中关于视频爬虫的工程实际上还有很多，大家可以去上面看看！</p><p>最后附上一个github上关于学习爬虫比较好的干货。链接如下。</p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Ehco1996/Python-crawler\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/Ehco1996/Pyt</span><span class=\"invisible\">hon-crawler</span><span class=\"ellipsis\"></span></a> </p><p>AI领域必须掌握的数据爬虫基础就讲到这里，这方面的知识还有很多，大家平时还需要多注意学习！</p><p><i>下期预告：下一期我们会讲用可视化来理解你的数据，如果你有建议，欢迎留言，我们会及时采纳的。</i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p></p>", 
            "topic": [
                {
                    "tag": "python爬虫", 
                    "tagLink": "https://api.zhihu.com/topics/20086364"
                }, 
                {
                    "tag": "前端开发", 
                    "tagLink": "https://api.zhihu.com/topics/19550901"
                }, 
                {
                    "tag": "网页爬虫", 
                    "tagLink": "https://api.zhihu.com/topics/19794679"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55027085", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 23, 
            "title": "【AI白身境】只会用Python？g++，CMake和Makefile了解一下", 
            "content": "<p>首发于《有三AI》</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a><p>今天是新专栏<b>《AI白身境》</b>的第六篇，所谓白身，就是什么都不会，还没有进入角色。</p><p>对于大部分小白来说，因为python用的太爽，以致于或许都没有听说过CMake。python是脚本语言，而当前大量的AI算法都部署在移动端嵌入式平台，需要使用c/java语言，因此熟悉CMake和Makefile也是必备的基础。</p><p>                                                                                                                    作者 | 汤兴旺 言有三<br/>                                                                                                                    编辑 | 汤兴旺 言有三</p><h2><b>01 g++必备基础</b></h2><p>在学习CMake和和Makefile之前我们先学下g++这个工具，大家或许会问为什么要学g++，不应该直接学CMake和Makefile吗。实际上如果你不掌握g++根本就不会写Makefile，因为它实际上就是对g++代码的整理，有了Makefile，执行程序会更加快速方便。另外CMake就是为了简化Makefile的编写，它可以自动生成Makefile。</p><p><b>1.1 安装g++</b></p><p>我们在安装g++之前可以看一下自己是否已经安装了g++，因为ubuntu安装后就默认安装了g++，下面命令可查看自己g++版本。</p><p><b>Tips：如果不想作死，就不要手贱去降级或者升级g++版本。</b></p><p>g++ --version</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f2b4fcfd0b3ab0c1b44bdcb045175a94_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"133\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-f2b4fcfd0b3ab0c1b44bdcb045175a94_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;133&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"133\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-f2b4fcfd0b3ab0c1b44bdcb045175a94_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-f2b4fcfd0b3ab0c1b44bdcb045175a94_b.jpg\"/></figure><p>因为我已经安装了g++，出现了上面安装的版本号。如果你出现了上面信息，就不需要再安装了，没有的话，用下面的命令即可完成安装。</p><p>sudo apt-get install g++</p><p>安装好后也可以通过g++ --version查看是否安装成功</p><p><b>1.2 编译流程</b></p><p>现在我们已经安装好了g++，接下来通过写一个简单的程序来看看整个的编译流程。</p><p>我们通过vim创建一个test.cpp文件，测试的代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">#include &lt;iostream&gt;\nusing namespace std;\nint main() \n{    \n      cout &lt;&lt; &#34;Hello, world!&#34; &lt;&lt;endl;   \n      return 0; \n}</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-34444003105f70bf4f5f875d6b8f3bae_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"135\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-34444003105f70bf4f5f875d6b8f3bae_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;135&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"135\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-34444003105f70bf4f5f875d6b8f3bae_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-34444003105f70bf4f5f875d6b8f3bae_b.jpg\"/></figure><p>测试代码完成后，我们来进行下编译，打开终端，在终端输入g++  文件名即可，在这个程序中就是下面命令：</p><div class=\"highlight\"><pre><code class=\"language-text\">g++  test.cpp</code></pre></div><p>注意这里的文件名是包括路径的，要是不知道文件路径的话可以在敲完g++和空格之后直接把文件拖进去，系统会自动添加文件路径。</p><p>在终端完成上面的命令后，你发现并没有任何输出，但这时候你去主文件夹下（默认主文件夹）看下会发现有个a.out文件</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f9b7676a141e9ec7e0368b32aa3d1aff_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"135\" data-rawheight=\"86\" class=\"content_image\" width=\"135\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;135&#39; height=&#39;86&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"135\" data-rawheight=\"86\" class=\"content_image lazy\" width=\"135\" data-actualsrc=\"https://pic4.zhimg.com/v2-f9b7676a141e9ec7e0368b32aa3d1aff_b.jpg\"/></figure><p>现在你再在终端输入下面命令就能看到结果。</p><div class=\"highlight\"><pre><code class=\"language-text\">./a.out</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-eb09cb0ecbc2224a9cf4d386869777a6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"86\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-eb09cb0ecbc2224a9cf4d386869777a6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;86&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"86\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-eb09cb0ecbc2224a9cf4d386869777a6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-eb09cb0ecbc2224a9cf4d386869777a6_b.jpg\"/></figure><p>接下来我来解释下这个.out文件，实际上这是个经过相应的链接产生的可执行文件。还有个.o文件，它是个中间文件，一般是通过编译的但还未链接。我们通过看看g++在执行编译工作的时候的流程，你就会有更好的理解。如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">1.预处理，生成.i的文件\n2.将预处理后的文件转换成汇编语言，生成.s文件\n3.将汇编变为目标代码(机器代码)，生成.o的文件\n4.连接目标代码,生成可执行程序</code></pre></div><p>对于这个流程，我们结合上面的例子，再详细介绍下，如下：</p><p><b>1.预处理阶段</b></p><p>首先在终端输入下面代码：</p><p>g++ -E test.cpp &gt; test.i </p><p>预处理后的文件在 linux下以.i为后缀名，这个过程是用来激活预处理，执行完命令后，你会发现主文件夹下多了一个test.i文件</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-fc589cd7d1d7d49b5825368c79095b79_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"141\" data-rawheight=\"66\" class=\"content_image\" width=\"141\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;141&#39; height=&#39;66&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"141\" data-rawheight=\"66\" class=\"content_image lazy\" width=\"141\" data-actualsrc=\"https://pic2.zhimg.com/v2-fc589cd7d1d7d49b5825368c79095b79_b.jpg\"/></figure><p>这一步（预处理）主要做了宏的替换，和注释的消除。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b4ac45420e37bd5da575f125c6977f2d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"456\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-b4ac45420e37bd5da575f125c6977f2d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;456&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"456\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-b4ac45420e37bd5da575f125c6977f2d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b4ac45420e37bd5da575f125c6977f2d_b.jpg\"/></figure><p>上图是test.i文件的最后部分，可以看见宏的替换和注释的消除。</p><p><b>2.将预处理后的文件转换成汇编语言</b></p><p>在终端输入下面代码：</p><div class=\"highlight\"><pre><code class=\"language-text\">g++ -S test.cpp</code></pre></div><p>这一步主要就是生成test.s文件，.s文件表示汇编文件，用编辑器打开就都是汇编指令。下图是test.s文件的一部分。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9ea26388fa451bab19bc2036a6a4c36a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"441\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-9ea26388fa451bab19bc2036a6a4c36a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;441&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"441\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-9ea26388fa451bab19bc2036a6a4c36a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9ea26388fa451bab19bc2036a6a4c36a_b.jpg\"/></figure><p><b>3.将汇编语言变为目标代码(机器代码)</b></p><p>在终端输入下面代码：</p><div class=\"highlight\"><pre><code class=\"language-text\">g++ -c test.cpp </code></pre></div><p>这一步就是生成目标文件，用编辑器打开就都是二进制机器码。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-cc00fadfadcdeb5bbeec845b4ec58828_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"439\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-cc00fadfadcdeb5bbeec845b4ec58828_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;439&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"439\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-cc00fadfadcdeb5bbeec845b4ec58828_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-cc00fadfadcdeb5bbeec845b4ec58828_b.jpg\"/></figure><p><b>4.链接目标代码，生成可执行程序</b></p><p>在终端输入下面代码：</p><div class=\"highlight\"><pre><code class=\"language-text\">g++ test.o -o test</code></pre></div><p>在这一步中生成的可执行程序名为test，如果执行命令 g++ test.o  这样默认生成a.out</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-8c4f17312dbaa811175a393bfa7282a0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"444\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-8c4f17312dbaa811175a393bfa7282a0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;444&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"444\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-8c4f17312dbaa811175a393bfa7282a0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-8c4f17312dbaa811175a393bfa7282a0_b.jpg\"/></figure><p>最后我们再看下这个过程中产生的所有文件，如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c631eb00b32971742783e4245c13834d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"373\" data-rawheight=\"72\" class=\"content_image\" width=\"373\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;373&#39; height=&#39;72&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"373\" data-rawheight=\"72\" class=\"content_image lazy\" width=\"373\" data-actualsrc=\"https://pic2.zhimg.com/v2-c631eb00b32971742783e4245c13834d_b.jpg\"/></figure><p>这就是编译的整个过程，你掌握了吗，这个过程对于后面编写Makefile非常重要，一定要深刻理解。</p><blockquote><b>02 Makefile必备基础</b></blockquote><p>上面我们对g++和编译过程进行了介绍，现在我们继续学习如何编写Makefile。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.1 Makefile介绍                        </code></pre></div><p>Makefile描述了整个工程的编译、链接等规则，它定义了一系列规则来指定哪些文件需要编译以及如何编译、需要创建哪些库文件以及如何创建这些库文件、如何产生我们想要的可执行文件。</p><p>而且Makefile可以有效的减少大工程中需要编译和链接的文件，只编译和链接那些需要修改的文件，可以说使用Makefile，整个工程都可以完全自动化编译。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b91cc88690c40eda57ee18544bc193a9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"500\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic2.zhimg.com/v2-b91cc88690c40eda57ee18544bc193a9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;800&#39; height=&#39;500&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"500\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"800\" data-original=\"https://pic2.zhimg.com/v2-b91cc88690c40eda57ee18544bc193a9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b91cc88690c40eda57ee18544bc193a9_b.jpg\"/></figure><p><b>2.2 Makefile基本格式</b></p><div class=\"highlight\"><pre><code class=\"language-text\">target ... : prerequisites ...\n   command\n   ...\n   ...</code></pre></div><p>target - 目标文件, 可以是 Object File, 也可以是可执行文件</p><p>prerequisites - 生成target所需要的文件或者目标</p><p>command - make需要执行的命令(任意的shell命令)，Makefile中的命令必须以 [tab] 开头</p><p><b>2.3 Makefile语法</b></p><p>Makefile包含了五个重要的东西：显示规则、隐晦规则、变量定义、文件指示和注释。详细解释如下：</p><p> 1. 显示规则：</p><p>通常在写makefile时使用的都是显式规则，这需要指明target和prerequisite文件。一条规则可以包含多个target，这意味着其中每个target的prerequisite都是相同的。当其中的一个target被修改后，整个规则中的其他target文件都会被重新编译或执行。 </p><p>2. 隐晦规则：</p><p>make的自动推导功能所执行的规则</p><p>3. 变量的定义：</p><p>Makefile中定义的变量，一般是字符串</p><p>4. 文件指示：</p><p>Makefile中引用其他Makefile；指定Makefile中有效部分；定义一个多行命令 </p><p>5. 注释：</p><p>Makefile只有行注释 &#34;#&#34;, 如果要使用或者输出&#34;#&#34;字符, 需要进行转义, &#34;\\#</p><p><b>2.4 Makefile简单实例</b></p><p>尽管上面介绍了许多Makefile的知识点，但我相信一定你很晕，接下来我通过一个实例来说明如何编写Makefile。</p><p><b>2.4.1 准备程序文件</b></p><p>我们使用opencv对下面这只可爱的猫进行读取显示。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b3844e604b937931d64c91cd614c3012_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"746\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-b3844e604b937931d64c91cd614c3012_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;746&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"746\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-b3844e604b937931d64c91cd614c3012_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b3844e604b937931d64c91cd614c3012_b.jpg\"/></figure><p>在这里我们用c++和opencv对图片进行读取和显示，程序保存在DisplayImage.cpp这个文件里，代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">#include &lt;stdio.h&gt;\n#include &lt;opencv2/opencv.hpp&gt;\nusing namespace cv;\nint main(int argc, char** argv )\n{\n    if ( argc != 2 )\n    {\n       printf(&#34;usage: DisplayImage.out &lt;Image_Path&gt;\\n&#34;);\n        return -1;\n    }\n   Mat image;\n    image = imread( argv[1], 1 );\n    if ( !image.data )\n    {\n        printf(&#34;No image data \\n&#34;);\n        return -1;\n    }\n    namedWindow(&#34;Display Image&#34;, WINDOW_AUTOSIZE );\n    imshow(&#34;Display Image&#34;, image);\n    waitKey(0);\n    return 0;\n}</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-cc24023f2262825e2315534ad716cab8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"564\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb\" width=\"564\" data-original=\"https://pic1.zhimg.com/v2-cc24023f2262825e2315534ad716cab8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;564&#39; height=&#39;468&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"564\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"564\" data-original=\"https://pic1.zhimg.com/v2-cc24023f2262825e2315534ad716cab8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-cc24023f2262825e2315534ad716cab8_b.jpg\"/></figure><p><b>2.4.2 Makefile编写</b></p><p>上面我们已经准备好了.cpp文件，现在我们来编写Makefile进而进行编译，程序如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a275e4d794bb2430ac2331e6562b9bbc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"240\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-a275e4d794bb2430ac2331e6562b9bbc_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;240&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"240\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-a275e4d794bb2430ac2331e6562b9bbc_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a275e4d794bb2430ac2331e6562b9bbc_b.jpg\"/></figure><p>现在我来解释下应该如何编写这个Makefile，对于编写Makefile我建议从下往上写。步骤如下：</p><p><b>1.编写clean</b></p><p>这一步在Makefile中基本差不多，它的作用就是删除所有的.o文件和可执行文件。为什么这样做呢?我举个例子说明下，如果你有100个.cpp文件，经过编译后会得到一个可执行文件。在这个过程中我们会得到许多不必要的文件，例如100个.o文件，但这个文件又没有用，如果用rm的话那就太麻烦了，所以我们用了clean，它可以很轻松完成这个任务。另外请注意Makefile文件在执行时不会执行clean这个命令，需要我们调用才会执行，即make clean。clean代码如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0e42b3186126ff8d22ed267c5f576797_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"41\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-0e42b3186126ff8d22ed267c5f576797_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;41&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"41\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-0e42b3186126ff8d22ed267c5f576797_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0e42b3186126ff8d22ed267c5f576797_b.jpg\"/></figure><p><b>2.编写目标文件1：依赖文件1</b></p><p>目标文件就是你想得到的文件，依赖文件就是你目前所拥有的东西。在本实例中我们现在拥有DisplayImage.cpp，所以DisplayImage.cpp是依赖文件，我们想得到DisplayImage.o，所以它是目标文件。代码如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e3281619efcb9b3fc413904ae8aca261_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"39\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-e3281619efcb9b3fc413904ae8aca261_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;39&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"39\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-e3281619efcb9b3fc413904ae8aca261_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e3281619efcb9b3fc413904ae8aca261_b.jpg\"/></figure><p><b>3.编写目标文件2：依赖文件2</b></p><p>这一步的依赖文件2实际就是第二步的目标文件1，在第二步我们通过DisplayImage.cpp得到了DisplayImage.o，现在我们需要通过DisplayImage.o得到可执行文件DisplayImage。所以在这一步目标文件是DisplayImage，依赖文件是DisplayImage.o，代码如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3e1edb90d46681546ceec3c6ff62a5f6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"41\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-3e1edb90d46681546ceec3c6ff62a5f6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;41&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"41\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-3e1edb90d46681546ceec3c6ff62a5f6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-3e1edb90d46681546ceec3c6ff62a5f6_b.jpg\"/></figure><p><b>4.应用opencv库和头文件</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-443f4df693b8f2c59664fe3972c631d1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"86\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-443f4df693b8f2c59664fe3972c631d1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;86&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"86\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-443f4df693b8f2c59664fe3972c631d1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-443f4df693b8f2c59664fe3972c631d1_b.jpg\"/></figure><p>这一步就需要根据自己计算机来配置了，对于我们初学者来说挺麻烦的，可以自己尝试下。有问题可以联系我们。</p><p>编写完makefile后，我们在终端make下就行了。下面编译后的文件：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5670d04a7ebed674d602f3de27fc254f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"953\" data-rawheight=\"81\" class=\"origin_image zh-lightbox-thumb\" width=\"953\" data-original=\"https://pic4.zhimg.com/v2-5670d04a7ebed674d602f3de27fc254f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;953&#39; height=&#39;81&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"953\" data-rawheight=\"81\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"953\" data-original=\"https://pic4.zhimg.com/v2-5670d04a7ebed674d602f3de27fc254f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5670d04a7ebed674d602f3de27fc254f_b.jpg\"/></figure><p>最后在终端输入下面代码即可显示图片。</p><div class=\"highlight\"><pre><code class=\"language-text\">./DisplayImage 01.jpg</code></pre></div><p>总体来说编写Makefile可以按照这个套路写，多写几次就会了。</p><h2><b>03 CMake必备基础</b></h2><p>说完Makefile，我们再说下CMake。CMake是一个跨平台的编译(Build)工具，可以用简单的语句来描述所有平台的编译过程，其是在make基础上发展而来的，早期的make需要程序员写Makefile文件，进行编译，而现在CMake能够通过对cmakelists.txt的编辑，轻松实现对复杂工程的组织。下面我带大家学习下CMake的基础知识。</p><p><b>3.1 安装CMake</b></p><p>首先我们看看如何在自己的linux系统(我的系统Ubuntu18.04)下安装CMake。方法如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">sudo apt-get install cmake</code></pre></div><p>输入上面命令后实际上就安装成功了，可以通过下面命令来检查：</p><div class=\"highlight\"><pre><code class=\"language-text\">cmake --version</code></pre></div><p>如果你的界面如下图所示即说明安装成功。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-30460bfc30281b2056ff97fdaf2de1f5_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"531\" data-rawheight=\"53\" class=\"origin_image zh-lightbox-thumb\" width=\"531\" data-original=\"https://pic2.zhimg.com/v2-30460bfc30281b2056ff97fdaf2de1f5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;531&#39; height=&#39;53&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"531\" data-rawheight=\"53\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"531\" data-original=\"https://pic2.zhimg.com/v2-30460bfc30281b2056ff97fdaf2de1f5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-30460bfc30281b2056ff97fdaf2de1f5_b.png\"/></figure><p><b>3.2 CMake编译流程</b></p><p>成功安装好CMake后我们再来说说如何在linux平台下使用CMake生成Makefile并编译的流程，如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">1.编写CMake配置文件CMakeLists.txt，我们可以认为CMakeLists.txt就是CMake所处理的&#34;代码&#34;。\n2.执行命令 cmake path生成Makefile,其中path是CMakeLists.txt所在的目录。\n3.使用make命令进行编译。</code></pre></div><p><b>3.3 使用CMake编译程序</b></p><p>我们通过一个关于opencv读取图片的程序，让大家更好的理解整个CMake的编译过程。</p><p><b>3.3.1 准备程序文件</b></p><p>这里程序准备可以按照第二部分makefile那里准备。最后文件目录结构如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">├── build\n├── CMakeLists.txt\n├── DisplayImage.cpp</code></pre></div><p>opencv读取图片的程序写完后，我们需要编写CMake处理的代码了，即CMakeLists.txt。</p><p><b>3.3.2 编写CMakeLists.txt</b></p><p>现在我们编写CMakeLists.txt文件，该文件实际上放在哪里都可以，只要编写的路径能够正确指向就好了，CMakeLists.txt文件内容如下所示：</p><div class=\"highlight\"><pre><code class=\"language-text\">cmake_minimum_required(VERSION 2.8)\nproject( DisplayImage )\nfind_package( OpenCV REQUIRED )\nadd_executable( DisplayImage DisplayImage.cpp )\ntarget_link_libraries( DisplayImage ${OpenCV_LIBS} )</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5e4f6162e31ed2a973e7729acead4d15_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"703\" data-rawheight=\"132\" class=\"origin_image zh-lightbox-thumb\" width=\"703\" data-original=\"https://pic2.zhimg.com/v2-5e4f6162e31ed2a973e7729acead4d15_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;703&#39; height=&#39;132&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"703\" data-rawheight=\"132\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"703\" data-original=\"https://pic2.zhimg.com/v2-5e4f6162e31ed2a973e7729acead4d15_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5e4f6162e31ed2a973e7729acead4d15_b.jpg\"/></figure><p>看到这些代码是不是很闷逼，为了让大家明白CMakeLists.txt文件内容，接下来我说一下Cmake的一些常用命令，你就能很好的理解上面的代码了。</p><p>1）cmake_minimum_required命令</p><p>命令语法：cmake_minimum_required(VERSION major[.minor[.patch[.tweak]]][FATAL_ERROR])</p><p>命令简述：用于指定需要的CMake 的最低版本</p><p>使用范例：cmake_minimum_required(VERSION 2.8)</p><p>2）project 命令</p><p>命令语法：project(&lt;projectname&gt; [languageName1 languageName2 … ] )</p><p>命令简述：用于指定项目的名称，一般和项目的文件夹名称对应</p><p>使用范例：project(DisplayImage)</p><p>3）aux_source_directory命令</p><p>命令语法：aux_source_directory(&lt;dir&gt; &lt;variable&gt;)</p><p>命令简述：用于将 dir 目录下的所有源文件的名字保存在变量 variable 中</p><p>使用范例：aux_source_directory(src DIR_SRCS)</p><p>4）add_executable 命令</p><p>命令语法：add_executable(&lt;name&gt; [WIN32] [MACOSX_BUNDLE][EXCLUDE_FROM_ALL] source1 source2 … sourceN)</p><p>命令简述：用于指定从一组源文件 source1 source2 … sourceN 编译出一个可执行文件且命名为name</p><p>使用范例:add_executable( DisplayImage DisplayImage.cpp )</p><p>5）target_link_libraries命令</p><p>命令语法：target_link_libraries(&lt;target&gt; [item1 [item2 […]]][[debug|optimized|general] ] …)</p><p>命令简述：用于指定 target 需要的链接 item1 item2 …。这里 target 必须已经被创建，链接的 item 可以是已经存在的 target（依赖关系会自动添加）</p><p>使用范例：target_link_libraries( DisplayImage ${OpenCV_LIBS} )</p><p>6）add_subdirectory 命令</p><p>命令语法：add_subdirectory(source_dir [binary_dir] [EXCLUDE_FROM_ALL])</p><p>命令简述：用于添加一个需要进行构建的子目录</p><p>使用范例：add_subdirectory(Lib)</p><p>7）include_directories 命令</p><p>命令语法：include_directories([AFTER|BEFORE] [SYSTEM] dir1 dir2 …)</p><p>命令简述：用于设定目录，这些设定的目录将被编译器用来查找 include 文件</p><p>使用范例：include_directories(${PROJECT_SOURCE_DIR}/lib)</p><p>像这样的命令还有很多，如find_package（）寻找使用第三方库等，这些都需要我们平时多加积累。给大家一个查询命令的方法，大家可以多去看cmake官网的help，链接如下：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//cmake.org/cmake/help/v2.8.8/cmake.html%23section_Commands\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cmake.org/cmake/help/v2</span><span class=\"invisible\">.8.8/cmake.html#section_Commands</span><span class=\"ellipsis\"></span></a></p><p><b>3.3 编译和运行程序</b></p><p>现在CMakeLists.txt文件已经编写好了，意味着我们的工作即将进入尾声。现在看看我们的文件结构目录，如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7f4d8b6dd47f197ba2b6ba0d92bd3d82_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1075\" data-rawheight=\"147\" class=\"origin_image zh-lightbox-thumb\" width=\"1075\" data-original=\"https://pic3.zhimg.com/v2-7f4d8b6dd47f197ba2b6ba0d92bd3d82_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1075&#39; height=&#39;147&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1075\" data-rawheight=\"147\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1075\" data-original=\"https://pic3.zhimg.com/v2-7f4d8b6dd47f197ba2b6ba0d92bd3d82_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-7f4d8b6dd47f197ba2b6ba0d92bd3d82_b.png\"/></figure><p>接下来我们就需要进行编译了。编译的过程相对于CMakeLists.txt文件的编写是很简单的，只有两步，如下</p><div class=\"highlight\"><pre><code class=\"language-text\">cmake\nmake</code></pre></div><p>其中cmake命令将CMakeLists.txt文件转化为make所需要的makefile文件，最后用make命令编译源码生成可执行程序或共享库。对于我们这个实例，编译如下：</p><p>首先我们在命令行输入<b>cmake .</b>(注意cmake和.之间有空格)，表明Cmakelist.txt文件在当前目录下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-150e7ac22a6016249f96df15bc54ee21_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"726\" data-rawheight=\"397\" class=\"origin_image zh-lightbox-thumb\" width=\"726\" data-original=\"https://pic2.zhimg.com/v2-150e7ac22a6016249f96df15bc54ee21_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;726&#39; height=&#39;397&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"726\" data-rawheight=\"397\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"726\" data-original=\"https://pic2.zhimg.com/v2-150e7ac22a6016249f96df15bc54ee21_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-150e7ac22a6016249f96df15bc54ee21_b.jpg\"/></figure><p>接下来在命令行输入<b>make</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-52a108c2ef32ed64ec53e101edaba60a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"96\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-52a108c2ef32ed64ec53e101edaba60a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;96&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"96\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-52a108c2ef32ed64ec53e101edaba60a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-52a108c2ef32ed64ec53e101edaba60a_b.jpg\"/></figure><p>这样我们就编译成功了，我们看下编译后的文件目录</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-650a52b0162dbea6340b7375fc019f6a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"893\" data-rawheight=\"89\" class=\"origin_image zh-lightbox-thumb\" width=\"893\" data-original=\"https://pic3.zhimg.com/v2-650a52b0162dbea6340b7375fc019f6a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;893&#39; height=&#39;89&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"893\" data-rawheight=\"89\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"893\" data-original=\"https://pic3.zhimg.com/v2-650a52b0162dbea6340b7375fc019f6a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-650a52b0162dbea6340b7375fc019f6a_b.jpg\"/></figure><p>解释下这个build文件夹，由于cmake后会生成很多编译的中间文件以及makefile文件，所以一般建议新建一个新的目录，专门用来编译，这就是这里的build，打开build后，里面的文件如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b1fe4123bb1722968bfec66f8c5919d9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"849\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb\" width=\"849\" data-original=\"https://pic2.zhimg.com/v2-b1fe4123bb1722968bfec66f8c5919d9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;849&#39; height=&#39;110&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"849\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"849\" data-original=\"https://pic2.zhimg.com/v2-b1fe4123bb1722968bfec66f8c5919d9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b1fe4123bb1722968bfec66f8c5919d9_b.jpg\"/></figure><p>到这里，我们不禁要问怎么没有图片显示呢，别急，在build目录下的命令行输入下面命令即可显示图片，这就是生产的DisplayImage可执行文件。</p><div class=\"highlight\"><pre><code class=\"language-text\">./DisplayImage ../01.jpg</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f7aec3dfe24a77c7cb7fad219e19c11a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"38\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-f7aec3dfe24a77c7cb7fad219e19c11a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;38&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"38\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-f7aec3dfe24a77c7cb7fad219e19c11a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f7aec3dfe24a77c7cb7fad219e19c11a_b.jpg\"/></figure><p>到这里，关于CMake的一些基本操作就介绍的差不多了，其实对于CMake的学习我认为必须在实例中多加应用，才能更好的掌握，因为它的复杂命令太多了。</p><p><b>总结</b></p><p>CMake和Makefile的基础我们就介绍完了，对于这两个工具其实不是一时就能学会的，需要大量的实践积累才能游刃有余。</p><p><i>下期预告：下一期我们会讲AI领域必须掌握的数据爬虫基础，如果你有建议，欢迎留言，我们会及时采纳的。</i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "CMake", 
                    "tagLink": "https://api.zhihu.com/topics/19834837"
                }, 
                {
                    "tag": "开源项目", 
                    "tagLink": "https://api.zhihu.com/topics/19565961"
                }, 
                {
                    "tag": "linux编译", 
                    "tagLink": "https://api.zhihu.com/topics/19761818"
                }
            ], 
            "comments": [
                {
                    "userName": "御宅暴君", 
                    "userLink": "https://www.zhihu.com/people/a2417f5b568eae957dea31316f241349", 
                    "content": "<p>别邀请我写文章了，天天发，估计是机器人发的吧。</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "与我无关噢", 
                            "likes": 0, 
                            "replyToAuthor": "御宅暴君"
                        }, 
                        {
                            "userName": "御宅暴君", 
                            "userLink": "https://www.zhihu.com/people/a2417f5b568eae957dea31316f241349", 
                            "content": "<p>不好意思怪错人了。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "拎着瓢打水的小伙", 
                    "userLink": "https://www.zhihu.com/people/01245b52fc3bce45043a459b06b29e03", 
                    "content": "<p>非常好的入门简介 学习了</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "能学到东西就好", 
                            "likes": 0, 
                            "replyToAuthor": "拎着瓢打水的小伙"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/54800023", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 24, 
            "title": "【AI白身境】搞计算机视觉必备的OpenCV入门基础", 
            "content": "<p>今天是新专栏<b>《AI白身境》</b>的第五篇。</p><p>曾经看过一个视频，树莓派自平衡机器人自动追着小球跑。不经让我脑子蹦出一个有趣的想法，可以做一个识别猫的机器人，让机器人跟着猫跑，有这样一个小东西陪伴喵星人一定很有意思。</p><p>不过，首先你要有一只猫，其次，这个机器人不仅要有一双会视觉处理的眼睛，还一定要有一个坚强的外壳，不然会被喵星人给拆了。</p><p>那机器人是如何完成处理图像和视频的各项任务呢？开源的计算机视觉包——<b>OpenCV</b> 会是你的最佳选择，今天给小白们做一个最简单的入门介绍。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>                                                                                                                         作者 |  臧小满 言有三 </p><p>                                                                                                                         编辑 |  臧小满 言有三</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-5da9c3e04aadecb3f0dcc310c38f6b0a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"598\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-5da9c3e04aadecb3f0dcc310c38f6b0a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;598&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"598\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-5da9c3e04aadecb3f0dcc310c38f6b0a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-5da9c3e04aadecb3f0dcc310c38f6b0a_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>今天很开心与大家分享一篇关于OpenCV的文章，重点阐述以下几个问题： </p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>1.如何部署OpenCV。</b></p><p><b>2.OpenCV有哪些模块，可以做什么。</b></p><p><b>3.OpenCV的基本数据结构的熟悉与使用。</b></p><p>希望看过文章后，你也可以开始玩转OpenCV之路。</p><h2>01 <b>什么OpenCV？</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-fd84c98cdfffb1ddb0581a59eff2b18b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"605\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-fd84c98cdfffb1ddb0581a59eff2b18b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;605&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"605\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-fd84c98cdfffb1ddb0581a59eff2b18b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-fd84c98cdfffb1ddb0581a59eff2b18b_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f570304788d8c979ae6b0f7f288a820f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-f570304788d8c979ae6b0f7f288a820f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-f570304788d8c979ae6b0f7f288a820f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f570304788d8c979ae6b0f7f288a820f_b.jpg\"/></figure><p>它是一款由Intel公司俄罗斯团队发起并参与和维护的一个计算机视觉处理开源软件库。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>作为一款优秀的计算机视觉库，在诸多方面都有着卓越的表现：</p><p><b>1.编程语言</b></p><p>多数模块基于C++实现，少部分基于C语言实现，同时提供了Python、Ruby、MATLAB等语言的接口。</p><p><b>2.跨平台   </b></p><p>可自由地运行在Linux、Windows和Mac OS等桌面平台，Android、 IOS、BlackBerray等移动平台。</p><p><b>3.活跃的开发团队</b></p><p>目前已更新至OpenCV4.0</p><p><b>4.丰富的API</b></p><p>完善的传统计算机视觉算法，涵盖主流传统机器学习算法，同时添加了对深度学习的支持。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>OpenCV可以完成几乎所有的图像处理任务，下面是一个简要list。</p><ul><li>视频分析(Video analysis)</li><li>3D重建(3D reconstruction)</li><li>特征提取(Feature extraction)</li><li>目标检测(Object detection)</li><li>机器学习(Machine learning)</li><li>计算摄影(Computational photography)</li><li>形状分析(Shape analysis)</li><li>光流算法(Optical flow algorithms)</li><li>人脸和目标识别(Face and object recognition)</li><li>表面匹配(Surface matching)</li><li>文本检测和识别(Text detection and recognition)<br/></li></ul><h2>02 <b>如何部署OpenCV?</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e8a8174a08cab5fff53be9f8f67cc503_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-e8a8174a08cab5fff53be9f8f67cc503_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-e8a8174a08cab5fff53be9f8f67cc503_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e8a8174a08cab5fff53be9f8f67cc503_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>一般来说我们会使用OpenCV的C++和Python版本，所以下面分别对其安装进行介绍，以ubuntu系统为例。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>2.1 Ubuntu安装C++ OpenCV</b></p><p>安裝OpenCV所需的库</p><p>sudo apt-get install build-essential</p><p>sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev </p><p>libswscale-dev3 sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev <br/></p><p>下载最新opencv源码</p><p>unzip opencv-3.2.0.zip</p><p>cd ~/opencv-3.2.0 <br/></p><p>编译OpenCV</p><p>cd ~/opencv-3.2.0</p><p>mkdir release</p><p>cd release</p><p>cmake -D CMAKE_BUILD_TYPE=RELEASE -D </p><p>CMAKE_INSTALL_PREFIX=/usr/local ..</p><p>make</p><p>sudo make install</p><p class=\"ztext-empty-paragraph\"><br/></p><p>一般来说，编译安装绝对不可能一次顺利完成，以下是几个常见的问题。</p><div class=\"highlight\"><pre><code class=\"language-text\">1，编译过程中ippcv下载失败， 解决问题的办法就是手动下载。\n2，LAPACK包include报错， 解决问题的办法就是在cmake之后马上修改对应include文件的路径  如果make失败后再修改则无效。\n3，某些模块找不到， 通常是因为少了编译安装contrib模块。</code></pre></div><p><b>2.2  Ubuntu安装Python-OpenCV</b></p><p>安装opencv</p><p>pip3 install opencv-python</p><p>进入python，导入cv2</p><p>import cv2</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>03 <b>OpenCV模块简介</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fbe152aa9a9f1bbcb9e99b653f9746e2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"609\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fbe152aa9a9f1bbcb9e99b653f9746e2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;609&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"609\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fbe152aa9a9f1bbcb9e99b653f9746e2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fbe152aa9a9f1bbcb9e99b653f9746e2_b.jpg\"/></figure><p>OpenCV提供了许多内置的用于图像处理和计算机视觉相关操作的基础数据结构，它们都包含在core模块中，并且这些数据结构都已经针对速度和内存做了优化，下面以4.0版本为例进行介绍，参考<i><u><a href=\"https://link.zhihu.com/?target=https%3A//docs.opencv.org/master/d9/df8/tutorial_root.html\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">docs.opencv.org/master/</span><span class=\"invisible\">d9/df8/tutorial_root.html</span><span class=\"ellipsis\"></span></a></u></i>。</p><p>Opencv目录下”modules目录”列出了OpenCV包含的各个模块，其中<b>core、highgui、imgproc</b>是最基础的模块。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7ce743309747a0087e2d109ee142c7ad_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-7ce743309747a0087e2d109ee142c7ad_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-7ce743309747a0087e2d109ee142c7ad_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7ce743309747a0087e2d109ee142c7ad_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><ul><li><b>core模块</b>实现了最核心的数据结构及其基本运算，如绘图函数、数组操作相关函数，与OpenGL的互操作等。<br/></li><li><b>highgui模块</b>实现了视频与图像的读取、显示、存储等接口。</li><li><b>imgproc模块</b>实现了图像处理的基础方法，包括图像滤波、图像的几何变换、平滑、阈值分割、形态学处理、边缘检测、目标检测、运动分析和对象跟踪等。</li></ul><p class=\"ztext-empty-paragraph\"><br/></p><p>对于图像处理其他更高层次的方向及应用，OpenCV也有相关的模块实现</p><ul><li><b>features2d模块</b>用于提取图像特征以及特征匹配，nonfree模块实现了一些专利算法，如sift特征。</li><li><b>objdetect模块</b>实现了一些目标检测的功能，经典的基于Haar、LBP特征的人脸检测，基于HOG的行人、汽车等目标检测，分类器使用Cascade Classification（级联分类）和Latent SVM等。</li><li><b>stitching模块</b>实现了图像拼接功能。</li><li><b>FLANN模块</b>（Fast Library for Approximate Nearest Neighbors），包含快速近似最近邻搜索FLANN <br/>和聚类Clustering算法。</li><li><b>ml模块</b>机器学习模块（SVM，决策树，Boosting等等）。</li><li><b>photo模块</b>包含图像修复和图像去噪两部分。</li><li><b>video模块</b>针对视频处理，如背景分离，前景检测、对象跟踪等。</li><li><b>calib3d模块</b>即Calibration（校准）3D，这个模块主要是相机校准和三维重建相关的内容。包含了基本的多视角几何算法，单个立体摄像头标定，物体姿态估计，立体相似性算法，3D信息的重建等等。</li><li><b>G-API模块</b>包含超高效的图像处理pipeline引擎。<br/></li></ul><p>另外，原来在opencv2中的<b>shape, superres, videostab, viz等模块</b>被移动到opencv_contrib中，关于opencv contrib，我们以后再详细介绍。</p><h2>04 <b>OpenCV基本数据结构</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-58f4a0d406310c52cc840b1a2610847d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"603\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-58f4a0d406310c52cc840b1a2610847d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;603&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"603\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-58f4a0d406310c52cc840b1a2610847d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-58f4a0d406310c52cc840b1a2610847d_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>OpenCv提供了多种基本的数据类型，常用的OpenCV的基本数据结构有以下几种:</p><ul><li><b>Mat类</b></li><li><b>Point类</b></li><li><b>Size类</b></li><li><b>Rect类</b></li><li><b>Scalar类</b></li><li><b>Vec类</b></li><li><b>Range类</b></li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-61316d1c8b914604e979d213c795d239_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-61316d1c8b914604e979d213c795d239_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-61316d1c8b914604e979d213c795d239_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-61316d1c8b914604e979d213c795d239_b.jpg\"/></figure><p>下面我们重点说一下MAT类。</p><p><b>4.1  Mat类</b></p><p>要熟练使用OpenCV，最重要的就是学会Mat数据结构，在OpenCV中Mat被定义为一个类，把它看作一个数据结构，以矩阵的形式来存储数据的。</p><p>Mat有哪些常见的属性？</p><ul><li>dims：表示矩阵M的维度，如2*3的矩阵为2维，3*4*5的矩阵为3维</li><li>data：uchar型的指针，指向内存中存放矩阵数据的一块内存</li><li>rows, cols：矩阵的行数、列数</li><li>type：表示了矩阵中元素的类型(depth)与矩阵的通道个数(channels)；命名规则为CV_ + (位数）+（数据类型）+（通道数）<br/>其中：U（unsigned integer）-- 无符号整数<br/>S（signed integer）-- 有符号整数<br/>F（float）-- 浮点数<br/>例如CV_8UC3，可拆分为：CV_：type的前缀, <br/>8U：8位无符号整数(depth)，C3：3通道(channels)</li><li>depth：即图像每一个像素的位数(bits)；这个值和type是相关的。例如CV_8UC3中depth则是CV_8U。</li><li>channels：通道数量，若图像为RGB、HSV等三通道图像，则channels = 3；若图像为灰度图，则为单通道，则channels = 1</li><li>elemSize：矩阵中每一个元素的数据大小<br/>elemSize = channels * depth / 8 ，例如：type是CV_8UC3，elemSize = 3 * 8 / 8 = 3bytes</li><li>elemSize1：单通道的矩阵元素占用的数据大小，elemSize1 = depth / 8，例如：type是CV_8UC3，elemSize1 = 8 / 8 = 1bytes</li></ul><p class=\"ztext-empty-paragraph\"><br/></p><p><b>4.2  其他数据类型</b></p><p>1.<b>点Point类</b></p><p>包含两个整型数据成员x和y，即坐标点</p><p>2.<b>尺寸Size类</b></p><p>数据成员是width和height，一般用来表示图像的大小，或者矩阵的大小</p><p>3.<b>矩形Rect类</b></p><p>数据成员x,y,width,height，分别代表这个矩形左上角的坐标点和矩形的宽度和高度</p><p>4.<b>颜色Scalar类</b></p><p>Scalar_(_Tp v0, _Tp v1, _Tp v2=0, _Tp v3=0)</p><p>这个默认构造函数的四个参数分别表示RGB+Alpha颜色中的: </p><p>v0---表示RGB中的B（蓝色）分量 </p><p>v1---表示RGB中的G（绿色）分量 </p><p>v2---表示RGB中的R（红色）分量 </p><p>v3---表示Alpha是透明色分量 </p><p>5.<b>向量Vec类</b></p><p>一个“一维矩阵”</p><p>Vec&lt;int,n&gt;---就是用类型int和向量模板类做一个实例化。其中第一个参数int表示Vec中存储的为int类型；第二个参数n为一个整型值，表示Vec每个对象中存储n个int值，也就是n维向量(列向量)</p><p>6.<b>Range类</b></p><p>用于指定一个连续的子序列，例如一个轮廓的一部分，或者一个矩阵的列空间</p><h2>05 <b>基本IO操作</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b4427c0e6d5d9ec0d014d9acf24ece86_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-b4427c0e6d5d9ec0d014d9acf24ece86_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-b4427c0e6d5d9ec0d014d9acf24ece86_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b4427c0e6d5d9ec0d014d9acf24ece86_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>这里使用的是python接口</p><p class=\"ztext-empty-paragraph\"><br/></p><p>1.图像读写</p><p>cv2.imread(文件名,显示控制参数)  # 读入图像   </p><p>cv2.imshow(窗口名，图像名)   #显示图像</p><p>cv2.imwrite(文件地址,文件名)  #保存图像</p><p>cv2.namedWindow(窗口名)  #创建窗口</p><p>cv2.destroyAllWindows() #销毁窗口</p><p>cv2.waitKey(   [,delay])  #decay ＞ 0 等待delay 毫秒</p><p>                                      #decay ＜ 0 等待键盘单击</p><p>                                      #decay =  0 无限等待</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ff80ea559fe0f5ef1ca387b49711e8e6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"497\" data-rawheight=\"331\" class=\"origin_image zh-lightbox-thumb\" width=\"497\" data-original=\"https://pic3.zhimg.com/v2-ff80ea559fe0f5ef1ca387b49711e8e6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;497&#39; height=&#39;331&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"497\" data-rawheight=\"331\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"497\" data-original=\"https://pic3.zhimg.com/v2-ff80ea559fe0f5ef1ca387b49711e8e6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ff80ea559fe0f5ef1ca387b49711e8e6_b.jpg\"/></figure><p>2.图像缩放</p><p>dst = cv2.resize(src,dsize,fx,fy)  #dsize表示缩放大小 </p><p>                                                   #fx，fy缩放比例</p><p>3.图像翻转</p><p>dst = cv2.flip(src,flipCode) </p><p>        #flipCode=0 以X轴为对称轴的翻转 </p><p>        #lipCode＞0 以Y轴为对称轴的翻转 </p><p>        #flipCode＜0 对X、Y轴同时翻转</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-cbe690527f62da4d4a67d83ef9a2b887_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"841\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb\" width=\"841\" data-original=\"https://pic4.zhimg.com/v2-cbe690527f62da4d4a67d83ef9a2b887_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;841&#39; height=&#39;312&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"841\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"841\" data-original=\"https://pic4.zhimg.com/v2-cbe690527f62da4d4a67d83ef9a2b887_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-cbe690527f62da4d4a67d83ef9a2b887_b.jpg\"/></figure><p>4.通道拆分与合并</p><p>b,g,r = cv2.split(图像) </p><p>b = cv2.split(图像)[通道数] #拆分</p><p>bgr = cv2.merge([b,g,r]) #合并</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8b1f71a9c9b3b24db8c4e1bc889b1d9a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"653\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb\" width=\"653\" data-original=\"https://pic3.zhimg.com/v2-8b1f71a9c9b3b24db8c4e1bc889b1d9a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;653&#39; height=&#39;476&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"653\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"653\" data-original=\"https://pic3.zhimg.com/v2-8b1f71a9c9b3b24db8c4e1bc889b1d9a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8b1f71a9c9b3b24db8c4e1bc889b1d9a_b.jpg\"/></figure><h2>06 <b>相关学习资料</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-1ee1e3363d9e547555ffb5fca02b2c02_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-1ee1e3363d9e547555ffb5fca02b2c02_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-1ee1e3363d9e547555ffb5fca02b2c02_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-1ee1e3363d9e547555ffb5fca02b2c02_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>6.1  网络资料</b></p><ul><li>OpenCV Docs官方文档 <br/><i><u><a href=\"https://link.zhihu.com/?target=https%3A//docs.opencv.org/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">docs.opencv.org/</span><span class=\"invisible\"></span></a></u></i></li><li>OpenCV 官方Github<br/><u><i><a href=\"https://link.zhihu.com/?target=https%3A//github.com/opencv/opencv\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/opencv/openc</span><span class=\"invisible\">v</span><span class=\"ellipsis\"></span></a></i></u></li><li>OpenCV 中文教程<br/><u><i><a href=\"https://link.zhihu.com/?target=http%3A//www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/tutorials.html\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">opencv.org.cn/opencvdoc</span><span class=\"invisible\">/2.3.2/html/doc/tutorials/tutorials.html</span><span class=\"ellipsis\"></span></a></i></u></li></ul><p><b>6.2  中文书籍</b></p><ul><li>Python计算机视觉编程</li><li>OpenCV 3计算机视觉：Python语言实现</li><li>OpenCV算法精解：基于Python与C++<br/></li></ul><p>最后，推荐一下大家的Opencv学习路线。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0cac6b63e93676bc224ee91a226dc5f3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"357\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0cac6b63e93676bc224ee91a226dc5f3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;357&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"357\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0cac6b63e93676bc224ee91a226dc5f3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0cac6b63e93676bc224ee91a226dc5f3_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>总结</b></p><p>本文简单介绍了OpenCV框架，它是计算机视觉领域必须要熟练掌握的工具，这一期我们没有说具体的算法和模块，以后会开设<b>《OpenCV专题》</b>讲述。</p><p>下期预告：下一期我们会说说Makefile和CMake的基础。 </p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "OpenCV", 
                    "tagLink": "https://api.zhihu.com/topics/19587715"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "图像处理", 
                    "tagLink": "https://api.zhihu.com/topics/19556376"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>opencv 系列可以开个专栏，深度学习主要使用到的 API分析分析</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "没问题，必须开", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "Fantasy", 
                    "userLink": "https://www.zhihu.com/people/280e5a04ac8058d3c0c16367eff2245a", 
                    "content": "图像处理包那么多，skimage,PIL,opencv, 请问该如何选取呢？<br>不知道是否都是BGR格式[好奇]", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "不是噢，小孩子才做选择，大人都要[飙泪笑]", 
                            "likes": 0, 
                            "replyToAuthor": "Fantasy"
                        }, 
                        {
                            "userName": "Fantasy", 
                            "userLink": "https://www.zhihu.com/people/280e5a04ac8058d3c0c16367eff2245a", 
                            "content": "<p>可以的</p><p></p><p></p>", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/54610306", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 13, 
            "title": "【AI白身境】深度学习必备图像基础", 
            "content": "<p>首发于《有三AI》</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a><p>今天是新专栏<b>《AI白身境》</b>的第四篇，所谓白身，就是什么都不会，还没有进入角色。</p><p>我们已经说了linux基础和python基础，接下来就要开始真正干活了。所谓万丈高楼平地起，正式从事深度学习技术的三大方向，图像，语音，NLP之前，自然要先了解各自的基础。</p><p>笔者身处计算机视觉领域，所以这一期就跟大家说说<b>必备的图像基础</b>。</p><p>                                                                                                   作者 | 言有三，微信Longlongtogo<br/>                                                                                                                                      编辑 | 言有三</p><h2><b>1 图像的起源</b></h2><p><b>1.1 图像的进化</b></p><p>图像是什么？这个问题大家都有自己的答案。我的答案是，<b>图像是一门语言</b>，是人类文明的象征。</p><p>人类起源时没有图像，最开始记事采用的方法是什么呢？据《易·系辞下》中记录，“上古结绳而治，后世圣人易之书契 ，百官以治，万民以查”，也就是说，最开始没有文字，大家采用结绳的方法来记录。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a9fc95ee9c12169bda10885f072b1769_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"438\" data-rawheight=\"439\" class=\"origin_image zh-lightbox-thumb\" width=\"438\" data-original=\"https://pic2.zhimg.com/v2-a9fc95ee9c12169bda10885f072b1769_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;438&#39; height=&#39;439&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"438\" data-rawheight=\"439\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"438\" data-original=\"https://pic2.zhimg.com/v2-a9fc95ee9c12169bda10885f072b1769_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a9fc95ee9c12169bda10885f072b1769_b.jpg\"/></figure><p>到了后来，中国进入了一个文明时代，商朝，并且有了自己的文字，甲骨文，这就是我们现在汉字的起源。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9b6af01035ed6a1ce1a72b5745749544_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"419\" data-rawheight=\"338\" class=\"content_image\" width=\"419\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;419&#39; height=&#39;338&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"419\" data-rawheight=\"338\" class=\"content_image lazy\" width=\"419\" data-actualsrc=\"https://pic1.zhimg.com/v2-9b6af01035ed6a1ce1a72b5745749544_b.jpg\"/></figure><p>再后来，随着西方文明的发展，有了照片，从此我们进入了多媒体记录信息的时代。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-05c9d7bd040058f120fdc66feca86b3f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1035\" data-rawheight=\"1017\" class=\"origin_image zh-lightbox-thumb\" width=\"1035\" data-original=\"https://pic4.zhimg.com/v2-05c9d7bd040058f120fdc66feca86b3f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1035&#39; height=&#39;1017&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1035\" data-rawheight=\"1017\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1035\" data-original=\"https://pic4.zhimg.com/v2-05c9d7bd040058f120fdc66feca86b3f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-05c9d7bd040058f120fdc66feca86b3f_b.jpg\"/></figure><p>如今，图片视频已经成为了人的一生中非常重要的记忆载体。<br/></p><p>英文image来源于拉丁文imāgō，它的含义有很多，比如reflection，visible form等等，实际上表述的就是一种语言。</p><p><b>图像包括图和像，图，它是一直客观存在的光的分布。而像则是图在人大脑中的印象。</b></p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>1.2 模拟图像与数字图像</b></p><p>图像起源于1826年前后法国科学家Joseph Nicéphore Niépce发明的第一张可永久保存的照片，属于<b>模拟图像</b>。</p><p><b>模拟图像又称连续图像</b>，它通过某种物理量（如光、电等）的强弱变化来记录图像亮度信息，所以是连续变换的。模拟信号的特点是容易受干扰，如今已经基本全面被数字图像替代。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-bc386223f6061ac1654628d082f587d6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"269\" data-rawheight=\"187\" class=\"content_image\" width=\"269\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;269&#39; height=&#39;187&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"269\" data-rawheight=\"187\" class=\"content_image lazy\" width=\"269\" data-actualsrc=\"https://pic3.zhimg.com/v2-bc386223f6061ac1654628d082f587d6_b.jpg\"/></figure><p>在第一次世界大战后，1921年美国科学家发明了Bartlane System，并从<b>伦敦传到纽约传输了第一幅数字图像</b>，其亮度用离散数值表示。</p><p>这是一种电缆图片传输系统，将图片编码成<b>5个灰度级</b>，1929年发展成15个灰度级，通过海底电缆进行传输。在发送端图片被编码并使用打孔带记录，通过系统传输后在接收方使用特殊的打印机恢复成图像。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-32f90a461d5a233b6139e4975ca53b8f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"440\" data-rawheight=\"273\" class=\"origin_image zh-lightbox-thumb\" width=\"440\" data-original=\"https://pic4.zhimg.com/v2-32f90a461d5a233b6139e4975ca53b8f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;440&#39; height=&#39;273&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"440\" data-rawheight=\"273\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"440\" data-original=\"https://pic4.zhimg.com/v2-32f90a461d5a233b6139e4975ca53b8f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-32f90a461d5a233b6139e4975ca53b8f_b.jpg\"/></figure><p>二战时,世界各国报纸上的图像都是采用Bartlane System进行传输。<br/></p><p><b>1950年左右，计算机被发明，数字图像处理学科正式诞生。</b></p><p>模拟图像和数字图像的对比，大家可以看看。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d541b9f66c8b7dfa18a339bfa7a7266e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-d541b9f66c8b7dfa18a339bfa7a7266e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;338&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-d541b9f66c8b7dfa18a339bfa7a7266e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d541b9f66c8b7dfa18a339bfa7a7266e_b.jpg\"/></figure><h2>02 <b>数字图像表示</b></h2><p><b>2.1 位数</b></p><p>计算机采用0/1编码的系统，数字图像也是利用0/1来记录信息，我们平常接触的图像都是8位数图像，包含0～255灰度，其中0，代表最黑，1，表示最白。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0e195b4fc595b994dbb504171424bbfb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"543\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0e195b4fc595b994dbb504171424bbfb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;543&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"543\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0e195b4fc595b994dbb504171424bbfb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0e195b4fc595b994dbb504171424bbfb_b.jpg\"/></figure><p>其实人眼对亮度的对比的敏感度远远超过亮度的本身。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3d69d09d717a39cd7567ea2c9cf78c52_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"824\" data-rawheight=\"816\" class=\"origin_image zh-lightbox-thumb\" width=\"824\" data-original=\"https://pic3.zhimg.com/v2-3d69d09d717a39cd7567ea2c9cf78c52_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;824&#39; height=&#39;816&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"824\" data-rawheight=\"816\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"824\" data-original=\"https://pic3.zhimg.com/v2-3d69d09d717a39cd7567ea2c9cf78c52_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-3d69d09d717a39cd7567ea2c9cf78c52_b.jpg\"/></figure><p>就像上面的两条线，是一样的灰度值，但是人眼很难分辨这是相同的灰度，尽管知识告诉我们它是。实际上，人眼能分辨的灰度级不到32级，大于16级。<br/></p><p><b>2.2 分辨率 </b></p><p>数字图像有两个分辨率，<b>图像分辨率与输出分辨率</b>。</p><p><b>图像分辨率指的是每英寸的像素数</b>，简写为ppi，我们平常说一张图片大小的时候使用的就是图像分辨率。</p><p><b>输出分辨率指的是设备输出图像时每英寸可产生的点数，简写为dpi</b>，这是在印刷行业，摄影行业常用的分辨率，摄影行业通常要求DPI不低于300。</p><p>相同的图像分辨率，更高的DPI表现为物理尺寸更小。因为这个时候每英寸点更多，像素变小。</p><p>如下面两张图，左图的DPI=72，物理尺寸大小为高46.85厘米，宽67.73厘米。右图的DPI=150，物理尺寸大小为高22.47厘米，宽32.49厘米。两者的像素数是相等的，都是1920*1328像素分辨率，但是右边的dpi更大。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-09717441fe3a1f0918295f5cd9cc6e65_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"491\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-09717441fe3a1f0918295f5cd9cc6e65_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;491&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"491\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-09717441fe3a1f0918295f5cd9cc6e65_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-09717441fe3a1f0918295f5cd9cc6e65_b.jpg\"/></figure><p>物理尺寸相同，DPI较低表现为较低的分辨率，此时每英寸的点数变少，像素变大。如下面两张图，图像实际大小相等，但是右边的图像分辨率较低，像素数较少，清晰度有所下降。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-731812c05f2245f5fa16365f1d62254d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"370\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-731812c05f2245f5fa16365f1d62254d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;370&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"370\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-731812c05f2245f5fa16365f1d62254d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-731812c05f2245f5fa16365f1d62254d_b.jpg\"/></figure><p><b>2.3  彩色空间 </b></p><p>图像有灰度图有彩色图，灰度图即只包含亮度信息，而彩色图不仅包含亮度信息还包含颜色信息。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5aa8f630be63a96c19758b88e46b942b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-5aa8f630be63a96c19758b88e46b942b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;369&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-5aa8f630be63a96c19758b88e46b942b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5aa8f630be63a96c19758b88e46b942b_b.jpg\"/></figure><p>我们平常接触的是RGB彩色图，即由红（Red）绿（Green）蓝（Blue）3个通道组成，一张图像的每一个像素由矢量（R，G，B）表示。</p><p>这是在消费市场最广泛使用的，最常用的用途就是显示器系统，计算机、电视机等都是采用RGB颜色空间来进行图像显示。RGB颜色空间背后的生物学原理是人眼有对这3种颜色最敏感的细胞，在自然界中肉眼所能看到的任何色彩都可以由这三种色彩叠加而成，因此也被称为加色原理。比如黄色，可以通过红色和绿色相加，全红色为（255，0，0），全绿色为（0，255，0），全黄色为（255，255，0）。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-90c2392a6542ae897753bbe8e0319ba2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"400\" class=\"content_image\" width=\"400\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;400&#39; height=&#39;400&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"400\" class=\"content_image lazy\" width=\"400\" data-actualsrc=\"https://pic3.zhimg.com/v2-90c2392a6542ae897753bbe8e0319ba2_b.jpg\"/></figure><p>有艺术背景的读者会提出绿色和红色混合在一起产生的是褐色，与这里的计算机色彩模型加色原理不同，这是因为绘画遵循的是减色模型。</p><p>除了RGB颜色空间，常用的颜色空间还有HSV，CIELab等，我们以后会集中讲述。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>03 数字图像处理基础</b></h2><p>数字图像处理有一些基本的表述和概念我们必须清楚。</p><p><b>3.1  直方图 </b></p><p>图像之所以能处理，是因为像素与像素是有空间联系的，对像素灰度值进行统计，就得到了直方图。</p><p>下面分别是上面灰度和彩色图的直方图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c485e1e50f0952d5ec91dfe7e33a1909_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"381\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c485e1e50f0952d5ec91dfe7e33a1909_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;381&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"381\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c485e1e50f0952d5ec91dfe7e33a1909_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c485e1e50f0952d5ec91dfe7e33a1909_b.jpg\"/></figure><p>统计代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sys\nimport os\n \nfilename=sys.argv[1]\nimg=cv2.imread(filename)\ncolors=[&#39;blue&#39;,&#39;green&#39;,&#39;red&#39;]\n \nfor i in range(3):\n    hist,x=np.histogram(img[:,:,i].ravel(),bins=256,range=(0,256))\n    plt.plot(0.5*(x[:-1]+x[1:]),hist,label=colors[i],color=colors[i])\nplt.show()\n \nimggray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\ncv2.imwrite(&#39;sample_gray.jpg&#39;,imggray)\n \nhistgray,xgray=np.histogram(imggray.ravel(),bins=256,range=(0,256))\nprint xgray\nplt.figure()\nplt.plot(0.5*(xgray[:-1]+xgray[1:]),histgray)\nplt.show()</code></pre></div><p>我们可以看到，在灰度直方图包含两个很明显的分布，在彩色直方图的红色通道也包含两个很明显的分布，分别对应的就是<b>“前景”和“背景”</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-351018ebaea88f5f300f16724592caa4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"948\" data-rawheight=\"590\" class=\"origin_image zh-lightbox-thumb\" width=\"948\" data-original=\"https://pic1.zhimg.com/v2-351018ebaea88f5f300f16724592caa4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;948&#39; height=&#39;590&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"948\" data-rawheight=\"590\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"948\" data-original=\"https://pic1.zhimg.com/v2-351018ebaea88f5f300f16724592caa4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-351018ebaea88f5f300f16724592caa4_b.jpg\"/></figure><p>如上图，感兴趣的是图中的“柿子”，这就是前景，它的灰度比较高，对应的就是直方图中的较高峰。</p><p><b>3.2  边缘 </b></p><p>视觉机制和马赫达效应都表明人眼对不连续的东西是最敏感的，而图像中不连续的东西，表现出来就是图像边缘。</p><p>边缘包含上升阶跃型、下降阶跃型、屋脊型、脉冲型等类型，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6794cd176f211359259f1f83c8832a91_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-6794cd176f211359259f1f83c8832a91_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-6794cd176f211359259f1f83c8832a91_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6794cd176f211359259f1f83c8832a91_b.jpg\"/></figure><p>边缘检测在计算机视觉与图像处理中基础且应用广泛。通过提取目标的轮廓，用于识别不同的物体，或作为图像的特征表示。边缘检测的基本方法有很多，它们的绝大部分可以划分为两类：基于一阶导数和二阶导数的方法。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>关于边缘检测方法，公众号有视频公开课</b>，大家可以去看。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>3.3  对比度与清晰度 </b></p><p>图像有高亮度也有低亮度，对应的就是白与黑，目前多数显示系统利用8字节，即灰度值0代表最黑，灰度值255代表最亮，不过大部分图像上的亮度范围通常都小于最大最小值之差。</p><p><b>对比度，指的就是画面的明暗反差程度</b>。</p><p>对比度有全局对比度和局部对比度。增加对比度，画面中亮的地方会更亮，暗的地方会更暗，明暗反差会增强。下面分别是降低对比度和增加对比度，感受一下。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d4f8e90f34b6df2f5bc26513156de638_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"243\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d4f8e90f34b6df2f5bc26513156de638_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;243&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"243\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d4f8e90f34b6df2f5bc26513156de638_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d4f8e90f34b6df2f5bc26513156de638_b.jpg\"/></figure><p><b>清晰度，指的是边缘附近的敏感对比。</b></p><p>如果增加清晰度，边缘较暗的一侧会变得更暗，边缘较亮的一侧会变得更亮，轮廓更加清晰，不过调节过度，会出现晕影。</p><p>增加清晰度，可以通过锐化操作来进行。降低清晰度，可以通过降低图像分辨率，增加模糊等方法。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1d1da83ed8465f1fe9b6c2d23ecbd940_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"243\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-1d1da83ed8465f1fe9b6c2d23ecbd940_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;243&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"243\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-1d1da83ed8465f1fe9b6c2d23ecbd940_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-1d1da83ed8465f1fe9b6c2d23ecbd940_b.jpg\"/></figure><h2>04 <b>图像处理与计算机视觉，图形学的关系</b></h2><p>有一些基本概念容易混淆，图像处理，图形学，计算机视觉等，用几个图就很好理解了。</p><p><b>4.1  图像处理领域 </b></p><p><b>图像处理一般指数字图像处理</b>，输入是图像，输出也是图像，通常是为了改善，增强图像的内容以方便后续的分析。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-66c7148ef88e592e49538cd01998e2b3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"224\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-66c7148ef88e592e49538cd01998e2b3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;224&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"224\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-66c7148ef88e592e49538cd01998e2b3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-66c7148ef88e592e49538cd01998e2b3_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-56149040a96ca919d8a3f577d85a75a5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-56149040a96ca919d8a3f577d85a75a5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;372&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-56149040a96ca919d8a3f577d85a75a5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-56149040a96ca919d8a3f577d85a75a5_b.jpg\"/></figure><p>图像模糊</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-0651432997334e148975d8583126b6ce_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"768\" class=\"origin_image zh-lightbox-thumb\" width=\"1024\" data-original=\"https://pic3.zhimg.com/v2-0651432997334e148975d8583126b6ce_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1024&#39; height=&#39;768&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"768\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1024\" data-original=\"https://pic3.zhimg.com/v2-0651432997334e148975d8583126b6ce_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-0651432997334e148975d8583126b6ce_b.jpg\"/></figure><p>对比度增强</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-29d07bff21e14fb12ebd52a30314cee0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"394\" data-rawheight=\"240\" class=\"content_image\" width=\"394\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;394&#39; height=&#39;240&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"394\" data-rawheight=\"240\" class=\"content_image lazy\" width=\"394\" data-actualsrc=\"https://pic1.zhimg.com/v2-29d07bff21e14fb12ebd52a30314cee0_b.jpg\"/></figure><p>图像降噪</p><p class=\"ztext-empty-paragraph\"><br/></p><p>更多的图像算法，等我更新即可。</p><p><b>4.2  计算机视觉 </b></p><p>所谓计算机视觉，即compute vision，就是通过用计算机来模拟人的视觉工作原理，来完成模式分析，比如图像分类，分割，检测等。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-8f8cefc1242369b3974aa1f9ada2528f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"191\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-8f8cefc1242369b3974aa1f9ada2528f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;191&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"191\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-8f8cefc1242369b3974aa1f9ada2528f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-8f8cefc1242369b3974aa1f9ada2528f_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-293380f77330075f78632126bf0f1759_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"469\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-293380f77330075f78632126bf0f1759_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;469&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"469\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-293380f77330075f78632126bf0f1759_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-293380f77330075f78632126bf0f1759_b.jpg\"/></figure><p><b>4.3  图形学 </b></p><p>所谓计算机图形学(Computer Graphics，简称CG)，是指使用数学算法将二维或三维图形转化为计算机显示器的栅格形式的科学。</p><p>简单地说，计算机图形学的主要研究内容就是研究如何在计算机中<b>表示图形</b>、以及利用计算机进行图形的计算，比如我们熟知的<b>CG制作</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c63b806867fcdc85af2d3528bf4be68f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"935\" data-rawheight=\"583\" class=\"origin_image zh-lightbox-thumb\" width=\"935\" data-original=\"https://pic4.zhimg.com/v2-c63b806867fcdc85af2d3528bf4be68f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;935&#39; height=&#39;583&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"935\" data-rawheight=\"583\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"935\" data-original=\"https://pic4.zhimg.com/v2-c63b806867fcdc85af2d3528bf4be68f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c63b806867fcdc85af2d3528bf4be68f_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-523843ff4d03b0b0e5c730bc3ab0c195_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"904\" data-rawheight=\"508\" class=\"origin_image zh-lightbox-thumb\" width=\"904\" data-original=\"https://pic2.zhimg.com/v2-523843ff4d03b0b0e5c730bc3ab0c195_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;904&#39; height=&#39;508&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"904\" data-rawheight=\"508\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"904\" data-original=\"https://pic2.zhimg.com/v2-523843ff4d03b0b0e5c730bc3ab0c195_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-523843ff4d03b0b0e5c730bc3ab0c195_b.jpg\"/></figure><p>图形学中三维重建占了很大一部分比例，感兴趣可以了解更多。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d11405d3cab24befd78ba980b2dffb2c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"382\" data-rawheight=\"422\" class=\"content_image\" width=\"382\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;382&#39; height=&#39;422&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"382\" data-rawheight=\"422\" class=\"content_image lazy\" width=\"382\" data-actualsrc=\"https://pic1.zhimg.com/v2-d11405d3cab24befd78ba980b2dffb2c_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-fb23798be625f7852615a39788b01ec3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"387\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-fb23798be625f7852615a39788b01ec3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;387&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"387\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-fb23798be625f7852615a39788b01ec3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-fb23798be625f7852615a39788b01ec3_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>以上几个领域都是相互交叉，实际上没必要分的那么开，了解即可。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "图像处理", 
                    "tagLink": "https://api.zhihu.com/topics/19556376"
                }, 
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/54591558", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 8, 
            "title": "【AI白身境】学AI必备的python基础", 
            "content": "<p>首发于《有三AI》</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D1400726199%26lang%3Dzh_CN%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a><p>今天是新专栏<b>《AI白身境》</b>的第三篇，所谓白身，就是什么都不会，还没有进入角色。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>上一篇给大家介绍了如何正确使用Linux，如何利用shell，vim，git这三大神器。相信大家也掌握的差不多了，今天就和大家分享下对于python，我们应该如何掌握，如何正确把它和深度学习完美的结合起来。</p><p>                                                                                                                          作者 | 汤兴旺 言有三<br/>                                                                                                                          编辑 | 汤兴旺 言有三</p><h2><b>1 基础操作</b></h2><p>人生苦短，必须学好python！python现在火的程度已经不需要我多言了，它为什么为火，我认为有两个原因，第一是人工智能这个大背景，第二是它真的太容易学了，没有任何一门语言比它好上手，接下来我将和大家分享下python的基础操作。另外请注意，我的所有操作都是基于python3！</p><p><b>1.1 python核心内容之函数</b></p><p>如果你想要学好python，务必学好function，不然就相当于没学过python。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-86e59057dbcc014166cf3cb5ffcba3c5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"426\" data-rawheight=\"165\" class=\"origin_image zh-lightbox-thumb\" width=\"426\" data-original=\"https://pic2.zhimg.com/v2-86e59057dbcc014166cf3cb5ffcba3c5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;426&#39; height=&#39;165&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"426\" data-rawheight=\"165\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"426\" data-original=\"https://pic2.zhimg.com/v2-86e59057dbcc014166cf3cb5ffcba3c5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-86e59057dbcc014166cf3cb5ffcba3c5_b.jpg\"/></figure><p><b>1.1.1 函数定义</b></p><p>在python函数定义时有五个要点，分别是def、函数名、函数体、参数、返回值、以及两个英文版符号：小括号（括号内为参数）和冒号。下面对这5点分别解释下：</p><p class=\"ztext-empty-paragraph\"><br/></p><p>def：函数关键字。必须要有，系统看到它，就知道下面是个函数了。</p><p>函数名：函数的名称。就是给函数起了个名字，当你调用函数时，用函数名就可以直接调用了。</p><p>函数体：函数中进行的具体操作。就是你这个函数想要实现的功能。</p><p>参数：提供给函数体。</p><p>返回值：当函数执行完毕后，可以给调用者返回想要的数据。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>下面通过一个具体的实例来说明下：</p><div class=\"highlight\"><pre><code class=\"language-text\">def get_image(picture_path):\n     img = cv2.imread(&#34;picture_path&#34;)\n     return  img</code></pre></div><p>上面实例中，get_image是这个函数的函数名，这个函数的参数是picture_path，就是图片的路径，这个参数会传到函数体中。如果你的图片路径是d://01.jpg，这时候函数体就会变成img = cv2.imread(&#34;d://01.jpg&#34;),最后返回图片。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>1.1.2 函数参数</b></p><p>相信你已经知道函数应该如何定义了，接下来再说说函数中最难理解也是最重要的一点，那就是函数参数。</p><p>首先我们说说<b>位置参数</b>。</p><div class=\"highlight\"><pre><code class=\"language-text\">def sum(x):\n    z = x+x\n    return z\n&gt;&gt;&gt;sum(10)\n20</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-82b98c0d0ebbf95e962d80798f6676f0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"339\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-82b98c0d0ebbf95e962d80798f6676f0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;339&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"339\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-82b98c0d0ebbf95e962d80798f6676f0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-82b98c0d0ebbf95e962d80798f6676f0_b.jpg\"/></figure><p>这里的x可以认为是一个位置参数，顾名思义，x先占一个位置，当给予它一个值时，它会传到函数体中，注意像这种位置参数，务必要给予一个值，不然程序会报错。</p><p>接下来说说<b>默认参数</b>。</p><div class=\"highlight\"><pre><code class=\"language-text\">def sum(x,y=12):\n    z = x+y\n    return z\n&gt;&gt;&gt;sum(10)\n22\n&gt;&gt;&gt;sum(10,13)\n23</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b6a7aa2ce8e1395f26beb399c573830a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"290\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-b6a7aa2ce8e1395f26beb399c573830a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;290&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"290\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-b6a7aa2ce8e1395f26beb399c573830a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b6a7aa2ce8e1395f26beb399c573830a_b.jpg\"/></figure><p>这个实例中，y = 12就是个默认参数，当该参数没有传入相应的值时，该参数就使用默认值。但有点需要注意：默认参数必须在位置参数后面，否则会报错。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f9255f96522db3b62594e906ced04577_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"322\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-f9255f96522db3b62594e906ced04577_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;322&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"322\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-f9255f96522db3b62594e906ced04577_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f9255f96522db3b62594e906ced04577_b.jpg\"/></figure><p>哈哈，报错了，千万不要放这样的错误哟，想避免这样的错误很简单，就从你定义的顺序从前往后写就行。</p><p>然后再说说<b>可变参数</b>。</p><p>在使用python函数时，有时候我们不知道我们需要传入多少个参数，于是就有了可变参数的这个概念。为了更好的理解这个概念，先抛出一个问题：计算a+b+c+d+...的和，因为不知道有几个数字，所以是个可变的问题。那么如何用python函数来解决这个问题呢，如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">def sum(*numbers):\n    sum = 0\n    for n in numbers:\n        sum =sum +n*n\n    return sum \n&gt;&gt;&gt;sum(10,2,12,3,4)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-8abd03227ace29e1dcb63d8c808847e4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"289\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-8abd03227ace29e1dcb63d8c808847e4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;289&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"289\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-8abd03227ace29e1dcb63d8c808847e4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-8abd03227ace29e1dcb63d8c808847e4_b.jpg\"/></figure><p>我们在参数前面加了一个*号。这样这个参数就变成了可变参数。在调用该函数时，可以传入任意个参数，包括0个参数。</p><p>最后说一下<b>关键字参数</b>。</p><p>什么是关键字参数，对于这个概念我们先看下面的代码：</p><div class=\"highlight\"><pre><code class=\"language-text\">def penson(name,age,**kw):\n    print(&#39;name:&#39;,name,&#39;age:&#39;,age,&#39;other:&#39;,kw)\n&gt;&gt;&gt;person(&#39;zhang san&#39;,24,city=&#39;changchun&#39;)\nname:zhang san age:24 other:{&#39;city&#39;:&#39;changchun&#39;}</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c32e8a76659f2427aa19c9f74f9e2722_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-c32e8a76659f2427aa19c9f74f9e2722_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;312&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-c32e8a76659f2427aa19c9f74f9e2722_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c32e8a76659f2427aa19c9f74f9e2722_b.jpg\"/></figure><p>通过上面的例子你应该明白了关键字参数是什么了吧，实际上就是你传入的参数比你之前定义的参数会多，注意位置参数必须要给它传值。</p><p>这就是python函数的一些基本的方法，更复杂的函数实际上也就是上面的组合而已，只要多加练习，一定能够很好的掌握它。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>1.2 python 缩进规则</b></p><p>你可能已经注意到上面我写python函数时用到了许多缩进，你可能也会问自己为什么要采用缩进，应该如何缩进这些问题，下面请看我一一道来。</p><p><b>1.2.1 python缩进的由来</b></p><p>我们在大学时可能都学过c语言，在c中主要通过{}来区分代码快，但我们初学者往往忘记打{}，而且花括号多了，我们就晕了。而python就不会出现这种问题，python中的缩进可以理解为c中的{}。我们来看下下面这个例子：</p><div class=\"highlight\"><pre><code class=\"language-text\">def SayHello():\n    print(&#34;hello world&#34;)\n    SayHello()</code></pre></div><p>你会发现此时不能输出任何结果，我们再看下面一段代码</p><div class=\"highlight\"><pre><code class=\"language-text\">def SayHello():\n    print(&#34;hello world&#34;)\nSayHello()</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6ea89260e1badbd1d3ace31603afe46a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"359\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-6ea89260e1badbd1d3ace31603afe46a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;359&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"359\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-6ea89260e1badbd1d3ace31603afe46a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-6ea89260e1badbd1d3ace31603afe46a_b.jpg\"/></figure><p>这样就成功了，为什么会这样呢，下面我介绍一种画框法。如下图所示相同颜色框在一起说明它们是属于同一代码块。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-9039bbf5a60cf0a07455bb76af855a63_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"371\" data-rawheight=\"132\" class=\"content_image\" width=\"371\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;371&#39; height=&#39;132&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"371\" data-rawheight=\"132\" class=\"content_image lazy\" width=\"371\" data-actualsrc=\"https://pic4.zhimg.com/v2-9039bbf5a60cf0a07455bb76af855a63_b.jpg\"/></figure><p>这段代码只是定义了一个函数并未执行它，正确的写法如下：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-1c1bc4e5acb80709a06a64d45ca83c97_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"378\" data-rawheight=\"112\" class=\"content_image\" width=\"378\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;378&#39; height=&#39;112&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"378\" data-rawheight=\"112\" class=\"content_image lazy\" width=\"378\" data-actualsrc=\"https://pic4.zhimg.com/v2-1c1bc4e5acb80709a06a64d45ca83c97_b.jpg\"/></figure><p>以后大家可以用这种画框法确定缩进是否正确。</p><h2><b>02 矩阵库——NumPy</b></h2><p>NumPy(Numerical Python) 是 Python语言的一个扩展程序库，支持高维数组与矩阵运算，提供了大量的数学函数库。</p><p>对于深度学习来说，高维数组我们用的很多，因此要想学好深度学习，必须<b>对NumPy了如指掌</b>。</p><p><b>2.1 ndarray对象                          </b></p><p>在NumPy中我们用ndarray表示数组，可以说它是整个库的核心。下面我们将从以下几个方面来理解ndarray。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-020550adbfb1eaadf17a1a9d50451a80_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"497\" data-rawheight=\"307\" class=\"origin_image zh-lightbox-thumb\" width=\"497\" data-original=\"https://pic1.zhimg.com/v2-020550adbfb1eaadf17a1a9d50451a80_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;497&#39; height=&#39;307&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"497\" data-rawheight=\"307\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"497\" data-original=\"https://pic1.zhimg.com/v2-020550adbfb1eaadf17a1a9d50451a80_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-020550adbfb1eaadf17a1a9d50451a80_b.jpg\"/></figure><p><b>2.2 创建数组</b></p><p>要想对数组进行运算操作，我们必须先创建个数组。方法如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np#导入numpy这个包\na0 = np.array([1,2,3,4])#采用列表方式\na1 = np.array((1,2,3,4))#采用元组方式</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-17a93d8767c5d084e9513c6bc9cf5c7d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"364\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-17a93d8767c5d084e9513c6bc9cf5c7d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;364&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"364\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-17a93d8767c5d084e9513c6bc9cf5c7d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-17a93d8767c5d084e9513c6bc9cf5c7d_b.jpg\"/></figure><p>对于多维数组的创建（注意中括号），如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.array([[1,2,3],[2,3,4],[4,5,6]])</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4fe3990673e781d2941c0eaa99ba2888_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-4fe3990673e781d2941c0eaa99ba2888_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-4fe3990673e781d2941c0eaa99ba2888_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-4fe3990673e781d2941c0eaa99ba2888_b.jpg\"/></figure><p>上面我们创建的数组里面的元素都是我们指定的，那么如何自动生成数组?又如何随机的生成一个数组呢？我们首先看第一个方法arange()，如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.arange(0,1,0.1)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a6cefab9b15c316fbbe8d77429b36ab6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"345\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-a6cefab9b15c316fbbe8d77429b36ab6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;345&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"345\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-a6cefab9b15c316fbbe8d77429b36ab6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a6cefab9b15c316fbbe8d77429b36ab6_b.jpg\"/></figure><p>在上面这个数组中，arange()的第一个值代表开始值，第二个值代表终值（不包括这个值），最后一个值代表步长（间隔），如arange(1,10,1)代表一个从0-9，步长为1的数组。这就是arange()，经常用的到！我们再看第二个方法linspace()，如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.linspace(0,10,10)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-3279412ac3fb94e2f4b2260fbb169eb5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-3279412ac3fb94e2f4b2260fbb169eb5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;369&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-3279412ac3fb94e2f4b2260fbb169eb5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-3279412ac3fb94e2f4b2260fbb169eb5_b.jpg\"/></figure><p>对于linspace()，它的前两个值和arange()一样，代表开始值和终值，但有个区别是linspace()默认包括终值，如果你不想包括终值，加上endpoint = False即可，对于第三个值它是指元素的个数，这个和arange不一样，一定不要混淆。</p><p>最后我们再说下如何创建一个随机数组。</p><p>在NumPy中有一庞大的函数库，对于随机数我们可以采用numpy.random模块，该模块中有大量和随机数相关的函数。一些函数如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-825ee7f238014affabc9a6bc4c924919_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"671\" data-rawheight=\"263\" class=\"origin_image zh-lightbox-thumb\" width=\"671\" data-original=\"https://pic2.zhimg.com/v2-825ee7f238014affabc9a6bc4c924919_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;671&#39; height=&#39;263&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"671\" data-rawheight=\"263\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"671\" data-original=\"https://pic2.zhimg.com/v2-825ee7f238014affabc9a6bc4c924919_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-825ee7f238014affabc9a6bc4c924919_b.jpg\"/></figure><p>我们可以利用这些函数来创建你想要的随机数，一些实例如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.random.rand(2,2)\nb = np.random.randn(2,2)\nc = np.random.randint(0,9,(2,2))</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ce47a9aa504dcb4ff1935910e850fa7a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-ce47a9aa504dcb4ff1935910e850fa7a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-ce47a9aa504dcb4ff1935910e850fa7a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ce47a9aa504dcb4ff1935910e850fa7a_b.jpg\"/></figure><p>创建随机数是不是很简单，其实对于数组的创建还有许多方法,如下面所示：</p><div class=\"highlight\"><pre><code class=\"language-text\">np.zeros() :生成元素全是0的数组\nnp.ones()：生成元素全是1的数组\nnp.zeros_like(a):生成形状和a一样且元素全是0的数组\nnp.ones_like(a):生成形状和a一样且元素全是1的数组\n...</code></pre></div><p>相信通过上面的介绍你已经掌握了如何创建一个数组了，很好！那么我们再思考一个问题，若碰到一个元素很多的数组，但却不知道它的形状等参数，这时该怎么办呢？对于这个问题我们可以通过下面的一些方法来解决。</p><div class=\"highlight\"><pre><code class=\"language-text\">获取数组a的shape:a.shape\n获取数组a的元素类型：a.dtype\n获取数组a的维度：a.ndim\n....</code></pre></div><p><b>2.3 存取数组</b></p><p>当一个数组创建好后，我们有时候可能需要对一个数组中的一些具体元素进行运算，或者更改数组中一些元素的值。进行这些操作的前提是先能存取数组，为了解决这个问题，这里我们主要介绍切片法和整数列表来存取数组元素，这种方法其实也是最常见的。</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.array([4,2,3,5,9,0,,6,8,7])\n&gt;&gt;&gt;[4,2,3,5,9,0,6,8,7]</code></pre></div><p>对于上面这个数组，如果我想要得到5这个元素该怎么办呢？很简单，在ndarray中第一个元素的位置是0，本例中5在第四个位置，所以a[3] = 5。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-88a729a5f0f6c9198c6a075d654bc6b1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"320\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-88a729a5f0f6c9198c6a075d654bc6b1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;320&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"320\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-88a729a5f0f6c9198c6a075d654bc6b1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-88a729a5f0f6c9198c6a075d654bc6b1_b.jpg\"/></figure><p>我们还可以用切片获取数组的一部分，如a[3:5]表示获取第四个位置和第五个位置的元素,a[3:5]=[5,9];a[::-1]表示从最后一个元素到第一个元素，该方法省略了开始下标和结束下标，这时候开始下标就是对应第一个元素，结束下标就对应着最后一个数，-1表示步长为1，负号从后往前数。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5248d40314584ce884e0a5df6a225b71_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"381\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-5248d40314584ce884e0a5df6a225b71_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;381&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"381\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-5248d40314584ce884e0a5df6a225b71_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5248d40314584ce884e0a5df6a225b71_b.jpg\"/></figure><p>上面说的都是一维数组的存取，我们再来说一下二维数组。其实二维数组和一维数组数组类似，只是二维数组有2个轴，所以下标自然需要2个值来表示。请看下面的实例：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-dcad81670d7bcfa319a7af88c720e413_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"328\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-dcad81670d7bcfa319a7af88c720e413_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;328&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"328\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-dcad81670d7bcfa319a7af88c720e413_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-dcad81670d7bcfa319a7af88c720e413_b.jpg\"/></figure><p>在二维数组中竖轴表示第0轴，横轴表示第1轴，读取元素时我们通过逗号把0轴和1轴隔开，这样就可以通过一维数组的方法来读取，最后两者的交集就是我们需要读取的元素。</p><p>我们再看下三维数组，这也是最复杂的，在深度学习特征数据处理时用的是最多的。我们先创建一个3行5列3通道的数组，看看效果。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c8cf924cfad46d88ffff721de5e3cf0d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-c8cf924cfad46d88ffff721de5e3cf0d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-c8cf924cfad46d88ffff721de5e3cf0d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c8cf924cfad46d88ffff721de5e3cf0d_b.jpg\"/></figure><p>再来分析下这个生成的数组。我们知道这个三维数组有下图所示的三块，而第几块又代表通道的第几行数据，图中圈的那个块就是通道的第2行数据，另外在每一个块里面每行数据代表通道的第几列数据。图中圈的那个块5有行数据，则代表着这个通道有5列数据。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fcb3c7aa5dabfa31890dd584f9a92d5e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"158\" data-rawheight=\"310\" class=\"content_image\" width=\"158\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;158&#39; height=&#39;310&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"158\" data-rawheight=\"310\" class=\"content_image lazy\" width=\"158\" data-actualsrc=\"https://pic3.zhimg.com/v2-fcb3c7aa5dabfa31890dd584f9a92d5e_b.jpg\"/></figure><p>其次在这个三维数组中，有下面图示的这样三列，一列代表一个通道。另外要注意所有的数据位置的下标都是从0开始。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-cd3a78a2ea0373045ac4cba71f8f2d24_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"135\" data-rawheight=\"310\" class=\"content_image\" width=\"135\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;135&#39; height=&#39;310&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"135\" data-rawheight=\"310\" class=\"content_image lazy\" width=\"135\" data-actualsrc=\"https://pic1.zhimg.com/v2-cd3a78a2ea0373045ac4cba71f8f2d24_b.jpg\"/></figure><p>下面我要把图示的元素改成8该怎么办呢？如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-75c7b6b77474b10652e7ba5cb5910c97_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"180\" data-rawheight=\"309\" class=\"content_image\" width=\"180\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;180&#39; height=&#39;309&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"180\" data-rawheight=\"309\" class=\"content_image lazy\" width=\"180\" data-actualsrc=\"https://pic4.zhimg.com/v2-75c7b6b77474b10652e7ba5cb5910c97_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7957d59676289ba00bf88855bd0e7a66_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-7957d59676289ba00bf88855bd0e7a66_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-7957d59676289ba00bf88855bd0e7a66_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-7957d59676289ba00bf88855bd0e7a66_b.jpg\"/></figure><p>通过上面的例子你是否理解了三维数组应该怎样存取数据了呢？理解了的话就打开vim多写写基本就能深刻的掌握了。</p><p><b>2.4 NumPy常见函数使用</b></p><p>现在我们已经学会了创建数组和数组的存取，那么我们该如何对数组进行函数运算呢，这也是NumPy的核心内容。</p><p><b>2.4.1 数组维度变换</b></p><p>我们首先说一下如何对数组的形状进行整理，即将一个任意形状的矩阵转化我们想要转化的任意形状，当然要想完成这个操作，元素个数必须要满足。请看下面实例：</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.arange(0,10,1)\nb = a.reshape(2,5)\n\nprint(a)\nprint(b)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-eaeff886fc68dd1b7ea70d4cedbc5a91_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"403\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-eaeff886fc68dd1b7ea70d4cedbc5a91_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;403&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"403\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-eaeff886fc68dd1b7ea70d4cedbc5a91_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-eaeff886fc68dd1b7ea70d4cedbc5a91_b.jpg\"/></figure><p>上面的实例通过reshape()函数把一个1维数组，变成了一个2行5列的一个数组。reshape()里面的参数就是你想要转换成的数组的形状。再看一个实例对reshape()熟练下，如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.arange(0,10,1)\nb = a.reshape(2,-1)\nc = a.reshape(-1,5)\nprint(a)\nprint(b)\nprint(c)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2e2f0e329d2edc15405bc850fb89f525_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"439\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-2e2f0e329d2edc15405bc850fb89f525_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;439&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"439\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-2e2f0e329d2edc15405bc850fb89f525_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2e2f0e329d2edc15405bc850fb89f525_b.jpg\"/></figure><p>b和c的结果是一样的，而且和上一个实例的结果也一样，这是为什么呢？其实这里面的-1代表自动生成的意思，意思就是对于b我已经指定了数组的行是2行，那么系统就会自动生成一个5列，因为是10个数，必须是5列，所以b和c仍然是2行5列的数组，这就是数组形状变换。</p><p>说完数组形状变换我们再看下如何对数组进行维度交换。请看下面实例：</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.arange(10).reshape(2,5)\nb = a.swapaxes(0,1)\nprint(a)\nprint(b)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-630bdf085cd25d5ae1301e0896e41d98_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"403\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-630bdf085cd25d5ae1301e0896e41d98_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;403&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"403\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-630bdf085cd25d5ae1301e0896e41d98_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-630bdf085cd25d5ae1301e0896e41d98_b.jpg\"/></figure><p>通过上面实例我们看出通过swapaxes()将一个数组的第0轴和第1轴进行了交换，由2行5列变成了5列2行。这是二维数组的维度交换，我们再看一个三维数组的例子，如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.arange(24).reshape(2,3,4)\nb = a.swapaxes(0,1)\nprint(a)\nprint(b)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-dc4e5918caca2fc71454f17789bc22a3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-dc4e5918caca2fc71454f17789bc22a3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-dc4e5918caca2fc71454f17789bc22a3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-dc4e5918caca2fc71454f17789bc22a3_b.jpg\"/></figure><p>这个实例我将三维数组的第0轴和第1轴进行了交换，第0轴就是我在上面2.3存取数组这一节中说的块，第1轴就是块中的行，下面我将我对三维数组维度交换的理解和大家分享下。</p><p>如下，我们首先将第一块第一行的[0,1,2,3]的位置记为(1,1)，第一块第二行的[4,5,6,7]的位置记为(1,2)，第二块第三行的[20,21,22,23]记为(2,3)，其它几个位置坐标类推。现在我们需要将第0轴和第1轴交换，所以第一块第一行的[0,1,2,3]的位置变为(1,1),就是第一块第一行；第一块第二行的[4,5,6,7]的位置变为为(2,1),就是第二块第一行；第二块第三行的[20,21,22,23]变为(3,2),就是第三块第二行。通过这样的理解你对上面实例输出的结果明白了吗？明白的话，请继续往下学如何对数组进行降维。</p><p>对于数组降维，我们继续通过实例来分析，如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.arange(10).reshape(2,5)\nb =np.flatten()\nc = a.reshape(-1)\nd = a.ravel()\nprint(a)\nprint(b)\nprint(c)\nprint(d)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4c784b7551c303982204feea7119738d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"530\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-4c784b7551c303982204feea7119738d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;530&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"530\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-4c784b7551c303982204feea7119738d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4c784b7551c303982204feea7119738d_b.jpg\"/></figure><p>可以看出我们通过reshape(-1)、flatten()和ravel()函数将多维很容易就变成了1维数组。</p><p><b>2.4.2 堆叠数组</b></p><p>我们再说一下数组的堆叠，这个也是经常会用的。数组的堆叠通常有水平叠加和垂直叠加，分别用到hstack()和vstack()函数，请看下面的实例：<br/></p><div class=\"highlight\"><pre><code class=\"language-text\">import numpy as np\na = np.array([1,2,3,4])\nb = np.array([5,6,7,8])\nc = np.hstack((a,b))\nd = np.vstack((a,b))\nprint(c)\nprint(d)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-1f302cd288c689a38ed31b7d97e7cefb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-1f302cd288c689a38ed31b7d97e7cefb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;416&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-1f302cd288c689a38ed31b7d97e7cefb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-1f302cd288c689a38ed31b7d97e7cefb_b.jpg\"/></figure><p>通过这个例子我们也看出通过hstack()和vstack()将数组a和b堆叠成了一个数组。</p><p>上面就是我对NumPy在深度学习中最常见的几点的介绍，其实还有许多，平时多多积累就行。</p><h2><b>03 数据可视化——matplotlib</b></h2><p>说完python我们再说说深度学习中用的比较多的matplotlib。matplotlib是python中最常用的可视化工具之一，用处非常大。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c171cafdc14c41e785b46e63c8577593_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"959\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb\" width=\"959\" data-original=\"https://pic4.zhimg.com/v2-c171cafdc14c41e785b46e63c8577593_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;959&#39; height=&#39;540&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"959\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"959\" data-original=\"https://pic4.zhimg.com/v2-c171cafdc14c41e785b46e63c8577593_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c171cafdc14c41e785b46e63c8577593_b.jpg\"/></figure><p><b>3.1 使用pyplot模块绘图</b><br/></p><p>我们先通过matplotlib和NumPy绘制一个图像。</p><div class=\"highlight\"><pre><code class=\"language-text\">import matplotlib.pyplot as plt\nimport numpy as np \nx= np.linspace(0,10,100) \ny=np.sin(x) \nplt.figure(figsize=(8,4))  \nplt.plot(x,y)  \nplt.show()   </code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-32e91205167487f30674fc1e2f220494_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"300\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-32e91205167487f30674fc1e2f220494_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;300&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"300\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-32e91205167487f30674fc1e2f220494_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-32e91205167487f30674fc1e2f220494_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-3207f467e620a8d9c38e7dc8c2fb9663_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"464\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic4.zhimg.com/v2-3207f467e620a8d9c38e7dc8c2fb9663_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;800&#39; height=&#39;464&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"464\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"800\" data-original=\"https://pic4.zhimg.com/v2-3207f467e620a8d9c38e7dc8c2fb9663_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-3207f467e620a8d9c38e7dc8c2fb9663_b.jpg\"/></figure><p>在这个实例中，我们首先通过import matplotlib的绘图块pyplot，并重新命名为plt。然后用figure调出一个画布,figsize参数指定画布的宽度和高度，单位是英寸（1英寸为25.4毫米）。创建好画布后，我们就可以用plot()在画布上画图了，plot()的前两个参数分别代表X，Y轴数据的对象。另外plot()参数还可以指定曲线的标签，颜色，线宽等。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>其实我们还能对坐标轴通过下面的方法进行一些参数的设置：</p><div class=\"highlight\"><pre><code class=\"language-text\">xlabel,ylabel：分别设置X，Y轴的标题文字\ntitle：设置标题\nxlim,ylim：分别设置X,Y轴的显示范围\nlegend:显示图例</code></pre></div><p>请看下面一个标准的图形：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-79c6defc94ae729908fc1749135bfa24_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"458\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-79c6defc94ae729908fc1749135bfa24_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;458&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"458\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-79c6defc94ae729908fc1749135bfa24_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-79c6defc94ae729908fc1749135bfa24_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-28d7c358e1c78f22cb5f8503605776a8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"464\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic1.zhimg.com/v2-28d7c358e1c78f22cb5f8503605776a8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;800&#39; height=&#39;464&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"464\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"800\" data-original=\"https://pic1.zhimg.com/v2-28d7c358e1c78f22cb5f8503605776a8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-28d7c358e1c78f22cb5f8503605776a8_b.jpg\"/></figure><p>接下来我们再看看如何画直方图，直方图在图像处理中经常会用到。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e65e959412456f84cf7825cf4cff0354_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"185\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-e65e959412456f84cf7825cf4cff0354_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;185&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"185\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-e65e959412456f84cf7825cf4cff0354_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e65e959412456f84cf7825cf4cff0354_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-fdfc2a0fdaf19af5129de47e0c4cbfeb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"544\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-fdfc2a0fdaf19af5129de47e0c4cbfeb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;544&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"544\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-fdfc2a0fdaf19af5129de47e0c4cbfeb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-fdfc2a0fdaf19af5129de47e0c4cbfeb_b.jpg\"/></figure><p>在用plt.hist()画直方图时，第一个参数是绘图数据，这是必须要有的；另外bins代表直方图的长条形数目，默认为10；normed表示是否将得到的直方图向量归一化，默认为0，代表不归一；facecolor代表长条形的颜色；edgecolor代表长条行边框的颜色；alpha代表透明度。</p><p><b>3.2 matlibplot读取图像</b></p><p>matplotlib的imread和imshow()提供了图像的读取和显示功能，另外imread()从图像文件中读入数据得到的是一个图像的NumPy数组。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b3844e604b937931d64c91cd614c3012_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"746\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-b3844e604b937931d64c91cd614c3012_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;746&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"746\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-b3844e604b937931d64c91cd614c3012_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b3844e604b937931d64c91cd614c3012_b.jpg\"/></figure><p>现在我们用matlibplot读取上面这一张可爱的猫图，方法如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import matplotlib.pyplot as plt\nimg = plt.imread(&#34;02.jpg&#34;)\nplt.imshow(img)\nplt.show()</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-3ffa8b6a393bcf15183071768ef037bc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-3ffa8b6a393bcf15183071768ef037bc_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-3ffa8b6a393bcf15183071768ef037bc_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-3ffa8b6a393bcf15183071768ef037bc_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b8f3439649570715f06d2d505e100cd5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"544\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-b8f3439649570715f06d2d505e100cd5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;544&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"544\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-b8f3439649570715f06d2d505e100cd5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b8f3439649570715f06d2d505e100cd5_b.jpg\"/></figure><p>可以看出，很容易就能读取一张图片。我们可以通过下面一些方法查看这张图片的属性。</p><div class=\"highlight\"><pre><code class=\"language-text\">print(img.shape)\nprint(img.dtype)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-55b408bbbc4e9013932f0bb240e37035_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-55b408bbbc4e9013932f0bb240e37035_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-55b408bbbc4e9013932f0bb240e37035_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-55b408bbbc4e9013932f0bb240e37035_b.jpg\"/></figure><p>我们再看看matplotlib读取的图像是不是NumPy数组，如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6745144273878ec660dd060acc5e18fd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-6745144273878ec660dd060acc5e18fd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic2.zhimg.com/v2-6745144273878ec660dd060acc5e18fd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6745144273878ec660dd060acc5e18fd_b.jpg\"/></figure><p>可以明显看到这是ndarray格式，总共三个通道，分别代表RGB。<br/></p><p><b>3.3 matplotlib工具栏</b></p><p>从上面的例子中就可以看到，当显示一张图片时，菜单栏自动生成了一些按钮，这些按钮都有各自的功能。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6b5a6c097cc45441efdabe6f227a442d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"245\" data-rawheight=\"41\" class=\"content_image\" width=\"245\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;245&#39; height=&#39;41&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"245\" data-rawheight=\"41\" class=\"content_image lazy\" width=\"245\" data-actualsrc=\"https://pic2.zhimg.com/v2-6b5a6c097cc45441efdabe6f227a442d_b.jpg\"/></figure><p><b>3.3.1 前进后退按钮</b></p><p>这三个按钮就像是我们使用的浏览器中的主页和前进后退按钮一样，一开始这三个图是没有什么用的，因为它本来就处于主页，既不能前进也不能后退，当你使用平移和缩放功能后，每一次操作就相当于在浏览器中点开了一个网页一样，这时候你就可以使用前进后退和回到最开始状态的按钮了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-161decbaf0b9da3086ed75fd350c0db2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"91\" data-rawheight=\"44\" class=\"content_image\" width=\"91\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;91&#39; height=&#39;44&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"91\" data-rawheight=\"44\" class=\"content_image lazy\" width=\"91\" data-actualsrc=\"https://pic3.zhimg.com/v2-161decbaf0b9da3086ed75fd350c0db2_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>3.3.2 平移缩放按钮</b></p><p>这个按钮也比较简单，按住鼠标左键在图片区域左右移动可以实现图像的左右平移，上下移动就可以使图像上下平移，按住X或者Y键移动即只能在X或者Y方向上平移。同理按住鼠标右键就是缩放。如果按住Ctrl键再进行上述操作，则是XY轴成比例平移或缩放。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-046b6972c7772bbedd0b8cb933f04505_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"34\" data-rawheight=\"46\" class=\"content_image\" width=\"34\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;34&#39; height=&#39;46&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"34\" data-rawheight=\"46\" class=\"content_image lazy\" width=\"34\" data-actualsrc=\"https://pic2.zhimg.com/v2-046b6972c7772bbedd0b8cb933f04505_b.jpg\"/></figure><p><b>3.3.3 缩放到指定矩形按钮</b></p><p>按住鼠标左键或者右键，选定一个矩形区域，即可将图形放大或者缩小到制定的矩形区域中。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8e97ddab475ba6250fb650469bac2266_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"29\" data-rawheight=\"37\" class=\"content_image\" width=\"29\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;29&#39; height=&#39;37&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"29\" data-rawheight=\"37\" class=\"content_image lazy\" width=\"29\" data-actualsrc=\"https://pic3.zhimg.com/v2-8e97ddab475ba6250fb650469bac2266_b.jpg\"/></figure><p>在放大局部细节图时经常使用。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-02ef0e9abccdf3f1aaa530a9209fc976_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-02ef0e9abccdf3f1aaa530a9209fc976_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-02ef0e9abccdf3f1aaa530a9209fc976_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-02ef0e9abccdf3f1aaa530a9209fc976_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-0b7be8e94df95b7c704a56abd2db5620_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-0b7be8e94df95b7c704a56abd2db5620_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-0b7be8e94df95b7c704a56abd2db5620_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-0b7be8e94df95b7c704a56abd2db5620_b.jpg\"/></figure><p><b>3.3.4 设置子图参数按钮</b></p><p>点击该按钮可以设置子绘图区域的长度和宽度，还可以设置各个子图之间的距离。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-607ff968e01a88fdbd39e63aab5a0c6c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"33\" data-rawheight=\"39\" class=\"content_image\" width=\"33\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;33&#39; height=&#39;39&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"33\" data-rawheight=\"39\" class=\"content_image lazy\" width=\"33\" data-actualsrc=\"https://pic1.zhimg.com/v2-607ff968e01a88fdbd39e63aab5a0c6c_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>3.3.5 保存按钮</b></p><p>该按钮可以将图像保存为png、pdf等格式。</p><p>matplotlib的一些基础知识就介绍到这里，大家一定要多加实践，这样才能更好的掌握。</p><h2><b>04 必备的python库</b></h2><p>要想深度学习学的好，必须非常好的掌握python各种库，这是进行深度学习的基础。下面我和大家分享下一些常用的库，其实上面我已经介绍了两个了那就是NumPy和matplotlib，还有一些其他的库，请继续往下看。</p><p><b>4.1 科学计算与数据处理库</b></p><p>说到科学计算和数据处理，我们可能马上就会想到NumPy但其实还有两个其他的库，那就是SciPy和Pandas。</p><p>Scipy在Numpy的基础上增加了众多的数学计算、科学计算及工程计算中常用的模块，例如线性代数、图像处理等。在Scipy中的ndimage子模块就是致力于进行图像处理的。</p><p>Pandas是基于NumPy开发，提供了众多更高级的数据处理工能。Pandas中包含许多用于分组，过滤和组合数据的内置方法，以及时间序列功能。</p><p>有机会我们再说说这两个库。</p><p><b>4.2 深度学习框架</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-505ea3a0591a9df69c648611ea0a0aaf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"484\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-505ea3a0591a9df69c648611ea0a0aaf_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;484&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"484\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-505ea3a0591a9df69c648611ea0a0aaf_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-505ea3a0591a9df69c648611ea0a0aaf_b.jpg\"/></figure><p>目前深度学习框架已经呈百家争鸣之态势，有Caffe、TensorFlow、Pytorch、Keras等等，对于我们来说，不可能都能掌握，但市面上主流的框架我们还是必须要熟练的掌握。</p><p><b>这些深度学习框架，我们在公众号的往期文章已经说过大半，大家可以自行翻阅。</b></p><p><b>4.3 服务端Flask</b></p><p>Flask是一个微型的服务端框架，它旨在保持核心的简单，但同时又易于扩展。默认情况下，Flask不包含数据库抽象层、表单验证，或是其他任何已有多种库可以胜任的功能。然而，Flask 支持用扩展来给应用添加这些功能。众多的扩展提供了数据库集成、表单验证、上传处理、各种各样的开放认证技术等功能。Flask 的这些特性，使得它在 Web 开发方面变得非常流行。</p><p><b>4.4 前端urilib等</b></p><p>urllib是Python自带的标准库，无需安装，直接可以用。提供了如下功能：网页请求、响应获取、代理和cookie设置、异常处理和URL解析，主要用于前端爬虫，对于获取和整理数据是必备的。</p><p><b>前后端的这些框架，我们在公众号的往期文章都已经说过，大家可以自行翻阅。</b></p><h2><b>总结</b></h2><p>AI白身境第三讲结束了，但学习的路永无止境，python、NumPy、matplotlib、深度学习框架的知识还有很多，需要我们不断的学习。期待我们的下期吧。</p><p><i>下期预告：下一期我们会讲图像基础，如果你有建议，欢迎留言，我们会及时采纳的。</i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "Python", 
                    "tagLink": "https://api.zhihu.com/topics/19552832"
                }, 
                {
                    "tag": "AI教程", 
                    "tagLink": "https://api.zhihu.com/topics/20182941"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/54143638", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 31, 
            "title": "【AI白身境】Linux干活三板斧，shell、vim和git", 
            "content": "<p>首发于《有三AI》</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a><p>今天是专栏<b>《AI白身境》</b>的第二篇，所谓白身，就是什么都不会，还没有进入角色。</p><p>上一篇给大家介绍了要想真正进入深度学习这个行业，必须要先学会使用Linux，今天就和大家说说我们应该如何使用Linux，如何利用shell，vim和git这三大神器。</p><p>                                                                                                                         作者 | 汤兴旺 言有三<br/>                                                                                                                         编辑 | 言有三</p><blockquote><b>01 Linux基础命令与shell脚本</b></blockquote><p>通过第一篇的介绍，我们已经知道在Linux下面操作会比windows下效率高很多，下面和大家讲解一下Linux的基础操作，默认大家已经装好了Linux系统。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.1 cd命令</code></pre></div><p>命令格式：cd &lt;路径&gt;</p><p>意义：cd是change directory 的缩写；cd命令后面跟一个路径，用于切换当前用户所在的路径，其中路径可以是绝对路径也可以是相对路径。</p><p>示例：</p><p>cd /system/bin 表示切换到/system/bin路径下。</p><p>cd logs 表示切换到logs路径下。</p><p>cd / 表示切换到根目录。</p><p>cd ../ 表示切换到上一层路径。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.2 ls命令</code></pre></div><p>命令格式：ls &lt;参数&gt; &lt;路径&gt;</p><p>意义：ls是list的缩写；ls命令后面可以跟一个路径或参数，也可以不跟，表示列出路径或当前目录下的所有文件信息。最常用的的参数是“-l&#34;，也就是“ls -l”命令。</p><p>示例：</p><p>ls / 显示根目录下的所有文件及文件夹。</p><p>ls -l /data 显示/data路径下的所有文件及文件夹的详细信息。</p><p>ls -l 显示当前路径下的所有文件及文件夹的详细信息</p><p>ls *l wc显示当前目录下面的文件数量。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.3 cat命令</code></pre></div><p>命令格式： cat &lt;文件&gt;</p><p>意义：cat是concatenate 的缩写。表示读取文件内容及拼接文件。</p><p>示例：</p><p>cat /sys/devices/system/cpu/online 读取 /sys/devices/system/cpu/路径下online文件内容。</p><p>cat test.txt 读取当前路径下test.txt文件内容。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.4 rm命令</code></pre></div><p>命令格式： rm &lt;文件&gt; 或 rm -r &lt;文件夹&gt;</p><p>意义：rm是remove 的缩写。用于删除文件或文件夹，常用参数-r -f，-r表示删除目录，也可以用于删除文件，-f表示强制删除，不需要确认。同样的，删除文件前需保证当前用户对当前路径有修改的权限。</p><p>示例：</p><p>rm -rf path 删除path。</p><p>rm test.txt 删除test.txt。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.5 mkdir命令</code></pre></div><p>命令格式： mkdir 文件夹</p><p>意义：mkdir是make directory 的缩写。用于创建文件夹。创建文件夹前需保证当前用户对当前路径有修改的权限。</p><p>示例：</p><p>mkdir /data/path 在/data路径下创建path文件夹。</p><p>mkdir -p a/b/c 参数 -p用于创建多级文件夹，这句命令表示在当前路径下创建文件夹a， 而a文件夹包含子文件夹b，b文件夹下又包含子文件夹c。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.6 cp命令</code></pre></div><p>命令格式： cp &lt;文件&gt;&lt;目标文件&gt;或者cp -r&lt;文件夹&gt;&lt;目标文件夹&gt;</p><p>意义：cp是copy 的缩写。用于复制文件或文件夹。</p><p>示例：</p><p>cp /data/logs /data/local/tmp/logs 复制/data路径下的logs到/data/local/tmp路径下。</p><p>cp 1.sh /sdcard/ 复制当前路径下的1.sh到/sdcard下。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.7 kill命令</code></pre></div><p>命令格式：kill PID码</p><p>意义：结束当前进程<br/></p><p>示例：</p><p>先通过输入命令 ps au查看进程，找到需要终止进程的PID再通过kill PID即可，如我这里想要终止的进程是vim test.py，查到的PID是3163，我们可以输入kill 3163结束这个程序，如果结束不了，可以通过kill -9 PID码强制结束，即kii -9 3163</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-31b712cf5f8f50ee26977696535e7638_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"636\" data-rawheight=\"431\" class=\"origin_image zh-lightbox-thumb\" width=\"636\" data-original=\"https://pic1.zhimg.com/v2-31b712cf5f8f50ee26977696535e7638_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;636&#39; height=&#39;431&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"636\" data-rawheight=\"431\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"636\" data-original=\"https://pic1.zhimg.com/v2-31b712cf5f8f50ee26977696535e7638_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-31b712cf5f8f50ee26977696535e7638_b.jpg\"/></figure><p>除了这七个命令，还有许多常见的命令，如pwd命令，这个可以查看当前路径，这个在移动数据集或者整理文件list的时候很有用；tar命令，这个可以文件压缩；unzip命令，这个可以用于文件解压，这样的命令其实还有很多，需要我们在使用的过程中不断熟练，需要我们不停的查阅学习。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.8 shell脚本文件之&#34;hello world&#34;</code></pre></div><p>有了基本的命令之后，接下来就可以写一些常用的脚本。脚本常用于获取参数，循环遍历。</p><p>首先我们看一个“hello world”。</p><p>#!/bin/sh<br/>a=&#34;hello world!&#34;</p><p>num=2</p><p>echo &#34;a is : $a num is : ${num}nd&#34;<br/></p><p>运行结果：</p><p>a is : hello world! num is : 2nd</p><p>可以看出，用$来获取变量值，通常运行脚本的时候，可以用$1，$2，$3等获取多个参数。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>比如脚本test.sh</p><p>x=$1</p><p>y=$2</p><p>z=$3</p><p>echo $1 $2 $3</p><p>调用的时候就可以：sh test.sh 1 2 3</p><div class=\"highlight\"><pre><code class=\"language-text\">1.9 shell脚本文件之遍历目录</code></pre></div><p>问题：</p><p>1. 切换工作目录至/tmp</p><p>2. 依次向/tmp目录中的每个文件或子目录问好（Hello,log）</p><p>3. 统计/tmp目录下共有多个文件，并显示出来</p><p>#!/bin/bash</p><p>cd /tmp</p><p>for i in /tmp/*</p><p>do</p><p>    echo &#34;Hello , $i&#34;</p><p>done</p><p>count=`ls -l|grep &#39;^-&#39;|wc -l`</p><p>echo &#34;====file_count:$count====&#34;</p><p>运行结果：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1bfc3273f64df132e91cb5def2ca307c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-1bfc3273f64df132e91cb5def2ca307c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-1bfc3273f64df132e91cb5def2ca307c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-1bfc3273f64df132e91cb5def2ca307c_b.jpg\"/></figure><p>shell命令还有很多高级用法，大家在实战中进行练习提高吧。</p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote><b>02 github</b></blockquote><p>github是全球最大的程序员交友平台，所以如果你要想从事技术行业，就必须拥有一个账号，跟微信一样离不开你的生活。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.1 注册github                            </code></pre></div><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/</span><span class=\"invisible\"></span></a>这个是github官方网站，我们可以在官网上注册属于自己的gitHub账号。点击网址后，界面如下图，由于我们没有github账户， 我们需要点击Sign up for  Github进行简单的注册。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-adf50cc53a0f412475a421f31a94dbfa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-adf50cc53a0f412475a421f31a94dbfa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-adf50cc53a0f412475a421f31a94dbfa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-adf50cc53a0f412475a421f31a94dbfa_b.jpg\"/></figure><p>点击Sign up for Github后，进入下方这个界面，在Step1中填写好个人信息，Step2-3全部采用默认设置，即可完成github注册，记得要去自己的邮箱verify，不然后面没办法创建仓库。是不是很简单。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5baed61361b0cad8668c00630da95eec_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"491\" class=\"origin_image zh-lightbox-thumb\" width=\"619\" data-original=\"https://pic1.zhimg.com/v2-5baed61361b0cad8668c00630da95eec_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;619&#39; height=&#39;491&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"491\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"619\" data-original=\"https://pic1.zhimg.com/v2-5baed61361b0cad8668c00630da95eec_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5baed61361b0cad8668c00630da95eec_b.jpg\"/></figure><p>完成上面的步骤后你就拥有了自己的github账户，下图就是我的github主页。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9afb746155b88b762b0384a62a888f14_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"390\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-9afb746155b88b762b0384a62a888f14_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;390&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"390\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-9afb746155b88b762b0384a62a888f14_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-9afb746155b88b762b0384a62a888f14_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">2.2 创建仓库</code></pre></div><p>有了上面的主页后，我们点击start a project后就可以创建仓库了，下图就是仓库需要填写一些信息的界面。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0aeaefcee29a8412f95eac91b9555947_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"767\" data-rawheight=\"502\" class=\"origin_image zh-lightbox-thumb\" width=\"767\" data-original=\"https://pic4.zhimg.com/v2-0aeaefcee29a8412f95eac91b9555947_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;767&#39; height=&#39;502&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"767\" data-rawheight=\"502\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"767\" data-original=\"https://pic4.zhimg.com/v2-0aeaefcee29a8412f95eac91b9555947_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0aeaefcee29a8412f95eac91b9555947_b.jpg\"/></figure><p>仓库名通常就填写我们的项目名，为了说明，这里我填写my_github，描述可以对自己的仓库进行一个简单的说明，也可以不填。点击“Create repository”按钮，就成功地创建了一个新的github仓库，如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-604c9fc66d8bea286b822efacf74d292_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1060\" data-rawheight=\"496\" class=\"origin_image zh-lightbox-thumb\" width=\"1060\" data-original=\"https://pic3.zhimg.com/v2-604c9fc66d8bea286b822efacf74d292_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1060&#39; height=&#39;496&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1060\" data-rawheight=\"496\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1060\" data-original=\"https://pic3.zhimg.com/v2-604c9fc66d8bea286b822efacf74d292_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-604c9fc66d8bea286b822efacf74d292_b.jpg\"/></figure><p>现在我们就有了自己的github和仓库，为了便于管理，我们需要安装一个软件git。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.3 安装git</code></pre></div><p>下面我将说一下在ubuntu18.04上安装git，其他的linux系统其实也是一样的，安装方法很简单，输入下面命令即可安装。</p><p>sudo apt install git</p><p>安装完成后，你可以用下面命令查看git版本。</p><p> git --version</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-6b8d7960c5fe0ccba932dd0950a06fc7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-6b8d7960c5fe0ccba932dd0950a06fc7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-6b8d7960c5fe0ccba932dd0950a06fc7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-6b8d7960c5fe0ccba932dd0950a06fc7_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">2.4 配置参数</code></pre></div><p>接下来你需要做的就是在git中配置自己的名称和电子邮件地址，可以通过使用以下命令来完成此操作：</p><p>$git config --global user.name &#34;your name&#34;<br/>$git config --global user.email  &#34;your email&#34;</p><p>我们可以通过下面命令查看是否正确配置。</p><p>git config --list</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-57171365d6a1bd62731d0d91349666e4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-57171365d6a1bd62731d0d91349666e4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-57171365d6a1bd62731d0d91349666e4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-57171365d6a1bd62731d0d91349666e4_b.jpg\"/></figure><p>这还没有完，我们还需要创建一个ssh key，这个实际上就是一个将你的电脑和github账号联系在一起的密钥，这样以后就可以十分方便的通过git上传你的代码。下面介绍一下如何获得这个密钥，又是如何输入到你的Github中。</p><p>获取密钥的方法如下：</p><p>首先在命令行输入cd  ~/.ssh，第一次配置会显示没有那个文件或目录，这是正常现象。然后在命令行输入ssh-keygen -t rsa -C &#34;邮箱地址&#34;，接下来连按三次回车就可以了。</p><p>命令行代码如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-df1ca62658df65c7afbe0041cd91c57f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-df1ca62658df65c7afbe0041cd91c57f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-df1ca62658df65c7afbe0041cd91c57f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-df1ca62658df65c7afbe0041cd91c57f_b.jpg\"/></figure><p>这样我们的密钥就创建成功了。</p><p>然后打开/home/tangxingwang/.ssh/id_rsa文件夹下id_rsa.pub文件，复制里面的内容，打开之后不要惊讶，这就是你需要的密钥。你需要登录你的github来添加这个密钥，登录github后找到SSH and GPG keys这个选项（在setting里面），然后点击网页右上角的New SSH keys进行添加。具体细节如下图:<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-029012f651b74c50e9ae3a5bf2b43eb3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"497\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-029012f651b74c50e9ae3a5bf2b43eb3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;497&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"497\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-029012f651b74c50e9ae3a5bf2b43eb3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-029012f651b74c50e9ae3a5bf2b43eb3_b.jpg\"/></figure><p>点击New SSH keys后界面如下图所示，这里的Title是让你给你的密钥起一个名字，随便起一个就行，然后把你刚刚复制的密钥填写在下边的大框里，点击Add SSH keys即可。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8a3cfe35b581a750699a73e88c48bd42_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"451\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8a3cfe35b581a750699a73e88c48bd42_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;451&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"451\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8a3cfe35b581a750699a73e88c48bd42_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8a3cfe35b581a750699a73e88c48bd42_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">2.5 clone操作</code></pre></div><p>当我们想要从github上面拉取代码时，就需要使用clone操作，现在我们看看怎么进行clone，其实很简单，只需要输入 git clone&lt;需要clone的地址&gt;，示例如下：</p><p>git clone git@github.com:tangxingwang/my_github.git</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-bb7fb4590c7ae38a5bd052ff8bc8b8f6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-bb7fb4590c7ae38a5bd052ff8bc8b8f6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic3.zhimg.com/v2-bb7fb4590c7ae38a5bd052ff8bc8b8f6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-bb7fb4590c7ae38a5bd052ff8bc8b8f6_b.jpg\"/></figure><p>这样就clone成功了，是不是很简单。</p><p>有的时候我们需要拉取依赖库，就需要加上--recursive选项。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.6 push操作</code></pre></div><p>说完clone，我们再讲讲push，现在我想在刚刚clone下的文件夹my_github里面添加一个新的文件test.py，然后把它push到github中。命令如下：</p><p>cd my_github  </p><p>touch test.py</p><p>git add <a href=\"https://link.zhihu.com/?target=http%3A//test.py/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">test.py</a></p><p>git status</p><p>git commit -m&#34;first commit&#34;</p><p>git push origin master</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-9ca645584bc05387ebf2be97652a75c3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-9ca645584bc05387ebf2be97652a75c3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic4.zhimg.com/v2-9ca645584bc05387ebf2be97652a75c3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-9ca645584bc05387ebf2be97652a75c3_b.jpg\"/></figure><p>这样我们就push成功了，我们再看看github</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b95bb991c22975258f7612ac0f5530b6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"781\" data-rawheight=\"368\" class=\"origin_image zh-lightbox-thumb\" width=\"781\" data-original=\"https://pic3.zhimg.com/v2-b95bb991c22975258f7612ac0f5530b6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;781&#39; height=&#39;368&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"781\" data-rawheight=\"368\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"781\" data-original=\"https://pic3.zhimg.com/v2-b95bb991c22975258f7612ac0f5530b6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b95bb991c22975258f7612ac0f5530b6_b.jpg\"/></figure><blockquote><b>03 VIM基本操作</b></blockquote><p>最后我们说说编辑器之神vim。vim是从vi发展出来的一个文本编辑器，其在代码补全、编译等方便的功能特别丰富，在程序员中被广泛使用。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c212db7e161d33b136897cda96a90915_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"490\" data-rawheight=\"490\" class=\"origin_image zh-lightbox-thumb\" width=\"490\" data-original=\"https://pic2.zhimg.com/v2-c212db7e161d33b136897cda96a90915_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;490&#39; height=&#39;490&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"490\" data-rawheight=\"490\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"490\" data-original=\"https://pic2.zhimg.com/v2-c212db7e161d33b136897cda96a90915_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c212db7e161d33b136897cda96a90915_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">3.1 基本命令模式</code></pre></div><p>用户刚刚启动 vi/vim，便进入了命令模式。</p><p>此状态下敲击键盘动作会被vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。</p><p>以下是常用的几个命令：</p><ul><li>i 切换到输入模式，以输入字符。</li><li>x 删除当前光标所在处的字符。</li><li>: 切换到底线命令模式，以在最底一行输入命令</li></ul><div class=\"highlight\"><pre><code class=\"language-text\">3.2 输入模式</code></pre></div><p>在输入模式下可以对文件执行写操作，类似在Windows 的文档中输入内容。进入输入模式的方法是输入<b>i、a、o</b> 等插入命令，编写完成后按 Esc 键即可返回基本命令模式。</p><div class=\"highlight\"><pre><code class=\"language-text\">3.3 底线命令模式</code></pre></div><p>如果要保存、查找或者替换一些内容等，就需要进入底线命令模式。</p><p>底线命令模式的进入方法为：在基本命令模式下<b>按&#34;:&#34;键</b>，vim 窗口的左下方会出现一个&#34;:&#34;符号，这时就可以输入相关的指令进行操作了。</p><p>对于新手来说，经常不知道自己处于什么模式，不论是自己忘了，还是不小心切换了模式，都可以按一次 Esc 键返回基本命令模式。如果你多按几次 Esc 键后听到&#34;嘀————&#34;的声音，则代表你已经处于基本命令模式了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e8ff81affb5b267615ec526324e677c9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"787\" data-rawheight=\"531\" class=\"origin_image zh-lightbox-thumb\" width=\"787\" data-original=\"https://pic2.zhimg.com/v2-e8ff81affb5b267615ec526324e677c9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;787&#39; height=&#39;531&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"787\" data-rawheight=\"531\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"787\" data-original=\"https://pic2.zhimg.com/v2-e8ff81affb5b267615ec526324e677c9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e8ff81affb5b267615ec526324e677c9_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">3.4 vim使用实例</code></pre></div><p>现在我们使用 vim 来建立一个名为 test.py 的文件，你可以这样做：vi test.py，这样就就入了基本命令模式了</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-120b06e1522713dc1c0f73e074250281_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"736\" data-rawheight=\"497\" class=\"origin_image zh-lightbox-thumb\" width=\"736\" data-original=\"https://pic2.zhimg.com/v2-120b06e1522713dc1c0f73e074250281_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;736&#39; height=&#39;497&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"736\" data-rawheight=\"497\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"736\" data-original=\"https://pic2.zhimg.com/v2-120b06e1522713dc1c0f73e074250281_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-120b06e1522713dc1c0f73e074250281_b.jpg\"/></figure><p>按下 i 进入输入模式，开始编辑文字，其实在基本命令模式下，只要按下 i, o, a 等字符就可以进入输入模式了！但各自的功能不同。</p><p>其中i是光标前插入，a是光标后插入，o是换行。另外在输入模式当中，你可以发现在左下角状态栏中会出现 –插入- 的字样，那就是可以输入任意字符的提示。这个时候，键盘上除了 Esc 这个按键之外，其他的按键都可以视作为一般的输入按钮了，所以你可以进行任何的编辑。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-6fdf83f7fc9ac4b1a25acd72c40c592f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"727\" data-rawheight=\"492\" class=\"origin_image zh-lightbox-thumb\" width=\"727\" data-original=\"https://pic4.zhimg.com/v2-6fdf83f7fc9ac4b1a25acd72c40c592f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;727&#39; height=&#39;492&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"727\" data-rawheight=\"492\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"727\" data-original=\"https://pic4.zhimg.com/v2-6fdf83f7fc9ac4b1a25acd72c40c592f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-6fdf83f7fc9ac4b1a25acd72c40c592f_b.jpg\"/></figure><p>那么假设我已经按照下面的样式给它编辑完毕了，应该要如何退出呢？其实很简单，就是给它按下Esc这个按钮即可！马上你就会发现画面左下角的 –插入 – 不见了！</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-212db546854c3b672057382bc01ca100_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"731\" data-rawheight=\"490\" class=\"origin_image zh-lightbox-thumb\" width=\"731\" data-original=\"https://pic1.zhimg.com/v2-212db546854c3b672057382bc01ca100_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;731&#39; height=&#39;490&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"731\" data-rawheight=\"490\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"731\" data-original=\"https://pic1.zhimg.com/v2-212db546854c3b672057382bc01ca100_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-212db546854c3b672057382bc01ca100_b.jpg\"/></figure><p>对文件编辑完后，我们需要对文件进行保存，其实存盘并离开的指令很简单，在基本命令模式下输入<b> :wq </b>即可保存离开！</p><p><b>或者按住shift，连续按两次大写的ZZ。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7021b16c094a0e348029eb2af2929549_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"724\" data-rawheight=\"490\" class=\"origin_image zh-lightbox-thumb\" width=\"724\" data-original=\"https://pic2.zhimg.com/v2-7021b16c094a0e348029eb2af2929549_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;724&#39; height=&#39;490&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"724\" data-rawheight=\"490\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"724\" data-original=\"https://pic2.zhimg.com/v2-7021b16c094a0e348029eb2af2929549_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7021b16c094a0e348029eb2af2929549_b.jpg\"/></figure><p>OK! 这样我们就成功创建了一个test.py文件</p><div class=\"highlight\"><pre><code class=\"language-text\">3.5 vim按键说明</code></pre></div><p>除了上面简易范例的 i, o,a，Esc, :wq 之外，其实 vim 还有非常多的按键可以使用</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-66798d0ac7cf5427f1410cef10f7f691_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"796\" data-rawheight=\"260\" class=\"origin_image zh-lightbox-thumb\" width=\"796\" data-original=\"https://pic2.zhimg.com/v2-66798d0ac7cf5427f1410cef10f7f691_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;796&#39; height=&#39;260&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"796\" data-rawheight=\"260\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"796\" data-original=\"https://pic2.zhimg.com/v2-66798d0ac7cf5427f1410cef10f7f691_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-66798d0ac7cf5427f1410cef10f7f691_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-9c87e8092a794a4ea69653f9edf52855_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"791\" data-rawheight=\"298\" class=\"origin_image zh-lightbox-thumb\" width=\"791\" data-original=\"https://pic2.zhimg.com/v2-9c87e8092a794a4ea69653f9edf52855_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;791&#39; height=&#39;298&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"791\" data-rawheight=\"298\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"791\" data-original=\"https://pic2.zhimg.com/v2-9c87e8092a794a4ea69653f9edf52855_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-9c87e8092a794a4ea69653f9edf52855_b.jpg\"/></figure><p>这些基本命令需要我们在使用过程中不断的总结，这样才会融会贯通。附上一张vim的键盘图，哈哈。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-038c877b2cd4ae877c0322c9e1932300_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"724\" class=\"origin_image zh-lightbox-thumb\" width=\"1024\" data-original=\"https://pic1.zhimg.com/v2-038c877b2cd4ae877c0322c9e1932300_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1024&#39; height=&#39;724&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"724\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1024\" data-original=\"https://pic1.zhimg.com/v2-038c877b2cd4ae877c0322c9e1932300_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-038c877b2cd4ae877c0322c9e1932300_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">3.6 vim插件攻略</code></pre></div><p>工欲善其事，必先利其器。一个强大的开发环境可以大大提高工作效率。好吧，我知道这是废话。。。不过，我想一定有很多跟我一样打算进入Linux平台开发的新手，一开始都为找不到一个像Windows下的VS那样可以一键安装并且功能几乎完美无缺的开发工具而郁闷不已，甚至打算收回刚刚迈出的脚步。所幸的是，Vim有许多强大的插件。</p><div class=\"highlight\"><pre><code class=\"language-text\">3.6.1 vim插件之Vundle</code></pre></div><p>vim 通过插件可以被拓展出不同层次的功能。通常，所有的插件和附属的配置文件都会存放在 <b>~/.vim</b>目录中。由于所有的插件文件都被存储在同一个目录下，所以当你安装更多插件时，不同的插件文件之间相互混淆。因而，跟踪和管理它们将是一个恐怖的任务。然而，这正是 Vundle 所能处理的。</p><p>Vundle，分别是 vim 和 Bundle 的缩写，它是一款能够管理 vim 插件的非常实用的工具。它为每一个你安装的插件创建一个独立的目录树，并在相应的插件目录中存储附加的配置文件。因此，相互之间没有混淆的文件。简言之，Vundle 允许你安装新的插件、配置已有的插件、更新插件配置、搜索安装的插件和清理不使用的插件。所有的操作都可以在一键交互模式下完成</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f3e50a7d2bf81b737ce63bdafd149258_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-f3e50a7d2bf81b737ce63bdafd149258_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;734&#39; height=&#39;494&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"734\" data-rawheight=\"494\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"734\" data-original=\"https://pic1.zhimg.com/v2-f3e50a7d2bf81b737ce63bdafd149258_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-f3e50a7d2bf81b737ce63bdafd149258_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">3.6.2 Vim插件之YouCompleteMe</code></pre></div><p>使用Vim编写程序少不了使用自动补全插件。这时候当然少不了YouCompleteMe，它是一个随键而全的、支持模糊搜索的、高速补全的插件。YCM 由 google 公司搜索项目组的软件工程师 Strahinja Val Markovic 所开发，YCM 后端调用 libclang(以获取AST,当然还有其他语言的语义分析库)、前端由 C++ 开发(以提升补全效 率)、外层由 python 封装,这就是最好用的自动补全插件。vim插件还有很多，大家可以根据自己的需要进行安装。</p><p>当我们真正熟悉使用了上面的3类工具之后，就从Linux菜鸟开始进步了。</p><p>你现在对shell，vim，git是不是有点感觉了，抓紧学习，也要期待我们下一篇的内容哟。</p><p><i>下期预告：下一期我们会讲python的常用基础，如果你有建议，欢迎留言，我们会及时采纳的。</i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "shell 脚本", 
                    "tagLink": "https://api.zhihu.com/topics/19617864"
                }, 
                {
                    "tag": "Vim", 
                    "tagLink": "https://api.zhihu.com/topics/19570193"
                }, 
                {
                    "tag": "GitHub", 
                    "tagLink": "https://api.zhihu.com/topics/19566035"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/53976970", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 12, 
            "title": "【AI白身境】深度学习从弃用windows开始", 
            "content": "<p>首发于微信公众号《有三AI》</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D420860541%26lang%3Dzh_CN%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a><p>今天是新专栏<b>《AI白身境》</b>的第一篇，所谓白身，就是什么都不会，还没有进入角色。</p><p>给大家准备了10期左右的文章来完成这个身份的转变，今天是第一篇，关于开发环境的选择(另外，接受粉丝们的意见，暂时以<b>三天一篇</b>的频率更新)。</p><p>要想正式进入AI行业发展，离不开称手的软硬件兵器，其中操作系统就是“软”兵器，本文给大家的建议是<b>彻底放弃Windows，只用Linux与Mac</b>。</p><blockquote>1 <b>windows写代码不如linux</b></blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c35d6cb9556c20bfa1d99def977a7543_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c35d6cb9556c20bfa1d99def977a7543_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c35d6cb9556c20bfa1d99def977a7543_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c35d6cb9556c20bfa1d99def977a7543_b.jpg\"/></figure><p>很多人会说，Windows不适合写代码？各种各样类似于visual studio的IDE那么牛逼，还不适合写代码？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4f689199219a83b2b5715eb42c900036_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"581\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-4f689199219a83b2b5715eb42c900036_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;581&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"581\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-4f689199219a83b2b5715eb42c900036_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4f689199219a83b2b5715eb42c900036_b.jpg\"/></figure><p>莫急，且听我说几个理由。</p><p>当今<b>大部分程序员</b>，开始一个任务时的流程是什么？我想应该是这样的！</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-19fd4cfd454dd4df974a82cf0fff386f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"197\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-19fd4cfd454dd4df974a82cf0fff386f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;197&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"197\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-19fd4cfd454dd4df974a82cf0fff386f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-19fd4cfd454dd4df974a82cf0fff386f_b.jpg\"/></figure><p>我们看看上面这些操作都要干什么。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.1 github找代码</code></pre></div><p>最常用的操作包括git clone，git push，git pull等，这些在命令行下操作是最简洁优雅的，如果你说每次从github上面下载代码采用的是download模式，如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-086fb42063262ebf7d58ec5dbc4fd6bf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"708\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb\" width=\"708\" data-original=\"https://pic4.zhimg.com/v2-086fb42063262ebf7d58ec5dbc4fd6bf_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;708&#39; height=&#39;369&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"708\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"708\" data-original=\"https://pic4.zhimg.com/v2-086fb42063262ebf7d58ec5dbc4fd6bf_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-086fb42063262ebf7d58ec5dbc4fd6bf_b.jpg\"/></figure><p>那么少年，下次我们说github的时候好好看看，这样做有多么外行。一句话，windows不合适。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.2 配置所需环境</code></pre></div><p>几乎没有一个开源项目是能够下下来直接就能用的，尤其是你的电脑还处于初段水平的时候，<b>配置环境是新手们的大敌</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-58d76bfe220e3edbe0fc11216c26919a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"246\" data-rawheight=\"240\" class=\"content_image\" width=\"246\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;246&#39; height=&#39;240&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"246\" data-rawheight=\"240\" class=\"content_image lazy\" width=\"246\" data-actualsrc=\"https://pic3.zhimg.com/v2-58d76bfe220e3edbe0fc11216c26919a_b.jpg\"/></figure><p>在<b>windows中要装一个新的软件包真的好麻烦</b>（要自己找软件，看版本，下载安装，配置环境变量），版本控制和更新更麻烦（就是把前面的操作重来一遍嘛），给python装各种依赖库好麻烦（想都不敢想），反正就是<b>很麻烦，巨麻烦，超级麻烦</b>。而Linux，通常就是一条命令。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.3 开发，迭代</code></pre></div><p>这个周期就长了，解决bug，编译运行等等。看起来，visual studio之类的IDE好像很方便，但是这一切都建立在你还不认识<b>VIM</b>之类编辑器的强大的前提下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-2668fb4c299e8df771ebb8e837bcc5a0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"880\" data-rawheight=\"495\" class=\"origin_image zh-lightbox-thumb\" width=\"880\" data-original=\"https://pic1.zhimg.com/v2-2668fb4c299e8df771ebb8e837bcc5a0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;880&#39; height=&#39;495&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"880\" data-rawheight=\"495\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"880\" data-original=\"https://pic1.zhimg.com/v2-2668fb4c299e8df771ebb8e837bcc5a0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-2668fb4c299e8df771ebb8e837bcc5a0_b.jpg\"/></figure><p>随随便便说几个功能，比如<b>列编辑模式，比如复杂的字符替换。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-21857b69897fd4c4b4d311f7f13a508f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1053\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-21857b69897fd4c4b4d311f7f13a508f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1053&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1053\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-21857b69897fd4c4b4d311f7f13a508f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-21857b69897fd4c4b4d311f7f13a508f_b.jpg\"/></figure><p>写起代码来真的是会舒服很多，高效很多。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.4 模型部署</code></pre></div><p>开发的最后一步就是模型部署，代码经常需要跨平台迁移的，能想象一个依赖于Windows下面IDE的项目能够毫无隐患，顺利地迁移到嵌入式平台吗？</p><p>你很可能不自觉写了一些依赖于Windows窗体之类的代码(比如有人喜欢用C#，MFC)，目录可能也是不上心胡乱配置的，更别说各种日志，到时候就等着重写代码吧。</p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote>02 <b>windows没有Linux干净</b></blockquote><p>Windows本就是一个<b>桌面级的应用系统，不是开发环境</b>。Windows是给普罗大众用户用的，不是给程序员用的。是开发好了软件给你用的，而不是开发软件的。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.1 诱惑太多，没有仪式感</code></pre></div><p>将这个放在第一条貌似有点喧宾夺主，但实际上我觉得是最重要的。</p><p>在Windows下面搞开发，<b>写着写着就不知道干什么去了</b>，反正不写代码也不会死。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7dd3ed73c0dbee6b4039800334ad3957_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"650\" class=\"origin_image zh-lightbox-thumb\" width=\"700\" data-original=\"https://pic4.zhimg.com/v2-7dd3ed73c0dbee6b4039800334ad3957_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;700&#39; height=&#39;650&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"650\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"700\" data-original=\"https://pic4.zhimg.com/v2-7dd3ed73c0dbee6b4039800334ad3957_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-7dd3ed73c0dbee6b4039800334ad3957_b.jpg\"/></figure><p>在windows下面搞开发就没有仪式感好吗！居然还用鼠标，说出去逼格都降低了。</p><p>总之，Windows下开发效率很低，处于鄙视链底层。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.2 多用户 </code></pre></div><p>Linux实现了用户之间完全的隔离，在同一台机器上，每个人可以有自己独立的目录，如/home/zhangsan，/home/lisi，除非有root权限，否则一个用户是看不到别人目录的东西的。</p><p>除了公共的软件库和硬件资源，大家在同一台机器上<b>既可以相互协作，又互不干扰</b>，这是Windows办不到的。</p><p>它带来的好处很明显，有几个突出的；</p><p>(1) 可以<b>各自配置独立的环境</b>，你喜欢python2，我喜欢python3，互不侵犯，尊重个性嘛。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6fff45b354143bf3b20307021bad22f5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-6fff45b354143bf3b20307021bad22f5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-6fff45b354143bf3b20307021bad22f5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6fff45b354143bf3b20307021bad22f5_b.jpg\"/></figure><p>这一点非常重要，而一些小团队仍然不重视这个问题。还可以通过配置不同的权限，让小白们权限低一点，老司机们权限高一点，避免出现<b>小白手贱滥用apt-get之类的命令随意更改系统软件库，造成系统崩溃</b>的情况。<br/></p><p>(2) 合理利用资源，比如小实验室买了一块24G显存的卡，买不起第2块了，总不能放在Windows下面分时用吧。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f6e82a1d316e0bcc44f6a518ff642297_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"361\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic4.zhimg.com/v2-f6e82a1d316e0bcc44f6a518ff642297_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;361&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"361\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic4.zhimg.com/v2-f6e82a1d316e0bcc44f6a518ff642297_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f6e82a1d316e0bcc44f6a518ff642297_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">2.3 高效率 </code></pre></div><p>Linux没有复杂的桌面渲染，能更专注地将<b>服务器的硬件优势表现出来</b>，有各种各样的命令来进行检测。</p><p>对于从事<b>计算密集型的深度学习算法工程师</b>来说，GPU就是命，硬盘都是钱呐。8G显存，恨不能用到7.99G。</p><blockquote>3 <b>windows没有linux靠谱</b></blockquote><p>这要从两方面来说。</p><p><b>第一是安全</b>，linux系统是开源系统，人多力量大，bug往往都被及时发现了。平时很少听到Linux中毒的，Windows在早些年动不动就中毒了。</p><p><b>第二是稳定</b>，Windows和Mac，死个机什么的就是毛毛雨，家常便饭习以为常。但是Linux突然死机是很罕见很罕见的，我见过最多的就是小白手贱把系统搞死了，类似于rm -rf /这种。</p><p>哪有人这么傻直接运行rm -rf /，当时是手指在高速运行敲代码，删除其他东西的时候，<b>不小心带上了</b>，然后就......</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-434f9458441e0f6db52609c92dde390f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"226\" data-rawheight=\"300\" class=\"content_image\" width=\"226\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;226&#39; height=&#39;300&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"226\" data-rawheight=\"300\" class=\"content_image lazy\" width=\"226\" data-actualsrc=\"https://pic4.zhimg.com/v2-434f9458441e0f6db52609c92dde390f_b.jpg\"/></figure><p>以上理由，已经足够让你放弃Windows了，更多Linux的好处，用着用着，就会知道了。</p><p>长痛不如短痛，如果有做开发者的觉悟了，就尽快换上Linux吧。</p><p><i>下期预告：下一期我们会讲Linux的常用基础，如果你有建议，欢迎留言，我们会及时采纳的。</i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-763307c797bc7f833ad49b3f17433d7c_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "Linux", 
                    "tagLink": "https://api.zhihu.com/topics/19554300"
                }, 
                {
                    "tag": "操作系统", 
                    "tagLink": "https://api.zhihu.com/topics/19552686"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "爆米花和洛可可", 
                    "userLink": "https://www.zhihu.com/people/95a1bfc41c2615b89c26cff8305d496d", 
                    "content": "<p>AI入门小白，刚配置了一台二手DELL准备用来学习深度学习，看到这篇文章感觉很及时诶~可以尝试用Linux开发试试看</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "哈哈，早入坑早好", 
                            "likes": 0, 
                            "replyToAuthor": "爆米花和洛可可"
                        }, 
                        {
                            "userName": "爆米花和洛可可", 
                            "userLink": "https://www.zhihu.com/people/95a1bfc41c2615b89c26cff8305d496d", 
                            "content": "嗯嗯 新机还没有到货，估计到时候装机，装系统，乱七八糟至少折腾一两天。虽然有点怕，但想想第一次做这些事，还是兴奋的搓手手", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>Windows 也挺好用。。。</p>", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "👍👍", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>Win/Mac/Linux 三个系统一起使用</p>", 
                    "likes": 2, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "没有罩门了", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "高冷暖微笑", 
                    "userLink": "https://www.zhihu.com/people/53ead79c22504b90963ee0c072c16090", 
                    "content": "双系统，不解释", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "🤝🤝🤝", 
                            "likes": 0, 
                            "replyToAuthor": "高冷暖微笑"
                        }
                    ]
                }, 
                {
                    "userName": "诺侠", 
                    "userLink": "https://www.zhihu.com/people/a3c4779768fded50f0d81f8f053f0f63", 
                    "content": "<p>道理我都懂，就是。。。</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "😂", 
                            "likes": 0, 
                            "replyToAuthor": "诺侠"
                        }
                    ]
                }, 
                {
                    "userName": "wheat", 
                    "userLink": "https://www.zhihu.com/people/e18d257b0facc193c9c8786b1fa2b10a", 
                    "content": "谢谢 刚装了linux搞深度学习 不知从何入手 帮助很及时[赞]", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "🤝", 
                            "likes": 0, 
                            "replyToAuthor": "wheat"
                        }
                    ]
                }, 
                {
                    "userName": "dandelion", 
                    "userLink": "https://www.zhihu.com/people/797f78f9a1acab7d424adae7f40a5def", 
                    "content": "最近想换电脑，那是推荐mac还是linux？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "先搞linux吧", 
                            "likes": 0, 
                            "replyToAuthor": "dandelion"
                        }, 
                        {
                            "userName": "daiyizheng123", 
                            "userLink": "https://www.zhihu.com/people/b99be3823ca6b7f9e95275552e6708d6", 
                            "content": "<p>mac 写代码舒服，但不支持GPU，硬伤啊</p>", 
                            "likes": 0, 
                            "replyToAuthor": "dandelion"
                        }
                    ]
                }, 
                {
                    "userName": "岱GSAA", 
                    "userLink": "https://www.zhihu.com/people/44e492de964bb32921b018f0f13e439d", 
                    "content": "看得想笑，[捂嘴]", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/52344534", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 27, 
            "title": "【AI基础】OpenCV，PIL，Skimage你pick谁", 
            "content": "<p>首发于《有三AI》</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030642%26idx%3D1%26sn%3D67b1aa7668777198d5738d9087715ec7%26chksm%3D8713418fb064c899a1f7f37ef0c71c8ab1f5a9333b7461935348f93655bd7af8feeeaf3fe422%26token%3D228730087%26lang%3Dzh_CN%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI基础】OpenCV，PIL，Skimage你pick谁</a><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-021ea15c8aa1acb789821613224e17c1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1956\" data-rawheight=\"400\" class=\"origin_image zh-lightbox-thumb\" width=\"1956\" data-original=\"https://pic2.zhimg.com/v2-021ea15c8aa1acb789821613224e17c1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1956&#39; height=&#39;400&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1956\" data-rawheight=\"400\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1956\" data-original=\"https://pic2.zhimg.com/v2-021ea15c8aa1acb789821613224e17c1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-021ea15c8aa1acb789821613224e17c1_b.jpg\"/></figure><p>如何对图像进行处理是深度学习图像处理的基础，我们常常需要对图像进行读取、保存、缩放、裁剪、旋转、颜色转换等基本操作。<br/></p><p>本文将讲解如何利用opencv、PIL、 scikit-image等进行图像处理，并比较它们之间微小的差异。</p><blockquote><b>01 三大包的基础操作</b></blockquote><p>本节讲解如何利用opencv、PIL、 scikit-image等工具进行图像读取、图像保存、图像缩放、裁剪、旋转、颜色转换等基本操作。</p><p>下面将基于下面这张图片演示如何对图形进行基本的处理</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-09e873d1b7f281cc9a3ffa476b375f3d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"427\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-09e873d1b7f281cc9a3ffa476b375f3d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;427&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"427\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-09e873d1b7f281cc9a3ffa476b375f3d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-09e873d1b7f281cc9a3ffa476b375f3d_b.jpg\"/></figure><ul><li>1.1 利用PIL处理图像                            </li></ul><p>我们首先从读取图片开始，很多图像处理库（如opencv、skimage）都以imread()读取图片，但是PIL用open方法。</p><p> 如果我们想要使用PIL来处理图像，必须先导入Image模块，这是进行一切操作的前提。导入方法如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">from PIL import Image</code></pre></div><p><b>读取一幅图像</b></p><p>#我的图片是保存在d盘picture文件夹下</p><div class=\"highlight\"><pre><code class=\"language-text\">img = Image.open(&#39;d:/picture/cat.jpg&#39;)</code></pre></div><p>执行上述代码返回的结果如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-837de50eea346ccc4faf53ac7aca2fc9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"913\" data-rawheight=\"29\" class=\"origin_image zh-lightbox-thumb\" width=\"913\" data-original=\"https://pic2.zhimg.com/v2-837de50eea346ccc4faf53ac7aca2fc9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;913&#39; height=&#39;29&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"913\" data-rawheight=\"29\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"913\" data-original=\"https://pic2.zhimg.com/v2-837de50eea346ccc4faf53ac7aca2fc9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-837de50eea346ccc4faf53ac7aca2fc9_b.jpg\"/></figure><p>怎样才能可视化这个图像呢？</p><p>我们需要调用matplotlib这个库，如果没有matplotlib.pyplot中的show()方法，图像只会在内存中，我们当然看不见了。话不多说，代码如下</p><div class=\"highlight\"><pre><code class=\"language-text\">from PIL import Image\nimport matplotlib.pyplot as plt\nimg = Image.open(&#39;d:/picture/cat.jpg&#39;)\nplt.imshow(img)\nplt.show()</code></pre></div><p>结果如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-46bad51e1e632fbcc356a5e5e9ec826d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"422\" data-rawheight=\"324\" class=\"origin_image zh-lightbox-thumb\" width=\"422\" data-original=\"https://pic2.zhimg.com/v2-46bad51e1e632fbcc356a5e5e9ec826d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;422&#39; height=&#39;324&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"422\" data-rawheight=\"324\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"422\" data-original=\"https://pic2.zhimg.com/v2-46bad51e1e632fbcc356a5e5e9ec826d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-46bad51e1e632fbcc356a5e5e9ec826d_b.jpg\"/></figure><p><b>查看图片信息</b></p><p>哈哈！图片我们已经看到了，这是万里长征的第一步。如果我们想要了解图片格式，大小应该怎么办呢？方法如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">print(img.format)#查看图片格式\nprint(img.size)#查看图片大小\nprint(img.mode)#查看图片模式</code></pre></div><p>我只列举了常用的三个其实还有很多，可以自行搜索</p><p><b>更改图像形式</b></p><p>使用PIL中的crop()方法可以从一幅图像中裁剪指定区域，该区域使用四元组来指定，四元组的的坐标依次是（b1,a1,b2,a2），通常一张图片的左上角为0。示意图如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4882b5634a842283c976693b672c9d55_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"479\" data-rawheight=\"352\" class=\"origin_image zh-lightbox-thumb\" width=\"479\" data-original=\"https://pic2.zhimg.com/v2-4882b5634a842283c976693b672c9d55_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;479&#39; height=&#39;352&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"479\" data-rawheight=\"352\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"479\" data-original=\"https://pic2.zhimg.com/v2-4882b5634a842283c976693b672c9d55_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4882b5634a842283c976693b672c9d55_b.jpg\"/></figure><p>如何对图像进行裁剪，具体代码如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-8fa0dee0728b99e9f89626a174ffa3ed_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"458\" data-rawheight=\"224\" class=\"origin_image zh-lightbox-thumb\" width=\"458\" data-original=\"https://pic2.zhimg.com/v2-8fa0dee0728b99e9f89626a174ffa3ed_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;458&#39; height=&#39;224&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"458\" data-rawheight=\"224\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"458\" data-original=\"https://pic2.zhimg.com/v2-8fa0dee0728b99e9f89626a174ffa3ed_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-8fa0dee0728b99e9f89626a174ffa3ed_b.jpg\"/></figure><p>裁剪后的图片<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e645dea6057f3fd39a977b7157e3a563_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"287\" data-rawheight=\"288\" class=\"content_image\" width=\"287\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;287&#39; height=&#39;288&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"287\" data-rawheight=\"288\" class=\"content_image lazy\" width=\"287\" data-actualsrc=\"https://pic4.zhimg.com/v2-e645dea6057f3fd39a977b7157e3a563_b.jpg\"/></figure><p><b>调整图片尺寸和旋转</b></p><p>我们可以使用resize()来调整图片尺寸，该方法的参数是一个元组，用来指定图像的大小，代码如下：</p><p>#把图片的尺寸改为400x400,tuple里面是图像的weight和height</p><div class=\"highlight\"><pre><code class=\"language-text\">Img2 = img1.resize((400,400))</code></pre></div><p>调整大小后的图片</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-b3247495d7f1735ad4ad96d590680313_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"606\" data-rawheight=\"455\" class=\"origin_image zh-lightbox-thumb\" width=\"606\" data-original=\"https://pic4.zhimg.com/v2-b3247495d7f1735ad4ad96d590680313_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;606&#39; height=&#39;455&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"606\" data-rawheight=\"455\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"606\" data-original=\"https://pic4.zhimg.com/v2-b3247495d7f1735ad4ad96d590680313_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-b3247495d7f1735ad4ad96d590680313_b.jpg\"/></figure><p>要旋转一幅图像，可以使用逆时针方法表示角度，调用rotate()方法，代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">img2 = img1.rotate((45))</code></pre></div><p><b>旋转后的图片</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1208956f05045a2b359dba8c720fcda4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"601\" data-rawheight=\"453\" class=\"origin_image zh-lightbox-thumb\" width=\"601\" data-original=\"https://pic1.zhimg.com/v2-1208956f05045a2b359dba8c720fcda4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;601&#39; height=&#39;453&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"601\" data-rawheight=\"453\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"601\" data-original=\"https://pic1.zhimg.com/v2-1208956f05045a2b359dba8c720fcda4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-1208956f05045a2b359dba8c720fcda4_b.jpg\"/></figure><p>对图像旋转（旋转90度的整数倍）和翻转也可以用transpose，方法如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">#左右对换。\nimg2=img1.transpose(Image.FLIP_LEFT_RIGHT) \n#上下对换。\nimg2=img1.transpose(Image.FLIP_TOP_BOTTOM)  \n#旋转 90 度角。注意只能旋转90度的整数倍\nimg2=img1.transpose(Image.ROTATE_90)  </code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-fef28f05b60f9accb7217e9ebd9bdf30_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"312\" data-rawheight=\"232\" class=\"content_image\" width=\"312\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;312&#39; height=&#39;232&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"312\" data-rawheight=\"232\" class=\"content_image lazy\" width=\"312\" data-actualsrc=\"https://pic1.zhimg.com/v2-fef28f05b60f9accb7217e9ebd9bdf30_b.jpg\"/></figure><p>左右翻转</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-2a52f3d16da7fd39a52c11f5f1709034_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"309\" data-rawheight=\"236\" class=\"content_image\" width=\"309\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;309&#39; height=&#39;236&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"309\" data-rawheight=\"236\" class=\"content_image lazy\" width=\"309\" data-actualsrc=\"https://pic1.zhimg.com/v2-2a52f3d16da7fd39a52c11f5f1709034_b.jpg\"/></figure><p>上下翻转<br/></p><p><b>图像颜色变化</b></p><p>PIL中可以使用convet()方法来实现图像一些颜色的变化，convert（）函数会根据传入参数的不同将图片变成不同的模式。在PIL中有9种模式，如下表所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d68f71c221f7a5dd748d311d5e5050cc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"857\" data-rawheight=\"395\" class=\"origin_image zh-lightbox-thumb\" width=\"857\" data-original=\"https://pic1.zhimg.com/v2-d68f71c221f7a5dd748d311d5e5050cc_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;857&#39; height=&#39;395&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"857\" data-rawheight=\"395\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"857\" data-original=\"https://pic1.zhimg.com/v2-d68f71c221f7a5dd748d311d5e5050cc_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d68f71c221f7a5dd748d311d5e5050cc_b.jpg\"/></figure><p>下面我们以灰度图像为例，将目标图像转换成灰度图像，方法如下：</p><p>img1 = img.convert(&#39;F&#39;)#将图片转化为32位浮点灰色图像，结果如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a250ec83c3fe28a3446fc5477e63ee8a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"409\" data-rawheight=\"310\" class=\"content_image\" width=\"409\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;409&#39; height=&#39;310&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"409\" data-rawheight=\"310\" class=\"content_image lazy\" width=\"409\" data-actualsrc=\"https://pic3.zhimg.com/v2-a250ec83c3fe28a3446fc5477e63ee8a_b.jpg\"/></figure><p>下面再使用skimage和opencv对图像进行基本操作，只附上具体实现代码和注释，效果和上面的其实没什么差别。</p><ul><li>1.2 使用skimage对图像处理                  </li></ul><div class=\"highlight\"><pre><code class=\"language-text\">#导入io模块\nfrom skimage import io\n#以彩色模式读取图片\nimg=io.imread(&#39;d:/picture/cat.jpg&#39;)\n#以灰色图像模式读取图片\nimg=io.imread(&#39;d:/picture/cat.jpg&#39;,as_grey=True)\n#将图片保存在c盘,picture文件夹下\nio.imsave(&#39;c:/picture/cat.jpg&#39;)\n#将图片的大小变为500x500\nimg1 = transform.resize(img, (500,500))\n#缩小为原来图片大小的0.1\nimg2 = transform.rescale(img, 0.1) \n#缩小为原来图片行数一半，列数四分之一\nimg3 = transform.rescale(img, [0.5,0.25])\n#放大为原来图片大小的2倍\nimg4 =transform.rescale(img, 2)\n#旋转60度，不改变大小\nimg5 =transform.rotate(img, 60)\n#旋转60度，同时改变大小\nimg6=transform.rotate(img, 60,resize=True) \n#将图片调暗，。如果gamma大于1，新图像比原图像暗，如果gamma&lt;1，新图像比原图像亮\nimg7= exposure.adjust_gamma(img, 4) \n#将图片调亮\nimg8= exposure.adjust_gamma(img, 0.3)</code></pre></div><ul><li>1.3使用opencv对图像进行处理 </li></ul><div class=\"highlight\"><pre><code class=\"language-text\">#导入opencv\nimport cv2</code></pre></div><p>#读取图片返回的是numpy.array格式</p><p>#cv2.imread共两个参数，第一个参数为要读入的图片文件名，第二个参数为如何读取图片，包括cv2.IMREAD_COLOR：读入一副彩色图片；cv2.IMREAD_GRAYSCALE：以灰度模式读入图片；cv2.IMREAD_UNCHANGED：读入一幅图片，并包括其alpha通道。</p><div class=\"highlight\"><pre><code class=\"language-text\">img = cv2.imread(&#39;d:/picture/cat.jpg&#39;)</code></pre></div><p>#获取图片属性</p><div class=\"highlight\"><pre><code class=\"language-text\">print(img.shape)#返回图片的长，宽和通道数</code></pre></div><p>#保存图片，共两个参数，第一个为保存文件名，第二个为读入图片</p><div class=\"highlight\"><pre><code class=\"language-text\">cv2.imwrite(&#39;c:/picture/cat4.jpg&#39;,img)</code></pre></div><p>#创建一个窗口显示图片，共两个参数，第一个参数表示窗口名字，可以创建多个窗口中，但是每个窗口不能重名；第二个参数是读入的图片。</p><div class=\"highlight\"><pre><code class=\"language-text\">cv2.imshow()</code></pre></div><p>#键盘绑定函数，共一个参数，表示等待毫秒数，将等待特定的几毫秒，看键盘是否有输入，返回值为ASCII值。如果其参数为0，则表示无限期的等待键盘输入</p><div class=\"highlight\"><pre><code class=\"language-text\">cv2.waitKey()</code></pre></div><p>#删除建立的全部窗口</p><div class=\"highlight\"><pre><code class=\"language-text\">cv2.destroyAllWindows()</code></pre></div><p>删除指定的窗口</p><div class=\"highlight\"><pre><code class=\"language-text\">cv2.destroyWindows()</code></pre></div><p>#opencv中图像彩色空间变换函数cv2.cvtColor</p><div class=\"highlight\"><pre><code class=\"language-text\">cv2.cvtColor(input_image,fiag)</code></pre></div><p>参数一： input_image表示将要变换色彩的图像ndarray对象 <br/>参数二： 表示图像色彩空间变换的类型，以下介绍常用的两种： <br/>· cv2.COLOR_BGR2GRAY： 表示将图像从BGR空间转化成灰度图，最常用 <br/>· cv2.COLOR_BGR2HSV： 表示将图像从RGB空间转换到HSV空间 <br/>如果想查看参数flag的全部类型，请执行以下程序便可查阅，总共有274种空间转换类型：</p><div class=\"highlight\"><pre><code class=\"language-text\">import cv2\nflags = [i for i in dir(cv2) if i.startswith(&#39;COLOR_&#39;)]\nprint(flags)</code></pre></div><blockquote><b>02 比较细节差异</b></blockquote><ul><li>2.1读取方式上的不同</li></ul><p>我们首先从读取图片开始，PIL用open方法来读取图片，但opencv、skimage都以imread()读取图片。</p><ul><li>2.2读进来内容的差异</li></ul><p>opencv读进来的图片已经是一个numpy矩阵了，彩色图片维度是（高度，宽度，通道数）。数据类型是uint8；</p><p><b>opencv对于读进来的图片的通道排列是BGR，而不是主流的RGB！谨记！</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-89d2f8c38e387ae4ee90adf73b36eb5f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"247\" data-rawheight=\"93\" class=\"content_image\" width=\"247\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;247&#39; height=&#39;93&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"247\" data-rawheight=\"93\" class=\"content_image lazy\" width=\"247\" data-actualsrc=\"https://pic4.zhimg.com/v2-89d2f8c38e387ae4ee90adf73b36eb5f_b.jpg\"/></figure><p>opencV存储的格式：BGR</p><p>PIL读进来的图像是一个对象，而不是我们所熟知的numpy 矩阵</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-3e6626162d68f7fed25db9ae37e5e7ab_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"913\" data-rawheight=\"29\" class=\"origin_image zh-lightbox-thumb\" width=\"913\" data-original=\"https://pic4.zhimg.com/v2-3e6626162d68f7fed25db9ae37e5e7ab_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;913&#39; height=&#39;29&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"913\" data-rawheight=\"29\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"913\" data-original=\"https://pic4.zhimg.com/v2-3e6626162d68f7fed25db9ae37e5e7ab_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-3e6626162d68f7fed25db9ae37e5e7ab_b.jpg\"/></figure><p>PIL储存的格式</p><p>针对PIL读进来的图像是一个对象，那么如何才能将读进来的图片转为矩阵呢，方法如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">from PIL import Image\nimport numpy as np\nimg1 = Image.open(&#39;d:/picture/cat.jpg&#39;)\narr = np.array(img1)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-2bfa40cada70e05fa1ae68152ea7659c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"275\" data-rawheight=\"118\" class=\"content_image\" width=\"275\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;275&#39; height=&#39;118&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"275\" data-rawheight=\"118\" class=\"content_image lazy\" width=\"275\" data-actualsrc=\"https://pic1.zhimg.com/v2-2bfa40cada70e05fa1ae68152ea7659c_b.jpg\"/></figure><p>转换后的格式<br/></p><p>skimage读取一张图像时也是以numpy array形式读入skimage的存储格式是RGB。如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-64b84a47b419a7e5b156492a95ee45e7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"241\" data-rawheight=\"118\" class=\"content_image\" width=\"241\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;241&#39; height=&#39;118&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"241\" data-rawheight=\"118\" class=\"content_image lazy\" width=\"241\" data-actualsrc=\"https://pic4.zhimg.com/v2-64b84a47b419a7e5b156492a95ee45e7_b.jpg\"/></figure><p>skimage的存储格式RGB</p><p><b>skimage有一个巨大的不同是读取灰度图时其图像的矩阵的值被归一化了，注意注意！</b></p><p>我们skimage先看读取灰度图的方式，代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">from skimage import io\nimg=io.imread(&#39;d:/picture/cat.jpg&#39;,as_grey=True)</code></pre></div><p>读取的结果如下图所示，明显看到被归一化了!</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d56013581a952e9cbbcd04dc54d86cb8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"825\" data-rawheight=\"207\" class=\"origin_image zh-lightbox-thumb\" width=\"825\" data-original=\"https://pic1.zhimg.com/v2-d56013581a952e9cbbcd04dc54d86cb8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;825&#39; height=&#39;207&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"825\" data-rawheight=\"207\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"825\" data-original=\"https://pic1.zhimg.com/v2-d56013581a952e9cbbcd04dc54d86cb8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d56013581a952e9cbbcd04dc54d86cb8_b.jpg\"/></figure><p>我们再看opencv和PIL读取灰度图时会不会被归一化呢？代码和对比如下：</p><p>opencv读取灰度图</p><div class=\"highlight\"><pre><code class=\"language-text\">import cv2\nimg=cv2.imread(&#39;d:/picture/cat.jpg&#39;,cv2.IMREAD_GRAYSCALE)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d8416776ac45c030de6fb9e1c7c24695_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"357\" data-rawheight=\"205\" class=\"content_image\" width=\"357\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;357&#39; height=&#39;205&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"357\" data-rawheight=\"205\" class=\"content_image lazy\" width=\"357\" data-actualsrc=\"https://pic2.zhimg.com/v2-d8416776ac45c030de6fb9e1c7c24695_b.jpg\"/></figure><p>opencv读取灰度图格式</p><p>PIL读取灰度图</p><div class=\"highlight\"><pre><code class=\"language-text\">from PIL import Image\nimport numpy as np\nimg1 = Image.open(&#39;d:/picture/cat.jpg&#39;).convert(&#39;L&#39;)\narr = np.array(img1)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-43ef0e12638082a8a44e09748d5256ee_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"369\" data-rawheight=\"209\" class=\"content_image\" width=\"369\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;369&#39; height=&#39;209&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"369\" data-rawheight=\"209\" class=\"content_image lazy\" width=\"369\" data-actualsrc=\"https://pic3.zhimg.com/v2-43ef0e12638082a8a44e09748d5256ee_b.jpg\"/></figure><p>PIL读取灰度图格式</p><p>从上面的对比可以看出skimage读取灰度图时的巨大不同就是其图像的矩阵的值被归一化了！！！</p><blockquote><b>03 总结</b></blockquote><p>总的来说OpenCV、Skimage、PIL各有千秋。各种框架中进行进行混用，所以我们都必须要掌握，而且要注意区分他们之间微小的差异。</p>", 
            "topic": [
                {
                    "tag": "OpenCV", 
                    "tagLink": "https://api.zhihu.com/topics/19587715"
                }, 
                {
                    "tag": "PIL", 
                    "tagLink": "https://api.zhihu.com/topics/19704173"
                }, 
                {
                    "tag": "图像处理", 
                    "tagLink": "https://api.zhihu.com/topics/19556376"
                }
            ], 
            "comments": [
                {
                    "userName": "Tinkle", 
                    "userLink": "https://www.zhihu.com/people/3696ff589b9bea0d9c5ac2effbddad31", 
                    "content": "python，c++，java都会用到的开发人员还是建议opencv", 
                    "likes": 2, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "🤝", 
                            "likes": 0, 
                            "replyToAuthor": "Tinkle"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>优先 OpenCV ，目前已经更新至4.0+</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "嗯", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "andyx", 
                    "userLink": "https://www.zhihu.com/people/17f140d9bba27a5e088609e728df37e7", 
                    "content": "<p>opencv对于超过３波段的图像支持不是很友好</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/c_1056864415533572096"
}

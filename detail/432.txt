{
    "title": "Microsoft认知工具集(CNTK)", 
    "description": "CNTK 是一个统一的计算网络框架，它将深层神经网络描述为一系列通过有向图的计算步骤。在有向图中，每个节点代表一个输入值或一个网络参数，每个边表示在其中的一个矩阵运算。CNTK 提供了实现前向计算和梯度计算的算法。CNTK中预定义了很多主流的计算网络结构，用户可以轻松地在开源许可证下扩展节点类型。社区可以利用它来更方便地来推进关于人工智能的研究。", 
    "followers": [
        "https://www.zhihu.com/people/xiao-zhang-lai-xue-xi", 
        "https://www.zhihu.com/people/teddy-66-30", 
        "https://www.zhihu.com/people/tian-shi-yu-bei-yi", 
        "https://www.zhihu.com/people/bawfgfhv", 
        "https://www.zhihu.com/people/wu-jin-shi-guang-de-ai", 
        "https://www.zhihu.com/people/liu-yang-11", 
        "https://www.zhihu.com/people/nu-shen-jing-66", 
        "https://www.zhihu.com/people/da-ming-ming-57-42", 
        "https://www.zhihu.com/people/heng-qing-shi-35", 
        "https://www.zhihu.com/people/jesse-hao", 
        "https://www.zhihu.com/people/sunlichao", 
        "https://www.zhihu.com/people/wang-fu-gui-57-22", 
        "https://www.zhihu.com/people/youjingju", 
        "https://www.zhihu.com/people/shui-bian-ing-48", 
        "https://www.zhihu.com/people/xxsc02", 
        "https://www.zhihu.com/people/fei-ge-li-li-tu", 
        "https://www.zhihu.com/people/chen-pan-95-97", 
        "https://www.zhihu.com/people/ronald-xie", 
        "https://www.zhihu.com/people/heng-ge-zai-ma", 
        "https://www.zhihu.com/people/mu-mu-ke-ke-69", 
        "https://www.zhihu.com/people/cukie-74", 
        "https://www.zhihu.com/people/koui-64", 
        "https://www.zhihu.com/people/bai-guo-dong-7", 
        "https://www.zhihu.com/people/ji-yi-sui-pian-66", 
        "https://www.zhihu.com/people/ke-ke-23-12", 
        "https://www.zhihu.com/people/lin-tim-89", 
        "https://www.zhihu.com/people/yan-zheng-tong", 
        "https://www.zhihu.com/people/xiao-hei-ji", 
        "https://www.zhihu.com/people/ma-yu-xiang-4", 
        "https://www.zhihu.com/people/winston.wen", 
        "https://www.zhihu.com/people/aihaoge1314", 
        "https://www.zhihu.com/people/a-feng-1-48", 
        "https://www.zhihu.com/people/yym0924", 
        "https://www.zhihu.com/people/nuan-chong-83", 
        "https://www.zhihu.com/people/cao-yi-xiao-74", 
        "https://www.zhihu.com/people/gmc2", 
        "https://www.zhihu.com/people/ku-ding-cha-13-83", 
        "https://www.zhihu.com/people/zhao-han-61-41", 
        "https://www.zhihu.com/people/lao-guo-2-44", 
        "https://www.zhihu.com/people/hui-hui-58-60-10", 
        "https://www.zhihu.com/people/xiao-tai-huang", 
        "https://www.zhihu.com/people/zheng-cai-yuan", 
        "https://www.zhihu.com/people/zhan-zheng-nu-shen-ya-2942514937-98", 
        "https://www.zhihu.com/people/tiao-liang-fc", 
        "https://www.zhihu.com/people/jiazhiqushijishupai", 
        "https://www.zhihu.com/people/Xingchen0000", 
        "https://www.zhihu.com/people/li-yi-heng-60-80", 
        "https://www.zhihu.com/people/xu-shao-zhi", 
        "https://www.zhihu.com/people/jin-tian-xia-wu-qu-shang-ban", 
        "https://www.zhihu.com/people/forestsen", 
        "https://www.zhihu.com/people/roamer-30", 
        "https://www.zhihu.com/people/tyronetown", 
        "https://www.zhihu.com/people/Soap-Miko-47", 
        "https://www.zhihu.com/people/kaleyroy", 
        "https://www.zhihu.com/people/ma-ma-63", 
        "https://www.zhihu.com/people/guyao", 
        "https://www.zhihu.com/people/cbd-55", 
        "https://www.zhihu.com/people/chrisanderson", 
        "https://www.zhihu.com/people/li-hang-21", 
        "https://www.zhihu.com/people/songsharp", 
        "https://www.zhihu.com/people/yea-miles", 
        "https://www.zhihu.com/people/fu-hong-yu-21", 
        "https://www.zhihu.com/people/li-shao-52-36", 
        "https://www.zhihu.com/people/wang-mu-yun-39", 
        "https://www.zhihu.com/people/umu618", 
        "https://www.zhihu.com/people/gjchunqiu", 
        "https://www.zhihu.com/people/ren-hh-41", 
        "https://www.zhihu.com/people/javagg", 
        "https://www.zhihu.com/people/zhuan-jian-41", 
        "https://www.zhihu.com/people/kai-xin-86", 
        "https://www.zhihu.com/people/zhang-zi-bo-7", 
        "https://www.zhihu.com/people/wang-hao-HouHuiLiang", 
        "https://www.zhihu.com/people/luvee", 
        "https://www.zhihu.com/people/ygy-blazer", 
        "https://www.zhihu.com/people/xu-da-kai-66", 
        "https://www.zhihu.com/people/zhang-yue-57-15", 
        "https://www.zhihu.com/people/pan-zu-jiang", 
        "https://www.zhihu.com/people/zatsunen", 
        "https://www.zhihu.com/people/pei-wang-69", 
        "https://www.zhihu.com/people/karvn", 
        "https://www.zhihu.com/people/coderpreacher", 
        "https://www.zhihu.com/people/zhang-ya-sheng-29", 
        "https://www.zhihu.com/people/vinkwok", 
        "https://www.zhihu.com/people/zhui-xun-meng-tu", 
        "https://www.zhihu.com/people/genghanqiang", 
        "https://www.zhihu.com/people/shua-jin-xiao-bing", 
        "https://www.zhihu.com/people/sharemy-15", 
        "https://www.zhihu.com/people/he-li-16-66", 
        "https://www.zhihu.com/people/lu-wu-yi-59", 
        "https://www.zhihu.com/people/zhou-lian-77-27", 
        "https://www.zhihu.com/people/han-zhuang-18", 
        "https://www.zhihu.com/people/shi-qiao-62", 
        "https://www.zhihu.com/people/ming-yun-de-chao-feng", 
        "https://www.zhihu.com/people/du-guang-long", 
        "https://www.zhihu.com/people/gp-wang", 
        "https://www.zhihu.com/people/MineTerra", 
        "https://www.zhihu.com/people/di-mo-64", 
        "https://www.zhihu.com/people/two-little", 
        "https://www.zhihu.com/people/MeetTaoTao", 
        "https://www.zhihu.com/people/zhang-xu-86-29", 
        "https://www.zhihu.com/people/ma-wei-92-26", 
        "https://www.zhihu.com/people/liu-fei-fei-47-77", 
        "https://www.zhihu.com/people/zhangshaojie-98", 
        "https://www.zhihu.com/people/liu-music", 
        "https://www.zhihu.com/people/goodxiao-jia", 
        "https://www.zhihu.com/people/xie-ze-xuan-8", 
        "https://www.zhihu.com/people/guzhusun", 
        "https://www.zhihu.com/people/ceng-suo-ye", 
        "https://www.zhihu.com/people/yige-ng-hen-feng-kuang-de-ren", 
        "https://www.zhihu.com/people/yang-tian-67-81", 
        "https://www.zhihu.com/people/moloach", 
        "https://www.zhihu.com/people/lin-jiao-ying-43", 
        "https://www.zhihu.com/people/roach-kind", 
        "https://www.zhihu.com/people/liu-meng-yuan-72-95", 
        "https://www.zhihu.com/people/eric_hu", 
        "https://www.zhihu.com/people/lin-min-quan", 
        "https://www.zhihu.com/people/li-shi-50-29", 
        "https://www.zhihu.com/people/wu-chao-77", 
        "https://www.zhihu.com/people/yiwwan", 
        "https://www.zhihu.com/people/wang-zhi-cheng-97", 
        "https://www.zhihu.com/people/CoderHelper", 
        "https://www.zhihu.com/people/noke-95", 
        "https://www.zhihu.com/people/cedro", 
        "https://www.zhihu.com/people/guo-er-37", 
        "https://www.zhihu.com/people/yani7242", 
        "https://www.zhihu.com/people/wei-xing-29-42", 
        "https://www.zhihu.com/people/feng-feng-yu-yu", 
        "https://www.zhihu.com/people/zhang-han-yi", 
        "https://www.zhihu.com/people/chis-oaty", 
        "https://www.zhihu.com/people/jijiechen", 
        "https://www.zhihu.com/people/simon-jiang-63", 
        "https://www.zhihu.com/people/ning-meng-qi-shui-jing-ling", 
        "https://www.zhihu.com/people/gnjiao", 
        "https://www.zhihu.com/people/tom-pareto", 
        "https://www.zhihu.com/people/juchun-tien-21", 
        "https://www.zhihu.com/people/qi-tian-qing-shui", 
        "https://www.zhihu.com/people/mr-kin", 
        "https://www.zhihu.com/people/cao-zhi-wei-36", 
        "https://www.zhihu.com/people/mrzhh", 
        "https://www.zhihu.com/people/cao-si-cheng", 
        "https://www.zhihu.com/people/liu-hui-31-40", 
        "https://www.zhihu.com/people/wang-shi-hao-99-79", 
        "https://www.zhihu.com/people/xiao-he-85-48", 
        "https://www.zhihu.com/people/missbear-46-6", 
        "https://www.zhihu.com/people/wx_hu", 
        "https://www.zhihu.com/people/cheng-xiao-zu", 
        "https://www.zhihu.com/people/sth4nothing", 
        "https://www.zhihu.com/people/zovie", 
        "https://www.zhihu.com/people/ouzyg", 
        "https://www.zhihu.com/people/kebill", 
        "https://www.zhihu.com/people/cui-peng-25-80", 
        "https://www.zhihu.com/people/zhu-yu-cong-95", 
        "https://www.zhihu.com/people/dai-xiao-liang-47", 
        "https://www.zhihu.com/people/chun-sheng-88-62", 
        "https://www.zhihu.com/people/tu-mi-76-69", 
        "https://www.zhihu.com/people/shi-ren-26-58", 
        "https://www.zhihu.com/people/homer-wong-33", 
        "https://www.zhihu.com/people/liu-dc-63", 
        "https://www.zhihu.com/people/peng-bo-36-74", 
        "https://www.zhihu.com/people/stay.calm", 
        "https://www.zhihu.com/people/cqwcys6r8", 
        "https://www.zhihu.com/people/rohan-18", 
        "https://www.zhihu.com/people/lin-hao-69-83", 
        "https://www.zhihu.com/people/mashiro-62", 
        "https://www.zhihu.com/people/zmqcherish", 
        "https://www.zhihu.com/people/tan-ben-dong", 
        "https://www.zhihu.com/people/abe1", 
        "https://www.zhihu.com/people/yu-xiao-83-98", 
        "https://www.zhihu.com/people/jacklqc8", 
        "https://www.zhihu.com/people/wulingmin", 
        "https://www.zhihu.com/people/peng-shayne", 
        "https://www.zhihu.com/people/bei-xi-12-17", 
        "https://www.zhihu.com/people/ming-di-87-35", 
        "https://www.zhihu.com/people/link-19-71", 
        "https://www.zhihu.com/people/duan-hua-55", 
        "https://www.zhihu.com/people/jiu-ye-20-63", 
        "https://www.zhihu.com/people/yomunsam", 
        "https://www.zhihu.com/people/cc-cc-64-11", 
        "https://www.zhihu.com/people/liu-xiao-jia-09", 
        "https://www.zhihu.com/people/lan-yu-wen-52", 
        "https://www.zhihu.com/people/zhuangyan-stone", 
        "https://www.zhihu.com/people/yuan-qi-93-76", 
        "https://www.zhihu.com/people/zhou-san-zhou-si-41", 
        "https://www.zhihu.com/people/li-guo-dong-8", 
        "https://www.zhihu.com/people/430chii", 
        "https://www.zhihu.com/people/qiu-jia-zhao", 
        "https://www.zhihu.com/people/nyanya-77", 
        "https://www.zhihu.com/people/gu-zhou-suo-li-weng-65-84", 
        "https://www.zhihu.com/people/xie-chen-yu-8-67", 
        "https://www.zhihu.com/people/chen-cong-31-27", 
        "https://www.zhihu.com/people/hu-wei-er-51", 
        "https://www.zhihu.com/people/zhang-xin-56-42", 
        "https://www.zhihu.com/people/wiphom", 
        "https://www.zhihu.com/people/panovr", 
        "https://www.zhihu.com/people/ren-yu-65", 
        "https://www.zhihu.com/people/sx-tian", 
        "https://www.zhihu.com/people/zhang-yu-xiang-83", 
        "https://www.zhihu.com/people/zhou-da-xia-71", 
        "https://www.zhihu.com/people/hanlin.lin", 
        "https://www.zhihu.com/people/ling-wal", 
        "https://www.zhihu.com/people/jiang-min-miao", 
        "https://www.zhihu.com/people/hippiezhou", 
        "https://www.zhihu.com/people/rain-92-52", 
        "https://www.zhihu.com/people/long-gang-62-42", 
        "https://www.zhihu.com/people/arkham", 
        "https://www.zhihu.com/people/yi-wu-zhi", 
        "https://www.zhihu.com/people/bu-ru-gui-qu-22-63", 
        "https://www.zhihu.com/people/wang-po-shi-21", 
        "https://www.zhihu.com/people/chengshun", 
        "https://www.zhihu.com/people/tian-li-67-94", 
        "https://www.zhihu.com/people/lovelycat-31-84", 
        "https://www.zhihu.com/people/yuchenlin", 
        "https://www.zhihu.com/people/hubett", 
        "https://www.zhihu.com/people/wang-zhen-47-1", 
        "https://www.zhihu.com/people/wang-zhe-85-98", 
        "https://www.zhihu.com/people/bu-hui-53-22", 
        "https://www.zhihu.com/people/ma-jin-rui-67", 
        "https://www.zhihu.com/people/wang-chao-87-73-80", 
        "https://www.zhihu.com/people/sanshi1982", 
        "https://www.zhihu.com/people/yi-jiang-shi-tou", 
        "https://www.zhihu.com/people/johnny-ho-19", 
        "https://www.zhihu.com/people/lai-hua-ming-29", 
        "https://www.zhihu.com/people/liu-robin-74", 
        "https://www.zhihu.com/people/solemnizeljf", 
        "https://www.zhihu.com/people/Gome", 
        "https://www.zhihu.com/people/jiapengzhang", 
        "https://www.zhihu.com/people/wang-yue-jun-51", 
        "https://www.zhihu.com/people/xin-de-rui-la-74-15", 
        "https://www.zhihu.com/people/song-fei-81-20-83", 
        "https://www.zhihu.com/people/po-tai-jun", 
        "https://www.zhihu.com/people/zhangzuliang", 
        "https://www.zhihu.com/people/yt752", 
        "https://www.zhihu.com/people/cmpute", 
        "https://www.zhihu.com/people/zhi-hu-19-88", 
        "https://www.zhihu.com/people/zhong-ping-97-7", 
        "https://www.zhihu.com/people/flyer-sam", 
        "https://www.zhihu.com/people/dai-si-meng-89", 
        "https://www.zhihu.com/people/nange-49", 
        "https://www.zhihu.com/people/5yesan", 
        "https://www.zhihu.com/people/VVeixiao", 
        "https://www.zhihu.com/people/zuoyejun", 
        "https://www.zhihu.com/people/liu-xiao-yao-12", 
        "https://www.zhihu.com/people/dearc", 
        "https://www.zhihu.com/people/zhong-2-91", 
        "https://www.zhihu.com/people/heyang-36", 
        "https://www.zhihu.com/people/codepiano", 
        "https://www.zhihu.com/people/lei-liu-93", 
        "https://www.zhihu.com/people/leoxiao", 
        "https://www.zhihu.com/people/fu-lei-68", 
        "https://www.zhihu.com/people/jiang-jing-57-64-53", 
        "https://www.zhihu.com/people/ming-wu-40", 
        "https://www.zhihu.com/people/kevin-hill", 
        "https://www.zhihu.com/people/lu-le-wei", 
        "https://www.zhihu.com/people/yi-lu-huan-ge-59", 
        "https://www.zhihu.com/people/qing-mu-10-60", 
        "https://www.zhihu.com/people/camark", 
        "https://www.zhihu.com/people/madbyte", 
        "https://www.zhihu.com/people/eld-tm", 
        "https://www.zhihu.com/people/linuxcpp", 
        "https://www.zhihu.com/people/li-tuo-ma-si", 
        "https://www.zhihu.com/people/ggff-ss", 
        "https://www.zhihu.com/people/lin-guo-wei", 
        "https://www.zhihu.com/people/jiahui_zhang", 
        "https://www.zhihu.com/people/liu-teng-yu", 
        "https://www.zhihu.com/people/luo-yicheng", 
        "https://www.zhihu.com/people/fan-qie-dan-fan-24", 
        "https://www.zhihu.com/people/myuan", 
        "https://www.zhihu.com/people/feixue", 
        "https://www.zhihu.com/people/EricW", 
        "https://www.zhihu.com/people/lfyzjck", 
        "https://www.zhihu.com/people/zhong-guang-ze", 
        "https://www.zhihu.com/people/fleurer", 
        "https://www.zhihu.com/people/miaoyuangu", 
        "https://www.zhihu.com/people/li-fei-5-50", 
        "https://www.zhihu.com/people/ni-hui-51-23", 
        "https://www.zhihu.com/people/ke-wu-88", 
        "https://www.zhihu.com/people/jiagengliu", 
        "https://www.zhihu.com/people/yiiwood", 
        "https://www.zhihu.com/people/hijackjave", 
        "https://www.zhihu.com/people/wei-mu", 
        "https://www.zhihu.com/people/zixvan-wei", 
        "https://www.zhihu.com/people/ArronTang", 
        "https://www.zhihu.com/people/guo-qian-29-20", 
        "https://www.zhihu.com/people/wang-jian-fei", 
        "https://www.zhihu.com/people/bao-xin-qi", 
        "https://www.zhihu.com/people/ran-quan", 
        "https://www.zhihu.com/people/yima-jing", 
        "https://www.zhihu.com/people/monster-73-54", 
        "https://www.zhihu.com/people/Alexander-Z-94-85", 
        "https://www.zhihu.com/people/qiangchong2017", 
        "https://www.zhihu.com/people/duo-man-xiao-bai", 
        "https://www.zhihu.com/people/qiu-ri-3-94", 
        "https://www.zhihu.com/people/qiu-guang-lei", 
        "https://www.zhihu.com/people/liang-yong-zhu-58", 
        "https://www.zhihu.com/people/ling-yi-qun"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/29945804", 
            "userName": "王万霖", 
            "userLink": "https://www.zhihu.com/people/b8f13b7ce876ce5f99a47ce6cd2956f0", 
            "upvote": 6, 
            "title": "升级至cuDNN6.0：CNTK2.2版本发布", 
            "content": "<p>本文最后更新于2017年11月11日， 本次更新包含了翻译。</p><p>2017年9月16日，微软发布了认知工具集（CNTK）的2.2版本，这距离上次的版本（2.1）发布有47天。微软官方发布了本次更新的相关内容的英文版本，我们将其翻译为简体中文版本。</p><h2>不向后兼容的更改</h2><ul><li>为了支持dilated convolution以及deterministic pooling的特性，从该版本开始需要cuDNN 6.0。请升级你的cuDNN。</li><li>为了支持TensorBoard Image的特性，请在安装CNTK之前安装OpenCV。</li></ul><h2>文档</h2><h2>添加了HTML版本的教程和手册，以便更好地索引</h2><p>我们为<a href=\"https://link.zhihu.com/?target=https%3A//www.cntk.ai/pythondocs/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Python版本文档</a>添加了HTML格式的<a href=\"https://link.zhihu.com/?target=https%3A//www.cntk.ai/pythondocs/tutorials.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">指引</a>和<a href=\"https://link.zhihu.com/?target=https%3A//www.cntk.ai/pythondocs/manuals.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">手册</a>（英文）。这能让入门手册和文档能够更好地索引。</p><h2>添加评估文档</h2><p>关于模型选择的文档已经更新，请在<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/CNTK-Evaluation-Overview\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">此处</a>查看最新的文档（英文）。</p><h2>系统</h2><h2>对于Volta GPU的16 bits训练支持(有限功能)</h2><p>此项工作将会在下一个版本被整合进去，我们现在仍需进行一些测试工作。</p><h2>对于NCCL 2的支持</h2><p>从这一版本开始，<a href=\"https://link.zhihu.com/?target=https%3A//developer.nvidia.com/nccl\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">NCCL</a>可以被用于跨实例。用户需要按照<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-linux\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">此处</a>配置（英文），以启用NCCL。<br/>注意：</p><ul><li>在安装NCCL 2之后，会出现以下两个包：<br/><code>/var/nccl-repo-2.0.4-ga/libnccl2_2.0.4-1+cuda8.0_amd64.deb<br/>/var/nccl-repo-2.0.4-ga/libnccl-dev_2.0.4-1+cuda8.0_amd64.deb.</code><br/>构建带NCCL2的CNTK时，需要将以上两个包全部安装。</li><li>由于系统配置中的某些问题，用户可能会在NCCL初始化时遇到一些问题。将环境变量<i>NCCL_DEBUG=INFO</i>进行设置，可以查看详细的错误信息。</li><li>一个已知的问题是，当NCCL2与运行于混合IB和IPoIB的InfiniBand设备一起运行时会出现问题。为了只使用IB模式的设备，请设置环境变量NCCL_IB_HCA=devices以便运行于IB模式，比如：export NCCL_IB_HCA=mlx5_0,mlx5_2。</li></ul><h2>CNTK学习器界面改进</h2><p>本次更新简化了学习器的相关API，并且摒弃了有关unitType.minibatch和UnitType.sample的概念。我们的目的是为了使API调用更加直观，同时以便于保持CNTK独特的模型更新技术。对于所有的N-示例的平均梯度<br/> The purpose is to make the API intuitive to specify the learner <br/>hyper-parameters while preserving the unique model update techniques in <br/>CNTK --- the mean gradients of every N samples contributes approximately<br/> the same to the model updates regardless of the actual data minibatch <br/>sizes. Detailed explanation can be found at the manual on <a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/master/Manual/Manual_How_to_use_learners.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">How to Use CNTK Learners</a>. </p><p>在新版本的API中，所有受支持的学习器，包括：<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.adadelta\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">AdaDelta</a>,<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.adagrad\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">AdaGrad</a>,<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.fsadagrad\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">FSAdaGrad</a>,<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.adam\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Adam</a>,<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.momentum_sgd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">MomentumSGD</a>,<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.nesterov\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Nesterov</a>,<br/><a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.rmsprop\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">RMSProp</a>和<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.sgd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">SGD</a>，能够在Python代码中选择和指定</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">cntk</span><span class=\"o\">.&lt;</span><span class=\"n\">cntk_supporting_learner</span><span class=\"o\">&gt;</span><span class=\"p\">(</span><span class=\"n\">parameters</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parametes</span><span class=\"p\">,</span>\n    <span class=\"n\">lr</span><span class=\"o\">=&lt;</span><span class=\"nb\">float</span> <span class=\"ow\">or</span> <span class=\"nb\">list</span><span class=\"o\">&gt;</span><span class=\"p\">,</span>\n    <span class=\"p\">[</span><span class=\"n\">momentum</span><span class=\"o\">=&lt;</span><span class=\"nb\">float</span> <span class=\"ow\">or</span> <span class=\"nb\">list</span><span class=\"o\">&gt;</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"n\">variance_momentum</span><span class=\"o\">=&lt;</span><span class=\"nb\">float</span> <span class=\"ow\">or</span> <span class=\"nb\">list</span><span class=\"o\">&gt;</span><span class=\"p\">],</span>\n    <span class=\"n\">minibatch_size</span><span class=\"o\">=&lt;</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"ow\">or</span> <span class=\"n\">cntk</span><span class=\"o\">.</span><span class=\"n\">learners</span><span class=\"o\">.</span><span class=\"n\">IGNORE</span><span class=\"o\">&gt;</span><span class=\"p\">,</span>\n    <span class=\"o\">...</span><span class=\"n\">other</span> <span class=\"n\">learner</span> <span class=\"n\">parameters</span><span class=\"p\">)</span></code></pre></div><p>存在以下两处显著更改：</p><ul><li><code>lr</code>: 学习率的计划可以以浮点数、浮点数列表或者元组（float, int）列表指定。（请参考<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%3Fhighlight%3Dlearning_rate_schedule%23cntk.learners.learning_parameter_schedule\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">learning_parameter_schedule</a>中的参数定义）同样，学习器的momentum以及variance_moment参数，<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.fsadagrad\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">FSAdaGrad</a>、<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.adam\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Adam</a>、<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.momentum_sgd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">MomentumSGD</a>以及<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.nesterov\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Nesterov</a>函数也进行了以上改进。</li><li><code>minibatch_size</code>: minibatch_size可以被指定为 can be specified to<br/> guarantee that the mean gradient of every N (minibatch_size=N) samples <br/>contribute to the model updates with the same learning rate even if the <br/>actual minibatch size of the data is different from N. This is useful <br/>when the data minibatch size varies, especially in scenarios of training<br/> with variable length sequences, and/or uneven data partition in <br/>distributed training.</li><ul><li>如果设置了<code>minibatch_size=cntk.learners.IGNORE</code>，那么我们将会恢复then we <br/>recover the behavior in the literature: The mean gradient of the whole <br/>minibatch contributes to the model update with the same learning rate. <br/>The behavior of ignoring the data minibatch data size is the same as <br/>specifying a minibatch size for the learner when the data minibatch size<br/> equals to the specified minibatch size.</li></ul></ul><p>在新版本的API中：</p><ul><li>为了使模型的更新保持与传统机器学习论文一致，我们可以通过以下设置指定学习器： <code>minibatch_size=cntk.learners.IGNORE</code>，使其忽略minibatch size，比如：<br/><code>python<br/>sgd_learner_m = C.sgd(z.parameters, lr = 0.5, minibatch_size = C.learners.IGNORE)</code> </li></ul><p><b>注意</b></p><ul><li>To enable CNTK specific techniques which apply the same learning <br/>rate to the mean gradient of every N samples regardless of the actual <br/>minibatch sizes, 我们可以通过以下设置指定学习器 <code>minibatch_size=N</code>，比如我们设置 <code>minibatch_size=2</code>,<br/><code>python<br/>sgd_learner_s2 = C.sgd(z.parameters, lr = 0.5, minibatch_size = 2)</code></li></ul><p>Regarding the <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%3Fhighlight%3Dlearning_rate_schedule%23cntk.learners.momentum_schedule\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">momentum_schedule</a> of the learners <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.fsadagrad\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">FSAdaGrad</a>,<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.adam\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Adam</a>,<a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.momentum_sgd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">MomentumSGD</a>,<br/>以及 <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.learners.html%23cntk.learners.nesterov\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Nesterov</a>, it can be specified in a similar way. Let&#39;s use <code>momentum_sgd</code> as an example: </p><p>Python </p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">momentum_sgd</span><span class=\"p\">(</span><span class=\"n\">parameters</span><span class=\"p\">,</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"nb\">float</span> <span class=\"ow\">or</span> <span class=\"nb\">list</span> <span class=\"n\">of</span> <span class=\"n\">floats</span><span class=\"p\">,</span> <span class=\"n\">momentum</span><span class=\"o\">=</span><span class=\"nb\">float</span> <span class=\"ow\">or</span> <span class=\"nb\">list</span> <span class=\"n\">of</span> <span class=\"n\">floats</span><span class=\"p\">,</span>\n             <span class=\"n\">minibatch_size</span><span class=\"o\">=</span><span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">learners</span><span class=\"o\">.</span><span class=\"n\">IGNORE</span><span class=\"p\">,</span> <span class=\"n\">epoch_size</span><span class=\"o\">=</span><span class=\"n\">epoch_size</span><span class=\"p\">)</span>\n<span class=\"n\">momentum_sgd</span><span class=\"p\">(</span><span class=\"n\">parameters</span><span class=\"p\">,</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"nb\">float</span> <span class=\"ow\">or</span> <span class=\"nb\">list</span> <span class=\"n\">of</span> <span class=\"n\">floats</span><span class=\"p\">,</span> <span class=\"n\">momentum</span><span class=\"o\">=</span><span class=\"nb\">float</span> <span class=\"ow\">or</span> <span class=\"nb\">list</span> <span class=\"n\">of</span> <span class=\"n\">floats</span><span class=\"p\">,</span>\n             <span class=\"n\">minibatch_size</span><span class=\"o\">=</span><span class=\"n\">N</span><span class=\"p\">,</span> <span class=\"n\">epoch_size</span><span class=\"o\">=</span><span class=\"n\">epoch_size</span><span class=\"p\">)</span>\n</code></pre></div><p>与<code>learning_rate_schedule</code>类似，参数通过以下相同的方式被解释：</p><ul><li>当设置 <code>minibatch_size=C.learners.IGNORE</code>时， 衰减<code>momentum=beta</code><br/>被应用于mean gradient of the whole minibatch regardless of <br/>its size. For example, regardless of the minibatch size either be N or <br/>2N (or any size), the mean gradient of such a minibatch will have same <br/>decay factor beta.</li><li>当设置 <code>minibatch_size=N</code>时，衰减 <code>momentum=beta</code>被应用于每N实例的平均梯度上。一个例子是，当minibatches的大小为N、2N、3N或者kN时，将会存在β的衰减，分别为pow(β,2)、pow(β,3)以及pow(β,k)。衰减取决于真实的minibatch大小，其比例是指数级的。</li></ul><h2>新的C#/.NET API允许用户构建和训练网络</h2><h2>对于网络的训练现已支持C#/.NET API</h2><p>我们不但添加了对于C#的CNTK评估API，对于.NET开发者来说，得益于CNTK强大的性能，还已经拥有了一套从构建评估到预测网络的完整体验。你可以直接从CNTK的源代码来了解一个DNN网络是如何训练并且评估的。一些新的特性包括：</p><h2>基础的C#训练API</h2><p>在这个版本中，有超过100个基础的函数能够帮助你去构建一个计算网络。这些函数包括Sigmoid、Tanh、ReLU、Plus、Minus、Convolution（卷积）、Pooling（池化）、BatchNormalization（批量归一化）等。</p><p>我们以一个逻辑回归损失函数作为示例：</p><p>C#</p><div class=\"highlight\"><pre><code class=\"language-csharp\"><span class=\"n\">Function</span> <span class=\"n\">z</span> <span class=\"p\">=</span> <span class=\"n\">CNTKLib</span><span class=\"p\">.</span><span class=\"n\">Times</span><span class=\"p\">(</span><span class=\"n\">weightParam</span><span class=\"p\">,</span> <span class=\"n\">input</span><span class=\"p\">)</span> <span class=\"p\">+</span> <span class=\"n\">biasParam</span><span class=\"p\">;</span>\n<span class=\"n\">Function</span> <span class=\"n\">loss</span> <span class=\"p\">=</span> <span class=\"n\">CNTKLib</span><span class=\"p\">.</span><span class=\"n\">CrossEntropyWithSoftmax</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">labelVariable</span><span class=\"p\">);</span>\n</code></pre></div><h2>使用独立的CNTK函数构建DNN网络</h2><p>可以使用独立的函数结合以构建DNN网络。我们通过构建一个ResNet节点以举例：</p><p>C# </p><div class=\"highlight\"><pre><code class=\"language-csharp\"><span class=\"n\">Function</span> <span class=\"n\">conv</span> <span class=\"p\">=</span> <span class=\"n\">CNTKLib</span><span class=\"p\">.</span><span class=\"n\">Pooling</span><span class=\"p\">(</span><span class=\"n\">CNTKLib</span><span class=\"p\">.</span><span class=\"n\">Convolution</span><span class=\"p\">(</span><span class=\"n\">convParam</span><span class=\"p\">,</span> <span class=\"n\">input</span><span class=\"p\">),</span>\n                                <span class=\"n\">PoolingType</span><span class=\"p\">.</span><span class=\"n\">Average</span><span class=\"p\">,</span> <span class=\"n\">poolingWindowShape</span><span class=\"p\">);</span>\n<span class=\"n\">Function</span> <span class=\"n\">resNetNode</span> <span class=\"p\">=</span> <span class=\"n\">CNTKLib</span><span class=\"p\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"n\">CNTKLib</span><span class=\"p\">.</span><span class=\"n\">Plus</span><span class=\"p\">(</span><span class=\"n\">conv</span><span class=\"p\">,</span> <span class=\"n\">input</span><span class=\"p\">));</span>\n</code></pre></div><h2>批处理支持</h2><p>我们提供了MinibatchSource和MinibacthData以有效地提升数据的加载和批处理能力。</p><h2>训练支持</h2><p>我们支持在DNN网络中常用的多种随机梯度下降方法的优化：MomentumSGDLearner、AdamLearner、AdaGradLearner等。我们以训练一个包含ADAM随机优化器的模型举例： </p><p>C# </p><div class=\"highlight\"><pre><code class=\"language-csharp\"><span class=\"kt\">var</span> <span class=\"n\">parameterLearners</span> <span class=\"p\">=</span> <span class=\"k\">new</span> <span class=\"n\">List</span><span class=\"p\">&lt;</span><span class=\"n\">Learner</span><span class=\"p\">&gt;()</span> <span class=\"p\">{</span> <span class=\"n\">Learner</span><span class=\"p\">.</span><span class=\"n\">AdamLearner</span><span class=\"p\">(</span><span class=\"n\">classifierOutput</span><span class=\"p\">.</span><span class=\"n\">Parameters</span><span class=\"p\">(),</span>\n                                                                  <span class=\"n\">learningRate</span><span class=\"p\">,</span> <span class=\"n\">momentum</span><span class=\"p\">)</span> <span class=\"p\">};</span>\n<span class=\"kt\">var</span> <span class=\"n\">trainer</span> <span class=\"p\">=</span> <span class=\"n\">Trainer</span><span class=\"p\">.</span><span class=\"n\">CreateTrainer</span><span class=\"p\">(</span><span class=\"n\">classifierOutput</span><span class=\"p\">,</span> <span class=\"n\">trainingLoss</span><span class=\"p\">,</span>\n                                    <span class=\"n\">prediction</span><span class=\"p\">,</span> <span class=\"n\">parameterLearners</span><span class=\"p\">);</span>\n</code></pre></div><p>关于训练部分的示例涵盖了DNN的以下使用情景：</p><ul><li>一个hello-world 示例，用来展示使用C# API的有关逻辑回归模型的训练和评估的过程： <br/><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/master/Examples/TrainingCSharp/Common/LogisticRegression.cs\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/Microsoft/CN</span><span class=\"invisible\">TK/tree/master/Examples/TrainingCSharp/Common/LogisticRegression.cs</span><span class=\"ellipsis\"></span></a></li><li>对于MNIST数据集的图像分类示例（基于卷积神经网络）：<br/><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/master/Examples/TrainingCSharp/Common/MNISTClassifier.cs\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/Microsoft/CN</span><span class=\"invisible\">TK/tree/master/Examples/TrainingCSharp/Common/MNISTClassifier.cs</span><span class=\"ellipsis\"></span></a></li><li>基于C# API构建、训练和评估ResNet模型：<br/><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/master/Examples/TrainingCSharp/Common/CifarResNetClassifier.cs\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/Microsoft/CN</span><span class=\"invisible\">TK/tree/master/Examples/TrainingCSharp/Common/CifarResNetClassifier.cs</span><span class=\"ellipsis\"></span></a></li><li>使用C#/.NET API转移训练：<br/><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/master/Examples/TrainingCSharp/Common/TransferLearning.cs\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/Microsoft/CN</span><span class=\"invisible\">TK/tree/master/Examples/TrainingCSharp/Common/TransferLearning.cs</span><span class=\"ellipsis\"></span></a></li><li>使用C#/.NET API构建并训练LSTM序列分类器：<br/><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/master/Examples/TrainingCSharp/Common/LSTMSequenceClassifier.cs\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/Microsoft/CN</span><span class=\"invisible\">TK/tree/master/Examples/TrainingCSharp/Common/LSTMSequenceClassifier.cs</span><span class=\"ellipsis\"></span></a></li></ul><h2>对于CNTK的R语言-绑定</h2><p>对于可用于训练和评估的CNTK的R语言-绑定，将会以单独的仓库的形式很快发布。</p><h2>示例</h2><h2>基于Fast R-CNN和Faster R-CNN的物体检测</h2><ul><li>在快速R-CNN中支持bounding box回归。</li><li>添加了一篇指引：<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/Object-Detection-using-Faster-R-CNN\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">快速 R-CNN 物体检测</a> ；更新了一篇指引： <a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/Object-Detection-using-Fast-R-CNN\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">快速 R-CNN</a>。</li><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/master/Examples/Image/Detection\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">物体检测示例代码</a>现已允许选择不同的检测器，基础模型以及数据集。</li></ul><h2>新的C++示例</h2><p>我们添加了以下新C++示例：<code><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/release/2.2/Examples/Evaluation/CNTKLibraryCPPEvalCPUOnlyExamples\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">CNTKLibraryCPPEvalCPUOnlyExamples</a></code> 以及 <code><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/release/2.2/Examples/Evaluation/CNTKLibraryCPPEvalGPUExamples\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">CNTKLibraryCPPEvalGPUExamples</a></code>。它们提供了有关如何在CPU或者GPU计算机上使用C++版本的CNTK库的相关指导。另一个新添加的示例是<a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/release/2.2/Examples/Evaluation/UWPImageRecognition\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">UWPImageRecognition</a>，它给出了使用UWP版本CNTK进行模型评估的示例。</p><h2>新的C#示例</h2><p>我们添加了用于异步评估的示例：<code><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/release/2.2/Examples/Evaluation/CNTKLibraryCSEvalCPUOnlyExamples/CNTKLibraryCSEvalExamples.cs\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">EvaluationSingleImageAsync()</a></code>。需要注意的一点是，对于C# API版本的CNTK来说，目前还没有一个对于Evaluate()的异步方法，这是因为评估操作是一步CPU操作（详情请参考 <a href=\"https://link.zhihu.com/?target=https%3A//blogs.msdn.microsoft.com/pfxteam/2012/03/24/should-i-expose-asynchronous-wrappers-for-synchronous-methods/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这篇文章</a>）。然而，it is desired to run evaluation asynchronously in some use cases, e.g. offloading for responsiveness, we<br/> show in the example <code><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/release/2.2/Examples/Evaluation/CNTKLibraryCSEvalCPUOnlyExamples/CNTKLibraryCSEvalExamples.cs\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">EvaluationSingleImageAsync()</a></code> how to achieve that by using the extension method <code><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/release/2.2/Examples/Evaluation/CNTKLibraryCSEvalCPUOnlyExamples/CNTKExtensions.cs\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">EvaluateAsync()</a></code>. 请在<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/CNTK-Library-Evaluation-on-Windows%23using-cnet-managed-api\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">使用 C#/.NET API</a>页面中的<i>运行异步评估</i>段落以查看详情。</p><ul><li>评估 intermediate 层: <code><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/release/2.2/Examples/Evaluation/CNTKLibraryCSEvalCPUOnlyExamples/CNTKLibraryCSEvalExamples.cs\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">EvaluateIntermediateLayer()</a></code></li><li>对于多节点的输出评估： <code><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/release/2.2/Examples/Evaluation/CNTKLibraryCSEvalCPUOnlyExamples/CNTKLibraryCSEvalExamples.cs\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">EvaluateCombinedOutputs()</a></code></li></ul><h2>功能</h2><h2>噪声对比评估节点</h2><p>这项功能提供了一种内置的损失函数，用于在为非常大型的网络中进行训练。如果你的任务是在千万量级词典的情况下预测下一个单词的信息，那么这个功能将很有用。</p><p>为了利用这个特性，你需要将你的损失（loss）定义为：</p><p>Python </p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">nce_loss</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"p\">,</span> <span class=\"n\">biases</span><span class=\"p\">,</span> <span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">noise_distribution</span><span class=\"p\">)</span></code></pre></div><p>每当你完成训练过程，你可以使用类似以下过程进行预测</p><p>Python </p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">logits</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">times</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,),</span> <span class=\"mi\">1</span><span class=\"p\">))</span> <span class=\"o\">+</span> <span class=\"n\">biases</span></code></pre></div><p><b>注意</b></p><p>噪音对比评估损失无法帮助减少噪音，它仅用于训练。</p><h2>增强的AttentionModel</h2><p>在AttentionModel层的一处bug已经被修复，并且我们依据以下论文进行了完全实现：</p><blockquote>Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau et. al.) </blockquote><p>因此，在AttentionModel中的参数<code>attention_span</code> 和 <code>attention_axis</code>已经被<b>摒弃</b>。它们应该由默认值代替，They should be left to their default values, in which case the attention is computed over the whole sequenceand the output is a sequence of vectors of the same dimension as the first argument over the axis of the second argument.<br/>This also leads to substantial speed gains (our CNTK 204 Tutorial now runs more than 2x faster). </p><h2>对于embedded layer的Aggregation on sparse gradient</h2><p>This change saves costly conversion from sparse to dense before gradient <br/>aggregation when embedding vocabulary size is huge. It is currently <br/>enabled for GPU build when training on GPU with non-quantized data <br/>parallel SGD. For other distributed learners and CPU build, it is <br/>disabled by default. It can be manually turned off in python by calling <code>cntk.cntk_py.use_sparse_gradient_aggregation_in_data_parallel_sgd(False)</code>.<br/> Note that for a rare case of running distributed training with CPU <br/>device on a GPU build, you need to manually turn it off to avoid <br/>unimplemented exception </p><h2>在C++中卷积操作使用较少的秩以处理一维数据</h2><p>现在， <code>convolution</code> 以及 <code>convolution_transpose</code> 支持不含channel或者depth dimension的数据，只需将<code>reductionRank</code>设置为0（默认为1）。我们进行这个更改是为了对于地理信息数据进行更好地处理，而无需将其预先进行没有意义的维度增加。</p><h2>Dilated convolution（仅GPU）</h2><p>我们添加了GPU上运行dilation convolution的支持，可用于BrainScript, C++ 以及 Python API。 Dilation convolution effectively increase the kernel size, without actually requiring a big kernel. To use dilation convolution you need at least cuDNN 6.0. Dilated <br/>convolution improved the result of image segmentation in <a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1511.07122.pdf\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">arxiv.org/pdf/1511.0712</span><span class=\"invisible\">2.pdf</span><span class=\"ellipsis\"></span></a>, in addition it exponentially increase the receptive field without increasing the required memory. One thing to note is there is currently no implementation of dilated convolution on CPU, therefore you cannot evaluate a model containing dilated convolution on CPU. </p><h2>对于卷积的Free static axes支持</h2><ul><li>我们添加了卷积过程中的free static axes <code>FreeDimension</code>支持。 This allows changing the input tensor size from minibatch to minibatch. For example, in case of CNNs this allows each minibatch to potentially have a different underlying image size. Similar support has also been enabled for pooling node.</li><li>要注意，快速R-CNN对于物体检测的示例并没有对于卷积操作进行Note that the Faster R-CNN example for object detection does not yet leverage the free static axes support for convolution (i.e., still scales and pads input images to a fixed size). This example is being updated to use free static axes for arbitrary input image sizes, and is targeted for next release.</li></ul><h2>Deterministic Pooling</h2><p>现在称作<code>cntk.debug.force_deterministic()</code>，可用于最大和平均的Pooling deterministic。这个特性需要cuDNN 6或者以上版本。 </p><h2>向Python API 添加了 Crop 节点</h2><p>为了支持针对部分图像的分割网络，我们在C++和Python API中添加了Crop节点。Crop节点将Crop node crops its first input along spatial axes so that the result matches the spatial size of its second (reference) input. All non-spatial dimensions are unchanged. Crop offsets can be specified directly, or computed automatically, by traversing the network, and matching centers of receptive fields between activations in the two inputs </p><h2>性能</h2><h2>Intel MKL更新在AlexNetIntel（CPU）上获得了大约2倍的性能提升</h2><p>这项工作将在下一个版本中发布，目前仍在进行一些测试。</p><h2>Keras 与 Tensorboard</h2><h2>对于基于CNTK的Keras的多GPU支持</h2><p>我们发布了一篇新文章，用来详细解释如何使用基于CNTK的Keras进行并行化的训练，详情请见<a href=\"https://link.zhihu.com/?target=http%3A//docs.microsoft.com/en-us/cognitive-toolkit/Using-CNTK-MultiGPU-Support-with-Keras\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这篇文章</a>。</p><h2>对于CNTK的Tensorboard图像支持</h2><p>我们添加了针对TensorBoard的图像特性。现在，CNTK的使用者可以使用TensorBoard来显示图像。更多的示例和细节请见<a href=\"https://link.zhihu.com/?target=http%3A//docs.microsoft.com/en-us/cognitive-toolkit/Using-TensorBoard-for-Visualization\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这篇文章</a>。</p>", 
            "topic": [
                {
                    "tag": "CNTK", 
                    "tagLink": "https://api.zhihu.com/topics/20046732"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/28314924", 
            "userName": "王万霖", 
            "userLink": "https://www.zhihu.com/people/b8f13b7ce876ce5f99a47ce6cd2956f0", 
            "upvote": 4, 
            "title": "支持UWP！微软发布CNTK2.1版本", 
            "content": "<p>2017年07月31日，微软CNTK团队<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/ReleaseNotes/CNTK_2_1_Release_Notes\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">发布</a>了微软认知工具集（CNTK）的2.1版本。这距离上一个版本（2.0）发布有66天。微软官方发布了CNTK 2.1版本的发行说明：</p><p>本文最后更新于2017年11月06日，最近一次更新包含了较小的修复和改进</p><p>新版本带来的最新特性有：</p><ul><li>cuDNN 6.0 整合</li><li>支持<b>通用Windows平台</b> (UWP)</li><li>改进了CNTK作为Keras后端的表现</li><li>性能提升</li><li>全新的手册、指引和示例页</li><li>Bug修复</li></ul><h2>不向后兼容的更改</h2><p>这一个发布版本存在以下<b>不向后兼容</b>的更改：</p><ul><li>更新感兴趣区域（ROI）的池化功能，以匹配Caffe的实现。以下部分进行了显著改进：</li><ul><li>参数 pooling_type 、 spatial_scale 已经被添加进来，并且</li><li>对于图像感兴趣区域的坐标参数已更改为绝对于原图像的坐标系</li></ul><li>为了从头文件中去除一个static变量，C++ API. NDShape::Unknown 已经更改为 NDShape::Unknown() 。</li></ul><h2>NVIDIA cuDNN 6.0 整合</h2><p>Windows和Linux平台上CNTK 2.1的GPU版本已经移植到 <a href=\"https://link.zhihu.com/?target=https%3A//developer.nvidia.com/cudnn\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">NVIDIA CUDA Deep Neural Network library (cuDNN) v.6.0</a>。这项改进导致CNTK处理诸如ResNet 50的速度提升了大约10%。</p><p>如果从源代码编译CNTK，你现在应该一同安装NVIDIA cuDNN6.0，它现在已作为Windows和Linux平台构建和测试CNTK的默认组件。</p><h2>CNTK Evaluation 库：支持通用Windows平台(UWP)</h2><p>从该版本开始，我们开始支持<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/windows/uwp/get-started/whats-a-uwp\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">通用Windows平台 (UWP)</a>。新的CNTK NuGet包（<a href=\"https://link.zhihu.com/?target=http%3A//www.nuget.org/packages/CNTK.UWP.CPUOnly\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">CNTK以及UWP CPU-Only Build</a>）现已可供下载。 详见 <a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/CNTK-Library-Evaluation-on-UWP\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Model Evaluation on Universal Windows Platform</a>。为了构建CNTK UWP的评估版本，请参考<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/Setup-UWP-Build-on-Windows\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">此处</a>的描述。</p><h2>作为Keras后端的CNTK</h2><p>2.1版本对于<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/Using-CNTK-with-Keras\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">用作Keras后端的CNTK</a>，有着以下提升：</p><ul><li>对于状态反馈神经网络（Stateful recurrent network）的支持</li><li>支持包含遮罩（mask）的反馈层</li><li>修正了批量规约层（batch normalization layer）存在的问题</li></ul><h2>性能提升</h2><ul><li>ResNet 50 性能提升（减少了训练阶段的memcpy和memset），单机训练的速度提升了约8%</li><li>在索引缓存（index caching）方面提升了CNTK读取器（reader）的性能</li><li>我们已经成功地测试了CNTK在大数据集基础上训练ResNet 50以及Inception V3的能力，并发表在<a href=\"https://link.zhihu.com/?target=https%3A//research.fb.com/publications/imagenet1kin1h/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">最近的论文</a>中。这证明了CNTK不仅能处理语音数据的能力，处理图像任务也同样优秀</li></ul><h2>新的手册、示例、指引和课程</h2><ul><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/release/2.1/Manual/Manual_How_to_train_using_declarative_and_imperative_API.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">How to train model using declarative and imperative API</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/release/2.1/Manual/Manual_How_to_create_user_minibatch_sources.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">How to create user minibatch sources</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/release/2.1/Manual/Manual_How_to_feed_data.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">How to feed data</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/release/2.1/Manual/Manual_How_to_debug.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Debugging CNTK programs</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/release/2.1/Manual/Manual_How_to_use_learners.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">How to use learners</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/release/2.1/Manual/Manual_How_to_write_a_custom_deserializer.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">How to write a custom deserializer</a></li></ul><h2>指引和示例</h2><ul><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/release/2.1/Tutorials/CNTK_208_Speech_Connectionist_Temporal_Classification.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Training Acoustic Model with Connectionist Temporal Classification (CTC) Criteria</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/release/2.1/Examples/ReinforcementLearning/FlappingBirdWithKeras\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Flapping Bird using Keras and Reinforcement Learning</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/release/2.1/Examples/Image/Detection/FasterRCNN\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Faster R-CNN object detection</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/Evaluate-a-model-in-an-Azure-WebApi\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Using CNTK V2 API in Azure WebAPI for model evaluation</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//cvpr2017.thecvf.com/program/tutorials\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">CVPR 2017</a> - July 26, 2017, Tutorial by <i>Emad Barsoum</i>, <i>Sayan Pathak</i> and <i>Cha Zhang</i>, Scalable Deep Learning with Microsoft Cognitive Toolkit. <a href=\"https://link.zhihu.com/?target=https%3A//www.cntk.ai/Tutorials/CVPR2017/CVPR_2017_Tutorial_final.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Presentation</a></li></ul><h2>课程</h2><p>关于 <a href=\"https://link.zhihu.com/?target=https%3A//www.edx.org/course/deep-learning-explained-microsoft-dat236x\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Deep Learning Explained</a> 的最新课程已经发布于 <a href=\"https://link.zhihu.com/?target=https%3A//www.edx.org/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">edX</a>. </p><h2>Bug修复</h2><p>2.1版本修复了以下Bugs：</p><ul><li>并行验证中的递归问题</li><li>在next_minibatch偶尔出现的引用问题</li><li>对于bptt的检查点</li></ul><h2>CNTK NuGet 包</h2><p>一个全新系列的 NuGet 包(2.1.0版本) 在这个版本中被发布，包含了最新的 <i>CNTK</i>版本，<i>UWP CPU-Only 构建</i> (请见上方“UWP支持”一节).</p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "CNTK", 
                    "tagLink": "https://api.zhihu.com/topics/20046732"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/28194607", 
            "userName": "王万霖", 
            "userLink": "https://www.zhihu.com/people/b8f13b7ce876ce5f99a47ce6cd2956f0", 
            "upvote": 4, 
            "title": "CNTK103B：在MNIST数据集上进行逻辑回归（暂缓翻译）", 
            "content": "<blockquote>我们假设你已经完成了CNTK 103 A部分的内容。In this tutorial we will build and train a Multinomial Logistic Regression model using the MNIST data. This notebook provides the recipe using Python APIs. If you are looking for this example in BrainScript, please look <u><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/tree/v2.0/Examples/Image/GettingStarted\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">here</a></u></blockquote><p>本文最后更新于2017年09月03日，最近一次更新包含了翻译。</p><p>大家好，这是我们 CNTK103 教程的第二部分（B）。</p><h2><b>简介</b></h2><p><b>问题：</b> <b>光学字符识别</b>（OCR）是研究的热点问题，并且有较高的自动化的需求。MNIST数据集是 The MNIST data comprises of hand-written digits with little background noise making it a nice dataset to create, experiment and learn deep learning models with reasonably small computing resources.</p><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-5e085aeeb48827dab07cd7dadbb143a4_b.png\" data-rawwidth=\"581\" data-rawheight=\"448\" class=\"origin_image zh-lightbox-thumb\" width=\"581\" data-original=\"https://pic1.zhimg.com/v2-5e085aeeb48827dab07cd7dadbb143a4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;581&#39; height=&#39;448&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"581\" data-rawheight=\"448\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"581\" data-original=\"https://pic1.zhimg.com/v2-5e085aeeb48827dab07cd7dadbb143a4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5e085aeeb48827dab07cd7dadbb143a4_b.png\"/></figure><p><b>Goal</b>: Our goal is to train a classifier that will identify the digits in the MNIST dataset.</p><p><b>Approach</b>: The same 5 stages we have used in the previous tutorial are applicable: Data reading, Data preprocessing, Creating a model, Learning the model parameters and Evaluating (a.k.a. testing/prediction) the model.</p><ul><li>Data reading: We will use the CNTK Text reader</li><li>Data preprocessing: Covered in part A (suggested extension section).</li></ul><p>Rest of the steps are kept identical to CNTK 102.</p><h2><b>逻辑回归</b></h2><p><u><a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Logistic_regression\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Logistic Regression</a></u> (LR) is a fundamental machine learning technique that uses a linear weighted combination of features and generates probability-based predictions of different classes.<br/> There are two basic forms of LR: <b>Binary LR</b> (with a single output that can predict two classes) and <b>multinomial LR</b> (with multiple outputs, each of which is used to predict a single class).</p><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic4.zhimg.com/v2-e054da9d52a208e351fb1af2f506b673_b.png\" data-rawwidth=\"497\" data-rawheight=\"385\" class=\"origin_image zh-lightbox-thumb\" width=\"497\" data-original=\"https://pic4.zhimg.com/v2-e054da9d52a208e351fb1af2f506b673_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;497&#39; height=&#39;385&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"497\" data-rawheight=\"385\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"497\" data-original=\"https://pic4.zhimg.com/v2-e054da9d52a208e351fb1af2f506b673_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e054da9d52a208e351fb1af2f506b673_b.png\"/></figure><p>In <b>Binary Logistic Regression</b> (see top of figure above), the input features are each scaled by an associated weight and summed together. The sum is passed through a squashing (aka activation) function and generates an output in [0,1]. This output value (which can be thought of as a probability) is then compared with a threshold (such as 0.5) to produce a binary label (0 or 1). This technique supports only classification problems with two output classes, hence the name binary LR. In the binary LR example shown above, the <u><a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Sigmoid_function\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">sigmoid</a></u> function is used as the squashing function.</p><p>In <b>Multinomial Linear Regression</b> (see bottom of figure above), 2 or more output nodes are used, one for each output class to be predicted. Each summation node uses its own set of weights to scale the input features and sum them together. Instead of passing the summed output of the weighted input features through a sigmoid squashing function, the output is often passed through a <u><a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Softmax_function\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">softmax</a></u> function (which in addition to squashing, like the sigmoid, the softmax normalizes each nodes&#39; output value using the sum of all unnormalized nodes). (Details in the context of MNIST image to follow)</p><p>In this tutorials, we will use multinomial LR for classifying the MNIST digits (0-9) using 10 output nodes (1 for each of our output classes).</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Import the relevant components</span>\n<span class=\"kn\">from</span> <span class=\"nn\">__future__</span> <span class=\"k\">import</span> <span class=\"n\">print_function</span> <span class=\"c1\"># Use a function definition from future version (say 3.x from 2.7 interpreter)</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.image</span> <span class=\"k\">as</span> <span class=\"nn\">mpimg</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">sys</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">cntk</span> <span class=\"k\">as</span> <span class=\"nn\">C</span>\n<span class=\"kn\">import</span> <span class=\"nn\">cntk.tests.test_utils</span>\n<span class=\"n\">cntk</span><span class=\"o\">.</span><span class=\"n\">tests</span><span class=\"o\">.</span><span class=\"n\">test_utils</span><span class=\"o\">.</span><span class=\"n\">set_device_from_pytest_env</span><span class=\"p\">()</span> <span class=\"c1\"># (only needed for our build system)</span>\n<span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">cntk_py</span><span class=\"o\">.</span><span class=\"n\">set_fixed_random_seed</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\"># fix the random seed so that LR examples are repeatable</span>\n\n<span class=\"o\">%</span><span class=\"n\">matplotlib</span> <span class=\"n\">inline</span></code></pre></div><p><b>初始化</b></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 定义数据的维度</span>\n<span class=\"n\">input_dim</span> <span class=\"o\">=</span> <span class=\"mi\">784</span>\n<span class=\"n\">num_output_classes</span> <span class=\"o\">=</span> <span class=\"mi\">10</span></code></pre></div><h2><b>读取数据</b></h2><p>In this tutorial we are using the MNIST data you have downloaded using CNTK_103A_MNIST_DataLoader notebook. The dataset has 60,000 training images and 10,000 test images with each image being 28 x 28 pixels. Thus the number of features is equal to 784 (= 28 x 28 pixels), 1 per pixel. The variable num_output_classes is set to 10 corresponding to the number of digits (0-9) in the dataset.</p><p>The data is in the following format:</p><div class=\"highlight\"><pre><code class=\"language-text\">|labels 0 0 0 1 0 0 0 0 0 0 |features 0 0 0 0 ... \n                                              (784 integers each representing a pixel)\n\n</code></pre></div><p>In this tutorial we are going to use the image pixels corresponding the integer stream named &#34;features&#34;. We define a create_reader function to read the training and test data using the <u><a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/pythondocs/cntk.io.html%3Fhighlight%3Dctfdeserializer%23cntk.io.CTFDeserializer\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">CTF deserializer</a></u>. The labels are <u><a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/One-hot\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">1-hot encoded</a></u>. Refer to CNTK 103A tutorial for data format visualizations.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file</span>\n<span class=\"k\">def</span> <span class=\"nf\">create_reader</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">,</span> <span class=\"n\">is_training</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">num_label_classes</span><span class=\"p\">):</span>\n\n    <span class=\"n\">labelStream</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">io</span><span class=\"o\">.</span><span class=\"n\">StreamDef</span><span class=\"p\">(</span><span class=\"n\">field</span><span class=\"o\">=</span><span class=\"s1\">&#39;labels&#39;</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"n\">num_label_classes</span><span class=\"p\">,</span> <span class=\"n\">is_sparse</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n    <span class=\"n\">featureStream</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">io</span><span class=\"o\">.</span><span class=\"n\">StreamDef</span><span class=\"p\">(</span><span class=\"n\">field</span><span class=\"o\">=</span><span class=\"s1\">&#39;features&#39;</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">is_sparse</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n    <span class=\"n\">deserailizer</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">io</span><span class=\"o\">.</span><span class=\"n\">CTFDeserializer</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">io</span><span class=\"o\">.</span><span class=\"n\">StreamDefs</span><span class=\"p\">(</span><span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">labelStream</span><span class=\"p\">,</span> <span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">featureStream</span><span class=\"p\">))</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">io</span><span class=\"o\">.</span><span class=\"n\">MinibatchSource</span><span class=\"p\">(</span><span class=\"n\">deserailizer</span><span class=\"p\">,</span>\n       <span class=\"n\">randomize</span> <span class=\"o\">=</span> <span class=\"n\">is_training</span><span class=\"p\">,</span> <span class=\"n\">max_sweeps</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">io</span><span class=\"o\">.</span><span class=\"n\">INFINITELY_REPEAT</span> <span class=\"k\">if</span> <span class=\"n\">is_training</span> <span class=\"k\">else</span> <span class=\"mi\">1</span><span class=\"p\">)</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Ensure the training and test data is generated and available for this tutorial.</span>\n<span class=\"c1\"># We search in two locations in the toolkit for the cached MNIST data set.</span>\n<span class=\"n\">data_found</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n\n<span class=\"k\">for</span> <span class=\"n\">data_dir</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"s2\">&#34;..&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;Examples&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;Image&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;DataSets&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;MNIST&#34;</span><span class=\"p\">),</span>\n                 <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"s2\">&#34;data&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;MNIST&#34;</span><span class=\"p\">)]:</span>\n    <span class=\"n\">train_file</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">data_dir</span><span class=\"p\">,</span> <span class=\"s2\">&#34;Train-28x28_cntk_text.txt&#34;</span><span class=\"p\">)</span>\n    <span class=\"n\">test_file</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">data_dir</span><span class=\"p\">,</span> <span class=\"s2\">&#34;Test-28x28_cntk_text.txt&#34;</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">isfile</span><span class=\"p\">(</span><span class=\"n\">train_file</span><span class=\"p\">)</span> <span class=\"ow\">and</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">isfile</span><span class=\"p\">(</span><span class=\"n\">test_file</span><span class=\"p\">):</span>\n        <span class=\"n\">data_found</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n        <span class=\"k\">break</span>\n\n<span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">data_found</span><span class=\"p\">:</span>\n    <span class=\"k\">raise</span> <span class=\"ne\">ValueError</span><span class=\"p\">(</span><span class=\"s2\">&#34;Please generate the data by completing CNTK 103 Part A&#34;</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;Data directory is </span><span class=\"si\">{0}</span><span class=\"s2\">&#34;</span><span class=\"o\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">data_dir</span><span class=\"p\">))</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">Data directory is ..\\Examples\\Image\\DataSets\\MNIST</code></pre></div><h2><b>创建模型</b></h2><p>A logistic regression (LR) network is a simple building block that has been effectively powering many ML applications in the past decade. The figure below summarizes the model in the context of the MNIST data.</p><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic2.zhimg.com/v2-63ba58c9fac1d7774b50be84642c6919_b.png\" data-rawwidth=\"1769\" data-rawheight=\"885\" class=\"origin_image zh-lightbox-thumb\" width=\"1769\" data-original=\"https://pic2.zhimg.com/v2-63ba58c9fac1d7774b50be84642c6919_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1769&#39; height=&#39;885&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1769\" data-rawheight=\"885\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1769\" data-original=\"https://pic2.zhimg.com/v2-63ba58c9fac1d7774b50be84642c6919_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-63ba58c9fac1d7774b50be84642c6919_b.png\"/></figure><p>LR is a simple linear model that takes as input, a vector of numbers describing the properties of what we are classifying (also known as a feature vector, <img src=\"https://www.zhihu.com/equation?tex=%5Cbf+%5Cvec%7Bx%7D\" alt=\"\\bf \\vec{x}\" eeimg=\"1\"/> , the pixels in the input MNIST digit image) and emits the <i>evidence</i> ( <img src=\"https://www.zhihu.com/equation?tex=z\" alt=\"z\" eeimg=\"1\"/> ). For each of the 10 digits, there is a vector of weights corresponding to the input pixels as show in the figure. These 10 weight vectors define the weight matrix (<img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BW%7D\" alt=\"\\bf{W}\" eeimg=\"1\"/> ) with dimension of 10 x 784. Each feature in the input layer is connected with a summation node by a corresponding weight <img src=\"https://www.zhihu.com/equation?tex=w\" alt=\"w\" eeimg=\"1\"/> (individual weight values from the <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BW%7D\" alt=\"\\bf{W}\" eeimg=\"1\"/> matrix). Note there are 10 such nodes, 1 corresponding to each digit to be classified.</p><p>The first step is to compute the evidence for an observation.</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cvec%7Bz%7D+%3D+%5Ctextbf%7BW%7D+%5Cbf+%5Cvec%7Bx%7D%5ET+%2B+%5Cvec%7Bb%7D\" alt=\"\\vec{z} = \\textbf{W} \\bf \\vec{x}^T + \\vec{b}\" eeimg=\"1\"/></p><p>where <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BW%7D\" alt=\"\\bf{W}\" eeimg=\"1\"/> is the weight matrix of dimension 10 x 784 and <img src=\"https://www.zhihu.com/equation?tex=%5Cvec%7Bb%7D\" alt=\"\\vec{b}\" eeimg=\"1\"/> is known as the <i>bias</i> vector with lenght 10, one for each digit.</p><p>The evidence (</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cvec%7Bz%7D\" alt=\"\\vec{z}\" eeimg=\"1\"/> ) is not squashed (hence no activation). Instead the output is normalized using a <u><a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Softmax_function\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">softmax</a></u> function such that all the outputs add up to a value of 1, thus lending a probabilistic iterpretation to the prediction. In CNTK, we use the softmax operation that is combined with the cross entropy error function.</p><p>Network input and output:</p><ul><li><b>input</b> variable (a key CNTK concept):An <b>input</b> variable is a container in which we fill different observations in this case image pixels during model learning (a.k.a.training) and model evaluation (a.k.a. testing). Thus, the shape of the input must match the shape of the data that will be provided. For example, when data are images each of height 10 pixels and width 5 pixels, the input feature dimension will be 50 (representing the total number of image pixels). More on data and their dimensions to appear in separate tutorials.</li></ul><p><b>Question</b> What is the input dimension of your chosen model? This is fundamental to our understanding of variables in a network or model representation in CNTK.</p><p>Network input and output:</p><ul><li><b>input</b> variable (a key CNTK concept):An <b>input</b> variable is a container in which we fill different observations in this case image pixels during model learning (a.k.a.training) and model evaluation (a.k.a. testing). Thus, the shape of the input must match the shape of the data that will be provided. For example, when data are images each of height 10 pixels and width 5 pixels, the input feature dimension will be 50 (representing the total number of image pixels). More on data and their dimensions to appear in separate tutorials.</li></ul><p><b>Question</b> What is the input dimension of your chosen model? This is fundamental to our understanding of variables in a network or model representation in CNTK.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"nb\">input</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">input_variable</span><span class=\"p\">(</span><span class=\"n\">input_dim</span><span class=\"p\">)</span>\n<span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">input_variable</span><span class=\"p\">(</span><span class=\"n\">num_output_classes</span><span class=\"p\">)</span></code></pre></div><h2><b>线性回归网络构建</b></h2><p>The CNTK Layers module provides a Dense function that creates a fully connected layer which performs the above operations of weighted input summing and bias addition.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"k\">def</span> <span class=\"nf\">create_model</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">):</span>\n    <span class=\"k\">with</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">default_options</span><span class=\"p\">(</span><span class=\"n\">init</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">glorot_uniform</span><span class=\"p\">()):</span>\n        <span class=\"n\">r</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"n\">num_output_classes</span><span class=\"p\">,</span> <span class=\"n\">activation</span> <span class=\"o\">=</span> <span class=\"kc\">None</span><span class=\"p\">)(</span><span class=\"n\">features</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">r</span></code></pre></div><p><img src=\"https://www.zhihu.com/equation?tex=z\" alt=\"z\" eeimg=\"1\"/> will be used to represent the output of a network.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Scale the input to 0-1 range by dividing each pixel by 255.</span>\n<span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">create_model</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"o\">/</span><span class=\"mf\">255.0</span><span class=\"p\">)</span></code></pre></div><h2><b>Learning model parameters</b></h2><p>Same as the previous tutorial, we use the softmax function to map the accumulated evidences or activations to a probability distribution over the classes (Details of the <u><a href=\"https://link.zhihu.com/?target=http%3A//cntk.ai/pythondocs/cntk.ops.html%23cntk.ops.softmax\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">softmax function</a></u> and other <u><a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/Brainscript-Activation-Functions\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">activation</a></u> functions).</p><h2><b>Training</b></h2><p>Similar to CNTK 102, we use minimize the cross-entropy between the label and predicted probability by the network. If this terminology sounds strange to you, please refer to the CNTK 102 for a refresher.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">cross_entropy_with_softmax</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">)</span></code></pre></div><h2><b>Evaluation</b></h2><p>In order to evaluate the classification, one can compare the output of the network which for each observation emits a vector of evidences (can be converted into probabilities using softmax functions) with dimension equal to number of classes.</p><div class=\"highlight\"><pre><code class=\"language-text\">label_error = C.classification_error(z, label)</code></pre></div><h2><b>Configure training</b></h2><p>The trainer strives to reduce the loss function by different optimization approaches, <u><a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Stochastic_gradient_descent\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Stochastic Gradient Descent</a></u> (sgd) being one of the most popular one. Typically, one would start with random initialization of the model parameters. The sgd optimizer would calculate the loss or error between the predicted label against the corresponding ground-truth label and using <u><a href=\"https://link.zhihu.com/?target=http%3A//www.statisticsviews.com/details/feature/5722691/Getting-to-the-Bottom-of-Regression-with-Gradient-Descent.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">gradient-decent</a></u>generate a new set model parameters in a single iteration.</p><p>The aforementioned model parameter update using a single observation at a time is attractive since it does not require the entire data set (all observation) to be loaded in memory and also requires gradient computation over fewer datapoints, thus allowing for training on large data sets. However, the updates generated using a single observation sample at a time can vary wildly between iterations. An intermediate ground is to load a small set of observations and use an average of the loss or error from that set to update the model parameters. This subset is called a <i>minibatch</i>.</p><p>With minibatches, we often sample observation from the larger training dataset. We repeat the process of model parameters update using different combination of training samples and over a period of time minimize the loss (and the error). When the incremental error rates are no longer changing significantly or after a preset number of maximum minibatches to train, we claim that our model is trained.</p><p>One of the key optimization parameter is called the learning_rate. For now, we can think of it as a scaling factor that modulates how much we change the parameters in any iteration. We will be covering more details in later tutorial. With this information, we are ready to create our trainer.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Instantiate the trainer object to drive the model training</span>\n<span class=\"n\">learning_rate</span> <span class=\"o\">=</span> <span class=\"mf\">0.2</span>\n<span class=\"n\">lr_schedule</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">learning_rate_schedule</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">UnitType</span><span class=\"o\">.</span><span class=\"n\">minibatch</span><span class=\"p\">)</span>\n<span class=\"n\">learner</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">sgd</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">,</span> <span class=\"n\">lr_schedule</span><span class=\"p\">)</span>\n<span class=\"n\">trainer</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">Trainer</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"n\">label_error</span><span class=\"p\">),</span> <span class=\"p\">[</span><span class=\"n\">learner</span><span class=\"p\">])</span></code></pre></div><p>First let us create some helper functions that will be needed to visualize different functions associated with training.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Define a utility function to compute the moving average sum.</span>\n<span class=\"c1\"># A more efficient implementation is possible with np.cumsum() function</span>\n<span class=\"k\">def</span> <span class=\"nf\">moving_average</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span> <span class=\"n\">w</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"n\">a</span><span class=\"p\">[:]</span>    <span class=\"c1\"># Need to send a copy of the array</span>\n    <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">val</span> <span class=\"k\">if</span> <span class=\"n\">idx</span> <span class=\"o\">&lt;</span> <span class=\"n\">w</span> <span class=\"k\">else</span> <span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">[(</span><span class=\"n\">idx</span><span class=\"o\">-</span><span class=\"n\">w</span><span class=\"p\">):</span><span class=\"n\">idx</span><span class=\"p\">])</span><span class=\"o\">/</span><span class=\"n\">w</span> <span class=\"k\">for</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">val</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)]</span>\n\n\n<span class=\"c1\"># Defines a utility that prints the training progress</span>\n<span class=\"k\">def</span> <span class=\"nf\">print_training_progress</span><span class=\"p\">(</span><span class=\"n\">trainer</span><span class=\"p\">,</span> <span class=\"n\">mb</span><span class=\"p\">,</span> <span class=\"n\">frequency</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">):</span>\n    <span class=\"n\">training_loss</span> <span class=\"o\">=</span> <span class=\"s2\">&#34;NA&#34;</span>\n    <span class=\"n\">eval_error</span> <span class=\"o\">=</span> <span class=\"s2\">&#34;NA&#34;</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">mb</span><span class=\"o\">%</span><span class=\"n\">frequency</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n        <span class=\"n\">training_loss</span> <span class=\"o\">=</span> <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">previous_minibatch_loss_average</span>\n        <span class=\"n\">eval_error</span> <span class=\"o\">=</span> <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">previous_minibatch_evaluation_average</span>\n        <span class=\"k\">if</span> <span class=\"n\">verbose</span><span class=\"p\">:</span> \n            <span class=\"nb\">print</span> <span class=\"p\">(</span><span class=\"s2\">&#34;Minibatch: </span><span class=\"si\">{0}</span><span class=\"s2\">, Loss: </span><span class=\"si\">{1:.4f}</span><span class=\"s2\">, Error: </span><span class=\"si\">{2:.2f}</span><span class=\"s2\">%&#34;</span><span class=\"o\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">mb</span><span class=\"p\">,</span> <span class=\"n\">training_loss</span><span class=\"p\">,</span> <span class=\"n\">eval_error</span><span class=\"o\">*</span><span class=\"mi\">100</span><span class=\"p\">))</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">mb</span><span class=\"p\">,</span> <span class=\"n\">training_loss</span><span class=\"p\">,</span> <span class=\"n\">eval_error</span></code></pre></div><h2><b>Run the trainer</b></h2><p>We are now ready to train our fully connected neural net. We want to decide what data we need to feed into the training engine.</p><p>In this example, each iteration of the optimizer will work on minibatch_size sized samples. We would like to train on all 60000 observations. Additionally we will make multiple passes through the data specified by the variable num_sweeps_to_train_with. With these parameters we can proceed with training our simple feed forward network.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Initialize the parameters for the trainer</span>\n<span class=\"n\">minibatch_size</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>\n<span class=\"n\">num_samples_per_sweep</span> <span class=\"o\">=</span> <span class=\"mi\">60000</span>\n<span class=\"n\">num_sweeps_to_train_with</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>\n<span class=\"n\">num_minibatches_to_train</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">num_samples_per_sweep</span> <span class=\"o\">*</span> <span class=\"n\">num_sweeps_to_train_with</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">minibatch_size</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Create the reader to training data set</span>\n<span class=\"n\">reader_train</span> <span class=\"o\">=</span> <span class=\"n\">create_reader</span><span class=\"p\">(</span><span class=\"n\">train_file</span><span class=\"p\">,</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Map the data streams to the input and labels.</span>\n<span class=\"n\">input_map</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"n\">label</span>  <span class=\"p\">:</span> <span class=\"n\">reader_train</span><span class=\"o\">.</span><span class=\"n\">streams</span><span class=\"o\">.</span><span class=\"n\">labels</span><span class=\"p\">,</span>\n    <span class=\"nb\">input</span>  <span class=\"p\">:</span> <span class=\"n\">reader_train</span><span class=\"o\">.</span><span class=\"n\">streams</span><span class=\"o\">.</span><span class=\"n\">features</span>\n<span class=\"p\">}</span> \n\n<span class=\"c1\"># Run the trainer on and perform model training</span>\n<span class=\"n\">training_progress_output_freq</span> <span class=\"o\">=</span> <span class=\"mi\">500</span>\n\n<span class=\"n\">plotdata</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">:[],</span> <span class=\"s2\">&#34;loss&#34;</span><span class=\"p\">:[],</span> <span class=\"s2\">&#34;error&#34;</span><span class=\"p\">:[]}</span>\n\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">num_minibatches_to_train</span><span class=\"p\">)):</span>\n\n    <span class=\"c1\"># Read a mini batch from the training data file</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">reader_train</span><span class=\"o\">.</span><span class=\"n\">next_minibatch</span><span class=\"p\">(</span><span class=\"n\">minibatch_size</span><span class=\"p\">,</span> <span class=\"n\">input_map</span> <span class=\"o\">=</span> <span class=\"n\">input_map</span><span class=\"p\">)</span>\n\n    <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">train_minibatch</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n    <span class=\"n\">batchsize</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">print_training_progress</span><span class=\"p\">(</span><span class=\"n\">trainer</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">training_progress_output_freq</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"p\">(</span><span class=\"n\">loss</span> <span class=\"o\">==</span> <span class=\"s2\">&#34;NA&#34;</span> <span class=\"ow\">or</span> <span class=\"n\">error</span> <span class=\"o\">==</span><span class=\"s2\">&#34;NA&#34;</span><span class=\"p\">):</span>\n        <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">batchsize</span><span class=\"p\">)</span>\n        <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;loss&#34;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">)</span>\n        <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;error&#34;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">error</span><span class=\"p\">)</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">Minibatch: 0, Loss: 2.2132, Error: 221.32%\nMinibatch: 500, Loss: 0.5081, Error: 50.81%\nMinibatch: 1000, Loss: 0.2309, Error: 23.09%\nMinibatch: 1500, Loss: 0.4300, Error: 43.00%\nMinibatch: 2000, Loss: 0.1918, Error: 19.18%\nMinibatch: 2500, Loss: 0.1843, Error: 18.43%\nMinibatch: 3000, Loss: 0.1117, Error: 11.17%\nMinibatch: 3500, Loss: 0.3094, Error: 30.94%\nMinibatch: 4000, Loss: 0.3554, Error: 35.54%\nMinibatch: 4500, Loss: 0.2465, Error: 24.65%\nMinibatch: 5000, Loss: 0.1988, Error: 19.88%\nMinibatch: 5500, Loss: 0.1277, Error: 12.77%\nMinibatch: 6000, Loss: 0.1448, Error: 14.48%\nMinibatch: 6500, Loss: 0.2789, Error: 27.89%\nMinibatch: 7000, Loss: 0.1692, Error: 16.92%\nMinibatch: 7500, Loss: 0.3069, Error: 30.69%\nMinibatch: 8000, Loss: 0.1194, Error: 11.94%\nMinibatch: 8500, Loss: 0.1464, Error: 14.64%\nMinibatch: 9000, Loss: 0.1096, Error: 10.96%</code></pre></div><p>Let us plot the errors over the different training minibatches. Note that as we iterate the training loss decreases though we do see some intermediate bumps.</p><p>Hence, we use smaller minibatches and using sgd enables us to have a great scalability while being performant for large data sets.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Compute the moving average loss to smooth out the noise in SGD</span>\n<span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgloss&#34;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">moving_average</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;loss&#34;</span><span class=\"p\">])</span>\n<span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgerror&#34;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">moving_average</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;error&#34;</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Plot the training loss and the training error</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">subplot</span><span class=\"p\">(</span><span class=\"mi\">211</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">],</span> <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgloss&#34;</span><span class=\"p\">],</span> <span class=\"s1\">&#39;b--&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch number&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Loss&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch run vs. Training loss&#39;</span><span class=\"p\">)</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">subplot</span><span class=\"p\">(</span><span class=\"mi\">212</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">],</span> <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgerror&#34;</span><span class=\"p\">],</span> <span class=\"s1\">&#39;r--&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch number&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Label Prediction Error&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch run vs. Label Prediction Error&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic3.zhimg.com/v2-a8a99665d27b89adfb46f9d2eae1c056_b.png\" data-rawwidth=\"396\" data-rawheight=\"159\" class=\"content_image\" width=\"396\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;396&#39; height=&#39;159&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"396\" data-rawheight=\"159\" class=\"content_image lazy\" width=\"396\" data-actualsrc=\"https://pic3.zhimg.com/v2-a8a99665d27b89adfb46f9d2eae1c056_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic2.zhimg.com/v2-1baa21a10f2932e85211020ab92dce45_b.png\" data-rawwidth=\"396\" data-rawheight=\"159\" class=\"content_image\" width=\"396\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;396&#39; height=&#39;159&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"396\" data-rawheight=\"159\" class=\"content_image lazy\" width=\"396\" data-actualsrc=\"https://pic2.zhimg.com/v2-1baa21a10f2932e85211020ab92dce45_b.png\"/></figure><h2><b>Evaluation / Testing</b></h2><p>Now that we have trained the network, let us evaluate the trained network on the test data. This is done using trainer.test_minibatch.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Read the training data</span>\n<span class=\"n\">reader_test</span> <span class=\"o\">=</span> <span class=\"n\">create_reader</span><span class=\"p\">(</span><span class=\"n\">test_file</span><span class=\"p\">,</span> <span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">)</span>\n\n<span class=\"n\">test_input_map</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"n\">label</span>  <span class=\"p\">:</span> <span class=\"n\">reader_test</span><span class=\"o\">.</span><span class=\"n\">streams</span><span class=\"o\">.</span><span class=\"n\">labels</span><span class=\"p\">,</span>\n    <span class=\"nb\">input</span>  <span class=\"p\">:</span> <span class=\"n\">reader_test</span><span class=\"o\">.</span><span class=\"n\">streams</span><span class=\"o\">.</span><span class=\"n\">features</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\"># Test data for trained model</span>\n<span class=\"n\">test_minibatch_size</span> <span class=\"o\">=</span> <span class=\"mi\">512</span>\n<span class=\"n\">num_samples</span> <span class=\"o\">=</span> <span class=\"mi\">10000</span>\n<span class=\"n\">num_minibatches_to_test</span> <span class=\"o\">=</span> <span class=\"n\">num_samples</span> <span class=\"o\">//</span> <span class=\"n\">test_minibatch_size</span>\n<span class=\"n\">test_result</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>\n\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_minibatches_to_test</span><span class=\"p\">):</span>\n\n    <span class=\"c1\"># We are loading test data in batches specified by test_minibatch_size</span>\n    <span class=\"c1\"># Each data point in the minibatch is a MNIST digit image of 784 dimensions </span>\n    <span class=\"c1\"># with one pixel per dimension that we will encode / decode with the </span>\n    <span class=\"c1\"># trained model.</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">reader_test</span><span class=\"o\">.</span><span class=\"n\">next_minibatch</span><span class=\"p\">(</span><span class=\"n\">test_minibatch_size</span><span class=\"p\">,</span>\n                                      <span class=\"n\">input_map</span> <span class=\"o\">=</span> <span class=\"n\">test_input_map</span><span class=\"p\">)</span>\n\n    <span class=\"n\">eval_error</span> <span class=\"o\">=</span> <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">test_minibatch</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n    <span class=\"n\">test_result</span> <span class=\"o\">=</span> <span class=\"n\">test_result</span> <span class=\"o\">+</span> <span class=\"n\">eval_error</span>\n\n<span class=\"c1\"># Average of evaluation errors of all test minibatches</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;Average test error: </span><span class=\"si\">{0:.2f}</span><span class=\"s2\">%&#34;</span><span class=\"o\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">test_result</span><span class=\"o\">*</span><span class=\"mi\">100</span> <span class=\"o\">/</span> <span class=\"n\">num_minibatches_to_test</span><span class=\"p\">))</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">Average test error: 7.41%</code></pre></div><p>Note, this error is very comparable to our training error indicating that our model has good &#34;out of sample&#34; error a.k.a. generalization error. This implies that our model can very effectively deal with previously unseen observations (during the training process). This is key to avoid the phenomenon of overfitting.</p><p>We have so far been dealing with aggregate measures of error. Let us now get the probabilities associated with individual data points. For each observation, the eval function returns the probability distribution across all the classes. The classifier is trained to recognize digits, hence has 10 classes. First let us route the network output through a softmax function. This maps the aggregated activations across the network to probabilities across the 10 classes.</p><div class=\"highlight\"><pre><code class=\"language-text\">out = C.softmax(z)</code></pre></div><p>Let us a small minibatch sample from the test data.</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Read the data for evaluation</span>\n<span class=\"n\">reader_eval</span> <span class=\"o\">=</span> <span class=\"n\">create_reader</span><span class=\"p\">(</span><span class=\"n\">test_file</span><span class=\"p\">,</span> <span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">)</span>\n\n<span class=\"n\">eval_minibatch_size</span> <span class=\"o\">=</span> <span class=\"mi\">25</span>\n<span class=\"n\">eval_input_map</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"nb\">input</span><span class=\"p\">:</span> <span class=\"n\">reader_eval</span><span class=\"o\">.</span><span class=\"n\">streams</span><span class=\"o\">.</span><span class=\"n\">features</span><span class=\"p\">}</span> \n\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">reader_test</span><span class=\"o\">.</span><span class=\"n\">next_minibatch</span><span class=\"p\">(</span><span class=\"n\">eval_minibatch_size</span><span class=\"p\">,</span> <span class=\"n\">input_map</span> <span class=\"o\">=</span> <span class=\"n\">test_input_map</span><span class=\"p\">)</span>\n\n<span class=\"n\">img_label</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"n\">label</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">asarray</span><span class=\"p\">()</span>\n<span class=\"n\">img_data</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"nb\">input</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">asarray</span><span class=\"p\">()</span>\n<span class=\"n\">predicted_label_prob</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"nb\">eval</span><span class=\"p\">(</span><span class=\"n\">img_data</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">img_data</span><span class=\"p\">))]</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Find the index with the maximum value for both predicted as well as the ground truth</span>\n<span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">predicted_label_prob</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">predicted_label_prob</span><span class=\"p\">))]</span>\n<span class=\"n\">gtlabel</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">img_label</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">img_label</span><span class=\"p\">))]</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">print(&#34;Label    :&#34;, gtlabel[:25])\nprint(&#34;Predicted:&#34;, pred)</code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">Label    : [4, 5, 6, 7, 8, 9, 7, 4, 6, 1, 4, 0, 9, 9, 3, 7, 8, 4, 7, 5, 8, 5, 3, 2, 2]\nPredicted: [4, 6, 6, 7, 5, 8, 7, 4, 6, 1, 6, 0, 4, 9, 3, 7, 1, 2, 7, 5, 8, 6, 3, 2, 2]</code></pre></div><p>Let us visualize some of the results</p><div class=\"highlight\"><pre><code class=\"language-text\"># Plot a random image\nsample_number = 5\nplt.imshow(img_data[sample_number].reshape(28,28), cmap=&#34;gray_r&#34;)\nplt.axis(&#39;off&#39;)\n\nimg_gt, img_pred = gtlabel[sample_number], pred[sample_number]\nprint(&#34;Image Label: &#34;, img_pred)</code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">Image Label:  8</code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic2.zhimg.com/v2-b8d5a68723780fecc215c0823488dd39_b.png\" data-rawwidth=\"254\" data-rawheight=\"252\" class=\"content_image\" width=\"254\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;254&#39; height=&#39;252&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"254\" data-rawheight=\"252\" class=\"content_image lazy\" width=\"254\" data-actualsrc=\"https://pic2.zhimg.com/v2-b8d5a68723780fecc215c0823488dd39_b.png\"/></figure><p><b>Exploration Suggestion</b></p><ul><li>Try exploring how the classifier behaves with different parameters, e.g. changing the minibatch_size parameter from 25 to say 64 or 128. What happens to the error rate? How does the error compare to the logistic regression classifier?</li><li>Try increasing the number of sweeps</li><li>Try changing the network to reduce the training error rate? When do you see <i>overfitting</i> happening?</li></ul>", 
            "topic": [
                {
                    "tag": "CNTK", 
                    "tagLink": "https://api.zhihu.com/topics/20046732"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "手写数字识别", 
                    "tagLink": "https://api.zhihu.com/topics/20073557"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/28190464", 
            "userName": "王万霖", 
            "userLink": "https://www.zhihu.com/people/b8f13b7ce876ce5f99a47ce6cd2956f0", 
            "upvote": 7, 
            "title": "CNTK103A：加载MNIST手写识别数据集", 
            "content": "<blockquote>刚开始接触 CNTK 以及机器学习？这一讲就是为你准备的。在阅读这一节之前，你应该已经看完了之前的教程：<a href=\"https://zhuanlan.zhihu.com/p/28048444\" class=\"internal\">101</a>和<a href=\"https://zhuanlan.zhihu.com/p/28072262\" class=\"internal\">102</a>。在这一讲中，我们将下载并预处理MNIST数字图像，构建不同的模型，来识别手写数字。 我们将拓展前两节讲到的内容，用来完成我们的手写识别任务。 此外，我们还将使用<b>卷积神经网络</b>（CNN）来提高手写识别的性能。不同于前两节，在本教程中，我们将使用真实的数据集进行实验！</blockquote><p>本文最后修订于2017年11月06日，最近一次更新包含了较小的修复和改进。</p><p>大家好，这是本专栏关于CNTK教程入门课程的第三讲。今天我们将使用 <a href=\"https://zhuanlan.zhihu.com/p/28047133\" class=\"internal\">CNTK</a> 中的<b>读取器</b>（Reader）加载<a href=\"https://link.zhihu.com/?target=http%3A//yann.lecun.com/exdb/mnist/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">MNIST手写数据集</a>——这是一个使用很广泛的数据集。下面我们就来一起完成今天的任务吧。</p><p>和之前的两个教程不同，本教程（CNTK103）分为多个部分：</p><ul><li>这一部分（<b>103A</b>）：下载并熟悉将在稍后会用到的 MNIST 手写识别数据集</li><li>在103教程的其他部分（103B、103C和103D）：我们将会使用不同的网络来处理我们的 MNIST 数据集</li></ul><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"kn\">from</span> <span class=\"nn\">__future__</span> <span class=\"k\">import</span> <span class=\"n\">print_function</span>\n<span class=\"kn\">import</span> <span class=\"nn\">gzip</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.image</span> <span class=\"k\">as</span> <span class=\"nn\">mpimg</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">shutil</span>\n<span class=\"kn\">import</span> <span class=\"nn\">struct</span>\n<span class=\"kn\">import</span> <span class=\"nn\">sys</span>\n\n<span class=\"k\">try</span><span class=\"p\">:</span> \n    <span class=\"kn\">from</span> <span class=\"nn\">urllib.request</span> <span class=\"k\">import</span> <span class=\"n\">urlretrieve</span> \n<span class=\"k\">except</span> <span class=\"ne\">ImportError</span><span class=\"p\">:</span> \n    <span class=\"kn\">from</span> <span class=\"nn\">urllib</span> <span class=\"k\">import</span> <span class=\"n\">urlretrieve</span>\n\n<span class=\"o\">%</span><span class=\"n\">matplotlib</span> <span class=\"n\">inline</span></code></pre></div><h2><b>下载数据</b></h2><p>我们使用下面的Python脚本，将数据下载到本地机器上。 MNIST手写识别数据集是在机器学习领域非常经典的数据集，它被广泛用于不同的机器学习算法的训练和测试。 在MNIST数据集中，存储了70000多张人类手写的数字，其中每张图像为28 x 28像素。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 用于将MNIST数据集下载，并且解压缩到训练集和测试集的函数</span>\n<span class=\"c1\"># - loadData 读取图片数据，并且将其格式化为28x28的长数组</span>\n<span class=\"c1\"># - loadLabels 读取正确的标签数据，每个图像有1个标签</span>\n<span class=\"c1\"># - 将下载的图像加载打包并将数据标签组合，以便稍后使用</span>\n<span class=\"c1\">#   CNTK 文本读取器（Reader）</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">loadData</span><span class=\"p\">(</span><span class=\"n\">src</span><span class=\"p\">,</span> <span class=\"n\">cimg</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span> <span class=\"p\">(</span><span class=\"s1\">&#39;正在下载 &#39;</span> <span class=\"o\">+</span> <span class=\"n\">src</span><span class=\"p\">)</span>\n    <span class=\"n\">gzfname</span><span class=\"p\">,</span> <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">urlretrieve</span><span class=\"p\">(</span><span class=\"n\">src</span><span class=\"p\">,</span> <span class=\"s1\">&#39;./delete.me&#39;</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span> <span class=\"p\">(</span><span class=\"s1\">&#39;完成.&#39;</span><span class=\"p\">)</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"k\">with</span> <span class=\"n\">gzip</span><span class=\"o\">.</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">gzfname</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">gz</span><span class=\"p\">:</span>\n            <span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"n\">struct</span><span class=\"o\">.</span><span class=\"n\">unpack</span><span class=\"p\">(</span><span class=\"s1\">&#39;I&#39;</span><span class=\"p\">,</span> <span class=\"n\">gz</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">))</span>\n            <span class=\"c1\"># 读取magic number</span>\n            <span class=\"k\">if</span> <span class=\"n\">n</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"mh\">0x3080000</span><span class=\"p\">:</span>\n                <span class=\"k\">raise</span> <span class=\"ne\">Exception</span><span class=\"p\">(</span><span class=\"s1\">&#39;文件无效: 未预期的magic number.&#39;</span><span class=\"p\">)</span>\n            <span class=\"c1\"># 将数据整体读入</span>\n            <span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"n\">struct</span><span class=\"o\">.</span><span class=\"n\">unpack</span><span class=\"p\">(</span><span class=\"s1\">&#39;&gt;I&#39;</span><span class=\"p\">,</span> <span class=\"n\">gz</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">))[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n            <span class=\"k\">if</span> <span class=\"n\">n</span> <span class=\"o\">!=</span> <span class=\"n\">cimg</span><span class=\"p\">:</span>\n                <span class=\"k\">raise</span> <span class=\"ne\">Exception</span><span class=\"p\">(</span><span class=\"s1\">&#39;文件无效: expected </span><span class=\"si\">{0}</span><span class=\"s1\"> entries.&#39;</span><span class=\"o\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">cimg</span><span class=\"p\">))</span>\n            <span class=\"n\">crow</span> <span class=\"o\">=</span> <span class=\"n\">struct</span><span class=\"o\">.</span><span class=\"n\">unpack</span><span class=\"p\">(</span><span class=\"s1\">&#39;&gt;I&#39;</span><span class=\"p\">,</span> <span class=\"n\">gz</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">))[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n            <span class=\"n\">ccol</span> <span class=\"o\">=</span> <span class=\"n\">struct</span><span class=\"o\">.</span><span class=\"n\">unpack</span><span class=\"p\">(</span><span class=\"s1\">&#39;&gt;I&#39;</span><span class=\"p\">,</span> <span class=\"n\">gz</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">))[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n            <span class=\"k\">if</span> <span class=\"n\">crow</span> <span class=\"o\">!=</span> <span class=\"mi\">28</span> <span class=\"ow\">or</span> <span class=\"n\">ccol</span> <span class=\"o\">!=</span> <span class=\"mi\">28</span><span class=\"p\">:</span>\n                <span class=\"k\">raise</span> <span class=\"ne\">Exception</span><span class=\"p\">(</span><span class=\"s1\">&#39;文件无效: 每张图像应该有 28 行/列.&#39;</span><span class=\"p\">)</span>\n            <span class=\"c1\"># 读取数据</span>\n            <span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">fromstring</span><span class=\"p\">(</span><span class=\"n\">gz</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"n\">cimg</span> <span class=\"o\">*</span> <span class=\"n\">crow</span> <span class=\"o\">*</span> <span class=\"n\">ccol</span><span class=\"p\">),</span> <span class=\"n\">dtype</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">uint8</span><span class=\"p\">)</span>\n    <span class=\"k\">finally</span><span class=\"p\">:</span>\n        <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">remove</span><span class=\"p\">(</span><span class=\"n\">gzfname</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">res</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">((</span><span class=\"n\">cimg</span><span class=\"p\">,</span> <span class=\"n\">crow</span> <span class=\"o\">*</span> <span class=\"n\">ccol</span><span class=\"p\">))</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">loadLabels</span><span class=\"p\">(</span><span class=\"n\">src</span><span class=\"p\">,</span> <span class=\"n\">cimg</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span> <span class=\"p\">(</span><span class=\"s1\">&#39;正在下载 &#39;</span> <span class=\"o\">+</span> <span class=\"n\">src</span><span class=\"p\">)</span>\n    <span class=\"n\">gzfname</span><span class=\"p\">,</span> <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">urlretrieve</span><span class=\"p\">(</span><span class=\"n\">src</span><span class=\"p\">,</span> <span class=\"s1\">&#39;./delete.me&#39;</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span> <span class=\"p\">(</span><span class=\"s1\">&#39;完成.&#39;</span><span class=\"p\">)</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"k\">with</span> <span class=\"n\">gzip</span><span class=\"o\">.</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">gzfname</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">gz</span><span class=\"p\">:</span>\n            <span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"n\">struct</span><span class=\"o\">.</span><span class=\"n\">unpack</span><span class=\"p\">(</span><span class=\"s1\">&#39;I&#39;</span><span class=\"p\">,</span> <span class=\"n\">gz</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">))</span>\n            <span class=\"c1\"># 读取magic number</span>\n            <span class=\"k\">if</span> <span class=\"n\">n</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"mh\">0x1080000</span><span class=\"p\">:</span>\n                <span class=\"k\">raise</span> <span class=\"ne\">Exception</span><span class=\"p\">(</span><span class=\"s1\">&#39;文件无效: 未预期的 magic number.&#39;</span><span class=\"p\">)</span>\n            <span class=\"c1\"># 将数据整体读入</span>\n            <span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"n\">struct</span><span class=\"o\">.</span><span class=\"n\">unpack</span><span class=\"p\">(</span><span class=\"s1\">&#39;&gt;I&#39;</span><span class=\"p\">,</span> <span class=\"n\">gz</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">))</span>\n            <span class=\"k\">if</span> <span class=\"n\">n</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"n\">cimg</span><span class=\"p\">:</span>\n                <span class=\"k\">raise</span> <span class=\"ne\">Exception</span><span class=\"p\">(</span><span class=\"s1\">&#39;Invalid file: expected </span><span class=\"si\">{0}</span><span class=\"s1\"> rows.&#39;</span><span class=\"o\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">cimg</span><span class=\"p\">))</span>\n            <span class=\"c1\"># 读取标签</span>\n            <span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">fromstring</span><span class=\"p\">(</span><span class=\"n\">gz</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"n\">cimg</span><span class=\"p\">),</span> <span class=\"n\">dtype</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">uint8</span><span class=\"p\">)</span>\n    <span class=\"k\">finally</span><span class=\"p\">:</span>\n        <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">remove</span><span class=\"p\">(</span><span class=\"n\">gzfname</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">res</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">((</span><span class=\"n\">cimg</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">try_download</span><span class=\"p\">(</span><span class=\"n\">dataSrc</span><span class=\"p\">,</span> <span class=\"n\">labelsSrc</span><span class=\"p\">,</span> <span class=\"n\">cimg</span><span class=\"p\">):</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">loadData</span><span class=\"p\">(</span><span class=\"n\">dataSrc</span><span class=\"p\">,</span> <span class=\"n\">cimg</span><span class=\"p\">)</span>\n    <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">loadLabels</span><span class=\"p\">(</span><span class=\"n\">labelsSrc</span><span class=\"p\">,</span> <span class=\"n\">cimg</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">hstack</span><span class=\"p\">((</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">))</span></code></pre></div><p>MNIST手写数字数据集分为训练集和测试集两部分来提供，其中，训练集中含有60000张图像，而测试集中含有10000张图像。</p><p>我们现在来下载数据：</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 训练集图像和标签数据的url</span>\n<span class=\"n\">url_train_image</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz&#39;</span>\n<span class=\"n\">url_train_labels</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz&#39;</span>\n<span class=\"n\">num_train_samples</span> <span class=\"o\">=</span> <span class=\"mi\">60000</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;下载训练集数据&#34;</span><span class=\"p\">)</span>\n<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">try_download</span><span class=\"p\">(</span><span class=\"n\">url_train_image</span><span class=\"p\">,</span> <span class=\"n\">url_train_labels</span><span class=\"p\">,</span> <span class=\"n\">num_train_samples</span><span class=\"p\">)</span>\n\n\n<span class=\"n\">url_test_image</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz&#39;</span>\n<span class=\"n\">url_test_labels</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz&#39;</span>\n<span class=\"n\">num_test_samples</span> <span class=\"o\">=</span> <span class=\"mi\">10000</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;下载测试集数据&#34;</span><span class=\"p\">)</span>\n<span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">try_download</span><span class=\"p\">(</span><span class=\"n\">url_test_image</span><span class=\"p\">,</span> <span class=\"n\">url_test_labels</span><span class=\"p\">,</span> <span class=\"n\">num_test_samples</span><span class=\"p\">)</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">下载训练集数据\n正在下载 http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n完成.\n正在下载 http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n完成.\n下载测试集数据\n正在下载 http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n完成.\n正在下载 http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n完成.</code></pre></div><h2><b>可视化数据</b></h2><p>让我们来看看下载好的MNIST数据集中的手写数字：</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 显示随机一张图像</span>\n<span class=\"n\">sample_number</span> <span class=\"o\">=</span> <span class=\"mi\">5001</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">[</span><span class=\"n\">sample_number</span><span class=\"p\">,:</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"mi\">28</span><span class=\"p\">,</span><span class=\"mi\">28</span><span class=\"p\">),</span> <span class=\"n\">cmap</span><span class=\"o\">=</span><span class=\"s2\">&#34;gray_r&#34;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"p\">(</span><span class=\"s1\">&#39;off&#39;</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;图像标签为: &#34;</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"p\">[</span><span class=\"n\">sample_number</span><span class=\"p\">,</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">])</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">图像标签为:  3</code></pre></div><figure><noscript><img src=\"https://pic1.zhimg.com/v2-d39ba78914562639843f60cb35485350_b.png\" data-caption=\"\" data-rawwidth=\"353\" data-rawheight=\"351\" class=\"content_image\" width=\"353\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;353&#39; height=&#39;351&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"353\" data-rawheight=\"351\" class=\"content_image lazy\" width=\"353\" data-actualsrc=\"https://pic1.zhimg.com/v2-d39ba78914562639843f60cb35485350_b.png\"/></figure><h2><b>保存图像</b></h2><p>我们现在将图像保存在我们电脑的本地目录中。 在保存数据的同时，我们将图像格式化为一个向量（将28×28的图像变成长度为784个数据点的数组）</p><figure><noscript><img src=\"https://pic3.zhimg.com/v2-c0814d9f0e322612f3ee428ac9b7da9a_b.png\" data-caption=\"\" data-rawwidth=\"470\" data-rawheight=\"434\" class=\"origin_image zh-lightbox-thumb\" width=\"470\" data-original=\"https://pic3.zhimg.com/v2-c0814d9f0e322612f3ee428ac9b7da9a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;470&#39; height=&#39;434&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"470\" data-rawheight=\"434\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"470\" data-original=\"https://pic3.zhimg.com/v2-c0814d9f0e322612f3ee428ac9b7da9a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c0814d9f0e322612f3ee428ac9b7da9a_b.png\"/></figure><p>其中，标签被格式化为长度为10位的“二值化”编码（比如标签为3，则变为0001000000，其中第一个索引对应于数字0，最后一个对应于数字9）</p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-fc1cbfbba253d01704a1a9a3b642f5f0_b.png\" data-caption=\"\" data-rawwidth=\"615\" data-rawheight=\"124\" class=\"origin_image zh-lightbox-thumb\" width=\"615\" data-original=\"https://pic1.zhimg.com/v2-fc1cbfbba253d01704a1a9a3b642f5f0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;615&#39; height=&#39;124&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"615\" data-rawheight=\"124\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"615\" data-original=\"https://pic1.zhimg.com/v2-fc1cbfbba253d01704a1a9a3b642f5f0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-fc1cbfbba253d01704a1a9a3b642f5f0_b.png\"/></figure><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 将数据文件保存为与CNTK文本读取器（reader）相兼容的格式</span>\n<span class=\"k\">def</span> <span class=\"nf\">savetxt</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"n\">ndarray</span><span class=\"p\">):</span>\n    <span class=\"nb\">dir</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">dirname</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">(</span><span class=\"nb\">dir</span><span class=\"p\">):</span>\n        <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">makedirs</span><span class=\"p\">(</span><span class=\"nb\">dir</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">isfile</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">):</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;正在保存&#34;</span><span class=\"p\">,</span> <span class=\"n\">filename</span> <span class=\"p\">)</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"s1\">&#39;w&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"s1\">&#39; &#39;</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">eye</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">uint</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">)))</span>\n            <span class=\"k\">for</span> <span class=\"n\">row</span> <span class=\"ow\">in</span> <span class=\"n\">ndarray</span><span class=\"p\">:</span>\n                <span class=\"n\">row_str</span> <span class=\"o\">=</span> <span class=\"n\">row</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">)</span>\n                <span class=\"n\">label_str</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"p\">[</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]]</span>\n                <span class=\"n\">feature_str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39; &#39;</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">row_str</span><span class=\"p\">[:</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n                <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"s1\">&#39;|labels </span><span class=\"si\">{}</span><span class=\"s1\"> |features </span><span class=\"si\">{}</span><span class=\"se\">\\n</span><span class=\"s1\">&#39;</span><span class=\"o\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">label_str</span><span class=\"p\">,</span> <span class=\"n\">feature_str</span><span class=\"p\">))</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;文件已经存在&#34;</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">)</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 保存训练集和测试集文件</span>\n<span class=\"n\">data_dir</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"s2\">&#34;..&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;Examples&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;Image&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;DataSets&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;MNIST&#34;</span><span class=\"p\">)</span>\n<span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">(</span><span class=\"n\">data_dir</span><span class=\"p\">):</span>\n    <span class=\"n\">data_dir</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"s2\">&#34;data&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;MNIST&#34;</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span> <span class=\"p\">(</span><span class=\"s1\">&#39;正在写入训练集文本文件...&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">savetxt</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">data_dir</span><span class=\"p\">,</span> <span class=\"s2\">&#34;Train-28x28_cntk_text.txt&#34;</span><span class=\"p\">),</span> <span class=\"n\">train</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span> <span class=\"p\">(</span><span class=\"s1\">&#39;正在写入测试集文本文件...&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">savetxt</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">data_dir</span><span class=\"p\">,</span> <span class=\"s2\">&#34;Test-28x28_cntk_text.txt&#34;</span><span class=\"p\">),</span> <span class=\"n\">test</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;完成&#39;</span><span class=\"p\">)</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">正在写入训练集文本文件...\n正在保存 ..\\Examples\\Image\\DataSets\\MNIST\\Train-28x28_cntk_text.txt\n正在写入测试集文本文件...\n正在保存 ..\\Examples\\Image\\DataSets\\MNIST\\Test-28x28_cntk_text.txt\n完成</code></pre></div><h2><b>后续建议</b></h2><p>其实，我们可以对数据集进行一些处理，以提高机器学习系统的性能。我们建议您首先使用到目前为止生成的数据，并在后续部分的教程中中运行我们的分类器。 一旦基准线以原始格式分类数据，现在使用不同的数据操作技术来进一步改进模型。</p><p>有几种方法可以修改数据集，但是 CNTK 的<b>读取器</b>（Reader）可以为您自动执行大量的操作。 然而，为了感受通过对数据集的改变，如何影响训练和测试精度，我们强烈鼓励你尝试一个或多个数据变换：</p><ul><li>搅乱训练数据。你可以使用 permute_indices = np.random.permutation(train.shape[0]). 然后，在103B教程中用上你自己修改的数据集。</li><li>向数据添加噪声往往会改善泛化误差。 您可以通过将训练图像中添加噪音（用numpy，提示：使用numpy.random生成）来增强训练集。</li><li>使用仿射变换扭曲图像（转换或旋转）</li></ul><p>本文根据MIT协议授权的<a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/master/Tutorials/CNTK_103A_MNIST_DataLoader.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">CNTK103A</a>教程（英文），由<a href=\"https://www.zhihu.com/people/DGideas\" class=\"internal\">王万霖</a>进行了演绎和本地化。</p>", 
            "topic": [
                {
                    "tag": "CNTK", 
                    "tagLink": "https://api.zhihu.com/topics/20046732"
                }, 
                {
                    "tag": "手写数字识别", 
                    "tagLink": "https://api.zhihu.com/topics/20073557"
                }, 
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/28072262", 
            "userName": "王万霖", 
            "userLink": "https://www.zhihu.com/people/b8f13b7ce876ce5f99a47ce6cd2956f0", 
            "upvote": 4, 
            "title": "CNTK102：构建前向神经网络", 
            "content": "<blockquote>这一讲的主要目的是让你熟悉使用CNTK工具集的Python接口去完成一个<b>分类</b>任务。如果你已经完成了逻辑回归教程或熟悉机器学习，你可以跳过介绍部分。</blockquote><p>本文最后更新于2017年11月06日，最后一次更新包含了较小的修复和改进。</p><p>大家好，我是本专栏的作者王万霖。今天我们来学习如何使用CNTK构建前向神经网络解决分类问题，类似于CNTK101，我们在这一讲仍然使用“医院患者数据集”。</p><p><b>问题</b>（和CNTK101的问题一样）<b>：</b><br/>一家癌症医院为我们提供了一批患者的数据，并希望我们能确定患者是否患有致命的恶性肿瘤，这是一个分类问题。为了帮助对每个病人进行分类，医院能够提供的数据是：患者的年龄和肿瘤的大小。换句话说，我们可以想象：年轻的病人和/或小肿瘤患者不太可能患上恶性肿瘤。</p><p>我们在这一讲使用了机器生成的模拟数据集进行练习：每个病人在图表中表示成为一个点，其中红色表示其患有恶性肿瘤、蓝色则表示良性。</p><p>注意：这只是一个学习的简单示例；在现实生活中，医生将会对患者从不同的方面进行测试/检查，之后再做出决定。</p><p><b>目标</b>：</p><p>我们的目标是学习一个分类器，通过给定病人的两个特征（年龄和肿瘤大小），将病人的肿瘤分类为良性和恶性其中一类。</p><p>在 CNTK101教程中，我们学习了使用线性分类器对数据点进行逻辑回归。在现实世界的问题中，线性分类器通常不能准确地对数据进行建模，因为很少有文章讲述关于如何构造好的特征。这通常会导致精确度的限制，并需要具有更复杂决策边界的模型。在本教程中，我们将结合多个线性单元（从 CNTK 101 教程：逻辑回归），从而制作一个非线性分类器。此类分类器的另一个用途是自动从数据中学习到特征编码，我们将在后边的教程对此进行介绍。</p><p><b>步骤：</b></p><p>一般地，一种学习方法一般由五个步骤组成：数据读取、数据预处理、创建模型、学习模型参数和模型评估（又称测试/预测）</p><p>除了第三个步骤，其他的所有内容与CNTK 101保持一致。</p><h2>前馈网络模型</h2><p>在这一讲中，所使用的数据集类似于逻辑回归教程中使用的。该模型结合了多个逻辑分类器，以便能够对数据进行分类，从而导致对数据进行正确分类所需的决策边界比简单的线性模型 (如逻辑回归) 更复杂。下图显示了网络的一般形状。</p><p><b>前馈神经网络</b>（feedforward neural network）是一种人工神经网络，之所以被称为“前馈”（或者“前向”），是因为在网络结构的拓扑中<b>不出现</b>环（注意，这并不意味着数据不能反方向流通）。前馈神经网络是设计的第一种最简单的人工神经网络。在这个网络中, 信息只在一个方向移动, 向前, 从输入节点, 通过隐藏节点 (如果有) 和输出节点。</p><p>在本教程中, 我们将通过完成五步骤所需的不同步骤来训练和测试玩具数据的模型。</p><p><b>生成数据</b></p><p>如果你已经完成了CNTK 101的相关内容，你可以跳过这一节。</p><p>让我们用 numpy 库生成一些模拟癌症例子的合成数据。我们有两个特征 (以两个维度表示), 分别是两个类之一 (良性：蓝点或恶性：红点)。</p><p>在我们的例子中, 每个样本在训练数据有一个标签 (蓝色或红色) 对应于每个样本 (一组特征-年龄和大小)。在本例中, 我们有两个由标签0或1表示的类，因此是一个二进制分类任务。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Ensure we always get the same amount of randomness</span>\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Define the data dimensions</span>\n<span class=\"n\">input_dim</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n<span class=\"n\">num_output_classes</span> <span class=\"o\">=</span> <span class=\"mi\">2</span></code></pre></div><h2><b>输入和标签</b></h2><p>在本教程中，我们使用 numpy 库生成合成数据。在解决实际问题的过程中，你将会使用Reader类，这将帮助你从文件中读取数据的特征值 (年龄、肿瘤大小) 对应的每一个样本 (病人)。注意，每个样本都可以驻留在更高维度空间中 (当有更多的特征可用时)，并将其表示为 CNTK 中的张量。更高级的教程应介绍高维数据的处理。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Helper function to generate a random data sample</span>\n<span class=\"k\">def</span> <span class=\"nf\">generate_random_data_sample</span><span class=\"p\">(</span><span class=\"n\">sample_size</span><span class=\"p\">,</span> <span class=\"n\">feature_dim</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Create synthetic data using NumPy. </span>\n    <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">sample_size</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">low</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">high</span><span class=\"o\">=</span><span class=\"n\">num_classes</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Make sure that the data is separable</span>\n    <span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">sample_size</span><span class=\"p\">,</span> <span class=\"n\">feature_dim</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"mi\">3</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>    \n    <span class=\"c1\"># converting class 0 into the vector &#34;1 0 0&#34;, </span>\n    <span class=\"c1\"># class 1 into vector &#34;0 1 0&#34;, ...</span>\n    <span class=\"n\">class_ind</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">Y</span><span class=\"o\">==</span><span class=\"n\">class_number</span> <span class=\"k\">for</span> <span class=\"n\">class_number</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_classes</span><span class=\"p\">)]</span>\n    <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">asarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">hstack</span><span class=\"p\">(</span><span class=\"n\">class_ind</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">Y</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Create the input variables denoting the features and the label data. Note: the input </span>\n<span class=\"c1\"># does not need additional info on number of observations (Samples) since CNTK first create only </span>\n<span class=\"c1\"># the network tooplogy first </span>\n<span class=\"n\">mysamplesize</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>\n<span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">generate_random_data_sample</span><span class=\"p\">(</span><span class=\"n\">mysamplesize</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">)</span></code></pre></div><p>来让我们看看数据集的样子。</p><p><b>注意：</b>如果导入matplotlib.pyplot失败了，请在命令行运行以下命令： conda install <br/>matplotlib，这将会修复pyplot的相关依赖。如果你使用的是Anaconda以外的环境，请使用这个命令：pip install matplotlib。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 画出图像</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"o\">%</span><span class=\"n\">matplotlib</span> <span class=\"n\">inline</span>\n\n<span class=\"c1\"># 一共有两个分类</span>\n<span class=\"n\">colors</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;r&#39;</span> <span class=\"k\">if</span> <span class=\"n\">l</span> <span class=\"o\">==</span> <span class=\"mi\">0</span> <span class=\"k\">else</span> <span class=\"s1\">&#39;b&#39;</span> <span class=\"k\">for</span> <span class=\"n\">l</span> <span class=\"ow\">in</span> <span class=\"n\">labels</span><span class=\"p\">[:,</span><span class=\"mi\">0</span><span class=\"p\">]]</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">scatter</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">[:,</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">features</span><span class=\"p\">[:,</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">c</span><span class=\"o\">=</span><span class=\"n\">colors</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s2\">&#34;Scaled age (in yrs)&#34;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s2\">&#34;Tumor size (in cm)&#34;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic3.zhimg.com/v2-9f28d5aa865be9160e7e2c10daee3722_b.png\" data-caption=\"\" data-rawwidth=\"387\" data-rawheight=\"271\" class=\"content_image\" width=\"387\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;387&#39; height=&#39;271&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"387\" data-rawheight=\"271\" class=\"content_image lazy\" width=\"387\" data-actualsrc=\"https://pic3.zhimg.com/v2-9f28d5aa865be9160e7e2c10daee3722_b.png\"/></figure><h2><b>创建模型</b></h2><p>我们的前向神经网络具有简单的 <img src=\"https://www.zhihu.com/equation?tex=2\" alt=\"2\" eeimg=\"1\"/> 个<b>隐藏层</b>（hidden layers），其中每一层具有 <img src=\"https://www.zhihu.com/equation?tex=50\" alt=\"50\" eeimg=\"1\"/> 个<b>隐藏节点</b>（hidden nodes）。</p><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-86022d1d5257327a7bdc54b629554d6c_b.jpg\" data-caption=\"\" data-rawwidth=\"398\" data-rawheight=\"483\" class=\"content_image\" width=\"398\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;398&#39; height=&#39;483&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"398\" data-rawheight=\"483\" class=\"content_image lazy\" width=\"398\" data-actualsrc=\"https://pic1.zhimg.com/v2-86022d1d5257327a7bdc54b629554d6c_b.jpg\"/></figure><p>在示例中, 每个隐藏层中的绿色节点数 (参见上面的图片) 设置为 50, 隐藏层数 (参见绿色节点的层数) 为2。填写以下值:</p><ul><li>num_hidden_layers</li><li>hidden_layers_dim</li></ul><p>注意：在本图中，我们没有显示偏置节点（在逻辑回归教程中引入）。每个隐藏层都有一个偏置节点。</p><div class=\"highlight\"><pre><code class=\"language-text\">num_hidden_layers = 2\nhidden_layers_dim = 50</code></pre></div><p>网络的输入与输出：</p><ul><li><b>输入</b>变量 (一个关键的CNTK概念)：</li></ul><blockquote>在CNTK中，输入变量是面向用户代码的<b>容器</b>（container）。用户通过向输入变量提供不同的实例数据（数据点或数据点示例），等同于 (年龄、肿瘤大小) 元组在我们的例子中) 作为模型函数的输入 (也就是训练) 和模型评估 (又称测试)。因此，输入的形状必须与将提供的数据的形状相匹配。例如，如果每个数据点都是高度 <img src=\"https://www.zhihu.com/equation?tex=10\" alt=\"10\" eeimg=\"1\"/> 像素、宽度 <img src=\"https://www.zhihu.com/equation?tex=5\" alt=\"5\" eeimg=\"1\"/> 像素的灰度图像，则输入特征将是 <img src=\"https://www.zhihu.com/equation?tex=50\" alt=\"50\" eeimg=\"1\"/> 个 floating-point 值的向量，表示每个 <img src=\"https://www.zhihu.com/equation?tex=50\" alt=\"50\" eeimg=\"1\"/> 像素的强度，并且可以写成 c. input_variable (10 * 5, np float32)。同样，在我们的例子维度是年龄和肿瘤大小，因而 input_dim = 2。有关数据及其维度的更多信息，我们将在另外的教程中介绍。</blockquote><p><b>问题：</b></p><p>您所选择的模型的输入维度是什么？这对于我们理解网络中的变量或 CNTK 中的模型表示是至关重要的。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># The input variable (representing 1 observation, in our example of age and size) x, which </span>\n<span class=\"c1\"># in this case has a dimension of 2. </span>\n<span class=\"c1\">#</span>\n<span class=\"c1\"># The label variable has a dimensionality equal to the number of output classes in our case 2. </span>\n\n<span class=\"nb\">input</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">input_variable</span><span class=\"p\">(</span><span class=\"n\">input_dim</span><span class=\"p\">)</span>\n<span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">input_variable</span><span class=\"p\">(</span><span class=\"n\">num_output_classes</span><span class=\"p\">)</span></code></pre></div><h2><b>构建前向神经网络</b></h2><p>让我们在这里定义前向神经网络。其中，第一层接收 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> 维的<b>输入特征向量</b>，并输出维度为 <img src=\"https://www.zhihu.com/equation?tex=n\" alt=\"n\" eeimg=\"1\"/> 的<b>置信度</b>（<i>evidence</i>）层 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bz_1%7D\" alt=\"\\bf{z_1}\" eeimg=\"1\"/> 。在输入层的每一个特征，都在输出层由某个特定的 <img src=\"https://www.zhihu.com/equation?tex=m%2An\" alt=\"m*n\" eeimg=\"1\"/> 维的矩阵 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BW%7D\" alt=\"\\bf{W}\" eeimg=\"1\"/> 表示。我们的第一步时计算整个特征集合中的<b>置信度</b>（evidence）。注意，对于矩阵或者向量，我们使用<b>粗体</b>表示：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bz_1%7D+%3D+%5Cbf%7BW%7D+%5Ccdot+%5Cbf%7Bx%7D+%2B+%5Cbf%7Bb%7D\" alt=\"\\bf{z_1} = \\bf{W} \\cdot \\bf{x} + \\bf{b}\" eeimg=\"1\"/></p><p>其中， <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bb%7D\" alt=\"\\bf{b}\" eeimg=\"1\"/> 是维度为 <img src=\"https://www.zhihu.com/equation?tex=n\" alt=\"n\" eeimg=\"1\"/> 的向量。</p><p>在<b>线性层</b>（linear_layer）函数中，我们定义了两种运算：</p><ol><li>将权重 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BW%7D\" alt=\"\\bf{W}\" eeimg=\"1\"/> 与特征向量 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bx%7D\" alt=\"\\bf{x}\" eeimg=\"1\"/> 相乘，再加上独立的<b>特征贡献</b>（individual features&#39; contribution）。</li><li>加上偏置 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bb%7D\" alt=\"\\bf{b}\" eeimg=\"1\"/> .</li></ol><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"k\">def</span> <span class=\"nf\">linear_layer</span><span class=\"p\">(</span><span class=\"n\">input_var</span><span class=\"p\">,</span> <span class=\"n\">output_dim</span><span class=\"p\">):</span>\n    <span class=\"n\">input_dim</span> <span class=\"o\">=</span> <span class=\"n\">input_var</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n\n    <span class=\"n\">weight</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">parameter</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">output_dim</span><span class=\"p\">))</span>\n    <span class=\"n\">bias</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">parameter</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">output_dim</span><span class=\"p\">))</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">bias</span> <span class=\"o\">+</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">times</span><span class=\"p\">(</span><span class=\"n\">input_var</span><span class=\"p\">,</span> <span class=\"n\">weight</span><span class=\"p\">)</span></code></pre></div><p>我们需要做的下一步，是将<b>置信度</b>（<i>evidence</i>）通过你选择的<b>激活函数</b>（ <i>activation functions</i>），转换为离散的具体分类。简而言之，如果网络认为某个特定分类的置信度很高，则可能说明输入特性 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bx%7D\" alt=\"\\bf{x}\" eeimg=\"1\"/> 输入这个分类。 <img src=\"https://www.zhihu.com/equation?tex=sigmoid\" alt=\"sigmoid\" eeimg=\"1\"/> 或者 <img src=\"https://www.zhihu.com/equation?tex=tanh\" alt=\"tanh\" eeimg=\"1\"/> 函数曾经很流行。我们将在这一讲中使用 <img src=\"https://www.zhihu.com/equation?tex=sigmoid\" alt=\"sigmoid\" eeimg=\"1\"/> 函数作为示例。 <img src=\"https://www.zhihu.com/equation?tex=sigmoid\" alt=\"sigmoid\" eeimg=\"1\"/> 函数的输出将作为下一层的输出，或者整个网络的输出。</p><p><b>问题：</b></p><p>试试将激活函数换为其他的函数：</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"k\">def</span> <span class=\"nf\">dense_layer</span><span class=\"p\">(</span><span class=\"n\">input_var</span><span class=\"p\">,</span> <span class=\"n\">output_dim</span><span class=\"p\">,</span> <span class=\"n\">nonlinearity</span><span class=\"p\">):</span>\n    <span class=\"n\">l</span> <span class=\"o\">=</span> <span class=\"n\">linear_layer</span><span class=\"p\">(</span><span class=\"n\">input_var</span><span class=\"p\">,</span> <span class=\"n\">output_dim</span><span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">nonlinearity</span><span class=\"p\">(</span><span class=\"n\">l</span><span class=\"p\">)</span></code></pre></div><p>现在，我们创建了一个<b>隐藏层</b>（hidden layer），我们需要对这些层进行迭代，以训练一个<b>全连接</b>（fully connected）的分类器。第一层的输出 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bh_1%7D\" alt=\"\\bf{h_1}\" eeimg=\"1\"/>，将作为下一层的输入。</p><p>在我们拥有 <img src=\"https://www.zhihu.com/equation?tex=2\" alt=\"2\" eeimg=\"1\"/> 层的示例中，我们可以用代码表示为：</p><div class=\"highlight\"><pre><code class=\"language-text\">h1 = dense_layer(input_var, hidden_layer_dim, sigmoid)\nh2 = dense_layer(h1, hidden_layer_dim, sigmoid)</code></pre></div><p>要在尝试使用层数时更加灵活, 我们更愿意将其写成如下所示:</p><div class=\"highlight\"><pre><code class=\"language-text\">h = dense_layer(input_var, hidden_layer_dim, sigmoid)\nfor i in range(1, num_hidden_layers):\n    h = dense_layer(h, hidden_layer_dim, sigmoid)</code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Define a multilayer feedforward classification model</span>\n<span class=\"k\">def</span> <span class=\"nf\">fully_connected_classifier_net</span><span class=\"p\">(</span><span class=\"n\">input_var</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">,</span> <span class=\"n\">hidden_layer_dim</span><span class=\"p\">,</span> \n                                   <span class=\"n\">num_hidden_layers</span><span class=\"p\">,</span> <span class=\"n\">nonlinearity</span><span class=\"p\">):</span>\n\n    <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">dense_layer</span><span class=\"p\">(</span><span class=\"n\">input_var</span><span class=\"p\">,</span> <span class=\"n\">hidden_layer_dim</span><span class=\"p\">,</span> <span class=\"n\">nonlinearity</span><span class=\"p\">)</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">num_hidden_layers</span><span class=\"p\">):</span>\n        <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">dense_layer</span><span class=\"p\">(</span><span class=\"n\">h</span><span class=\"p\">,</span> <span class=\"n\">hidden_layer_dim</span><span class=\"p\">,</span> <span class=\"n\">nonlinearity</span><span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">linear_layer</span><span class=\"p\">(</span><span class=\"n\">h</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">)</span></code></pre></div><p>网络输出 <img src=\"https://www.zhihu.com/equation?tex=z\" alt=\"z\" eeimg=\"1\"/> 将用于表示跨网络的输出。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Create the fully connected classfier</span>\n<span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">fully_connected_classifier_net</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">,</span> <span class=\"n\">hidden_layers_dim</span><span class=\"p\">,</span> \n                                   <span class=\"n\">num_hidden_layers</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">sigmoid</span><span class=\"p\">)</span></code></pre></div><p>虽然上述网络帮助我们更好地理解如何使用 CNTK 的基元实现网络, 但使用层库更方便、更快。它提供了预定义的常用 &#34;层&#34; (乐高积木), 它简化了由标准层堆叠在一起的网络的设计。例如, dense_layer 已经很容易地通过稠密层函数来组成我们的深模型。我们可以通过输入变量 (输入) 到这个模型, 以获得网络输出。</p><p><b>建议任务：</b></p><p>请浏览上面定义的模型和 create_model 函数的输出，并说服您自己，下面的实现封装了上面的代码。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"k\">def</span> <span class=\"nf\">create_model</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">):</span>\n    <span class=\"k\">with</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">default_options</span><span class=\"p\">(</span><span class=\"n\">init</span><span class=\"o\">=</span><span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">glorot_uniform</span><span class=\"p\">(),</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">sigmoid</span><span class=\"p\">):</span>\n        <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">features</span>\n        <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_hidden_layers</span><span class=\"p\">):</span>\n            <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"n\">hidden_layers_dim</span><span class=\"p\">)(</span><span class=\"n\">h</span><span class=\"p\">)</span>\n        <span class=\"n\">last_layer</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"n\">num_output_classes</span><span class=\"p\">,</span> <span class=\"n\">activation</span> <span class=\"o\">=</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n\n        <span class=\"k\">return</span> <span class=\"n\">last_layer</span><span class=\"p\">(</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">create_model</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">)</span></code></pre></div><p><b>学习模型参数</b></p><p>现在我们的网络已经构建好了，我们需要对于我们网络中的每一<b>层</b>（layer），学习参数 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BW%7D\" alt=\"\\bf{W}\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bb%7D\" alt=\"\\bf{b}\" eeimg=\"1\"/>。</p><p>fNow that the network is setup, we would like to learn the paramor each of the layers in our network. To do so we convert, the computed evidence ( <img src=\"https://www.zhihu.com/equation?tex=+%5Cbf+z_%7Bfinal~layer%7D\" alt=\" \\bf z_{final~layer}\" eeimg=\"1\"/> ) into a set of predicted probabilities ( <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BP%7D\" alt=\"\\bf{P}\" eeimg=\"1\"/> ) using a softmax function.</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ctextbf%7Bp%7D+%3D+%5Cmathrm%7Bsoftmax%7D%28%5Cbf%7Bz_%7Bfinal~layer%7D%7D%29\" alt=\"\\textbf{p} = \\mathrm{softmax}(\\bf{z_{final~layer}})\" eeimg=\"1\"/></p><p>One can see the softmax function as an activation function that maps the accumulated evidences to a probability distribution over the classes (Details of the <u><a href=\"https://link.zhihu.com/?target=https%3A//www.cntk.ai/pythondocs/cntk.ops.html%23cntk.ops.softmax\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">softmax function</a></u>). Other choices of activation function can be <u><a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/Brainscript-Activation-Functions\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">found here</a></u>.</p><h2><b>训练</b></h2><p>如果你已经阅读过 CNTK101的相关部分，你可以跳过这一节的描述。</p><p><img src=\"https://www.zhihu.com/equation?tex=%7Bsoftmax%7D\" alt=\"{softmax}\" eeimg=\"1\"/> 函数的输出是一个概率，它表示了数据属于哪个类的概率有多大。为了训练分类器，我们需要确定模型需要模仿的行为。换言之，我们希望生成的概率尽可能接近所观察到的标签。我们可以通过最小化我们的输出和地面真相标签的区别来实现这一点。此差异由成本函数 <img src=\"https://www.zhihu.com/equation?tex=%7Bcost%7D\" alt=\"{cost}\" eeimg=\"1\"/> 或损失函数<img src=\"https://www.zhihu.com/equation?tex=%7Bloss%7D\" alt=\"{loss}\" eeimg=\"1\"/>计算。</p><p><b>交叉熵</b> <img src=\"https://www.zhihu.com/equation?tex=%7BCross-entropy%7D\" alt=\"{Cross-entropy}\" eeimg=\"1\"/> 是一种常见的损耗函数。它被定义为：</p><p><img src=\"https://www.zhihu.com/equation?tex=H%28p%29+%3D+-+%5Csum_%7Bj%3D1%7D%5E%7B%7C+%5Ctextbf+y+%7C%7D+y_j+%5Clog+%28p_j%29\" alt=\"H(p) = - \\sum_{j=1}^{| \\textbf y |} y_j \\log (p_j)\" eeimg=\"1\"/></p><p>其中，训练数据随附的 <img src=\"https://www.zhihu.com/equation?tex=%7Bp%7D\" alt=\"{p}\" eeimg=\"1\"/> 是从 <img src=\"https://www.zhihu.com/equation?tex=softmax\" alt=\"softmax\" eeimg=\"1\"/> 函数得出的预测概率，y是标签。在我们的二分类示例中，<b>标签</b>（label）是一个二维变量（等同于num_output_classes或者 <img src=\"https://www.zhihu.com/equation?tex=%7C+y+%7C\" alt=\"| y |\" eeimg=\"1\"/> ）。通常，标签变量将有 <img src=\"https://www.zhihu.com/equation?tex=%7B%7Cy%7C%7D\" alt=\"{|y|}\" eeimg=\"1\"/> 元素与 <img src=\"https://www.zhihu.com/equation?tex=0\" alt=\"0\" eeimg=\"1\"/> 的任何地方, 除了在数据点的真正类的索引, 它将是 <img src=\"https://www.zhihu.com/equation?tex=%7B1%7D\" alt=\"{1}\" eeimg=\"1\"/> 。强烈建议您了解交叉熵函数的<a href=\"https://link.zhihu.com/?target=http%3A//colah.github.io/posts/2015-09-Visual-Information/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">详细信息</a>。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">cross_entropy_with_softmax</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">)</span></code></pre></div><h2><b>评估模型</b></h2><p>为了评估我们分类的效果，我们可将网络对于每一个实例的输出当做<b>置信向量</b>（vector of evidences），使用 <img src=\"https://www.zhihu.com/equation?tex=softmax\" alt=\"softmax\" eeimg=\"1\"/> 函数转换为最可能的分类，然后与标准答案进行对比。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">eval_error</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">classification_error</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">)</span></code></pre></div><h2><b>设置训练</b></h2><p>训练者使用<b>最优化</b>技术来尽量减少训练的<b>损耗</b>（loss）。在本教程中，我们将使用<b>随机梯度下降</b> ( <img src=\"https://www.zhihu.com/equation?tex=sgd\" alt=\"sgd\" eeimg=\"1\"/> )来进行训练，这是目前最流行的技术之一。通常，一个模型从其参数（权重 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BW%7D\" alt=\"\\bf{W}\" eeimg=\"1\"/> 和偏差 <img src=\"https://www.zhihu.com/equation?tex=b\" alt=\"b\" eeimg=\"1\"/> ）的随机初始化开始 ，模型接收到每个训练样本，随机梯度下降优化器都可以计算预测标签和对应的真实标签之间的损失或错误，并应用梯度下降算法，在每次观察后生成一组新的模型参数，从而改善模型的分类性能。</p><p>上述方法在每次迭代后，更新所有参数的过程都是有方向性的。因为它不需要将整个数据集（所有样本点）加载到内存中，并且可以在较少的数据上做出调整，从而允许对大型数据集进行培训。但是，每次使用单个样本生成的更新，在迭代之间会有很大的不同。于是，我们的变通方法是，先将一小组观察加载到模型中，并使用该集合中的损失或错误的平均值来更新模型参数。这个小的子集被称为 <img src=\"https://www.zhihu.com/equation?tex=minibatch\" alt=\"minibatch\" eeimg=\"1\"/>。</p><p>有了 <img src=\"https://www.zhihu.com/equation?tex=minibatches\" alt=\"minibatches\" eeimg=\"1\"/> ，我们经常从更大的训练数据集中抽取样本点。我们重复使用不同的训练样本组合更新模型参数的过程，并在一段时间内拟合最小化损失（和错误）。当错误率不再显著变化，或经过预设的最大 <img src=\"https://www.zhihu.com/equation?tex=minibatches\" alt=\"minibatches\" eeimg=\"1\"/> 数后，我们就可以说我们的模型是<b>经过训练</b>的。</p><p>其中，用于优化的关键参数之一是 <img src=\"https://www.zhihu.com/equation?tex=learning+rate\" alt=\"learning rate\" eeimg=\"1\"/> 。现在，我们可以简单地把它看作是一个缩放因子，它用于调整我们在任何迭代中改变参数的<b>程度</b>。我们将在后面的教程中介绍更多的细节。现在，有了这些信息，我们就可以创建我们的训练器了。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Instantiate the trainer object to drive the model training</span>\n<span class=\"n\">learning_rate</span> <span class=\"o\">=</span> <span class=\"mf\">0.5</span>\n<span class=\"n\">lr_schedule</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">learning_rate_schedule</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">UnitType</span><span class=\"o\">.</span><span class=\"n\">minibatch</span><span class=\"p\">)</span> \n<span class=\"n\">learner</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">sgd</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">,</span> <span class=\"n\">lr_schedule</span><span class=\"p\">)</span>\n<span class=\"n\">trainer</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">Trainer</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"n\">eval_error</span><span class=\"p\">),</span> <span class=\"p\">[</span><span class=\"n\">learner</span><span class=\"p\">])</span></code></pre></div><p>首先, 让我们构建一些额外的函数，来实现数据的可视化，以及与训练相关的功能。注意：这些方便的功能是为了让你深入地了解到底发生了什么。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Define a utility function to compute the moving average sum.</span>\n<span class=\"c1\"># A more efficient implementation is possible with np.cumsum() function</span>\n<span class=\"k\">def</span> <span class=\"nf\">moving_average</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">):</span>    \n    <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span> <span class=\"n\">w</span><span class=\"p\">:</span> \n        <span class=\"k\">return</span> <span class=\"n\">a</span><span class=\"p\">[:]</span>    <span class=\"c1\"># Need to send a copy of the array</span>\n    <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">val</span> <span class=\"k\">if</span> <span class=\"n\">idx</span> <span class=\"o\">&lt;</span> <span class=\"n\">w</span> <span class=\"k\">else</span> <span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">[(</span><span class=\"n\">idx</span><span class=\"o\">-</span><span class=\"n\">w</span><span class=\"p\">):</span><span class=\"n\">idx</span><span class=\"p\">])</span><span class=\"o\">/</span><span class=\"n\">w</span> <span class=\"k\">for</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">val</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)]</span>\n\n\n<span class=\"c1\"># Defines a utility that prints the training progress</span>\n<span class=\"k\">def</span> <span class=\"nf\">print_training_progress</span><span class=\"p\">(</span><span class=\"n\">trainer</span><span class=\"p\">,</span> <span class=\"n\">mb</span><span class=\"p\">,</span> <span class=\"n\">frequency</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">):</span>    \n    <span class=\"n\">training_loss</span> <span class=\"o\">=</span> <span class=\"s2\">&#34;NA&#34;</span>\n    <span class=\"n\">eval_error</span> <span class=\"o\">=</span> <span class=\"s2\">&#34;NA&#34;</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">mb</span><span class=\"o\">%</span><span class=\"n\">frequency</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n        <span class=\"n\">training_loss</span> <span class=\"o\">=</span> <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">previous_minibatch_loss_average</span>\n        <span class=\"n\">eval_error</span> <span class=\"o\">=</span> <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">previous_minibatch_evaluation_average</span>\n        <span class=\"k\">if</span> <span class=\"n\">verbose</span><span class=\"p\">:</span> \n            <span class=\"nb\">print</span> <span class=\"p\">(</span><span class=\"s2\">&#34;Minibatch: </span><span class=\"si\">{}</span><span class=\"s2\">, Train Loss: </span><span class=\"si\">{}</span><span class=\"s2\">, Train Error: </span><span class=\"si\">{}</span><span class=\"s2\">&#34;</span><span class=\"o\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">mb</span><span class=\"p\">,</span> <span class=\"n\">training_loss</span><span class=\"p\">,</span> <span class=\"n\">eval_error</span><span class=\"p\">))</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">mb</span><span class=\"p\">,</span> <span class=\"n\">training_loss</span><span class=\"p\">,</span> <span class=\"n\">eval_error</span></code></pre></div><h2><b>运行训练器</b></h2><p>我们现在已经准备好训练我们的逻辑回归模型。我们要决定哪些数据是我们需要投入到训练器中。</p><p>在本例中, 每一次迭代将对 <img src=\"https://www.zhihu.com/equation?tex=25\" alt=\"25\" eeimg=\"1\"/> 个样本进行处理（上面图中的 <img src=\"https://www.zhihu.com/equation?tex=25\" alt=\"25\" eeimg=\"1\"/> 个点），也就是 <img src=\"https://www.zhihu.com/equation?tex=minibatchsize\" alt=\"minibatchsize\" eeimg=\"1\"/> 。我们想训练 <img src=\"https://www.zhihu.com/equation?tex=20000\" alt=\"20000\" eeimg=\"1\"/> 个数据点。如果数据中的样本数仅为 <img src=\"https://www.zhihu.com/equation?tex=10000\" alt=\"10000\" eeimg=\"1\"/> 个，则训练器将通过数据进行 <img src=\"https://www.zhihu.com/equation?tex=2\" alt=\"2\" eeimg=\"1\"/> 轮传递。这由  <img src=\"https://www.zhihu.com/equation?tex=numMinibatchesToTrain\" alt=\"numMinibatchesToTrain\" eeimg=\"1\"/>表示。注意：在现实世界中，我们会得到一定数量的标记数据 (在这个例子中，(年龄, 大小) 观察及其标签 (良性/恶性))。我们将其中的大量的数据（比如说  <img src=\"https://www.zhihu.com/equation?tex=70\" alt=\"70\" eeimg=\"1\"/> %）用于训练，并将剩下的部分用于评估训练过的模型。</p><p>有了这些参数，我们就可以继续训练我们的简单前馈网络。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Initialize the parameters for the trainer</span>\n<span class=\"n\">minibatch_size</span> <span class=\"o\">=</span> <span class=\"mi\">25</span>\n<span class=\"n\">num_samples</span> <span class=\"o\">=</span> <span class=\"mi\">20000</span>\n<span class=\"n\">num_minibatches_to_train</span> <span class=\"o\">=</span> <span class=\"n\">num_samples</span> <span class=\"o\">/</span> <span class=\"n\">minibatch_size</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Run the trainer and perform model training</span>\n<span class=\"n\">training_progress_output_freq</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>\n\n<span class=\"n\">plotdata</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">:[],</span> <span class=\"s2\">&#34;loss&#34;</span><span class=\"p\">:[],</span> <span class=\"s2\">&#34;error&#34;</span><span class=\"p\">:[]}</span>\n\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">num_minibatches_to_train</span><span class=\"p\">)):</span>\n    <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">generate_random_data_sample</span><span class=\"p\">(</span><span class=\"n\">minibatch_size</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Specify the input variables mapping in the model to actual minibatch data for training</span>\n    <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">train_minibatch</span><span class=\"p\">({</span><span class=\"nb\">input</span> <span class=\"p\">:</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">label</span> <span class=\"p\">:</span> <span class=\"n\">labels</span><span class=\"p\">})</span>\n    <span class=\"n\">batchsize</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">print_training_progress</span><span class=\"p\">(</span><span class=\"n\">trainer</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> \n                                                     <span class=\"n\">training_progress_output_freq</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"p\">(</span><span class=\"n\">loss</span> <span class=\"o\">==</span> <span class=\"s2\">&#34;NA&#34;</span> <span class=\"ow\">or</span> <span class=\"n\">error</span> <span class=\"o\">==</span><span class=\"s2\">&#34;NA&#34;</span><span class=\"p\">):</span>\n        <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">batchsize</span><span class=\"p\">)</span>\n        <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;loss&#34;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">)</span>\n        <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;error&#34;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">error</span><span class=\"p\">)</span></code></pre></div><p>让我们来看看在不同的让我们在不同的训练 minibatches 上绘制错误。请注意, 当我们迭代训练损失减少, 虽然我们看到一些中间的颠簸。凸点表明, 在迭代过程中, 模型遇到了错误的观测。这可能发生在模型训练期间是新颖的观察。</p><p>一个方法来抚平的颠簸是通过增加 minibatch 的大小。在每个迭代中, 都可以从概念上使用整个数据集。这将确保损失在迭代时持续递减。但是, 此方法要求在数据集中的所有点上进行梯度计算, 并在本地更新大量迭代的模型参数之后重复这些运算。对于这个玩具的例子, 它不是一个大问题。然而, 在实际的例子中, 对每个参数更新迭代的整个数据集进行多次传递将变得计算性的禁止。</p><p>因此, 我们使用较小的 minibatches, 使用 sgd 可以使我们在性能大型数据集时具有很大的可伸缩性。有先进的变种的优化器独特的 CNTK, 使利用计算效率的真实世界的数据集, 将在高级教程中介绍。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Compute the moving average loss to smooth out the noise in SGD</span>\n<span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgloss&#34;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">moving_average</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;loss&#34;</span><span class=\"p\">])</span>\n<span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgerror&#34;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">moving_average</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;error&#34;</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Plot the training loss and the training error</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">subplot</span><span class=\"p\">(</span><span class=\"mi\">211</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">],</span> <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgloss&#34;</span><span class=\"p\">],</span> <span class=\"s1\">&#39;b--&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch number&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Loss&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch run vs. Training loss&#39;</span><span class=\"p\">)</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">subplot</span><span class=\"p\">(</span><span class=\"mi\">212</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">],</span> <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgerror&#34;</span><span class=\"p\">],</span> <span class=\"s1\">&#39;r--&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch number&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Label Prediction Error&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch run vs. Label Prediction Error&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-48a1abe63c35aa35db57e2326acd30bc_b.png\" data-caption=\"\" data-rawwidth=\"393\" data-rawheight=\"159\" class=\"content_image\" width=\"393\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;393&#39; height=&#39;159&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"393\" data-rawheight=\"159\" class=\"content_image lazy\" width=\"393\" data-actualsrc=\"https://pic1.zhimg.com/v2-48a1abe63c35aa35db57e2326acd30bc_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-601ffae6769e129bd0eac6574c2968e0_b.png\" data-caption=\"\" data-rawwidth=\"393\" data-rawheight=\"159\" class=\"content_image\" width=\"393\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;393&#39; height=&#39;159&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"393\" data-rawheight=\"159\" class=\"content_image lazy\" width=\"393\" data-actualsrc=\"https://pic1.zhimg.com/v2-601ffae6769e129bd0eac6574c2968e0_b.png\"/></figure><h2><b>评估/测试</b></h2><p>到目前为止，我们已经对我们的网络进行了训练。现在来让我们预测那些没有在训练集中出现的数据——这就是所谓的<b>测试数据</b>（testing）。在本例中，我们来创建一些新的数据，并评估这一组数据的的平均错误和损失。我们使用训练器的 <img src=\"https://www.zhihu.com/equation?tex=testMinibatch\" alt=\"testMinibatch\" eeimg=\"1\"/> 方法。注意，此以前未看过的数据的错误与培训错误类似。这是一个<b>关键的</b>检查。如果错误大于训练错误的幅度很大，则表明训练的模型在训练过程中所未看到的数据将无法很好地执行。这就是所谓的拟合。有几种方法可以解决超出本教程范围的拟合，但CNTK提供了解决拟的必要组件。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Generate new data</span>\n<span class=\"n\">test_minibatch_size</span> <span class=\"o\">=</span> <span class=\"mi\">25</span>\n<span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">generate_random_data_sample</span><span class=\"p\">(</span><span class=\"n\">test_minibatch_size</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">)</span>\n\n<span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">test_minibatch</span><span class=\"p\">({</span><span class=\"nb\">input</span> <span class=\"p\">:</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">label</span> <span class=\"p\">:</span> <span class=\"n\">labels</span><span class=\"p\">})</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">0.12</code></pre></div><p><b>为什么我们需要Why do we need to route the network output</b> <b>netout</b> <b>via</b> <b>softmax?</b></p><p>我们配置网络的方式包括所有激活节点的输出 (如图4中的绿色层)。输出节点 (图4中的橙色层) 将激活转换为概率。一个简单有效的方法是通过 softmax 函数来路由激活。</p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-86022d1d5257327a7bdc54b629554d6c_b.jpg\" data-caption=\"\" data-rawwidth=\"398\" data-rawheight=\"483\" class=\"content_image\" width=\"398\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;398&#39; height=&#39;483&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"398\" data-rawheight=\"483\" class=\"content_image lazy\" width=\"398\" data-actualsrc=\"https://pic1.zhimg.com/v2-86022d1d5257327a7bdc54b629554d6c_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">)</span></code></pre></div><p>让我们来对这些数据进行测试</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">predicted_label_probs</span> <span class=\"o\">=</span> <span class=\"n\">out</span><span class=\"o\">.</span><span class=\"nb\">eval</span><span class=\"p\">({</span><span class=\"nb\">input</span> <span class=\"p\">:</span> <span class=\"n\">features</span><span class=\"p\">})</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;Label    :&#34;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">label</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">label</span> <span class=\"ow\">in</span> <span class=\"n\">labels</span><span class=\"p\">])</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;Predicted:&#34;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">row</span> <span class=\"ow\">in</span> <span class=\"n\">predicted_label_probs</span><span class=\"p\">])</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">Label    : [1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1]\nPredicted: [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1]</code></pre></div><p>探索与建议</p><ul><li>试试看我们的分类器在不同的数据分布下的表现如何——比如，将 <img src=\"https://www.zhihu.com/equation?tex=minibatchSize\" alt=\"minibatchSize\" eeimg=\"1\"/> 参数从  <img src=\"https://www.zhihu.com/equation?tex=25\" alt=\"25\" eeimg=\"1\"/> 调整到 <img src=\"https://www.zhihu.com/equation?tex=64\" alt=\"64\" eeimg=\"1\"/> 。为什么错误的个数增加了？ 和逻辑回归相比，错误率有何不同？</li><li>尝试不同的优化器，比如： Adam (fsadagrad). learner = fsadagrad(z.parameters(), 0.02, 0, targetAdagradAvDenom=1)</li><li>你能尝试修改神经网络，来进一步降低错误率吗？什么时候你会看到<i>过拟合</i>现象的发生？</li></ul><p><b>代码链接</b></p><p>如果你想从命令行运行本教程的代码，请见<u><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/v2.0/Tutorials/NumpyInterop/FeedForwardNet.py\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">FeedForwardNet.py</a></u></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "CNTK", 
                    "tagLink": "https://api.zhihu.com/topics/20046732"
                }, 
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }, 
                {
                    "tag": "入门指南", 
                    "tagLink": "https://api.zhihu.com/topics/19564657"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/28048444", 
            "userName": "王万霖", 
            "userLink": "https://www.zhihu.com/people/b8f13b7ce876ce5f99a47ce6cd2956f0", 
            "upvote": 8, 
            "title": "CNTK101：使用CNTK进行线性回归", 
            "content": "<blockquote>如果你刚开始接触CNTK或者机器学习，<a href=\"https://zhuanlan.zhihu.com/msrcntk\" class=\"internal\">我们的专栏</a>正适合你！在这一讲中，你将会接触到一种在机器学习中简单高效且广泛应用的模型：该模型通过利用其可伸缩性，以最快的方式对海量数据集，利用现有的计算资源（一个或多个 CPU 内核、一个或多个 GPU、一组 CPU 或一组 GPU）通过 CNTK 库直观地进行数据分析。</blockquote><p>大家好，相信看了我们的<a href=\"https://zhuanlan.zhihu.com/p/28047133\" class=\"internal\">第一篇文章</a>，大家对 CNTK 已经有一个简单的了解了。在<a href=\"https://zhuanlan.zhihu.com/p/28048210\" class=\"internal\">将 CNTK 安装好</a>之后，今天我们将带领大家使用 CNTK 库完成我们的第一个任务，使大家对于 CNTK 库和线性回归有着简单的了解，那么，我们开始吧！</p><h2>简介</h2><p><b>我们的问题：</b><br/>一家癌症医院为我们提供了一批<b>患者</b>的数据，并希望我们能确定患者<b>是否患有致命的恶性肿瘤</b>：这是一个<b>分类</b>（classification）问题。为了能让我们对每个病人进行分类，医院提供的数据是：患者的年龄和肿瘤的大小。有了这些数据，我们就有了一个主观的想法：也许年轻的病人和/或小肿瘤患者不太可能患上恶性肿瘤？</p><p>在这一讲中，我们将机器生成的<b>模拟</b>数据集进行练习：每个病人在图表中表示成为一个<b>点</b>，这个点被称为数据<b>实例</b>（instance）。其中红色的点表示其患有恶性肿瘤、蓝色则表示良性。</p><p>注意：这只是一个学习的简单示例；在现实生活中，医生将会对患者从不同的方面进行测试/检查，之后再做出决定。</p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-8ba134e4e08030eeb563fedc917d1bd4_b.jpg\" data-rawwidth=\"570\" data-rawheight=\"400\" class=\"origin_image zh-lightbox-thumb\" width=\"570\" data-original=\"https://pic1.zhimg.com/v2-8ba134e4e08030eeb563fedc917d1bd4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;570&#39; height=&#39;400&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"570\" data-rawheight=\"400\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"570\" data-original=\"https://pic1.zhimg.com/v2-8ba134e4e08030eeb563fedc917d1bd4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-8ba134e4e08030eeb563fedc917d1bd4_b.jpg\"/></figure><p><b>我们的目标：</b></p><p>我们的目标是构建一个<b>分类器</b>（classifier），它可以根据每个病人的属性 （年龄和肿瘤大小）来进行学习，从而分辨出病人所患的肿瘤是良性还是恶性的。在这一讲中，我们会使用 CNTK 构造一个<b>线性分类器</b>（linear classifier）——这是一种深度学习网络中的基础元素。</p><p>下面的图是我们今天要完成的目标：绿色的直线代表我们的学习器从数据集中学习的模型，它能够将蓝色点与红色点分开。在这一讲中，我们将指导你通过一些机器学习算法，生成图中的绿线。</p><p>注意：这个分类器有时可能会出错，在图中我们会发现，在绿线的一侧有几个蓝色的点被分类错误了。有一些方法可以解决这个问题，我们将在后面的教程中介绍一些技巧。</p><figure><noscript><img src=\"https://pic4.zhimg.com/v2-19a3c3267118b474491fa37fa173050f_b.jpg\" data-rawwidth=\"860\" data-rawheight=\"575\" class=\"origin_image zh-lightbox-thumb\" width=\"860\" data-original=\"https://pic4.zhimg.com/v2-19a3c3267118b474491fa37fa173050f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;860&#39; height=&#39;575&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"860\" data-rawheight=\"575\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"860\" data-original=\"https://pic4.zhimg.com/v2-19a3c3267118b474491fa37fa173050f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-19a3c3267118b474491fa37fa173050f_b.jpg\"/></figure><p><b>我们的研究方法：</b><br/>一般地，实现一种机器学习方法一般由五个步骤组成：数据读取、数据预处理、创建模型、学习模型参数和模型评估（又称测试/预测）</p><ol><li><b>数据读取</b>：生成我们的模拟数据集，其中每个样本应该具有两个<b>特征</b>（feature）：表明患者的<b>年龄</b>和<b>肿瘤大小</b>。</li><li><b>数据预处理</b>：通常，我们需要对肿瘤大小或年龄等个别特征的数值进行<b>缩放</b>。通常，我们会将数据映射在 <img src=\"https://www.zhihu.com/equation?tex=0\" alt=\"0\" eeimg=\"1\"/> 到 <img src=\"https://www.zhihu.com/equation?tex=%7B1%7D\" alt=\"{1}\" eeimg=\"1\"/> 之间的区间。为了简单起见，我们在本教程中并没有涉及（有兴趣的同学可以看看： <a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Feature_scaling\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">功能缩放</a>（英文））。</li><li><b>模型创建</b>：我们将在本教程中引入一个基本的线性模型。</li><li><b>学习模型</b>：这也称为<b>训练</b>（training）。我们可以通过各种方式（比如，线性回归）来拟合线性模型，获取我们的最终直线。在 CNTK 中，我们使用<b>随机梯度下降</b>的方法, 又称 <img src=\"https://www.zhihu.com/equation?tex=SGD\" alt=\"SGD\" eeimg=\"1\"/> 。</li><li><b>评估</b>：这也称为<b>测试</b>，我们使用一组<b>不在训练集中的数据</b>对模型进行测试，以便我们能够评估模型在真实环境中的表现，我们管这组数据叫做<b>测试集</b>（test set），从而和<b>训练集</b>（training set）区分开。</li></ol><h2>逻辑回归</h2><p><b><a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Logistic_regression\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">逻辑回归</a></b>（Logistic regression）是一种常用而基础的机器学习算法，它使用<b>线性加权</b>的<b>特征组合</b>，生成预测样本属于不同类的<b>概率</b>。在我们的例子中，分类器将产生一个区间在 <img src=\"https://www.zhihu.com/equation?tex=%5B0%2C1%5D\" alt=\"[0,1]\" eeimg=\"1\"/> 之间的概率，我们可以将它与某一个<b>阈值</b> (如 <img src=\"https://www.zhihu.com/equation?tex=0.5\" alt=\"0.5\" eeimg=\"1\"/>) 相比，从而判断其所属的类别 ( <img src=\"https://www.zhihu.com/equation?tex=0\" alt=\"0\" eeimg=\"1\"/>类或 <img src=\"https://www.zhihu.com/equation?tex=1\" alt=\"1\" eeimg=\"1\"/>类 ）。我们的方法也可以很容易地扩展到存在多个类的情况。</p><figure><noscript><img src=\"https://pic4.zhimg.com/v2-1fde0406d84f35b72f4e5513085aa6b3_b.jpg\" data-rawwidth=\"1830\" data-rawheight=\"603\" class=\"origin_image zh-lightbox-thumb\" width=\"1830\" data-original=\"https://pic4.zhimg.com/v2-1fde0406d84f35b72f4e5513085aa6b3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1830&#39; height=&#39;603&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1830\" data-rawheight=\"603\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1830\" data-original=\"https://pic4.zhimg.com/v2-1fde0406d84f35b72f4e5513085aa6b3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-1fde0406d84f35b72f4e5513085aa6b3_b.jpg\"/></figure><p>在上图中，来自不同输入特征的贡献（蓝色到绿色之间的黑线）是<b>线性加权</b>后<b>聚合</b>（fusion）的。所得的<b>总和</b>通过 <img src=\"https://www.zhihu.com/equation?tex=sigmoid\" alt=\"sigmoid\" eeimg=\"1\"/> 函数<b>映射</b>到 <img src=\"https://www.zhihu.com/equation?tex=%280%2C1%29\" alt=\"(0,1)\" eeimg=\"1\"/> 范围。对于具有<b>两个以上输出标签</b>的分类器，我们可以使用 <img src=\"https://www.zhihu.com/equation?tex=softmax\" alt=\"softmax\" eeimg=\"1\"/> 函数。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 导入相关组件</span>\n<span class=\"kn\">from</span> <span class=\"nn\">__future__</span> <span class=\"k\">import</span> <span class=\"n\">print_function</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">sys</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">cntk</span> <span class=\"k\">as</span> <span class=\"nn\">C</span>\n<span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">cntk_py</span><span class=\"o\">.</span><span class=\"n\">set_fixed_random_seed</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\"># 固定好随机种子，以便每次测试的结果一致</span></code></pre></div><h2>生成数据</h2><p>让我们基于 NumPy 库生成一些用于示例的模拟癌症数据。我们有两个输入特性 (以二维表示) 和两个输出类 (良性/蓝色或恶性/红色)。</p><p>在我们的示例中，训练数据中的每个实例 ( <img src=\"https://www.zhihu.com/equation?tex=2\" alt=\"2\" eeimg=\"1\"/> 个特征——年龄和大小) 都有一个标签 (蓝色或红色)。因为我们的输出只有两类，我们称之为二分类任务。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 定义我们的网络</span>\n<span class=\"n\">input_dim</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n<span class=\"n\">num_output_classes</span> <span class=\"o\">=</span> <span class=\"mi\">2</span></code></pre></div><h2>输入数据和标签</h2><p>在本教程中，我们将使用 NumPy 库生成的合成数据。在真实世界的问题中，你会用到CNTK中的<b>读取器</b>（Reader），读取特征值（年龄 和 肿瘤大小），并与每个患者对应。模拟的<i>年龄</i>变量被缩小到与另一个变量的范围相似：这是数据预处理的一个关键方面，我们将在以后的教程中进一步了解这些内容。注意：通常，观察和标签可以驻留在更高维度的空间中（当有更多的特征或分类可用时），然后在 CNTK 中表示为<b>张量</b>（tensor）。之后的教程将会介绍对高维数据的处理。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 固定好NumPy额随机种子</span>\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 用于生成随机样本的函数</span>\n<span class=\"k\">def</span> <span class=\"nf\">generate_random_data_sample</span><span class=\"p\">(</span><span class=\"n\">sample_size</span><span class=\"p\">,</span> <span class=\"n\">feature_dim</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"p\">):</span>\n    <span class=\"c1\"># 使用NumPy构建数据 </span>\n    <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">sample_size</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">low</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">high</span><span class=\"o\">=</span><span class=\"n\">num_classes</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># 确保数据可分</span>\n    <span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">sample_size</span><span class=\"p\">,</span> <span class=\"n\">feature_dim</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"mi\">3</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># 指定数据集的具体数据类型，我们后边会用到这个数据集</span>\n    <span class=\"c1\"># (默认的类型是double)</span>\n    <span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>    \n\n    <span class=\"c1\"># 将类别 0 转换为向量 &#34;1 0 0&#34;, </span>\n    <span class=\"c1\"># 类似地，类别 1 转换为向量 &#34;0 1 0&#34;, ...</span>\n    <span class=\"n\">class_ind</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">Y</span><span class=\"o\">==</span><span class=\"n\">class_number</span> <span class=\"k\">for</span> <span class=\"n\">class_number</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_classes</span><span class=\"p\">)]</span>\n    <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">asarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">hstack</span><span class=\"p\">(</span><span class=\"n\">class_ind</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">Y</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># Create the input variables denoting the features and the label data. Note: the input </span>\n<span class=\"c1\"># does not need additional info on the number of observations (Samples) since CNTK creates only </span>\n<span class=\"c1\"># the network topology first </span>\n<span class=\"n\">mysamplesize</span> <span class=\"o\">=</span> <span class=\"mi\">32</span>\n<span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">generate_random_data_sample</span><span class=\"p\">(</span><span class=\"n\">mysamplesize</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">)</span></code></pre></div><p>让我们将输入的数据可视化：</p><p><b>注意：</b>如果导入matplotlib.pyplot失败了，请在命令行运行以下命令： conda install matplotlib，这将会修复pyplot的相关依赖。如果你使用的是Anaconda以外的环境，请使用这个命令：pip install matplotlib。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 画出图像</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n\n<span class=\"c1\"># 0表示恶性(红色)，1表示良性(蓝色)</span>\n<span class=\"n\">colors</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;r&#39;</span> <span class=\"k\">if</span> <span class=\"n\">label</span> <span class=\"o\">==</span> <span class=\"mi\">0</span> <span class=\"k\">else</span> <span class=\"s1\">&#39;b&#39;</span> <span class=\"k\">for</span> <span class=\"n\">label</span> <span class=\"ow\">in</span> <span class=\"n\">labels</span><span class=\"p\">[:,</span><span class=\"mi\">0</span><span class=\"p\">]]</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">scatter</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">[:,</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">features</span><span class=\"p\">[:,</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">c</span><span class=\"o\">=</span><span class=\"n\">colors</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s2\">&#34;Age (scaled)&#34;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s2\">&#34;Tumor size (in cm)&#34;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span></code></pre></div><p>如果不安装插件的话，matplotlib好像是不支持中文的= =</p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-6fcd0c800454d11d79803efa86d51468_b.png\" data-rawwidth=\"387\" data-rawheight=\"271\" class=\"content_image\" width=\"387\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;387&#39; height=&#39;271&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"387\" data-rawheight=\"271\" class=\"content_image lazy\" width=\"387\" data-actualsrc=\"https://pic1.zhimg.com/v2-6fcd0c800454d11d79803efa86d51468_b.png\"/></figure><h2>创建模型</h2><p><b>逻辑回归</b>（logistic regression，LR）网络是一种简单的模型。在过去的十年里，逻辑回归驱动了许多重要的机器学习算法及其应用。它属于一种线性模型，我们能将一组存储待分类实例特征的向量 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bx%7D\" alt=\"\\bf{x}\" eeimg=\"1\"/> （又称<b>特征向量</b>，下图中蓝色的点集）作为模型的输入，得出<b>证据</b>（evidence） <img src=\"https://www.zhihu.com/equation?tex=%7Bz%7D\" alt=\"{z}\" eeimg=\"1\"/> （绿色节点的输出，又称<b>激活</b>）。在输入层的每一个特征都与输出层存在一个连接权重 <img src=\"https://www.zhihu.com/equation?tex=%7Bw%7D\" alt=\"{w}\" eeimg=\"1\"/> （以不同粗细的黑线表示，见下图）</p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-dd2077b2f59cda3166d9aa90b10c6828_b.jpg\" data-rawwidth=\"1123\" data-rawheight=\"482\" class=\"origin_image zh-lightbox-thumb\" width=\"1123\" data-original=\"https://pic1.zhimg.com/v2-dd2077b2f59cda3166d9aa90b10c6828_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1123&#39; height=&#39;482&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1123\" data-rawheight=\"482\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1123\" data-original=\"https://pic1.zhimg.com/v2-dd2077b2f59cda3166d9aa90b10c6828_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-dd2077b2f59cda3166d9aa90b10c6828_b.jpg\"/></figure><p>第一步是计算点集的<b>证据</b>（evidence）：</p><p><img src=\"https://www.zhihu.com/equation?tex=+z+%3D+%5Csum_%7Bi%3D1%7D%5En+w_i+%5Ctimes+x_i+%2B+b+%3D+%5Ctextbf%7Bw%7D+%5Ccdot+%5Ctextbf%7Bx%7D+%2B+b\" alt=\" z = \\sum_{i=1}^n w_i \\times x_i + b = \\textbf{w} \\cdot \\textbf{x} + b\" eeimg=\"1\"/></p><p>其中， <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bw%7D\" alt=\"\\bf{w}\" eeimg=\"1\"/> 是长度为 <img src=\"https://www.zhihu.com/equation?tex=%7Bn%7D\" alt=\"{n}\" eeimg=\"1\"/> 的<b>权重向量</b>（weight vector）， <img src=\"https://www.zhihu.com/equation?tex=%7Bb%7D\" alt=\"{b}\" eeimg=\"1\"/> 被称为<b>偏置</b>（bias）。我们使用数学公式中的<b>粗体</b>来表示向量。</p><p>计算出的证据被映射到 <img src=\"https://www.zhihu.com/equation?tex=%280%2C1%29\" alt=\"(0,1)\" eeimg=\"1\"/> 范围。使用 <img src=\"https://www.zhihu.com/equation?tex=%7Bsoftmax%7D\" alt=\"{softmax}\" eeimg=\"1\"/> 函数，(当结果可以在两个可能的类之一) 或一个 <img src=\"https://www.zhihu.com/equation?tex=%7Bsoftmax%7D\" alt=\"{softmax}\" eeimg=\"1\"/> 函数 (当结果可以在两个以上可能的类之一)。</p><p>网络的输入与输出：</p><ul><li><b>输入</b>变量（一个关键的CNTK概念）：</li></ul><blockquote>在CNTK中，输入变量是面向用户代码的<b>容器</b>（container）。用户通过向输入变量提供不同的实例数据（数据点或数据点示例），等同于 (年龄、肿瘤大小) 元组在我们的例子中) 作为模型函数的输入 (也就是训练) 和模型评估 (又称测试)。因此，输入的形状必须与将提供的数据的形状相匹配。例如，如果每个数据点都是高度 <img src=\"https://www.zhihu.com/equation?tex=10\" alt=\"10\" eeimg=\"1\"/> 像素、宽度 <img src=\"https://www.zhihu.com/equation?tex=5\" alt=\"5\" eeimg=\"1\"/> 像素的灰度图像，则输入特征将是 <img src=\"https://www.zhihu.com/equation?tex=50\" alt=\"50\" eeimg=\"1\"/> 个 floating-point 值的向量，表示每个 <img src=\"https://www.zhihu.com/equation?tex=50\" alt=\"50\" eeimg=\"1\"/> 像素的强度，并且可以写成 c. input_variable (10 * 5, np float32)。同样，在我们的例子维度是年龄和肿瘤大小，因而 input_dim = 2。有关数据及其维度的更多信息，我们将在另外的教程中介绍。</blockquote><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">feature</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">input_variable</span><span class=\"p\">(</span><span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span></code></pre></div><h2>构建网络</h2><p><i>linear_layer </i>函数是上述操作的等价实现。我们执行了其中的两种操作：</p><ol><li>使用 CNTK 提供的 <img src=\"https://www.zhihu.com/equation?tex=%7Btimes%7D\" alt=\"{times}\" eeimg=\"1\"/> 函数，将权重<img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bw%7D\" alt=\"\\bf{w}\" eeimg=\"1\"/>与特征向量<img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bx%7D\" alt=\"\\bf{x}\" eeimg=\"1\"/>相乘</li><li>加上偏置 <img src=\"https://www.zhihu.com/equation?tex=%7Bb%7D\" alt=\"{b}\" eeimg=\"1\"/></li></ol><p>CNTK提供的这些函数是针对特定硬件进行优化的，并且其具体细节对用户是隐藏的。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 定义一个dict，来存储模型的参数</span>\n<span class=\"n\">mydict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">linear_layer</span><span class=\"p\">(</span><span class=\"n\">input_var</span><span class=\"p\">,</span> <span class=\"n\">output_dim</span><span class=\"p\">):</span>\n\n    <span class=\"n\">input_dim</span> <span class=\"o\">=</span> <span class=\"n\">input_var</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n    <span class=\"n\">weight_param</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">parameter</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">output_dim</span><span class=\"p\">))</span>\n    <span class=\"n\">bias_param</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">parameter</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">output_dim</span><span class=\"p\">))</span>\n\n    <span class=\"n\">mydict</span><span class=\"p\">[</span><span class=\"s1\">&#39;w&#39;</span><span class=\"p\">],</span> <span class=\"n\">mydict</span><span class=\"p\">[</span><span class=\"s1\">&#39;b&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">weight_param</span><span class=\"p\">,</span> <span class=\"n\">bias_param</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">times</span><span class=\"p\">(</span><span class=\"n\">input_var</span><span class=\"p\">,</span> <span class=\"n\">weight_param</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">bias_param</span></code></pre></div><p><img src=\"https://www.zhihu.com/equation?tex=z\" alt=\"z\" eeimg=\"1\"/> 将用于表示网络的输出</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">output_dim</span> <span class=\"o\">=</span> <span class=\"n\">num_output_classes</span>\n<span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">linear_layer</span><span class=\"p\">(</span><span class=\"n\">feature</span><span class=\"p\">,</span> <span class=\"n\">output_dim</span><span class=\"p\">)</span></code></pre></div><p><b>学习模型参数</b></p><p>现在我们的网络已经构建好了，我们希望让我们的<b>线性层</b>（linear layer）来学习模型中的参数 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7Bw%7D\" alt=\"\\bf{w}\" eeimg=\"1\"/>和 <img src=\"https://www.zhihu.com/equation?tex=%7Bb%7D\" alt=\"{b}\" eeimg=\"1\"/>。为了达到我们的目的，我们通过 <img src=\"https://www.zhihu.com/equation?tex=softmax\" alt=\"softmax\" eeimg=\"1\"/> 函数，来将<b>计算证据</b>（computed evidence） <img src=\"https://www.zhihu.com/equation?tex=z\" alt=\"z\" eeimg=\"1\"/> 转换为一系列预测的概率 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BP%7D\" alt=\"\\bf{P}\" eeimg=\"1\"/> ：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BP%7D%3Dsoftmax%28%7Bz%7D%29\" alt=\"\\bf{P}=softmax({z})\" eeimg=\"1\"/></p><p><img src=\"https://www.zhihu.com/equation?tex=%7Bsoftmax%7D\" alt=\"{softmax}\" eeimg=\"1\"/> 函数是一个<b>激活函数</b>（activation function），它将置信度转换为一系列分类的概率。除此之外，在<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/Brainscript-Activation-Functions\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这里</a>还有其他的函数可供选择。</p><h2>训练 </h2><p><img src=\"https://www.zhihu.com/equation?tex=%7Bsoftmax%7D\" alt=\"{softmax}\" eeimg=\"1\"/> 函数的输出是一个概率，它表示了数据属于哪个类的可能性有多大。为了训练分类器，我们需要确定模型需要模仿的行为。换言之，我们希望生成的概率尽可能接近所<b>观察到</b>的标签。我们可以通过<b>最小化</b>我们的输出和地面真相标签的区别来实现这一点。此差异由成本函数 <img src=\"https://www.zhihu.com/equation?tex=%7Bcost%7D\" alt=\"{cost}\" eeimg=\"1\"/> 或损失函数<img src=\"https://www.zhihu.com/equation?tex=%7Bloss%7D\" alt=\"{loss}\" eeimg=\"1\"/>计算。</p><p><b>交叉熵</b> <img src=\"https://www.zhihu.com/equation?tex=%7BCross-entropy%7D\" alt=\"{Cross-entropy}\" eeimg=\"1\"/> 是一种常见的损耗函数。它被定义为：</p><p><img src=\"https://www.zhihu.com/equation?tex=H%28p%29+%3D+-+%5Csum_%7Bj%3D1%7D%5E%7B%7C+%5Ctextbf+y+%7C%7D+y_j+%5Clog+%28p_j%29\" alt=\"H(p) = - \\sum_{j=1}^{| \\textbf y |} y_j \\log (p_j)\" eeimg=\"1\"/></p><p>其中，训练数据随附的 <img src=\"https://www.zhihu.com/equation?tex=%7Bp%7D\" alt=\"{p}\" eeimg=\"1\"/> 是从 <img src=\"https://www.zhihu.com/equation?tex=softmax\" alt=\"softmax\" eeimg=\"1\"/> 函数得出的预测概率， <img src=\"https://www.zhihu.com/equation?tex=y\" alt=\"y\" eeimg=\"1\"/> 是标签。在我们的二分类示例中，<b>标签</b>（label）是一个二维变量（等同于num_output_classes或者 <img src=\"https://www.zhihu.com/equation?tex=%7C+y+%7C\" alt=\"| y |\" eeimg=\"1\"/> ）。通常，标签变量将有 <img src=\"https://www.zhihu.com/equation?tex=%7B%7Cy%7C%7D\" alt=\"{|y|}\" eeimg=\"1\"/> 元素与 <img src=\"https://www.zhihu.com/equation?tex=0\" alt=\"0\" eeimg=\"1\"/> 的任何地方, 除了在数据点的真正类的索引, 它将是 <img src=\"https://www.zhihu.com/equation?tex=%7B1%7D\" alt=\"{1}\" eeimg=\"1\"/> 。强烈建议您了解交叉熵函数的<a href=\"https://link.zhihu.com/?target=http%3A//colah.github.io/posts/2015-09-Visual-Information/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">详细信息</a>。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">label</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">input_variable</span><span class=\"p\">(</span><span class=\"n\">num_output_classes</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">cross_entropy_with_softmax</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">)</span></code></pre></div><p><b>评估</b></p><p>为了能够量化我们的分类效果，我们引入了 <a href=\"https://link.zhihu.com/?target=https%3A//www.cntk.ai/pythondocs/cntk.metrics.html%23cntk.metrics.classification_error\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">分类错误</a> 的概念，当我们的模型正确时（它能够预测正确的患者分类）其值为 <img src=\"https://www.zhihu.com/equation?tex=0\" alt=\"0\" eeimg=\"1\"/> ，否则为 <img src=\"https://www.zhihu.com/equation?tex=1\" alt=\"1\" eeimg=\"1\"/> 。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">eval_error</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">classification_error</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"p\">)</span></code></pre></div><h2>设置训练参数</h2><p>训练者使用<b>最优化</b>技术来尽量减少训练的<b>损耗</b>（loss）。在本教程中，我们将使用<b>随机梯度下降</b> ( <img src=\"https://www.zhihu.com/equation?tex=sgd\" alt=\"sgd\" eeimg=\"1\"/> )来进行训练，这是目前最流行的技术之一。通常，一个模型从其参数（权重 <img src=\"https://www.zhihu.com/equation?tex=%5Cbf%7BW%7D\" alt=\"\\bf{W}\" eeimg=\"1\"/> 和偏差 <img src=\"https://www.zhihu.com/equation?tex=b\" alt=\"b\" eeimg=\"1\"/> ）的随机初始化开始 ，模型接收到每个训练样本，随机梯度下降优化器都可以计算预测标签和对应的真实标签之间的损失或错误，并应用梯度下降算法，在每次观察后生成一组新的模型参数，从而改善模型的分类性能。</p><p>上述方法在每次迭代后，更新所有参数的过程都是有方向性的。因为它不需要将整个数据集（所有样本点）加载到内存中，并且可以在较少的数据上做出调整，从而允许对大型数据集进行培训。但是，每次使用单个样本生成的更新，在迭代之间会有很大的不同。于是，我们的变通方法是，先将一小组观察加载到模型中，并使用该集合中的损失或错误的平均值来更新模型参数。这个小的子集被称为 <img src=\"https://www.zhihu.com/equation?tex=minibatch\" alt=\"minibatch\" eeimg=\"1\"/>。</p><p>有了 <img src=\"https://www.zhihu.com/equation?tex=minibatches\" alt=\"minibatches\" eeimg=\"1\"/> ，我们经常从更大的训练数据集中抽取样本点。我们重复使用不同的训练样本组合更新模型参数的过程，并在一段时间内拟合最小化损失（和错误）。当错误率不再显著变化，或经过预设的最大 <img src=\"https://www.zhihu.com/equation?tex=minibatches\" alt=\"minibatches\" eeimg=\"1\"/> 数后，我们就可以说我们的模型是<b>经过训练</b>的。</p><p>其中，用于优化的关键参数之一是 <img src=\"https://www.zhihu.com/equation?tex=learning+rate\" alt=\"learning rate\" eeimg=\"1\"/> 。现在，我们可以简单地把它看作是一个缩放因子，它用于调整我们在任何迭代中改变参数的<b>程度</b>。我们将在后面的教程中介绍更多的细节。现在，有了这些信息，我们就可以创建我们的训练器了。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 设置训练器的一些参数，以用于训练</span>\n<span class=\"n\">learning_rate</span> <span class=\"o\">=</span> <span class=\"mf\">0.5</span>\n<span class=\"n\">lr_schedule</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">learning_rate_schedule</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">UnitType</span><span class=\"o\">.</span><span class=\"n\">minibatch</span><span class=\"p\">)</span> \n<span class=\"n\">learner</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">sgd</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">,</span> <span class=\"n\">lr_schedule</span><span class=\"p\">)</span>\n<span class=\"n\">trainer</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">Trainer</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"n\">eval_error</span><span class=\"p\">),</span> <span class=\"p\">[</span><span class=\"n\">learner</span><span class=\"p\">])</span></code></pre></div><p>首先，让我们构建一些额外的函数，来实现数据的可视化，以及与训练相关的功能。注意：这些方便的功能是为了让你深入地了解到底发生了什么。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 定义计算移动平均的函数</span>\n<span class=\"c1\"># 另外一种效率更快的实现是使用NumPy的np.cumsum()函数</span>\n<span class=\"k\">def</span> <span class=\"nf\">moving_average</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span> <span class=\"n\">w</span><span class=\"p\">:</span> \n        <span class=\"k\">return</span> <span class=\"n\">a</span><span class=\"p\">[:]</span>    \n    <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">val</span> <span class=\"k\">if</span> <span class=\"n\">idx</span> <span class=\"o\">&lt;</span> <span class=\"n\">w</span> <span class=\"k\">else</span> <span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">[(</span><span class=\"n\">idx</span><span class=\"o\">-</span><span class=\"n\">w</span><span class=\"p\">):</span><span class=\"n\">idx</span><span class=\"p\">])</span><span class=\"o\">/</span><span class=\"n\">w</span> <span class=\"k\">for</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">val</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)]</span>\n\n<span class=\"c1\"># 定义print训练过程的函数</span>\n<span class=\"k\">def</span> <span class=\"nf\">print_training_progress</span><span class=\"p\">(</span><span class=\"n\">trainer</span><span class=\"p\">,</span> <span class=\"n\">mb</span><span class=\"p\">,</span> <span class=\"n\">frequency</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">):</span>\n    <span class=\"n\">training_loss</span><span class=\"p\">,</span> <span class=\"n\">eval_error</span> <span class=\"o\">=</span> <span class=\"s2\">&#34;NA&#34;</span><span class=\"p\">,</span> <span class=\"s2\">&#34;NA&#34;</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">mb</span> <span class=\"o\">%</span> <span class=\"n\">frequency</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n        <span class=\"n\">training_loss</span> <span class=\"o\">=</span> <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">previous_minibatch_loss_average</span>\n        <span class=\"n\">eval_error</span> <span class=\"o\">=</span> <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">previous_minibatch_evaluation_average</span>\n        <span class=\"k\">if</span> <span class=\"n\">verbose</span><span class=\"p\">:</span> \n            <span class=\"nb\">print</span> <span class=\"p\">(</span><span class=\"s2\">&#34;Minibatch: </span><span class=\"si\">{0}</span><span class=\"s2\">, Loss: </span><span class=\"si\">{1:.4f}</span><span class=\"s2\">, Error: </span><span class=\"si\">{2:.2f}</span><span class=\"s2\">&#34;</span><span class=\"o\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">mb</span><span class=\"p\">,</span> <span class=\"n\">training_loss</span><span class=\"p\">,</span> <span class=\"n\">eval_error</span><span class=\"p\">))</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">mb</span><span class=\"p\">,</span> <span class=\"n\">training_loss</span><span class=\"p\">,</span> <span class=\"n\">eval_error</span></code></pre></div><h2>运行训练器</h2><p>我们现在已经准备好训练我们的逻辑回归模型。我们要决定哪些数据是我们需要投入到训练器中。</p><p>在本例中，每一次迭代将对 <img src=\"https://www.zhihu.com/equation?tex=25\" alt=\"25\" eeimg=\"1\"/> 个样本进行处理（上面图中的 <img src=\"https://www.zhihu.com/equation?tex=25\" alt=\"25\" eeimg=\"1\"/> 个点），也就是 <img src=\"https://www.zhihu.com/equation?tex=minibatchsize\" alt=\"minibatchsize\" eeimg=\"1\"/> 。我们想训练 <img src=\"https://www.zhihu.com/equation?tex=20000\" alt=\"20000\" eeimg=\"1\"/> 个数据点。如果数据中的样本数仅为 <img src=\"https://www.zhihu.com/equation?tex=10000\" alt=\"10000\" eeimg=\"1\"/> 个，则训练器将通过数据进行 <img src=\"https://www.zhihu.com/equation?tex=2\" alt=\"2\" eeimg=\"1\"/> 轮传递。这由  <img src=\"https://www.zhihu.com/equation?tex=numMinibatchesToTrain\" alt=\"numMinibatchesToTrain\" eeimg=\"1\"/>表示。注意：在现实世界中，我们会得到一定数量的标记数据 (在这个例子中，(年龄, 大小) 观察及其标签 (良性/恶性))。我们将其中的大量的数据（比如说  <img src=\"https://www.zhihu.com/equation?tex=70\" alt=\"70\" eeimg=\"1\"/> %）用于训练，并将剩下的部分用于评估训练过的模型。</p><p>有了这些参数，我们就可以继续训练我们的简单前馈网络。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 初始化训练器使用的相关参数</span>\n<span class=\"n\">minibatch_size</span> <span class=\"o\">=</span> <span class=\"mi\">25</span>\n<span class=\"n\">num_samples_to_train</span> <span class=\"o\">=</span> <span class=\"mi\">20000</span>\n<span class=\"n\">num_minibatches_to_train</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">num_samples_to_train</span>  <span class=\"o\">/</span> <span class=\"n\">minibatch_size</span><span class=\"p\">)</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"kn\">from</span> <span class=\"nn\">collections</span> <span class=\"k\">import</span> <span class=\"n\">defaultdict</span>\n\n<span class=\"c1\"># 运行我们的训练器（trainer），展示训练过程</span>\n<span class=\"n\">training_progress_output_freq</span> <span class=\"o\">=</span> <span class=\"mi\">50</span>\n<span class=\"n\">plotdata</span> <span class=\"o\">=</span> <span class=\"n\">defaultdict</span><span class=\"p\">(</span><span class=\"nb\">list</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">num_minibatches_to_train</span><span class=\"p\">):</span>\n    <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">generate_random_data_sample</span><span class=\"p\">(</span><span class=\"n\">minibatch_size</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">)</span>\n    <span class=\"c1\"># 使用minibatch的数据训练我们的模型</span>\n    <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">train_minibatch</span><span class=\"p\">({</span><span class=\"n\">feature</span> <span class=\"p\">:</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">label</span> <span class=\"p\">:</span> <span class=\"n\">labels</span><span class=\"p\">})</span>\n    <span class=\"n\">batchsize</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">print_training_progress</span><span class=\"p\">(</span><span class=\"n\">trainer</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> \n                                                     <span class=\"n\">training_progress_output_freq</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"p\">(</span><span class=\"n\">loss</span> <span class=\"o\">==</span> <span class=\"s2\">&#34;NA&#34;</span> <span class=\"ow\">or</span> <span class=\"n\">error</span> <span class=\"o\">==</span><span class=\"s2\">&#34;NA&#34;</span><span class=\"p\">):</span>\n        <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">batchsize</span><span class=\"p\">)</span>\n        <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;loss&#34;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">)</span>\n        <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;error&#34;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">error</span><span class=\"p\">)</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-text\">Minibatch: 0, Loss: 0.6931, Error: 0.32\nMinibatch: 50, Loss: 1.9350, Error: 0.36\nMinibatch: 100, Loss: 1.0764, Error: 0.32\nMinibatch: 150, Loss: 0.4856, Error: 0.20\nMinibatch: 200, Loss: 0.1319, Error: 0.08\nMinibatch: 250, Loss: 0.1330, Error: 0.08\nMinibatch: 300, Loss: 0.1012, Error: 0.04\nMinibatch: 350, Loss: 0.1091, Error: 0.04\nMinibatch: 400, Loss: 0.3094, Error: 0.08\nMinibatch: 450, Loss: 0.3230, Error: 0.12\nMinibatch: 500, Loss: 0.3986, Error: 0.20\nMinibatch: 550, Loss: 0.6744, Error: 0.24\nMinibatch: 600, Loss: 0.3004, Error: 0.12\nMinibatch: 650, Loss: 0.1676, Error: 0.12\nMinibatch: 700, Loss: 0.2777, Error: 0.12\nMinibatch: 750, Loss: 0.2311, Error: 0.04</code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 在随机梯度下降中计算移动平均损失，并平滑曲线</span>\n<span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgloss&#34;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">moving_average</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;loss&#34;</span><span class=\"p\">])</span>\n<span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgerror&#34;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">moving_average</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;error&#34;</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># 画出训练损失和训练错误的图像</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">subplot</span><span class=\"p\">(</span><span class=\"mi\">211</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">],</span> <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgloss&#34;</span><span class=\"p\">],</span> <span class=\"s1\">&#39;b--&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch number&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Loss&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch run vs. Training loss&#39;</span><span class=\"p\">)</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">subplot</span><span class=\"p\">(</span><span class=\"mi\">212</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;batchsize&#34;</span><span class=\"p\">],</span> <span class=\"n\">plotdata</span><span class=\"p\">[</span><span class=\"s2\">&#34;avgerror&#34;</span><span class=\"p\">],</span> <span class=\"s1\">&#39;r--&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch number&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s1\">&#39;Label Prediction Error&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s1\">&#39;Minibatch run vs. Label Prediction Error&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic2.zhimg.com/v2-da69c019d81244031d74dfc75c397fad_b.png\" data-rawwidth=\"393\" data-rawheight=\"159\" class=\"content_image\" width=\"393\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;393&#39; height=&#39;159&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"393\" data-rawheight=\"159\" class=\"content_image lazy\" width=\"393\" data-actualsrc=\"https://pic2.zhimg.com/v2-da69c019d81244031d74dfc75c397fad_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic3.zhimg.com/v2-06387d7f5c3318668de185a8dbb36b7a_b.png\" data-rawwidth=\"400\" data-rawheight=\"159\" class=\"content_image\" width=\"400\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;400&#39; height=&#39;159&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"400\" data-rawheight=\"159\" class=\"content_image lazy\" width=\"400\" data-actualsrc=\"https://pic3.zhimg.com/v2-06387d7f5c3318668de185a8dbb36b7a_b.png\"/></figure><h2>评估与测试</h2><p>到目前为止，我们已经对我们的网络进行了训练。现在来让我们预测那些没有在训练集中出现的数据——这就是所谓的<b>测试数据</b>（testing）。在本例中，我们来创建一些新的数据，并评估这一组数据的的平均错误和损失。我们使用训练器的 <img src=\"https://www.zhihu.com/equation?tex=testMinibatch\" alt=\"testMinibatch\" eeimg=\"1\"/> 方法。注意，此以前未看过的数据的错误与培训错误类似。这是一个<b>关键的</b>检查。如果错误大于训练错误的幅度很大，则表明训练的模型在训练过程中所未看到的数据将无法很好地执行。这就是所谓的拟合。有几种方法可以解决超出本教程范围的拟合，但CNTK提供了解决拟的必要组件。</p><p>注意：我们正在测试一个单一的 <img src=\"https://www.zhihu.com/equation?tex=minibatch\" alt=\"minibatch\" eeimg=\"1\"/> 为说明目的。在实践中, 你运行几个 <img src=\"https://www.zhihu.com/equation?tex=minibatches\" alt=\"minibatches\" eeimg=\"1\"/> 的测试数据和报告的平均值。</p><p><b>问题：</b></p><p>为什么会有这建议呢？尝试在几组生成的数据示例中绘制测试错误, 并使用用于培训的绘图函数绘制绘图。你看到图案了吗？</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 在新生成的数据集中运行我们已经训练好的模型</span>\n<span class=\"n\">test_minibatch_size</span> <span class=\"o\">=</span> <span class=\"mi\">25</span>\n<span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">generate_random_data_sample</span><span class=\"p\">(</span><span class=\"n\">test_minibatch_size</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"p\">,</span> <span class=\"n\">num_output_classes</span><span class=\"p\">)</span>\n\n<span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">test_minibatch</span><span class=\"p\">({</span><span class=\"n\">feature</span> <span class=\"p\">:</span> <span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">label</span> <span class=\"p\">:</span> <span class=\"n\">labels</span><span class=\"p\">})</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"mf\">0.12</span></code></pre></div><h2>检查预测 / 评估</h2><p>对于评估, 我们将网络的输出 <img src=\"https://www.zhihu.com/equation?tex=softmax\" alt=\"softmax\" eeimg=\"1\"/> 为两个类的概率分布, 每个观察的概率是恶性的或良性的。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">C</span><span class=\"o\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">)</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">out</span><span class=\"o\">.</span><span class=\"nb\">eval</span><span class=\"p\">({</span><span class=\"n\">feature</span> <span class=\"p\">:</span> <span class=\"n\">features</span><span class=\"p\">})</span></code></pre></div><p>让我们比较一下真实的标签和预测出来的分类，他们应该一致。</p><p><b>问题：</b></p><ul><li>有多少数据的预测错了？你能否更改下面的代码，以确定有多少预测是错误的？</li></ul><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;标签    :&#34;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">label</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">label</span> <span class=\"ow\">in</span> <span class=\"n\">labels</span><span class=\"p\">])</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;预测:&#34;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">result</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]])</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">标签</span>    <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"n\">预测</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]</span></code></pre></div><h2>数据可视化</h2><p>我们可以将我们的结果进行可视化。在我们的示例中，可以使用患者的两个维度的属性作为输入 ( <img src=\"https://www.zhihu.com/equation?tex=%7Bx%7D\" alt=\"{x}\" eeimg=\"1\"/> 轴上的患者年龄和 <img src=\"https://www.zhihu.com/equation?tex=y\" alt=\"y\" eeimg=\"1\"/> 轴上的肿瘤大小) 来绘制数据，患者的肿瘤性质，即我们的输出表示为图像上点的颜色 (红色为恶性、蓝色为良性)。对于具有较高维度的数据，对数据进行可视化是一件充满挑战性的工作。还好我们有先进的降维技术, 如 <img src=\"https://www.zhihu.com/equation?tex=t-sne\" alt=\"t-sne\" eeimg=\"1\"/>，允许我们来做这样的可视化。</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"c1\"># 模型参数</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">mydict</span><span class=\"p\">[</span><span class=\"s1\">&#39;b&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"p\">)</span>\n\n<span class=\"n\">bias_vector</span>   <span class=\"o\">=</span> <span class=\"n\">mydict</span><span class=\"p\">[</span><span class=\"s1\">&#39;b&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">value</span>\n<span class=\"n\">weight_matrix</span> <span class=\"o\">=</span> <span class=\"n\">mydict</span><span class=\"p\">[</span><span class=\"s1\">&#39;w&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">value</span>\n\n<span class=\"c1\"># 画出数据</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n\n<span class=\"c1\"># 0表示恶性/红色,1表示良性/蓝色</span>\n<span class=\"n\">colors</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;r&#39;</span> <span class=\"k\">if</span> <span class=\"n\">label</span> <span class=\"o\">==</span> <span class=\"mi\">0</span> <span class=\"k\">else</span> <span class=\"s1\">&#39;b&#39;</span> <span class=\"k\">for</span> <span class=\"n\">label</span> <span class=\"ow\">in</span> <span class=\"n\">labels</span><span class=\"p\">[:,</span><span class=\"mi\">0</span><span class=\"p\">]]</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">scatter</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">[:,</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">features</span><span class=\"p\">[:,</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">c</span><span class=\"o\">=</span><span class=\"n\">colors</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">bias_vector</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">/</span><span class=\"n\">weight_matrix</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]],</span> \n         <span class=\"p\">[</span> <span class=\"n\">bias_vector</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">/</span><span class=\"n\">weight_matrix</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;g&#39;</span><span class=\"p\">,</span> <span class=\"n\">lw</span> <span class=\"o\">=</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s2\">&#34;Patient age (scaled)&#34;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s2\">&#34;Tumor size (in cm)&#34;</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span></code></pre></div><p>程序的输出为：</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"p\">[</span> <span class=\"mf\">8.00007153</span> <span class=\"o\">-</span><span class=\"mf\">8.00006485</span><span class=\"p\">]</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic2.zhimg.com/v2-3d60e1cdefa2b0d05a2288857572cdd5_b.png\" data-rawwidth=\"389\" data-rawheight=\"271\" class=\"content_image\" width=\"389\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;389&#39; height=&#39;271&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"389\" data-rawheight=\"271\" class=\"content_image lazy\" width=\"389\" data-actualsrc=\"https://pic2.zhimg.com/v2-3d60e1cdefa2b0d05a2288857572cdd5_b.png\"/></figure><h2><b>探索与建议</b></h2><ul><li>看看我们的分类器在不同的数据分布下的表现如何——比如，将 <img src=\"https://www.zhihu.com/equation?tex=minibatchSize\" alt=\"minibatchSize\" eeimg=\"1\"/> 参数从  <img src=\"https://www.zhihu.com/equation?tex=25\" alt=\"25\" eeimg=\"1\"/> 调整到 <img src=\"https://www.zhihu.com/equation?tex=64\" alt=\"64\" eeimg=\"1\"/> 。为什么错误的个数增加了？</li><li>试着使用不一样的激活函数</li><li>试着使用不一样的学习器</li><li>你可以试着去训练 <a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Multinomial_logistic_regression\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">多类别线性回归</a> 分类器</li></ul><p>本文基于MIT协议发布的<a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/blob/master/Tutorials/CNTK_101_LogisticRegression.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">CNTK101</a>教程（英文），由<a href=\"https://www.zhihu.com/people/DGideas\" class=\"internal\">王万霖</a>进行演绎和本地化。本文最后修订于：2017年07月30日</p>", 
            "topic": [
                {
                    "tag": "CNTK", 
                    "tagLink": "https://api.zhihu.com/topics/20046732"
                }, 
                {
                    "tag": "线性回归", 
                    "tagLink": "https://api.zhihu.com/topics/19650500"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/28048210", 
            "userName": "王万霖", 
            "userLink": "https://www.zhihu.com/people/b8f13b7ce876ce5f99a47ce6cd2956f0", 
            "upvote": 4, 
            "title": "安装适用于Python的CNTK工具集", 
            "content": "<blockquote>微软认知工具集（Microsoft Cognitive Toolkit，CNTK）支持64位的Windows和\n64位的Linux平台。完成安装之后，您可以<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/setup-test-python\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">在Python中测试你的安装</a> ，或者看看官方文档中的 <a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/tutorials\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">导览</a> 和 <a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/examples\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">示例</a> 部分。</blockquote><p>翻译自原文：<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Setup CNTK on your machine</a></p><p>我们推荐你通过预编译的二进制文件安装CNTK，如果你打算通过源代码编译它， <a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-from-source\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这篇文章</a> 描述了你需要做的步骤。我们将首先介绍在Windows中的安装方法，如果你使用Linux系统，请翻到文章的后半部分。本文适用于最新的CNTK2.0版本（2017年6月发布）。</p><h2>在Windows中安装适用于Python的CNTK工具集</h2><p>这一小节将指引你在Windows系统上安装适用于Python的CNTK工具集。如果你正在打算构建一套CNTK构建环境，或者在你的系统上安装CNTK工具集，请遵循 <a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这篇文章</a> 的指示。</p><p>我们提供了different wheel (.whl)格式的文件，帮助你来安装适用于Python的CNTK（CPU、GPU、1bit-SGD）版本。需要注意，基于1bit-SGD的版本相较CNTK本身的协议，有着更多的<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/cntk-1bit-sgd-license\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">限制</a>。</p><ul><li>适用于 <a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/Setup-Windows-Python%23anaconda3\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Anaconda3 4.1.1</a> 的 pip 安装</li><li>适用于 <a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/Setup-Windows-Python%23anaconda2\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Anaconda2 4.3.0.1</a> 的 pip 安装</li></ul><p>适用于Python 2.7</p><ul><li>CPU-Only <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/CPU-Only/cntk-2.0-cp27-cp27m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/CPU</span><span class=\"invisible\">-Only/cntk-2.0-cp27-cp27m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU/cntk-2.0-cp27-cp27m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">/cntk-2.0-cp27-cp27m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU-1bit-SGD <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.0-cp27-cp27m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">-1bit-SGD/cntk-2.0-cp27-cp27m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>   </li></ul><p>适用于Python 3.4 </p><ul><li>CPU-Only <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/CPU-Only/cntk-2.0-cp34-cp34m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/CPU</span><span class=\"invisible\">-Only/cntk-2.0-cp34-cp34m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU/cntk-2.0-cp34-cp34m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">/cntk-2.0-cp34-cp34m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU-1bit-SGD <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.0-cp34-cp34m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">-1bit-SGD/cntk-2.0-cp34-cp34m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>   </li></ul><p>适用于Python 3.5 </p><ul><li>CPU-Only <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/CPU-Only/cntk-2.0-cp35-cp35m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/CPU</span><span class=\"invisible\">-Only/cntk-2.0-cp35-cp35m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU/cntk-2.0-cp35-cp35m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">/cntk-2.0-cp35-cp35m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU-1bit-SGD <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.0-cp35-cp35m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">-1bit-SGD/cntk-2.0-cp35-cp35m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>   </li></ul><p>适用于Python 3.6 </p><ul><li>CPU-Only <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/CPU-Only/cntk-2.0-cp36-cp36m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/CPU</span><span class=\"invisible\">-Only/cntk-2.0-cp36-cp36m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU/cntk-2.0-cp36-cp36m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">/cntk-2.0-cp36-cp36m-win_amd64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU-1bit-SGD <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.0-cp36-cp36m-win_amd64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">-1bit-SGD/cntk-2.0-cp36-cp36m-win_amd64.whl</span><span class=\"ellipsis\"></span></a></li></ul><p>使用类似以下的形式安装：</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">cntk</span><span class=\"o\">.</span><span class=\"n\">ai</span><span class=\"o\">/</span><span class=\"n\">PythonWheel</span><span class=\"o\">/</span><span class=\"n\">CPU</span><span class=\"o\">-</span><span class=\"n\">Only</span><span class=\"o\">/</span><span class=\"n\">cntk</span><span class=\"o\">-</span><span class=\"mf\">2.0</span><span class=\"o\">-</span><span class=\"n\">cp35</span><span class=\"o\">-</span><span class=\"n\">cp35m</span><span class=\"o\">-</span><span class=\"n\">win_amd64</span><span class=\"o\">.</span><span class=\"n\">whl</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><h2>在Linux中安装适用于Python的CNTK工具集（Ubuntu 14.04或者Ubuntu 16.04）</h2><p>这一小节将指引你在Linux系统（Ubuntu 14.04或者Ubuntu 16.04）上安装适用于Python的CNTK工具集。如果你正在打算构建一套CNTK构建环境，或者在你的系统上安装CNTK工具集，请遵循 <a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这篇文章</a> 的指示。</p><p>我们提供了different wheel (.whl)格式的文件，帮助你来安装适用于Python的CNTK（CPU、GPU、1bit-SGD）版本。需要注意，基于1bit-SGD的版本相较CNTK本身的协议，有着更多的<a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/cntk-1bit-sgd-license\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">限制</a>。</p><p>适用于Python 2.7 </p><ul><li>CPU-Only <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/CPU-Only/cntk-2.0-cp27-cp27mu-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/CPU</span><span class=\"invisible\">-Only/cntk-2.0-cp27-cp27mu-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU/cntk-2.0-cp27-cp27mu-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">/cntk-2.0-cp27-cp27mu-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU-1bit-SGD <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.0-cp27-cp27mu-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">-1bit-SGD/cntk-2.0-cp27-cp27mu-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>  </li></ul><p>适用于Python 3.4 </p><ul><li>CPU-Only <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/CPU-Only/cntk-2.0-cp34-cp34m-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/CPU</span><span class=\"invisible\">-Only/cntk-2.0-cp34-cp34m-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>   </li><li> GPU <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU/cntk-2.0-cp34-cp34m-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">/cntk-2.0-cp34-cp34m-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU-1bit-SGD <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.0-cp34-cp34m-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">-1bit-SGD/cntk-2.0-cp34-cp34m-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>   </li></ul><p>适用于Python 3.5 </p><ul><li>CPU-Only <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/CPU-Only/cntk-2.0-cp35-cp35m-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/CPU</span><span class=\"invisible\">-Only/cntk-2.0-cp35-cp35m-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU/cntk-2.0-cp35-cp35m-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">/cntk-2.0-cp35-cp35m-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU-1bit-SGD <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.0-cp35-cp35m-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">-1bit-SGD/cntk-2.0-cp35-cp35m-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>   </li></ul><p>适用于Python 3.6 </p><ul><li>CPU-Only <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/CPU-Only/cntk-2.0-cp36-cp36m-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/CPU</span><span class=\"invisible\">-Only/cntk-2.0-cp36-cp36m-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU/cntk-2.0-cp36-cp36m-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">/cntk-2.0-cp36-cp36m-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a>    </li><li>GPU-1bit-SGD <a href=\"https://link.zhihu.com/?target=https%3A//cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.0-cp36-cp36m-linux_x86_64.whl\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">cntk.ai/PythonWheel/GPU</span><span class=\"invisible\">-1bit-SGD/cntk-2.0-cp36-cp36m-linux_x86_64.whl</span><span class=\"ellipsis\"></span></a></li></ul><p>使用类似于以下的形式安装：</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">cntk</span><span class=\"o\">.</span><span class=\"n\">ai</span><span class=\"o\">/</span><span class=\"n\">PythonWheel</span><span class=\"o\">/</span><span class=\"n\">CPU</span><span class=\"o\">-</span><span class=\"n\">Only</span><span class=\"o\">/</span><span class=\"n\">cntk</span><span class=\"o\">-</span><span class=\"mf\">2.0</span><span class=\"o\">-</span><span class=\"n\">cp35</span><span class=\"o\">-</span><span class=\"n\">cp35m</span><span class=\"o\">-</span><span class=\"n\">win_amd64</span><span class=\"o\">.</span><span class=\"n\">whl</span></code></pre></div><p>要注意，CNTK 需要 OpenMPI 1.10.x 安装在你的系统中。在Ubuntu16.04中，这需要：</p><div class=\"highlight\"><pre><code class=\"language-console\">sudo apt-get install openmpi-bin</code></pre></div><p>在 Ubuntu 14.04 系统中，请依据 <a href=\"https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-linux%23open-mpi\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这里</a> 的指示自行构建。</p><p></p>", 
            "topic": [
                {
                    "tag": "CNTK", 
                    "tagLink": "https://api.zhihu.com/topics/20046732"
                }, 
                {
                    "tag": "Microsoft Windows", 
                    "tagLink": "https://api.zhihu.com/topics/19552612"
                }, 
                {
                    "tag": "Ubuntu", 
                    "tagLink": "https://api.zhihu.com/topics/19557067"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>我就想知道CNTK安装对CUDA版本要求是什么？官方给出的CUDA9.0未免太高了。</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/28047133", 
            "userName": "王万霖", 
            "userLink": "https://www.zhihu.com/people/b8f13b7ce876ce5f99a47ce6cd2956f0", 
            "upvote": 9, 
            "title": "让我们一起来学习CNTK吧", 
            "content": "<blockquote>2014年，在微软研究院，黄学东博士和他的团队正在致力于对计算机能够理解语音的能力进行更快的改进，但当时使用的工具显然拖慢了他们的进度。于是，一组由志愿者组成的开发团队构想设计了他们自己的解决方案，他们的内部工具成为了目前广为认知的认知工具集（CNTK）的基础。2015年8月，微软公司在CodePlex上宣布了CNTK将开源。5个月后，2016年1月25日，微软公司在他们的GitHub仓库上宣布开源了由微软研究院开发的计算网络工具集CNTK……</blockquote><p>本文最后更新于：2017年11月06日，最近一次更新包含了语法修复，以及较小的错误修复和改进。</p><p>大家好，我是本专栏的作者王万霖。<b>微软认知工具集</b>（Microsoft Cognitive Toolkit，CNTK），自从2016年1月微软公司在GitHub上开源自家的认知工具集CNTK之后，在这一年多的时间里，经过开发者和开源社区的不断努力，已经取得了巨大的进步：从支持C#/.NET语言接口、通用Windows平台（UWP），到发布了工具集的2.2版本……CNTK工具正在在社区的推动下快速地发展着。</p><h2>CNTK是什么</h2><p>根据微软官方的介绍，CNTK 是一个统一的计算网络框架，它将深层神经网络描述为一系列通过有向图的计算步骤。在有向图中，每个节点代表一个输入值或一个网络参数，每个边表示在其中的一个矩阵运算。CNTK 提供了实现前向计算和梯度计算的算法。CNTK中预定义了很多主流的计算网络结构，用户可以轻松地在开源许可证下扩展节点类型。社区可以利用它来更方便地来推进关于人工智能的研究。</p><p>CNTK拥有高度优化的内建模型，以及有着良好的多GPU支持，相信已经有不少同学已经使用或者有意向使用CNTK进行机器认知方面的开发了，同时有很多同学已经在他们的博客或者网站分享了他们使用CNTK的经历。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure><noscript><img src=\"https://pic2.zhimg.com/v2-df39d811a6283f20eb695d4c92d11e51_b.png\" data-caption=\"\" data-rawwidth=\"626\" data-rawheight=\"352\" class=\"origin_image zh-lightbox-thumb\" width=\"626\" data-original=\"https://pic2.zhimg.com/v2-df39d811a6283f20eb695d4c92d11e51_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;626&#39; height=&#39;352&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"626\" data-rawheight=\"352\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"626\" data-original=\"https://pic2.zhimg.com/v2-df39d811a6283f20eb695d4c92d11e51_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-df39d811a6283f20eb695d4c92d11e51_b.png\"/></figure><p>微软官方公布的，CNTK与其他工具集相比执行特定任务的效率对比。可以看到，在同样4GPU的配置下，针对特定的学习任务，CNTK有速度上的优势</p><h2>CNTK目前的情况</h2><p>自 CNTK 的首次亮相以来，针对CNTK的开发已大大提高了微软内部实验室的机器学习效率。通过CNTK和Azure GPU实验室的结合，让微软公司能够建立和训练针对深神经网络的Cortana语音识别任务，而且比他们以前的深学习系统快10倍。CNTK 同样可以用来执行其他任务，如ImageNet 分类和深层结构化语义模型。微软公司表示，希望社区能够充分利用 CNTK 的优势，通过和开源社区的交流和代码分享，更快地分享彼此的想法。</p><p>在计算性能和灵活性之间有许多设计考虑因素，每个工具包都有其独特的优点。TensorFlow 提供了一个用户友好且易于使用的Python接口；Theano 由其代表性的操作深入人心；Torch使用 Lua 编程语言；Caffe其高效的性能而受到计算机视觉研究者的青睐；而CNTK在自家的Azure GPU实验室中表现出了最高效的分布式计算性能。</p><figure><noscript><img src=\"https://pic2.zhimg.com/v2-ce23934235c2783229c08701d1321705_b.png\" data-caption=\"\" data-rawwidth=\"709\" data-rawheight=\"694\" class=\"origin_image zh-lightbox-thumb\" width=\"709\" data-original=\"https://pic2.zhimg.com/v2-ce23934235c2783229c08701d1321705_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;709&#39; height=&#39;694&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"709\" data-rawheight=\"694\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"709\" data-original=\"https://pic2.zhimg.com/v2-ce23934235c2783229c08701d1321705_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ce23934235c2783229c08701d1321705_b.png\"/></figure><p>在必应搜索引擎关于一些机器学习框架的搜索结果</p><p>从另一方面看到，由于CNTK在最近几年才被推出，在网上有关于CNTK的资料还是很有限的，并且很多新的资料均为英文版。我们缺乏本土的，有关CNTK框架的教学内容。在搜索引擎进行相关的搜索，排名靠前的结果均是介绍使用BrainScript来使用CNTK框架的文章。</p><p>相比BrainScript的编写，使用Python进行机器认知、机器学习相关的开发更加普遍且易于交流。本专栏希望能够通过更多的文章和优质资料，让大家更好地了解CNTK框架及其应用。欢迎大家多多关注，欢迎有兴趣的同学一起投入到写作中来。</p><h2>未来的写作方向</h2><p>截止到2017年11月，本专栏以翻译官方的CNTK入门（指引）文章为主。</p><p>在未来的更多时间里，我们将有兴趣针对CNTK的内部实现，以及它的相关应用进行更深入的探讨。<br/></p><p>参考资料：</p><ul><li><a href=\"https://link.zhihu.com/?target=https%3A//blogs.microsoft.com/next/2016/01/25/microsoft-releases-cntk-its-open-source-deep-learning-toolkit-on-github/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Microsoft releases CNTK, its open source deep learning toolkit, on GitHub - Next at Microsoft</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//www.microsoft.com/en-us/research/publication/an-introduction-to-computational-networks-and-the-computational-network-toolkit/%3Ffrom%3Dhttp%253A%252F%252Fresearch.microsoft.com%252Fapps%252Fpubs%252F%253Fid%253D226641%23\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">An Introduction to Computational Networks and the Computational Network Toolkit - Microsoft Research</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTk/wiki/CNTK_1_5_Release_Notes\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Microsoft/CNTK</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//www.microsoft.com/en-us/research/blog/microsoft-computational-network-toolkit-offers-most-efficient-distributed-deep-learning-computational-performance/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Microsoft Computational Network Toolkit offers most efficient distributed deep learning computational performance - Microsoft Research</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//news.microsoft.com/features/speak-hear-talk-the-long-quest-for-technology-that-understands-speech-as-well-as-a-human/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Speak, hear, talk: The long quest for technology that understands speech as well as a human - News Center</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//github.com/Microsoft/CNTK/commit/61694509551f38e031c74f3d9409b44fe50224cf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">First Release of CNTK · Microsoft/CNTK@6169450</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//www.microsoft.com/en-us/research/people/xdh/%23\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Xuedong Huang, Microsoft speech NLP AI</a></li><li><a href=\"https://link.zhihu.com/?target=https%3A//www.cntk.ai/Tutorials/CVPR2017/CVPR_2017_Tutorial_final.pdf\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://www.</span><span class=\"visible\">cntk.ai/Tutorials/CVPR2</span><span class=\"invisible\">017/CVPR_2017_Tutorial_final.pdf</span><span class=\"ellipsis\"></span></a></li></ul>", 
            "topic": [
                {
                    "tag": "CNTK", 
                    "tagLink": "https://api.zhihu.com/topics/20046732"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "微软（Microsoft）", 
                    "tagLink": "https://api.zhihu.com/topics/19551667"
                }
            ], 
            "comments": [
                {
                    "userName": "暖虫", 
                    "userLink": "https://www.zhihu.com/people/93bbd8328a5e003f25625ddd862b26a2", 
                    "content": "请问一下 是否有 比较推荐的 cntk教学 或者入门的书籍。最好是中文的 谢谢", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/msrcntk"
}

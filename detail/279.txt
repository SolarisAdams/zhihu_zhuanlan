{
    "title": "一起来看流星雨", 
    "description": "", 
    "followers": [
        "https://www.zhihu.com/people/jamylu", 
        "https://www.zhihu.com/people/taomo-44", 
        "https://www.zhihu.com/people/ljtme-13", 
        "https://www.zhihu.com/people/huo-shao-yun-68", 
        "https://www.zhihu.com/people/dou-xian-sheng-29-79", 
        "https://www.zhihu.com/people/fancybug", 
        "https://www.zhihu.com/people/libingwu", 
        "https://www.zhihu.com/people/zhuo-ran-68", 
        "https://www.zhihu.com/people/xue-hua-dou-fu-nao", 
        "https://www.zhihu.com/people/liu-fei-94-95", 
        "https://www.zhihu.com/people/yige-wu-liao-de-ren-85", 
        "https://www.zhihu.com/people/arachis-60-97", 
        "https://www.zhihu.com/people/kit-6-90", 
        "https://www.zhihu.com/people/ziran-91", 
        "https://www.zhihu.com/people/shenzhiwei", 
        "https://www.zhihu.com/people/shi-chen-hao-75", 
        "https://www.zhihu.com/people/ding-zhao-86", 
        "https://www.zhihu.com/people/daydayup_Mr.damiao", 
        "https://www.zhihu.com/people/13811022864", 
        "https://www.zhihu.com/people/zhang-mou-61-11", 
        "https://www.zhihu.com/people/ren-lang-3", 
        "https://www.zhihu.com/people/ma-xing-yu-72-30", 
        "https://www.zhihu.com/people/Only_Episode", 
        "https://www.zhihu.com/people/liu-jia-hao-32-30", 
        "https://www.zhihu.com/people/hao-zhang-44-23", 
        "https://www.zhihu.com/people/wholton", 
        "https://www.zhihu.com/people/zhu-pao-pao-30-11", 
        "https://www.zhihu.com/people/zhang-tian-xiang-73", 
        "https://www.zhihu.com/people/jia-lan-yu-bu-ting", 
        "https://www.zhihu.com/people/chen-xing-qiang-61", 
        "https://www.zhihu.com/people/bai-cai-25-90", 
        "https://www.zhihu.com/people/zjude90", 
        "https://www.zhihu.com/people/cyberland", 
        "https://www.zhihu.com/people/ceng-qiang-16-57", 
        "https://www.zhihu.com/people/hao-yue-22-85", 
        "https://www.zhihu.com/people/ning-rain", 
        "https://www.zhihu.com/people/zhenning-li-59", 
        "https://www.zhihu.com/people/patrickwang-95", 
        "https://www.zhihu.com/people/chen-qi-64-71", 
        "https://www.zhihu.com/people/shu-luo-de-yang-guang", 
        "https://www.zhihu.com/people/xu-ming-hao-2-10", 
        "https://www.zhihu.com/people/wangyuanzhf", 
        "https://www.zhihu.com/people/manutdmoon", 
        "https://www.zhihu.com/people/sxx-84-16", 
        "https://www.zhihu.com/people/mbinary", 
        "https://www.zhihu.com/people/andy-3-36", 
        "https://www.zhihu.com/people/echo-75-50-36", 
        "https://www.zhihu.com/people/wj2014-59", 
        "https://www.zhihu.com/people/MerleCahng", 
        "https://www.zhihu.com/people/liusen63", 
        "https://www.zhihu.com/people/ke-chen-74", 
        "https://www.zhihu.com/people/zhang-jia-zhu-27-21", 
        "https://www.zhihu.com/people/HamRadioDXerGly", 
        "https://www.zhihu.com/people/yu-zi-jun-49", 
        "https://www.zhihu.com/people/yao-a-xing", 
        "https://www.zhihu.com/people/zhu-forrest", 
        "https://www.zhihu.com/people/a-cui-ya-34", 
        "https://www.zhihu.com/people/payne-xianr", 
        "https://www.zhihu.com/people/yang-jing-lin-16", 
        "https://www.zhihu.com/people/huang-hui-58-72", 
        "https://www.zhihu.com/people/aidiming", 
        "https://www.zhihu.com/people/ray-li-34", 
        "https://www.zhihu.com/people/duan-xing-99", 
        "https://www.zhihu.com/people/cao-ji-49-42", 
        "https://www.zhihu.com/people/qian-li-tiao-tiao-41", 
        "https://www.zhihu.com/people/wang-crown-94", 
        "https://www.zhihu.com/people/yu-cheng-47-36", 
        "https://www.zhihu.com/people/xie-zhao-yang-80-76", 
        "https://www.zhihu.com/people/libin-sui", 
        "https://www.zhihu.com/people/qianghuazhnag", 
        "https://www.zhihu.com/people/namephobia", 
        "https://www.zhihu.com/people/yang-pei-wen-22", 
        "https://www.zhihu.com/people/dennis-92-13-5", 
        "https://www.zhihu.com/people/chensheng-49", 
        "https://www.zhihu.com/people/meeme", 
        "https://www.zhihu.com/people/ye-yuan-xiao-bai-20", 
        "https://www.zhihu.com/people/xiao-jie-69-52-68", 
        "https://www.zhihu.com/people/xiang-fang-pin-93", 
        "https://www.zhihu.com/people/jin-xue-feng", 
        "https://www.zhihu.com/people/wang-lei-35-77", 
        "https://www.zhihu.com/people/Lemonz_rl", 
        "https://www.zhihu.com/people/zhang-ming-hao-41", 
        "https://www.zhihu.com/people/xiao-bai-63-94-54", 
        "https://www.zhihu.com/people/redblue-71", 
        "https://www.zhihu.com/people/mo-yan-37-77-85", 
        "https://www.zhihu.com/people/zzx-47-7", 
        "https://www.zhihu.com/people/mo-shui-er-60", 
        "https://www.zhihu.com/people/sohala", 
        "https://www.zhihu.com/people/xing-zhe-88-11", 
        "https://www.zhihu.com/people/jy0-98", 
        "https://www.zhihu.com/people/long-yan-42-77", 
        "https://www.zhihu.com/people/kerry-wu-96", 
        "https://www.zhihu.com/people/li-shi-lin-93-31", 
        "https://www.zhihu.com/people/xie-tian-you-38", 
        "https://www.zhihu.com/people/zhao-da-hu-58", 
        "https://www.zhihu.com/people/you-jing-69-85", 
        "https://www.zhihu.com/people/steven-sun-74-38", 
        "https://www.zhihu.com/people/lan-lan-lan-lan-96-82", 
        "https://www.zhihu.com/people/yang-han-42-35", 
        "https://www.zhihu.com/people/dong-yu-long-37", 
        "https://www.zhihu.com/people/liu-yu-wei-27-16", 
        "https://www.zhihu.com/people/lu-guo-62-60", 
        "https://www.zhihu.com/people/imbzai-nan-dao", 
        "https://www.zhihu.com/people/lohaspig", 
        "https://www.zhihu.com/people/Miyacom", 
        "https://www.zhihu.com/people/lu-yu-chen-86-23", 
        "https://www.zhihu.com/people/its-zhi-guang", 
        "https://www.zhihu.com/people/wang-jing-bo-27-88", 
        "https://www.zhihu.com/people/hu-shao-han", 
        "https://www.zhihu.com/people/hu-rui-yang-9", 
        "https://www.zhihu.com/people/chiling-15", 
        "https://www.zhihu.com/people/zhuxixixi", 
        "https://www.zhihu.com/people/yin-yu-yun-65", 
        "https://www.zhihu.com/people/Joyce_Yuan", 
        "https://www.zhihu.com/people/zhang-cheng-wei-36", 
        "https://www.zhihu.com/people/wang-kuan-57-47", 
        "https://www.zhihu.com/people/kong-cheng-zui-da-ying-jia", 
        "https://www.zhihu.com/people/qin-xue-fei-56", 
        "https://www.zhihu.com/people/cong-qian-38-26", 
        "https://www.zhihu.com/people/jason-liu-17", 
        "https://www.zhihu.com/people/liao-xin-ru", 
        "https://www.zhihu.com/people/j99999999955555", 
        "https://www.zhihu.com/people/hh-zz-77-1", 
        "https://www.zhihu.com/people/she-liang", 
        "https://www.zhihu.com/people/yongboshen", 
        "https://www.zhihu.com/people/xiao-bai-75-16", 
        "https://www.zhihu.com/people/xia-bo-han", 
        "https://www.zhihu.com/people/zhu-meng-yue-24", 
        "https://www.zhihu.com/people/zhi-shi-xiao-kuo-nai", 
        "https://www.zhihu.com/people/zhao-hu-41-13", 
        "https://www.zhihu.com/people/ao-mou-shan-mi", 
        "https://www.zhihu.com/people/ke-wu-88", 
        "https://www.zhihu.com/people/XiaMin1314", 
        "https://www.zhihu.com/people/yu-zhi-2-59-39", 
        "https://www.zhihu.com/people/hong-xian-68-14-47", 
        "https://www.zhihu.com/people/zhen-zhen-62-41-12", 
        "https://www.zhihu.com/people/wang-xiang-43-65", 
        "https://www.zhihu.com/people/cloudsrollby", 
        "https://www.zhihu.com/people/su-sai", 
        "https://www.zhihu.com/people/tian-bi-luo-ying", 
        "https://www.zhihu.com/people/lihong-36", 
        "https://www.zhihu.com/people/zy366", 
        "https://www.zhihu.com/people/blueman", 
        "https://www.zhihu.com/people/xie-jun-6-44", 
        "https://www.zhihu.com/people/cai-xin-74-46", 
        "https://www.zhihu.com/people/zai-sen-42", 
        "https://www.zhihu.com/people/kuppo", 
        "https://www.zhihu.com/people/xiao-yao-73-56", 
        "https://www.zhihu.com/people/cai-hong-hao-61", 
        "https://www.zhihu.com/people/tao-ke-xia-70", 
        "https://www.zhihu.com/people/joyce-58-73-53", 
        "https://www.zhihu.com/people/song-xiao-yang-88", 
        "https://www.zhihu.com/people/ri-yue-dang-kong-zhao-37", 
        "https://www.zhihu.com/people/feng-xie-jun-17", 
        "https://www.zhihu.com/people/ma-er-gu-bo-duo-lue-24", 
        "https://www.zhihu.com/people/le-le-95-4-58", 
        "https://www.zhihu.com/people/xiong-kun-12", 
        "https://www.zhihu.com/people/jiong-shen-71", 
        "https://www.zhihu.com/people/xiao-tong-59-87", 
        "https://www.zhihu.com/people/xia-chen-feng", 
        "https://www.zhihu.com/people/ycsuperlife", 
        "https://www.zhihu.com/people/ai-jia-da-ren", 
        "https://www.zhihu.com/people/wang-peng-cheng-39-36", 
        "https://www.zhihu.com/people/jj-kim", 
        "https://www.zhihu.com/people/ci-miao-94", 
        "https://www.zhihu.com/people/zheng-cheng-43-41", 
        "https://www.zhihu.com/people/zhu-xian-6-16", 
        "https://www.zhihu.com/people/cai-hui-liang", 
        "https://www.zhihu.com/people/qiao-hai-jun", 
        "https://www.zhihu.com/people/arnold-chen-48", 
        "https://www.zhihu.com/people/jiangce6174", 
        "https://www.zhihu.com/people/zhihucompeople", 
        "https://www.zhihu.com/people/wen-yu-xin-54", 
        "https://www.zhihu.com/people/andykung", 
        "https://www.zhihu.com/people/panzhengyuxhu", 
        "https://www.zhihu.com/people/guo-xiao-can"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/60257706", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 34, 
            "title": "TRPO论文推导", 
            "content": "<h2>Trust Region Policy Optimization</h2><p>作者：John Schulman</p><h2>概述</h2><ul><li>描述了一个用来<b>优化策略</b>的<b>迭代过程</b></li><li>这个过程是使得优化过程<b>单调提高</b>的</li><li>在对理论证明过程进行几处<b>近似</b>之后，提出一个实际算法<code>TRPO</code></li><li>该算法对于优化<b>大规模非线性策略</b>，例如神经网络，有较高的效率</li></ul><h2>符号约定</h2><ul><li><img src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/> ——有限状态空间</li><li><img src=\"https://www.zhihu.com/equation?tex=A%E2%80%8B\" alt=\"A​\" eeimg=\"1\"/> ——有限动作空间</li><li><img src=\"https://www.zhihu.com/equation?tex=P%3AS%5Ctimes+A%5Ctimes+S%5Cto+%5Cmathbb%7BR%7D\" alt=\"P:S\\times A\\times S\\to \\mathbb{R}\" eeimg=\"1\"/> ——转移概率分布</li><li><img src=\"https://www.zhihu.com/equation?tex=r%3AS%5Cto+%5Cmathbb%7BR%7D\" alt=\"r:S\\to \\mathbb{R}\" eeimg=\"1\"/> ——奖励函数</li><li><img src=\"https://www.zhihu.com/equation?tex=%5Crho_0%3AS%5Cto+%5Cmathbb%7BR%7D\" alt=\"\\rho_0:S\\to \\mathbb{R}\" eeimg=\"1\"/> ——初始状态 <img src=\"https://www.zhihu.com/equation?tex=s_0\" alt=\"s_0\" eeimg=\"1\"/> 的概率分布</li><li><img src=\"https://www.zhihu.com/equation?tex=%5Cgamma+%5Cin+%280%2C1%29\" alt=\"\\gamma \\in (0,1)\" eeimg=\"1\"/> ——折扣因子</li><li><img src=\"https://www.zhihu.com/equation?tex=%5Cpi%3AS%5Ctimes+A+%5Cto+%5B0%2C1%5D\" alt=\"\\pi:S\\times A \\to [0,1]\" eeimg=\"1\"/> ——随机策略</li><li><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> ——期望折扣回报</li></ul><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29%3D%5Cmathbb%7BE%7D%7Bs_0%2Ca_0%2C%5Cldots%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5Etr%28s_t%29+%5Cright%5D+\" alt=\"\\eta(\\pi)=\\mathbb{E}{s_0,a_0,\\ldots}\\left[ \\sum_{t=0}^{\\infty}\\gamma^tr(s_t) \\right] \" eeimg=\"1\"/> </p><p>其中： </p><p><img src=\"https://www.zhihu.com/equation?tex=s_0%5Csim+%5Crho_0%28s_0%29%2C%5Cquad+a_t%5Csim+%5Cpi+%28a_t%5Cmid+s_t%29%2C%5Cquad+s_%7Bt%2B1%7D%5Csim+P%28s_%7Bt%2B1%7D%5Cmid+s_t%2Ca_t%29+\" alt=\"s_0\\sim \\rho_0(s_0),\\quad a_t\\sim \\pi (a_t\\mid s_t),\\quad s_{t+1}\\sim P(s_{t+1}\\mid s_t,a_t) \" eeimg=\"1\"/> </p><p>并定义如下三个量： </p><p>1. 状态-动作价值函数： <img src=\"https://www.zhihu.com/equation?tex=Q_%5Cpi+%28s_t%2Ca_t%29%3D%5Cmathbb%7BE%7D%7Bs_%7Bt%2B1%7D%2Ca_%7Bt%2B1%7D%2C%5Cldots%7D%5Cleft%5B+%5Csum_%7Bl%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5El+r%28s_%7Bt%2Bl%7D%29+%5Cright%5D\" alt=\"Q_\\pi (s_t,a_t)=\\mathbb{E}{s_{t+1},a_{t+1},\\ldots}\\left[ \\sum_{l=0}^{\\infty}\\gamma^l r(s_{t+l}) \\right]\" eeimg=\"1\"/> </p><p>2. 价值函数： <img src=\"https://www.zhihu.com/equation?tex=V_%7B%5Cpi%7D%28s_t%29%3D%5Cmathbb%7BE%7D%7Ba_t%2Cs_%7Bt%2B1%7D%2C%5Cldots%7D+%5Cleft%5B%5Csum_%7Bl%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5El+r%28s_%7Bt%2Bl%7D%29+%5Cright%5D+\" alt=\"V_{\\pi}(s_t)=\\mathbb{E}{a_t,s_{t+1},\\ldots} \\left[\\sum_{l=0}^{\\infty}\\gamma^l r(s_{t+l}) \\right] \" eeimg=\"1\"/> </p><p>3. 优势函数： <img src=\"https://www.zhihu.com/equation?tex=A_%5Cpi+%28s%2Ca%29%3DQ_%5Cpi%28s%2Ca%29-V_%5Cpi%28s%29+\" alt=\"A_\\pi (s,a)=Q_\\pi(s,a)-V_\\pi(s) \" eeimg=\"1\"/> </p><p>    其中：  <img src=\"https://www.zhihu.com/equation?tex=a_t%5Csim+%5Cpi+%28a_t%5Cmid+s_t%29%2C%5Cquad+s_%7Bt%2B1%7D%5Csim+P%28s_%7Bt%2B1%7D%5Cmid+s_t%2Ca_t%29%5Cquad+for+%5Cquad+t%5Cge+0\" alt=\"a_t\\sim \\pi (a_t\\mid s_t),\\quad s_{t+1}\\sim P(s_{t+1}\\mid s_t,a_t)\\quad for \\quad t\\ge 0\" eeimg=\"1\"/> </p><ul><li><img src=\"https://www.zhihu.com/equation?tex=V_%5Cpi%28s_t%29\" alt=\"V_\\pi(s_t)\" eeimg=\"1\"/> 是状态 <img src=\"https://www.zhihu.com/equation?tex=s_t\" alt=\"s_t\" eeimg=\"1\"/> 下，对所有可能动作 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 而言的期望价值</li><li><img src=\"https://www.zhihu.com/equation?tex=Q_%5Cpi%28s_t%2Ca_t%29\" alt=\"Q_\\pi(s_t,a_t)\" eeimg=\"1\"/> 是状态 <img src=\"https://www.zhihu.com/equation?tex=s_t\" alt=\"s_t\" eeimg=\"1\"/> 下，当采取动作 <img src=\"https://www.zhihu.com/equation?tex=a_t\" alt=\"a_t\" eeimg=\"1\"/> 时对应的价值</li><li><img src=\"https://www.zhihu.com/equation?tex=A_%5Cpi%28s_t%2Ca_t%29\" alt=\"A_\\pi(s_t,a_t)\" eeimg=\"1\"/> 反映了状态 <img src=\"https://www.zhihu.com/equation?tex=s_t\" alt=\"s_t\" eeimg=\"1\"/> 下，选择某一个动作对应的价值，和对于所有可能动作的期望价值的差</li></ul><h2>一、重写 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> ——写成增量式</h2><p>我们希望每一次对策略 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"/> 的更新，可以使得 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> 单调增大，能否将 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> 的表达式写成如下形式：</p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29%3D%5Ceta%28%5Cpi%29%2B%28%5Cldots%29+\" alt=\" \\eta(\\widetilde{\\pi})=\\eta(\\pi)+(\\ldots) \" eeimg=\"1\"/> </p><p>这样的话，我们只需要考虑如何使得 <img src=\"https://www.zhihu.com/equation?tex=%28%5Cldots%29%5Cge0\" alt=\"(\\ldots)\\ge0\" eeimg=\"1\"/> ，便可保证 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> 单调增大。</p><h3>由 <img src=\"https://www.zhihu.com/equation?tex=A_%5Cpi%28s%2Ca%29\" alt=\"A_\\pi(s,a)\" eeimg=\"1\"/> 重新定义 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> ：</h3><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29%3D%5Ceta%28%5Cpi%29%2B%5Cmathbb%7BE%7D%7Bs_0%2Ca_0%2C%5Cldots+%5Csim+%5Cwidetilde%7B%5Cpi%7D%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%7B%5Cgamma%5Et+A_%5Cpi%28s_t%2Ca_t%29%7D+%5Cright%5D+\" alt=\"\\eta(\\widetilde{\\pi})=\\eta(\\pi)+\\mathbb{E}{s_0,a_0,\\ldots \\sim \\widetilde{\\pi}}\\left[ \\sum_{t=0}^{\\infty}{\\gamma^t A_\\pi(s_t,a_t)} \\right] \" eeimg=\"1\"/> </p><h3>proof ：</h3><p>考察两个策略 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Cwidetilde%7B%5Cpi%7D\" alt=\"\\widetilde{\\pi}\" eeimg=\"1\"/> 。 <br/>首先注意到如下等式：</p><p><img src=\"https://www.zhihu.com/equation?tex=+A_%5Cpi%28s%2Ca%29%3Dr%28s%29%2B%5Cgamma+V_%5Cpi%28s%27%29-V_%5Cpi%28s%29+\" alt=\" A_\\pi(s,a)=r(s)+\\gamma V_\\pi(s&#39;)-V_\\pi(s) \" eeimg=\"1\"/> </p><p>于是有如下关系，</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmathbb%7BE%7D%7B%5Ctau+%5Csim+%5Cwidetilde%7B%5Cpi%7D%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%7B%5Cgamma%5Et+A_%5Cpi%28s_t%2Ca_t%29%7D+%5Cright%5D\" alt=\"\\mathbb{E}{\\tau \\sim \\widetilde{\\pi}}\\left[ \\sum_{t=0}^{\\infty}{\\gamma^t A_\\pi(s_t,a_t)} \\right]\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Cmathbb%7BE%7D%7B%5Ctau+%5Csim+%5Cwidetilde%7B%5Cpi%7D%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5Et+%28r%28s_t%29%2B%5Cgamma+V_%5Cpi%28s_%7Bt%2B1%7D%29-V_%5Cpi%28s_t%29%29+%5Cright%5D\" alt=\"=\\mathbb{E}{\\tau \\sim \\widetilde{\\pi}}\\left[ \\sum_{t=0}^{\\infty}\\gamma^t (r(s_t)+\\gamma V_\\pi(s_{t+1})-V_\\pi(s_t)) \\right]\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Cmathbb%7BE%7D%7B%5Ctau+%5Csim+%5Cwidetilde%7B%5Cpi%7D%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5E%7Bt%2B1%7DV_%5Cpi%28s_%7Bt%2B1%7D%29-+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5E%7Bt%7DV_%5Cpi%28s_%7Bt%7D%29%2B%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5Et+r%28%7Bs_t%7D%29+%5Cright%5D+\" alt=\"=\\mathbb{E}{\\tau \\sim \\widetilde{\\pi}}\\left[ \\sum_{t=0}^{\\infty}\\gamma^{t+1}V_\\pi(s_{t+1})- \\sum_{t=0}^{\\infty}\\gamma^{t}V_\\pi(s_{t})+\\sum_{t=0}^{\\infty}\\gamma^t r({s_t}) \\right] \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Cmathbb%7BE%7D%7B%5Ctau+%5Csim+%5Cwidetilde%7B%5Cpi%7D%7D%5Cleft%5B+-V%5Cpi%28s_0%29%2B%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5Et+r%28%7Bs_t%7D%29+%5Cright%5D\" alt=\"=\\mathbb{E}{\\tau \\sim \\widetilde{\\pi}}\\left[ -V\\pi(s_0)+\\sum_{t=0}^{\\infty}\\gamma^t r({s_t}) \\right]\" eeimg=\"1\"/> </p><p>注意到，</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29+%3D+%5Cmathbb%7BE%7D%7Bs_0%2Ca_0%2C%5Cldots%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5Etr%28s_t%29+%5Cright%5D\" alt=\"\\eta(\\pi) = \\mathbb{E}{s_0,a_0,\\ldots}\\left[ \\sum_{t=0}^{\\infty}\\gamma^tr(s_t) \\right]\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=V_%7B%5Cpi%7D%28s_t%29+%3D+%5Cmathbb%7BE%7D%7Ba_t%2Cs_%7Bt%2B1%7D%2C%5Cldots%7D+%5Cleft%5B%5Csum_%7Bl%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5El+r%28s_%7Bt%2Bl%7D%29+%5Cright%5D+\" alt=\"V_{\\pi}(s_t) = \\mathbb{E}{a_t,s_{t+1},\\ldots} \\left[\\sum_{l=0}^{\\infty}\\gamma^l r(s_{t+l}) \\right] \" eeimg=\"1\"/> </p><p>由以上两式可得： <img src=\"https://www.zhihu.com/equation?tex=V_%5Cpi%28s_0%29%3D%5Ceta%28%5Cpi%29+\" alt=\"V_\\pi(s_0)=\\eta(\\pi) \" eeimg=\"1\"/> </p><p>于是有，</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmathbb%7BE%7D%7B%5Ctau+%5Csim+%5Cwidetilde%7B%5Cpi%7D%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5Et+A_%5Cpi%28s_t%2Ca_t%29+%5Cright%5D%3D-%5Ceta%28%5Cpi%29%2B%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29+\" alt=\"\\mathbb{E}{\\tau \\sim \\widetilde{\\pi}}\\left[ \\sum_{t=0}^{\\infty}\\gamma^t A_\\pi(s_t,a_t) \\right]=-\\eta(\\pi)+\\eta(\\widetilde{\\pi}) \" eeimg=\"1\"/> </p><p>即，</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29%3D%5Ceta%28%5Cpi%29%2B%5Cmathbb%7BE%7D%7B%5Ctau+%5Csim+%5Cwidetilde%7B%5Cpi%7D%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5Et+A_%5Cpi%28s_t%2Ca_t%29+%5Cright%5D\" alt=\"\\eta(\\widetilde{\\pi})=\\eta(\\pi)+\\mathbb{E}{\\tau \\sim \\widetilde{\\pi}}\\left[ \\sum_{t=0}^{\\infty}\\gamma^t A_\\pi(s_t,a_t) \\right]\" eeimg=\"1\"/> </p><p>原式得证。</p><h2>二、进一步改写 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> ——显式的写出 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> </h2><p><img src=\"https://www.zhihu.com/equation?tex=+%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29%3D%5Ceta%28%5Cpi%29%2B%5Cmathbb%7BE%7D%7B%5Ctau+%5Csim+%5Cwidetilde%7B%5Cpi%7D%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5Et+A_%5Cpi%28s_t%2Ca_t%29+%5Cright%5D+\" alt=\" \\eta(\\widetilde{\\pi})=\\eta(\\pi)+\\mathbb{E}{\\tau \\sim \\widetilde{\\pi}}\\left[ \\sum_{t=0}^{\\infty}\\gamma^t A_\\pi(s_t,a_t) \\right] \" eeimg=\"1\"/> </p><p>可以看到我们成功的把对策略进行评价的折扣回报函数 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> 写成了 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29%3D%5Ceta%28%5Cpi%29%2B%28%5Cldots%29\" alt=\"\\eta(\\widetilde{\\pi})=\\eta(\\pi)+(\\ldots)\" eeimg=\"1\"/> 的形式，于是我们要考虑这一项何时为正，为正时则要对策略进行更新。但这一表达式并没有给出太多信息，我们来把其中的状态 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 和动作 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 显式的表现出来： </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29%3D+%5Ceta%28%5Cpi%29%2B%5Cmathbb%7BE%7D%7B%5Ctau+%5Csim+%5Cwidetilde%7B%5Cpi%7D%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5Et+A_%5Cpi%28s_t%2Ca_t%29+%5Cright%5D++%5C\" alt=\"\\eta(\\widetilde{\\pi})= \\eta(\\pi)+\\mathbb{E}{\\tau \\sim \\widetilde{\\pi}}\\left[ \\sum_{t=0}^{\\infty}\\gamma^t A_\\pi(s_t,a_t) \\right]  \\\" eeimg=\"1\"/> </p><p>期望是以概率为权重的加权和：</p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29+%3D+%5Ceta%28%5Cpi%29%2B%5Csum_%7Bt%3D0%7D%5E%5Cinfty++%5Csum_s+P%28s_t%3Ds+%5Cmid+%5Cwidetilde%7B%5Cpi%7D%29+%5Csum_a+%5Cwidetilde%7B%5Cpi%7D%28a_t%3Da+%5Cmid+s_t%29+%5Cgamma%5Et+A_%5Cpi%28s_t%2Ca_t%29+\" alt=\" \\eta(\\widetilde{\\pi}) = \\eta(\\pi)+\\sum_{t=0}^\\infty  \\sum_s P(s_t=s \\mid \\widetilde{\\pi}) \\sum_a \\widetilde{\\pi}(a_t=a \\mid s_t) \\gamma^t A_\\pi(s_t,a_t) \" eeimg=\"1\"/> </p><p>调整各项的位置：</p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29+%3D+%5Ceta%28%5Cpi%29%2B+%5Csum_s+%5Csum_%7Bt%3D0%7D%5E%5Cinfty+++%5Cgamma%5Et++P%28s_t%3Ds+%5Cmid+%5Cwidetilde%7B%5Cpi%7D%29++%5Csum_a+%5Cwidetilde%7B%5Cpi%7D%28a_t%3Da+%5Cmid+s_t%29+A_%5Cpi%28s_t%2Ca_t%29\" alt=\" \\eta(\\widetilde{\\pi}) = \\eta(\\pi)+ \\sum_s \\sum_{t=0}^\\infty   \\gamma^t  P(s_t=s \\mid \\widetilde{\\pi})  \\sum_a \\widetilde{\\pi}(a_t=a \\mid s_t) A_\\pi(s_t,a_t)\" eeimg=\"1\"/> </p><p>定义<b>折扣状态访问概率</b>：</p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Crho_%5Cpi+%28s%29%3DP%28s_0%3Ds+%5Cmid+%5Cpi%29%2B%5Cgamma+P%28s_1%3Ds+%5Cmid+%5Cpi%29%2B%5Cgamma%5E2+P%28s_2%3Ds+%5Cmid+%5Cpi%29%2B%5Cdots%3D%5Csum_%7Bt%3D0%7D%5E%5Cinfty+%5Cgamma%5Et++P%28s_t%3Ds+%5Cmid+%5Cpi%29+\" alt=\" \\rho_\\pi (s)=P(s_0=s \\mid \\pi)+\\gamma P(s_1=s \\mid \\pi)+\\gamma^2 P(s_2=s \\mid \\pi)+\\dots=\\sum_{t=0}^\\infty \\gamma^t  P(s_t=s \\mid \\pi) \" eeimg=\"1\"/> </p><p>表示策略 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"/> 下，带有折扣因子的访问到状态 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 的概率（没有归一化），此时 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29\" alt=\"\\eta(\\widetilde{\\pi})\" eeimg=\"1\"/> 为：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29+%3D+%5Ceta%28%5Cpi%29%2B+%5Csum_s+%5Csum_%7Bt%3D0%7D%5E%5Cinfty+%5Cgamma%5Et++P%28s_t%3Ds+%5Cmid+%5Cwidetilde%7B%5Cpi%7D%29++%5Csum_a+%5Cwidetilde%7B%5Cpi%7D%28a_t%3Da+%5Cmid+s_t%29+A_%5Cpi%28s_t%2Ca_t%29+\" alt=\"\\eta(\\widetilde{\\pi}) = \\eta(\\pi)+ \\sum_s \\sum_{t=0}^\\infty \\gamma^t  P(s_t=s \\mid \\widetilde{\\pi})  \\sum_a \\widetilde{\\pi}(a_t=a \\mid s_t) A_\\pi(s_t,a_t) \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29+%3D+%5Ceta%28%5Cpi%29%2B++%5Csum_s++%5Crho_%5Cwidetilde%7B%5Cpi%7D%28s%29+%5Csum_a+%5Cwidetilde%7B%5Cpi%7D%28a+%5Cmid+s%29+A_%5Cpi%28s%2Ca%29\" alt=\"\\eta(\\widetilde{\\pi}) = \\eta(\\pi)+  \\sum_s  \\rho_\\widetilde{\\pi}(s) \\sum_a \\widetilde{\\pi}(a \\mid s) A_\\pi(s,a)\" eeimg=\"1\"/> </p><p>从这个式子可以看出，对于一个新策略 <img src=\"https://www.zhihu.com/equation?tex=%5Cwidetilde%7B%5Cpi%7D\" alt=\"\\widetilde{\\pi}\" eeimg=\"1\"/> 如何判断其是否为更优的策略？就是对于在新策略 <img src=\"https://www.zhihu.com/equation?tex=%5Cwidetilde%7B%5Cpi%7D\" alt=\"\\widetilde{\\pi}\" eeimg=\"1\"/> 下，对所有可能到达的状态 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> ，考察其<b>期望优势值</b>，若有： </p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Csum_a+%5Cwidetilde%7B%5Cpi%7D%28a+%5Cmid+s%29+A_%5Cpi%28s%2Ca%29+%5Cge+0+\" alt=\" \\sum_a \\widetilde{\\pi}(a \\mid s) A_\\pi(s,a) \\ge 0 \" eeimg=\"1\"/> </p><p>则说明 <img src=\"https://www.zhihu.com/equation?tex=%5Cwidetilde%7B%5Cpi%7D\" alt=\"\\widetilde{\\pi}\" eeimg=\"1\"/> 为更优的策略，在所考察的状态 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 处，依据下式更新策略：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cwidetilde%7B%5Cpi%7D%28s%29%3D%5Cmathop%7B%5Carg%5Cmax%7D_a+A_%5Cpi%28s%2Ca%29+\" alt=\"\\widetilde{\\pi}(s)=\\mathop{\\arg\\max}_a A_\\pi(s,a) \" eeimg=\"1\"/> </p><p>直到对于所有 <img src=\"https://www.zhihu.com/equation?tex=%5Cwidetilde%7B%5Cpi%7D\" alt=\"\\widetilde{\\pi}\" eeimg=\"1\"/> 下可能到达的状态 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> ，和状态 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 下所有可能采取的动作 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 都不再有正的 <img src=\"https://www.zhihu.com/equation?tex=A_%5Cpi%28s%2Ca%29\" alt=\"A_\\pi(s,a)\" eeimg=\"1\"/> ，则说明收敛到最优策略。</p><h2>三、第一次近似</h2><p>上一节推导出的表达式中，在新策略 <img src=\"https://www.zhihu.com/equation?tex=%5Cwidetilde%7B%5Cpi%7D\" alt=\"\\widetilde{\\pi}\" eeimg=\"1\"/> 下，对所有可能到达的状态 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> ，和状态 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 下所有可能采取的动作 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> ，考察其<b>期望优势值</b> <img src=\"https://www.zhihu.com/equation?tex=A_%5Cpi%28s%2Ca%29\" alt=\"A_\\pi(s,a)\" eeimg=\"1\"/> 。对于一个参数化的策略 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%5Ctheta%28a+%5Cmid+s%29\" alt=\"\\pi_\\theta(a \\mid s)\" eeimg=\"1\"/> ，给定状态 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 输出动作 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 是很直接的，但若用其对状态采样，获得 <img src=\"https://www.zhihu.com/equation?tex=%5Crho_%7B%5Cpi%7D%28s%29\" alt=\"\\rho_{\\pi}(s)\" eeimg=\"1\"/> 则是一个漫长的过程。考虑忽略<b>折扣状态访问概率</b>因策略更新而产生的变化，用 <img src=\"https://www.zhihu.com/equation?tex=%5Crho_%7B%5Cpi%7D%28s%29\" alt=\"\\rho_{\\pi}(s)\" eeimg=\"1\"/> 替代 <img src=\"https://www.zhihu.com/equation?tex=%5Crho_%5Cwidetilde%7B%5Cpi%7D%28s%29\" alt=\"\\rho_\\widetilde{\\pi}(s)\" eeimg=\"1\"/> ，于是便有了 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29\" alt=\"\\eta(\\widetilde{\\pi})\" eeimg=\"1\"/> 的近似表达式 <img src=\"https://www.zhihu.com/equation?tex=L_%5Cpi%28%5Cwidetilde%7B%5Cpi%7D%29\" alt=\"L_\\pi(\\widetilde{\\pi})\" eeimg=\"1\"/> ： </p><p><img src=\"https://www.zhihu.com/equation?tex=L_%5Cpi%28%5Cwidetilde%7B%5Cpi%7D%29%3D%5Ceta%28%5Cpi%29%2B++%5Csum_s++%5Crho_%7B%5Cpi%7D%28s%29+%5Csum_a+%5Cwidetilde%7B%5Cpi%7D%28a+%5Cmid+s%29+A_%5Cpi%28s%2Ca%29\" alt=\"L_\\pi(\\widetilde{\\pi})=\\eta(\\pi)+  \\sum_s  \\rho_{\\pi}(s) \\sum_a \\widetilde{\\pi}(a \\mid s) A_\\pi(s,a)\" eeimg=\"1\"/> </p><p>那么这样近似之后还可信吗？方便对比写出原式： </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29+%3D+%5Ceta%28%5Cpi%29%2B++%5Csum_s++%5Crho_%5Cwidetilde%7B%5Cpi%7D%28s%29+%5Csum_a+%5Cwidetilde%7B%5Cpi%7D%28a+%5Cmid+s%29+A_%5Cpi%28s%2Ca%29+\" alt=\"\\eta(\\widetilde{\\pi}) = \\eta(\\pi)+  \\sum_s  \\rho_\\widetilde{\\pi}(s) \\sum_a \\widetilde{\\pi}(a \\mid s) A_\\pi(s,a) \" eeimg=\"1\"/> </p><h3>proof:</h3><p>对于一个关于参数向量 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 可微的策略函数 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%5Ctheta%28a+%5Cmid+s%29\" alt=\"\\pi_\\theta(a \\mid s)\" eeimg=\"1\"/> ，有这样的关系： </p><p><img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%29%3D%5Ceta%28%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%29+\" alt=\"L_{\\pi_{\\theta_{old}}}(\\pi_{\\theta_{old}})=\\eta(\\pi_{\\theta_{old}}) \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cnabla_%5Ctheta+L_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28%5Cpi_%7B%5Ctheta%7D%29%5Cmid_+%7B%5Ctheta%3D%5Ctheta%7Bold%7D%7D%3D%5Cnabla_%5Ctheta+%5Ceta+%28%5Cpi_%7B%5Ctheta%7D%29%5Cmid_%7B%5Ctheta%3D%5Ctheta_%7Bold%7D%7D\" alt=\"\\nabla_\\theta L_{\\pi_{\\theta_{old}}}(\\pi_{\\theta})\\mid_ {\\theta=\\theta{old}}=\\nabla_\\theta \\eta (\\pi_{\\theta})\\mid_{\\theta=\\theta_{old}}\" eeimg=\"1\"/> </p><p>对第一个式子，因为策略并没有改变，故： </p><p><img src=\"https://www.zhihu.com/equation?tex=+L_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%29%3D%5Ceta%28%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%29%2B%5Csum_s++%5Crho_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28s%29+%5Csum_a+%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%28a+%5Cmid+s%29+A_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28s%2Ca%29%3D%5Ceta%28%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%29+\" alt=\" L_{\\pi_{\\theta_{old}}}(\\pi_{\\theta_{old}})=\\eta(\\pi_{\\theta_{old}})+\\sum_s  \\rho_{\\pi_{\\theta_{old}}}(s) \\sum_a \\pi_{\\theta_{old}}(a \\mid s) A_{\\pi_{\\theta_{old}}}(s,a)=\\eta(\\pi_{\\theta_{old}}) \" eeimg=\"1\"/> </p><p>对第二个式子，分别来计算左右两项： </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cnabla_%5Ctheta+L_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28%5Cpi_%7B%5Ctheta%7D%29%5Cmid+_%7B%5Ctheta%3D%5Ctheta_%7Bold%7D%7D%3D%5Csum_s++%5Crho_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28s%29+%5Csum_a+%5Cnabla_%5Ctheta%5Cpi_%7B%5Ctheta%7D%28a+%5Cmid+s%29+A_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28s%2Ca%29+%5Cmid_%7B%5Ctheta%3D%5Ctheta_%7Bold%7D%7D\" alt=\"\\nabla_\\theta L_{\\pi_{\\theta_{old}}}(\\pi_{\\theta})\\mid _{\\theta=\\theta_{old}}=\\sum_s  \\rho_{\\pi_{\\theta_{old}}}(s) \\sum_a \\nabla_\\theta\\pi_{\\theta}(a \\mid s) A_{\\pi_{\\theta_{old}}}(s,a) \\mid_{\\theta=\\theta_{old}}\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cnabla_%5Ctheta+%5Ceta+%28%5Cpi_%7B%5Ctheta%7D%29%5Cmid_%7B%5Ctheta%3D%5Ctheta_%7Bold%7D%7D%3D%5Csum_s++%5Crho_%7B%5Cpi_%7B%5Ctheta%7D%7D%28s%29+%5Csum_a+%5Cnabla_%5Ctheta%5Cpi_%7B%5Ctheta%7D%28a+%5Cmid+s%29+A_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28s%2Ca%29+%5Cmid_%7B%5Ctheta%3D%5Ctheta_%7Bold%7D%7D+\" alt=\"\\nabla_\\theta \\eta (\\pi_{\\theta})\\mid_{\\theta=\\theta_{old}}=\\sum_s  \\rho_{\\pi_{\\theta}}(s) \\sum_a \\nabla_\\theta\\pi_{\\theta}(a \\mid s) A_{\\pi_{\\theta_{old}}}(s,a) \\mid_{\\theta=\\theta_{old}} \" eeimg=\"1\"/> </p><p>实际操作中， <img src=\"https://www.zhihu.com/equation?tex=%5Csum_s++%5Crho_%7B%5Cpi_%7B%5Ctheta%7D%7D%28s%29\" alt=\"\\sum_s  \\rho_{\\pi_{\\theta}}(s)\" eeimg=\"1\"/> 是由样本信息得到的，当安照 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta%3D%5Ctheta_%7Bold%7D\" alt=\"\\theta=\\theta_{old}\" eeimg=\"1\"/> ，即 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Ctheta_%7Bold%7D%7D\" alt=\"\\pi_{\\theta_{old}}\" eeimg=\"1\"/> 采样时， <img src=\"https://www.zhihu.com/equation?tex=%5Csum_s++%5Crho_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28s%29%3D%5Csum_s++%5Crho_%7B%5Cpi_%7B%5Ctheta%7D%7D%28s%29\" alt=\"\\sum_s  \\rho_{\\pi_{\\theta_{old}}}(s)=\\sum_s  \\rho_{\\pi_{\\theta}}(s)\" eeimg=\"1\"/> ，左右两项相等。</p><h3>结论:</h3><p>表明对于函数 <img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28%5Cpi_%7B%5Ctheta%7D%29\" alt=\"L_{\\pi_{\\theta_{old}}}(\\pi_{\\theta})\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta+%28%5Cpi_%7B%5Ctheta%7D%29\" alt=\"\\eta (\\pi_{\\theta})\" eeimg=\"1\"/> ，在 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta_%7Bold%7D\" alt=\"\\theta_{old}\" eeimg=\"1\"/> 处，对 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta_%7Bold%7D\" alt=\"\\theta_{old}\" eeimg=\"1\"/> 更新足够小的一步，那么对 <img src=\"https://www.zhihu.com/equation?tex=L_%7B%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%7D%28%5Cpi_%7B%5Ctheta%7D%29\" alt=\"L_{\\pi_{\\theta_{old}}}(\\pi_{\\theta})\" eeimg=\"1\"/> 的提高相等于对 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta+%28%5Cpi_%7B%5Ctheta%7D%29\" alt=\"\\eta (\\pi_{\\theta})\" eeimg=\"1\"/> 的提高。</p><h2>四、策略更新的定量描述</h2><p>经过上面的讨论，现在就面临两个问题： </p><p>1. 如何衡量 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta_%7Bold%7D\" alt=\"\\theta_{old}\" eeimg=\"1\"/> 与 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta_%7Bnew%7D\" alt=\"\\theta_{new}\" eeimg=\"1\"/> 之间的距离？</p><p>2. 更新策略后，会带来 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi_%7B%5Ctheta%7D%29\" alt=\"\\eta(\\pi_{\\theta})\" eeimg=\"1\"/> 多大的提升？</p><p>本文提出的衡量 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7Bold%7D\" alt=\"\\pi_{old}\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7Bnew%7D\" alt=\"\\pi_{new}\" eeimg=\"1\"/> （此后用 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7Bold%7D\" alt=\"\\pi_{old}\" eeimg=\"1\"/> 表示 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Ctheta_%7Bold%7D%7D\" alt=\"\\pi_{\\theta_{old}}\" eeimg=\"1\"/> ，用 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7Bnew%7D\" alt=\"\\pi_{new}\" eeimg=\"1\"/> 表示 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Ctheta_%7Bnew%7D%7D\" alt=\"\\pi_{\\theta_{new}}\" eeimg=\"1\"/> ）之间距离的方式为： <img src=\"https://www.zhihu.com/equation?tex=the%5C+total%5C++variation%5C++divergence\" alt=\"the\\ total\\  variation\\  divergence\" eeimg=\"1\"/> </p><h3>定义</h3><p><img src=\"https://www.zhihu.com/equation?tex=the%5C+total%5C++variation%5C++divergence\" alt=\"the\\ total\\  variation\\  divergence\" eeimg=\"1\"/> 的表达式： </p><p><img src=\"https://www.zhihu.com/equation?tex=D_%7BTV%7D%28p%7C%7Cq%29%3D%5Cfrac%7B1%7D%7B2%7D%5Csum_i+%5Cleft%7C+p_i-q_i+%5Cright%7C+\" alt=\"D_{TV}(p||q)=\\frac{1}{2}\\sum_i \\left| p_i-q_i \\right| \" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=p\" alt=\"p\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=q\" alt=\"q\" eeimg=\"1\"/> 为离散随机变量的概率函数。如果对连续随机变量，则 <img src=\"https://www.zhihu.com/equation?tex=p\" alt=\"p\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=q\" alt=\"q\" eeimg=\"1\"/> 表示概率密度函数，需将求和改为积分。定义：</p><p><img src=\"https://www.zhihu.com/equation?tex=D_%7BTV%7D%5E%7Bmax%7D%28%5Cpi_%7Bold%7D%2C%5Cpi_%7Bnew%7D%29%3D%5Cmax_sD_%7BTV%7D%28%5Cpi_%7Bold%7D%28%5Ccdot+%5Cmid+s%29%5Cparallel+%5Cpi_%7Bnew%7D%28%5Ccdot+%5Cmid+s%29%29+\" alt=\"D_{TV}^{max}(\\pi_{old},\\pi_{new})=\\max_sD_{TV}(\\pi_{old}(\\cdot \\mid s)\\parallel \\pi_{new}(\\cdot \\mid s)) \" eeimg=\"1\"/> </p><h3>重要不等式</h3><p>有如下不等式关系： </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi_%7Bnew%7D%29%5Cge+L_%7B%5Cpi_%7Bold%7D%7D%28%5Cpi_%7Bnew%7D%29-%5Cfrac%7B4%5Cepsilon+%5Cgamma%7D%7B%281-%5Cgamma%29%5E2%7D%5Calpha+%5E2+\" alt=\"\\eta(\\pi_{new})\\ge L_{\\pi_{old}}(\\pi_{new})-\\frac{4\\epsilon \\gamma}{(1-\\gamma)^2}\\alpha ^2 \" eeimg=\"1\"/> </p><p>其中：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cepsilon%3D%5Cmax_%7Bs%2Ca%7D%5Cleft+%7C+A_%5Cpi%28s%2Ca%29+%5Cright%7C+%5C+\" alt=\"\\epsilon=\\max_{s,a}\\left | A_\\pi(s,a) \\right| \\ \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Calpha%3DD_%7BTV%7D%5E%7Bmax%7D%28%5Cpi_%7Bold%7D%2C%5Cpi_%7Bnew%7D%29+\" alt=\"\\alpha=D_{TV}^{max}(\\pi_{old},\\pi_{new}) \" eeimg=\"1\"/> </p><p>注意到 <img src=\"https://www.zhihu.com/equation?tex=total%5C++variation%5C++divergence\" alt=\"total\\  variation\\  divergence\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=KL%5C+divergence\" alt=\"KL\\ divergence\" eeimg=\"1\"/> 之间的关系： </p><p><img src=\"https://www.zhihu.com/equation?tex=D_%7BTV%7D%28p+%5Cparallel+q%29%5E2+%5Cle+D_%7BKL%7D%28p+%5Cparallel+q%29+\" alt=\"D_{TV}(p \\parallel q)^2 \\le D_{KL}(p \\parallel q) \" eeimg=\"1\"/> </p><p>令</p><p><img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D%5E%7Bmax%7D%28%5Cpi_%7Bold%7D%2C%5Cpi_%7Bnew%7D%29%3D%5Cmax_sD_%7BTV%7D%28%5Cpi_%7Bold%7D%28%5Ccdot+%5Cmid+s%29%5Cparallel+%5Cpi_%7Bnew%7D%28%5Ccdot+%5Cmid+s%29%29\" alt=\"D_{KL}^{max}(\\pi_{old},\\pi_{new})=\\max_sD_{TV}(\\pi_{old}(\\cdot \\mid s)\\parallel \\pi_{new}(\\cdot \\mid s))\" eeimg=\"1\"/> </p><p>于是经过变换得到了本文的重要不等式： </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi_%7Bnew%7D%29%5Cge+L_%7B%5Cpi_%7Bold%7D%7D%28%5Cpi_%7Bnew%7D%29-C%5Ccdot+D_%7BKL%7D%5E%7Bmax%7D%28%5Cpi_%7Bold%7D%2C%5Cpi_%7Bnew%7D%29+\" alt=\"\\eta(\\pi_{new})\\ge L_{\\pi_{old}}(\\pi_{new})-C\\cdot D_{KL}^{max}(\\pi_{old},\\pi_{new}) \" eeimg=\"1\"/> </p><p>其中 </p><p><img src=\"https://www.zhihu.com/equation?tex=C%3D%5Cfrac%7B4%5Cepsilon+%5Cgamma%7D%7B%281-%5Cgamma%29%5E2%7D+\" alt=\"C=\\frac{4\\epsilon \\gamma}{(1-\\gamma)^2} \" eeimg=\"1\"/> </p><h2>五、策略更新的方式</h2><p>经过上面的讨论我们得出了一个重要的不等关系： </p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Ceta%28%5Cpi_%7Bnew%7D%29%5Cge+L_%7B%5Cpi_%7Bold%7D%7D%28%5Cpi_%7Bnew%7D%29-C%5Ccdot+D_%7BKL%7D%5E%7Bmax%7D%28%5Cpi_%7Bold%7D%2C%5Cpi_%7Bnew%7D%29+\" alt=\" \\eta(\\pi_{new})\\ge L_{\\pi_{old}}(\\pi_{new})-C\\cdot D_{KL}^{max}(\\pi_{old},\\pi_{new}) \" eeimg=\"1\"/> </p><p>更改一下变量脚标：</p><p>​                                      <img src=\"https://www.zhihu.com/equation?tex=+%5Ceta%28%5Cpi%29%5Cge+L_%7B%5Cpi_%7Bi%7D%7D%28%5Cpi%29-C%5Ccdot+D_%7BKL%7D%5E%7Bmax%7D%28%5Cpi_%7Bi%7D%2C%5Cpi%29+\" alt=\" \\eta(\\pi)\\ge L_{\\pi_{i}}(\\pi)-C\\cdot D_{KL}^{max}(\\pi_{i},\\pi) \" eeimg=\"1\"/> </p><p>此后以 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_i\" alt=\"\\pi_i\" eeimg=\"1\"/> 表示当前策略，以 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7Bi%2B1%7D%E2%80%8B\" alt=\"\\pi_{i+1}​\" eeimg=\"1\"/> 表示更新后的策略，这是一个以 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"/> 为变量的不等式，在 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi%3D%5Cpi_i\" alt=\"\\pi=\\pi_i\" eeimg=\"1\"/> 时取等。</p><p>可以利用这一不等关系对参数化的策略函数进行更新。此不等式表明了 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> 的下限，我们用 <img src=\"https://www.zhihu.com/equation?tex=M_i%28%5Cpi%29\" alt=\"M_i(\\pi)\" eeimg=\"1\"/> 来表示此下限：</p><p><img src=\"https://www.zhihu.com/equation?tex=M_i%28%5Cpi%29%3DL_%7B%5Cpi_i%7D%28%5Cpi%29-C%5Ccdot+D_%7BKL%7D%5E%7Bmax%7D%28%5Cpi_%7Bi%7D%2C%5Cpi%29\" alt=\"M_i(\\pi)=L_{\\pi_i}(\\pi)-C\\cdot D_{KL}^{max}(\\pi_{i},\\pi)\" eeimg=\"1\"/> </p><p>通过提升 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> 的下限 <img src=\"https://www.zhihu.com/equation?tex=M_i%28%5Cpi%29\" alt=\"M_i(\\pi)\" eeimg=\"1\"/> ，来带来 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi%29\" alt=\"\\eta(\\pi)\" eeimg=\"1\"/> 的提升：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi_%7Bi%2B1%7D%29%5Cge+M_i%28%5Cpi_%7Bi%2B1%7D%29\" alt=\"\\eta(\\pi_{i+1})\\ge M_i(\\pi_{i+1})\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi_i%29%3DM_i%28%5Cpi_i%29%3DL_%7B%5Cpi_i%7D%28%5Cpi_i%29+\" alt=\"\\eta(\\pi_i)=M_i(\\pi_i)=L_{\\pi_i}(\\pi_i) \" eeimg=\"1\"/> </p><p>由以上两式可得：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi_%7Bi%2B1%7D%29-%5Ceta%28%5Cpi_i%29%5Cge+M_i%28%5Cpi_%7Bi%2B1%7D%29-M_i%28%5Cpi_i%29+\" alt=\"\\eta(\\pi_{i+1})-\\eta(\\pi_i)\\ge M_i(\\pi_{i+1})-M_i(\\pi_i) \" eeimg=\"1\"/> </p><p>这种更新是一种最小最大算法： </p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-eaa31d02c721f324a7592b57fbb9739a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"527\" data-rawheight=\"348\" class=\"origin_image zh-lightbox-thumb\" width=\"527\" data-original=\"https://pic3.zhimg.com/v2-eaa31d02c721f324a7592b57fbb9739a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;527&#39; height=&#39;348&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"527\" data-rawheight=\"348\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"527\" data-original=\"https://pic3.zhimg.com/v2-eaa31d02c721f324a7592b57fbb9739a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-eaa31d02c721f324a7592b57fbb9739a_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-74c879ee8a99f6f789c9138d2cd01bab_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1051\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb\" width=\"1051\" data-original=\"https://pic4.zhimg.com/v2-74c879ee8a99f6f789c9138d2cd01bab_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1051&#39; height=&#39;414&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1051\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1051\" data-original=\"https://pic4.zhimg.com/v2-74c879ee8a99f6f789c9138d2cd01bab_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-74c879ee8a99f6f789c9138d2cd01bab_b.jpg\"/></figure><h2>六、第二次近似</h2><p>以上我们得出了可以对策略迭代更新的算法，下面来考虑将其应用于实际问题。以下所讨论的策略 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"/> 均是以向量 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 为参数的参数化的策略 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Ctheta%7D\" alt=\"\\pi_{\\theta}\" eeimg=\"1\"/> ，集中约定一下符号表示： </p><ul><li><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Ctheta%29%3A%3D%5Ceta%28%5Cpi_%5Ctheta%29\" alt=\"\\eta(\\theta):=\\eta(\\pi_\\theta)\" eeimg=\"1\"/> </li><li><img src=\"https://www.zhihu.com/equation?tex=L_%5Ctheta%28%5Cwidetilde%7B%5Ctheta%7D%29%3A%3DL_%7B%5Cpi_%7B%5Ctheta%7D%7D%28%5Cpi_%7B%5Cwidetilde%7B%5Ctheta%7D%7D%29\" alt=\"L_\\theta(\\widetilde{\\theta}):=L_{\\pi_{\\theta}}(\\pi_{\\widetilde{\\theta}})\" eeimg=\"1\"/> </li><li><img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D%28%5Ctheta+%5Cparallel+%5Cwidetilde%7B%5Ctheta%7D%29%3A%3DD_%7BKL%7D%28%5Cpi_%7B%5Ctheta%7D%5Cparallel+%5Cpi_%7B%5Cwidetilde%7B%5Ctheta%7D%7D%29\" alt=\"D_{KL}(\\theta \\parallel \\widetilde{\\theta}):=D_{KL}(\\pi_{\\theta}\\parallel \\pi_{\\widetilde{\\theta}})\" eeimg=\"1\"/> </li><li> 用 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta_%7Bold%7D\" alt=\"\\theta_{old}\" eeimg=\"1\"/> 表示待更新的参数</li></ul><p>之前得到的不等式为： </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Ctheta%29%5Cge+L_%7B%5Ctheta_%7Bold%7D%7D%28%5Ctheta%29-C%5Ccdot+D_%7BKL%7D%5E%7Bmax%7D%28%5Ctheta_%7Bold%7D%5Cparallel+%5Ctheta%29\" alt=\"\\eta(\\theta)\\ge L_{\\theta_{old}}(\\theta)-C\\cdot D_{KL}^{max}(\\theta_{old}\\parallel \\theta)\" eeimg=\"1\"/> </p><p>更新 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 的过程是这样的：找到一个 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 使得不等号右边值最大，然后令 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta_%7Bold%7D%3D%5Ctheta\" alt=\"\\theta_{old}=\\theta\" eeimg=\"1\"/> ： </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%5Ctheta+%5Cleft%5B++L_%7B%5Ctheta_%7Bold%7D%7D%28%5Ctheta%29-C%5Ccdot+D_%7BKL%7D%5E%7Bmax%7D%28%5Ctheta_%7Bold%7D%5Cparallel+%5Ctheta%29%5Cright%5D+\" alt=\"\\max_\\theta \\left[  L_{\\theta_{old}}(\\theta)-C\\cdot D_{KL}^{max}(\\theta_{old}\\parallel \\theta)\\right] \" eeimg=\"1\"/> </p><p>而这一更新方式在使用中有<b>如下问题</b>：</p><ul><li>如果使用理论推导出的不等式，系数 <img src=\"https://www.zhihu.com/equation?tex=C%3D%5Cfrac%7B4%5Cepsilon+%5Cgamma%7D%7B%281-%5Cgamma%29%5E2%7D\" alt=\"C=\\frac{4\\epsilon \\gamma}{(1-\\gamma)^2}\" eeimg=\"1\"/> ，那么更新步幅会很小，更新会很慢，而着眼于 <img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D%5E%7Bmax%7D\" alt=\"D_{KL}^{max}\" eeimg=\"1\"/> 项，通过对这一项进行约束，将问题转换成有约束的优化问题，可以获得较大的更新步幅。这种对于新旧策略间差距的约束称为 <img src=\"https://www.zhihu.com/equation?tex=trust+%5C+region+%5C+constraint\" alt=\"trust \\ region \\ constraint\" eeimg=\"1\"/> （这是TRPO区别于PPO的地方，PPO使用可调节大小的 <img src=\"https://www.zhihu.com/equation?tex=C\" alt=\"C\" eeimg=\"1\"/>  ）：</li></ul><p><img src=\"https://www.zhihu.com/equation?tex=+%5Cmax_%5Ctheta+L_%7B%5Ctheta_%7Bold%7D%7D%28%5Ctheta%29+%5C+\" alt=\" \\max_\\theta L_{\\theta_{old}}(\\theta) \\ \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=subject%5C+to+%5Cquad++D_%7BKL%7D%5E%7Bmax%7D%28%5Ctheta_%7Bold%7D%5Cparallel+%5Ctheta%29%5Cle+%5Cdelta+\" alt=\"subject\\ to \\quad  D_{KL}^{max}(\\theta_{old}\\parallel \\theta)\\le \\delta \" eeimg=\"1\"/> </p><ul><li>注意到 <img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D%5E%7Bmax%7D\" alt=\"D_{KL}^{max}\" eeimg=\"1\"/> 的定义式：</li></ul><p><img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D%5E%7Bmax%7D%3D%5Cmax_s+D_%7BKL%7D%28%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%28%5Ccdot+%5Cmid+s%29+%5Cparallel+%5Cpi_%7B%5Ctheta%7D%28%5Ccdot+%5Cmid+s%29+%29+\" alt=\"D_{KL}^{max}=\\max_s D_{KL}(\\pi_{\\theta_{old}}(\\cdot \\mid s) \\parallel \\pi_{\\theta}(\\cdot \\mid s) ) \" eeimg=\"1\"/> </p><p>  可见 <img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D%5E%7Bmax%7D%28%5Ctheta_%7Bold%7D%5Cparallel+%5Ctheta%29%5Cle+%5Cdelta\" alt=\"D_{KL}^{max}(\\theta_{old}\\parallel \\theta)\\le \\delta\" eeimg=\"1\"/> 这个约束是施加于所有状态的，要对每一个状态进行考察。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>基于以上两点讨论，本文进行了<b>第二次近似</b>：</p><p>用 <img src=\"https://www.zhihu.com/equation?tex=average+%5C+KL+%5C+divergence\" alt=\"average \\ KL \\ divergence\" eeimg=\"1\"/> 代替原来的 <img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D%5E%7Bmax%7D\" alt=\"D_{KL}^{max}\" eeimg=\"1\"/> 约束项。</p><h3>定义</h3><p><img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BD%7D_%7BKL%7D%5E%7B%5Crho%7D%28%5Ctheta_1%2C%5Ctheta_2%29%3A%3D%5Cmathbb%7BE%7D%7Bs%5Csim+%5Crho%7D%5Cleft%5BD_%7BKL%7D%28%5Cpi_%7B%5Ctheta_%7B1%7D%7D%28%5Ccdot+%5Cmid+s%29+%5Cparallel+%5Cpi_%7B%5Ctheta_%7B2%7D%7D%28%5Ccdot+%5Cmid+s%29+%29%5Cright%5D+\" alt=\"\\bar{D}_{KL}^{\\rho}(\\theta_1,\\theta_2):=\\mathbb{E}{s\\sim \\rho}\\left[D_{KL}(\\pi_{\\theta_{1}}(\\cdot \\mid s) \\parallel \\pi_{\\theta_{2}}(\\cdot \\mid s) )\\right] \" eeimg=\"1\"/> </p><p>这不是对所有可能到达的状态 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 中可取到的 <img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D\" alt=\"D_{KL}\" eeimg=\"1\"/> 的最大值，而是考虑对于采样到的所有 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 的 <img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D\" alt=\"D_{KL}\" eeimg=\"1\"/> 期望值。于是问题变为：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%5Ctheta+L_%7B%5Ctheta_%7Bold%7D%7D%28%5Ctheta%29+%5C+\" alt=\"\\max_\\theta L_{\\theta_{old}}(\\theta) \\ \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=subject+%5C+to+%5Cquad+%5Cbar%7BD%7D_%7BKL%7D%5E%7B%5Crho_%7B%5Ctheta_%7Bold%7D%7D%7D%28%5Ctheta_%7Bold%7D%2C%5Ctheta%29+%5Cle+%5Cdelta+\" alt=\"subject \\ to \\quad \\bar{D}_{KL}^{\\rho_{\\theta_{old}}}(\\theta_{old},\\theta) \\le \\delta \" eeimg=\"1\"/> </p><p>这样近似之后，是否可行？<b>在实验中发现，</b> <img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BD%7D_%7BKL%7D%5E%7B%5Crho%7D\" alt=\"\\bar{D}_{KL}^{\\rho}\" eeimg=\"1\"/> <b>和</b> <img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D%5E%7Bmax%7D\" alt=\"D_{KL}^{max}\" eeimg=\"1\"/> <b>有着相似的表现</b>。</p><h2>七、第三次近似——这一次近似了三处</h2><p>接下来进一步走向实际使用，用 <img src=\"https://www.zhihu.com/equation?tex=sample-based+%5C+estimation\" alt=\"sample-based \\ estimation\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=Monte+Carlo+simulation\" alt=\"Monte Carlo simulation\" eeimg=\"1\"/> 去估计<b>目标函数</b>和<b>约束条件</b>： <br/>将目标函数展开： </p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-8bf833df99b0ff30700c5c29bb53e9e7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"561\" data-rawheight=\"321\" class=\"origin_image zh-lightbox-thumb\" width=\"561\" data-original=\"https://pic4.zhimg.com/v2-8bf833df99b0ff30700c5c29bb53e9e7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;561&#39; height=&#39;321&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"561\" data-rawheight=\"321\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"561\" data-original=\"https://pic4.zhimg.com/v2-8bf833df99b0ff30700c5c29bb53e9e7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-8bf833df99b0ff30700c5c29bb53e9e7_b.jpg\"/></figure><ul><li>对 <img src=\"https://www.zhihu.com/equation?tex=A_%7B%5Ctheta_%7Bold%7D%7D%28s%2Ca%29\" alt=\"A_{\\theta_{old}}(s,a)\" eeimg=\"1\"/> 的替换：</li></ul><p><img src=\"https://www.zhihu.com/equation?tex=%5Csum_a+%5Cpi_%7B%5Ctheta%7D%28a+%5Cmid+s%29+A_%7B%5Ctheta_%7Bold%7D%7D%28s%2Ca%29%3D+%5Csum_a+%5Cpi_%7B%5Ctheta%7D%28a+%5Cmid+s%29%5BQ_%7B%5Ctheta_%7Bold%7D%7D%28s%2Ca%29-V_%7B%5Ctheta_%7Bold%7D%7D%28s%29%5D%5C\" alt=\"\\sum_a \\pi_{\\theta}(a \\mid s) A_{\\theta_{old}}(s,a)= \\sum_a \\pi_{\\theta}(a \\mid s)[Q_{\\theta_{old}}(s,a)-V_{\\theta_{old}}(s)]\\\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D+%5Csum_a+%5B%5Cpi_%7B%5Ctheta%7D%28a+%5Cmid+s%29+Q_%7B%5Ctheta_%7Bold%7D%7D%28s%2Ca%29%5D-+V_%7B%5Ctheta_%7Bold%7D%7D%28s%29+%5Csum_a+%5Cpi_%7B%5Ctheta%7D%28a+%5Cmid+s%29+\" alt=\"= \\sum_a [\\pi_{\\theta}(a \\mid s) Q_{\\theta_{old}}(s,a)]- V_{\\theta_{old}}(s) \\sum_a \\pi_{\\theta}(a \\mid s) \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D+%5Csum_a+%5Cpi_%7B%5Ctheta%7D%28a+%5Cmid+s%29+Q_%7B%5Ctheta_%7Bold%7D%7D%28s%2Ca%29-V_%7B%5Ctheta_%7Bold%7D%7D%28s%29+\" alt=\"= \\sum_a \\pi_{\\theta}(a \\mid s) Q_{\\theta_{old}}(s,a)-V_{\\theta_{old}}(s) \" eeimg=\"1\"/> </p><h2>八、优化目标的最终形态</h2><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%7B%5Ctheta%7D%5Cmathbb%7BE%7D_%7Bs%5Csim+%5Crho_%7B%5Ctheta_%7Bold%7D%7D%2Ca%5Csim+q%7D%5Cleft%5B+%5Cfrac%7B%5Cpi_%7B%5Ctheta%7D%28a+%5Cmid+s%29%7D%7Bq%28a%5Cmid+s%29%7DQ_%7B%5Ctheta_%7Bold%7D%28s%2Ca%29%7D%5Cright%5D%5C\" alt=\"\\max_{\\theta}\\mathbb{E}_{s\\sim \\rho_{\\theta_{old}},a\\sim q}\\left[ \\frac{\\pi_{\\theta}(a \\mid s)}{q(a\\mid s)}Q_{\\theta_{old}(s,a)}\\right]\\\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=subject+%5C+to+%5Cquad+%5Cmathbb%7BE%7D_%7Bs%5Csim+%5Crho_%7B%5Ctheta_%7Bold%7D%7D%7D%5Cleft%5B+D_%7BKL%7D%28%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%28%5Ccdot+%5Cmid+s%29%5Cparallel+%5Cpi_%7B%5Ctheta%7D%28%5Ccdot+%5Cmid+s%29%29%5Cright%5D+%5Cle+%5Cdelta\" alt=\"subject \\ to \\quad \\mathbb{E}_{s\\sim \\rho_{\\theta_{old}}}\\left[ D_{KL}(\\pi_{\\theta_{old}}(\\cdot \\mid s)\\parallel \\pi_{\\theta}(\\cdot \\mid s))\\right] \\le \\delta\" eeimg=\"1\"/> </p><p>在实际操作时： </p><ul><li>用样本均值 <img src=\"https://www.zhihu.com/equation?tex=%28sample+%5C+averages%29\" alt=\"(sample \\ averages)\" eeimg=\"1\"/> 替换期望 <img src=\"https://www.zhihu.com/equation?tex=%5Cmathbb%7BE%7D\" alt=\"\\mathbb{E}\" eeimg=\"1\"/> </li><li>用实验估计 <img src=\"https://www.zhihu.com/equation?tex=%28empirical+%5C+estimate%29\" alt=\"(empirical \\ estimate)\" eeimg=\"1\"/> 替换 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 值</li></ul><h2>九、采样估计方式</h2><ol><li>Single Path</li><li>Vine   </li></ol><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-41cc446010662a889c7f0a7dbd3214df_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"593\" data-rawheight=\"221\" class=\"origin_image zh-lightbox-thumb\" width=\"593\" data-original=\"https://pic4.zhimg.com/v2-41cc446010662a889c7f0a7dbd3214df_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;593&#39; height=&#39;221&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"593\" data-rawheight=\"221\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"593\" data-original=\"https://pic4.zhimg.com/v2-41cc446010662a889c7f0a7dbd3214df_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-41cc446010662a889c7f0a7dbd3214df_b.jpg\"/></figure><h3>Single Path</h3><ol><li>通过 <img src=\"https://www.zhihu.com/equation?tex=s_0%5Csim+%5Crho_0\" alt=\"s_0\\sim \\rho_0\" eeimg=\"1\"/> 选取一个 <img src=\"https://www.zhihu.com/equation?tex=s_0\" alt=\"s_0\" eeimg=\"1\"/> </li><li>由这个 <img src=\"https://www.zhihu.com/equation?tex=s_0\" alt=\"s_0\" eeimg=\"1\"/> 出发，执行 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Ctheta_%7Bold%7D%7D\" alt=\"\\pi_{\\theta_{old}}\" eeimg=\"1\"/> 。经过 <img src=\"https://www.zhihu.com/equation?tex=T\" alt=\"T\" eeimg=\"1\"/> 步之后结束，得到一条轨迹： <img src=\"https://www.zhihu.com/equation?tex=s_0%2Ca_0%2Cs_1%2Ca_1%2C%5Cdots%2Cs_%7BT-1%7D%2Ca_%7BT-1%7D%2Cs_T\" alt=\"s_0,a_0,s_1,a_1,\\dots,s_{T-1},a_{T-1},s_T\" eeimg=\"1\"/> </li><li><img src=\"https://www.zhihu.com/equation?tex=q%28a%5Cmid+s%29\" alt=\"q(a\\mid s)\" eeimg=\"1\"/> 即为 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%28a%5Cmid+s%29\" alt=\"\\pi_{\\theta_{old}}(a\\mid s)\" eeimg=\"1\"/> </li><li><img src=\"https://www.zhihu.com/equation?tex=Q_%7B%5Ctheta_%7Bold%7D%28s%2Ca%29%7D\" alt=\"Q_{\\theta_{old}(s,a)}\" eeimg=\"1\"/> ：在每一步 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> ，计算从 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 到 <img src=\"https://www.zhihu.com/equation?tex=T\" alt=\"T\" eeimg=\"1\"/> 之间的这一段轨迹的折扣回报总和</li></ol><h2>十、算法流程梳理</h2><ol><li>使用 <img src=\"https://www.zhihu.com/equation?tex=Single+Path\" alt=\"Single Path\" eeimg=\"1\"/> 或 <img src=\"https://www.zhihu.com/equation?tex=Vine\" alt=\"Vine\" eeimg=\"1\"/> 的方式采集样本，即状态-动作对，估计 <img src=\"https://www.zhihu.com/equation?tex=Q-Value\" alt=\"Q-Value\" eeimg=\"1\"/> </li><li>将需要的量关于所有样本求平均，求出下式中需要估计出的值和约束项</li></ol><p><img src=\"https://www.zhihu.com/equation?tex=+%5Cmax_%7B%5Ctheta%7D%5Cmathbb%7BE%7D_%7Bs%5Csim+%5Crho_%7B%5Ctheta_%7Bold%7D%7D%2Ca%5Csim+q%7D%5Cleft%5B+%5Cfrac%7B%5Cpi_%7B%5Ctheta%7D%28a+%5Cmid+s%29%7D%7Bq%28a%5Cmid+s%29%7DQ_%7B%5Ctheta_%7Bold%7D%28s%2Ca%29%7D%5Cright%5D%5C\" alt=\" \\max_{\\theta}\\mathbb{E}_{s\\sim \\rho_{\\theta_{old}},a\\sim q}\\left[ \\frac{\\pi_{\\theta}(a \\mid s)}{q(a\\mid s)}Q_{\\theta_{old}(s,a)}\\right]\\\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=subject+%5C+to+%5Cquad+%5Cmathbb%7BE%7D_%7Bs%5Csim+%5Crho_%7B%5Ctheta_%7Bold%7D%7D%7D%5Cleft%5B+D_%7BKL%7D%28%5Cpi_%7B%5Ctheta_%7Bold%7D%7D%28%5Ccdot+%5Cmid+s%29%5Cparallel+%5Cpi_%7B%5Ctheta%7D%28%5Ccdot+%5Cmid+s%29%29%5Cright%5D+%5Cle+%5Cdelta+\" alt=\"subject \\ to \\quad \\mathbb{E}_{s\\sim \\rho_{\\theta_{old}}}\\left[ D_{KL}(\\pi_{\\theta_{old}}(\\cdot \\mid s)\\parallel \\pi_{\\theta}(\\cdot \\mid s))\\right] \\le \\delta \" eeimg=\"1\"/> </p><p>3. 求解这一带有约束的最优化问题，去更新策略参数 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> </p><h2>十一、优化过程</h2><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%5Ctheta+L_%7B%5Ctheta_%7Bold%7D%7D%28%5Ctheta%29+%5C\" alt=\"\\max_\\theta L_{\\theta_{old}}(\\theta) \\\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=subject+%5C+to+%5Cquad+%5Cbar%7BD%7D_%7BKL%7D%5E%7B%5Crho_%7B%5Ctheta_%7Bold%7D%7D%7D%28%5Ctheta_%7Bold%7D%2C%5Ctheta%29+%5Cle+%5Cdelta+\" alt=\"subject \\ to \\quad \\bar{D}_{KL}^{\\rho_{\\theta_{old}}}(\\theta_{old},\\theta) \\le \\delta \" eeimg=\"1\"/> </p><p>用蒙特卡洛方法估计出目标函数与约束方程中的待估计值之后，来考虑如何解这一有约束的最优化问题。目标函数和约束方程都是关于策略参数 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 的函数，记作： </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%5Ctheta+l%28%5Ctheta%29\" alt=\"\\max_\\theta l(\\theta)\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=subject+%5C+to++%5Cqquad+kl%28%5Ctheta%29+%5Cle+%5Cdelta+\" alt=\"subject \\ to  \\qquad kl(\\theta) \\le \\delta \" eeimg=\"1\"/> </p><p>在 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta_%7Bold%7D%E2%80%8B\" alt=\"\\theta_{old}​\" eeimg=\"1\"/> 处，将 <img src=\"https://www.zhihu.com/equation?tex=l%28%5Ctheta%29%E2%80%8B\" alt=\"l(\\theta)​\" eeimg=\"1\"/> 与 <img src=\"https://www.zhihu.com/equation?tex=kl%28%5Ctheta%29%E2%80%8B\" alt=\"kl(\\theta)​\" eeimg=\"1\"/> 做 <img src=\"https://www.zhihu.com/equation?tex=Taylor%E2%80%8B\" alt=\"Taylor​\" eeimg=\"1\"/> 展开：<br/> <img src=\"https://www.zhihu.com/equation?tex=l%28%5Ctheta%29+%5Capprox+l%28%5Ctheta_%7Bold%7D%29%2B%5Cnabla+l%28%5Ctheta_%7Bold%7D%29%5ET%28%5Ctheta-%5Ctheta_%7Bold%7D%29%2B%5Cfrac%7B1%7D%7B2%7D%28%5Ctheta-%5Ctheta_%7Bold%7D%29%5ETH%28l%29%28%5Ctheta_%7Bold%7D%29%28%5Ctheta-%5Ctheta_%7Bold%7D%29+\" alt=\"l(\\theta) \\approx l(\\theta_{old})+\\nabla l(\\theta_{old})^T(\\theta-\\theta_{old})+\\frac{1}{2}(\\theta-\\theta_{old})^TH(l)(\\theta_{old})(\\theta-\\theta_{old}) \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Capprox+g%28%5Ctheta-%5Ctheta_%7Bold%7D%29\" alt=\"\\approx g(\\theta-\\theta_{old})\" eeimg=\"1\"/> </p><p><i>注：第一项为常数；第三项极小</i></p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=g%3D%5Cnabla+l%28%5Ctheta_%7Bold%7D%29%5ET%3D%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Ctheta%7Dl%28%5Ctheta%29%5Cmid_%7B%5Ctheta%3D%5Ctheta_%7Bold%7D%7D\" alt=\"g=\\nabla l(\\theta_{old})^T=\\frac{\\partial}{\\partial \\theta}l(\\theta)\\mid_{\\theta=\\theta_{old}}\" eeimg=\"1\"/> <br/> <img src=\"https://www.zhihu.com/equation?tex=kl%28%5Ctheta%29+%5Capprox+kl%28%5Ctheta_%7Bold%7D%29%2B%5Cnabla+kl%28%5Ctheta_%7Bold%7D%29%5ET%28%5Ctheta-%5Ctheta_%7Bold%7D%29%2B%5Cfrac%7B1%7D%7B2%7D%28%5Ctheta-%5Ctheta_%7Bold%7D%29%5ET+H%28kl%29%28%5Ctheta_%7Bold%7D%29%28%5Ctheta-%5Ctheta_%7Bold%7D%29+\" alt=\"kl(\\theta) \\approx kl(\\theta_{old})+\\nabla kl(\\theta_{old})^T(\\theta-\\theta_{old})+\\frac{1}{2}(\\theta-\\theta_{old})^T H(kl)(\\theta_{old})(\\theta-\\theta_{old}) \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Capprox+%5Cfrac%7B1%7D%7B2%7D%28%5Ctheta-%5Ctheta_%7Bold%7D%29%5ETF%28%5Ctheta-%5Ctheta_%7Bold%7D%29%E2%80%8B\" alt=\"\\approx \\frac{1}{2}(\\theta-\\theta_{old})^TF(\\theta-\\theta_{old})​\" eeimg=\"1\"/> </p><p><i>注：第一项为0；第二项为0 </i><br/>其中 <img src=\"https://www.zhihu.com/equation?tex=F%3DH%28kl%29%28%5Ctheta_%7Bold%7D%29%3D%5Cfrac%7B%5Cpartial%5E2%7D%7B%5Cpartial%5E2%5Ctheta%7Dkl%28%5Ctheta%29%5Cmid_%7B%5Ctheta%3D%5Ctheta_%7Bold%7D%7D%E2%80%8B\" alt=\"F=H(kl)(\\theta_{old})=\\frac{\\partial^2}{\\partial^2\\theta}kl(\\theta)\\mid_{\\theta=\\theta_{old}}​\" eeimg=\"1\"/> <br/>此时优化问题近似成：</p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Cmax_%5Ctheta++g%28%5Ctheta-%5Ctheta_%7Bold%7D%29+%5C+\" alt=\" \\max_\\theta  g(\\theta-\\theta_{old}) \\ \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=subject+%5C+to+%5Cqquad++%5Cfrac%7B1%7D%7B2%7D%28%5Ctheta-%5Ctheta_%7Bold%7D%29%5ETF%28%5Ctheta-%5Ctheta_%7Bold%7D%29+%5Cle+%5Cdelta+\" alt=\"subject \\ to \\qquad  \\frac{1}{2}(\\theta-\\theta_{old})^TF(\\theta-\\theta_{old}) \\le \\delta \" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=g%3D%5Cnabla+l%28%5Ctheta_%7Bold%7D%29%5ET%3D%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Ctheta%7Dl%28%5Ctheta%29%5ET%5Cmid_%7B%5Ctheta%3D%5Ctheta_%7Bold%7D%7D\" alt=\"g=\\nabla l(\\theta_{old})^T=\\frac{\\partial}{\\partial \\theta}l(\\theta)^T\\mid_{\\theta=\\theta_{old}}\" eeimg=\"1\"/> <br/> <img src=\"https://www.zhihu.com/equation?tex=F%3DH%28kl%29%28%5Ctheta_%7Bold%7D%29%3D%5Cfrac%7B%5Cpartial%5E2%7D%7B%5Cpartial%5E2%5Ctheta%7Dkl%28%5Ctheta%29%5Cmid_%7B%5Ctheta%3D%5Ctheta_%7Bold%7D%7D\" alt=\"F=H(kl)(\\theta_{old})=\\frac{\\partial^2}{\\partial^2\\theta}kl(\\theta)\\mid_{\\theta=\\theta_{old}}\" eeimg=\"1\"/> </p><h3>转换成无约束优化问题</h3><p>构建拉格朗日函数：</p><p><img src=\"https://www.zhihu.com/equation?tex=L%28%5Ctheta%2C%5Clambda%29%3Dg%28%5Ctheta-%5Ctheta_%7Bold%7D%29-%5Cfrac%7B%5Clambda%7D%7B2%7D%5Cleft%5B%28%5Ctheta-%5Ctheta_%7Bold%7D%29%5ETF%28%5Ctheta-%5Ctheta_%7Bold%7D%29-%5Cdelta+%5Cright%5D+\" alt=\"L(\\theta,\\lambda)=g(\\theta-\\theta_{old})-\\frac{\\lambda}{2}\\left[(\\theta-\\theta_{old})^TF(\\theta-\\theta_{old})-\\delta \\right] \" eeimg=\"1\"/> </p><p>为约束项为不等式，故还应该满足 <img src=\"https://www.zhihu.com/equation?tex=KKT\" alt=\"KKT\" eeimg=\"1\"/> 条件： </p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Cfrac%7B1%7D%7B2%7D%28%5Ctheta-%5Ctheta_%7Bold%7D%29%5ETF%28%5Ctheta-%5Ctheta_%7Bold%7D%29+%5Cle+%5Cdelta+%5C\" alt=\" \\frac{1}{2}(\\theta-\\theta_{old})^TF(\\theta-\\theta_{old}) \\le \\delta \\\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Clambda+%5Cge+0+%5C\" alt=\" \\lambda \\ge 0 \\\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Clambda+%5Cfrac%7B1%7D%7B2%7D%5B%28%5Ctheta-%5Ctheta_%7Bold%7D%29%5ETF%28%5Ctheta-%5Ctheta_%7Bold%7D%29-%5Cdelta%5D+%3D+0+%5C+\" alt=\"\\lambda \\frac{1}{2}[(\\theta-\\theta_{old})^TF(\\theta-\\theta_{old})-\\delta] = 0 \\ \" eeimg=\"1\"/> </p><p>由以上三式可得：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B2%7Ds%5ETFs%3D%5Cdelta+\" alt=\"\\frac{1}{2}s^TFs=\\delta \" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 为参数 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 的更新方向 <img src=\"https://www.zhihu.com/equation?tex=s%3D%5Ctheta-%5Ctheta_%7Bold%7D\" alt=\"s=\\theta-\\theta_{old}\" eeimg=\"1\"/> </p><p>至此我们就可以真正开始寻找函数的极值了!</p><h2>十二、共轭梯度法</h2><p>像最速下降法一样寻找一个更新方向，不奢求像牛顿法那样一步到位，只求方向选的科学、且有较大的更新步长。 </p><h3>基本思路</h3><p>对一个凸函数，</p><p><img src=\"https://www.zhihu.com/equation?tex=f%28x%29%3D%5Cfrac%7B1%7D%7B2%7Dx%5ETQx%2Bqx%2Bc+\" alt=\"f(x)=\\frac{1}{2}x^TQx+qx+c \" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=Q%5Cin+%5Cmathbb%7BR%7D%5E%7Bn%5Ctimes+n%7D\" alt=\"Q\\in \\mathbb{R}^{n\\times n}\" eeimg=\"1\"/> 为对称正定矩阵， <img src=\"https://www.zhihu.com/equation?tex=q%5Cin+%5Cmathbb%7BR%7D%5En\" alt=\"q\\in \\mathbb{R}^n\" eeimg=\"1\"/> </p><p>找到一组方向向量 <img src=\"https://www.zhihu.com/equation?tex=d_1%2C%5Cldots%2Cd_n+%5Cin+%5Cmathbb%7BR%7D%5En\" alt=\"d_1,\\ldots,d_n \\in \\mathbb{R}^n\" eeimg=\"1\"/> ，依次按此方向组中的方向对迭代点 <img src=\"https://www.zhihu.com/equation?tex=x_%7Bi%7D%5Cin+%5Cmathbb%7BR%7D%5En\" alt=\"x_{i}\\in \\mathbb{R}^n\" eeimg=\"1\"/> 进行更新，对每一个方向 <img src=\"https://www.zhihu.com/equation?tex=d_i\" alt=\"d_i\" eeimg=\"1\"/> 找到一个合适的步长 <img src=\"https://www.zhihu.com/equation?tex=%5Clambda_i\" alt=\"\\lambda_i\" eeimg=\"1\"/> ，使得 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 在该方向上取得最小值。 </p><p>有这样一个关键<b>要求</b>，在每一个新的更新方向 <img src=\"https://www.zhihu.com/equation?tex=d_k\" alt=\"d_k\" eeimg=\"1\"/> 对迭代点 <img src=\"https://www.zhihu.com/equation?tex=x_k\" alt=\"x_k\" eeimg=\"1\"/> 进行更新时，不能影响在之前方向 <img src=\"https://www.zhihu.com/equation?tex=d_j%28j%5Cle+k-1%29\" alt=\"d_j(j\\le k-1)\" eeimg=\"1\"/> 上的更新结果。也即 <img src=\"https://www.zhihu.com/equation?tex=x_%7Bk%2B1%7D\" alt=\"x_{k+1}\" eeimg=\"1\"/> 不仅使 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 在 <img src=\"https://www.zhihu.com/equation?tex=d_k\" alt=\"d_k\" eeimg=\"1\"/> 方向上取得最小值且在 <img src=\"https://www.zhihu.com/equation?tex=d_j%28j%5Cle+k-1%29\" alt=\"d_j(j\\le k-1)\" eeimg=\"1\"/> 方向上均保持最小值。  </p><p>如果能找到这样一组方向 <img src=\"https://www.zhihu.com/equation?tex=d_1%2C%5Cldots%2Cd_n+%5Cin+%5Cmathbb%7BR%7D%5En\" alt=\"d_1,\\ldots,d_n \\in \\mathbb{R}^n\" eeimg=\"1\"/> ，那么在迭代次之后将找到 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 的全局极值点。而矩阵 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> <b>的共轭方向组</b>，正是我们寻找的这样一组方向。 </p><h3>算法流程</h3><p>1. 任意选择初始点 <img src=\"https://www.zhihu.com/equation?tex=x_0\" alt=\"x_0\" eeimg=\"1\"/> ，初始更新方向 <img src=\"https://www.zhihu.com/equation?tex=d_0%3D%5Cnabla+f%28x_0%29\" alt=\"d_0=\\nabla f(x_0)\" eeimg=\"1\"/> </p><p>2. 若 <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_i%29%3D0\" alt=\"\\nabla f(x_i)=0\" eeimg=\"1\"/> ，说明以找到极值点 </p><p>3. 若 <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_i%29%5Cne+0\" alt=\"\\nabla f(x_i)\\ne 0\" eeimg=\"1\"/> ，进行点的更新： <img src=\"https://www.zhihu.com/equation?tex=x_%7Bi%2B1%7D%3Dx_i%2B%5Clambda_i+d_i\" alt=\"x_{i+1}=x_i+\\lambda_i d_i\" eeimg=\"1\"/> ，<br/>     其中<br/> <img src=\"https://www.zhihu.com/equation?tex=%5Clambda_i%3D%5Cfrac%7B-d_i%5ET%5Cnabla+f%28x_i%29%7D%7Bd_i%5ETQd_i%7D\" alt=\"\\lambda_i=\\frac{-d_i^T\\nabla f(x_i)}{d_i^TQd_i}\" eeimg=\"1\"/> <br/> <img src=\"https://www.zhihu.com/equation?tex=d_i%3D-%5Cnabla+f%28x_i%29%2B%5Cgamma_%7Bi-1%7Dd_%7Bi-1%7D\" alt=\"d_i=-\\nabla f(x_i)+\\gamma_{i-1}d_{i-1}\" eeimg=\"1\"/> ，这里 <img src=\"https://www.zhihu.com/equation?tex=%5Cgamma_%7Bi-1%7D%3D%5Cfrac%7Bd_%7Bi-1%7D%5ETQ%5Cnabla+f%28x_i%29%7D%7Bd_%7Bi-1%7D%5ET+Qd_%7Bi-1%7D%7D\" alt=\"\\gamma_{i-1}=\\frac{d_{i-1}^TQ\\nabla f(x_i)}{d_{i-1}^T Qd_{i-1}}\" eeimg=\"1\"/> </p><h3>扩展到一般函数</h3><p>如牛顿法一样，先在迭代点处，将函数进行二阶Taylor展开：</p><p><img src=\"https://www.zhihu.com/equation?tex=f%28x%29%3D%5Cfrac%7B1%7D%7B2%7Dx%5ETQx%2Bqx%2Bc\" alt=\"f(x)=\\frac{1}{2}x^TQx+qx+c\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=f%28x_i%2B%5CDelta+x%29+%5Capprox+f%28x_i%29%2B%5Cnabla+f%28x_i%29%5CDelta+x%2B%5Cfrac%7B1%7D%7B2%7DH%5Bf%28x_i%29%5D%5CDelta+x%5E2\" alt=\"f(x_i+\\Delta x) \\approx f(x_i)+\\nabla f(x_i)\\Delta x+\\frac{1}{2}H[f(x_i)]\\Delta x^2\" eeimg=\"1\"/> </p><p>用这一二次函数对原函数做一个相对好的近似，然后一步步到达该二次函数的极值点。之后进行迭代点的更新，再新的迭代点再做Taylor展开，寻找极值点。这样迭代的进行下去。 </p><h3>对比牛顿法  </h3><p>这就是说，对于牛顿法直接解出的极值点 <img src=\"https://www.zhihu.com/equation?tex=x%3D-Q%5E%7B-1%7Db\" alt=\"x=-Q^{-1}b\" eeimg=\"1\"/> ，共轭梯度法用了<b>n步</b>去走到该点。但每一步都方向明确，步长坚定，抵达每一个方向上的函数极值点，因为Q-共轭方向组的性质<b>保证了</b>之后的更新，不会再影响此方向上的更新结果。<b>不用对Hessian矩阵求逆</b>。但仍需对Hessian矩阵进行存储和计算。</p><h2>十三、Hessian Free</h2><p>至此我们通过不断牺牲迭代速度来减小计算量和存储空间，而Hessian Free方法则是很聪明的一种处理方式可以让我们摆脱Hessian矩阵。<br/>通过观察共轭梯度法的算法流程，发现Hessian矩阵总是以<b>matrix-vector products</b>的形式出现的，即 <img src=\"https://www.zhihu.com/equation?tex=Hv\" alt=\"Hv\" eeimg=\"1\"/> 的形式。先来看Hessian矩阵的表达式： </p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-0826f9fabb745fa48b35dbf903412da4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"268\" data-rawheight=\"180\" class=\"content_image\" width=\"268\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;268&#39; height=&#39;180&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"268\" data-rawheight=\"180\" class=\"content_image lazy\" width=\"268\" data-actualsrc=\"https://pic1.zhimg.com/v2-0826f9fabb745fa48b35dbf903412da4_b.jpg\"/></figure><p>有以下关系：</p><p><img src=\"https://www.zhihu.com/equation?tex=%28Hv%29i%3D%5Csum_%7Bj%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+%5E2+f%7D%7B%5Cpartial+x_i+x_j%7D%28x%29%5Ccdot+v_j%3D%5Cnabla+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x_i%7D%28x%29%5Ccdot+v\" alt=\"(Hv)i=\\sum_{j=1}^N \\frac{\\partial ^2 f}{\\partial x_i x_j}(x)\\cdot v_j=\\nabla \\frac{\\partial f}{\\partial x_i}(x)\\cdot v\" eeimg=\"1\"/> </p><p>而这正是函数 <img src=\"https://www.zhihu.com/equation?tex=g%3D%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x_i%7D\" alt=\"g=\\frac{\\partial f}{\\partial x_i}\" eeimg=\"1\"/> 对于方向 <img src=\"https://www.zhihu.com/equation?tex=v\" alt=\"v\" eeimg=\"1\"/> 的方向导数，根据方向导数的定义式： </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cnabla_v+g%3D%5Clim_%7B%5Cvarepsilon+%5Cto+0%7D%5Cfrac%7Bg%28x%2B%5Cvarepsilon+v%29-g%28x%29%7D%7B%5Cvarepsilon%7D%5Capprox+%5Cfrac%7Bg%28x%2B%5Cvarepsilon+v%29-g%28x%29%7D%7B%5Cvarepsilon%7D+\" alt=\"\\nabla_v g=\\lim_{\\varepsilon \\to 0}\\frac{g(x+\\varepsilon v)-g(x)}{\\varepsilon}\\approx \\frac{g(x+\\varepsilon v)-g(x)}{\\varepsilon} \" eeimg=\"1\"/> </p><p>于是得到：</p><p><img src=\"https://www.zhihu.com/equation?tex=Hv+%5Capprox+%5Cfrac%7B%5Cnabla+f%28x%2B%5Cvarepsilon+v%29-%5Cnabla+f%28x%29%7D%7B%5Cvarepsilon%7D+\" alt=\"Hv \\approx \\frac{\\nabla f(x+\\varepsilon v)-\\nabla f(x)}{\\varepsilon} \" eeimg=\"1\"/> </p><p>经过两次梯度反向传播，即可得到关于Hessian矩阵的matrix-vector products.</p><h2>十四、Line search</h2><p>我们需要求极值的函数为此构造的拉格朗日函数： </p><p><img src=\"https://www.zhihu.com/equation?tex=L%28%5Ctheta%2C%5Clambda%29%3Dg%28%5Ctheta-%5Ctheta_%7Bold%7D%29-%5Cfrac%7B%5Clambda%7D%7B2%7D%5Cleft%5B%28%5Ctheta-%5Ctheta_%7Bold%7D%29%5ETF%28%5Ctheta-%5Ctheta_%7Bold%7D%29-%5Cdelta+%5Cright%5D+%5C\" alt=\"L(\\theta,\\lambda)=g(\\theta-\\theta_{old})-\\frac{\\lambda}{2}\\left[(\\theta-\\theta_{old})^TF(\\theta-\\theta_{old})-\\delta \\right] \\\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=constraint+%5Cqquad+%5Cfrac%7B1%7D%7B2%7Ds%5ETFs%3D%5Cdelta+\" alt=\"constraint \\qquad \\frac{1}{2}s^TFs=\\delta \" eeimg=\"1\"/> </p><p>对每一次迭代，用采用Hessian Free处理方式的共轭梯度法，计算出由当前点指向当前极值点的向量 <img src=\"https://www.zhihu.com/equation?tex=s_u%3D%5Cfrac%7B1%7D%7B%5Clambda%7DF%5E%7B-1%7Dg\" alt=\"s_u=\\frac{1}{\\lambda}F^{-1}g\" eeimg=\"1\"/> ，为满足限制条件，需要对 <img src=\"https://www.zhihu.com/equation?tex=s_u\" alt=\"s_u\" eeimg=\"1\"/> 进行修正： </p><p><img src=\"https://www.zhihu.com/equation?tex=s%3D%5Csqrt%7B%5Cfrac%7B2%5Cdelta%7D%7Bs_u%5ET+F+s_u%7D%7Ds_u+\" alt=\"s=\\sqrt{\\frac{2\\delta}{s_u^T F s_u}}s_u \" eeimg=\"1\"/> </p><p>利用这一修正后的向量 <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 进行线性搜索：<br/>分别以向量 <img src=\"https://www.zhihu.com/equation?tex=s%2C%5Cfrac%7Bs%7D%7B2%7D%2C%5Cfrac%7Bs%7D%7B4%7D%2C%5Cldots\" alt=\"s,\\frac{s}{2},\\frac{s}{4},\\ldots\" eeimg=\"1\"/> 与当前迭代点 <img src=\"https://www.zhihu.com/equation?tex=x_i\" alt=\"x_i\" eeimg=\"1\"/> 相加，直到优化目标 <img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%5Ctheta+L_%7B%5Ctheta_%7Bold%7D%7D%28%5Ctheta%29\" alt=\"\\max_\\theta L_{\\theta_{old}}(\\theta)\" eeimg=\"1\"/> 有所提升。 </p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-255c754a6216a86341e5f993cd22261b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"218\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https://pic4.zhimg.com/v2-255c754a6216a86341e5f993cd22261b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;720&#39; height=&#39;218&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"218\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"720\" data-original=\"https://pic4.zhimg.com/v2-255c754a6216a86341e5f993cd22261b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-255c754a6216a86341e5f993cd22261b_b.jpg\"/></figure><h2>十五、回顾</h2><ul><li>写出折扣期望回报 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Ctheta%29\" alt=\"\\eta(\\theta)\" eeimg=\"1\"/> 的增量形式：</li></ul><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cwidetilde%7B%5Cpi%7D%29%3D%5Ceta%28%5Cpi%29%2B%5Cmathbb%7BE%7D%7Bs_0%2Ca_0%2C%5Cldots+%5Csim+%5Cwidetilde%7B%5Cpi%7D%7D%5Cleft%5B+%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cgamma%5Et+A_%5Cpi%28s_t%2Ca_t%29+%5Cright%5D+\" alt=\"\\eta(\\widetilde{\\pi})=\\eta(\\pi)+\\mathbb{E}{s_0,a_0,\\ldots \\sim \\widetilde{\\pi}}\\left[ \\sum_{t=0}^{\\infty}\\gamma^t A_\\pi(s_t,a_t) \\right] \" eeimg=\"1\"/> </p><ul><li>写出 <img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Ctheta%29\" alt=\"\\eta(\\theta)\" eeimg=\"1\"/> 的local approximation： </li></ul><p><img src=\"https://www.zhihu.com/equation?tex=L_%5Cpi%28%5Cwidetilde%7B%5Cpi%7D%29%3D%5Ceta%28%5Cpi%29%2B++%5Csum_s++%5Crho_%7B%5Cpi%7D%28s%29+%5Csum_a+%5Cwidetilde%7B%5Cpi%7D%28a+%5Cmid+s%29+A_%5Cpi%28s%2Ca%29+\" alt=\"L_\\pi(\\widetilde{\\pi})=\\eta(\\pi)+  \\sum_s  \\rho_{\\pi}(s) \\sum_a \\widetilde{\\pi}(a \\mid s) A_\\pi(s,a) \" eeimg=\"1\"/> </p><ul><li>重要不等式： </li></ul><p><img src=\"https://www.zhihu.com/equation?tex=%5Ceta%28%5Cpi_%7Bnew%7D%29%5Cge+L_%7B%5Cpi_%7Bold%7D%7D%28%5Cpi_%7Bnew%7D%29-C%5Ccdot+D_%7BKL%7D%5E%7Bmax%7D%28%5Cpi_%7Bold%7D%2C%5Cpi_%7Bnew%7D%29+\" alt=\"\\eta(\\pi_{new})\\ge L_{\\pi_{old}}(\\pi_{new})-C\\cdot D_{KL}^{max}(\\pi_{old},\\pi_{new}) \" eeimg=\"1\"/> </p><p>其中 </p><p><img src=\"https://www.zhihu.com/equation?tex=C%3D%5Cfrac%7B4%5Cepsilon+%5Cgamma%7D%7B%281-%5Cgamma%29%5E2%7D+\" alt=\"C=\\frac{4\\epsilon \\gamma}{(1-\\gamma)^2} \" eeimg=\"1\"/> </p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-74c879ee8a99f6f789c9138d2cd01bab_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1051\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb\" width=\"1051\" data-original=\"https://pic4.zhimg.com/v2-74c879ee8a99f6f789c9138d2cd01bab_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1051&#39; height=&#39;414&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1051\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1051\" data-original=\"https://pic4.zhimg.com/v2-74c879ee8a99f6f789c9138d2cd01bab_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-74c879ee8a99f6f789c9138d2cd01bab_b.jpg\"/></figure><ul><li>找到目标函数： </li></ul><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%5Ctheta+%5Cleft%5B++L_%7B%5Ctheta_%7Bold%7D%7D%28%5Ctheta%29-C%5Ccdot+%5Cbar%7BD%7D_%7BKL%7D%28%5Ctheta_%7Bold%7D%5Cparallel+%5Ctheta%29%5Cright%5D\" alt=\"\\max_\\theta \\left[  L_{\\theta_{old}}(\\theta)-C\\cdot \\bar{D}_{KL}(\\theta_{old}\\parallel \\theta)\\right]\" eeimg=\"1\"/> </p><ul><li>近似为二次型： </li></ul><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%7B%5Ctheta%7Dg%28%5Ctheta-%5Ctheta_%7Bold%7D%29-%5Cfrac%7BC%7D%7B2%7D%28%5Ctheta-%5Ctheta_%7Bold%7D%29%5ETF%28%5Ctheta-%5Ctheta_%7Bold%7D%29+\" alt=\"\\max_{\\theta}g(\\theta-\\theta_{old})-\\frac{C}{2}(\\theta-\\theta_{old})^TF(\\theta-\\theta_{old}) \" eeimg=\"1\"/> </p><p>solution: </p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Ctheta-%5Ctheta_%7Bold%7D%3D%5Cfrac%7B1%7D%7BC%7DF%5E%7B-1%7D%7Bg%7D\" alt=\" \\theta-\\theta_{old}=\\frac{1}{C}F^{-1}{g}\" eeimg=\"1\"/> </p><ul><li>用共轭梯度法（Hessian Free）去计算 <img src=\"https://www.zhihu.com/equation?tex=F%5E%7B-1%7Dg\" alt=\"F^{-1}g\" eeimg=\"1\"/> </li></ul><h3>over!</h3><p class=\"ztext-empty-paragraph\"><br/></p><p>PS：很久以前读论文的时候写的，奈何要想把这么多公式搬到知乎文章上，真的太费劲了。但是在硬盘里放着也没啥用对吧。</p><p></p>", 
            "topic": [
                {
                    "tag": "强化学习 (Reinforcement Learning)", 
                    "tagLink": "https://api.zhihu.com/topics/20039099"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>补充下来源，绝大部分思路来自Joshua Achiam在Berkeley的DRL，Fall2017课程的guest lecture，Advanced Policy Gradient Methods；部分参考台大Hung-yi Lee的课件。</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "参考资料是原论文，和CS294刚出来的那个学期中Scholman所讲的那一节。图片来自原论文，CS294课件，以及我自己画的两张。思路的话我是按照原论文的顺序整理的。您说的两个并没有看到哦。", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }, 
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>赞~看来不少材料大同小异哇~</p><p></p>", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>\"期望是以概率为权重的加权和：\" 从这里开始的\\eta的几个期望展开式的后两个s_t都应该替换成s</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>这里的三个\\eta的表达式中，末尾关于a求和的两项，之所以是s_t，是因为这两项是关于a求和，此时s_t为已知条件，这是在前面对表达式P(s_t=s)关于s求和这一项中已经确定的。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }, 
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>你如果去对照schulman paper中的equation(2)就会发现真的是写错了，不能把随机变量s_t和待求和的变量s混为一谈</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>第三节“第一次近似”中有个疑问，既然说\\sum_{s} \\rho_{\\pi_{\\theta l d}}(s)=\\sum_{s} \\rho_{\\pi_{\\theta}}(s) 那么L_{\\pi_{\\theta_{\\text { old }}}}\\left(\\pi_{\\theta}\\right) 展开完不就直接跟\\eta\\left(\\pi_{\\theta}\\right)相等了么，那这样还要什么近似不直接就等了？</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "Ja1r0", 
                    "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                    "content": "<p>对评论里的第一个式子，文章中说的是当仍按照旧策略去采样的时候，等号两边才相等。所做的近似就是忽略“折扣状态转移概率”也就是\\rho，因策略更新而产生的变化。</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>文章中说按照旧策略采样于是有了第一次近似这个我理解，就是按照旧策略把\\eta(\\tilde(\\pi))近似成了L_\\pi(\\tilde{\\pi})。文中equation（4）讲的是这个近似是一阶近似，我不理解的是(4)是怎么推导出来的。我并没有看到paper中哪里有对(4)说到梯度相等是因为“仍按照旧策略去采样”，按这么个推导方法L_\\pi(\\tilde{\\pi})不就又直接变成了\\eta(\\tilde(\\pi))。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }, 
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>已经搞清了，利用policy gradient theorem 的结论可以得到。<a href=\"http://link.zhihu.com/?target=http%3A//rll.berkeley.edu/deeprlcourse/docs/lec5.pdf\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">rll.berkeley.edu/deeprl</span><span class=\"invisible\">course/docs/lec5.pdf</span><span class=\"ellipsis\"></span></a> page 4</p>", 
                            "likes": 1, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }, 
                {
                    "userName": "马星宇", 
                    "userLink": "https://www.zhihu.com/people/7f46fb62bf92cc4e2637fe4754df8b5c", 
                    "content": "请问，那个重要不等式是？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "就是“重要不等式”几个字下面的那个不等式啊😂", 
                            "likes": 0, 
                            "replyToAuthor": "马星宇"
                        }, 
                        {
                            "userName": "马星宇", 
                            "userLink": "https://www.zhihu.com/people/7f46fb62bf92cc4e2637fe4754df8b5c", 
                            "content": "谢谢", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }, 
                {
                    "userName": "诛仙", 
                    "userLink": "https://www.zhihu.com/people/84f9758276f2436bf6fd0a33db1c8c07", 
                    "content": "很多公式都写的有问题", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>请问哪些公式有问题呢？</p>", 
                            "likes": 0, 
                            "replyToAuthor": "诛仙"
                        }
                    ]
                }, 
                {
                    "userName": "潘曙", 
                    "userLink": "https://www.zhihu.com/people/ee5f36e976f1804523213227dca87137", 
                    "content": "<p>So much abuse of notations, it's not about you but Dr. Schulman.</p><p>Hopefully we all get the insights here.</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/60221396", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 2, 
            "title": "读取TFRecords注意事项", 
            "content": "<h2>读取TFRecords注意事项</h2><p>这里主要关注函数<code>tf.data.Dataset.shuffle(buffer_size)</code>。针对这个函数，做两点说明。一个是关于参数<code>buffer_size</code>的取值；一个是该函数与<code>tf.data.Dataset.batch()</code>的先后次序问题。</p><h2>buffer_size的取值</h2><p>先来看<code>tf.data.Dataset.shuffle(buffer_size)</code>的工作过程：</p><ol><li>在所有样本中按次序取前<code>buffer_size</code>个样本放入buffer中。</li></ol><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c2056b92c5a1738ae29e6392f5280bf9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"367\" data-rawheight=\"344\" class=\"content_image\" width=\"367\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;367&#39; height=&#39;344&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"367\" data-rawheight=\"344\" class=\"content_image lazy\" width=\"367\" data-actualsrc=\"https://pic2.zhimg.com/v2-c2056b92c5a1738ae29e6392f5280bf9_b.jpg\"/></figure><p>2. 当读取数据时，每次从buffer中随机取出一个样本。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c858e51722ae49f2b81373d53f3aebde_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"591\" data-rawheight=\"340\" class=\"origin_image zh-lightbox-thumb\" width=\"591\" data-original=\"https://pic3.zhimg.com/v2-c858e51722ae49f2b81373d53f3aebde_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;591&#39; height=&#39;340&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"591\" data-rawheight=\"340\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"591\" data-original=\"https://pic3.zhimg.com/v2-c858e51722ae49f2b81373d53f3aebde_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c858e51722ae49f2b81373d53f3aebde_b.jpg\"/></figure><p>3. 当buffer中取走数据后，会从所有样本中再按次序取下一个样本放入buffer。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e080f853484e0b8d456247177dc5eae3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"351\" data-rawheight=\"337\" class=\"content_image\" width=\"351\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;351&#39; height=&#39;337&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"351\" data-rawheight=\"337\" class=\"content_image lazy\" width=\"351\" data-actualsrc=\"https://pic4.zhimg.com/v2-e080f853484e0b8d456247177dc5eae3_b.jpg\"/></figure><p>这一函数的作用就是避免一次性将整个数据集读入内存，但又能有随机性的取样本。读入内存的为<code>buffer_size</code>个样本，且在buffer中取样本为随机的。<code>buffer_size</code>和数据集样本总数的相对大小，将会影响取样本的过程对整个数据集而言的随机性。</p><ul><li> buffer_size &gt;= 样本总数。那么此时整个数据集都会被放进buffer里，取样本时，对于整个数据集来说就是完全随机的。每个样本被选到的概率符合均匀分布。<br/> </li><li> buffer_size == 1。这相当于依次取样本，并没有随机性。<br/> </li></ul><p>以上是两种极端情况。那么其实还是没有回答应该如何取一个中间值，既避免因数据集过大而导致占用内存过多，又可以使样本的选取具有一定随机性。这种值的选取应该是要结合具体任务的。总之，要尽量保证一个<code>batch</code>的样本中，各类别样本数尽量平均。比如做猫和狗的图片分类，<code>batchsize = 32</code>，那么这其中大致应有16张猫的图片和16张狗的图片。<a href=\"https://link.zhihu.com/?target=https%3A//user-gold-cdn.xitu.io/2018/8/28/16580f396628e48b\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">参考链接</a>.</p><h2>Dataset.shuffle与Dataset.batch的顺序</h2><p>除了<code>tf.data.Dataset.shuffle(buffer_size)</code>还有一个函数叫<code>tf.data.Dataset.batch(batch_size)</code>。这两个都是对数据集的一种操作。结论是<code>shuffle</code>应该在<code>batch</code>前面。因为如果先执行<code>tf.data.Dataset.batch()</code>，会在原数据集中，依次将每<code>batch_size</code>个样本作为一个整体输出。那么如果在此之前数据集并没有很好的打乱的话，按顺序把样本组合起来的话，可能会有<code>batch</code>中 样本类别分布不均匀的情况。以<a href=\"https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/50437234/tensorflow-dataset-shuffle-then-batch-or-batch-then-shuffle\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">参考链接</a>中的例子为例：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">enable_eager_execution</span><span class=\"p\">()</span>  <span class=\"c1\"># To simplify the example code.</span>\n\n<span class=\"c1\"># Batch before shuffle.</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">])</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">shuffle</span><span class=\"p\">(</span><span class=\"mi\">9</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">elem</span> <span class=\"ow\">in</span> <span class=\"n\">dataset</span><span class=\"p\">:</span>\n  <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">elem</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Prints:</span>\n<span class=\"c1\"># tf.Tensor([1 1 1], shape=(3,), dtype=int32)</span>\n<span class=\"c1\"># tf.Tensor([2 2 2], shape=(3,), dtype=int32)</span>\n<span class=\"c1\"># tf.Tensor([0 0 0], shape=(3,), dtype=int32)</span>\n\n<span class=\"c1\"># Shuffle before batch.</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">])</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">shuffle</span><span class=\"p\">(</span><span class=\"mi\">9</span><span class=\"p\">)</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">elem</span> <span class=\"ow\">in</span> <span class=\"n\">dataset</span><span class=\"p\">:</span>\n  <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">elem</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Prints:</span>\n<span class=\"c1\"># tf.Tensor([2 0 2], shape=(3,), dtype=int32)</span>\n<span class=\"c1\"># tf.Tensor([2 1 0], shape=(3,), dtype=int32)</span>\n<span class=\"c1\"># tf.Tensor([0 1 1], shape=(3,), dtype=int32)</span></code></pre></div><p></p>", 
            "topic": [
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/35179635", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 9, 
            "title": "分层强化学习论文阅读", 
            "content": "<p>论文：<a href=\"https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/6233-hierarchical-deep-reinforcement-learning-integrating-temporal-abstraction-and-intrinsic-motivation.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">链接</a></p><p>作者：<a href=\"https://link.zhihu.com/?target=https%3A//tejasdkulkarni.github.io/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">链接</a></p><h2><b>文章结构</b></h2><ol><li>提出问题：强化学习智能体对环境不充分的探索（insufficient exploration）</li><li>解决方式：hierarchical-DQN</li><li>实验验证：stochastic decision process；ATARI game &#34;Montezuma&#39;s Revenge&#34;</li></ol><h2><b>问题描述</b></h2><ul><li>反馈的稀疏性</li><li>状态的复杂性</li></ul><p>很多状态出现的概率很小，需要大量的尝试才可能出现，而样本的数量对于训练的效果又是很重要的。于是这篇论文的想法就是，人工鼓励智能体去到达一些状态，从而建立状态间的正确联系，构建起可以解决问题的“决策树”。以一种Atari游戏为例子说明问题：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-3f2c9260dbc7dfc7496e4a8be4a07bad_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"333\" data-rawheight=\"416\" class=\"content_image\" width=\"333\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;333&#39; height=&#39;416&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"333\" data-rawheight=\"416\" class=\"content_image lazy\" width=\"333\" data-actualsrc=\"https://pic2.zhimg.com/v2-3f2c9260dbc7dfc7496e4a8be4a07bad_b.jpg\"/></figure><p>这个游戏的意思是，小人只有先拿到中间层的钥匙，才可以走出顶层的门。所以关键就是智能体能不能知道，在没钥匙的情况下，目标是找钥匙，在有钥匙的情况下，目标是找门。强化学习中的一个很难办的问题就是状态如何表示，虽然这可以说没涉及到算法的逻辑流程，但是对于算法的效果却是有极大影响的。我首先考虑到如果是用图像作为状态表示，能不能体现出是否拿到钥匙这个信息。我发现当小人拿到中层的钥匙的时候，画面顶端会出现一个钥匙，意为小人拿到了钥匙，且原来中层的钥匙也会消失。说明像素值信息还是包含了是否拿到钥匙的信息的。那么假设神经网络可以很好的利用起钥匙相关的像素输入值，也就能对是否拿到钥匙加以区分（实际上因为网络的目标值是两个动作价值分值，没有对钥匙的像素变化做直接的指示，所以我不认为这样训练出的网络真的可以区分出是否拿到钥匙）。论文中主要拿DQN来和自己的方法对比，DQN是用一个卷积网络来作为参数化的价值函数，毕竟图像作为输入的话，状态空间是巨大的。对卷积网络的更新是以价值迭代的结果作为目标值。所以每当得到非零的奖励值时，带来的较大的价值变化，会逐步扩散到临近状态的动作价值计算中去。而对于那些远离此状态的，需要通过漫长的过程，只有极小概率到达该状态的其他状态，则没法收到该奖励值变化信号。相反的，他们主要受离自己较近的奖励信号变化。在这个游戏中，取得钥匙的状态，和到达门口的状态之间，是很可能间隔了数量巨大的其他状态的。所以即使是卷积网络能区别出是否拿到了钥匙，也无法在钥匙状态与门状态之间顺利的传递奖励信号的变化。在我们眼里这两个状态“很近”，但DQN眼里它们十分的远。</p><h2><b>试验场景</b></h2><p>有两个实验场景：tabular case；一种Atari游戏</p><ul><li>随机性连续决策过程</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9e34a5b4f39d5fa26fe032808c3c604c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb\" width=\"678\" data-original=\"https://pic1.zhimg.com/v2-9e34a5b4f39d5fa26fe032808c3c604c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;678&#39; height=&#39;150&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"678\" data-original=\"https://pic1.zhimg.com/v2-9e34a5b4f39d5fa26fe032808c3c604c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-9e34a5b4f39d5fa26fe032808c3c604c_b.jpg\"/></figure><p>意思是 <img src=\"https://www.zhihu.com/equation?tex=S_1+\" alt=\"S_1 \" eeimg=\"1\"/> 是终止状态，到达此状态会得到一个奖励值，该奖励值的数值取决于到达 <img src=\"https://www.zhihu.com/equation?tex=S_1\" alt=\"S_1\" eeimg=\"1\"/> 之前是否到达过 <img src=\"https://www.zhihu.com/equation?tex=S_6\" alt=\"S_6\" eeimg=\"1\"/> 。若是则奖励值为1，若没到达过则奖励值为1/100.</p><ul><li>一种Atari游戏</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f8480a0a152da0997bf806367df50673_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"333\" data-rawheight=\"416\" class=\"content_image\" width=\"333\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;333&#39; height=&#39;416&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"333\" data-rawheight=\"416\" class=\"content_image lazy\" width=\"333\" data-actualsrc=\"https://pic4.zhimg.com/v2-f8480a0a152da0997bf806367df50673_b.jpg\"/></figure><h2><b>解决方式</b></h2><p>设定一个又一个的目标，鼓励智能体探索状态空间的每个角落。每个目标下，有自己独立的奖励机制，仅当到达目标位置时获得一个正的回报值。</p><p>对于tabular case：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9e34a5b4f39d5fa26fe032808c3c604c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb\" width=\"678\" data-original=\"https://pic1.zhimg.com/v2-9e34a5b4f39d5fa26fe032808c3c604c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;678&#39; height=&#39;150&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"678\" data-original=\"https://pic1.zhimg.com/v2-9e34a5b4f39d5fa26fe032808c3c604c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-9e34a5b4f39d5fa26fe032808c3c604c_b.jpg\"/></figure><p>在每一个状态，依据以下价值表格选择一个子目标goal：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-24e1a5c68b5eef7893cb290742b3419b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"277\" data-rawheight=\"264\" class=\"content_image\" width=\"277\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;277&#39; height=&#39;264&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"277\" data-rawheight=\"264\" class=\"content_image lazy\" width=\"277\" data-actualsrc=\"https://pic4.zhimg.com/v2-24e1a5c68b5eef7893cb290742b3419b_b.jpg\"/></figure><p>goal的集合就直接设为所有状态的集合。然后开始进行决策过程，直到到达当前目标位置，或到达中止状态 <img src=\"https://www.zhihu.com/equation?tex=S_1+\" alt=\"S_1 \" eeimg=\"1\"/> 。每个goal下，奖励机制将会改变，当且仅当到达该子目标状态时，会获得一个正的奖励值：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4e70ab2697a0b30d3884cc4e4e521a96_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1130\" data-rawheight=\"387\" class=\"origin_image zh-lightbox-thumb\" width=\"1130\" data-original=\"https://pic3.zhimg.com/v2-4e70ab2697a0b30d3884cc4e4e521a96_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1130&#39; height=&#39;387&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1130\" data-rawheight=\"387\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1130\" data-original=\"https://pic3.zhimg.com/v2-4e70ab2697a0b30d3884cc4e4e521a96_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4e70ab2697a0b30d3884cc4e4e521a96_b.jpg\"/></figure><p>goal的作用是，设定一个<b>新的奖励机制</b>，来通过强化学习鼓励智能体到达该目标状态。<b>每一个goal都对应着自己的一个<i>Q</i>(<i>s</i>,<i>a</i>)函数，这个函数最终对应的最优策略可以使得智能体到达goal状态</b>。 而如何选择goal，同样是对一个价值函数<i>Q</i>(<i>s</i>,<i>g</i>)进行价值迭代得到的。<b>只不过更新这个表格使用的奖励值<i>r</i>是从上一个goal到当前的goal之间所获得的累计回报,且奖励机制是原问题的</b>。于是将Q-Learning中的一个Q表格，变成了如今的5个子目标Q表，外加一个用来选择下一个子目标是什么的表格。通过这种方式，在 <img src=\"https://www.zhihu.com/equation?tex=S_1\" alt=\"S_1\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=S_6\" alt=\"S_6\" eeimg=\"1\"/> 之间建立起了一定的关系。</p><p>对那个Atari游戏来说，红色框表示这个位置是是要到达的一个子目标，论文中是人工标定的这些子目标，应该也用到了小人和画面中其他物体的位置信息。举几个子目标的例子：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-40d50e101506fc83c860ecb9ba62e620_b.jpg\" data-size=\"normal\" data-rawwidth=\"125\" data-rawheight=\"167\" class=\"content_image\" width=\"125\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;125&#39; height=&#39;167&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"125\" data-rawheight=\"167\" class=\"content_image lazy\" width=\"125\" data-actualsrc=\"https://pic1.zhimg.com/v2-40d50e101506fc83c860ecb9ba62e620_b.jpg\"/><figcaption>目标1</figcaption></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5e6d866ab20a443123abb5ec7bab6273_b.jpg\" data-size=\"normal\" data-rawwidth=\"126\" data-rawheight=\"164\" class=\"content_image\" width=\"126\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;126&#39; height=&#39;164&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"126\" data-rawheight=\"164\" class=\"content_image lazy\" width=\"126\" data-actualsrc=\"https://pic4.zhimg.com/v2-5e6d866ab20a443123abb5ec7bab6273_b.jpg\"/><figcaption>目标2</figcaption></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-835def5e73005555506933930fa0d288_b.jpg\" data-size=\"normal\" data-rawwidth=\"125\" data-rawheight=\"162\" class=\"content_image\" width=\"125\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;125&#39; height=&#39;162&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"125\" data-rawheight=\"162\" class=\"content_image lazy\" width=\"125\" data-actualsrc=\"https://pic1.zhimg.com/v2-835def5e73005555506933930fa0d288_b.jpg\"/><figcaption>目标3</figcaption></figure><p>tabular的情形下，这种方法倒感觉更普适一些，因为直接把所有状态作为目标集合了。而Atari游戏的话，是人框出了几个位置，那也就是说我故意把钥匙和门那里标出来，然后用一个做子目标选择的表格，来决定现在是去找钥匙还是去门那里。这也就像做游戏的时候，人物的寻路过程，本来从起点到终点有无数种可能的路径，只要避开障碍物，但现在给它标记了一系列点，人物要按着这一系列点来到达终点。也好比RTS游戏中对角色的控制。</p><h2><b>实验验证</b></h2><p>将本文方法与Q-Learning对比：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d0782a0acc0cb947523aa2f0613c32ce_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"804\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb\" width=\"804\" data-original=\"https://pic3.zhimg.com/v2-d0782a0acc0cb947523aa2f0613c32ce_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;804&#39; height=&#39;222&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"804\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"804\" data-original=\"https://pic3.zhimg.com/v2-d0782a0acc0cb947523aa2f0613c32ce_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d0782a0acc0cb947523aa2f0613c32ce_b.jpg\"/></figure><p>Q-Learning是不能解决这一问题的，本论文方法通过不断选择子目标，来指引智能体对状态空间进行广泛的探索，加强了中间关键状态与终止状态的联系。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-3638ca4eddfbff45382df3104aca3080_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"825\" data-rawheight=\"485\" class=\"origin_image zh-lightbox-thumb\" width=\"825\" data-original=\"https://pic1.zhimg.com/v2-3638ca4eddfbff45382df3104aca3080_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;825&#39; height=&#39;485&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"825\" data-rawheight=\"485\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"825\" data-original=\"https://pic1.zhimg.com/v2-3638ca4eddfbff45382df3104aca3080_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-3638ca4eddfbff45382df3104aca3080_b.jpg\"/></figure><h2>欢迎讨论！！</h2>", 
            "topic": [
                {
                    "tag": "强化学习 (Reinforcement Learning)", 
                    "tagLink": "https://api.zhihu.com/topics/20039099"
                }
            ], 
            "comments": [
                {
                    "userName": "卢卡斯", 
                    "userLink": "https://www.zhihu.com/people/15834de9d5e63d6b8edb279818c81742", 
                    "content": "你好，我想问一下这篇文章中的方法是假设目标任务中人为的划分了多个子目标，再进行学习的，当前是否有相关的方法可以做到自动的去发现。", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "这篇论文的future work里有说可以尝试用目标识别的方式去标定几个位置。然后像实验中的tabular的情况，就直接把所有可能状态作为子目标了", 
                            "likes": 0, 
                            "replyToAuthor": "卢卡斯"
                        }, 
                        {
                            "userName": "卢卡斯", 
                            "userLink": "https://www.zhihu.com/people/15834de9d5e63d6b8edb279818c81742", 
                            "content": "你有看过 Feudal Networks 这篇文章吗？我正在读这篇文章，他应该是可以做到自动发现目标的，就是现在的实验结果无法收敛。", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/32285354", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 4, 
            "title": "Reinforcement Learning:An Introduction-摘记-Capter2(2)", 
            "content": "<h2><b>上节回顾</b></h2><ul><li>如何制衡<b>探索</b>与<b>利用</b>，是多臂老虎机游戏以及之后所要介绍的强化学习中的核心问题。对这一问题的解决，在上一节主要提出了 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon-\" alt=\"\\varepsilon-\" eeimg=\"1\"/> 贪心策略， 即以一个小的概率 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon\" alt=\"\\varepsilon\" eeimg=\"1\"/> 进行探索，而在其余的大部分情况对现有知识进行利用。于是这种策略唯一的参数 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon\" alt=\"\\varepsilon\" eeimg=\"1\"/> 极大的影响着智能体最终的表现。</li><li>如何估计每一种选择的可能分值，是令一个关键问题。估计方式是否科学合理也深刻影响着智能体能否取得较高的分数。对这个问题，举出了一种老虎机游戏的非稳态情况，并对参数 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha\" alt=\"\\alpha\" eeimg=\"1\"/> 进行了调整与对比。</li></ul><p>这一节的内容为，</p><ol><li>首先列出一种不同于 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon-\" alt=\"\\varepsilon-\" eeimg=\"1\"/> 贪心策略的，平衡探索与利用的方式；</li><li>之后提出另一种估计每种选择好坏程度的方式，这种方式不同于对选项对应的分值的估计。</li></ol><h2><b>UCB方法</b></h2><p>对多臂老虎机的某一个臂而言，随着游戏者选择到它的次数的增大，对这个选项的分值的估计就越准确、越可信。我们对每一个选项的分值都有一个估计，然后设计一个用来描述这一估计的可信程度的函数，并依据这种可信程序，进行选择，这就是UCB方法所做的事情。对于那些所做估计可信程度较小的选项，有相对较大的概率选择到。这种选择是依照下式进行的：</p><p><img src=\"https://www.zhihu.com/equation?tex=A_t%5Cdoteq+arg%5Cmax_a%5Cleft%5BQ_t%28a%29%2Bc%5Csqrt%7B%5Cfrac%7Blogt%7D%7BN_t%28a%29%7D%7D%5Cright%5D\" alt=\"A_t\\doteq arg\\max_a\\left[Q_t(a)+c\\sqrt{\\frac{logt}{N_t(a)}}\\right]\" eeimg=\"1\"/> </p><p>上式各符号表示在第 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 次选择中——</p><ol><li><img src=\"https://www.zhihu.com/equation?tex=A_t%3A\" alt=\"A_t:\" eeimg=\"1\"/> 所选的选项</li><li><img src=\"https://www.zhihu.com/equation?tex=Q_t%28a%29%3A\" alt=\"Q_t(a):\" eeimg=\"1\"/> 对选项 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 的分值的估计</li><li><img src=\"https://www.zhihu.com/equation?tex=N_t%28a%29%3A\" alt=\"N_t(a):\" eeimg=\"1\"/> 历史中选项 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 被选到的总次数</li><li><img src=\"https://www.zhihu.com/equation?tex=c%3A\" alt=\"c:\" eeimg=\"1\"/> 一个大于零的参数</li></ol><p>规定当 <img src=\"https://www.zhihu.com/equation?tex=N_t%28a%29%3D0\" alt=\"N_t(a)=0\" eeimg=\"1\"/> 时，对应的选项 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 即为使中括号中的值最大的那个选项。式中：</p><ul><li><img src=\"https://www.zhihu.com/equation?tex=Q_t%28a%29\" alt=\"Q_t(a)\" eeimg=\"1\"/> 项对应着“利用”，有越大的估计值该项越大；</li><li><img src=\"https://www.zhihu.com/equation?tex=c%5Csqrt%7B%5Cfrac%7Blogt%7D%7BN_t%28a%29%7D%7D\" alt=\"c\\sqrt{\\frac{logt}{N_t(a)}}\" eeimg=\"1\"/> 项对应着“探索”，随着游戏的进行，选择到对应选项的次数越少该项越大，表示当前对这一选项的分值估计越不可靠。</li></ul><p>将两项加和，综合对两项的考虑，选出使其值最大的那个选项。完成了对“探索”与“利用”的制衡。</p><p>将UCB方法和之前的 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon-greedy\" alt=\"\\varepsilon-greedy\" eeimg=\"1\"/> 方法做一个比较：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7e8256f6c8fe269a2d89386131cb8b7e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-7e8256f6c8fe269a2d89386131cb8b7e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-7e8256f6c8fe269a2d89386131cb8b7e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-7e8256f6c8fe269a2d89386131cb8b7e_b.jpg\"/></figure><p>可见在这种情景下，UCB方法是优于 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon-\" alt=\"\\varepsilon-\" eeimg=\"1\"/> 贪心方法的。但具体UCB方法是不是合适，还要看具体情况，例如在非稳、较大状态空间等情况下该方法的使用就有一些问题。</p><h2><b>策略函数</b></h2><p>在之前的算法中，我们对每个选项的分值进行估计，并在游戏的过程中用采集到的样本不断修正这些估计值，依照估计值进行抉择。还有另一种不同于值估计的方式——依据“偏好”进行选择。</p><p>这种方式将每次选择看做一个随机变量，可能取到的值就是老虎机的十个选项，每个选项都有一个概率被选到，这一概率分布函数为：</p><p><img src=\"https://www.zhihu.com/equation?tex=Pr%5C%7BA_t%3Da%5C%7D%5Cdoteq+%5Cfrac%7Be%5E%7BH_t%28a%29%7D%7D%7B%5Csum_%7Bb%3D1%7D%5E%7Bk%7De%5E%7BH_t%28b%29%7D%7D%5Cdoteq+%5Cpi_t%28a%29\" alt=\"Pr\\{A_t=a\\}\\doteq \\frac{e^{H_t(a)}}{\\sum_{b=1}^{k}e^{H_t(b)}}\\doteq \\pi_t(a)\" eeimg=\"1\"/> </p><p>这可以称为一个“策略函数” <img src=\"https://www.zhihu.com/equation?tex=%5Cpi_t%28a%29\" alt=\"\\pi_t(a)\" eeimg=\"1\"/> ，它是一个“动作”的概率分布。这其中的 <img src=\"https://www.zhihu.com/equation?tex=H_t%28a%29\" alt=\"H_t(a)\" eeimg=\"1\"/> 称为对选项、或者说“动作” <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 的偏好。这个值越大，选择这一选项的概率越大。对这一策略函数的更新使用<b>随机梯度上升</b>方法。我们的目的是最大化</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmathbb%7BE%7D%5BR_t%5D%5Cdoteq%5Csum_%7Bb%3D1%7D%5E%7B10%7D%5Cpi_t%28b%29q_%2A%28b%29\" alt=\"\\mathbb{E}[R_t]\\doteq\\sum_{b=1}^{10}\\pi_t(b)q_*(b)\" eeimg=\"1\"/> </p><p>于是这一随机梯度上升计算公式为下式。进行一次选择会得到一个分值 <img src=\"https://www.zhihu.com/equation?tex=R_t\" alt=\"R_t\" eeimg=\"1\"/> ，之后依照下式进行更新。</p><p><img src=\"https://www.zhihu.com/equation?tex=H_%7Bt%2B1%7D%28A_t%29%5Cdoteq+H_t%28A_t%29%2B%5Calpha%5Cfrac%7B%5Cpartial%5Cmathbb%7BE%7D%5BR_t%5D%7D%7B%5Cpartial+H_t%28a%29%7D\" alt=\"H_{t+1}(A_t)\\doteq H_t(A_t)+\\alpha\\frac{\\partial\\mathbb{E}[R_t]}{\\partial H_t(a)}\" eeimg=\"1\"/> </p><p>经过推导，这一更新公式转换为：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Beqnarray%7D+H_%7Bt%2B1%7D%28A_t%29%26%5Cdoteq%26+H_t%28A_t%29%2B%5Calpha%28R_t-%5Cbar%7BR_t%7D%29%281-%5Cpi_t%28A_t%29%29+%2C%5C%5C+H_%7Bt%2B1%7D%28a%29%26%5Cdoteq%26+H_t%28a%29-%5Calpha%28R_t-%5Cbar%7BR_t%7D%29%5Cpi_t%28a%29+%2C%5Cqquad+for%5Cquad%5Cforall+a%5Cne+A_t+%5Cend%7Beqnarray%7D\" alt=\"\\begin{eqnarray} H_{t+1}(A_t)&amp;\\doteq&amp; H_t(A_t)+\\alpha(R_t-\\bar{R_t})(1-\\pi_t(A_t)) ,\\\\ H_{t+1}(a)&amp;\\doteq&amp; H_t(a)-\\alpha(R_t-\\bar{R_t})\\pi_t(a) ,\\qquad for\\quad\\forall a\\ne A_t \\end{eqnarray}\" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha%3E0\" alt=\"\\alpha&gt;0\" eeimg=\"1\"/> 为随机梯度上升的学习率。 <img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BR%7D_t%5Cin+%5Cmathbb%7BR%7D\" alt=\"\\bar{R}_t\\in \\mathbb{R}\" eeimg=\"1\"/> 是截止到当前第 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 次选择所获得的所有分值的平均值，它扮演着baseline的角色，如果本次选择获得的分值高于此前的平均得分，那么对这一选项的“偏好”增大，反之减小；除该选项的其余选项的“偏好”对应减小或增大。baseline的存在使得更新过程对分值 <img src=\"https://www.zhihu.com/equation?tex=R_t\" alt=\"R_t\" eeimg=\"1\"/> 的绝对值不敏感，而只关心 <img src=\"https://www.zhihu.com/equation?tex=R_t\" alt=\"R_t\" eeimg=\"1\"/> 之间的相对值。学习率与baseline深刻影响着这一算法的性能：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a3a2ad2584cfa0039066e9769beaf312_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"703\" data-rawheight=\"558\" class=\"origin_image zh-lightbox-thumb\" width=\"703\" data-original=\"https://pic3.zhimg.com/v2-a3a2ad2584cfa0039066e9769beaf312_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;703&#39; height=&#39;558&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"703\" data-rawheight=\"558\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"703\" data-original=\"https://pic3.zhimg.com/v2-a3a2ad2584cfa0039066e9769beaf312_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a3a2ad2584cfa0039066e9769beaf312_b.jpg\"/></figure><p>这一章围绕多臂老虎机问题展开，包含了稳态与非稳态两种情况。提出了探索与利用间的抉择这一关键问题，展示了分别基于分值估计函数与策略函数的两种方法。每种处理方式都有对应的一些重要参数。下一章将会向更一般的强化学习问题进发。</p>", 
            "topic": [
                {
                    "tag": "强化学习 (Reinforcement Learning)", 
                    "tagLink": "https://api.zhihu.com/topics/20039099"
                }
            ], 
            "comments": [
                {
                    "userName": "Caihh", 
                    "userLink": "https://www.zhihu.com/people/98fffee151dccf2fe06a908e97c15239", 
                    "content": "<p>在偏好计算的公式里面，baseline是所有行动的奖赏平均值吗？但是在程序里面，是对每一个行动分别计算平均值，然后考虑，当前行动的奖赏，和每个行动的平均奖赏比较，这是为什么呢？</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "这里所说的baseline是截止到当前第 t 次选择所获得的所有分值的平均值。强化学习的policy gradient方法中，对baseline有很多种处理方式，但是不管哪种设定方式，baseline全都是与动作无关的，这样baseline才不影响梯度表达式的期望值。", 
                            "likes": 0, 
                            "replyToAuthor": "Caihh"
                        }, 
                        {
                            "userName": "Caihh", 
                            "userLink": "https://www.zhihu.com/people/98fffee151dccf2fe06a908e97c15239", 
                            "content": "<p>感谢楼主回复。也就是说，在书中的实例中，是无论当前采取的哪一类行动，更新期望值时所用的baseline就是当前总奖赏除以总执行次数？话说 我编程的时候，baseline相当于对于不同行动不一样，分别是每个行动的奖赏平均值，然后算出来也是OK的。但是从公式的意义来说，是不太一样的了？</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/32062721", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 4, 
            "title": "Reinforcement Learning:An Introduction-摘记-Capter2(1)", 
            "content": "<p>本人开始阅读Richard S. Sutton的著作《Reinforcement Learning:An introduction》，觉得可以分享一点在知乎上。文章内容不详实翻译原书，而是记录我在读的过程中觉得印象深刻的一些要点，这样会更精简和便于记忆。</p><h2><b>多臂老虎机问题</b></h2><p>这一章都是围绕这样一个游戏展开的：</p><p>摆在你面前有十个选项，每个回合你需要选择其中一个，并会得到一个分值。第 <img src=\"https://www.zhihu.com/equation?tex=i\" alt=\"i\" eeimg=\"1\"/> 个选项的分值 <img src=\"https://www.zhihu.com/equation?tex=q%28i%29\" alt=\"q(i)\" eeimg=\"1\"/> 服从一个高斯分布 <img src=\"https://www.zhihu.com/equation?tex=q%28i%29%5Csim+N%28q_%2A%28i%29%2C1%29\" alt=\"q(i)\\sim N(q_*(i),1)\" eeimg=\"1\"/> ，其中 <img src=\"https://www.zhihu.com/equation?tex=q_%2A%28i%29\" alt=\"q_*(i)\" eeimg=\"1\"/> 表示其均值。且每个选项的均值也是服从高斯分布的 ，即<img src=\"https://www.zhihu.com/equation?tex=q_%2A%28i%29%5Csim+N%280%2C1%29\" alt=\"q_*(i)\\sim N(0,1)\" eeimg=\"1\"/> 。</p><p>你事先并不知道这些概率分布，也就是说不知道哪个选项更有可能获得高的分值，而你的目的就是在若干回合之后获得的分值最大。</p><p>十个选项的分值可以用琴形图来表示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-24ad17ad132fa9ae1ed3db4173c33de0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-24ad17ad132fa9ae1ed3db4173c33de0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-24ad17ad132fa9ae1ed3db4173c33de0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-24ad17ad132fa9ae1ed3db4173c33de0_b.jpg\"/></figure><h2><b>探索与利用</b></h2><p>那么怎样在这个游戏中有较好的表现呢？我们已经知道每个选项的分值都服从一个概率分布，如果我们在游戏前有足够多尝试的机会，就可以用采样的方式，对每个选项都采样足够多的次数，然后就可以估计出每个概率分布，这样一来问题就极其简单了。但是我们并没有这种预先采样的机会，而是要在游戏进行的过程中进行尝试。可以想见如果不在乎开始阶段的表现，而只管不断尝试每个选项的话，终将估计出每个分布。</p><p>我们面临着这样一个选择：</p><ul><li>一方面要利用已有的经验去选择目前看起来不错的选项，来得到尽可能大的分值；</li><li>另一方面因为你的经验还不充足，你对每个选项的估计是不准确的，需要再去尝试其他选项，来修正当前的估计。</li></ul><h2><b>分值函数</b></h2><p>我们把对选项的分值估计记为 <img src=\"https://www.zhihu.com/equation?tex=Q_t%28a%29\" alt=\"Q_t(a)\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 指示选择哪一个选项。在第 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 个回合：</p><p><img src=\"https://www.zhihu.com/equation?tex=Q_t%28a%29%3D%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5E%7Bt-1%7DR_i+%5Ccdot+1_%7BA_i%3Da%7D%7D%7B%5Csum_%7Bi%3D1%7D%5E%7Bt-1%7D+1_%7BA_i%3Da%7D%7D\" alt=\"Q_t(a)=\\frac{\\sum_{i=1}^{t-1}R_i \\cdot 1_{A_i=a}}{\\sum_{i=1}^{t-1} 1_{A_i=a}}\" eeimg=\"1\"/> </p><p>即对选项 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> ，把从 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 获得的历史分值求平均，作为我们对 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 的分值估计。</p><h2><img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon\" alt=\"\\varepsilon\" eeimg=\"1\"/> -<b>贪心策略</b></h2><p><b>利用</b></p><p>从利用的角度来讲，就是选择使得 <img src=\"https://www.zhihu.com/equation?tex=Q_%7Bt%7D%28a%29\" alt=\"Q_{t}(a)\" eeimg=\"1\"/> 最大的那个选项 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> ，作为第 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 个回合做出的选择 <img src=\"https://www.zhihu.com/equation?tex=A_t\" alt=\"A_t\" eeimg=\"1\"/> ，即： <img src=\"https://www.zhihu.com/equation?tex=A_t+%5Cdoteq+arg%5Cmax_a+Q_t%28a%29\" alt=\"A_t \\doteq arg\\max_a Q_t(a)\" eeimg=\"1\"/> </p><p><b>探索</b></p><p>我们还要以一定的概率 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon\" alt=\"\\varepsilon\" eeimg=\"1\"/> 随机选择一个选项，来进行探索。这种对探索与利用进行权衡的方式成为 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon-greedy\" alt=\"\\varepsilon-greedy\" eeimg=\"1\"/> 策略。</p><p>我们来看看这种策略的表现如何。有三个被试者，它们分别依据以下三个策略进行游戏：</p><ol><li><img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon%3D0\" alt=\"\\varepsilon=0\" eeimg=\"1\"/> ，这意味着这个被试不去进行探索</li><li><img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon%3D0.1\" alt=\"\\varepsilon=0.1\" eeimg=\"1\"/> </li><li><img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon%3D0.01\" alt=\"\\varepsilon=0.01\" eeimg=\"1\"/> </li></ol><p>有2000台老虎机，在每台老虎机上三个被试进行1000轮游戏。对每个被试，在2000台老虎机上的表现做平均，得到了下图。第二张图意思是在每一轮游戏，在这2000台老虎机中，选中了真实的最优选项的占多大比例。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-2c0c448e7f458fa5729858b0347a3e37_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-2c0c448e7f458fa5729858b0347a3e37_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-2c0c448e7f458fa5729858b0347a3e37_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-2c0c448e7f458fa5729858b0347a3e37_b.jpg\"/></figure><p>可以看到，</p><ul><li><img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon%3D0\" alt=\"\\varepsilon=0\" eeimg=\"1\"/> ：完全的贪心策略每次只挑选它目前所认为的最大值选项，而失去了发现更好的选项的机会。在长期看来，它的选择稳定在次优选项上。下图则直接表示了只有30%多的这种智能体可以发现最优选项，换句话说它有30%多的可能性发现最优选项。</li><li><img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon%3D0.01\" alt=\"\\varepsilon=0.01\" eeimg=\"1\"/> ：这种智能体会以一定的概率去随机选择一个选项，经过的回合较多之后，它有更大的概率能够发现最优选项。</li><li><img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon%3D0.1+\" alt=\"\\varepsilon=0.1 \" eeimg=\"1\"/> ：同样是以一定概率进行探索，但相较于上一个智能体，这个探索概率显然有点过大了，即使当它发现了真实的最优策略，它仍以一个相对大的概率去盲目探索，从而使表现差于上一个智能体。</li></ul><p>应该注意到的是，如何选择 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon\" alt=\"\\varepsilon\" eeimg=\"1\"/> ，包括 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon%3D0\" alt=\"\\varepsilon=0\" eeimg=\"1\"/> ，是取决于任务本身的。当每个选项分值的方差为0，那么只要采样到一次这个选项，就已经知道了它的具体分值，这种情况就不需要大量的采样去估计每一个选项服从的分布。总之，如何平衡探索与利用是对智能体的表现有极大影响的，且和具体的任务有很大关系的一个核心问题。</p><h2><b>非稳态情况</b></h2><p>之前每个选项的均值是固定的</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"k\">class</span> <span class=\"nc\">env</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">arms_num</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"n\">bandit_arm</span> <span class=\"o\">=</span> <span class=\"n\">namedtuple</span><span class=\"p\">(</span><span class=\"s1\">&#39;bandit_arm&#39;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">&#39;mean&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;std&#39;</span><span class=\"p\">])</span>\n        <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">arms_num</span><span class=\"p\">):</span>\n            <span class=\"n\">arm</span> <span class=\"o\">=</span> <span class=\"n\">bandit_arm</span><span class=\"p\">(</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">gauss</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\"># 分布的均值在初始化时固定了</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">arm</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">optimal_arm_idx</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">(</span><span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span><span class=\"p\">))</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">reset</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">pass</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">arm_idx</span><span class=\"p\">):</span>\n        <span class=\"n\">arm</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span><span class=\"p\">[</span><span class=\"n\">arm_idx</span><span class=\"p\">]</span>\n        <span class=\"n\">reward</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">gauss</span><span class=\"p\">(</span><span class=\"n\">arm</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">,</span> <span class=\"n\">arm</span><span class=\"o\">.</span><span class=\"n\">std</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">reward</span>\n</code></pre></div><p>而更一般的情况是，这个均值随着时间的推移会有一些小小的变化。当 <img src=\"https://www.zhihu.com/equation?tex=Q%28a%29\" alt=\"Q(a)\" eeimg=\"1\"/> 所服从的分布随时间改变时，该问题称为非稳态的。这种时候，之前通过求平均来计算分值的方式就不那么合理了。</p><p>上面提到的求平均来计算分值的方式是很自然的，并且可以很容易的改写成增量式，从而不需要每次计算都记录所有的采样过的分值。对某一个选项的分值估计可以这样计算：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cbegin%7Beqnarray%7D+Q_%7Bk%2B1%7D+%26%3D%26+%5Cfrac%7B1%7D%7Bk%7D%5Csum_%7Bi%3D1%7D%5Ek+R_i+%5C%5C+%26+%3D+%26+%5Cfrac%7B1%7D%7Bk%7D%28R_%7Bk%7D%2B%5Csum_%7Bi%3D1%7D%5E%7Bk-1%7DR_i+%29+%5C%5C+%26%3D%26+%5Cfrac%7B1%7D%7Bk%7D+%28R_k+%2B+%28k-1%29Q_k+%29+%5C%5C+%26%3D%26+%5Cfrac%7B1%7D%7Bk%7D+%28R_k%2BkQ_k+-Q_k%29+%5C%5C+%26%3D%26+Q_k%2B%5Cfrac%7B1%7D%7Bk%7D%28R_k-Q_k%29+%5Cend%7Beqnarray%7D+\" alt=\"\\begin{eqnarray} Q_{k+1} &amp;=&amp; \\frac{1}{k}\\sum_{i=1}^k R_i \\\\ &amp; = &amp; \\frac{1}{k}(R_{k}+\\sum_{i=1}^{k-1}R_i ) \\\\ &amp;=&amp; \\frac{1}{k} (R_k + (k-1)Q_k ) \\\\ &amp;=&amp; \\frac{1}{k} (R_k+kQ_k -Q_k) \\\\ &amp;=&amp; Q_k+\\frac{1}{k}(R_k-Q_k) \\end{eqnarray} \" eeimg=\"1\"/> </p><p>令 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7Bk%7D%3D%5Calpha\" alt=\"\\frac{1}{k}=\\alpha\" eeimg=\"1\"/> ，通过对时间序列 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha\" alt=\"\\alpha\" eeimg=\"1\"/> 进行一些设计来使对分值的估计更符合非稳态的情况。比如将 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha\" alt=\"\\alpha\" eeimg=\"1\"/> 设置为一个固定值。那么 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha\" alt=\"\\alpha\" eeimg=\"1\"/> 的取值是如何适应非稳态情况的呢？可以不断的将 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 的增量表达式代入等号右边。最终得到：</p><p><img src=\"https://www.zhihu.com/equation?tex=Q_k%3D%281-%5Calpha%29%5EkQ_1%2B%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Calpha%281-%5Calpha%29%5E%7Bk-i%7DR_i\" alt=\"Q_k=(1-\\alpha)^kQ_1+\\sum_{i=1}^{k}\\alpha(1-\\alpha)^{k-i}R_i\" eeimg=\"1\"/> </p><p>当 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha\" alt=\"\\alpha\" eeimg=\"1\"/> 为一个常数，且 <img src=\"https://www.zhihu.com/equation?tex=0%3C%5Calpha%5Cle1\" alt=\"0&lt;\\alpha\\le1\" eeimg=\"1\"/> 时，可以看到对于早先获得的 <img src=\"https://www.zhihu.com/equation?tex=R_i\" alt=\"R_i\" eeimg=\"1\"/>，其系数 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha%281-%5Calpha%29%5E%7Bk-i%7D\" alt=\"\\alpha(1-\\alpha)^{k-i}\" eeimg=\"1\"/> 会是一个相对很小的数值。目的就是更关心最近获得的信息，而遗忘掉过早的信息，因为情况是在改变的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c501aa383fcd7575ba31ad3b4caaa03c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-c501aa383fcd7575ba31ad3b4caaa03c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-c501aa383fcd7575ba31ad3b4caaa03c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c501aa383fcd7575ba31ad3b4caaa03c_b.jpg\"/></figure><p>在给选项的均值加上一个random walk之后，对比之前求均值的方式与将 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha\" alt=\"\\alpha\" eeimg=\"1\"/> 设置为固定值的方式。所谓random walk就是在原来的数值上加上一个随机变量：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"k\">class</span> <span class=\"nc\">bandit</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">arm_num</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">arm_num</span><span class=\"p\">):</span>\n            <span class=\"n\">arm</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">&#39;mean&#39;</span><span class=\"p\">:</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">gauss</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"s1\">&#39;std&#39;</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">}</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">arm</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">reset</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"n\">random_walk_std</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span><span class=\"p\">)):</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"s1\">&#39;mean&#39;</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">gauss</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">random_walk_std</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">arm_idx</span><span class=\"p\">):</span>\n        <span class=\"n\">mean</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span><span class=\"p\">[</span><span class=\"n\">arm_idx</span><span class=\"p\">][</span><span class=\"s1\">&#39;mean&#39;</span><span class=\"p\">]</span>\n        <span class=\"n\">std</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">arms</span><span class=\"p\">[</span><span class=\"n\">arm_idx</span><span class=\"p\">][</span><span class=\"s1\">&#39;std&#39;</span><span class=\"p\">]</span>\n        <span class=\"n\">reward</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">gauss</span><span class=\"p\">(</span><span class=\"n\">mean</span><span class=\"p\">,</span> <span class=\"n\">std</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">reward</span></code></pre></div><h2><b>初始分值的设置</b></h2><p>这里是想指出，通过对初始 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 值的设置，也是可以影响智能体的探索与利用的。之前对智能体进行初始化时，对所有选项的 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 都设置为0。而如果将 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 值设置为一个大于真实的 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 的期望值时，智能体会在初期进行大量的探索，从而对各个选项有个更好的估计。比如将所有的 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 初始化为5，那么没选到一个选项，所获得的分值基本都是比5小的，于是依据贪心策略，智能体就会选择其他 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 仍为初始值5的选项。这样就相当于鼓励了初期的探索。将这种设置与之前的 <img src=\"https://www.zhihu.com/equation?tex=%5Cvarepsilon%3D0.1\" alt=\"\\varepsilon=0.1\" eeimg=\"1\"/> 的情况做个对比：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6a762fa0db9415bda8a605ea79a2da76_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-6a762fa0db9415bda8a605ea79a2da76_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-6a762fa0db9415bda8a605ea79a2da76_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-6a762fa0db9415bda8a605ea79a2da76_b.jpg\"/></figure><p>但在非稳态的情况，由于初期的 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 值所占比重太大，效果并不好：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-ddfa743d8ecd6ebdf86825f86090f198_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-ddfa743d8ecd6ebdf86825f86090f198_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-ddfa743d8ecd6ebdf86825f86090f198_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-ddfa743d8ecd6ebdf86825f86090f198_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "强化学习 (Reinforcement Learning)", 
                    "tagLink": "https://api.zhihu.com/topics/20039099"
                }
            ], 
            "comments": [
                {
                    "userName": "Caihh", 
                    "userLink": "https://www.zhihu.com/people/98fffee151dccf2fe06a908e97c15239", 
                    "content": "<p>首先感谢楼主分享。还有个问题，为什么要2000台老虎机，取平均值呢？我用1台算的话，就不会收敛，为什么呢？</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>原来有人看的啊，哈哈。因为每个臂的回报分值，是来自一个分布的，而且玩家的行为也有一定的探索概率。所以同一个玩家，在同一个老虎机上，每次重新开始游戏，都会有不同的表现。只有进行多次游戏求平均，才可以体现出平均表现怎么样</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Caihh"
                        }
                    ]
                }, 
                {
                    "userName": "Gjh", 
                    "userLink": "https://www.zhihu.com/people/99bfe310ee1c2664ff0a77e68e0511e3", 
                    "content": "文中琴形图是用什么软件画的？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>都是matplotlab</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Gjh"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/29946059", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 9, 
            "title": "用PyTorch构建卷积神经网络", 
            "content": "<p>在pytorch中神经网络的构建是通过torch.nn工具</p><p>上一章介绍了autograd，而nn正是基于autograd来定义模型并求取其中的各种梯度。</p><ul><li>nn.Module定义了网络的每一层</li><li>forward(input) 则用来计算网络的输出</li></ul><p>举一个例子，来看这样一个用来识别手写体数字的网络（图片来自<a href=\"https://link.zhihu.com/?target=http%3A//pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html%23\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">官方文档</a>）：</p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-4ff4210b3d88e36f44d1c3b76478e934_b.jpg\" data-caption=\"\" data-rawwidth=\"660\" data-rawheight=\"214\" class=\"origin_image zh-lightbox-thumb\" width=\"660\" data-original=\"https://pic1.zhimg.com/v2-4ff4210b3d88e36f44d1c3b76478e934_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;660&#39; height=&#39;214&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"660\" data-rawheight=\"214\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"660\" data-original=\"https://pic1.zhimg.com/v2-4ff4210b3d88e36f44d1c3b76478e934_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-4ff4210b3d88e36f44d1c3b76478e934_b.jpg\"/></figure><p>一个典型的训练神经网络的步骤是：</p><ul><li>定义一个包含一组待学习的参数的神经网络</li><li>将数据输入到神经网络中并进行前向传播</li><li>根据损失函数计算输出结果与目标值之间的差距</li><li>进行梯度反向传播到各个参数</li><li>更新网络参数，典型的更新方式是：weight=weight-learning_rate*gradinet</li></ul><h2><b>Define the network</b></h2><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.autograd</span> <span class=\"kn\">import</span> <span class=\"n\">Variable</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"kn\">as</span> <span class=\"nn\">nn</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn.functional</span> <span class=\"kn\">as</span> <span class=\"nn\">F</span>\n<span class=\"k\">class</span> <span class=\"nc\">Net</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"c1\">#使用super()方法调用基类的构造器，即nn.Module.__init__(self)</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">Net</span><span class=\"p\">,</span><span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"c1\"># 1 input image channel ,6 output channels,5x5 square convolution kernel</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"o\">=</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n        <span class=\"c1\"># 6 input channl,16 output channels,5x5 square convolution kernel</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span><span class=\"o\">=</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">16</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n        <span class=\"c1\"># an affine operation:y=Wx+b</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span><span class=\"o\">=</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"o\">*</span><span class=\"mi\">5</span><span class=\"o\">*</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">120</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span><span class=\"o\">=</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">120</span><span class=\"p\">,</span><span class=\"mi\">84</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc3</span><span class=\"o\">=</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">84</span><span class=\"p\">,</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"c1\"># x是网络的输入，然后将x前向传播，最后得到输出</span>\n        <span class=\"c1\"># 下面两句定义了两个2x2的池化层</span>\n        <span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">max_pool2d</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)),(</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n        <span class=\"c1\"># if the size is square you can only specify a single number</span>\n        <span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">max_pool2d</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)),</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">num_flat_features</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc3</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">x</span>\n    <span class=\"k\">def</span> <span class=\"nf\">num_flat_features</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">()[</span><span class=\"mi\">1</span><span class=\"p\">:]</span> <span class=\"c1\"># all dimensions except the batch dimension</span>\n        <span class=\"n\">num_features</span><span class=\"o\">=</span><span class=\"mi\">1</span>\n        <span class=\"k\">for</span> <span class=\"n\">s</span> <span class=\"ow\">in</span> <span class=\"n\">size</span><span class=\"p\">:</span>\n            <span class=\"n\">num_features</span><span class=\"o\">*=</span><span class=\"n\">s</span>\n        <span class=\"k\">return</span> <span class=\"n\">num_features</span>\n<span class=\"n\">net</span><span class=\"o\">=</span><span class=\"n\">Net</span><span class=\"p\">()</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic3.zhimg.com/v2-1861306a580a61e0f9cbcff093621df2_b.jpg\" data-caption=\"\" data-rawwidth=\"572\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb\" width=\"572\" data-original=\"https://pic3.zhimg.com/v2-1861306a580a61e0f9cbcff093621df2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;572&#39; height=&#39;128&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"572\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"572\" data-original=\"https://pic3.zhimg.com/v2-1861306a580a61e0f9cbcff093621df2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-1861306a580a61e0f9cbcff093621df2_b.jpg\"/></figure><p>以上是定义了一个网络，并且定义了值的前向传播过程。在前向传播的过程中，可以进行各种Tensor可以进行的运算。而在梯度反向传播的时候，要用到上章介绍的autograd</p><h2><b>卷积运算</b></h2><p>这是卷积核矩阵和输入矩阵中的感受野矩阵之间做内积，也就是两个向量之间的内积，如两个n维向量a和b的内积为：</p><p><img src=\"https://www.zhihu.com/equation?tex=a%5Ccdot+b%3D%5Csum%5En_%7Bi%3D1%7Da_ib_i%3Da_1b_1%2Ba_2b_2%2B%5Ccdots%2Ba_nb_n\" alt=\"a\\cdot b=\\sum^n_{i=1}a_ib_i=a_1b_1+a_2b_2+\\cdots+a_nb_n\" eeimg=\"1\"/> </p><p>那么torch.nn.Conv2d()是怎么运算的呢，先来看它有哪些参数(把这些参数的作用都搞清楚，就基本弄清了卷积层的具体工作方式)：</p><ul><li><b>in_channels</b> (int) – Number of channels in the input image</li><li><b>out_channels</b> (int) – Number of channels produced by the convolution</li><li><b>kernel_size</b> (int or tuple) – Size of the convolving kernel</li><li><b>stride</b> (int or tuple, optional) – Stride of the convolution. Default: 1</li><li><b>padding</b> (int or tuple, optional) – Zero-padding added to both sides of the input. Default: 0</li><li><b>dilation</b> (int or tuple, optional) – Spacing between kernel elements. Default: 1</li><li><b>groups</b> (int, optional) – Number of blocked connections from input channels to output channels. Default: 1</li><li><b>bias</b> (bool, optional) – If True, adds a learnable bias to the output. Default: True</li></ul><p>有关torch.nn的详细文档请看<a href=\"https://link.zhihu.com/?target=http%3A//pytorch.org/docs/master/nn.html%23conv2d\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这里</a></p><p>网络的输入用四元组 <img src=\"https://www.zhihu.com/equation?tex=%28N%2CC_%7Bin%7D%2CH%2CW%29\" alt=\"(N,C_{in},H,W)\" eeimg=\"1\"/> 来表示，输出表示为 <img src=\"https://www.zhihu.com/equation?tex=%28N%2CC_%7Bout%7D%2CH_%7Bout%7D%2CW_%7Bout%7D%29\" alt=\"(N,C_{out},H_{out},W_{out})\" eeimg=\"1\"/> 。其中：</p><ul><li><img src=\"https://www.zhihu.com/equation?tex=H\" alt=\"H\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=W\" alt=\"W\" eeimg=\"1\"/> 分别表示矩阵的高和宽</li><li><img src=\"https://www.zhihu.com/equation?tex=N\" alt=\"N\" eeimg=\"1\"/> 表示数据的batch dimension，就是批处理数据一批有多少个</li><li><img src=\"https://www.zhihu.com/equation?tex=C_%7Bin%7D\" alt=\"C_{in}\" eeimg=\"1\"/> 表示输入数据的通道数in_channels，按上图中可以理解为输入该层的有几个矩阵</li><li><img src=\"https://www.zhihu.com/equation?tex=C_%7Bout%7D\" alt=\"C_{out}\" eeimg=\"1\"/> 表示输出数据的通道数out_channels，可理解为该层输出的有多少个矩阵</li></ul><p>卷积层的输出满足这样的表达式：</p><p><img src=\"https://www.zhihu.com/equation?tex=out%28N_i%2CC_%7Bout_j%7D%29%3Dbias%28C_%7Bout_j%7D%29%2B%5Csum_%7Bk%3D0%7D%5E%7BC_%7Bin%7D-1%7Dweight%28C_%7Bout_j%7D%2Ck%29%5Cstar+input%28N_i%2Ck%29\" alt=\"out(N_i,C_{out_j})=bias(C_{out_j})+\\sum_{k=0}^{C_{in}-1}weight(C_{out_j},k)\\star input(N_i,k)\" eeimg=\"1\"/> </p><p>现在只看其中一个数据，即 <img src=\"https://www.zhihu.com/equation?tex=N_i\" alt=\"N_i\" eeimg=\"1\"/> 为一个常数，代表当前数据是batch中的第几个。以上面定义的网络的第一个卷积层为例：</p><figure><noscript><img src=\"https://pic4.zhimg.com/v2-ed3ac2ec598f9cc2add6003ca55bd263_b.jpg\" data-caption=\"\" data-rawwidth=\"442\" data-rawheight=\"322\" class=\"origin_image zh-lightbox-thumb\" width=\"442\" data-original=\"https://pic4.zhimg.com/v2-ed3ac2ec598f9cc2add6003ca55bd263_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;442&#39; height=&#39;322&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"442\" data-rawheight=\"322\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"442\" data-original=\"https://pic4.zhimg.com/v2-ed3ac2ec598f9cc2add6003ca55bd263_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ed3ac2ec598f9cc2add6003ca55bd263_b.jpg\"/></figure><p>蓝色方框中的红点称为A元素。对这一层上面表达式的各个数值为：</p><ul><li><img src=\"https://www.zhihu.com/equation?tex=N_i\" alt=\"N_i\" eeimg=\"1\"/> ——假设为一批数据中的第一个，即值为1</li><li><img src=\"https://www.zhihu.com/equation?tex=C_%7Bout_j%7D\" alt=\"C_{out_j}\" eeimg=\"1\"/> ——输出有6个通道， <img src=\"https://www.zhihu.com/equation?tex=C_0%2C%5Cldots%2CC_5\" alt=\"C_0,\\ldots,C_5\" eeimg=\"1\"/> ，对A点 <img src=\"https://www.zhihu.com/equation?tex=out_j%3D0\" alt=\"out_j=0\" eeimg=\"1\"/> </li><li><img src=\"https://www.zhihu.com/equation?tex=C_%7Bin%7D\" alt=\"C_{in}\" eeimg=\"1\"/> ——输入通道，只有一个</li><li><img src=\"https://www.zhihu.com/equation?tex=k\" alt=\"k\" eeimg=\"1\"/> ——是计数器，对应着输入数据的每一个通道，这里只有一个</li><li><img src=\"https://www.zhihu.com/equation?tex=bias\" alt=\"bias\" eeimg=\"1\"/> ——是偏置参数，维度和 <img src=\"https://www.zhihu.com/equation?tex=C_%7Bout%7D\" alt=\"C_{out}\" eeimg=\"1\"/> 一致</li></ul><p>卷积核或者说过滤器 <img src=\"https://www.zhihu.com/equation?tex=weight\" alt=\"weight\" eeimg=\"1\"/> 是一个 <img src=\"https://www.zhihu.com/equation?tex=1%5Ctimes6%5Ctimes5%5Ctimes5+\" alt=\"1\\times6\\times5\\times5 \" eeimg=\"1\"/> 的多维向量， <img src=\"https://www.zhihu.com/equation?tex=k\" alt=\"k\" eeimg=\"1\"/> 确定了其第一维， <img src=\"https://www.zhihu.com/equation?tex=C_%7Bout_j%7D\" alt=\"C_{out_j}\" eeimg=\"1\"/> 确定了其第二维。对于输入向量 <img src=\"https://www.zhihu.com/equation?tex=input\" alt=\"input\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=k\" alt=\"k\" eeimg=\"1\"/> 确定了其第一维。于是求和符号里就是两个向量的内积。当 <img src=\"https://www.zhihu.com/equation?tex=C_%7Bin%7D\" alt=\"C_{in}\" eeimg=\"1\"/> 大于1时，来看第二个卷积层：</p><figure><noscript><img src=\"https://pic2.zhimg.com/v2-9f45de3dcff9a944384fd404c88a4025_b.jpg\" data-caption=\"\" data-rawwidth=\"638\" data-rawheight=\"345\" class=\"origin_image zh-lightbox-thumb\" width=\"638\" data-original=\"https://pic2.zhimg.com/v2-9f45de3dcff9a944384fd404c88a4025_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;638&#39; height=&#39;345&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"638\" data-rawheight=\"345\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"638\" data-original=\"https://pic2.zhimg.com/v2-9f45de3dcff9a944384fd404c88a4025_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-9f45de3dcff9a944384fd404c88a4025_b.jpg\"/></figure><p>这时 <img src=\"https://www.zhihu.com/equation?tex=C_%7Bin%7D\" alt=\"C_{in}\" eeimg=\"1\"/> 有6个取值，求和符号中， <img src=\"https://www.zhihu.com/equation?tex=k%3D0%2C...%2C5\" alt=\"k=0,...,5\" eeimg=\"1\"/> ，以右侧红点元素为例：当 <img src=\"https://www.zhihu.com/equation?tex=k%3D0\" alt=\"k=0\" eeimg=\"1\"/> 时是绿色5x5的向量和左边第一个红色5x5的向量做内积，然后 <img src=\"https://www.zhihu.com/equation?tex=k%3D1\" alt=\"k=1\" eeimg=\"1\"/> 是绿色5x5的向量和第二个红色5x5的向量做内积，做6次之后，把这六个内积的结果加和，再加上和第一个输出通道对应的 <img src=\"https://www.zhihu.com/equation?tex=bias\" alt=\"bias\" eeimg=\"1\"/> ，就得到了右侧红点元素的值。</p><p>然后左侧红色方框即感受野再按步长移动。输出向量的尺寸是这样的（floor代表向下取整）：</p><p><img src=\"https://www.zhihu.com/equation?tex=H_%7Bout%7D%3Dfloor%28%28H_%7Bin%7D%2B2%2Apadding%5B0%5D-dilation%5B0%5D%2A%28kernel%5C_size%5B0%5D-1%29-1%29%2Fstride%5B0%5D%2B1%29\" alt=\"H_{out}=floor((H_{in}+2*padding[0]-dilation[0]*(kernel\\_size[0]-1)-1)/stride[0]+1)\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=W_%7Bout%7D%3Dfloor%28%28W_%7Bin%7D%2B2%2Apadding%5B1%5D-dilation%5B1%5D%2A%28kernel%5C_size%5B1%5D-1%29-1%29%2Fstride%5B1%5D%2B1%29\" alt=\"W_{out}=floor((W_{in}+2*padding[1]-dilation[1]*(kernel\\_size[1]-1)-1)/stride[1]+1)\" eeimg=\"1\"/> </p><p>可以看到上面两个式子涉及到了torch.nn.Conv2d()中的四个参数，kernel_size和stride都好理解，分别是卷积核尺寸和移动步长。</p><p><b>padding（零填充）：</b></p><blockquote>在网络的早期层中，我们想要尽可能多地保留原始输入内容的信息，这样我们就能提取出那些低层的特征。比如说我们想要应用同样的卷积层，但又想让输出量维持为 32 x 32 x 3 。为做到这点，我们可以对这个层应用大小为 2 的零填充（zero padding）。零填充在输入内容的边界周围补充零。</blockquote><figure><noscript><img src=\"https://pic2.zhimg.com/v2-993a96a64970915a9cfbdba54cdc4ca9_b.jpg\" data-caption=\"\" data-rawwidth=\"766\" data-rawheight=\"297\" class=\"origin_image zh-lightbox-thumb\" width=\"766\" data-original=\"https://pic2.zhimg.com/v2-993a96a64970915a9cfbdba54cdc4ca9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;766&#39; height=&#39;297&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"766\" data-rawheight=\"297\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"766\" data-original=\"https://pic2.zhimg.com/v2-993a96a64970915a9cfbdba54cdc4ca9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-993a96a64970915a9cfbdba54cdc4ca9_b.jpg\"/></figure><p>关于padding图片来自<a href=\"https://link.zhihu.com/?target=https%3A//adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这里</a>，这是一个很好的讲解卷积神经网络的文章，还有文字来自对这篇文章翻译的<a href=\"https://link.zhihu.com/?target=https%3A//www.jiqizhixin.com/articles/2016-08-01-3\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">中文版</a>。</p><p><b>dilation：</b>对于这个参数，<a href=\"https://link.zhihu.com/?target=https%3A//github.com/vdumoulin/conv_arithmetic/blob/master/README.md\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">链接</a>中的最后一个图是关于dilation的。</p><figure><noscript><img src=\"https://pic4.zhimg.com/v2-29db8216a3439eaadb2cc58c4db7b84b_b.jpg\" data-caption=\"\" data-rawwidth=\"395\" data-rawheight=\"381\" class=\"content_image\" width=\"395\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;395&#39; height=&#39;381&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"395\" data-rawheight=\"381\" class=\"content_image lazy\" width=\"395\" data-actualsrc=\"https://pic4.zhimg.com/v2-29db8216a3439eaadb2cc58c4db7b84b_b.jpg\"/></figure><p>来自<a href=\"https://www.zhihu.com/question/28385679\" class=\"internal\">这个</a>问题下<a href=\"https://www.zhihu.com/people/jiayangqing/activities\" class=\"internal\">贾扬清</a>的回答，有几个说明卷积运算过程的图（其中KxK代表卷积核的size，其他符号和上文所用的一致）：</p><figure><noscript><img src=\"https://pic1.zhimg.com/v2-bb68381f2cb76cfe80e48d5cf2d3acf4_b.jpg\" data-caption=\"\" data-rawwidth=\"568\" data-rawheight=\"292\" class=\"origin_image zh-lightbox-thumb\" width=\"568\" data-original=\"https://pic1.zhimg.com/v2-bb68381f2cb76cfe80e48d5cf2d3acf4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;568&#39; height=&#39;292&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"568\" data-rawheight=\"292\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"568\" data-original=\"https://pic1.zhimg.com/v2-bb68381f2cb76cfe80e48d5cf2d3acf4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-bb68381f2cb76cfe80e48d5cf2d3acf4_b.jpg\"/></figure><figure><noscript><img src=\"https://pic3.zhimg.com/v2-e20bb7792cc05aa600e9f8c97d09703e_b.jpg\" data-caption=\"\" data-rawwidth=\"564\" data-rawheight=\"292\" class=\"origin_image zh-lightbox-thumb\" width=\"564\" data-original=\"https://pic3.zhimg.com/v2-e20bb7792cc05aa600e9f8c97d09703e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;564&#39; height=&#39;292&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"564\" data-rawheight=\"292\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"564\" data-original=\"https://pic3.zhimg.com/v2-e20bb7792cc05aa600e9f8c97d09703e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-e20bb7792cc05aa600e9f8c97d09703e_b.jpg\"/></figure><figure><noscript><img src=\"https://pic2.zhimg.com/v2-565e5dd3f5855030b72e9677a3b3550d_b.jpg\" data-caption=\"\" data-rawwidth=\"617\" data-rawheight=\"295\" class=\"origin_image zh-lightbox-thumb\" width=\"617\" data-original=\"https://pic2.zhimg.com/v2-565e5dd3f5855030b72e9677a3b3550d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;617&#39; height=&#39;295&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"617\" data-rawheight=\"295\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"617\" data-original=\"https://pic2.zhimg.com/v2-565e5dd3f5855030b72e9677a3b3550d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-565e5dd3f5855030b72e9677a3b3550d_b.jpg\"/></figure><figure><noscript><img src=\"https://pic1.zhimg.com/v2-e6559d748fa735d51025ec4170eceb9c_b.jpg\" data-caption=\"\" data-rawwidth=\"623\" data-rawheight=\"427\" class=\"origin_image zh-lightbox-thumb\" width=\"623\" data-original=\"https://pic1.zhimg.com/v2-e6559d748fa735d51025ec4170eceb9c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;623&#39; height=&#39;427&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"623\" data-rawheight=\"427\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"623\" data-original=\"https://pic1.zhimg.com/v2-e6559d748fa735d51025ec4170eceb9c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e6559d748fa735d51025ec4170eceb9c_b.jpg\"/></figure><p>对于卷积神经网络每一层究竟做了什么，提取出什么特征，<a href=\"https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DAgkfIQ4IGaM\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这里</a>有个将神经网络<b>可视化</b>的视频</p><h2><b>参数个数</b></h2><p>对于卷积层来说，参数个数就是 <img src=\"https://www.zhihu.com/equation?tex=weight\" alt=\"weight\" eeimg=\"1\"/> 向量和 <img src=\"https://www.zhihu.com/equation?tex=bias\" alt=\"bias\" eeimg=\"1\"/> 向量的元素个数和，比如对第二个卷积层来说，就是 <img src=\"https://www.zhihu.com/equation?tex=6+%5Ctimes+16+%5Ctimes+5%5Ctimes+5%2B16\" alt=\"6 \\times 16 \\times 5\\times 5+16\" eeimg=\"1\"/> </p><p>可以通过：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">()</span></code></pre></div><p>来获得网络的参数。</p><figure><noscript><img src=\"https://pic3.zhimg.com/v2-45e05f643512dc6be108eadcd5f47292_b.jpg\" data-caption=\"\" data-rawwidth=\"561\" data-rawheight=\"278\" class=\"origin_image zh-lightbox-thumb\" width=\"561\" data-original=\"https://pic3.zhimg.com/v2-45e05f643512dc6be108eadcd5f47292_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;561&#39; height=&#39;278&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"561\" data-rawheight=\"278\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"561\" data-original=\"https://pic3.zhimg.com/v2-45e05f643512dc6be108eadcd5f47292_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-45e05f643512dc6be108eadcd5f47292_b.jpg\"/></figure><h2><b>网络的输入与输出</b></h2><p>下面来给网络一个输入：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"nb\">input</span> <span class=\"o\">=</span> <span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">))</span>\n<span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span> </code></pre></div><figure><noscript><img src=\"https://pic1.zhimg.com/v2-71ffea0f2a238f7a73fa487f9f31e5d8_b.jpg\" data-caption=\"\" data-rawwidth=\"568\" data-rawheight=\"58\" class=\"origin_image zh-lightbox-thumb\" width=\"568\" data-original=\"https://pic1.zhimg.com/v2-71ffea0f2a238f7a73fa487f9f31e5d8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;568&#39; height=&#39;58&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"568\" data-rawheight=\"58\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"568\" data-original=\"https://pic1.zhimg.com/v2-71ffea0f2a238f7a73fa487f9f31e5d8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-71ffea0f2a238f7a73fa487f9f31e5d8_b.jpg\"/></figure><p>在前面写卷积运算的时候也提到过，实际上网络的输入向量，第一个维度 <img src=\"https://www.zhihu.com/equation?tex=N\" alt=\"N\" eeimg=\"1\"/> 是批处理数据一批的个数。在torch.nn方法中必须要有这一维的数值，即输入的向量必须是 <img src=\"https://www.zhihu.com/equation?tex=%28nSamples%5Ctimes+nChannels+%5Ctimes+Height+%5Ctimes+Width%29\" alt=\"(nSamples\\times nChannels \\times Height \\times Width)\" eeimg=\"1\"/> 这样的四维向量。而如果数据没这第一个维度，也就是并不是一批数据，那么可以通过：</p><div class=\"highlight\"><pre><code class=\"language-text\">torch.Tensor.unsqueeze(0)</code></pre></div><p>在不改变数据所含数值的情况，增加一个维度。</p><figure><noscript><img src=\"https://pic3.zhimg.com/v2-f52392176d04d04d4aa8cda7a0c58ef2_b.jpg\" data-caption=\"\" data-rawwidth=\"450\" data-rawheight=\"303\" class=\"origin_image zh-lightbox-thumb\" width=\"450\" data-original=\"https://pic3.zhimg.com/v2-f52392176d04d04d4aa8cda7a0c58ef2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;450&#39; height=&#39;303&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"450\" data-rawheight=\"303\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"450\" data-original=\"https://pic3.zhimg.com/v2-f52392176d04d04d4aa8cda7a0c58ef2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f52392176d04d04d4aa8cda7a0c58ef2_b.jpg\"/></figure><figure><noscript><img src=\"https://pic2.zhimg.com/v2-da0f1f797edfe89e439655ef9c901611_b.jpg\" data-caption=\"\" data-rawwidth=\"565\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb\" width=\"565\" data-original=\"https://pic2.zhimg.com/v2-da0f1f797edfe89e439655ef9c901611_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;565&#39; height=&#39;222&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"565\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"565\" data-original=\"https://pic2.zhimg.com/v2-da0f1f797edfe89e439655ef9c901611_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-da0f1f797edfe89e439655ef9c901611_b.jpg\"/></figure><figure><noscript><img src=\"https://pic2.zhimg.com/v2-c5656f1f2920505d461a0630aae6baa9_b.jpg\" data-caption=\"\" data-rawwidth=\"549\" data-rawheight=\"442\" class=\"origin_image zh-lightbox-thumb\" width=\"549\" data-original=\"https://pic2.zhimg.com/v2-c5656f1f2920505d461a0630aae6baa9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;549&#39; height=&#39;442&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"549\" data-rawheight=\"442\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"549\" data-original=\"https://pic2.zhimg.com/v2-c5656f1f2920505d461a0630aae6baa9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c5656f1f2920505d461a0630aae6baa9_b.jpg\"/></figure><h2><b>损失函数</b></h2><p>如何定义损失函数也很简单的：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">)</span>\n<span class=\"n\">target</span> <span class=\"o\">=</span> <span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">11</span><span class=\"p\">))</span>  <span class=\"c1\"># a dummy target, for example</span>\n<span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">MSELoss</span><span class=\"p\">()</span> <span class=\"c1\"># mean-squared error between the input and the target</span>\n\n<span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">criterion</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">)</span></code></pre></div><p>torch.nn中还有很多种损失函数可以使用，见<a href=\"https://link.zhihu.com/?target=http%3A//pytorch.org/docs/master/nn.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这里</a></p><h2><b>梯度的反向传播</b></h2><p>这就要用到上一章autograd.Variable()的.backward()功能。在学习autograd.Variable时也发现，如果Variable.grad已经储存有梯度值，那么当再次写出.backward()命令进行梯度回传时，计算出的值将与各个创建变量（graph leaves）的.grad中已有的值累加。所以对于神经网络，要使用net.zero_grad()清除掉原有的梯度值。</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>     <span class=\"c1\"># zeroes the gradient buffers of all parameters</span>\n\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;conv1.bias.grad before backward&#39;</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"o\">.</span><span class=\"n\">bias</span><span class=\"o\">.</span><span class=\"n\">grad</span><span class=\"p\">)</span>\n\n<span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;conv1.bias.grad after backward&#39;</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"o\">.</span><span class=\"n\">bias</span><span class=\"o\">.</span><span class=\"n\">grad</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic2.zhimg.com/v2-ae92ca41ff72cb0a43e3acaa935e0ee9_b.jpg\" data-caption=\"\" data-rawwidth=\"323\" data-rawheight=\"336\" class=\"content_image\" width=\"323\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;323&#39; height=&#39;336&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"323\" data-rawheight=\"336\" class=\"content_image lazy\" width=\"323\" data-actualsrc=\"https://pic2.zhimg.com/v2-ae92ca41ff72cb0a43e3acaa935e0ee9_b.jpg\"/></figure><p>如果原来已有梯度值，然后执行net.zero_grad()，梯度值就变成0，如果原来就没有梯度值，那么变量x处的梯度x.grad=None</p><h2><b>参数更新</b></h2><p>使用torch.optim可以方便的定义参数更新算法：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"kn\">import</span> <span class=\"nn\">torch.optim</span> <span class=\"kn\">as</span> <span class=\"nn\">optim</span>\n\n<span class=\"c1\"># create your optimizer,such as SGD</span>\n<span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span><span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">)</span> <span class=\"c1\"># lr is learning rate</span>\n<span class=\"c1\"># in your training loop:</span>\n<span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span> <span class=\"c1\"># zero the gradient buffers</span>\n<span class=\"n\">output</span><span class=\"o\">=</span><span class=\"n\">net</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">)</span>\n<span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">criterion</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"p\">)</span>\n<span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n<span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span> <span class=\"c1\"># Does the update</span></code></pre></div><p></p>", 
            "topic": [
                {
                    "tag": "PyTorch", 
                    "tagLink": "https://api.zhihu.com/topics/20075993"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": [
                {
                    "userName": "刘邑", 
                    "userLink": "https://www.zhihu.com/people/e9024dd334570270c65114280952ab1b", 
                    "content": "<p>楼主大大你好，刚开始入坑pytorch。问一下卷积输入的时候只需要input_channel，那么image_sieze是怎么定义的，为什么就说这个期待输入是32x32呢？如果输入向量为(1x1x64x64)就报错：size mismatch</p><p>谢谢！！！</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/29904755", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 91, 
            "title": "Autograd:PyTorch中的梯度计算", 
            "content": "<p>用PyTorch构建的神经网络，其梯度计算是通过torch.autograd来完成的。当我们进行了一系列计算，并想获取一些变量间的梯度信息，需要进行以下步骤：</p><ol><li>构建一个计算图，用Variable将Tensor包装起来，形成计算图中的节点。然后Variable之间进行各种运算就像Tensor之间的运算一样，Variable支持几乎所有的Tensor运算。</li><li>当你进行完一系列运算之后，可以执行.backward()来自动计算出所有需要的梯度。</li><li>来针对某个变量x执行x.grad获得想要的梯度值。</li></ol><h2><b>Variable</b></h2><p>autograd.Variable是torch.autograd中很重要的类。它用来包装Tensor，将Tensor转换为Variable之后，可以装载梯度信息。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-38169db1961e5bd583d5c05f70e93456_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"351\" data-rawheight=\"260\" class=\"content_image\" width=\"351\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;351&#39; height=&#39;260&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"351\" data-rawheight=\"260\" class=\"content_image lazy\" width=\"351\" data-actualsrc=\"https://pic3.zhimg.com/v2-38169db1961e5bd583d5c05f70e93456_b.jpg\"/></figure><p>pytorch的一个重要特点就是<b>动态计算图</b>（Dynamic Computational Graphs）。计算图中每一个节点代表一个变量，变量间建立运算关系并且可以修改，而不像Tensorflow中的计算图是固定不可变的。</p><p>Variable用来构建一个计算图中的节点。将Tensor转换为Variabla类型之后，该Tensor就成了计算图中的一个节点。对于该节点，有两个重要的特性：</p><ul><li>.data——获得该节点的值，即Tensor类型的值</li><li>.grad——获得该节点处的梯度信息</li></ul><p>关于Variable的参数之一“requires_grad”和特性之一“grad_fn”有要注意的地方，都和该变量是否是人自己创建的有关：</p><ol><li>requires_grad有两个值：True和False，True代表此变量处需要计算梯度，False代表不需要。变量的“requires_grad”值是Variable的一个参数，在建立Variable的时候就已经设定好，默认是False。</li><li>grad_fn的值可以得知该变量是否是一个计算结果，也就是说该变量是不是一个函数的输出值。若是，则grad_fn返回一个与该函数相关的对象，否则是None。</li></ol><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.autograd</span> <span class=\"kn\">import</span> <span class=\"n\">Variable</span>\n<span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"n\">y</span><span class=\"o\">=</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"n\">z</span><span class=\"o\">=</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">),</span><span class=\"n\">requires_grad</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"n\">a</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">+</span><span class=\"n\">y</span>\n<span class=\"n\">b</span><span class=\"o\">=</span><span class=\"n\">a</span><span class=\"o\">+</span><span class=\"n\">z</span></code></pre></div><p>以上形成了这样一个计算图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-8e0ba2ab705d677a24b318cc428c36cf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"230\" data-rawheight=\"212\" class=\"content_image\" width=\"230\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;230&#39; height=&#39;212&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"230\" data-rawheight=\"212\" class=\"content_image lazy\" width=\"230\" data-actualsrc=\"https://pic4.zhimg.com/v2-8e0ba2ab705d677a24b318cc428c36cf_b.jpg\"/></figure><ul><li>用户<b>创建变量</b>：x,y,z</li><li>运算<b>结果变量</b>：a,b</li></ul><p><i>（官方文档中所说的<b>“graph leaves</b>”,“<b>leaf variables</b>”，都是指像x,y,z这样的事先创建的、而非运算得到的变量，本文我们把这样的变量称为<b>创建变量</b>，像a,b那样的称为<b>结果变量</b>）</i></p><p>运算结果变量的“requires_grad”值是取决于输入的变量的，例如变量b：其是由a和z计算得到的，如果a或者z需要计算关于自己的梯度（requires_grad=True），因为梯度要反向传播，那么b的“requires_grad”就是True；如果a和z的“requires_grad”都是False那么，b的也是False。而且运算结果变量的“requires_grad”是不可以更改的，且不会改变。用户创建变量的“requires_grad”是可以更改的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3964146c6a209a8c5e35871b8eb4f33a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"578\" data-rawheight=\"217\" class=\"origin_image zh-lightbox-thumb\" width=\"578\" data-original=\"https://pic3.zhimg.com/v2-3964146c6a209a8c5e35871b8eb4f33a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;578&#39; height=&#39;217&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"578\" data-rawheight=\"217\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"578\" data-original=\"https://pic3.zhimg.com/v2-3964146c6a209a8c5e35871b8eb4f33a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-3964146c6a209a8c5e35871b8eb4f33a_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6213f96a4b2732c547f2a6973a1ff2cd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"577\" data-rawheight=\"82\" class=\"origin_image zh-lightbox-thumb\" width=\"577\" data-original=\"https://pic2.zhimg.com/v2-6213f96a4b2732c547f2a6973a1ff2cd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;577&#39; height=&#39;82&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"577\" data-rawheight=\"82\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"577\" data-original=\"https://pic2.zhimg.com/v2-6213f96a4b2732c547f2a6973a1ff2cd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6213f96a4b2732c547f2a6973a1ff2cd_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-56b9497ad58564dfcab627037b0d57cb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"580\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb\" width=\"580\" data-original=\"https://pic4.zhimg.com/v2-56b9497ad58564dfcab627037b0d57cb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;580&#39; height=&#39;152&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"580\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"580\" data-original=\"https://pic4.zhimg.com/v2-56b9497ad58564dfcab627037b0d57cb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-56b9497ad58564dfcab627037b0d57cb_b.jpg\"/></figure><h2>Gradients</h2><p>我们再来建立一个计算稍微复杂一点能体现出梯度计算过程的计算图：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.autograd</span> <span class=\"kn\">import</span> <span class=\"n\">Variable</span>\n<span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">([[</span><span class=\"mf\">1.</span><span class=\"p\">,</span><span class=\"mf\">2.</span><span class=\"p\">,</span><span class=\"mf\">3.</span><span class=\"p\">],[</span><span class=\"mf\">4.</span><span class=\"p\">,</span><span class=\"mf\">5.</span><span class=\"p\">,</span><span class=\"mf\">6.</span><span class=\"p\">]])</span>\n<span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">requires_grad</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"n\">y</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">+</span><span class=\"mi\">2</span>\n<span class=\"n\">z</span><span class=\"o\">=</span><span class=\"n\">y</span><span class=\"o\">*</span><span class=\"n\">y</span><span class=\"o\">*</span><span class=\"mi\">3</span>\n<span class=\"n\">out</span><span class=\"o\">=</span><span class=\"n\">z</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span></code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f46e4e83c9037e71a6a2f67d53ea2fe8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"86\" data-rawheight=\"250\" class=\"content_image\" width=\"86\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;86&#39; height=&#39;250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"86\" data-rawheight=\"250\" class=\"content_image lazy\" width=\"86\" data-actualsrc=\"https://pic1.zhimg.com/v2-f46e4e83c9037e71a6a2f67d53ea2fe8_b.jpg\"/></figure><p>这是这样一个图。先来看一下这四个变量都是什么：</p><div class=\"highlight\"><pre><code class=\"language-text\">print(x)\nprint(y)\nprint(z)\nprint(out)</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7edc093d86a83869da574c3fa7c85a63_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"270\" data-rawheight=\"319\" class=\"content_image\" width=\"270\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;270&#39; height=&#39;319&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"270\" data-rawheight=\"319\" class=\"content_image lazy\" width=\"270\" data-actualsrc=\"https://pic4.zhimg.com/v2-7edc093d86a83869da574c3fa7c85a63_b.jpg\"/></figure><p>再来看一下上面讨论过的grad_fn的值：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">grad_fn</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"o\">.</span><span class=\"n\">grad_fn</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"o\">.</span><span class=\"n\">grad_fn</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">grad_fn</span><span class=\"p\">)</span></code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-3ce9bbc5da8900eddda61f1e3faa679b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"508\" data-rawheight=\"77\" class=\"origin_image zh-lightbox-thumb\" width=\"508\" data-original=\"https://pic4.zhimg.com/v2-3ce9bbc5da8900eddda61f1e3faa679b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;508&#39; height=&#39;77&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"508\" data-rawheight=\"77\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"508\" data-original=\"https://pic4.zhimg.com/v2-3ce9bbc5da8900eddda61f1e3faa679b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-3ce9bbc5da8900eddda61f1e3faa679b_b.jpg\"/></figure><p>可见作为<b>leaf Variable</b>的x，是一个用户创建的变量，它的grad_fn是None。而其余三个变量都是一个运算的结果，其grad_fn是一个与运算对应的对象。</p><p>计算图已经构建好了，下面来计算梯度。所计算的梯度都是<b>结果变量</b>关于<b>创建变量</b>的梯度。在这个计算图中，能计算的梯度有三个，分别是out,z和y关于x的梯度，以out关于x的梯度为例：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+out%7D%7B%5Cpartial+x%7D\" alt=\"\\frac{\\partial out}{\\partial x}\" eeimg=\"1\"/> </p><p>要在变量out处执行.backward()，这时开始计算梯度，由梯度计算的链式法则算到所有的结果变量（graph leaves），这个图中只有一个x。然后在创建变量处执行.grad，获得结果变量out关于创建变量x的梯度。我们先来手动计算一下：</p><p>用 <img src=\"https://www.zhihu.com/equation?tex=o\" alt=\"o\" eeimg=\"1\"/> 表示变量out,</p><p><img src=\"https://www.zhihu.com/equation?tex=o%3D%5Cfrac%7B1%7D%7B6%7D%5Csum_iz_i\" alt=\"o=\\frac{1}{6}\\sum_iz_i\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=z_i%3D3%28x_i%2B2%29%5E2\" alt=\"z_i=3(x_i+2)^2\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5CRightarrow\" alt=\"\\Rightarrow\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+o%7D%7B%5Cpartial+x_i%7D%3Dx_i%2B2\" alt=\"\\frac{\\partial o}{\\partial x_i}=x_i+2\" eeimg=\"1\"/> </p><p>这时我们就计算出了 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+out%7D%7B%5Cpartial+x%7D\" alt=\"\\frac{\\partial out}{\\partial x}\" eeimg=\"1\"/> 的表达式。在定义x的时候已经给 <img src=\"https://www.zhihu.com/equation?tex=x_i\" alt=\"x_i\" eeimg=\"1\"/> 赋值，然后代入表达式中计算，就可以得到一个具体的梯度值。要注意：</p><ul><li>若是关于graph leaves求导的<b>结果变量</b>是一个标量，那么gradient默认为None，或者指定为“torch.Tensor([1.0])”</li><li>若是关于graph leaves求导的<b>结果变量</b>是一个向量，那么gradient是不能缺省的，要是和该向量同纬度的tensor</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-33430152651b0e9b93ba91f2aeb6ee50_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"584\" data-rawheight=\"469\" class=\"origin_image zh-lightbox-thumb\" width=\"584\" data-original=\"https://pic1.zhimg.com/v2-33430152651b0e9b93ba91f2aeb6ee50_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;584&#39; height=&#39;469&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"584\" data-rawheight=\"469\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"584\" data-original=\"https://pic1.zhimg.com/v2-33430152651b0e9b93ba91f2aeb6ee50_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-33430152651b0e9b93ba91f2aeb6ee50_b.jpg\"/></figure><p>如果是z关于x求导就必须指定gradient参数：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-1933ba4b5ea53d07f02c85c0f5b67e8a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"582\" data-rawheight=\"304\" class=\"origin_image zh-lightbox-thumb\" width=\"582\" data-original=\"https://pic3.zhimg.com/v2-1933ba4b5ea53d07f02c85c0f5b67e8a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;582&#39; height=&#39;304&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"582\" data-rawheight=\"304\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"582\" data-original=\"https://pic3.zhimg.com/v2-1933ba4b5ea53d07f02c85c0f5b67e8a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-1933ba4b5ea53d07f02c85c0f5b67e8a_b.jpg\"/></figure><p>完。</p><p>PS:本人也是刚开始学，如果有理解的不对的还望不吝赐教。</p><hr/><p><i>17年12月28日更新</i></p><p>接上文。由 <img src=\"https://www.zhihu.com/equation?tex=z_i%3D3%28x_i%2B2%29%5E2\" alt=\"z_i=3(x_i+2)^2\" eeimg=\"1\"/> ，代入每一个 <img src=\"https://www.zhihu.com/equation?tex=x_i\" alt=\"x_i\" eeimg=\"1\"/> ，就得到了向量 <img src=\"https://www.zhihu.com/equation?tex=z\" alt=\"z\" eeimg=\"1\"/> 关于向量 <img src=\"https://www.zhihu.com/equation?tex=x\" alt=\"x\" eeimg=\"1\"/> 的导数，这个导数是和 <img src=\"https://www.zhihu.com/equation?tex=x\" alt=\"x\" eeimg=\"1\"/> 同维度的。这种情况需要给出gradient参数，这个参数需要和 <img src=\"https://www.zhihu.com/equation?tex=z\" alt=\"z\" eeimg=\"1\"/> 同纬度，而且当gradient向量所有元素为1.0时，可以得到正确的关于leaf Variable的导数。若不为1.0时，算出的导数就扩大对应倍数，我之前只是知道这个现象，但是不知道为什么要这样设置。那这个.backward()括号中的gradient参数到底是干嘛的呢。今天看到 <a class=\"member_mention\" href=\"https://www.zhihu.com/people/157deec64cc5e062b2207aeece42f50f\" data-hash=\"157deec64cc5e062b2207aeece42f50f\" data-hovercard=\"p$b$157deec64cc5e062b2207aeece42f50f\">@七月</a> 写的<a href=\"https://zhuanlan.zhihu.com/p/29923090\" class=\"internal\">这篇文章</a>，明白了是怎么回事。原来在执行</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">z</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">(</span><span class=\"n\">gradient</span><span class=\"p\">)</span></code></pre></div><p>的时候，若z不是一个标量，那么就先构造一个标量的值：<b>L = torch.sum(z*gradient)</b>，再关于L对各个leaf Variable计算梯度 </p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6b2513a2bdb97274f54f8bf68ecbfd0e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"582\" data-rawheight=\"288\" class=\"origin_image zh-lightbox-thumb\" width=\"582\" data-original=\"https://pic3.zhimg.com/v2-6b2513a2bdb97274f54f8bf68ecbfd0e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;582&#39; height=&#39;288&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"582\" data-rawheight=\"288\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"582\" data-original=\"https://pic3.zhimg.com/v2-6b2513a2bdb97274f54f8bf68ecbfd0e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-6b2513a2bdb97274f54f8bf68ecbfd0e_b.jpg\"/></figure><p>也就是说，若z不是标量，那么就在计算图中添加一个由z运算得到的标量L，</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">L</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"o\">*</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">gradients</span><span class=\"p\">))</span></code></pre></div><p>因为要把z和gradients对应元素相乘，于是向量gradients需要和z的维度相同。<b>L.backward()</b>，或者说 <b>z.backward(gradient=gradients) </b>会计算 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+x%7D\" alt=\"\\frac{\\partial L}{\\partial x}\" eeimg=\"1\"/> ，当gradients向量所有元素都为1时，计算出的 <b>x.grad </b>正是 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+z%7D%7B%5Cpartial+x%7D\" alt=\"\\frac{\\partial z}{\\partial x}\" eeimg=\"1\"/> ，因为 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+z%7D%3D1\" alt=\"\\frac{\\partial L}{\\partial z}=1\" eeimg=\"1\"/> 。这也是为什么<b>.backward(gradient=...)</b>括号里这个参数名为“gradient”，因为它是构造出的变量L关于原变量z的梯度。</p>", 
            "topic": [
                {
                    "tag": "PyTorch", 
                    "tagLink": "https://api.zhihu.com/topics/20075993"
                }
            ], 
            "comments": [
                {
                    "userName": "李军", 
                    "userLink": "https://www.zhihu.com/people/e5f037d0e608cfe301212f50a736ef8c", 
                    "content": "<p>文章输出变量o 的系数是1/6吧,不是1/4~</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "没错，是我写错了，多谢", 
                            "likes": 0, 
                            "replyToAuthor": "李军"
                        }
                    ]
                }, 
                {
                    "userName": "liuxxxl", 
                    "userLink": "https://www.zhihu.com/people/f7d419f709d202efc5f513cce19639a6", 
                    "content": "<p>知乎真的是大神多，感谢</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "饭饭", 
                    "userLink": "https://www.zhihu.com/people/7100f9043b893891679fd6862999eb43", 
                    "content": "<p>非常清晰，解决了困扰很久的问题</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "啦哒滴哒滴", 
                    "userLink": "https://www.zhihu.com/people/045f89021b24b58cdc39360f7f3ac450", 
                    "content": "<p>解释的太清晰了，刚从tensorflow转到pytorch这边，受益颇多！3x！！!</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "可可哒", 
                    "userLink": "https://www.zhihu.com/people/3f94ef291e639f2bb6f39e90d9c3d327", 
                    "content": "<p>真的很清楚，超感谢！！</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "😄", 
                            "likes": 0, 
                            "replyToAuthor": "可可哒"
                        }
                    ]
                }, 
                {
                    "userName": "test", 
                    "userLink": "https://www.zhihu.com/people/d0558e06fe46837443eeb9674492c592", 
                    "content": "<p></p><p>我的咋能改了，使得a.requires_grad = True，是版本的缘故吗</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "Morse Mo", 
                    "userLink": "https://www.zhihu.com/people/faacb6d3f4acd35fe864ba7d09a842f4", 
                    "content": "<p>Pytorch 1.0 已经合并了Variable 和 Tensor。现在可统一用torch.tensor （）来表示leaf</p>", 
                    "likes": 1, 
                    "childComments": []
                }, 
                {
                    "userName": "切水果菜鸟", 
                    "userLink": "https://www.zhihu.com/people/46c85b6715cef44dd26c6a79cdf07d80", 
                    "content": "<p>你好，最后一点是不是写错了，若gradient向量所有元素为1，则x.grad应该为</p><p>偏sum(z)/偏(x)，而且偏L/偏z也不会等于1吧，这是2个矩阵间的运算</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "里夫辰", 
                    "userLink": "https://www.zhihu.com/people/0d98deafbaab3ddc38528235ae5e4e75", 
                    "content": "写的超清楚，学到了！", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "Keep early", 
                    "userLink": "https://www.zhihu.com/people/fedf133cbe790acac0a87687811fffef", 
                    "content": "<p>第一张代码图里面：a.grad_fn应该是None?我运行出来是None</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>可能是版本问题，这个文章写的年代有点久远了</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Keep early"
                        }
                    ]
                }, 
                {
                    "userName": "nightmare", 
                    "userLink": "https://www.zhihu.com/people/7811f30ac5f4077b3fe7228fe70c4c8b", 
                    "content": "<p>如果把x转到cuda上面，结果grad就变成None了，这个Bug你知道为啥吗？</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>如果是x = x.cuda() 那x指向的就不是leaf node了哦那样中间的梯度是看不到的，你可以用另外一个变量名 比如X =  x.cuda(),这样的话x.grad就不会是None了。。。 希望可以帮到你</p><a class=\"comment_sticker\" href=\"https://pic3.zhimg.com/v2-744accde1bb3117fc74e1af0e0ac496e.gif\" data-width=\"\" data-height=\"\">[小建议]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "nightmare"
                        }
                    ]
                }, 
                {
                    "userName": "ZhuoRan", 
                    "userLink": "https://www.zhihu.com/people/d435ce8f7775426a5ebe8a9b95c5cdf3", 
                    "content": "<p>牛逼。清晰。</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/29900346", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 3, 
            "title": "什么是PyTorch", 
            "content": "<p>是基于python的一个科学计算工具，适用于以下情况：</p><ul><li>在使用GPUs的情况下，作为替代numpy的一个工具</li><li>是一个深度学习开发平台，提供了最大程度的灵活性和速度</li></ul><h2><b>Getting Started</b></h2><p><b>1.Tensors</b></p><p>Tensors类似于numpy的ndarray，所不同的是Tensor可以使用GPU加速计算</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"kn\">from</span> <span class=\"nn\">__future__</span> <span class=\"kn\">import</span> <span class=\"n\">print_function</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span></code></pre></div><p>构建一个5x3的未初始化的矩阵：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic3.zhimg.com/v2-0650527637ea2e1c17b865fc3c19a046_b.jpg\" data-caption=\"\" data-rawwidth=\"263\" data-rawheight=\"125\" class=\"content_image\" width=\"263\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;263&#39; height=&#39;125&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"263\" data-rawheight=\"125\" class=\"content_image lazy\" width=\"263\" data-actualsrc=\"https://pic3.zhimg.com/v2-0650527637ea2e1c17b865fc3c19a046_b.jpg\"/></figure><p>构建一个5x3的初始化了的矩阵：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic3.zhimg.com/v2-b0fdf301256e5efd3e4f28470a009c22_b.jpg\" data-caption=\"\" data-rawwidth=\"255\" data-rawheight=\"127\" class=\"content_image\" width=\"255\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;255&#39; height=&#39;127&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"255\" data-rawheight=\"127\" class=\"content_image lazy\" width=\"255\" data-actualsrc=\"https://pic3.zhimg.com/v2-b0fdf301256e5efd3e4f28470a009c22_b.jpg\"/></figure><p>获取矩阵的维度：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">())</span></code></pre></div><figure><noscript><img src=\"https://pic3.zhimg.com/v2-4f16d7e50528478244347e0d507dea6a_b.jpg\" data-caption=\"\" data-rawwidth=\"141\" data-rawheight=\"25\" class=\"content_image\" width=\"141\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;141&#39; height=&#39;25&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"141\" data-rawheight=\"25\" class=\"content_image lazy\" width=\"141\" data-actualsrc=\"https://pic3.zhimg.com/v2-4f16d7e50528478244347e0d507dea6a_b.jpg\"/></figure><p><b>2.运算</b></p><p>Tensor的每种运算都有多种写法，以加法为例：</p><ul><li>格式1</li></ul><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">y</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">+</span><span class=\"n\">y</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic4.zhimg.com/v2-ed20c3aabd0749c77548eaeefa9e9b77_b.jpg\" data-caption=\"\" data-rawwidth=\"237\" data-rawheight=\"133\" class=\"content_image\" width=\"237\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;237&#39; height=&#39;133&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"237\" data-rawheight=\"133\" class=\"content_image lazy\" width=\"237\" data-actualsrc=\"https://pic4.zhimg.com/v2-ed20c3aabd0749c77548eaeefa9e9b77_b.jpg\"/></figure><ul><li>格式2</li></ul><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">))</span></code></pre></div><figure><noscript><img src=\"https://pic4.zhimg.com/v2-7c9cf8abc14c5dc1b841c5fd825025bb_b.jpg\" data-caption=\"\" data-rawwidth=\"234\" data-rawheight=\"127\" class=\"content_image\" width=\"234\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;234&#39; height=&#39;127&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"234\" data-rawheight=\"127\" class=\"content_image lazy\" width=\"234\" data-actualsrc=\"https://pic4.zhimg.com/v2-7c9cf8abc14c5dc1b841c5fd825025bb_b.jpg\"/></figure><ul><li>将运算结果储存在一个名为result的tensor中</li></ul><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">result</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">,</span><span class=\"n\">out</span><span class=\"o\">=</span><span class=\"n\">result</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic3.zhimg.com/v2-7947516b07adc9707c96c158dbd1737e_b.jpg\" data-caption=\"\" data-rawwidth=\"239\" data-rawheight=\"124\" class=\"content_image\" width=\"239\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;239&#39; height=&#39;124&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"239\" data-rawheight=\"124\" class=\"content_image lazy\" width=\"239\" data-actualsrc=\"https://pic3.zhimg.com/v2-7947516b07adc9707c96c158dbd1737e_b.jpg\"/></figure><ul><li>原地操作（in-place）</li></ul><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"c1\">#add x to y</span>\n<span class=\"n\">y</span><span class=\"o\">.</span><span class=\"n\">add_</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic4.zhimg.com/v2-47fad6b8eb22d3db888e3371c1e45963_b.jpg\" data-caption=\"\" data-rawwidth=\"240\" data-rawheight=\"124\" class=\"content_image\" width=\"240\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;240&#39; height=&#39;124&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"240\" data-rawheight=\"124\" class=\"content_image lazy\" width=\"240\" data-actualsrc=\"https://pic4.zhimg.com/v2-47fad6b8eb22d3db888e3371c1e45963_b.jpg\"/></figure><p><i>注意： 所有对于tensor的原地操作都以_作为后缀，例如： x.copy_(y),x.t_(),这些操作都会改变变量x</i></p><p>可以使用像numpy中的切片方法那样来获取矩阵的一部分</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">[:,</span><span class=\"mi\">1</span><span class=\"p\">])</span></code></pre></div><figure><noscript><img src=\"https://pic4.zhimg.com/v2-e2f62548fcfa16127f534201a8aa59f3_b.jpg\" data-caption=\"\" data-rawwidth=\"230\" data-rawheight=\"129\" class=\"content_image\" width=\"230\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;230&#39; height=&#39;129&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"230\" data-rawheight=\"129\" class=\"content_image lazy\" width=\"230\" data-actualsrc=\"https://pic4.zhimg.com/v2-e2f62548fcfa16127f534201a8aa59f3_b.jpg\"/></figure><p>点击<u><a href=\"https://link.zhihu.com/?target=http%3A//pytorch.org/docs/master/torch.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这里</a></u>查看Tensor的更多操作，包括替换、索引、切片、数学运算、线性代数和随机数，等等。</p><h2><b>Numpy Bridge</b></h2><p>torch的Tensor与numpy的array互相转换</p><p>进行相互转换的tensor和array，可共享一个存储位置，两种类型下的操作都可以改变该存储位置的值</p><p><b>1.将torch.Tensor转换为numpy.array</b></p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">a</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic2.zhimg.com/v2-03b565ecb8d4f71243e256e3c4c377bd_b.jpg\" data-caption=\"\" data-rawwidth=\"215\" data-rawheight=\"131\" class=\"content_image\" width=\"215\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;215&#39; height=&#39;131&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"215\" data-rawheight=\"131\" class=\"content_image lazy\" width=\"215\" data-actualsrc=\"https://pic2.zhimg.com/v2-03b565ecb8d4f71243e256e3c4c377bd_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">b</span><span class=\"o\">=</span><span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic3.zhimg.com/v2-a3fb5a6af19f94525009c489e26a49d6_b.jpg\" data-caption=\"\" data-rawwidth=\"170\" data-rawheight=\"29\" class=\"content_image\" width=\"170\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;170&#39; height=&#39;29&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"170\" data-rawheight=\"29\" class=\"content_image lazy\" width=\"170\" data-actualsrc=\"https://pic3.zhimg.com/v2-a3fb5a6af19f94525009c489e26a49d6_b.jpg\"/></figure><p>来看numpy.array类型的b的值是如何被改变的</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">add_</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic1.zhimg.com/v2-ef7eb65059dce05de17d116164e82f40_b.jpg\" data-caption=\"\" data-rawwidth=\"231\" data-rawheight=\"153\" class=\"content_image\" width=\"231\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;231&#39; height=&#39;153&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"231\" data-rawheight=\"153\" class=\"content_image lazy\" width=\"231\" data-actualsrc=\"https://pic1.zhimg.com/v2-ef7eb65059dce05de17d116164e82f40_b.jpg\"/></figure><p><b>2.将numpy.array转换为torch.Tensor</b></p><p>来看当改变numpy.array时，其相同储存位置对应的torch.Tensor也会同时被改变</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"kn\">as</span> <span class=\"nn\">np</span>\n<span class=\"n\">a</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"n\">b</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">from_numpy</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">out</span><span class=\"o\">=</span><span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic4.zhimg.com/v2-ae1e066a8d355fb41840e7c63394fa27_b.jpg\" data-caption=\"\" data-rawwidth=\"233\" data-rawheight=\"147\" class=\"content_image\" width=\"233\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;233&#39; height=&#39;147&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"233\" data-rawheight=\"147\" class=\"content_image lazy\" width=\"233\" data-actualsrc=\"https://pic4.zhimg.com/v2-ae1e066a8d355fb41840e7c63394fa27_b.jpg\"/></figure><p>所有CPU中的Tensor，除了CharTensor，都可以和numpy的array类型互相转换</p><p>Tensor有许多类型，包括：</p><blockquote>–ByteTensor – contains unsigned chars <br/>–CharTensor – contains signed chars <br/>–ShortTensor – contains shorts <br/>–IntTensor – contains ints <br/>–LongTensor – contains longs <br/>–FloatTensor – contains floats <br/>–DoubleTensor – contains doubles</blockquote><p>可以在定义时指定是什么类型的Tensor，默认的是FloatTensor：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">ByteTensor</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic4.zhimg.com/v2-f08d1707d7af3d5fc1644830791729eb_b.jpg\" data-caption=\"\" data-rawwidth=\"222\" data-rawheight=\"60\" class=\"content_image\" width=\"222\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;222&#39; height=&#39;60&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"222\" data-rawheight=\"60\" class=\"content_image lazy\" width=\"222\" data-actualsrc=\"https://pic4.zhimg.com/v2-f08d1707d7af3d5fc1644830791729eb_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic2.zhimg.com/v2-a84274b8dbeef459cfe68f7aecc11199_b.jpg\" data-caption=\"\" data-rawwidth=\"233\" data-rawheight=\"64\" class=\"content_image\" width=\"233\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;233&#39; height=&#39;64&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"233\" data-rawheight=\"64\" class=\"content_image lazy\" width=\"233\" data-actualsrc=\"https://pic2.zhimg.com/v2-a84274b8dbeef459cfe68f7aecc11199_b.jpg\"/></figure><p>CharTensor是不可以转换成numpy的array类型的：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">ct</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">CharTensor</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">ct</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic4.zhimg.com/v2-24213c2c4445423733095fd261a8f50b_b.jpg\" data-caption=\"\" data-rawwidth=\"232\" data-rawheight=\"65\" class=\"content_image\" width=\"232\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;232&#39; height=&#39;65&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"232\" data-rawheight=\"65\" class=\"content_image lazy\" width=\"232\" data-actualsrc=\"https://pic4.zhimg.com/v2-24213c2c4445423733095fd261a8f50b_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">ct</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span></code></pre></div><figure><noscript><img src=\"https://pic1.zhimg.com/v2-a933f5a17a631161c23bf26100fa33ec_b.jpg\" data-caption=\"\" data-rawwidth=\"543\" data-rawheight=\"129\" class=\"origin_image zh-lightbox-thumb\" width=\"543\" data-original=\"https://pic1.zhimg.com/v2-a933f5a17a631161c23bf26100fa33ec_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;543&#39; height=&#39;129&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"543\" data-rawheight=\"129\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"543\" data-original=\"https://pic1.zhimg.com/v2-a933f5a17a631161c23bf26100fa33ec_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a933f5a17a631161c23bf26100fa33ec_b.jpg\"/></figure><h2><b>CUDA Tensors</b></h2><p>Tensor类型的变量可以移动到GPU中，通过.cuda()</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"c1\">#let us run this cell only if CUDA is available</span>\n<span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">():</span>\n    <span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"p\">()</span>\n    <span class=\"n\">y</span><span class=\"o\">=</span><span class=\"n\">y</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"p\">()</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">+</span><span class=\"n\">y</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic1.zhimg.com/v2-24b1c4e0f5deaf3bac9c79e5ae45bff4_b.jpg\" data-caption=\"\" data-rawwidth=\"335\" data-rawheight=\"129\" class=\"content_image\" width=\"335\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;335&#39; height=&#39;129&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"335\" data-rawheight=\"129\" class=\"content_image lazy\" width=\"335\" data-actualsrc=\"https://pic1.zhimg.com/v2-24b1c4e0f5deaf3bac9c79e5ae45bff4_b.jpg\"/></figure><p>转移到GPU中的Tensor就不能转换成numpy的array类型了：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"n\">x_np</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span></code></pre></div><figure><noscript><img src=\"https://pic1.zhimg.com/v2-1f477f90d7dfcf265e6f116f377f36f8_b.jpg\" data-caption=\"\" data-rawwidth=\"543\" data-rawheight=\"290\" class=\"origin_image zh-lightbox-thumb\" width=\"543\" data-original=\"https://pic1.zhimg.com/v2-1f477f90d7dfcf265e6f116f377f36f8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;543&#39; height=&#39;290&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"543\" data-rawheight=\"290\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"543\" data-original=\"https://pic1.zhimg.com/v2-1f477f90d7dfcf265e6f116f377f36f8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-1f477f90d7dfcf265e6f116f377f36f8_b.jpg\"/></figure><p>而要放回CPU中才可以转换：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">x_np</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">cpu</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">numpy</span><span class=\"p\">()</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">x_np</span><span class=\"p\">)</span></code></pre></div><figure><noscript><img src=\"https://pic1.zhimg.com/v2-a42eb250acdb4ac0e9aa5f4f4e47bfe0_b.jpg\" data-caption=\"\" data-rawwidth=\"287\" data-rawheight=\"94\" class=\"content_image\" width=\"287\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;287&#39; height=&#39;94&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-rawwidth=\"287\" data-rawheight=\"94\" class=\"content_image lazy\" width=\"287\" data-actualsrc=\"https://pic1.zhimg.com/v2-a42eb250acdb4ac0e9aa5f4f4e47bfe0_b.jpg\"/></figure><hr/><p>PS：基本就是按<a href=\"https://link.zhihu.com/?target=http%3A//pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html%23sphx-glr-beginner-blitz-tensor-tutorial-py\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">官方文档</a>来的，我自己不清楚的地方会多写一点。</p>", 
            "topic": [
                {
                    "tag": "PyTorch", 
                    "tagLink": "https://api.zhihu.com/topics/20075993"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/29520148", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 3, 
            "title": "2014GAN理论推导", 
            "content": "<h2><b>符号说明</b></h2><p><img src=\"https://www.zhihu.com/equation?tex=p_%7Bdata%7D\" alt=\"p_{data}\" eeimg=\"1\"/> ：真实数据 <img src=\"https://www.zhihu.com/equation?tex=data\" alt=\"data\" eeimg=\"1\"/> 的分布</p><p><img src=\"https://www.zhihu.com/equation?tex=p_z\" alt=\"p_z\" eeimg=\"1\"/> ：噪声信号 <img src=\"https://www.zhihu.com/equation?tex=z\" alt=\"z\" eeimg=\"1\"/> 来自的分布</p><p><img src=\"https://www.zhihu.com/equation?tex=p_g\" alt=\"p_g\" eeimg=\"1\"/> ：假数据来自的分布，即生成网络G对应的分布</p><p><img src=\"https://www.zhihu.com/equation?tex=D%28x%3B%5Ctheta_d%29\" alt=\"D(x;\\theta_d)\" eeimg=\"1\"/> ：数据 <img src=\"https://www.zhihu.com/equation?tex=x\" alt=\"x\" eeimg=\"1\"/> 来自真实数据分布 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bdata%7D\" alt=\"p_{data}\" eeimg=\"1\"/> ，而非 <img src=\"https://www.zhihu.com/equation?tex=p_g%28x%29\" alt=\"p_g(x)\" eeimg=\"1\"/> 的概率</p><p><img src=\"https://www.zhihu.com/equation?tex=G%28z%3B%5Ctheta_g%29\" alt=\"G(z;\\theta_g)\" eeimg=\"1\"/> ：接收一个噪声信号 <img src=\"https://www.zhihu.com/equation?tex=z\" alt=\"z\" eeimg=\"1\"/> ，由分布 <img src=\"https://www.zhihu.com/equation?tex=p_g\" alt=\"p_g\" eeimg=\"1\"/> 产生一个假数据</p><h2><b>算法流程</b></h2><p>1、固定G网络，更新D网络：</p><ul><li>自分布 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bg%7D%28z%29\" alt=\"p_{g}(z)\" eeimg=\"1\"/> 采集 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> 个噪声样本： <img src=\"https://www.zhihu.com/equation?tex=%5C%7Bz%5E%7B%281%29%7D%2C%5Cldots%2Cz%5E%7B%28m%29%7D%5C%7D\" alt=\"\\{z^{(1)},\\ldots,z^{(m)}\\}\" eeimg=\"1\"/> </li><li>自分布 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bdata%7D%28x%29\" alt=\"p_{data}(x)\" eeimg=\"1\"/> 采集 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> 个真实数据样本： <img src=\"https://www.zhihu.com/equation?tex=%5C%7Bx%5E%7B%281%29%7D%2C%5Cldots%2Cx%5E%7B%28m%29%7D%5C%7D\" alt=\"\\{x^{(1)},\\ldots,x^{(m)}\\}\" eeimg=\"1\"/> </li><li>用随机梯度上升更新D网络，梯度信息为： <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla_%7B%5Ctheta_d%7D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%5BlogD%28x%5E%7B%28i%29%7D%29%2Blog%281-D%28G%28z%5E%7B%28i%29%7D%29%29%29%5D\" alt=\"\\nabla_{\\theta_d}\\frac{1}{m}\\sum_{i=1}^m[logD(x^{(i)})+log(1-D(G(z^{(i)})))]\" eeimg=\"1\"/> </li></ul><p>2、对D网络更新 <img src=\"https://www.zhihu.com/equation?tex=k\" alt=\"k\" eeimg=\"1\"/> 轮之后，固定D网络，更新一轮G网络</p><ul><li>自分布 <img src=\"https://www.zhihu.com/equation?tex=p_g%28z%29\" alt=\"p_g(z)\" eeimg=\"1\"/> 采集 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> 个噪声样本： <img src=\"https://www.zhihu.com/equation?tex=%5C%7Bz%5E%7B%281%29%7D%2C%5Cldots%2Cz%5E%7B%28m%29%7D%5C%7D\" alt=\"\\{z^{(1)},\\ldots,z^{(m)}\\}\" eeimg=\"1\"/> </li><li>用随机梯度下降更新G网络，梯度信息为： <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla_%7B%5Ctheta_g%7D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%5Blog%281-D%28G%28z%5E%7B%28i%29%7D%29%29%29%5D\" alt=\"\\nabla_{\\theta_g}\\frac{1}{m}\\sum_{i=1}^m[log(1-D(G(z^{(i)})))]\" eeimg=\"1\"/> </li></ul><p>3、返回1</p><h2><b>求解最优的D</b></h2><p>对给定的 <img src=\"https://www.zhihu.com/equation?tex=G\" alt=\"G\" eeimg=\"1\"/> ，最优的 <img src=\"https://www.zhihu.com/equation?tex=D%28x%3B%5Ctheta_d%29\" alt=\"D(x;\\theta_d)\" eeimg=\"1\"/> 为： <img src=\"https://www.zhihu.com/equation?tex=D%5E%2A_G%28x%29%3D%5Cfrac%7Bp_%7Bdata%7D%28x%29%7D%7Bp_%7Bdata%28x%29%7D%2Bp_g%28x%29%7D\" alt=\"D^*_G(x)=\\frac{p_{data}(x)}{p_{data(x)}+p_g(x)}\" eeimg=\"1\"/> </p><p><b><i>证明：</i></b></p><p>对抗网络整体的优化目标为：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmin%5Climits_%7BG%7D%5Cmax%5Climits_%7BD%7DV%28G%2CD%29%3D%5Cmathbb%7BE%7D_%7Bx%5Csim+p_%7Bdata%7D%7D%5BlogD%28x%29%5D%2B%5Cmathbb%7BE%7D_%7Bz%5Csim+p_z%7D%5Blog%281-D%28G%28z%29%29%29%5D\" alt=\"\\min\\limits_{G}\\max\\limits_{D}V(G,D)=\\mathbb{E}_{x\\sim p_{data}}[logD(x)]+\\mathbb{E}_{z\\sim p_z}[log(1-D(G(z)))]\" eeimg=\"1\"/> </p><p>当固定 <img src=\"https://www.zhihu.com/equation?tex=G\" alt=\"G\" eeimg=\"1\"/> 之后，接下来最大化 <img src=\"https://www.zhihu.com/equation?tex=V%28G%2CD%29\" alt=\"V(G,D)\" eeimg=\"1\"/> ：</p><p><img src=\"https://www.zhihu.com/equation?tex=V%28G%2CD%29%3D%5Cmathbb%7BE%7D_%7Bx%5Csim+p_%7Bdata%7D%7D%5BlogD%28x%29%5D%2B%5Cmathbb%7BE%7D_%7Bz%5Csim+p_z%7D%5Blog%281-D%28G%28z%29%29%29%5D\" alt=\"V(G,D)=\\mathbb{E}_{x\\sim p_{data}}[logD(x)]+\\mathbb{E}_{z\\sim p_z}[log(1-D(G(z)))]\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Cmathbb%7BE%7D_%7Bx%5Csim+p_%7Bdata%7D%7D%5BlogD%28x%29%5D%2B%5Cmathbb%7BE%7D_%7Bx%5Csim+p_g%7D%5Blog%281-D%28x%29%29%5D\" alt=\"=\\mathbb{E}_{x\\sim p_{data}}[logD(x)]+\\mathbb{E}_{x\\sim p_g}[log(1-D(x))]\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Csum_x%5Bp_%7Bdata%7D%28x%29logD%28x%29%2Bp_g%28x%29log%281-D%28x%29%29%5D\" alt=\"=\\sum_x[p_{data}(x)logD(x)+p_g(x)log(1-D(x))]\" eeimg=\"1\"/> </p><p>对于形如 <img src=\"https://www.zhihu.com/equation?tex=f%28y%29%3Dalog%28y%29%2Bblog%281-y%29\" alt=\"f(y)=alog(y)+blog(1-y)\" eeimg=\"1\"/> 的函数，其中 <img src=\"https://www.zhihu.com/equation?tex=a%2Cb%5Cin%5Cmathbb%7BR%7D\" alt=\"a,b\\in\\mathbb{R}\" eeimg=\"1\"/> 且 <img src=\"https://www.zhihu.com/equation?tex=a%2Cb%5Cne0\" alt=\"a,b\\ne0\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=y%5Cin%5B0%2C1%5D\" alt=\"y\\in[0,1]\" eeimg=\"1\"/> 。在 <img src=\"https://www.zhihu.com/equation?tex=y%3D%5Cfrac%7Ba%7D%7Ba%2Bb%7D\" alt=\"y=\\frac{a}{a+b}\" eeimg=\"1\"/> 处取得极大值。故固定 <img src=\"https://www.zhihu.com/equation?tex=G\" alt=\"G\" eeimg=\"1\"/> 后最优的 <img src=\"https://www.zhihu.com/equation?tex=D\" alt=\"D\" eeimg=\"1\"/> 为：</p><p><img src=\"https://www.zhihu.com/equation?tex=D%5E%2A_G%28x%29%3D%5Cfrac%7Bp_%7Bdata%7D%28x%29%7D%7Bp_%7Bdata%28x%29%7D%2Bp_g%28x%29%7D\" alt=\"D^*_G(x)=\\frac{p_{data}(x)}{p_{data(x)}+p_g(x)}\" eeimg=\"1\"/> </p><h2><b>求解最优的G</b></h2><p>固定 <img src=\"https://www.zhihu.com/equation?tex=D\" alt=\"D\" eeimg=\"1\"/> 求解最优 <img src=\"https://www.zhihu.com/equation?tex=G%28z%3B%5Ctheta_g%29\" alt=\"G(z;\\theta_g)\" eeimg=\"1\"/> 的最后结果为 <img src=\"https://www.zhihu.com/equation?tex=p_g%3Dp_%7Bdata%7D\" alt=\"p_g=p_{data}\" eeimg=\"1\"/> </p><p><i><b>证明</b></i></p><p>当求得最优的 <img src=\"https://www.zhihu.com/equation?tex=D%3DD_G%5E%2A\" alt=\"D=D_G^*\" eeimg=\"1\"/> 之后，最小化 <img src=\"https://www.zhihu.com/equation?tex=V%28G%2CD_G%5E%2A%29\" alt=\"V(G,D_G^*)\" eeimg=\"1\"/> ：</p><p><img src=\"https://www.zhihu.com/equation?tex=V%28G%2CD_G%5E%2A%29%3D%5Cmathbb%7BE%7D_%7Bx%5Csim+p_%7Bdata%7D%7D%5BlogD_G%5E%2A%28x%29%5D%2B%5Cmathbb%7BE%7D_%7Bz%5Csim+p_z%7D%5Blog%281-D%5E%2A_G%28G%28z%29%29%29%5D\" alt=\"V(G,D_G^*)=\\mathbb{E}_{x\\sim p_{data}}[logD_G^*(x)]+\\mathbb{E}_{z\\sim p_z}[log(1-D^*_G(G(z)))]\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Cmathbb%7BE%7D_%7Bx%5Csim+p_%7Bdata%7D%7D%5BlogD_G%5E%2A%28x%29%5D%2B%5Cmathbb%7BE%7D_%7Bx%5Csim+p_g%7D%5Blog%281-D%5E%2A_G%28x%29%29%5D\" alt=\"=\\mathbb{E}_{x\\sim p_{data}}[logD_G^*(x)]+\\mathbb{E}_{x\\sim p_g}[log(1-D^*_G(x))]\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Cmathbb%7BE%7D_%7Bx%5Csim+p_%7Bdata%7D%7D%5Blog%28%5Cfrac%7Bp_%7Bdata%7D%28x%29%7D%7B%7Bp_g%28x%29%2Bp_%7Bdata%7D%28x%29%7D%7D%29%5D%2B%5Cmathbb%7BE%7D_%7Bx%5Csim+p_g%7D%5Blog%28%5Cfrac%7Bp_g%28x%29%7D%7Bp_g%28x%29%2Bp_%7Bdata%7D%28x%29%7D%29%5D\" alt=\"=\\mathbb{E}_{x\\sim p_{data}}[log(\\frac{p_{data}(x)}{{p_g(x)+p_{data}(x)}})]+\\mathbb{E}_{x\\sim p_g}[log(\\frac{p_g(x)}{p_g(x)+p_{data}(x)})]\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Csum_xp_%7Bdata%7D%28x%29log%5Cfrac%7Bp_%7Bdata%7D%28x%29%7D%7Bp_g%28x%29%2Bp_%7Bdata%7D%28x%29%7D%2B%5Csum_xp_g%28x%29log%5Cfrac%7Bp_%7Bg%7D%28x%29%7D%7Bp_g%28x%29%2Bp_%7Bdata%7D%28x%29%7D\" alt=\"=\\sum_xp_{data}(x)log\\frac{p_{data}(x)}{p_g(x)+p_{data}(x)}+\\sum_xp_g(x)log\\frac{p_{g}(x)}{p_g(x)+p_{data}(x)}\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Csum_xp_%7Bdata%7D%28x%29%5Blog%5Cfrac%7Bp_%7Bdata%7D%28x%29%7D%7B%5Cfrac%7Bp_g%28x%29%2Bp_%7Bdata%7D%28x%29%7D%7B2%7D%7D-1%5D%2B%5Csum_xp_g%28x%29%5Blog%5Cfrac%7Bp_%7Bg%7D%28x%29%7D%7B%5Cfrac%7Bp_g%28x%29%2Bp_%7Bdata%7D%28x%29%7D%7B2%7D%7D-1%5D\" alt=\"=\\sum_xp_{data}(x)[log\\frac{p_{data}(x)}{\\frac{p_g(x)+p_{data}(x)}{2}}-1]+\\sum_xp_g(x)[log\\frac{p_{g}(x)}{\\frac{p_g(x)+p_{data}(x)}{2}}-1]\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Csum_xp_%7Bdata%7D%28x%29log%5Cfrac%7Bp_%7Bdata%7D%28x%29%7D%7B%5Cfrac%7Bp_g%28x%29%2Bp_%7Bdata%7D%28x%29%7D%7B2%7D%7D-%5Csum_xp_%7Bdata%7D%28x%29%2B%5Csum_xp_g%28x%29log%5Cfrac%7Bp_%7Bg%7D%28x%29%7D%7B%5Cfrac%7Bp_g%28x%29%2Bp_%7Bdata%7D%28x%29%7D%7B2%7D%7D-%5Csum_xp_g%28x%29\" alt=\"=\\sum_xp_{data}(x)log\\frac{p_{data}(x)}{\\frac{p_g(x)+p_{data}(x)}{2}}-\\sum_xp_{data}(x)+\\sum_xp_g(x)log\\frac{p_{g}(x)}{\\frac{p_g(x)+p_{data}(x)}{2}}-\\sum_xp_g(x)\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5Csum_xp_%7Bdata%7D%28x%29log%5Cfrac%7Bp_%7Bdata%7D%28x%29%7D%7B%5Cfrac%7Bp_g%28x%29%2Bp_%7Bdata%7D%28x%29%7D%7B2%7D%7D%2B%5Csum_xp_g%28x%29log%5Cfrac%7Bp_%7Bg%7D%28x%29%7D%7B%5Cfrac%7Bp_g%28x%29%2Bp_%7Bdata%7D%28x%29%7D%7B2%7D%7D-2\" alt=\"=\\sum_xp_{data}(x)log\\frac{p_{data}(x)}{\\frac{p_g(x)+p_{data}(x)}{2}}+\\sum_xp_g(x)log\\frac{p_{g}(x)}{\\frac{p_g(x)+p_{data}(x)}{2}}-2\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3DKL%28p_%7Bdata%7D%7C%7C%5Cfrac%7Bp_g%2Bp_%7Bdata%7D%7D%7B2%7D%29%2BKL%28p_%7Bg%7D%7C%7C%5Cfrac%7Bp_g%2Bp_%7Bdata%7D%7D%7B2%7D%29-2\" alt=\"=KL(p_{data}||\\frac{p_g+p_{data}}{2})+KL(p_{g}||\\frac{p_g+p_{data}}{2})-2\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D2JS%28p_%7Bdata%7D%7C%7Cp_g%29-log%284%29\" alt=\"=2JS(p_{data}||p_g)-log(4)\" eeimg=\"1\"/> </p><p>由于JS散度非负，且两分布相等时取零，即 <img src=\"https://www.zhihu.com/equation?tex=JS%28p_%7Bdata%7D%7C%7Cp_g%29%5Cge0\" alt=\"JS(p_{data}||p_g)\\ge0\" eeimg=\"1\"/> 当 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bdata%7D%3Dp_g\" alt=\"p_{data}=p_g\" eeimg=\"1\"/> 时取 <img src=\"https://www.zhihu.com/equation?tex=0\" alt=\"0\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=V%28G%2CD_G%5E%2A%29\" alt=\"V(G,D_G^*)\" eeimg=\"1\"/> 最小值为 <img src=\"https://www.zhihu.com/equation?tex=-log%284%29\" alt=\"-log(4)\" eeimg=\"1\"/> 。即通过求解 <img src=\"https://www.zhihu.com/equation?tex=%5Cmin%5Climits_%7BG%7D%5Cmax%5Climits_%7BD%7DV%28G%2CD%29\" alt=\"\\min\\limits_{G}\\max\\limits_{D}V(G,D)\" eeimg=\"1\"/> 可以使 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bg%7D\" alt=\"p_{g}\" eeimg=\"1\"/> 逼近真实数据分布 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bdata%7D\" alt=\"p_{data}\" eeimg=\"1\"/> 。</p><p></p><p></p><p></p><p></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "生成对抗网络（GAN）", 
                    "tagLink": "https://api.zhihu.com/topics/20070859"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/28623599", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 84, 
            "title": "共轭梯度法", 
            "content": "<h2><b>概述</b></h2><p>共轭梯度法是用来解决无约束凸二次规划问题的一种方法。其思路为，对于一个目标函数 <img src=\"https://www.zhihu.com/equation?tex=%5Cmathop%5Cmin_xf%28x%29\" alt=\"\\mathop\\min_xf(x)\" eeimg=\"1\"/> ，找到一组方向向量 <img src=\"https://www.zhihu.com/equation?tex=d_1%2C%5Cldots%2Cd_n%5Cin%5Cmathbb%7BR%7D%5En+\" alt=\"d_1,\\ldots,d_n\\in\\mathbb{R}^n \" eeimg=\"1\"/> ，<b>依次</b>按此方向组中的方向对迭代点 <img src=\"https://www.zhihu.com/equation?tex=x_i%5Cin%5Cmathbb%7BR%7D%5En\" alt=\"x_i\\in\\mathbb{R}^n\" eeimg=\"1\"/> 进行更新，对每一个更新方向 <img src=\"https://www.zhihu.com/equation?tex=d_i\" alt=\"d_i\" eeimg=\"1\"/> ，找到合适的步长 <img src=\"https://www.zhihu.com/equation?tex=%5Clambda_i\" alt=\"\\lambda_i\" eeimg=\"1\"/> ，使得 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 在该方向上取得最小值。要求是，在每一个新的更新方向 <img src=\"https://www.zhihu.com/equation?tex=d_k\" alt=\"d_k\" eeimg=\"1\"/> 对迭代点 <img src=\"https://www.zhihu.com/equation?tex=x_k\" alt=\"x_k\" eeimg=\"1\"/> 进行更新时，不会影响在之前方向 <img src=\"https://www.zhihu.com/equation?tex=d_j%28j%5Cle+k-1%29\" alt=\"d_j(j\\le k-1)\" eeimg=\"1\"/> 上的更新结果，即 <img src=\"https://www.zhihu.com/equation?tex=x_%7Bk%2B1%7D\" alt=\"x_{k+1}\" eeimg=\"1\"/> 不仅使 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 在 <img src=\"https://www.zhihu.com/equation?tex=d_k\" alt=\"d_k\" eeimg=\"1\"/> 方向上取得最小值，且在 <img src=\"https://www.zhihu.com/equation?tex=d_j%28j%5Cle+k-1%29\" alt=\"d_j(j\\le k-1)\" eeimg=\"1\"/> 方向上均保持最小值。如果能找到这样一组方向 <img src=\"https://www.zhihu.com/equation?tex=d_1%2C%5Cldots%2Cd_n%5Cin%5Cmathbb%7BR%7D%5En\" alt=\"d_1,\\ldots,d_n\\in\\mathbb{R}^n\" eeimg=\"1\"/> ，那么可以保证在迭代 <img src=\"https://www.zhihu.com/equation?tex=n\" alt=\"n\" eeimg=\"1\"/> 次之后找到 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 的全局极小点。</p><h2><b>基本概念</b></h2><h2>A.无约束凸二次规划问题</h2><p><b>1、问题描述</b></p><p>这样的问题称为无约束凸二次规划问题： <img src=\"https://www.zhihu.com/equation?tex=%5Cmathop%7Bmin%7D_xf%28x%29%3D%5Cfrac%7B1%7D%7B2%7Dx%5ETQx%2Bq%5ETx+\" alt=\"\\mathop{min}_xf(x)=\\frac{1}{2}x^TQx+q^Tx \" eeimg=\"1\"/> ，其中 <img src=\"https://www.zhihu.com/equation?tex=Q%5Cin%5Cmathbb%7BR%7D%5E%7Bn%5Ctimes+n%7D\" alt=\"Q\\in\\mathbb{R}^{n\\times n}\" eeimg=\"1\"/> 为对称正定矩阵， <img src=\"https://www.zhihu.com/equation?tex=q%5Cin+%5Cmathbb%7BR%7D%5En\" alt=\"q\\in \\mathbb{R}^n\" eeimg=\"1\"/> 。</p><p><b>2、为何称为“凸”</b></p><p><img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 为正定矩阵的条件使得 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 为凸函数，这涉及到凸函数辨识的二阶充要条件：设 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29%3AS%5Crightarrow%5Cmathbb%7BR%7D\" alt=\"f(x):S\\rightarrow\\mathbb{R}\" eeimg=\"1\"/> 是定义在 <img src=\"https://www.zhihu.com/equation?tex=n\" alt=\"n\" eeimg=\"1\"/> 维向量空间 <img src=\"https://www.zhihu.com/equation?tex=%5Cmathbb%7BR%7D%5En\" alt=\"\\mathbb{R}^n\" eeimg=\"1\"/> 内的凸集 <img src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/> 上的函数，且可以二次微分。当且仅当其 <img src=\"https://www.zhihu.com/equation?tex=Hessian\" alt=\"Hessian\" eeimg=\"1\"/> 矩阵正定 <img src=\"https://www.zhihu.com/equation?tex=H_xf%28x%29%3D%5Cfrac%7B%5Cpartial%5E2f%28x%29%7D%7B%5Cpartial+x%5Cpartial+x%5ET%7D%5Csucc0%EF%BC%8C%5Cforall+x%5Cin+S\" alt=\"H_xf(x)=\\frac{\\partial^2f(x)}{\\partial x\\partial x^T}\\succ0，\\forall x\\in S\" eeimg=\"1\"/> ，则称 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 为严格凸函数。</p><p>对于 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29%3D%5Cfrac%7B1%7D%7B2%7Dx%5ETQx%2Bq%5ETx\" alt=\"f(x)=\\frac{1}{2}x^TQx+q^Tx\" eeimg=\"1\"/> 而言， <img src=\"https://www.zhihu.com/equation?tex=H_xf%28x%29%3DQ\" alt=\"H_xf(x)=Q\" eeimg=\"1\"/> ，已知 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 为正定矩阵，故 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 为严格凸函数。</p><p><b>3、最优解的充要条件</b></p><p>有这样一个定理：无约束凸函数 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 的任何局部极小点 <img src=\"https://www.zhihu.com/equation?tex=x%5E%2A\" alt=\"x^*\" eeimg=\"1\"/> 都是该函数的一个全局极小点，若该函数是可微的，则满足 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%28x%29%7D%7B%5Cpartial+x%7D%3D0\" alt=\"\\frac{\\partial f(x)}{\\partial x}=0\" eeimg=\"1\"/> 的平稳点 <img src=\"https://www.zhihu.com/equation?tex=x%5E%2A\" alt=\"x^*\" eeimg=\"1\"/> 是 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 的一个全局极小点。所以， <img src=\"https://www.zhihu.com/equation?tex=x%5E%2A\" alt=\"x^*\" eeimg=\"1\"/> 为之上无约束凸二次规划问题的最优解的充要条件为： <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x%5E%2A%29%3D0\" alt=\"\\nabla f(x^*)=0\" eeimg=\"1\"/> </p><h2>B.共轭方向组</h2><p><b>1、定义</b></p><p>设 <img src=\"https://www.zhihu.com/equation?tex=Q%5Cin+%5Cmathbb%7BR%7D%5E%7Bn%5Ctimes+n%7D\" alt=\"Q\\in \\mathbb{R}^{n\\times n}\" eeimg=\"1\"/> 为对称正定矩阵， <img src=\"https://www.zhihu.com/equation?tex=d_1%2C%5Cldots%2Cd_m%5Cin+%5Cmathbb%7BR%7D%5En\" alt=\"d_1,\\ldots,d_m\\in \\mathbb{R}^n\" eeimg=\"1\"/> ，若对于 <img src=\"https://www.zhihu.com/equation?tex=i%2Cj%3D1%2C%5Cldots+%2Cm\" alt=\"i,j=1,\\ldots ,m\" eeimg=\"1\"/> ，有这样的关系： <img src=\"https://www.zhihu.com/equation?tex=d_i%5ETQd_j%3D0%2Ci%5Cne+j\" alt=\"d_i^TQd_j=0,i\\ne j\" eeimg=\"1\"/> 。则称 <img src=\"https://www.zhihu.com/equation?tex=d_1%2C%5Cldots%2Cd_m\" alt=\"d_1,\\ldots,d_m\" eeimg=\"1\"/> 关于 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 相互共轭，称为 <img src=\"https://www.zhihu.com/equation?tex=Q-\" alt=\"Q-\" eeimg=\"1\"/> 共轭方向组。</p><p><b>2、共轭方向组同时也是线性无关方向组</b></p><p><b>定理</b>：设 <img src=\"https://www.zhihu.com/equation?tex=Q%5Cin+%5Cmathbb%7BR%7D%5E%7Bn%5Ctimes+n%7D\" alt=\"Q\\in \\mathbb{R}^{n\\times n}\" eeimg=\"1\"/> 为对称正定矩阵，非零向量组 <img src=\"https://www.zhihu.com/equation?tex=d_1%2C%5Cldots%2Cd_m\" alt=\"d_1,\\ldots,d_m\" eeimg=\"1\"/> 是 <img src=\"https://www.zhihu.com/equation?tex=Q-\" alt=\"Q-\" eeimg=\"1\"/> 共轭方向组，则 <img src=\"https://www.zhihu.com/equation?tex=d_1%2C%5Cdots%2Cd_m\" alt=\"d_1,\\dots,d_m\" eeimg=\"1\"/> 也是线性无关方向组。</p><p><b>证明</b>：设有一组实数 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha_1%2C%5Cldots%2C%5Calpha_m\" alt=\"\\alpha_1,\\ldots,\\alpha_m\" eeimg=\"1\"/> 使得： <img src=\"https://www.zhihu.com/equation?tex=%5Calpha_1d_1%2B%5Ccdots%2B%5Calpha_md_m%3D0\" alt=\"\\alpha_1d_1+\\cdots+\\alpha_md_m=0\" eeimg=\"1\"/> 。用 <img src=\"https://www.zhihu.com/equation?tex=d_i%5ETQ%2C%28i%3D1%2C%5Cldots%2Cm%29\" alt=\"d_i^TQ,(i=1,\\ldots,m)\" eeimg=\"1\"/> ，分别左乘上式，得到 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> 个等式。由 <img src=\"https://www.zhihu.com/equation?tex=d_i%5ETQd_j%3D0%2C%28i%5Cne+j%29\" alt=\"d_i^TQd_j=0,(i\\ne j)\" eeimg=\"1\"/> ，得到这 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> 个等式等号左侧只有一项，为： <img src=\"https://www.zhihu.com/equation?tex=d_i%5ETQd_i\" alt=\"d_i^TQd_i\" eeimg=\"1\"/> ；等号右侧为：0。即：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Calpha_id_i%5ETQd_i%3D0%2C%28i%3D1%2C%5Cldots%2Cm%29\" alt=\"\\alpha_id_i^TQd_i=0,(i=1,\\ldots,m)\" eeimg=\"1\"/> 。由于 <img src=\"https://www.zhihu.com/equation?tex=Q\" alt=\"Q\" eeimg=\"1\"/> 为正定的，由于正定矩阵的二次型大于零，故 <img src=\"https://www.zhihu.com/equation?tex=d_i%5ETQd_i%3E0\" alt=\"d_i^TQd_i&gt;0\" eeimg=\"1\"/> ，于是得到： <img src=\"https://www.zhihu.com/equation?tex=%5Calpha_i%3D0%2C%28i%3D1%2C%5Cldots%2Cm%29\" alt=\"\\alpha_i=0,(i=1,\\ldots,m)\" eeimg=\"1\"/> 。由线性无关方向组的定义，找不到一组非零实数 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha_i%28i%3D1%2C%5Cldots%2Cm%29\" alt=\"\\alpha_i(i=1,\\ldots,m)\" eeimg=\"1\"/> 使得 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha_1d_1%2B%5Ccdots%2B%5Calpha_md_m%3D0\" alt=\"\\alpha_1d_1+\\cdots+\\alpha_md_m=0\" eeimg=\"1\"/> ，则 <img src=\"https://www.zhihu.com/equation?tex=d_i%2C%5Cldots%2Cd_m\" alt=\"d_i,\\ldots,d_m\" eeimg=\"1\"/> 为线性无关方向组。</p><h2><b>共轭梯度法描述</b></h2><p>以下需要证明，以一个 <img src=\"https://www.zhihu.com/equation?tex=Q-\" alt=\"Q-\" eeimg=\"1\"/> 共轭方向组为更新方向依次更新，可以最终找到全剧最小值。</p><h2>A.按某一方向进行更新的最优步长</h2><p>在迭代点 <img src=\"https://www.zhihu.com/equation?tex=x_k%5Cin+%5Cmathbb%7BR%7D%5En\" alt=\"x_k\\in \\mathbb{R}^n\" eeimg=\"1\"/> 处，沿非零方向 <img src=\"https://www.zhihu.com/equation?tex=d_k\" alt=\"d_k\" eeimg=\"1\"/> 进行一维搜索，步长为 <img src=\"https://www.zhihu.com/equation?tex=%5Clambda_k\" alt=\"\\lambda_k\" eeimg=\"1\"/> ，目的是找到在 <img src=\"https://www.zhihu.com/equation?tex=d_k\" alt=\"d_k\" eeimg=\"1\"/> 方向上 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 的极小值。则需要满足： <img src=\"https://www.zhihu.com/equation?tex=%5Clambda_k%3D%5Cmathop%7Bargmin%7D_tf%28x_k%2B%5Clambda_kd_k%29\" alt=\"\\lambda_k=\\mathop{argmin}_tf(x_k+\\lambda_kd_k)\" eeimg=\"1\"/>。因为 <img src=\"https://www.zhihu.com/equation?tex=x_%7Bk%2B1%7D%3Dx_k%2B%5Clambda_kd_k\" alt=\"x_{k+1}=x_k+\\lambda_kd_k\" eeimg=\"1\"/> 使得 <img src=\"https://www.zhihu.com/equation?tex=f%28x%29\" alt=\"f(x)\" eeimg=\"1\"/> 在<img src=\"https://www.zhihu.com/equation?tex=d_k\" alt=\"d_k\" eeimg=\"1\"/> 方向取到最小值，所以有：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7Bdf%28x_k%2B%5Clambda+d_k%29%7D%7Bd%5Clambda%7D%7C_%7B%5Clambda%3D%5Clambda_k%7D%3D0\" alt=\"\\frac{df(x_k+\\lambda d_k)}{d\\lambda}|_{\\lambda=\\lambda_k}=0\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=d_k%5ET%5Ctimes+%5Cnabla+f%28x_%7Bk%2B1%7D%29%3D0\" alt=\"d_k^T\\times \\nabla f(x_{k+1})=0\" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_%7Bk%2B1%7D%29%3DQx_%7Bk%2B1%7D%2Bq%3DQ%28x_%7Bk%2B1%7D-x_k%29%2B%5Cnabla+f%28x_k%29\" alt=\"\\nabla f(x_{k+1})=Qx_{k+1}+q=Q(x_{k+1}-x_k)+\\nabla f(x_k)\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=d_k%5ET%5Ctimes+%28Q%28x_%7Bk%2B1%7D-x_k%29%2B%5Cnabla+f%28x_k%29%29%3D0\" alt=\"d_k^T\\times (Q(x_{k+1}-x_k)+\\nabla f(x_k))=0\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=d_k%5ET%5Ctimes+%28Q%28%5Clambda_kd_k%29%2B%5Cnabla+f%28x_k%29%29%3D0\" alt=\"d_k^T\\times (Q(\\lambda_kd_k)+\\nabla f(x_k))=0\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5CRightarrow%5Cqquad%5Clambda_k%3D%5Cfrac%7B-d_k%5ET%5Cnabla+f%28x_k%29%7D%7Bd_k%5ETQd_k%7D\" alt=\"\\Rightarrow\\qquad\\lambda_k=\\frac{-d_k^T\\nabla f(x_k)}{d_k^TQd_k}\" eeimg=\"1\"/> </p><h2>B.以一组共轭向量为更新方向最终会得到全局最小值</h2><p><b>证明</b>：在以 <img src=\"https://www.zhihu.com/equation?tex=Q-\" alt=\"Q-\" eeimg=\"1\"/> 共轭方向组为更新方向时， <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_k%29\" alt=\"\\nabla f(x_k)\" eeimg=\"1\"/> 与更新方向 <img src=\"https://www.zhihu.com/equation?tex=d_0%2C%5Cldots%2Cd_%7Bk-1%7D\" alt=\"d_0,\\ldots,d_{k-1}\" eeimg=\"1\"/> 均正交。</p><p>从 <img src=\"https://www.zhihu.com/equation?tex=x_0\" alt=\"x_0\" eeimg=\"1\"/> 出发，依次沿 <img src=\"https://www.zhihu.com/equation?tex=d_0%2C%5Cldots%2Cd_%7Bk-1%7D\" alt=\"d_0,\\ldots,d_{k-1}\" eeimg=\"1\"/> 进行一维搜索，点的更新步长为上一步求出的最优步长<img src=\"https://www.zhihu.com/equation?tex=%5Clambda_0%2C%5Cldots%2C%5Clambda_%7Bk-1%7D\" alt=\"\\lambda_0,\\ldots,\\lambda_{k-1}\" eeimg=\"1\"/> 。</p><p><img src=\"https://www.zhihu.com/equation?tex=x_k%3Dx_%7Bi%2B1%7D%2B%5Csum_%7Bj%3Di%2B1%7D%5E%7Bk-1%7D%5Clambda_jd_j%2C%5Cqquad%28i%3D0%2C%5Cldots%2Ck-1%29\" alt=\"x_k=x_{i+1}+\\sum_{j=i+1}^{k-1}\\lambda_jd_j,\\qquad(i=0,\\ldots,k-1)\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5CRightarrow%5Cqquad+%5Cnabla+f%28x_k%29%3DQx_k%2Bq%3DQx_%7Bi%2B1%7D%2B%5Csum_%7Bj%3Di%2B1%7D%5E%7Bk-1%7D%5Clambda_jQd_j%2Bq%3D%5Cnabla+f%28x_%7Bi%2B1%7D%29%2B%5Csum_%7Bj%3Di%2B1%7D%5E%7Bk-1%7D%5Clambda_jQd_j\" alt=\"\\Rightarrow\\qquad \\nabla f(x_k)=Qx_k+q=Qx_{i+1}+\\sum_{j=i+1}^{k-1}\\lambda_jQd_j+q=\\nabla f(x_{i+1})+\\sum_{j=i+1}^{k-1}\\lambda_jQd_j\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5CRightarrow%5Cqquad+d_i%5ET%5Cnabla+f%28x_k%29%3Dd_i%5ET%5Cnabla+f%28x_%7Bi%2B1%7D%29%2B%5Csum_%7Bj%3Di%2B1%7D%5E%7Bk-1%7D%5Clambda_jd_i%5ETQd_j\" alt=\"\\Rightarrow\\qquad d_i^T\\nabla f(x_k)=d_i^T\\nabla f(x_{i+1})+\\sum_{j=i+1}^{k-1}\\lambda_jd_i^TQd_j\" eeimg=\"1\"/> </p><p class=\"ztext-empty-paragraph\"><br/></p><p>由 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7Bdf%28x_i%2B%5Clambda+d_i%29%7D%7Bd%5Clambda%7D%7C_%7B%5Clambda%3D%5Clambda_i%7D%3D0%5Cqquad%5CRightarrow%5Cqquad+d_i%5ET%5Cnabla+f%28x_%7Bi%2B1%7D%29%3D0\" alt=\"\\frac{df(x_i+\\lambda d_i)}{d\\lambda}|_{\\lambda=\\lambda_i}=0\\qquad\\Rightarrow\\qquad d_i^T\\nabla f(x_{i+1})=0\" eeimg=\"1\"/> </p><p>由 <img src=\"https://www.zhihu.com/equation?tex=d_0%2C%5Cldots%2Cd_%7Bk-1%7D\" alt=\"d_0,\\ldots,d_{k-1}\" eeimg=\"1\"/> 为 <img src=\"https://www.zhihu.com/equation?tex=Q-\" alt=\"Q-\" eeimg=\"1\"/> 共轭方向组 <img src=\"https://www.zhihu.com/equation?tex=%5Cqquad%5CRightarrow%5Cqquad%5Csum_%7Bj%3Di%2B1%7D%5E%7Bk-1%7D%5Clambda_jd_i%5ETQd_j%3D0\" alt=\"\\qquad\\Rightarrow\\qquad\\sum_{j=i+1}^{k-1}\\lambda_jd_i^TQd_j=0\" eeimg=\"1\"/> </p><p>所以 <img src=\"https://www.zhihu.com/equation?tex=d_i%5ET%5Cnabla+f%28x_k%29%3D0%2C%28i%3D0%2C%5Cldots%2Ck-1%29\" alt=\"d_i^T\\nabla f(x_k)=0,(i=0,\\ldots,k-1)\" eeimg=\"1\"/> </p><p>即对于 <img src=\"https://www.zhihu.com/equation?tex=Q-\" alt=\"Q-\" eeimg=\"1\"/> 共轭方向组来说， <img src=\"https://www.zhihu.com/equation?tex=d_i%28i%3D0%2C%5Cldots%2Ck-1%29\" alt=\"d_i(i=0,\\ldots,k-1)\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_k%29\" alt=\"\\nabla f(x_k)\" eeimg=\"1\"/> 是正交的。当 <img src=\"https://www.zhihu.com/equation?tex=k%3Dn\" alt=\"k=n\" eeimg=\"1\"/> 时， <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_n%29\" alt=\"\\nabla f(x_n)\" eeimg=\"1\"/> 与 <img src=\"https://www.zhihu.com/equation?tex=d_i%28i%3D0%2C%5Cldots%2Cn-1%29\" alt=\"d_i(i=0,\\ldots,n-1)\" eeimg=\"1\"/> 正交，而 <img src=\"https://www.zhihu.com/equation?tex=d_i%28i%3D0%2C%5Cldots%2Cn-1%29\" alt=\"d_i(i=0,\\ldots,n-1)\" eeimg=\"1\"/> 之间是线性无关的。 <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_n%29%2Cx%5Cin+%5Cmathbb%7BR%7D%5En\" alt=\"\\nabla f(x_n),x\\in \\mathbb{R}^n\" eeimg=\"1\"/> 与 <img src=\"https://www.zhihu.com/equation?tex=n\" alt=\"n\" eeimg=\"1\"/> 个线性无关向量正交，故 <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_n%29%3D0\" alt=\"\\nabla f(x_n)=0\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=x_n\" alt=\"x_n\" eeimg=\"1\"/> 是该无约束凸二次规划问题的最优解。</p><h2>C.在每一个迭代点处如何产生下一个共轭方向</h2><p>先说结果再证明。令 <img src=\"https://www.zhihu.com/equation?tex=d_%7Bk%2B1%7D%3D-%5Cnabla+f%28x_%7Bk%2B1%7D%29%2B%5Cgamma_kd_k\" alt=\"d_{k+1}=-\\nabla f(x_{k+1})+\\gamma_kd_k\" eeimg=\"1\"/> ，</p><p>由 <img src=\"https://www.zhihu.com/equation?tex=d_k%5ETQd_%7Bk%2B1%7D%3D0\" alt=\"d_k^TQd_{k+1}=0\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5CRightarrow%5Cqquad+d_k%5ETQ%28-%5Cnabla+f%28x_%7Bk%2B1%7D%29%2B%5Cgamma_kd_k%29%3D0\" alt=\"\\Rightarrow\\qquad d_k^TQ(-\\nabla f(x_{k+1})+\\gamma_kd_k)=0\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5CRightarrow%5Cqquad%5Cgamma_k%3D%5Cfrac%7Bd_k%5ETQ%5Cnabla+f%28x_%7Bk%2B1%7D%29%7D%7Bd_k%5ETQd_k%7D\" alt=\"\\Rightarrow\\qquad\\gamma_k=\\frac{d_k^TQ\\nabla f(x_{k+1})}{d_k^TQd_k}\" eeimg=\"1\"/> </p><p>按这种方式由当前迭代点梯度 <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_%7Bk%2B1%7D%29\" alt=\"\\nabla f(x_{k+1})\" eeimg=\"1\"/> 和上一个更新方向 <img src=\"https://www.zhihu.com/equation?tex=d_k\" alt=\"d_k\" eeimg=\"1\"/> ，来确定新的更新方向 <img src=\"https://www.zhihu.com/equation?tex=d_%7Bk%2B1%7D\" alt=\"d_{k+1}\" eeimg=\"1\"/> 。</p><p><b>证明</b>：需要证明的是， <img src=\"https://www.zhihu.com/equation?tex=d_%7Bk%2B1%7D\" alt=\"d_{k+1}\" eeimg=\"1\"/> 和之前所有的更新方向 <img src=\"https://www.zhihu.com/equation?tex=d_0%2C%5Cldots%2Cd_k\" alt=\"d_0,\\ldots,d_k\" eeimg=\"1\"/> 之间满足 <img src=\"https://www.zhihu.com/equation?tex=Q-\" alt=\"Q-\" eeimg=\"1\"/> 共轭关系。</p><p><img src=\"https://www.zhihu.com/equation?tex=d_k%5ETQd_%7Bk%2B1%7D%3D0\" alt=\"d_k^TQd_{k+1}=0\" eeimg=\"1\"/> 是已经满足了的。下面计算 <img src=\"https://www.zhihu.com/equation?tex=d_i%5ETQd_%7Bk%2B1%7D%3D0%2C%28i%3D0%2C%5Cldots%2Ck-1%29\" alt=\"d_i^TQd_{k+1}=0,(i=0,\\ldots,k-1)\" eeimg=\"1\"/> 。</p><p><img src=\"https://www.zhihu.com/equation?tex=d_i%5ETQd_%7Bk%2B1%7D%3Dd_i%5ETQ%28-%5Cnabla+f%28x_%7Bk%2B1%7D%29%2B%5Cgamma_kd_k%29%3Dd_i%5ETQ%28-%5Cnabla+f%28x_%7Bk%2B1%7D%29%29%2B%5Cgamma_kd_i%5ETQd_k\" alt=\"d_i^TQd_{k+1}=d_i^TQ(-\\nabla f(x_{k+1})+\\gamma_kd_k)=d_i^TQ(-\\nabla f(x_{k+1}))+\\gamma_kd_i^TQd_k\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=d_0%2C%5Cldots%2Cd_k\" alt=\"d_0,\\ldots,d_k\" eeimg=\"1\"/> 之间是满足 <img src=\"https://www.zhihu.com/equation?tex=Q-\" alt=\"Q-\" eeimg=\"1\"/> 共轭关系的，从 <img src=\"https://www.zhihu.com/equation?tex=d_0\" alt=\"d_0\" eeimg=\"1\"/> 开始不断使用该证明可以得到这层关系。</p><p>由 <img src=\"https://www.zhihu.com/equation?tex=d_i%5ETQd_k%3D0%5Cqquad%5CRightarrow%5Cqquad+d_i%5ETQd_%7Bk%2B1%7D%3Dd_i%5ETQ%28-%5Cnabla+f%28x_%7Bk%2B1%7D%29%29\" alt=\"d_i^TQd_k=0\\qquad\\Rightarrow\\qquad d_i^TQd_{k+1}=d_i^TQ(-\\nabla f(x_{k+1}))\" eeimg=\"1\"/> </p><p>上式两边分别乘上最优更新步长 <img src=\"https://www.zhihu.com/equation?tex=%5Clambda_i\" alt=\"\\lambda_i\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Clambda_id_i%5ETQd_%7Bk%2B1%7D%3D%5Clambda_id_i%5ETQ%28-%5Cnabla+f%28x_%7Bk%2B1%7D%29%29%3D%28-%5Cnabla+f%28x_%7Bk%2B1%7D%29%29%5ETQ%5Clambda_id_i\" alt=\"\\lambda_id_i^TQd_{k+1}=\\lambda_id_i^TQ(-\\nabla f(x_{k+1}))=(-\\nabla f(x_{k+1}))^TQ\\lambda_id_i\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%28-%5Cnabla+f%28x_%7Bk%2B1%7D%29%29%5ETQ%28x_%7Bi%2B1%7D-x_i%29%3D%28-%5Cnabla+f%28x_%7Bk%2B1%7D%29%29%5ET%28%5Cnabla+f%28x_%7Bi%2B1%7D%29-%5Cnabla+f%28x_i%29%29\" alt=\"=(-\\nabla f(x_{k+1}))^TQ(x_{i+1}-x_i)=(-\\nabla f(x_{k+1}))^T(\\nabla f(x_{i+1})-\\nabla f(x_i))\" eeimg=\"1\"/> </p><p>由 <img src=\"https://www.zhihu.com/equation?tex=d_%7Bi%2B1%7D%3D-%5Cnabla+f%28x_%7Bi%2B1%7D%29%2B%5Cgamma_id_i\" alt=\"d_{i+1}=-\\nabla f(x_{i+1})+\\gamma_id_i\" eeimg=\"1\"/> 以及 <img src=\"https://www.zhihu.com/equation?tex=d_%7Bi%7D%3D-%5Cnabla+f%28x_%7Bi%7D%29%2B%5Cgamma_%7Bi-1%7Dd_%7Bi-1%7D\" alt=\"d_{i}=-\\nabla f(x_{i})+\\gamma_{i-1}d_{i-1}\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5CRightarrow+%5Cqquad+%5Cnabla+f%28x_%7Bi%2B1%7D%29-%5Cnabla+f%28x_i%29%3D%28%5Cgamma_id_i-d_%7Bi%2B1%7D%29-%28d_i-%5Cgamma_%7Bi-1%7Dd_%7Bi-1%7D%29\" alt=\"\\Rightarrow \\qquad \\nabla f(x_{i+1})-\\nabla f(x_i)=(\\gamma_id_i-d_{i+1})-(d_i-\\gamma_{i-1}d_{i-1})\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5CRightarrow%5Cqquad+d_i%5ETQd_%7Bk%2B1%7D%3D%28-%5Cnabla+f%28x_%7Bk%2B1%7D%29%29%5ET%28%5Cnabla+f%28x_%7Bi%2B1%7D%29-%5Cnabla+f%28x_i%29%29\" alt=\"\\Rightarrow\\qquad d_i^TQd_{k+1}=(-\\nabla f(x_{k+1}))^T(\\nabla f(x_{i+1})-\\nabla f(x_i))\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cqquad%3D%28-%5Cnabla+f%28x_%7Bk%2B1%7D%29%29%5ET%28%28%5Cgamma_id_i-d_%7Bi%2B1%7D%29-%28d_i-%5Cgamma_%7Bi-1%7Dd_%7Bi-1%7D%29%29\" alt=\"\\qquad=(-\\nabla f(x_{k+1}))^T((\\gamma_id_i-d_{i+1})-(d_i-\\gamma_{i-1}d_{i-1}))\" eeimg=\"1\"/> </p><p>由上一小节已知， <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_%7Bk%2B1%7D%29\" alt=\"\\nabla f(x_{k+1})\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=d_%7Bi-1%7D%2Cd_i%2Cd_%7Bi%2B1%7D%28i%3D0%2C%5Cldots%2Ck-1%29\" alt=\"d_{i-1},d_i,d_{i+1}(i=0,\\ldots,k-1)\" eeimg=\"1\"/> 均正交，故上式等于零，即 <img src=\"https://www.zhihu.com/equation?tex=d_i%5ETQd_%7Bk%2B1%7D%3D0%2C%28i%3D0%2C%5Cldots%2Ck-1%29\" alt=\"d_i^TQd_{k+1}=0,(i=0,\\ldots,k-1)\" eeimg=\"1\"/> 。</p><p>综上得证以这种方式产生的新的更新方向 <img src=\"https://www.zhihu.com/equation?tex=d_%7Bk%2B1%7D\" alt=\"d_{k+1}\" eeimg=\"1\"/> ，和之前的所有方向 <img src=\"https://www.zhihu.com/equation?tex=d_0%2C%5Cldots%2Cd_k\" alt=\"d_0,\\ldots,d_k\" eeimg=\"1\"/> 满足 <img src=\"https://www.zhihu.com/equation?tex=Q-\" alt=\"Q-\" eeimg=\"1\"/> 共轭关系。</p><h2>D.总结共轭梯度法步骤</h2><p>对无约束凸二次规划问题 <img src=\"https://www.zhihu.com/equation?tex=%5Cmathop%7Bmin%7D_xf%28x%29%3D%5Cfrac%7B1%7D%7B2%7Dx%5ETQx%2Bq%5ETx+\" alt=\"\\mathop{min}_xf(x)=\\frac{1}{2}x^TQx+q^Tx \" eeimg=\"1\"/> ，其中 <img src=\"https://www.zhihu.com/equation?tex=Q%5Cin%5Cmathbb%7BR%7D%5E%7Bn%5Ctimes+n%7D\" alt=\"Q\\in\\mathbb{R}^{n\\times n}\" eeimg=\"1\"/> 为对称正定矩阵， <img src=\"https://www.zhihu.com/equation?tex=q%5Cin+%5Cmathbb%7BR%7D%5En\" alt=\"q\\in \\mathbb{R}^n\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=x%5Cin%5Cmathbb%7BR%7D%5En\" alt=\"x\\in\\mathbb{R}^n\" eeimg=\"1\"/> 。</p><p>任意选择初始点 <img src=\"https://www.zhihu.com/equation?tex=x_0\" alt=\"x_0\" eeimg=\"1\"/> ，初始更新方向 <img src=\"https://www.zhihu.com/equation?tex=d_0%3D%5Cnabla+f%28x_0%29\" alt=\"d_0=\\nabla f(x_0)\" eeimg=\"1\"/> ；</p><p>如果 <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_i%29%3D0\" alt=\"\\nabla f(x_i)=0\" eeimg=\"1\"/> ，说明已找到最优解，返回 <img src=\"https://www.zhihu.com/equation?tex=x_i\" alt=\"x_i\" eeimg=\"1\"/> ；</p><p>如果 <img src=\"https://www.zhihu.com/equation?tex=%5Cnabla+f%28x_i%29%5Cne0\" alt=\"\\nabla f(x_i)\\ne0\" eeimg=\"1\"/> ，进行点的更新： <img src=\"https://www.zhihu.com/equation?tex=x_%7Bi%2B1%7D%3Dx_i%2B%5Clambda_id_i\" alt=\"x_{i+1}=x_i+\\lambda_id_i\" eeimg=\"1\"/> ，其中：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Clambda_i%3D%5Cfrac%7B-d_i%5ET%5Cnabla+f%28x_i%29%7D%7Bd_i%5ETQd_i%7D\" alt=\"\\lambda_i=\\frac{-d_i^T\\nabla f(x_i)}{d_i^TQd_i}\" eeimg=\"1\"/>，</p><p><img src=\"https://www.zhihu.com/equation?tex=d_%7Bi%7D%3D-%5Cnabla+f%28x_%7Bi%7D%29%2B%5Cgamma_%7Bi-1%7Dd_%7Bi-1%7D\" alt=\"d_{i}=-\\nabla f(x_{i})+\\gamma_{i-1}d_{i-1}\" eeimg=\"1\"/> ，这里 <img src=\"https://www.zhihu.com/equation?tex=%5Cgamma_%7Bi-1%7D%3D%5Cfrac%7Bd_%7Bi-1%7D%5ETQ%5Cnabla+f%28x_%7Bi%7D%29%7D%7Bd_%7Bi-1%7D%5ETQd_%7Bi-1%7D%7D\" alt=\"\\gamma_{i-1}=\\frac{d_{i-1}^TQ\\nabla f(x_{i})}{d_{i-1}^TQd_{i-1}}\" eeimg=\"1\"/> ；</p><p>至多经过 <img src=\"https://www.zhihu.com/equation?tex=n\" alt=\"n\" eeimg=\"1\"/> 轮迭代之后可以找到最优解。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>PS：我没有系统学过数值分析、最优化之类课程，只是遇到了共轭梯度法才稍微仔细的学习了一下，如果有发现文中的错误还望不吝赐教。后来想把自己的这个理解过程呈现在知乎文章里，但是写起来之后发现还是要花费些功夫，比起写在纸上慢多了，文字和公式全部都是手打的，如果有需要转载的还请注明本出处。</p><p>不过很担心写了没人看，因为毕竟全是数学公式，没有图像那么直观，但是没有办法只能是这种形式的。如果有人也遇到了这种方法可以参考一下，初衷是希望起到一点点传播知识的作用。</p><h2><b>参考书目</b></h2><p>1. 《深入浅出深度学习》——黄安埠</p><p>2. 《矩阵分析与应用》——张贤达</p>", 
            "topic": [
                {
                    "tag": "凸优化", 
                    "tagLink": "https://api.zhihu.com/topics/19602355"
                }, 
                {
                    "tag": "数值分析", 
                    "tagLink": "https://api.zhihu.com/topics/19665355"
                }
            ], 
            "comments": [
                {
                    "userName": "樊云", 
                    "userLink": "https://www.zhihu.com/people/97a7277d615e06d08d8612cac407b6ec", 
                    "content": "学霸好厉害～", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "big webs", 
                    "userLink": "https://www.zhihu.com/people/3ecd9766619f84541c8858dbb3d8aebe", 
                    "content": "哈哈 玩完女装又来玩数学啦？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "沃日我啥时候玩儿女装了", 
                            "likes": 0, 
                            "replyToAuthor": "big webs"
                        }
                    ]
                }, 
                {
                    "userName": "kare", 
                    "userLink": "https://www.zhihu.com/people/aef4889cbfd482815c9177e7574f00fa", 
                    "content": "共轭梯度法最早是用来求解SPD线性方程组问题的。整个idea也是从那而来。", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "嗯，数学还是很博大精深啊，我只能碰到一点看一点了", 
                            "likes": 0, 
                            "replyToAuthor": "kare"
                        }
                    ]
                }, 
                {
                    "userName": "死鸡", 
                    "userLink": "https://www.zhihu.com/people/f036dd78c8d4ef0e9238f9e3cf10248b", 
                    "content": "<p>非常感谢！如果可以将二次函数推广为一般的函数风f(x)就好了</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "对于一般的函数，可以进行泰勒展开成二次型，然后再使用共轭梯度法", 
                            "likes": 0, 
                            "replyToAuthor": "死鸡"
                        }
                    ]
                }, 
                {
                    "userName": "浪儿里个浪", 
                    "userLink": "https://www.zhihu.com/people/7bf98f1551ce640e61711b67aba3ea00", 
                    "content": "比国内某些教材直白很多 证明的线索和目的很清晰", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "驴驴", 
                    "userLink": "https://www.zhihu.com/people/c3dcd7a5c0273938614b3435226bae14", 
                    "content": "请问初始点怎么取哇。随便取吗。。", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "对随便取。就是要能够从随便一个点开始，最后找到极值点。牛顿法是直接计算出极值点一步到位，但是需要算矩阵的二阶导就是Hassian矩阵。共轭梯度法是不求一步到达，而是分n步到达，它不用计算Hassian矩阵。", 
                            "likes": 0, 
                            "replyToAuthor": "驴驴"
                        }, 
                        {
                            "userName": "驴驴", 
                            "userLink": "https://www.zhihu.com/people/c3dcd7a5c0273938614b3435226bae14", 
                            "content": "谢谢！！", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }, 
                {
                    "userName": "两个番茄", 
                    "userLink": "https://www.zhihu.com/people/8f90e370002506e4abbe8846400d9baa", 
                    "content": "为什么γ的值我们的书上写的是Δf(k＋1)/Δf(k)²，推不出来呀😭", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "没明白咋回事😅函数的梯度倒确实是和之前的更新方向有一定关系的", 
                            "likes": 0, 
                            "replyToAuthor": "两个番茄"
                        }
                    ]
                }, 
                {
                    "userName": "Obaxiong", 
                    "userLink": "https://www.zhihu.com/people/ae5c681ba53e7aa9c5f81098a9f96447", 
                    "content": "你在证明梯度与共轭方向垂直时用了共轭方向相互共轭，在证明共轭方向相互共轭时用了梯度与共轭方向垂直，相当于证明了两者的等价性", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>共轭方向关于Q相互共轭是定义，不用证明。第一部分证明的是当前点处函数的梯度和之前的更新方向都正交，这一步用到了共轭方向组的共轭定义。第二部分是证明下一个选定的更新方向和之前的所有更新方向满足共轭关系，这一步的证明用到了第一部分的结论，就是当前点处函数的梯度方向和之前的更新方向均正交。下一个更新方向是根据当前梯度方向和上一步的更新方向确定的。目的就是想沿着一组共轭方向进行更新，目的就是让当前的函数梯度和之前的更新方向都正交，这是两件事情，不叫等价吧。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Obaxiong"
                        }
                    ]
                }, 
                {
                    "userName": "YangYang Kim", 
                    "userLink": "https://www.zhihu.com/people/455cd0c71ce6fb08abcf3d0dc45fb37e", 
                    "content": "为什么下一个搜索方向是负梯度方向和上一次迭代的搜索方向的组合呢，可以从共轭方向法推导出来吗？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "第C步就是在证明这个的啊", 
                            "likes": 0, 
                            "replyToAuthor": "YangYang Kim"
                        }, 
                        {
                            "userName": "YangYang Kim", 
                            "userLink": "https://www.zhihu.com/people/455cd0c71ce6fb08abcf3d0dc45fb37e", 
                            "content": "我原本想问这个式子为什么这么构造来着😂，看了你上面的回答就明白了。", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }, 
                {
                    "userName": "doingys", 
                    "userLink": "https://www.zhihu.com/people/ad33a43333d03f92fdce42ad907cf789", 
                    "content": "老铁，有参考文献吗？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>更新在文章最后了</p>", 
                            "likes": 0, 
                            "replyToAuthor": "doingys"
                        }
                    ]
                }, 
                {
                    "userName": "飞钉", 
                    "userLink": "https://www.zhihu.com/people/fd23aa8a8e677f093b7ac042cb462ffc", 
                    "content": "<p>共轭梯度在神经网络上的应用和梯度下降相比，有优势吗？或者说可以用在神经网络上吗？谢谢</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>这些优化方法之间的差别，就是计算复杂度、空间复杂度、收敛速度这些区别。是有算法用共轭梯度法更新神经网络的。具体还要分不同的应用场景再进行选择吧。这些优化方法的比较，可以写好几篇文章了，你可以在网上搜一搜。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "飞钉"
                        }, 
                        {
                            "userName": "飞钉", 
                            "userLink": "https://www.zhihu.com/people/fd23aa8a8e677f093b7ac042cb462ffc", 
                            "content": "<p>或许我找资料的方式不对，我现在找到的共轭梯度用于神经网络权值更新的算法文献比较少，目前仅找到两篇，Self-Tuning PID Controller Based on Improved BP Neural Network   和     BP 神经网络算法的改进及其在 PID控制中的应用研究  。在求学习速率的时候，α(k)第二篇文章没有给出详细的方法。如果题主偶然看到相关的文章可以给我分享一下吗？谢谢啦</p><p> </p><p><br></p>", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }, 
                {
                    "userName": "Totty-top", 
                    "userLink": "https://www.zhihu.com/people/3c051fc502933aaf8b4a86fc0212f405", 
                    "content": "<p>B中，右箭头的第一等式的第二个等号怎么得来的？ 中间\\lambda 那一项不是0？</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>入j·dj 这一项是每一次更新，沿着dj方向更新步长入j。一直更新到Xk。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Totty-top"
                        }
                    ]
                }, 
                {
                    "userName": "Totty-top", 
                    "userLink": "https://www.zhihu.com/people/3c051fc502933aaf8b4a86fc0212f405", 
                    "content": "B步中，梯度与n个线性无关向量正交，故梯度等于0，这个没明白", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>一个n维向量，如果与n个线性无关的向量正交，那么这个n维向量就是0。这是固有性质。n个线性无关的向量，就能够描述一个n维坐标系，如果坐标系中的向量和所有坐标轴都正交，那么这个向量只能是0</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Totty-top"
                        }, 
                        {
                            "userName": "Totty-top", 
                            "userLink": "https://www.zhihu.com/people/3c051fc502933aaf8b4a86fc0212f405", 
                            "content": "明白了 谢谢", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }, 
                {
                    "userName": "邢笑伟", 
                    "userLink": "https://www.zhihu.com/people/65643a69bf456e2c1013759fcd0e1683", 
                    "content": "<p>C中，应该是-(r(i-1)d(i-1)-d(i))吧，虽然不影响最终结论</p><a class=\"comment_sticker\" href=\"https://pic3.zhimg.com/v2-cb8443f07a41298e45191cef11b90fd2.gif\" data-width=\"\" data-height=\"\">[干杯]</a>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "zhi hao", 
                    "userLink": "https://www.zhihu.com/people/53de89d610fe96479df6e4df182f44a2", 
                    "content": "请问deltaf(xk+1)=Qxk+1+q是怎么得到的？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>雷猴，这是因为已知f(x)的表达式为1/2 x^T Q x + q^T x ,求导之后就是Qx+q</p>", 
                            "likes": 0, 
                            "replyToAuthor": "zhi hao"
                        }, 
                        {
                            "userName": "zhi hao", 
                            "userLink": "https://www.zhihu.com/people/53de89d610fe96479df6e4df182f44a2", 
                            "content": "谢谢大牛，我再研究研究这些公式", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }, 
                {
                    "userName": "小杰", 
                    "userLink": "https://www.zhihu.com/people/f3ffcc40fe5002ec032890cec7a272e0", 
                    "content": "<p>感谢作者的付出，不是没人看啊</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/28549596", 
            "userName": "Ja1r0", 
            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
            "upvote": 77, 
            "title": "深度强化学习——从DQN到DDPG", 
            "content": "<p><b>引言</b></p><p>深度强化学习最近取得了很多进展，并在机器学习领域得到了很多的关注。传统的强化学习局限于动作空间和样本空间都很小，且一般是离散的情境下。然而比较复杂的、更加接近实际情况的任务则往往有着很大的状态空间和连续的动作空间。实现端到端的控制也是要求能处理高维的，如图像、声音等的数据输入。前些年开始兴起的深度学习，刚好可以应对高维的输入，如果能将两者结合，那么将使智能体同时拥有深度学习的理解能力和强化学习的决策能力。2013和2015年DeepMind的DQN可谓是将两者成功结合的开端，它用一个深度网络代表价值函数，依据强化学习中的Q-Learning，为深度网络提供目标值，对网络不断更新直至收敛。DQN用到了两个关键技术，一是用来打破样本间关联性的样本池，二是使训练稳定性和收敛性更好的固定目标网络。DQN可以应对高维输入，而对高维的动作输出则束手无策。随后，同样是DeepMind提出的DDPG，则可以解决有着高维或者说连续动作空间的情境。它包含一个策略网络用来生成动作，一个价值网络用来评判动作的好坏，并吸取DQN的成功经验，同样使用了样本池和固定目标网络，是一种结合了深度网络的Actor-Critic方法。</p><p><b>一、强化学习</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4713f22a9ba393ce03b4e178c2d262b3_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"262\" data-rawheight=\"170\" class=\"content_image\" width=\"262\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;262&#39; height=&#39;170&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"262\" data-rawheight=\"170\" class=\"content_image lazy\" width=\"262\" data-actualsrc=\"https://pic4.zhimg.com/v2-4713f22a9ba393ce03b4e178c2d262b3_b.png\"/></figure><p>智能体在完成某项任务时，如上图所示，首先通过动作A与周围环境进行交互，在动作A和环境的作用下，智能体会产生新的状态，同时环境会给出一个立即回报。如此循环下去，智能体与环境进行不断地交互从而产生很多数据。强化学习算法利用产生的数据修改自身的动作策略，再与环境交互，产生新的数据，并利用新的数据进一步改善自身的行为，经过数次迭代学习后，智能体能最终地学到完成相应任务的最优动作（最优策略）。这就是一个强化学习的过程。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-83a2426cf71e52bda31865737d721e2e_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"553\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb\" width=\"553\" data-original=\"https://pic3.zhimg.com/v2-83a2426cf71e52bda31865737d721e2e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;553&#39; height=&#39;142&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"553\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"553\" data-original=\"https://pic3.zhimg.com/v2-83a2426cf71e52bda31865737d721e2e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-83a2426cf71e52bda31865737d721e2e_b.png\"/></figure><p>强化学习所面对的是一个连续决策过程。这一问题框架基于一个MDP过程，即马尔科夫决策过程，如上图所示。智能体面对的环境有一个状态空间X，智能体自己有一个动作空间U，智能体根据状态的观察值O来进行决策。环境动态模型或者说转移概率描述了状态间是如何转化的，策略描述了智能体如何决策。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0efbcf7a97616536b2ac1ed9ee686e0b_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"601\" data-rawheight=\"256\" class=\"origin_image zh-lightbox-thumb\" width=\"601\" data-original=\"https://pic4.zhimg.com/v2-0efbcf7a97616536b2ac1ed9ee686e0b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;601&#39; height=&#39;256&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"601\" data-rawheight=\"256\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"601\" data-original=\"https://pic4.zhimg.com/v2-0efbcf7a97616536b2ac1ed9ee686e0b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0efbcf7a97616536b2ac1ed9ee686e0b_b.png\"/></figure><p>如上图所示，强化学习根据以策略为中心还是以值函数最优可以分为两大类，策略优化 方法和动态规划方法。其中策略优化方法又分为进化算法和策略梯度方法；动态规划方法分为策略迭代算法和值迭代算法。策略迭代算法和值迭代算法可以用广义策略迭代方法进行统一描述。另外，强化学习算法根据策略是否是随机的，分为确定性策略强化学习和随机性策略强化学习。根据转移概率是否已知可以分为基于模型的强化学习和无模型的强化学习算法。另外，强化学习算法中的回报函数r十分关键，根据回报函数是否已知，可以分为强化学习和逆向强化学习。逆向强化学习是根据专家演示将回报函数学习出来。</p><p><b>二、策略梯度</b></p><p>策略梯度方法中，将策略参数化表示为，计算出关于动作的策略函数梯度，不断调整动作，靠近最优策略。策略梯度的计算公式已由相关学者推导得到，且有两种策略梯度，一是随机性策略梯度，二是确定性策略梯度。</p><p>1、随机性策略梯度：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4bca23dbe1365188a0b51d230160efe9_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"361\" data-rawheight=\"72\" class=\"content_image\" width=\"361\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;361&#39; height=&#39;72&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"361\" data-rawheight=\"72\" class=\"content_image lazy\" width=\"361\" data-actualsrc=\"https://pic2.zhimg.com/v2-4bca23dbe1365188a0b51d230160efe9_b.png\"/></figure><p>2、确定性策略梯度：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3ded7498ccce13d7ab26296228335fba_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"373\" data-rawheight=\"84\" class=\"content_image\" width=\"373\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;373&#39; height=&#39;84&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"373\" data-rawheight=\"84\" class=\"content_image lazy\" width=\"373\" data-actualsrc=\"https://pic3.zhimg.com/v2-3ded7498ccce13d7ab26296228335fba_b.png\"/></figure><p>证明可参考相关论文。总之，策略梯度的直观理解是调整策略函数的参数，使得其给出的动作可以获得较大的Q值。</p><p>Actor-Critic方法是一种很重要的强化学习算法，其是一种时序差分方法（TD method），结合了基于值函数的方法和基于策略函数的方法。其中策略函数为行动者（Actor），给出动作；价值函数为评价者（Critic），评价行动者给出动作的好坏，并产生时序差分信号，来指导价值函数和策略函数的更新。其框架如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-1d6ad4d3531bfc786eeea0cdd8acc457_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"522\" data-rawheight=\"317\" class=\"origin_image zh-lightbox-thumb\" width=\"522\" data-original=\"https://pic4.zhimg.com/v2-1d6ad4d3531bfc786eeea0cdd8acc457_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;522&#39; height=&#39;317&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"522\" data-rawheight=\"317\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"522\" data-original=\"https://pic4.zhimg.com/v2-1d6ad4d3531bfc786eeea0cdd8acc457_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-1d6ad4d3531bfc786eeea0cdd8acc457_b.png\"/></figure><p>将此方法与深度学习结合的话，则是分别用两个深度网络去代表价值函数和策略函数。之后所介绍的DDPG就是基于这样一种Actor-Critic架构的深度强化学习方法。</p><p><b>三、DQN</b></p><p>DeepMind在2013年提出的DQN算法（2015年提出了DQN的改进版本）可以说是深度学习和强化学习的第一次成功结合。要想将深度学习融合进强化学习，是有一些很关键的问题需要解决的，其中的两个问题如下：</p><p>1、深度学习需要大量有标签的数据样本；而强化学习是智能体主动获取样本，样本量稀疏且有延迟。</p><p>2、深度学习要求每个样本相互之间是独立同分布的；而强化学习获取的相邻样本相互关联，并不是相互独立的。</p><p>若想将这两者结合，必须解决包括上面两点在内的问题。</p><p>DQN具体来说，是基于经典强化学习算法Q-Learning，用深度神经网络拟合其中的Q值的一种方法。Q-Learning算法提供给深度网络目标值，使其进行更新。先来看Q-Learning的算法流程图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4c586f5375f687546bb37f712e962dc2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"319\" data-rawheight=\"261\" class=\"content_image\" width=\"319\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;319&#39; height=&#39;261&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"319\" data-rawheight=\"261\" class=\"content_image lazy\" width=\"319\" data-actualsrc=\"https://pic3.zhimg.com/v2-4c586f5375f687546bb37f712e962dc2_b.jpg\"/></figure><p>智能体采用off-policy即执行的和改进的不是同一个策略，这通过方法实现。用这种方式采样，并以在线更新的方式，每采集一个样本进行一次对Q函数的更新。更新所依据的是时序差分公式。以更新后的Q函数得到新的策略。而这种经典强化学习算法的局限性在于，无法应对高维的输入，且无法应用于大的动作空间，特别的，无法应用于连续动作输出。DQN所做的是用一个深度神经网络进行端到端的拟合，发挥深度网络对高维数据输入的处理能力。其2013年版本结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-fa9562322d6698b6717237e5ea653a4f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"459\" data-rawheight=\"301\" class=\"origin_image zh-lightbox-thumb\" width=\"459\" data-original=\"https://pic4.zhimg.com/v2-fa9562322d6698b6717237e5ea653a4f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;459&#39; height=&#39;301&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"459\" data-rawheight=\"301\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"459\" data-original=\"https://pic4.zhimg.com/v2-fa9562322d6698b6717237e5ea653a4f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-fa9562322d6698b6717237e5ea653a4f_b.jpg\"/></figure><p>在2015年又发布了其改进版本：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-131e57e7604d33dd33f1f2d7c67c59c6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"466\" data-rawheight=\"308\" class=\"origin_image zh-lightbox-thumb\" width=\"466\" data-original=\"https://pic3.zhimg.com/v2-131e57e7604d33dd33f1f2d7c67c59c6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;466&#39; height=&#39;308&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"466\" data-rawheight=\"308\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"466\" data-original=\"https://pic3.zhimg.com/v2-131e57e7604d33dd33f1f2d7c67c59c6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-131e57e7604d33dd33f1f2d7c67c59c6_b.jpg\"/></figure><p>其有两个关键技术：</p><p>1、样本池（experience reply）：将采集到的样本先放入样本池，然后从样本池中随机选出一条样本用于对网络的训练。这种处理打破了样本间的关联，使样本间相互独立。</p><p>2、固定目标值网络（fixed Q-target）：计算网络目标值需用到现有的Q值，现用一个更新较慢的网络专门提供此Q值。这提高了训练的稳定性和收敛性。</p><p><b>四、DDPG</b></p><p>DQN是一种基于值函数的方法，基于值函数的方法难以应对的是大的动作空间，特别是连续动作情况。因为网络难以有这么多输出，且难以在这么多输出之中搜索最大的Q值。而DDPG是基于上面所讲到的Actor-Critic方法，在动作输出方面采用一个网络来拟合策略函数，直接输出动作，可以应对连续动作的输出及大的动作空间。</p><p>再来回顾一下Acror-Critic结构。如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-abce4e6d161dd20653a7f23c5fd4b489_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"391\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-abce4e6d161dd20653a7f23c5fd4b489_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;391&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"391\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-abce4e6d161dd20653a7f23c5fd4b489_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-abce4e6d161dd20653a7f23c5fd4b489_b.jpg\"/></figure><p>该结构包含两个网络，一个策略网络（Actor），一个价值网络（Critic）。策略网络输出动作，价值网络评判动作。两者都有自己的更新信息。策略网络通过梯度计算公式进行更新，而价值网络根据目标值进行更新。</p><p>DDPG采用了DQN的成功经验。即采用了样本池和固定目标值网络这两项技术。也就是说这两个网络分别有一个变化较慢的副本，该变化较慢的网络提供给更新信息中需要的一些值。DDPG的整体结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e2a3e9403308df56359b5fb5f41f4323_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"395\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic4.zhimg.com/v2-e2a3e9403308df56359b5fb5f41f4323_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;395&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"395\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic4.zhimg.com/v2-e2a3e9403308df56359b5fb5f41f4323_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e2a3e9403308df56359b5fb5f41f4323_b.jpg\"/></figure><p>DDPG方法是深度学习和强化学习的又一次成功结合，是深度强化学习发展过程中很重要的一个研究成果。其可以应对高维的输入，实现端对端的控制，且可以输出连续动作，使得深度强化学习方法可以应用于较为复杂的有大的动作空间和连续动作空间的情境。</p><p>参考文献：</p><p>[1] Silver D, Lever G, Heess N, et al. Deterministic Policy Gradient<br/>Algorithms[C]// International Conference on Machine Learning. 2014:387-395.</p><p>[2] Mnih V, Kavukcuoglu K, Silver D, et al. Human-level control through<br/>deep reinforcement learning.[J]. Nature, 2015, 518(7540):529.</p><p>[3] Mnih V, Kavukcuoglu K, Silver D, et al. Playing Atari with Deep<br/>Reinforcement Learning[J]. Computer Science, 2013.</p><p>[4] Lillicrap T P, Hunt J J, Pritzel A, et al. Continuous control with deep<br/>reinforcement learning[J]. Computer Science, 2015, 8(6):A187.</p><p class=\"ztext-empty-paragraph\"><br/></p><p>注：前四张图片来自网络，出处不详=。=文字及后五张彩色图片为自己写的和画的。</p>", 
            "topic": [
                {
                    "tag": "强化学习 (Reinforcement Learning)", 
                    "tagLink": "https://api.zhihu.com/topics/20039099"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "樊云", 
                    "userLink": "https://www.zhihu.com/people/97a7277d615e06d08d8612cac407b6ec", 
                    "content": "哇，好厉害！", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "给云云倒一杯卡布奇诺🍵", 
                            "likes": 0, 
                            "replyToAuthor": "樊云"
                        }
                    ]
                }, 
                {
                    "userName": "big webs", 
                    "userLink": "https://www.zhihu.com/people/3ecd9766619f84541c8858dbb3d8aebe", 
                    "content": "男神 求睡", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "你可能要排到下个月了", 
                            "likes": 0, 
                            "replyToAuthor": "big webs"
                        }
                    ]
                }, 
                {
                    "userName": "苏打爱咖喱", 
                    "userLink": "https://www.zhihu.com/people/4364ef5a9d24e5ee3cc57f12f0b99d38", 
                    "content": "深度好文，受益匪浅", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "水军你好😘", 
                            "likes": 0, 
                            "replyToAuthor": "苏打爱咖喱"
                        }
                    ]
                }, 
                {
                    "userName": "Eckes", 
                    "userLink": "https://www.zhihu.com/people/43dd731d50913da67fb3605aca61c4c7", 
                    "content": "死宅推动智能科技发展，滑稽", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "感觉被黑了…", 
                            "likes": 0, 
                            "replyToAuthor": "Eckes"
                        }
                    ]
                }, 
                {
                    "userName": "lens", 
                    "userLink": "https://www.zhihu.com/people/3ca3232ba2c4e60b18c4975a8a26b88f", 
                    "content": "请教有没有专门探讨深度强化学习的收敛性和收敛过程的，感觉太难训练了，而且出了问题也不知道原因。", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "deeprl boot camp 2017里面有一节课是Scholman讲如何训练rl系统", 
                            "likes": 0, 
                            "replyToAuthor": "lens"
                        }, 
                        {
                            "userName": "lens", 
                            "userLink": "https://www.zhihu.com/people/3ca3232ba2c4e60b18c4975a8a26b88f", 
                            "content": "谢谢，我去看看。", 
                            "likes": 0, 
                            "replyToAuthor": "Ja1r0"
                        }
                    ]
                }, 
                {
                    "userName": "小南", 
                    "userLink": "https://www.zhihu.com/people/24659852491ad11f38b5c30e52fef8ef", 
                    "content": "应该是experience replay而不是reply吧……", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "mr.kevin", 
                    "userLink": "https://www.zhihu.com/people/48c1e799619f838a58b3d44f6d8996d5", 
                    "content": "<p>您好，请问您实现过DDPG算法吗？我有个问题一直很困惑，还望前辈指点一二：我实现的DDPG算法的Actor网络一直输出action的最大值，在倒立摆的问题上表现就是agent一直朝着一个方向转，学不到一个好的策略。请问可能会是哪里出了问题？我在调试的时候应该关心那些值的变化？非常感谢。</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "<p>说实话训练DRL模型真的挺坑的，即使收敛了reward值的变化曲线也差别挺大的。参数与数据与环境间的关系很复杂以至于我觉得不是靠瞪眼看能分析出来的。可能也没人能告诉你明确的调参规律。上上个评论里那个视频可以看一下，听听专家怎么讲。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "mr.kevin"
                        }
                    ]
                }, 
                {
                    "userName": "the 20th", 
                    "userLink": "https://www.zhihu.com/people/88d65392c316bbeaf3cd0f64fbf925d5", 
                    "content": "<p>作者你好，有个问题一直困扰我很久了，就是DDPG部分actor的输出到底代表着什么什么呢？比如说，在开车这个场景里，这个输出是否代表着三个实数？[左转的角度，踩刹车的程度，加速的程度]，那么实际执行的时候，我们是否是这三个动作同时执行呢？</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "我觉得还是找源代码来看，就都清楚了", 
                            "likes": 0, 
                            "replyToAuthor": "the 20th"
                        }
                    ]
                }, 
                {
                    "userName": "菠萝大魔王", 
                    "userLink": "https://www.zhihu.com/people/342719c5232de1f86ccceed1194c1d39", 
                    "content": "<p>作者你好，请问强化学习是如何区分是否带着钥匙到达锁住的门这两种状态的（我想应该都会表示成到达门这个状态，但貌似不满足马尔科夫性质了）</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "meng2yz", 
                    "userLink": "https://www.zhihu.com/people/f1fd5aba3754f76b8d4901c7385a9a1d", 
                    "content": "<p>图画的真好 点赞收藏</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Ja1r0", 
                            "userLink": "https://www.zhihu.com/people/bf6f7428561f5ed61eddaae6f920c7aa", 
                            "content": "感谢~终于有人说我图画的好了哈哈", 
                            "likes": 0, 
                            "replyToAuthor": "meng2yz"
                        }
                    ]
                }
            ]
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/c_120091681"
}

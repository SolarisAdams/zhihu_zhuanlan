{
    "title": "语义 Web", 
    "description": "", 
    "followers": [
        "https://www.zhihu.com/people/huang-yan-ling-87-5", 
        "https://www.zhihu.com/people/666233-95-78", 
        "https://www.zhihu.com/people/carvin-71", 
        "https://www.zhihu.com/people/chen-yi-liang-64-71", 
        "https://www.zhihu.com/people/lu-jie-10-70", 
        "https://www.zhihu.com/people/fpcheng", 
        "https://www.zhihu.com/people/ben-pao-de-xiao-tu-ji-30", 
        "https://www.zhihu.com/people/guangg_sj", 
        "https://www.zhihu.com/people/yolo1996-22", 
        "https://www.zhihu.com/people/123456-36-71", 
        "https://www.zhihu.com/people/a-ai-41-94-79", 
        "https://www.zhihu.com/people/zhang-zhong-shuai", 
        "https://www.zhihu.com/people/zhang-da-xian-1973", 
        "https://www.zhihu.com/people/king-of-31", 
        "https://www.zhihu.com/people/jia-xue-feng", 
        "https://www.zhihu.com/people/ji-peng-83-71", 
        "https://www.zhihu.com/people/wu-tong-59-58", 
        "https://www.zhihu.com/people/xu-yi-hang", 
        "https://www.zhihu.com/people/a-piece-of-bread", 
        "https://www.zhihu.com/people/yansera", 
        "https://www.zhihu.com/people/heyang-36", 
        "https://www.zhihu.com/people/qinininin-67", 
        "https://www.zhihu.com/people/abrams-25", 
        "https://www.zhihu.com/people/Sing-F", 
        "https://www.zhihu.com/people/mr-lin-82-68", 
        "https://www.zhihu.com/people/liu-fei-94-95", 
        "https://www.zhihu.com/people/xie-fan-6-31", 
        "https://www.zhihu.com/people/tonic-your", 
        "https://www.zhihu.com/people/ye-li-tiao-deng-kan-jian-99", 
        "https://www.zhihu.com/people/ma-yong-qiang-55", 
        "https://www.zhihu.com/people/samurai3701", 
        "https://www.zhihu.com/people/du-zhu-lin", 
        "https://www.zhihu.com/people/wu-ye-nan-30", 
        "https://www.zhihu.com/people/www.310bar.com", 
        "https://www.zhihu.com/people/dong-dong-46-64", 
        "https://www.zhihu.com/people/gecanhui", 
        "https://www.zhihu.com/people/li-yifei-48-25", 
        "https://www.zhihu.com/people/jiu-shi-zhu-76-86", 
        "https://www.zhihu.com/people/xuxiao-looper"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/88521196", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 11, 
            "title": "[阅读] 知识图谱标准化白皮书（2019版）", 
            "content": "<h2>[阅读] 知识图谱标准化白皮书（2019版）</h2><p>本文通过由中国电子技术标准化研究院主编并于 2019 年 6 月发布的《知识图谱标准化白皮书（2019版）》来了解知识图谱的基本概念、相关技术和研究方面的挑战。虽然该白皮书的重心是在知识图谱的标准化，但对知识图谱入门来说，仍然值得一看。</p><h2>知识图谱介绍</h2><h3>知识图谱的起源与发展</h3><h3>知识图谱的发展历史</h3><p>知识图谱起源于 20 世纪 50 年代，至今大致分为三个发展阶段： - 1955-1977 知识图谱的起源阶段，引文网络分析开始成为一种研究当代科学发展脉络的常用方法； - 1977-2012 知识图谱的发展阶段，语义网快速发展，“知识本体”的研究开始成为计算机科学的一个重要领域，知识图谱吸收了语义网、本体在知识组织和表达方面的理念，使得知识更易于在计算机之间和计算机与人之间交换、流通和加工； - 2012-至今 知识图谱的繁荣阶段，2012 年谷歌提出 Google Knowledge Graph，知识图谱正式得名，谷歌通过知 识图谱技术改善了搜索引擎性能。 </p><p>在人工智能的蓬勃发展下，知识图谱涉及到的知识抽取、表示、融合、推理、问答等关键问题得到一定程度的解决和突破，知识图谱成为知识服务领域的一个新热点 。</p><h3>知识图谱与本体论、语义网络之间的区别</h3><p>知识图谱与本体论、语义网络等概念之间有密切的联系。语义网络由 Quillian 于上世纪 60 年代提出的知识表达模式，主要用于自然语言理解领域，其用相互连接的节点和边来表示知 识，节点表示对象、概念，边表示节点之间的关系。语义网络具有的优点包括：<b>容易理解和展示、相关概念容易聚类</b>，同时也具有以下方面的缺点： - 节点和边的值没有标准，完全由用户自己定义； - 多元数据融合比较困难，没有标准； - 无法概念节点和对象节点； - 无法对节点和边的标签进行定义。  语义网虽然能使我们比较容易地理解语义间的关系，由于<b>缺乏标准</b>，语义网难以应用于实践。</p><p>1980 年，本体论（Ontology）的哲学概念“本体”被引入到人工智能领域用于刻画知识。<b>本体</b>是共享概念模型的明确的形式化规范说明，该定义体现了本体的四层含义：概念模型、明确、形式化、共享。本体是实体存在形式的描述，往往表述为一组概念定义和概念之间的层次关系，本体框架形成树状结构，通常被用来为知识图谱定义 Schema。</p><h3>知识图谱的定义</h3><p><b>知识图谱</b>（Knowledge Graph）以结构化的形式描述客观世界中概念、实体及其关系，将互联网的信息表达为更接近人类认知世界的形式，提供了一种更好地组织、管理和理解互联网海量信息的能力。知识图谱给互联网语义搜索、智能问答等知识驱动的应用带来了巨大影响。</p><p>知识图谱不是一种新的知识表示方法，而是<b>知识表示在工业界的大规模知识应用</b>，它将互联网上可识别的客观对象进行关联，以形成客观世界实体和实体关系的知识库，其本质上是<b>一种语义网络</b>，其中的节点代表实体(entity)或者概念(concept)，边代表实体/概念之间的各种语义关系。 </p><p>知识图谱的架构，包括知识图谱自身的逻辑结构以及构建知识图谱所采用的技术(体系)架构。 知识图谱的逻辑结构分为模式层和数据层。     - 模式层：在数据层之上，是知识图谱的核心，存储的是经过提炼的知识，通常采用本体库来管理知识图谱的模式层，借助本体库对公理、规则和约束条件的支持能力来规范实体、关系以及实体的类型和属性等对象之间的联系。     - 数据层：数据层由一系列事实组成，而知识以事实为单位进行存储在图数据库中。如果以“实体-关系-实体”或者“实体-属性名-属性值”三元组作为事实 的基本表达方式，则存储在图数据库中的所有数据将构成庞大的实体关系网络，形成“知识图谱”。 </p><h2>知识图谱相关技术</h2><p>知识图谱的主要技术包括七个方面：知识获取、知识表示、知识存储、知识建模、知识融合、知识理解、知识运维。通过面向结构化、半结构化和非结构化数据构建知识图谱，为不同领域的应用提供支持。</p><h3>知识获取</h3><h3>知识获取概述</h3><p>知识图谱中的知识来源于结构化、半结构化和非结构化的信息资源。<b>知识获取</b>即通过获取这些不同来源、不同结构的知识，形成<b>结构化的知识</b>并存储到知识图谱中。</p><p>当前的知识获取，主要针对文本数据进行，需要解决的<b>抽取问题</b>包括：实体抽取、关系抽取、属性抽取和事件抽取。</p><p>知识获取是构建知识图谱的第一步，通常有四种方式： - 众包法：允许任何人创建、修改和查询的知识库。维基百科是典例。这类知识库存储的是<b>机器可读、具有一定结构</b>的数据格式。谷歌和百度的知识图谱已包含超过千亿级别的三元组。 - 爬虫：网页开发者将网页中出现的实体、实体属性、关系按某种规则标记。 - 机器学习：通过机器学习将数据变为可理解的知识，例如通过文本分类、主体模型等机器学习模型，获取文本<b>特征</b>，这些特征就可理解为知识。 - 专家：通常用于垂直领域的工程实践，通过专家的经验，归纳总结形成知识。知识图谱中的<b>事件图谱</b>通常由专家的经验形成。</p><h3>知识抽取的研究现状</h3><p>面向互联网海量文本数据的<b>知识抽取</b>是知识获取研究的主流。根据抽取对象不同，分为实体抽取、关系抽取、属性抽取和事件抽取。</p><ul><li>实体抽取：即<b>命名实体识别</b> NER，从文本语料库中自动识别专有名词（机构名、地名、人名、时间等）或有意义的名词性短语。当前，规则和监督学习相结合的方法、半监督方法、远程监督方法以及海量数据的自学习方法等被相继提出。</li><li>关系抽取：利用多种技术自动从文本中发现命名实体之间的语义关系，将文本中的关系映射到实体关系三元组上。<b>研究难点</b>是关系表达的隐含性（关系不一定明显）、关系的复杂性（二元或多元）、语言的多样性（关系有多种表述形式）。</li><li>属性抽取：由于可以把实体的属性看作实体与属性值之间的一种名词性关系，属性抽取任务可以转化为关系抽取任务。</li><li>事件抽取：事件是特定时间点或时间段、特定地域范围内，由一个或多个角色参与的一个或多个动作组成的事情或状态的改变。目前已存在的知识资源（如维基百科等）所描述实体及实体间的关联关系大多是静态的，事件能描述粒度<b>更大的、动态的、结构化的</b>知识，是现有知识资源的重要补充。</li></ul><h3>知识抽取的发展趋势</h3><p>发展趋势主要包括： - 资源缺乏下的知识抽取 - 面向开放域的知识抽取 - 跨语言的知识抽取 - 跨媒体的知识抽取</p><h3>资源缺乏下的知识抽取</h3><p>大多数方法采用有监督的方法，需要大量标注训练集去训练模型参数。然而构建标注数据集的成本大，算法性能与语料类型紧密相关。因此，如何构建资源缺乏下的知识抽取系统成为研究热点。 </p><h3>面向开放域的知识抽取</h3><p>虽然当前技术在特定领域取得一定效果，但受数据主题或规模的制约，方法的可移植性与可扩展性不强。面对大规模开放域环境的知识抽取，需要研究的问题： - <b>数据规模上的可扩展性</b>，能够高效完成海量数据的抽取任务； - <b>数据主题上的健壮性</b>，能够在面对不同主题的数据时具有健壮性。 </p><h3>跨语言的知识抽取</h3><p>跨语言的知识抽取为研究语言间的互补性和冗余性提供了机会，具体的研究包括： - <b>自然语言表达的多样性</b>，不同的语种在表示方式上均具有多样性， 需要将实体关系知识映射到三元组上； - <b>不同语种在知识表达方式上的差异性</b>，通过比较不同语种对同一知识的表述，可以达到删除或更新错误知识的目的。</p><p>目前针对跨语言的知识抽取，已有学者进行研究并取得成果。例如，清华大学李涓子教授团队融合中英文维基百科、法语维基以及百度百科构建的跨语言知识库 XLORE，并在此基础上实现了实体链接系统 XLink。 </p><h3>跨媒体的知识抽取</h3><p>跨媒体的知识抽取可以利用视觉、听觉等多模态已标注信息来辅助文本标注缺乏下的知识抽取，又可以作为类似跨语言知识抽取的另一维度为实体间未知关系的挖掘及已标注关系的消歧提供互补信息。此外，跨媒体知识抽取在上述开放应用域的基础上，从多模态数据域维度进一步扩展，对模型健壮性等方面提出更大挑战。具体研究内容包括:  - <b>视觉实体和关系的抽取</b>：视觉实体和关系呈现出尺度、表型、空间关系等多样性，需要通过鲁棒语义模型的构建实现视觉实体和关系的抽取，从而将视觉局部区域映射到三元组上； - <b>视觉事件的自然语言描述</b>：针对图像/视频，基于人工智能理论自动生成一段语法和逻辑合理的视觉内容自然语言描述，从而实现语义丰富的视觉信息到抽象的语义事件描述的映射  - <b>跨媒体信息融合</b>：跨媒体信息在知识载体上存在差异，通过多模态信息在相同粒度和语义上的对齐，进一步实现特征和语义层面的融合，可以综合利用多模态 信息，来辅助后续知识表示、建模、计算等关键技术，并形成面向跨媒体 知识图谱构建的创新理论体系和关键技术。 </p><h3>知识表示</h3><h3>知识表示概述</h3><p><b>知识表示</b>是将现实世界中存在的知识转换成计算机可识别和处理的内容，是一种描述知识的数据结构，用于对知识的一种描述或约定。 </p><h3>知识表示的研究现状</h3><p>主要分为基于符号的知识表示方法，与基于表示学习的知识表示方法。</p><h3>基于符号的知识表示方法</h3><p>主要分为早期知识表示方法与语义网知识表示方法。</p><ul><li><b>一阶谓词逻辑表示法</b>：基于谓词逻辑的知识表示方法，以数理逻辑为基础，表示结果准确，但只能表示确定性知识，对于过程性和非确定性知识表达有限。</li><li><b>产生式规则表示法</b>：根据因果关联关系的逻辑，形成 IF-THEN 的知识表示形式。直观自然，能表达的知识范畴广；但知识规模较大时，推理效率低，容出现组合爆炸问题。</li><li><b>框架表示法</b>：20世纪70年代初，美国人工智能专家M.Minsky提出了一种用于表示知识的“框架理论”。 框架具有继承性、结构化、自然性等优点，但构建成本高，对知识库的质量要求较高，表达不够灵活，难以与其他数据集相互关联使用。</li><li><b>语义网络表示法</b>：1960年，认知科学家 Allan M.Collins 提出了语义网络(Semantic Network)的知识表示方法。它具有广泛的表示范围和强大的表示能力，表示形式简单直接、容易理解、符合自然。然而语义网络存在节点与边的值没有标准，完全由用户自己定义，不便于知识的共享问题、无法区分知识描述与知识实例等问题。 </li></ul><h3>基于表示学习的知识表示方法</h3><p>早期知识表示方法与语义网知识表示法通过符号<b>显式地</b>表示概念及其 关系。事实上，许多知识具有不易符号化、隐含性等特点，因此仅通过显式表示的知识无法获得全面的知识特征。此外，语义计算是知识表示的重要目标，基于符号的知识表示方法无法有效计算实体间的<b>语义关系</b>。</p><h3>知识表示的发展趋势</h3><ul><li><b>符号与表示学习的融合统一</b>：基于符号的知识表示方法由于考虑了人类的自然语言理解方式，具有严密性、自然性、通用性、知识易表达等优点，但是也存在计算效率低、 无法捕捉隐含语义知识等不足。而基于表示学习的知识表示方法计算效率高却存在可靠性低，推理效果不佳等问题。因此研究基于符号逻辑与表示 学习融合统一的知识表示方法有助于知识表达性能的进一步提升。</li><li><b>面向事理逻辑的知识表示</b>：事理逻辑是指事件之间的演化规律和模式。 已有的以实体、实体属性、实体与实体或属性之间关系为核心的知识图谱缺乏针对事件之间的演化规律与模式的知识挖掘。事实上，事理逻辑是一种非常有价值的常识知识。哈工大 SCIR 提出了“事理图谱”的概念，在 2018 年 9 月发布了基于大规模财经新闻文本的金融事理图谱。</li><li><b>融合时空间维度的知识表示</b>：许多知识具有时间和空间属性，从时空维度拓展知识表示对许多特定领域具有较强的现实意义。德国马普研究所研制的 YAGO 知识库为许多知识条目增加了时间和空间维度的属性描述，丰富了知识库内容。 </li><li><b>融合跨媒体元素的知识表示</b>：当前的知识图谱主要以文本为主，事实上，跨媒体元素包括声音、 图片、视频、音频等数据对于丰富和增强知识图谱的知识语义具有重要作用。 不同的跨媒体元素能够表达相同的语义 信息，能比单一模态反映更加全面正确知识内容。 </li></ul><h2>知识存储</h2><h3>知识存储概述</h3><p><b>知识存储</b>是针对知识图谱的知识表示形式设计底层存储方式，完成各类知识的存储，以支持对大规模图数据的有效管理和计算。 <b>知识存储的对象</b>包括基本属性知识、关联知识、事件知识、时序知识和资源类知识等。</p><h3>知识存储方式</h3><p>从存储结构划分，知识存储分为<b>基于表结构的存储</b>和<b>基于图结构的存储</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0612d288223cd3b52d1bc9a83717cc61_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1216\" data-rawheight=\"330\" class=\"origin_image zh-lightbox-thumb\" width=\"1216\" data-original=\"https://pic2.zhimg.com/v2-0612d288223cd3b52d1bc9a83717cc61_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1216&#39; height=&#39;330&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1216\" data-rawheight=\"330\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1216\" data-original=\"https://pic2.zhimg.com/v2-0612d288223cd3b52d1bc9a83717cc61_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-0612d288223cd3b52d1bc9a83717cc61_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>基于表结构的存储</h3><p>基于表结构的存储，运用二维的数据表对知识图谱中的数据进行存储。根据不同的设计原则，可以具有不同的表结构，如：三元组表、 类型表和关系数据库。 三元组表如 jena 等，优点是简单直接，易于理解。缺点是整个知识图谱都存储在一张表中，导致单表的规模太大。相应的插入、删除、查询、修改的操作开销也大，对实用性大打折扣。 复杂查询在这种存储结构上的开销巨大。复杂查询拆分成若干个简单查询的操作，降低了查询的效率。 </p><h3>基于图结构的存储</h3><p>基于图结构的存储，即使用图模型描述和存储图谱数据。这种方式能直接反应图谱的内部结构，有利于知识的查询，结合图计算算法，进行知识的深度挖掘与推理。 常用的三种图模型是属性图、资源描述框架和三元组超图。</p><ul><li><b>属性图</b>：由顶点(圆圈)、边(箭头)、属性(key:value)和标签组成，顶点和边可以有标签。属性图的表达很贴近现实生活中的场景，也可以很好地描述业务中所包含的逻辑。 </li><li><b>资源描述框架</b>（RDF）：鉴于传统关系数据库拥有较高的通用性、可靠性、稳定性及成熟的技术，基于 RDF 的知识形式也广泛使用关系数据库作为其存储方式。目前主要有以下三种存储方案：基于三元组的三列表存储、水平存储、基于类型的属性表存储和基于谓词存储等 。对于基于RDF知识的三列表存储，该存储方式将关系数据库表的3列分别存储为 RDF 知识三元组的主语、谓语和宾语，即对应(实体，关系，实体)或者(实体，属性，属性值)。该三列表存储方式与传统的结构化数据存储方式相兼容，通用性好。但面向大规模的知识图谱，其本身包含大量的三元组，从而会造成关系数据库低效的查询性能。 </li><li><b>超图</b>：超图概念的提出，是为了解决简单图中的共指消解和分割等问题。对于我们熟悉的图而言，简单图的一个边(edge)只能和两个顶点连接；而对于超图来讲，人们定义它的边(超边hyperedge)可以和任意个数的顶点连接。超图可以完美刻画标签网络中一条边包含多节点的问题。</li></ul><h3>知识存储基础工具</h3><p>知识图谱的存储<b>并不依赖特定的底层结构</b>，一般的做法是按数据和应用的需求采用不同的底层存储，甚至可以基于现有关系数据库或 NoSQL 数据库进行构建。<b>关系型数据库</b>是典型的基于表结构的存储，<b>图数据库</b>是典型的基于图结构的存储。 </p><p><b>关系数据库</b>通过属性对现实世界中的事物进行描述，采用关系模型来 组织数据的数据库，其以行和列的形式存储数据。一行一个记录，一列表 示一个属性。用户通过查询来检索数据库中的数据，而查询是一个用于限 定数据库中某些区域的执行代码。 </p><p><b>图数据库</b>源起欧拉和图理论(graph theory)，也可称为面向/基于图的数据库，图数据库的基本含义是以“图”这种数据结构存储和查询数据。它的数据模型主要是以节点和关系(边)来体现，也可处理键值对，优点是快速解决复杂的关系问题。图数据库是一种<b>非关系型数据库</b>，支持对图结构进行查询、增加、删除、更新等操作。相对传统的关系型数据库，查询速度快、操作简单、能提供更为丰富的关系展现方式。</p><h3>知识存储的技术发展趋势</h3><p>针对知识图谱的分布式存储、知识存储的伸缩性和灵 活性，以及基于LOD的知识存储，是技术发展的重点方向，同时，超图 (Hyper Graph)也是未来知识存储的研究热点。知识存储相关技术发展趋势包括以下几个方面：</p><ul><li><b>基于 RDF 知识表示的分布式存储</b>：基于 RDF 存储的知识图谱更便于知识推理和计算，符合知识图谱应用的未来需求。但 RDF 存储模式所含有大量三元组的数据，使其索引效率与更新维护成本大于其它图存储模式。因此，未来知识存储的一种研究趋势为如何利用分布式数据库系统来解决 RDF 数据的大规模增长问题。 </li><li><b>设计高适应性的知识存储</b>：如何设计出可支持对复杂节点的定制、具有良好可伸缩性和灵活性的知识存储模式，满足复杂的查询、读取、计算和应用需求是知识存储方面的迫切需求。</li><li><b>基于链接开放数据(LOD)的知识存储</b>：由于知识表示 RDF 模型的通用性和灵活性，知识图谱供应方越来越倾向将自身的知识图谱数据表示成RDF格式并发布到互联网上。通过 URI 相互链接起来，这些发布在互联网上的 RDF 数据共同构成了一个覆盖整个互联网的庞大知识图谱。为了让这个庞大知识图谱网络更加丰富和完善，W3C 积极推进LOD项目。LOD 已成功将数百个 RDF 数据集相互链接在一起以增强数据的可用性。 </li><li><b>超图的进一步研究和应用</b>：超图所拥有的简单图无可比拟的复杂关系表示方式，能更加全面详尽地描述业务、还原场景。但目前对超图的可视化表示方法还没有理想方案，对于超图的划分方式、深度学习及应用，大部分仍处于实验室研究阶段。推广到各领域进行工程化运用，无论在计算效率和成本上都存在较大 问题。但随着知识图谱的普及，未来对于复杂关系的表示的需求，将逐步 增多，超图技术的研究和应用探索将是知识图谱的下一个方向。 </li></ul><h2>知识融合</h2><h3>知识融合概述</h3><p>维基百科认为<b>知识融合</b>是对来自多源的不同概念、上下文和不同表达等信息进行融合的过程；Smirnov 等人认为<b>知识融合</b>的目标是产生新的知识，是对松耦合来源中的知识进行集成，构成一个合成的资源， 用来补充不完全的知识和获取新知识；唐晓波等人在总结众多知识融合概念的基础上认为<b>知识融合</b>是知识组织与信息融合的交叉学科，它面向需求和创新，通过对众多分散、异构资源上知识的获取、匹配、集成、挖掘等处理，获取隐含的或有价值的新知识，同时优化知识的结构和内涵，提供知识服务。 </p><h3>知识融合过程</h3><p>知识融合是一个不断发展变化的概念，以往研究者的表述、角度、侧重不同，但研究成果中仍有共性。</p><p><b>知识融合</b>是面向知识服务和决策问题，以多源异构数据为基础，在本体库和规则库的支持下，通过知识抽取和转换获得隐藏在数据资源中的知识因子及其关联关系，进而在语义层次上组合、推理、创造出新知识的过程，并且这个过程需要根据数据源的变化和用户反馈进行实时动态调整。 </p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-524862f4c9efec011ae13866a94988af_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1180\" data-rawheight=\"516\" class=\"origin_image zh-lightbox-thumb\" width=\"1180\" data-original=\"https://pic4.zhimg.com/v2-524862f4c9efec011ae13866a94988af_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1180&#39; height=&#39;516&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1180\" data-rawheight=\"516\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1180\" data-original=\"https://pic4.zhimg.com/v2-524862f4c9efec011ae13866a94988af_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-524862f4c9efec011ae13866a94988af_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>知识融合研究现状</h3><p>知识融合从融合层面划分可以分为<b>数据层</b>知识融合与<b>概念层</b>知识融合。 - <b>数据层知识融合技术</b>：<b>实体链接</b>问题是数据层知识融合研究的主要任务，其核心是构建多类型多模态上下文及知识的统一表示，并建模不同信息、不同证据之间的相互交互，主要的实体链接方法有：基于实体知识的链接方法、基于篇章主题的链接方法和融合实体知识与篇章主题的实体链接方法。  - <b>概念层知识融合技术</b>：概念层知识融合是对多个知识库或者信息源在概念层进行模式对齐的过程。<b>本体对齐</b>或者<b>本体匹配</b>是概念层知识融合主要研究任务，是指确定本体概念之间映射关系的过程。本体匹配可以分为单语言本体匹配和跨语言本体匹配，单语言本体匹配是指同一自然语言中本体的对齐映射，跨语言本体匹配是指从两个或多个独立的语言本体中建立本体之间映射关系的过程。本体匹配的研究核心就在于如何通过本体概念之间的相似性度量，发现异构本体间的匹配关系，本体匹配基本方法包括基于结构的方法、基于实例的方法、基于语言学的匹配算法、基于文本的匹配算法和基于已知本体实体联结的匹配算法。  - <b>跨语言知识融合技术</b>：跨语言知识图谱研究的目的是构建一个包含当前重要知识库的大规模跨语言知识库，提高不同语言之间链接数据的国际化以及知识共享全球化，便于跨语言信息检索、机器翻译和跨语言知识问答等跨语言处理任务的研究与应用。 - <b>现有知识融合工具</b>：Falcon-AO、YAM++、Dedupe 等。Falcon-AO 是由南京大学计算机软件新技术国家重点实验室开发的一个基于 Java 的自动本体匹配系统。</p><h3>知识融合技术发展趋势</h3><ul><li><b>短文本及资源缺乏环境下的实体链接方法</b>：传统实体链接任务主要针对长文档，长文档的<b>上下文信息</b>能辅助实体的歧义消解并完成链接。短文本的实体链接存在口语化严重、短文本上下文语境不丰富等挑战。大部分实体链接模型依赖于有监督模型，需要大量标签数据集训练，因此短文本及资源缺乏环境下，基于<b>无监督/半监督</b>和<b>迁移学习</b>的实体链接模型是解决问题的关键。</li><li><b>融合先验知识的端到端深度学习实体链接方法</b>：基于深度学习的模型（如 BiLSTM-CRF）在实体链接任务上取得了较大进展，但深度学习算法需要大量标注数据集、缺少面向特定领域特点和任务的针对性设计。实体链接方法也可能受到实体识别等前序过程的误差影响。针对这些问题，一些研究尝试在深度学习模型中增加句法结构、语言学知识、特定领域任务约束、现有知识库知识和特征结构等，更好地利用<b>结合先验知识</b>；另外，设计端到端模型将有助于<b>降低</b>实体链接过程中的<b>误差传播</b>效应。</li><li><b>大规模本体的高效匹配方法</b>：大规模本体匹配的快速 并行计算问题和人机协同匹配问题。针对这个问题主要的思路有：（1）研究基于分布式处理技术的大规模本体匹配分布式处理算法，如研究利用 MapReduce、GPU 等技术的并行匹配算法，提高匹配效率；（2）研究利用现有本体匹配结果实现潜在本体匹配的方法，同时利用启发式相似度计算方法提高计算效率；（3）通过对实体匹配进行预剪枝，预先过滤不匹配的实体对，避免本体之间一对一的相似度计算。 </li></ul><h2>知识建模</h2><h3>知识建模概述</h3><p><b>知识建模</b>是指建立知识图谱的数据模型，即采用什么样的方式来表达知识，构建一个本体模型对知识进行描述。在本体模型中需要构建本体的概念，属性以及概念之间的关系。 </p><p>知识建模一般有<b>自顶向下</b>和<b>自底向上</b>两种途径： - 自顶向下：构建知识图谱时首先定义数据模式即本体，一般通过领域专家人工编制。从最顶层的概念开始定义，然后逐步细化，形成结构良好的分类层次结构。  - 自底向上：首先对现有实体进行归纳组织，形成底层的概念，再逐步往上抽象形成上 层的概念。自底向上的方法则多用于开放域知识图普的本体构建，因为开放的世界太过复杂，用自顶向下的方法无法考虑周全，且随着世界变化，对应的概念还在增长，自底向上的方法则可满足概念不断增长的需要。 </p><h3>知识建模方法</h3><p>分为<b>手工建模方式</b>和<b>半自动建模方式</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b16e10b8616ceed0c981fdbdcd5ad5ae_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"998\" data-rawheight=\"446\" class=\"origin_image zh-lightbox-thumb\" width=\"998\" data-original=\"https://pic3.zhimg.com/v2-b16e10b8616ceed0c981fdbdcd5ad5ae_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;998&#39; height=&#39;446&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"998\" data-rawheight=\"446\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"998\" data-original=\"https://pic3.zhimg.com/v2-b16e10b8616ceed0c981fdbdcd5ad5ae_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b16e10b8616ceed0c981fdbdcd5ad5ae_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-52a1b344207e24d40a9e122de7e37020_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1002\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"1002\" data-original=\"https://pic1.zhimg.com/v2-52a1b344207e24d40a9e122de7e37020_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1002&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1002\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1002\" data-original=\"https://pic1.zhimg.com/v2-52a1b344207e24d40a9e122de7e37020_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-52a1b344207e24d40a9e122de7e37020_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><ul><li>手工建模方式：包含六个步骤，明确领域本体及任务、模型复用、列出本体涉及领域中的元素、明确分类体系、定义属性及关系、定义约束条件。人工建模过程中，这六个步骤并不是一一顺序执行的，可根据具体需求组合其中的步骤。</li><li>半自动建模方式：先通过<b>自动方式获取</b>知识图谱，然后进行大量的<b>人工干预</b>过程。运用自然语言处理技术先<b>自动建模</b>的方法可分为三大类：</li><ul><li>基于结构化数据的知识建模方法</li><li>基于半结构化数据的知识建模方法</li><li>基于非结构化数据的知识建模方法，这方面研究较多</li></ul></ul><h3>知识建模评价</h3><p>一个合理的本体模型应满足以下标准： - <b>明确性和客观性</b>：用自然语言对所定义术语给出明确的、客观的语义定义。  - <b>完全性</b>：定义是完整的，完全能表达所描述领域内术语的含义。 - <b>一致性</b>：正确一致地展示数据、对象和信息，由术语得出的推论与术语本身含义不会产生矛盾。 - <b>最大单调可扩展性</b>：添加通用或专用的术语时，不需要修改己有的内容，便于知识图谱扩展。 - <b>最小承诺</b>：尽可能少的约束，指本体约定应该最小，对建模对象尽可能少的约束。  - <b>易用性</b>：有效地支撑业务的分析和决策需求。</p><h3>知识建模技术发展趋势</h3><ul><li><b>大规模</b>数据建模将发展，多人在线编辑，实时更新知识建模将成为可能。</li><li>与自动语义处理算法结合，实现<b>全自动建模</b>方式，避免人工干预和操作。</li><li>集成现有的<b>结构化知识模型</b>，支撑起事件、时序等复杂知识形式的表达模式。</li></ul><h2>知识计算</h2><h3>知识计算概述</h3><p><b>知识计算</b>是基于已构建的知识图谱进行能力输出的过程，是知识图谱能力输出的主要方式，其主要内容包括： - 知识统计与图挖掘     - 重点研究知识查询、指标统计和图挖掘 - 知识推理     - 重点研究基于图谱的逻辑推理算法         - 基于符号的推理         - 基于统计的推理</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-33a6aa1b5ec50ec85b733b40790620c7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"908\" data-rawheight=\"802\" class=\"origin_image zh-lightbox-thumb\" width=\"908\" data-original=\"https://pic4.zhimg.com/v2-33a6aa1b5ec50ec85b733b40790620c7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;908&#39; height=&#39;802&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"908\" data-rawheight=\"802\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"908\" data-original=\"https://pic4.zhimg.com/v2-33a6aa1b5ec50ec85b733b40790620c7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-33a6aa1b5ec50ec85b733b40790620c7_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>知识计算的概念中明确了以下问题： - 知识计算是<b>针对已构建的知识图谱</b>所存在的问题：不完备性和存在错误信息，在此基础上通过将知识统计与图挖掘、知识推理等方法与传统应用相结合进行能力输出，为传统应用形态进行赋能，进而提高知识的完备性和扩大知识的覆盖面。  - 知识计算中两种具有代表性的能力：<b>知识统计与图挖掘</b>、<b>知识推理</b>。知识统计和图挖掘的方法是基于图特征的算法来进行社区计算、相似子图计算、链接预测、不一致检测等；知识推理的目标在于从给定知识图谱中推导出新的实体、关系和属性。通过这两种能力实现对已有图谱的知识补全、知识纠错、知识更新、知识链接等功能。在此基础上，知识计算的能力输出可应用于用户精准画像、决策数据、辅助决策意见、智能问答/搜索等方面。 </p><h3>知识计算研究现状</h3><p>知识计算的能力输出方法包括：<b>知识统计与图挖掘</b>、<b>知识推理</b>。</p><h3>知识统计与图挖掘</h3><p><b>知识统计与图挖掘</b>是指基于图论的相关算法，实现对知识图谱的基础性查询、统计分析和图挖掘计算。 </p><ul><li><b>图查询检索</b>：最常见的计算，常用于查询目标节点的 n 度关联方，或查询某子图结构，主要是以深度优先或广度优先等方式遍历网络，输出关联节点或同构实例。</li><li><b>图特征统计</b>：对图谱中单一节点、或多个节点的图特征以及属性特征进行统计计算的过程。单主体图特征包括出度、入度、介度和中心度，出度表征某节点发出的边的多少，定义为统计节点发出的关系总条数；入度表征某节点接收到的边的多少，定义为统计指向该节点的关系总条数；介度表征某节点桥接作用的重要性；中心度表征节点在当前子网中的重要性。</li><li><b>关联分析</b>：指分析图谱中两个节点间或多个节点间的关联关系、紧密程度，进而可以实现社群发现和分割，例如两个公司间的多度投资关系、 个人与某公司的最短路径、两人之间的加权距离，多个账户之间的转账关 系等等。常用的方法有路径查询、距离计算，输出结果为节点及节点间边 的距离和边的集合(路径)。</li><li><b>节点分类</b>：对节点根据图特征或关联属性特征进行分类。例如信用违约公司具有典型的风险路径，且一度关联方中的违约公司数量等均可作为分类特征指标、洗钱账户的转账关系子图特征可作为洗钱标签的分类依据。常用方法为标注目标节点，图特征提取，分类算法等，输出结果为特征图谱库等。 </li><li><b>异常检测</b> ：在全网内发现异常节点、异常子图模式，例如出入度数值离群的节点、闭环的投资关系、未知业务含义但是罕见的频繁子图等。常见方法是聚类、子图发现算法等。输出结果异常节点库、异常子图结构模式库为主。</li><li><b>预测推理</b>：通过规则或机器学习等方法，从已有知识图谱中预测推理新的关系和信息，适用于弱关系的推理、链接预测、概率推理等。常见方法有规则推理、机器学习等。输出结果为新节点、新关系、新属性等信息。 </li><li><b>时序分析</b>：对单一关系、事件做时序分析，或者对网络拓扑结构的变化做时序分析，例如频繁工商变更的行为、风险在网络中的传播等。常见方法有时序分析、风险传播模型等。输出结果为时序异常、风险评分等。 </li></ul><h3>知识推理</h3><p><b>知识推理</b>可定义为按照某种策略，根据现有知识推出新知识的过程。知识推理可以分为<b>基于符号推理</b>和<b>基于统计的推理</b>。在知识理解的基础上构建应用，知识图谱的应用大多基于对复杂网络的大规模计算，计算的结果，或以在线服务，或以离线结果的形式提供给应用侧。  基于知识推理的典型应用主要包括智能搜索、智能推荐、智能问答等。 </p><ul><li><b>智能搜索</b>：传统搜索引擎，以关键词检索为核心技术。这种查询方式得到的无关信息比较多，且查询方式较为机械，不是按照人的思维方式给出结果。引入知识图谱技术后的搜索引擎将该问题得到更智能的解决。</li><li><b>智能推荐</b>：根据大数据算法，勾勒用户画像，基于用户画像提供更多的精准营销服务。</li><li><b>智能问答</b>：传统问答对有多跳关系的问题难以处理。</li></ul><h3>知识计算技术发展趋势</h3><ul><li><b>基于小样本学习的知识计算</b>：大规模高质量样本的获取会消耗大量的人力和时间。</li><li><b>面向一致性动态变化的知识计算</b>：现有的知识计算方法主要针对的是静态知识图谱，然而知识图谱并不是一成不变的，随着时间和空间的推移，知识图谱也在动态的变化，即在不同的时间轴下相同问题的答案也可能存在不同。引入时间要素进行有效地动态计算是未来知识计算发展的重要趋势。 </li><li><b>面向多元关系和多源信息的知识计算</b>：现有的知识计算大都是集中在二元和三元关系上，但<b>多元关系</b>相对二元和三元关系来说结构更多样、上下文语义关系更复杂，所涉及到的常识也更多样，针对复杂多元关系的常用处理方法是将复杂的多元关系简化为二元关系或三元关系，但这个过程中大量的<b>语义信息和上下文关系</b>会被损失，面向多元关系的知识计算准确度不高，另外，信息的多源性使得知识计算过程中需要考虑<b>更多上下文问题</b>和<b>额外的常识</b>等信息，来降低知识图谱稀疏性和不连通性，从而进行高效的知识计算，使知识计算的结果更加趋向于完备，因此，如何更好的解决多元关系和多源信息融合场景下的知识计算问题将成为重要的研究方向。 </li></ul><h2>知识运维</h2><h3>知识运维概述</h3><p><b>小步快走、快速迭代</b>是知识图谱构建和演化的方式。<b>知识运维</b>是指在知识图谱初次构建完成之后，根据用户的使用反馈、不断出现的同类型知识以及增加的新的知识来源进行全量行业知识图谱的演化和完善的过程。</p><p>知识图谱的运维有两个关注点： - 从数据源方面的基于增量数据的知识图谱的<b>构建过程监控</b>。 - 通过知识图谱的应用层发现的<b>知识错误</b>和<b>新的业务需求</b>：例如错误的实体属性值、缺失的实体间关系、未识别的实体、重复实体等问题。 </p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4d6d1bffb786700de168b21ca87c281e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1144\" data-rawheight=\"734\" class=\"origin_image zh-lightbox-thumb\" width=\"1144\" data-original=\"https://pic3.zhimg.com/v2-4d6d1bffb786700de168b21ca87c281e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1144&#39; height=&#39;734&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1144\" data-rawheight=\"734\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1144\" data-original=\"https://pic3.zhimg.com/v2-4d6d1bffb786700de168b21ca87c281e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4d6d1bffb786700de168b21ca87c281e_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>知识运维研究现状</h3><ul><li><b>基于增量数据的知识运维</b>：构建知识图谱是一个持续和增量的过程。知识图谱增量更新包括新元素的加入(节点、边或对应的属性)、旧元素属性的更改。更复杂的场景下可能涉及已有元素的删除操作。两种主要的增量方式是：数据从消息队列导入图谱、利用工作流引擎定时更新图谱。</li><li><b>图谱内容统计监控</b>：对知识图谱中的实体、本体、属性、关系进行统计，能对图谱运行中间产生的各种异常情况进行集中的展示、问题提醒等功能。</li><li><b>知识审核与修正</b>：需要对知识图谱有明确的新增知识入库的标准和流程；在构建和运维图谱的时候需要有冲突检测以及多人协同编辑的功能。 </li><li><b>知识版本管理</b>：在知识图谱的管理中，引入版本概念，按知识的更迭进行管理。方便业务平滑升级，避免误操作后的知识丢失。</li><li><b>知识安全管理</b>：明确不同部门或层级的权限，有日志记录、操作记录、变更内容的记录，便于追踪异常。</li><li><b>知识容灾备份</b>：保证分布式图谱服务在某个或者某些节点失效时还能稳定可用，并且意外发生时图谱数据不至于完全丢失。</li></ul><h3>知识运维技术发展趋势</h3><ul><li><b>知识图谱的全生命周期质量保障</b>：具备知识运维能力的知识图谱平台主要功能宜包括:本体的构建，针对多种数据来源的结构化、半结构化、非结构化的数据类型在不同的技术下的知识获取，实体识别、关系识别、实体链接、实体属性抽取的实现， 基于本体概念和实体知识图谱间的验证，构建流程与运维过程的监控，对知识图谱构建过程中的各种异常情况的记录和反馈，对入库知识图谱的人工审核。此外，通过在知识图谱平台的知识库以版本的形式进行管理，避免知识运维中因为新知识的错误发布对现有业务的影响，提供给运维人员上线发布前的质量检测方法，并将经过严格测试验证的知识图谱版本正式生效上线，最终保证知识图谱全生命周期各环节的数据质量。 </li><li><b>多知识图谱的运维管控</b>：面向按照不同领域和范围下多个知识图谱的构建和运维，有待开发一套完备的平台对多个不同知识应用提供支撑。 </li></ul><h2>知识图谱面临的挑战</h2><h3>数据相关的挑战</h3><p>数据来源多样性造成数据标准不统一、数据质量差，导致多源数据歧义、 噪声大、数据间关联关系不明确等问题。数据歧义和关系不明确对知识图 谱构建和推理形成了阻碍，对知识图谱应用成效的提升和技术的进步提出了挑战。 </p><ul><li>多源数据的歧义、噪声大</li><li>数据关联性不明确</li></ul><h3>算法相关的挑战</h3><p>知识图谱技术是对语义网标准与技术的一次扬弃与升华，但知识图谱中的知识抽取、知识融合及知识计算等技术依然面临着许多困难与挑战。</p><h3>现有技术存在的算法挑战</h3><ul><li><b>知识抽取</b>：现有的知识元素(实体、关系)抽取技术与方法往往是在<b>限定领域、主题</b>的数据集上进行，虽然取得了较好的效果，但由于制约条件较多方法的可扩展能力不够强，未能很好地适应<b>大规模、领域独立、高效的开放式信息抽取</b>要求。基于大规模开放域的知识抽取研究仍处于起步阶段。</li><li><b>知识融合</b>：指代消解和实体对齐是知识融合中的关键步骤，仍有探索的空间。</li><li><b>知识计算</b>：目前的神经网络方法，需要大量训练样本支撑，通过少量样本学习模型需要探索。另外，现有算法所需计算资源和存储资源较大，应用到大规模数据集上需要较长时间。</li></ul><h3>算法性能的挑战</h3><ul><li><b>算法泛化能力差</b>：算法的扩展性差、对客户响应慢、维护成本高、不能随数据的动态变化而复用和扩展，已成为算法所面临的一系列问题。 </li><li><b>算法鲁棒性差</b>：不同来源的数据中抽取的知识可能存在大量噪声和冗余，甚至算法输入的数据可能恶意生成样本和训练数据污染，面对噪声数据的干扰、多源异构数据的复杂性及 AI 安全所带来的恶意增加的干扰数据，现有算法模型的鲁棒性还有待提高。 </li><li><b>算法多样化，缺乏统一的评测指标</b>：众多文献中对同一任务不同算法的评测指标都是针对开源数据集的研究，但在实际算法需求中数据的来源、格式、任务需求等存在差异。目前大规模知识图谱的应用场景都是针对特定的任务需求，如何选择恰当的算法并对不同的算法进行统一的评 定，进而实现图谱的智能化应用是一个研究方向。 </li></ul><h3>对算法可解释性的挑战</h3><p>可解释性是指判别过程是否可以转化成具备逻辑关系的规则。目前对深度学习领域中的一个显著的问题是，随着模型复杂性的增加，模型可解释性按同样的速度降低。另外，不同领域对算法可解释性的具体要求也不相同。</p><h3>基础知识库相关的挑战</h3><ul><li>基础知识库融合挑战：在构建大规模知识图谱时将涉及不同基础知识库数据，而且在不同基础知识库的融合过程中会出现数据不一致、格式不统一、数据质量参差不齐等问题。 </li><li>垂直领域知识库构建挑战：目前基础知识库多集中在通用百科领域，缺乏垂直领域的知识库。在垂直领域知识库构建过程中，会面临知识获取问题、知识库边界问题及专业知识的正确性验证问题。 </li></ul>", 
            "topic": [
                {
                    "tag": "知识图谱", 
                    "tagLink": "https://api.zhihu.com/topics/19838204"
                }, 
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "语义网", 
                    "tagLink": "https://api.zhihu.com/topics/19551341"
                }
            ], 
            "comments": [
                {
                    "userName": "林一二", 
                    "userLink": "https://www.zhihu.com/people/16c82891a98d1e3e49d07a9c75aae4dc", 
                    "content": "看起来也没标准化什么东西？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Y.Shu", 
                            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
                            "content": "<p>因为我关注的部分不是“标准化”，算是当综述来读的吧</p>", 
                            "likes": 0, 
                            "replyToAuthor": "林一二"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/86745138", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 1, 
            "title": "【WSDM 2019】基于知识图谱嵌入的问答系统", 
            "content": "<p>论文原文：Knowledge Graph Embedding Based Question Answering</p><p>基于知识图谱嵌入的问答系统</p><p>来源：WSDM 2019</p><p>关键词：问答系统，知识图谱嵌入，简单问题</p><h2>介绍</h2><p>知识图谱是将真实世界实体作为节点，它们的关系作为边的有向图。在该图中，每个有向边和它的头实体、尾实体组成了一个三元组 (head entity, predicate, tail entity). 这称为一个事实。真实世界的知识图谱通常包含大量的事实。它们庞大的数量和复杂的数据结构使普通用户难以访问其中的大量宝贵知识。 为了解决这一问题，基于知识图谱的问答（QA-KG）被提出。 它的目标是自动将终端用户的自然语言问题转换为结构化查询（例如SPARQL），并在结果中返回 KG 中的实体和/或谓词。</p><p>例如，考虑到“哪个奥运会是在澳大利亚举行的？”问题，QA-KG 旨在确定其相应的两个事实，即（澳大利亚，olympics_participated_in，1952/2004年夏季奥运会）。</p><p>知识图谱上的问答系统为人工智能系统提供了一种将知识图谱作为回答人类问题的关键要素的方法，其应用范围从搜索引擎设计到会话代理构建。 但是，QA-KG 问题远未解决，因为它涉及多个具有挑战性的子问题，例如语义分析和实体链接。</p><p>知识图谱嵌入在不同的实际应用中的有效性促使作者探索其在解决 QA-KG 问题中的潜在用途。知识图谱嵌入的目标是学习 KG 中每个谓词/实体的低维向量表示，以使原始关系很好地保留在向量中。这些学习的向量表示可以被用来有效地完成各种下游应用。示例包括 KG 补全，推荐系统和关系提取。在该文中，作者建议利用知识图谱嵌入的优势来执行 QA-KG。 KG 嵌入表示可以以多种方式推进 QA-KG。它们不仅在低维空间内，而且还可以促进下游应用程序将整个 KG 纳入考虑范围，因为即使单个谓词/实体表示也是与整个 KG 交互的结果。另外，相似的谓词/实体倾向于具有相似的向量。这种属性可以帮助下游算法处理不在训练数据中的谓词或实体。</p><p>然而，基于知识图谱嵌入构建 QA-KG 始终并非易事。主要的挑战有三个：</p><ul><li>谓词在自然语言问题中通常有不同的表达。这些表达可能与谓词的名称截然不同。例如 person.nationality 可以被表达为 “谁的国籍是？”“谁来自哪个国家？”“谁来自哪里？”等。</li><li>即使假设实体名称可以被准确地识别，由于候选者的数量通常很大，因此实体名称和部分名称的歧义仍使得很难找到正确的实体。 随着 KG 规模的不断增加，许多实体将使用相同的名称。同样，终端用户可以在他们的话语中使用部分名称。 例如，在“奥巴马几岁了？”问题中，仅显示实体名称「巴拉克•奥巴马」的一部分。 </li><li>终端用户的问题域通常是无限制的，并且任何一个 KG 都不是完整的。 新问题可能涉及与训练中所用谓词不同的谓词。 这对 QA-KG 算法的鲁棒性提出了要求。</li></ul><p>为了解决这些问题，作者探索了知识图谱嵌入在执行问答任务中的优势。在该文中，作者关注于 QA-KG 中最常见的问题类型，即简单问题。一个<b>简单问题</b>是一种自然语言问题，它仅涉及单个头部实体和单个谓词。通过分析问题，作者旨在回答三个研究问题。</p><ul><li>如何运用谓词嵌入表示法来弥合自然语言表达与 KG 谓词之间的差距？</li><li>如何利用实体嵌入表示法来解决歧义性挑战？</li><li>如何利用 KG 嵌入表述中蕴含的全局关系来推进 QA-KG 框架？</li></ul><p>在这些问题之后，作者提出一个简单的框架，名为基于知识嵌入的问题回答（KEQA），该文的主要贡献如下：</p><ul><li>正式定义基于知识图谱嵌入的问答系统。</li><li>提出一个有效的框架 KEQA，该框架可以通过在知识图谱嵌入空间中共同恢复其头实体、谓词和尾实体来回答自然语言问题。</li><li>设计一个联合距离度量标准，该度量标准考虑了嵌入表示形式的知识图谱中保留的结构和关系。</li><li>在一个大型基准（即 SimpleQuestions）上以经验证明 KEQA 的有效性和鲁棒性。</li></ul><h2>基于知识嵌入的问答</h2><p>简单问题构成了 QA-KG 问题的大部分问题。 如果标识了正确的头实体和谓词，则尾部实体可以回答任何简单问题。【这里能否理解为，QA-KG 实际上是一个构建一个规模很大的映射，键是头实体和谓词，而值是尾实体。实际上记忆网络也已经应用到知识库问答中。】为了准确地识别头实体和谓词，作者提出了基于知识嵌入的问答框架（KEQA）。 KG 已嵌入两个低维空间中，并且每个事实都可以表示为三个潜在向量组成的三元组。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-fc674320e96ae601146243d30a535693_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2086\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"2086\" data-original=\"https://pic4.zhimg.com/v2-fc674320e96ae601146243d30a535693_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2086&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2086\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2086\" data-original=\"https://pic4.zhimg.com/v2-fc674320e96ae601146243d30a535693_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-fc674320e96ae601146243d30a535693_b.jpg\"/></figure><p>因此，给定一个问题，只要我们可以识别其对应事实的头实体和谓词，那么这个问题就可以正确回答。</p><p>KEQA 通过三个步骤实现了目标。</p><ul><li>基于问题集合中的问题及其谓词的嵌入表示，KEQA 训练一个谓词学习模型，该模型将问题作为输入并返回位于 KG 嵌入空间中的向量作为预测的谓词表示。类似地，可以构造一个头实体学习模型来预测问题的头实体表示。 </li><li>由于 KG 中的实体数量通常很大，因此 KEQA 使用 Head Entity Detection 模型来减少候选的头实体。主要目标是将问题中的多个标记识别为预测的头实体名称，然后将搜索空间从整个实体缩减为多个具有相同或相似名称的实体。然后头实体在嵌入空间中的向量主要用于解决歧义性挑战。</li><li>给定 KG 嵌入算法定义的关系函数 f(·) ，KEQA 计算预测的尾实体表示 f(头实体向量，谓词向量)，在精心设计的联合距离度量的基础上，预测事实的最接近的事实将作为问题的答案返回。</li></ul><h3>知识图谱嵌入</h3><p>提出的 KEQA 框架使用了所有谓词 P 和实体 E 的嵌入表示作为基础架构。作者使用现有的 KG 嵌入算法来学习 P 和 E.</p><p>知识图谱嵌入意图表示 KG 的每个谓词/实体为低维向量，这样知识图谱原有的结构和关系都蕴含在这些学习所得的向量中。大多数 KG 嵌入方法的核心思想可以被归结为：每个知识图谱中的事实三元组，表示为三个向量的三元组。嵌入算法随机初始化三个向量，或基于训练的词嵌入模型。然后，定义用于测量嵌入空间中的事实关系的函数 f(·)。 最后，对于知识图谱中的所有事实，嵌入算法都会使尾实体向量和通过函数预测所得向量之间的总距离最小化。一种典型的方法是定义基于边距的排名标准，并对正样本和负样本进行训练，即知识图谱中的事实和不存在其中的伪造的事实。</p><h3>谓词和头实体学习模型</h3><p>给定一个简单问题，目标是找到谓词嵌入空间的一个点作为谓词的表示向量，并在实体嵌入空间中找到一个点作为头实体的表示向量。</p><p>对于所有知识图谱可以解答的问题，它们的谓词向量必然在谓词嵌入空间中。因此，作者意图设计一个模型，将问题作为输入，并返回一个尽可能接近于问题谓词嵌入表示的向量。为了实现这个目标，作者使用了一个简单的神经网络结构。它主要包含一个双向循环神经网络层和一个注意力层。关键思想是将顺序和单词的重要性考虑到。单词的不同顺序组合可能表示不同的意思，不同单词的重要性也是不同的。例如，问题中实体名称相关的单词对谓词学习模型的影响更小。</p><blockquote>为什么这种方法能弥合问题中谓词和知识图谱中的谓词之间的差异？</blockquote><p>因为这种方法没有直接通过概率等方式生成谓词，而是通过神经网络计算表示谓词和头实体的向量表示。即使问题中出现的谓词，是训练过程从未出现过的谓词，神经网络也能学习出一个表示。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-de0513f462e7bb135c34be3f0b029b9d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"996\" data-rawheight=\"892\" class=\"origin_image zh-lightbox-thumb\" width=\"996\" data-original=\"https://pic2.zhimg.com/v2-de0513f462e7bb135c34be3f0b029b9d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;996&#39; height=&#39;892&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"996\" data-rawheight=\"892\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"996\" data-original=\"https://pic2.zhimg.com/v2-de0513f462e7bb135c34be3f0b029b9d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-de0513f462e7bb135c34be3f0b029b9d_b.jpg\"/></figure><p><b>基于神经网络的谓词表示学习 </b>为了预测问题的谓词，传统方法是基于语义解析和手动构建的词汇表学习映射，或者只将谓词类型作为标签类别，将它转换为一个分类问题。</p><p>然而，既然终端用户的问题域通常是没有边界的，一个新问题的谓词可能与训练数据中出现过的所有谓词都不相同。传统方法不能解决这种场景。另外，作者观察到蕴含在 P 和 E 中的全局关系信息是可用的，并可能可以用于提升问答的整体准确率。为了弥补谓词在问题和知识图谱中的差异，作者构建了一个基于神经网络的谓词学习模型。</p><p>使用 LSTM 作为循环神经网络的典型样例，图 2 阐述了所提解决方案的结构。</p><p><b>基于神经网络的头实体学习模型 </b>给定一个问题，而不是直接推断头实体，目标是在 KG 嵌入空间中恢复它的表示。因此，头实体学习模型的目标是计算头实体的向量，使它尽可能接近问题的头实体嵌入表示。这个问题是类似于谓词表示的学习的，作者使用图 2 中相同的网络结构来获得预测头实体的表示。</p><blockquote>头实体学习模型和头实体检测模型之间有什么关系？</blockquote><p>然而，KG 中的实体数量通常很大，将头实体的向量和所有实体嵌入表示进行比较可能是昂贵的和有噪声的。为了让学习更加有作用和高效，KEQA 使用头实体检测模型来减少候选头实体的数量。</p><h3>头实体检测模型</h3><p>在这一步骤中，目标是选择问题中的一个或多个连续的记号作为头实体的名称，这样搜索空间能从整个实体减少到有相同或相似名称的几个实体。然后，头实体向量的作用就是处理歧义性挑战。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b7e3e91f92f098551ca18c407586075d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"976\" data-rawheight=\"814\" class=\"origin_image zh-lightbox-thumb\" width=\"976\" data-original=\"https://pic2.zhimg.com/v2-b7e3e91f92f098551ca18c407586075d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;976&#39; height=&#39;814&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"976\" data-rawheight=\"814\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"976\" data-original=\"https://pic2.zhimg.com/v2-b7e3e91f92f098551ca18c407586075d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b7e3e91f92f098551ca18c407586075d_b.jpg\"/></figure><p>作者使用了基于 LSTM 的模型来执行头实体标记检测任务。头实体检测模型如图 3 所示。它与谓词/头实体学习模型有相似的结构，但没有注意力层。通过该结构，将记号分类，并识别一个或几个记号为头实体名称。</p><p>作者使用问题集中的头实体名称作为训练数据来训练头实体检测模型。因为这些问题中的实体名称记号是连续的，被训练的模型也会返回具有高概率值的连续记号。如果离散的实体被返回，每个连续部分可以被认为是独立的头实体名称。需要注意的是， 返回的头实体可能是正确的头实体名称的一部分。因此，所有与返回实体相同或包含返回实体的实体都将被包括在内，作为候选的头实体，这可能仍然很多，因为许多实体在一个大的 KG 中会共享相同的名称。</p><p>然后，作者提出了度量事实三元组之间距离的方法。此处暂时略去。</p><h2>结论与未来工作</h2><p>知识图谱上的问答是一个至关重要的工作，因为它允许普通用户在大规模知识图谱上通过自然语言轻松访问有价值但复杂的信息。它也是有挑战的一项工作，因为一个谓词可能有不同的自然语言表达。对于机器来说，捕捉语义信息是困难的。另外，即使假设一个问题的实体名称被准确识别，实体名称的歧义和不完整的名称也可能使候选实体的集合比较大。</p><p>为了弥补这个差距，作者调查一种新的基于知识图谱嵌入的问答问题，并设计了一个简单且有效的 KEQA 框架。它的目标在于解决简单问题，即 QA-KG 中最常见的问题类型。相比于直接推断头实体和谓词，KEQA 采用的方法是在 KG 嵌入空间中联合恢复问题的头实体、谓词和尾实体表示。基于注意力的双向 LSTM 模型被用于计算谓词和头实体表示学习。因为KG 中所有实体涉及到的计算代价和噪声，头实体检测模型被用于选择问题中的连续记号作为头实体名称，如此候选实体集被缩小到具有相同或类似名称的范围内。给定一个预测事实三元组，一个仔细设计的联合距离准则被用于度量所有候选事实之间的距离。具有最小距离的事实被返回为答案。在大规模基准测试上的实验表明，KEQA 取得了最先进的效果。</p><p>在未来工作中，作者计划研究以下问题：</p><ul><li>KEQA 基于预训练 KG 嵌入进行问答任务，我们如何通过联合进行 KG 嵌入和问答任务提升它？</li><li>真实世界的知识图谱和训练问题通常是动态更新的，如何扩展这个架构来处理这个场景？</li></ul><p class=\"ztext-empty-paragraph\"><br/></p><p>关于这项工作，个人认为存在的一些问题与个人的疑惑包括：</p><ul><li>只研究了简单问题，而知识图谱问答的研究在之后势必要深入到复杂问题及其分解当中去。</li><li>评估时出现训练集中没有的谓词的空缺(gap)问题，除了使用一个相对比较简单的神经网络计算嵌入向量之外，是否还有其他的策略？</li><li>头实体检测除了使用大量文本通过分类任务学习之外，是否还有其他思路？现有研究中，是否有例如基于规则的方法等其他方法来检测问题中的头实体？</li></ul>", 
            "topic": [
                {
                    "tag": "知识图谱", 
                    "tagLink": "https://api.zhihu.com/topics/19838204"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "问答系统", 
                    "tagLink": "https://api.zhihu.com/topics/19571693"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/86604724", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 5, 
            "title": "【EMNLP 2019】Language Models as Knowledge Bases?", 
            "content": "<p>原文：Language Models as Knowledge Bases?</p><p>语言模型作为知识库？</p><p>来源：EMNLP 2019</p><p>作者单位：Facebook AI 研究院，伦敦大学学院</p><p class=\"ztext-empty-paragraph\"><br/></p><p>该文不是为了阐述一个新的语言模型(language model)，或知识库(knowledge base)领域上的新方法，而主要关注的是实证研究，证明语言模型作为从文本抽取关系作为知识库的补充的可行性。具体实验结果请见原文。</p><h2>介绍</h2><p>语言模型用于预测句子中的下一个单词，或者给定句子预测其中任何位置的被掩盖的单词。预训练模型需要存储大量的对下游任务有用的语言学知识。通常通过以原始模型产生的潜在上下文表示为条件，或通过使用原始模型权重来初始化特定于任务的模型，然后进一步进行微调，来访问此知识。此类知识转移对于当前在各种任务上的最新成果至关重要。</p><p>与此对比，知识库是通过使用查询来访问带注释的有严格标准关系的数据的有效方案。 但是，在实践中，我们经常需要<b>从文本或其他方式中提取关系数据以填充这些知识库</b>。 这需要复杂的 NLP 流水线，包括实体提取，共指解析，实体链接和关系提取，这些组件通常需要监督数据和固定模式。 而且，错误很容易在整个流水线中传播和累积。相反，我们可以尝试通过要求以关系数据的形式查询神经语言模型，例如“ Dante出生于[Mask]”。在这种情况下，语言模型具有各种吸引人的属性：它们不需要架构工程，不需要人工注释，并且支持一组开放的查询。</p><figure data-size=\"small\"><noscript><img src=\"https://pic2.zhimg.com/v2-2ffb244d6f69644c4a67b492f178bbd9_b.jpg\" data-size=\"small\" data-rawwidth=\"698\" data-rawheight=\"580\" class=\"origin_image zh-lightbox-thumb\" width=\"698\" data-original=\"https://pic2.zhimg.com/v2-2ffb244d6f69644c4a67b492f178bbd9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;698&#39; height=&#39;580&#39;&gt;&lt;/svg&gt;\" data-size=\"small\" data-rawwidth=\"698\" data-rawheight=\"580\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"698\" data-original=\"https://pic2.zhimg.com/v2-2ffb244d6f69644c4a67b492f178bbd9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2ffb244d6f69644c4a67b492f178bbd9_b.jpg\"/><figcaption>在知识库和语言模型中查询事实类知识</figcaption></figure><p>鉴于语言模型的上述特性可以作为关系知识的潜在表示形式，作者表示对预先训练的现成语言模型（例如 ELMo 和 BERT）中已经存在的关系知识感兴趣。 他们存储多少关系知识？ 对于不同类型的知识（例如有关实体的事实、常识和一般性问答），这有何不同？ 与从文本中自动提取的符号知识库相比，无需微调的性能如何？ 除了收集对这些模型的更好的一般理解之外，我们认为这些问题的答案可以帮助我们设计更好的无监督知识表示，这些知识表示可以将事实知识和常识性知识可靠地转移到下游任务，例如常识（视觉）问题解答或增强学习。</p><p>为了解答上述问题，该文介绍了 LAMA（LAnguage Model Analysis），包含一系列知识源，每个知识源包含一组事实。作者定义，一个语言模型<b>知道</b>一个事实（主体，关系，客体）当它在完形填空任务中能成功预测被掩盖的客体时。</p><p>作者测试各种类型的知识：存储在 Wikidata 中的实体之间的关系，ConceptNet 概念之间的常识关系以及回答 SQuAD 中自然语言问题所必需的知识。 在后一种情况下，作者手动映射SQuAD 问题的子集以结束句子。</p><p>这项研究揭示了：</p><ul><li>BERT-large 模型捕获了（准确的）关系知识，该知识与使用现成的关系提取器和基于oracle 的实体链接器从已知表示相关知识的语料库中提取的知识库相当。</li><li>事实知识可以从预训练语言模型中意外地很好地恢复，但是，对于某些关系（特别是 N 对M 关系）的性能非常差。</li><li>BERT-large 在恢复事实和常识性知识方面始终优于其他语言模型。</li><li>BERT-large 在开放域 QA 中取得了显着的结果，与使用任务特定的监督关系提取系统构建的知识库取得的 63.5% precision@10 相比，它取得了 57.1 % 的效果。</li></ul><h2>讨论与结论</h2><p>作者通过事实和常识问题的系统性分析，发现 BERT-large 能够比其竞争对手更好地回忆起这些知识，并且在非神经和有监督的替代品方面具有明显的竞争力。 请注意，作者没有比较相应的架构和目标在给定的正文中捕获知识的能力，而是将重点放在现有的预训练模型权重中所存在的知识上，这些模型已被许多研究人员用作研究的起点。了解我们常用的模型和学习算法正在捕获哪些数据方面是至关重要的研究领域，并且本文对许多专注于所学习数据的语言特性的研究进行了补充。</p><p>作者发现从与标准性能相当的文本中提取知识库，直接使用预训练的 BERT-large 并非难事。尽管为关系提取基线仅提供了可能表达目标事实的数据，从而减少了假阴性的可能性，以及使用了慷慨的实体链接预言。作者怀疑 BERT 可能由于其处理的数据量较大而具有优势，因此将 Wikitext-103 作为附加数据添加到关系提取系统，并且观察到性能没有明显变化。这表明尽管可能无法通过更多数据来提高关系提取性能，但将来在不断增长的语料库上训练的语言模型可能会成为将来从文本中提取的传统知识库的可行替代方案。</p><p>除了使用 LAMA 探针测试未来的预训练语言模型外，我们还希望量化关于各种自然语言模板的回忆事实知识的方差。此外，评估多记号答案仍然是作者评估设置面临的开放挑战。</p>", 
            "topic": [
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "知识库", 
                    "tagLink": "https://api.zhihu.com/topics/19553061"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/86246631", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 0, 
            "title": "【NAACL 2019】用于知识库问答的双向注意力记忆网络", 
            "content": "<p>原文：Bidirectional Attentive Memory Networks for Question Answering over Knowledge Bases</p><p>来源：NAACL 2019</p><h2>动机</h2><p>随着大规模知识库，例如 DBPedia 和 FreeBase 的快速发展，知识库问答在过去几年获得了越来越多的关注。给定自然语言的问题，KBQA 的目标是自动从基础知识库中找到答案，这提供了一种更自然和直观的方式来访问大量基础知识资源。</p><p>KBQA 的一个主要挑战是<b>词汇空缺</b>。例如，同一个问题可以在自然语言中以不同的方式表达，而知识库通常有一个规范的词典。因此，将自然语言问题映射到结构化知识库并非易事。</p><p>现有的解决知识库问答任务的方法大致可分为两类：<b>语义解析</b>和<b>信息检索</b>。</p><p>基于语义解析的方法通过构建一个语义解析器来解决这个问题，该解析器针对知识库，将自然语言问题转换成中间逻辑形式。</p><p>传统的语义解析器需要注释的逻辑形式作为监督，并且局限于具有少量逻辑谓词的狭窄领域。最近的研究通过构建手工构建的规则或特征模式匹配，以及使用外部资源的弱监督来克服这些限制。</p><p>基于语义解析的方法通常设定一个词汇触发或规则的预定义集合。不同于此，基于信息检索的方法根据问题中蕴含的信息，直接从知识库中获取答案。</p><p>这些基于信息检索的方法通常不要求手工的规则，因此能适应更大和更复杂的知识库。最近，深度神经网络在很多 NLP 任务中展现出了很好的效果。在 KBQA 领域中，归于 IR 方法下，很多基于嵌入的方法被提出，并且展现出好的效果。这些模型使用多种方式将问题和知识库子图编码到一个共有的嵌入空间中，并直接在该空间中进行匹配，通常能使用端到端的方式训练。</p><p>相比于现有的基于嵌入的将问题和知识库子图独立编码的方法，作者介绍了一种全新的双向注意力记忆网络，称为 BAMnet。它捕捉问题和底层知识库之间的相互作用，知识库存储在内容可寻址的存储器中。作者假设知识库对于理解问题是有帮助的。【相比于语义解析方法，或知识库和问题分开学习嵌入的方法，知识库没有在理解问题上发挥作用。】类似地，问题本身能帮助我们关注于知识库中的重要部分。</p><p>出于这个目的，作者设计了一个两层双向注意力网络。<b>主注意力网络</b>旨在根据知识库关注问题的重要部分，并根据问题关注知识库的重要方面。在此基础上，<b>辅注意力网络</b>旨在通过进一步利用双向注意来增强问题和知识库表示。通过这种分层双向注意的思想，我们能够提取出与回答问题和知识库两边的问题最相关的信息。</p><p>作者的贡献主要包括：</p><p>1)针对知识问答的任务，提出了一种新型的双向注意记忆网络，旨在直接模拟问题和知识问答之间的双向交互；</p><p>2)通过设计，该方法由于注意机制提供了良好的解释能力；</p><p>3)在 WebQuestions 基准测试中，该方法明显优于以前基于信息检索的方法，同时与基于(手工制作的)语义解析的方法保持竞争。</p><p>KBQA 主要有基于语义解析的方法和基于信息检索的方法。前者试图将自然语言问题转换为逻辑形式。最近的工作关注于基于外部资源的弱监督。</p><h2>模块化的针对 KBQA 的双向注意力记忆网络</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a1d8b5499bf819081233588f2efc2c56_b.jpg\" data-size=\"normal\" data-rawwidth=\"1340\" data-rawheight=\"626\" class=\"origin_image zh-lightbox-thumb\" width=\"1340\" data-original=\"https://pic3.zhimg.com/v2-a1d8b5499bf819081233588f2efc2c56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1340&#39; height=&#39;626&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1340\" data-rawheight=\"626\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1340\" data-original=\"https://pic3.zhimg.com/v2-a1d8b5499bf819081233588f2efc2c56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a1d8b5499bf819081233588f2efc2c56_b.jpg\"/><figcaption>BAMnet 模型的总体结构</figcaption></figure><p>给定一个自然语言问题，目标是从底层知识库中获取答案。BAMnet 模型包含四个组件：输入组件、记忆组件、推理组件和作答组件。</p><h3>输入组件</h3><p>一个输入的自然语言问题通过词嵌入层，被表示为词嵌入的序列。然后模型使用双向 LSTM 对问题进行编码。双向 LSTM 的隐藏状态组合了前向和反向的隐藏状态。</p><h3>记忆组件</h3><p><b>候选答案生成</b> 即使知识库中的所有实体在原则上都可能是答案，在计算上这是昂贵切不必要的。我们只需要考虑接近于问题中话题实体的那些实体。一个答案是一个实体节点的一段文本描述。在获取话题实体之后，作者将该实体相关的 h 跳之内的所有实体作为候选答案。</p><p><b>知识表示 </b>对于知识库中的每个候选答案，作者将三种类型的信息进行编码：答案类型、路径和上下文。</p><ul><li>答案类型：实体类型信息是对答案进行排序的重要线索。例如，如果一个问题使用疑问词where，那么与位置概念相关的候选答案更有可能是正确的。作者使用双向 LSTM 对文本描述进行编码来获取 d 维向量（最后一个前向和反向隐藏状态的拼接）。</li><li>答案路径：被定义为从候选答案到主体实体的一系列关系。</li><li>答案上下文：被定义为候选答案的周围实体（例如，同级节点），其可以帮助回答具有约束的问题。然而，对于没有约束的简单问题来说，答案上下文可能是不必要的，而且潜在地包含噪声。作者解决这一问题的两种策略是：1)使用一个新提出的重要性模块（随后解释）关注于答案中的重要方面，2)只考虑那些与问题重叠的上下文节点。具体而言，对于候选答案的每个上下文节点（即单词序列），首先计算它与问题之间的最长公共子序列，然后仅在获得非停用词子串时才通过 BiLSTM 对其进行编码。</li></ul><p><b>键值记忆模块</b> 模型使用键值记忆网络来存储候选答案。不同于基本的记忆网络，它的寻址阶段基于键存储，而读取阶段则使用值存储，这为通过功能分离对先验知识进行编码提供了更大的灵活性。</p><h3>推理组件</h3><p>推理组件包含一个泛化组件，和一个新提出的两层双向注意力网络，它意图在两个方向上捕捉问题和知识库的相互关系。</p><p><b>主注意力网络</b>包含一个知识库感知的注意力模块，关注于知识库中与问题相关的部分和问题中与知识库相关的部分。<b>辅注意力网络</b>意图通过进一步探索两个方向的注意力，增强问题和知识库。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-98a572747a26074c42b9eae58f7be93d_b.jpg\" data-size=\"normal\" data-rawwidth=\"758\" data-rawheight=\"444\" class=\"origin_image zh-lightbox-thumb\" width=\"758\" data-original=\"https://pic2.zhimg.com/v2-98a572747a26074c42b9eae58f7be93d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;758&#39; height=&#39;444&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"758\" data-rawheight=\"444\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"758\" data-original=\"https://pic2.zhimg.com/v2-98a572747a26074c42b9eae58f7be93d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-98a572747a26074c42b9eae58f7be93d_b.jpg\"/><figcaption>推理组件中的知识库感知的注意力模块</figcaption></figure><p><b>知识库感知的注意力模块 </b>一个问题中的单词并不都是平等的。作者使用一个知识库感知的注意力机制关注于问题的关键部分。AddAtt 指 additive attention，SelfAtt 指 self-attention.</p><h2>结论与未来工作</h2><p>为了实现 KBQA，作者引入了一种新颖而有效的双向注意力记忆网络。 这是第一个对问题和知识库之间的交互进行建模的模型，它使我们能够提取与回答问题和知识库两边最相关的信息。 </p><p>将来，作者想探索对更复杂的约束类型（例如顺序，比较和聚合）建模的有效方法。</p>", 
            "topic": [
                {
                    "tag": "知识库", 
                    "tagLink": "https://api.zhihu.com/topics/19553061"
                }, 
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "问答系统", 
                    "tagLink": "https://api.zhihu.com/topics/19571693"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/86128329", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 0, 
            "title": "【VLDB 2017】KBQA: 在 QA 语料库和知识库上学习问答", 
            "content": "<p>原文：KBQA: Learning Question Answering over QA Corpora and Knowledge Bases</p><p>来源：VLDB 2017，arXiv1903.02419v1</p><p>作者单位：复旦大学，上海市数据科学重点实验室</p><p>原文在阐述时大量举例，行文思路清晰，对知识库问答这一领域提出了重要的见解。</p><h2>介绍</h2><p>智能问答引起了很多研究兴趣。一个 QA 系统被设计为回答特定类型的问题。最重要的问题类型之一是<b>事实类问题</b> (FQ)，它的问题是关于一个实体的客观事实。事实类问题的一种特殊类型，称为<b>二元事实类问题</b> (BFQ)，询问关于一个实体的属性的问题。</p><p>例如，「火奴鲁鲁有多少人口？」如果我们能够回答 BFQ，那么我们将能够回答其他类型的问题，例如 1)排名问题：哪个城市的人口数量排第三？ 2)比较问题：火奴鲁鲁或新泽西哪个城市人口更多？3)列举问题：根据人口列举城市等。在 BFQ 和它的变种之外，我们可以回答一个复杂的事实类问题，例如 「贝拉克·奥巴马的妻子是何时出生的？」这可以通过组合两个 BFQ 的回答来给出解答。「谁是贝拉克·奥巴马的妻子？」（米歇尔·奥巴马）「米歇尔·奥巴马是何时出生的？」（1964）。作者定义一个<b>复杂事实类问题</b>为一个可以分解为一系列 BFQ 的问题。在该文中，作者关注于 BFQ 和复杂事实类问题。</p><p>基于知识库的问答已有较长历史。最近，大规模知识库变得可用，包括 Google 知识图谱、Freebase、YAGO2 等，极大地提升了 QA 系统的重要性和商业价值。</p><p>大多数知识库采用 RDF 作为数据格式，并且包含百万级或十亿级的 SPO 三元组（主体、谓词、客体）。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-aaf6c01403e3993b1b14f4311b9bd8b3_b.jpg\" data-size=\"normal\" data-rawwidth=\"1026\" data-rawheight=\"654\" class=\"origin_image zh-lightbox-thumb\" width=\"1026\" data-original=\"https://pic4.zhimg.com/v2-aaf6c01403e3993b1b14f4311b9bd8b3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1026&#39; height=&#39;654&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1026\" data-rawheight=\"654\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1026\" data-original=\"https://pic4.zhimg.com/v2-aaf6c01403e3993b1b14f4311b9bd8b3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-aaf6c01403e3993b1b14f4311b9bd8b3_b.jpg\"/><figcaption>一个演示用 RDF 知识库，dob 表示出生日期，pob 表示出生地点。 </figcaption></figure><p>给定针对知识库的问题，我们面临两个挑战：在哪种表示形式中我们理解了问题（问题表示的设计），以及如何将表示形式映射到针对知识库的结构化查询（语义匹配）？</p><p><b>问题表示的设计 </b>问题描述了很多意图，一个意图有很多种问题模板。QA 系统对于不同问题需要不同的表示形式。这些表示必须满足：1) 识别相同语义的问题，2)区分不同的问题意图。在作者使用的 QA 语料库中，作者发现 2782 种问题意图上有 2700 万个问题模板。所以设计问题表示来处理这个问题是一项巨大的挑战。</p><p><b>语义匹配 </b>在解决问题的表示后，需要将问题的表示映射到结构化查询。对于 BFQ，结构化查询通常依赖于知识库中的谓词。因为谓词和问题表示之间的差别，找到映射方法并不容易。另外，在 RDF 图中，许多二元关系不只依赖于一条边，而是一个复杂结构。“spouse of”可以表示为一条路径：婚姻-人-姓名。对于作者使用的知识库，超过 98 % 的意图对应于复杂结构。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c453d534843ec72340f5581e3265f262_b.jpg\" data-size=\"normal\" data-rawwidth=\"1016\" data-rawheight=\"392\" class=\"origin_image zh-lightbox-thumb\" width=\"1016\" data-original=\"https://pic3.zhimg.com/v2-c453d534843ec72340f5581e3265f262_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1016&#39; height=&#39;392&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1016\" data-rawheight=\"392\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1016\" data-original=\"https://pic3.zhimg.com/v2-c453d534843ec72340f5581e3265f262_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c453d534843ec72340f5581e3265f262_b.jpg\"/><figcaption>自然语言中的问题和它对应的知识库中的谓词</figcaption></figure><p>因此，（知识库问答系统研究的）关键问题是通过适当的问题表示法在自然语言问题和知识库谓词之间建立映射。</p><h2>现有研究</h2><p>根据以前的基于知识的 QA 系统表示问题的方式，作者将其大致分为三类：基于规则，基于关键字和基于同义词。</p><p><b>基于规则的问题表示</b> 基于规则的方法使用手动构建的规则将问题映射到谓词。这导致了高 precision 和低 recall（低覆盖问题种类），因为手动构建用于大量问题的规则是不可行的。</p><p><b>基于关键字的问题表示</b> 基于关键字的规则使用问题中的关键字，并通过关键字匹配将问题映射到谓语。但总的来说，使用关键字不容易找到映射，因为知识库中的一个谓词表示无法匹配自然语言中的各种表示。</p><p><b>基于同义词的问题表示</b> 基于同义词的方法考虑到谓词的同义词，扩展了基于关键字的方法。这类方法，首先对每个谓词生成同义词，然后找到问题和同义词之间的映射。DEANNA 是一个典型的基于同义词的 QA 系统。主要思想是将 QA 简化为评估谓词和候选同义词（问题中的单词/段落）之间的<b>语义相似度</b>。它使用维基百科来计算语义相似度。gAnswer 通过针对更复杂的子结构学习同义词，进一步提升了 precision. 但作者此处举例说明，对于一些比较复杂的问题描述，或者没有指明上下文的问题描述，这类方法仍然无法解答。</p><p>总体上，这些工作不能解决上述的挑战。对于基于规则的方法，它需要难以承受的人工标注的努力。对于基于关键字或基于同义词的方法，一个单词或一个段落不能完整表示问题的语义意图。我们需要问题作为一个整体来理解。如果问题是一个复杂的问题，或映射到知识库中的一个复杂的结构，则对于以前的方法来说甚至更加困难。</p><h2>该文新方法的概览</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f9414cd462ee850191809951efebd236_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1004\" data-rawheight=\"346\" class=\"origin_image zh-lightbox-thumb\" width=\"1004\" data-original=\"https://pic3.zhimg.com/v2-f9414cd462ee850191809951efebd236_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1004&#39; height=&#39;346&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1004\" data-rawheight=\"346\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1004\" data-original=\"https://pic3.zhimg.com/v2-f9414cd462ee850191809951efebd236_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f9414cd462ee850191809951efebd236_b.jpg\"/></figure><p>为了解答一个问题，我们必须首先表示一个问题。通过表示一个问题，我们意图将问题从自然语言表示转换为捕捉问题语义和意图的内部表示。然后，对于每个内部表示，我们学习如何将它映射为对于知识库的 RDF 查询。</p><p>因此，作者表示该工作的核心是问题的内部表示，被称作<i>模板</i>。</p><p><b>通过模板表示问题 </b>同义词方法的失败启发了作者通过模板去理解问题。例如，「有多少人在$city? 」是一个模板，$city 表示火奴鲁鲁或其他城市，这个模板总是询问问题中提到的人口。</p><p>然后，表示一个问题的任务是将问题映射到模板上。为了实现这一点，作者将问题中的实体替换为它的概念。例如，火奴鲁鲁被 $city 替换。这个过程并不简单，它是通过一个称为<b>概念化</b>的机制完成的，它自动在输入上消除歧义。（apple 的总部是什么中的 apple 会被概念化为 $company 而不是$fruit）概念化机制本身基于一个大型语义网络，由数百万的概念组成，因此我们能有足够的粒度来表示各种问题。</p><p>模板的概念也适用于复杂问题。通过使用模板，作者将复杂问题分解为一系列问题，每个问题对应于一个谓词。</p><p><b>将模板映射到谓词 </b>首先，对于雅虎问答的每个 QA 对，作者提取问题中的实体和相应的值。 然后，通过查找连接实体和值的直接谓词，从知识库中找到谓词。 基本思想是，如果模板的大多数实例共享相同的谓词，则将模板映射到该谓词。 例如，假设通过模板得出的问题「在 $city 中有多少人？」始终映射到谓词<i>人口</i>，而无论具体的城市是什么。 我们可得出结论，模板以一定的概率映射到<i>人口</i>。 映射到复杂知识库结构的学习模板采用类似的过程。 唯一的不同是，我们找到了“扩展谓词”，该谓词对应于由多个边组成的路径，这些边从一个实体通向某个值（例如，婚姻-&gt;人-&gt;名字）。</p><h2>系统概览</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d704e15bf122ba1816ce658cfea5dca2_b.jpg\" data-size=\"normal\" data-rawwidth=\"786\" data-rawheight=\"828\" class=\"origin_image zh-lightbox-thumb\" width=\"786\" data-original=\"https://pic3.zhimg.com/v2-d704e15bf122ba1816ce658cfea5dca2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;786&#39; height=&#39;828&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"786\" data-rawheight=\"828\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"786\" data-original=\"https://pic3.zhimg.com/v2-d704e15bf122ba1816ce658cfea5dca2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d704e15bf122ba1816ce658cfea5dca2_b.jpg\"/><figcaption>系统概览，包括在线过程和离线过程</figcaption></figure><p>作者从问题 q 通过将每个实体 e 替换为它的类别 c 来获得模板 t. 一个问题可能包含多个实体，每个实体可能属于多个类别。通过上下文感知的<b>概念化</b>，获得 e 的概念分布。例如，问题中包含「贝拉克·奥巴马」这个实体，它属于两个类别，$Person 和 $Politician。</p><p><b>在线过程</b>：对于一个问题，首先将它解析为一系列的二元事实类问题。对于每个 BFQ，作者使用概率推断的方法找到它的值。这个推断基于给定模板的谓词分布，分布是离线学习的。</p><p><b>离线过程</b>：离线过程的目标是学习模板到谓词的映射。</p>", 
            "topic": [
                {
                    "tag": "知识库", 
                    "tagLink": "https://api.zhihu.com/topics/19553061"
                }, 
                {
                    "tag": "语料库", 
                    "tagLink": "https://api.zhihu.com/topics/19644703"
                }, 
                {
                    "tag": "智能问答", 
                    "tagLink": "https://api.zhihu.com/topics/20022694"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/85904073", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 1, 
            "title": "【ACL 2019】在知识库问答关系检测中学习表示映射", 
            "content": "<p>原文：Learning Representation Mapping for Relation Detection in Knowledge Base Question Answering</p><p>来源：ACL 2019</p><p>作者单位：计算机软件新技术国家重点实验室，南京大学，华为科技泊松实验室</p><p>关键词：知识库问答 关系检测 不可见关系</p><p>这篇文章探讨的问题仍然关注于知识库问答的<b>固有缺陷</b>：知识库不可能涵盖 QA 任务所需的所有关系。</p><p><b>主要研究的问题</b>：测试数据中可能出现训练数据中没有出现过的关系，而模型从来没有学习过它们的嵌入，导致模型表现受到影响。</p><p><b>理解难点</b>：适配器在伪目标表示的基础上，是如何处理不可见关系来提升模型性能的？对抗适配器所使用的强化学习的思想，在模型中发挥了怎样的作用？</p><h2>介绍</h2><p>知识库问答近年来取得不错的进展，它使用开放域知识库回答问题。知识库通常包含大量三元组，每个三元组的形式是 &lt;主体，关系，客体&gt;，表示主体实体和客体实体之间的关系。</p><p>典型的知识库问答系统 (KBQA) 可以分为两步：</p><ul><li>实体链接步骤：首先确定问题的目标实体，该实体与三元组的主体相对应；</li><li>关系检测步骤：然后从一组候选关系中确定问题提出的关系。</li></ul><p>经过这两个步骤，可以通过从知识库中提取相应的三元组来获得答案。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-1db178f194e19defb4b968356caa12ed_b.jpg\" data-size=\"normal\" data-rawwidth=\"668\" data-rawheight=\"262\" class=\"origin_image zh-lightbox-thumb\" width=\"668\" data-original=\"https://pic2.zhimg.com/v2-1db178f194e19defb4b968356caa12ed_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;668&#39; height=&#39;262&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"668\" data-rawheight=\"262\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"668\" data-original=\"https://pic2.zhimg.com/v2-1db178f194e19defb4b968356caa12ed_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-1db178f194e19defb4b968356caa12ed_b.jpg\"/><figcaption>问题中的粗体字是目标实体，在实体链接步骤中标识。关系检测步骤从一组候选关系中选择正确的关系，用粗体标记。这个问题的答案是从知识库中提取的三元组的对象实体。</figcaption></figure><p>本文的主要重点是<b>关系检测步骤</b>，它更具挑战性，因为它需要考虑整个疑问句的含义（例如，“出生于……的地方”的模式）以及句法的含义，还有候选人关系（例如，“出生地”）。 为了进行比较，实体链接步骤受益于问题中的单词与主体实体之间的表面形式的匹配。</p><p>在最近的基于深度学习的关系检测方法中，每个单词或关系都由一个稠密向量表示，称为<b>嵌入</b>，它通常在优化关系检测目标时自动学习得到。然后，这些方法的推断过程通过神经网络计算被执行。这些方法在常见的 KBQA 数据集上取得了巨大的成功，例如 SimpleQuestion。</p><p>但是作者注意到，在 SimpleQuestion 数据集的常见拆分中，训练集中也存在测试集中 99％ 的关系，这意味着在训练过程中可以很好地学习它们的嵌入。相反，对于那些从未在训练数据中看到的关系（称为<b>看不见的关系</b>），自初始化以来就从未对它们的嵌入进行过训练。结果，相应的检测性能可以是任意的，这是尚未仔细研究的问题。</p><p>作者强调发现这些看不见的关系至关重要，且具有挑战性，因为在大规模知识库中<b>为所有关系建立训练数据是不可行的</b>。 该问题可以被视为 zero-shot 学习问题，其中在训练数据集中看不到测试实例的标签。</p><p>本文对这个 zero-shot 关系检测问题进行了详细研究，作者的贡献总结为：</p><ol><li>作者没有仅从训练数据中学习关系表示，而是采用方法从覆盖面更广的整个知识图中学习表示。</li><li>作者提出一种映射机制，称为<b>表示适配器</b>，或<b>适配器</b>，将学习到的表示集成到关系检测模型中。作者从适配器的简单均方误差损失入手，并提出集成对抗性和重建目标函数以改善训练过程。</li><li>作者将 SimpleQuestion 数据集重新组织为 SimpleQuestion-Balance，以分别评估可见和不可见关系的表现。</li><li>作者进行的实验表明，其提出的方法为看不见的关系的检测带来了很大的改进，同时仍然可以与最先进的(state-of-the-art)可见关系的方法相提并论。</li></ol><h2>表示适配器</h2><h3>动机</h3><p>人类注解数据的表示学习受限于训练数据的大小和覆盖范围。关于不可见关系的表示无法在训练时被模型学习的问题，一种可能解决方案是采用大量未注释的数据（可能更容易获得）以提供更好的覆盖范围。【笔者认为，作者这里指的是在<b>训练时</b>使用一些未注释数据，以提升模型处理未注释数据的能力。】</p><p>通常，预训练所得的嵌入向量并不直接适用于特定任务，而是需要进行特定于任务的微调。然而由于上文提到的覆盖问题，不可见的关系向量无法在微调过程中被正确更新，导致测试时的表现较差。【在这里，作者突然提到了预训练模型。但前文似乎没有说明，关系的嵌入要通过预训练-微调这样的方法学习。】</p><p>为了解决关系向量在微调中无法被正确更新的这个问题，作者提出在训练过程中保持关系的表示不变，并提出一种表示适配器，以弥合通用表示（预训练所得的表示）和任务特定表示之间的差距。然后，作者将介绍基本的适配器框架，介绍对抗性适配器和重建目标函数。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b3efd240f2b62169a3d09718b3683910_b.jpg\" data-size=\"normal\" data-rawwidth=\"870\" data-rawheight=\"582\" class=\"origin_image zh-lightbox-thumb\" width=\"870\" data-original=\"https://pic1.zhimg.com/v2-b3efd240f2b62169a3d09718b3683910_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;870&#39; height=&#39;582&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"870\" data-rawheight=\"582\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"870\" data-original=\"https://pic1.zhimg.com/v2-b3efd240f2b62169a3d09718b3683910_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b3efd240f2b62169a3d09718b3683910_b.jpg\"/><figcaption>表示适配器的结构：左侧是基本适配器，中间是对抗适配器，右侧是重建损失函数的适配器。</figcaption></figure><h3>基本适配器</h3><p><b>伪目标表示 </b>基本思想是使用一个神经网络表示适配器执行由通用表示到任务特定表示的映射。适配器的输入是从知识库学习得到的嵌入。然而，适配器的输出是不确定的，因为没有用于关系检测任务的准则 (oracle) 表示。</p><p>因此，作者首先训练类似于 Yu 等人的传统关系检测模型。在训练期间，将更新训练集中的关系表示形式（可见关系）以进行关系检测任务。 作者使用这些表示作为<b>伪目标表示</b>，以训练适配器。</p><p><b>线性映射 </b>受到 Mikolov 等人的启发，它展示了相似语言的表示空间可以通过线性映射转换，作者也使用一个线性映射函数 G 来将通用嵌入映射到任务特定（伪目标）表示。</p><p>作者提出的适配器和神经网络中的一层(extra layer)的主要区别是，特定的损失被用于训练适配器，而不是隐式地将适配器作为整个网络的一部分。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-cbd437e9c8fa5f9407fe1f8363ff1aaf_b.jpg\" data-size=\"normal\" data-rawwidth=\"560\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb\" width=\"560\" data-original=\"https://pic4.zhimg.com/v2-cbd437e9c8fa5f9407fe1f8363ff1aaf_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;560&#39; height=&#39;142&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"560\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"560\" data-original=\"https://pic4.zhimg.com/v2-cbd437e9c8fa5f9407fe1f8363ff1aaf_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-cbd437e9c8fa5f9407fe1f8363ff1aaf_b.jpg\"/><figcaption>loss(任务特定表示, 线性映射(通用表示))</figcaption></figure><p>此处的损失函数，可以是评估两个表示之间差异的任何度量。 最常见和最简单的方法是在基本适配器中采用的均方误差。其他可能性在后文被讨论。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7df0d847d8aa5427fb3b99fa508f792e_b.png\" data-size=\"normal\" data-rawwidth=\"684\" data-rawheight=\"86\" class=\"origin_image zh-lightbox-thumb\" width=\"684\" data-original=\"https://pic3.zhimg.com/v2-7df0d847d8aa5427fb3b99fa508f792e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;684&#39; height=&#39;86&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"684\" data-rawheight=\"86\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"684\" data-original=\"https://pic3.zhimg.com/v2-7df0d847d8aa5427fb3b99fa508f792e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-7df0d847d8aa5427fb3b99fa508f792e_b.png\"/><figcaption>通过均方误差损失函数，度量「任务特定表示」和「通用表示」之间的差异</figcaption></figure><h3>对抗适配器</h3><p>均方误差只衡量两个嵌入向量之间的绝对距离。受到生成对抗网络(GAN)，和之前一些无监督机器翻译的工作等的启发，作者使用一个<b>判别器</b>提供对抗损失来指导训练。这是最小化伪目标表示和通用表示之间的差异的另外一种方法。</p><p>从细节看，作者训练了一个判别器 D(·) 来分辨“真实”的表示，即被微调的关系嵌入。它是从适配器的输出，即“虚假”的表示中分辨出来的。</p><p>适配器 G(·) 扮演了 GAN 中生成器的角色，它尝试生成类似于“真实”表示的表示。作者使用 WassersteinGAN 训练适配器。对于任何从训练集中采样的关系，判别器和生成器的目标函数分别是：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6578e8365fc0217fdae3014447e81fa6_b.jpg\" data-size=\"normal\" data-rawwidth=\"902\" data-rawheight=\"250\" class=\"origin_image zh-lightbox-thumb\" width=\"902\" data-original=\"https://pic3.zhimg.com/v2-6578e8365fc0217fdae3014447e81fa6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;902&#39; height=&#39;250&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"902\" data-rawheight=\"250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"902\" data-original=\"https://pic3.zhimg.com/v2-6578e8365fc0217fdae3014447e81fa6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-6578e8365fc0217fdae3014447e81fa6_b.jpg\"/><figcaption>判别器和生成器的目标函数</figcaption></figure><h3>重构损失函数</h3><p>适配器只能通过可见关系的表示学习映射，这忽略了大量不可见的关系。这里作者提出额外的重构损失来增强适配器。具体而言，使用一个反转的适配器，将通用嵌入的线性映射，映射回通用嵌入。</p><p>使用反转训练的优势包括两方面：1) 反转的适配器可以由所有的关系来学习，可见、不可见的关系都可以，2)反转映射能作为一种正则化前向映射的额外约束。</p><p>对于反转适配器，作者采用的映射简单地类似于基本适配器中的线性映射。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-abc207a048171cee8377d154c020bb91_b.jpg\" data-size=\"normal\" data-rawwidth=\"818\" data-rawheight=\"144\" class=\"origin_image zh-lightbox-thumb\" width=\"818\" data-original=\"https://pic2.zhimg.com/v2-abc207a048171cee8377d154c020bb91_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;818&#39; height=&#39;144&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"818\" data-rawheight=\"144\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"818\" data-original=\"https://pic2.zhimg.com/v2-abc207a048171cee8377d154c020bb91_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-abc207a048171cee8377d154c020bb91_b.jpg\"/><figcaption>重新构建的损失函数。类似于基本适配器中的损失函数，但不同之处在于该函数也适用于不可见关系。</figcaption></figure><p>注意，不同的是，重新构建的损失函数是同时针对可见的关系和不可见的关系的。</p><h2>使用适配器检测关系</h2><p>作者将适配器集成到最先进的(state-of-the-art)关系检测框架 Residual BiLSTM。</p><p><b>框架</b> 该框架使用问题网络将问题句子编码为向量 qf，并使用关系网络将关系编码为向量 rf。 这两个网络都基于具有最大池化操作的 Bi-LSTM。 然后，引入余弦相似度以计算 qf 和 rf 之间的距离，从而确定检测结果。作者提出的适配器是关系网络中用于增强此框架的附加模块。</p><p><b>调整关系表示 </b>由 Yu 等人提出的关系网络在关系表示上有两部分：单词层次上和关系层次上。这两部分被送入关系网络，来生成最终的关系表示。</p><p>与之前的方法不同，作者在关系层表示上使用所提出的适配器来解决不可见的关系检测问题。</p><p><b>训练 </b>跟随 Yu 等人，关系检测模型通过 hinge 损失函数进行训练。它尝试将每个负样本和正样本的分数通过间距分开：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bb4acb131bb26afeb7e06f849fe4f2c4_b.png\" data-size=\"normal\" data-rawwidth=\"904\" data-rawheight=\"124\" class=\"origin_image zh-lightbox-thumb\" width=\"904\" data-original=\"https://pic1.zhimg.com/v2-bb4acb131bb26afeb7e06f849fe4f2c4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;904&#39; height=&#39;124&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"904\" data-rawheight=\"124\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"904\" data-original=\"https://pic1.zhimg.com/v2-bb4acb131bb26afeb7e06f849fe4f2c4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-bb4acb131bb26afeb7e06f849fe4f2c4_b.png\"/><figcaption>区分负样本和正样本的训练函数，其中 s 是余弦距离函数</figcaption></figure><p>正样本是标注的训练数据，负样本是从剩余关系中采样得到。</p><p>基本的关系检测模型是预训练的，以获得伪目标表示。然后，适配器集成在训练过程中，和关系检测模型联合优化。对于对抗适配器，将按照常规做法交替训练生成器和判别器。</p><p>作者对 SimpleQuestion 数据集的重组在此处略去。</p><h2>相关工作</h2><ul><li>KBQA 的关系检测</li><li>嵌入映射</li><li>zero-shot learning</li></ul><h2>结论</h2><p>在本文中，作者讨论了 KBQA 中不可见关系的检测。其中主要问题在于这类关系表示的学习。 作者将 SimpleQuestion 数据集重组为 SimpleQuestion-Balance，以揭示和评估问题，并提出一个可显著改善结果的适配器。</p><p>作者强调，对于其他任何包含大量非可见样本的任务，针对可见样本进行训练、微调是不合理的。类似的问题可能存在于其他 NLP 任务，在未来进行探索将是有趣的。</p>", 
            "topic": [
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "知识库", 
                    "tagLink": "https://api.zhihu.com/topics/19553061"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/85845958", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 1, 
            "title": "【ACL 2019】基于知识库和大规模网络文本的问答系统", 
            "content": "<p>论文阅读：Improving Question Answering over Incomplete KBs with Knowledge-Aware Reader</p><p>来源：ACL 2019</p><p>关键词：知识库 网络文本 问答系统</p><h3>研究动机</h3><p>知识库（KB）被认为是<b>回答事实性问题的必要资源</b>。 但是，使用精心设计和复杂的架构准确构建知识库需要<b>大量的人力</b>，这不可避免地限制了知识库的<b>覆盖范围</b>。 实际上，知识库通常不完整，不足以涵盖<b>开放域问题</b>所需的全部证据。</p><p>另一方面，因特网上的大量<b>非结构化文本能轻松覆盖大量正在演化的知识</b>，这通常在开放域问题回答中很常见。为提升知识库的覆盖率，<b>将知识库和文本数据结合</b>起来的做法是很直观的。</p><p>最近，基于文本的问答模型在保证答案在一篇文章内的情况下取得了不错的进展。然而，他们对于<b>多个文档的情形</b>仍然研究不足。作者假设这一部分原因是由于<b>背景知识的缺乏</b>，无法将相关信息和无关信息区分开来。</p><p>为了更好地利用文本信息来提升不完整知识库上的问答系统，本文提出一种端到端模型，它包括：</p><p>1. 一个简单而有效的<b>子图阅读模块</b>，它从与问题相关的KB子图中积累每个KB实体的知识；</p><p>2. 一种具有知识感知的<b>文本阅读模块</b>，该阅读器通过一种新颖的条件门控机制有选择地将所学的有关知识的 KB 知识整合在一起。</p><h3>任务定义</h3><p>本文考虑的 QA 任务，需要通过阅读知识库元组 $K{(e_s, r, e_o)}$  并获得维基百科文档 $D$ 来回答。</p><p>本文参考其他相关文献，为每个问题考虑一个子图。子图通过从话题实体运行 Personalized PageRank 算法获得。文档通过一个现有的文档检索工具检索得到，再根据 Lucene 索引排序。</p><h3>模型介绍</h3><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-28b638f5d6f3ae3341d7bf9c651d71df_b.jpg\" data-size=\"normal\" data-rawwidth=\"1404\" data-rawheight=\"648\" class=\"origin_image zh-lightbox-thumb\" width=\"1404\" data-original=\"https://pic4.zhimg.com/v2-28b638f5d6f3ae3341d7bf9c651d71df_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1404&#39; height=&#39;648&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1404\" data-rawheight=\"648\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1404\" data-original=\"https://pic4.zhimg.com/v2-28b638f5d6f3ae3341d7bf9c651d71df_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-28b638f5d6f3ae3341d7bf9c651d71df_b.jpg\"/><figcaption>模型概览</figcaption></figure><p>模型的关键组件包括一个：</p><ul><li><b>子图阅读模块</b>：用于从知识库中获取和问题相关的知识信息。</li><li><b>知识感知的文本阅读模块</b>：利用获取的知识从文档中找出需要的答案。</li></ul><p>此处不详述计算过程，详细的计算过程还请阅读原文。</p><h3>子图阅读模块</h3><p>知识库子图阅读模块使用图注意技术从关联的邻居收集每个子图的知识。图注意机制被刻意设计为考虑两个重要的方面：</p><ol><li>邻接关系是否和问题相关（问题-关系匹配）</li><li>邻接实体是否是问题所提及的话题实体</li></ol><p>在传播之后，子图阅读模块最终输出每个实体的向量化表示，对由关联邻居表示的知识编码。</p><p>模型首先通过一个<b>共享</b>的 LSTM 得到<b>问题序列</b>和标记化<b>关系序列</b>的隐藏状态表示，然后使用自注意力编码器，通过关系的隐藏状态得到关系的语义表示向量。这相当于以一个关系语义向量，表示了标记化关系序列中的关键信息。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-da84084517abd0dd94b360e15f4eace1_b.jpg\" data-size=\"normal\" data-rawwidth=\"464\" data-rawheight=\"92\" class=\"origin_image zh-lightbox-thumb\" width=\"464\" data-original=\"https://pic2.zhimg.com/v2-da84084517abd0dd94b360e15f4eace1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;464&#39; height=&#39;92&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"464\" data-rawheight=\"92\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"464\" data-original=\"https://pic2.zhimg.com/v2-da84084517abd0dd94b360e15f4eace1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-da84084517abd0dd94b360e15f4eace1_b.jpg\"/><figcaption>使用自注意力编码器，通过关系的隐藏状态所得的关系的语义表示向量</figcaption></figure><p>由于一个问题可能涉及多个关系，一个关系只注意到问题中的一部分，每个关系不是只和一个问题向量对应。因此，问题的每个隐藏状态表示都与关系向量进行匹配，得到关系表示与问题的匹配度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-0b358c6414b29eeb337e54a5f89a6e68_b.jpg\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb\" width=\"480\" data-original=\"https://pic1.zhimg.com/v2-0b358c6414b29eeb337e54a5f89a6e68_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;480&#39; height=&#39;110&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"480\" data-original=\"https://pic1.zhimg.com/v2-0b358c6414b29eeb337e54a5f89a6e68_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-0b358c6414b29eeb337e54a5f89a6e68_b.jpg\"/><figcaption>关系与问题的匹配</figcaption></figure><p>在问题-关系匹配之外，作者发现话题实体的指示向量非常有用。如果一个话题实体连接的邻居出现在问题中，那么对应知识库中的三元组将比那些非话题实体的邻居对问题的语义更相关。</p><p>每个链接的注意力值可最终表示为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-639a14bd3d2b77074e23286771a71869_b.png\" data-size=\"normal\" data-rawwidth=\"448\" data-rawheight=\"64\" class=\"origin_image zh-lightbox-thumb\" width=\"448\" data-original=\"https://pic2.zhimg.com/v2-639a14bd3d2b77074e23286771a71869_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;448&#39; height=&#39;64&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"448\" data-rawheight=\"64\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"448\" data-original=\"https://pic2.zhimg.com/v2-639a14bd3d2b77074e23286771a71869_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-639a14bd3d2b77074e23286771a71869_b.png\"/><figcaption>(关系，实体)链接的注意力值计算</figcaption></figure><p>为了积累链接三元组的知识，每个实体的传播规则被定义为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-97a9c0bbc45867cda56cb9d5df44599a_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"696\" data-rawheight=\"106\" class=\"origin_image zh-lightbox-thumb\" width=\"696\" data-original=\"https://pic3.zhimg.com/v2-97a9c0bbc45867cda56cb9d5df44599a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;696&#39; height=&#39;106&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"696\" data-rawheight=\"106\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"696\" data-original=\"https://pic3.zhimg.com/v2-97a9c0bbc45867cda56cb9d5df44599a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-97a9c0bbc45867cda56cb9d5df44599a_b.png\"/></figure><h3>知识感知的文本阅读模块</h3><p>通过学习所得的知识库嵌入，模型通过知识感知文本阅读模块增强文本阅读。简而言之，作者使用现有的阅读理解模型（Chen et al 2017），并通过学习更多关于问题和文档的知识感知表示来改进它。</p><p>首先，作者尝试通过合并话题实体的知识库知识的方法，重新表示问题。这使读者可以区分文本匹配之外的相关信息。</p><p>作者首先采用原始问题编码，应用自注意编码器来获得独立的问题表示形式，收集关于问题的话题实体，然后使用一个门结构将这些信息进行融合：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f2acd6406142f2796725bcc198697d06_b.png\" data-size=\"normal\" data-rawwidth=\"622\" data-rawheight=\"86\" class=\"origin_image zh-lightbox-thumb\" width=\"622\" data-original=\"https://pic3.zhimg.com/v2-f2acd6406142f2796725bcc198697d06_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;622&#39; height=&#39;86&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"622\" data-rawheight=\"86\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"622\" data-original=\"https://pic3.zhimg.com/v2-f2acd6406142f2796725bcc198697d06_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f2acd6406142f2796725bcc198697d06_b.png\"/><figcaption>问题的重新表示</figcaption></figure><p>得到了对问题的重新表示之后，就是使用学习到的知识对文档进行增强表示，首先对文档和文档对应的实体使用 Bi-LSTM 进行处理，接下来作者设计了一种新的基于问题的表示的门机构，该结构允许模型能够动态选择跟问题相关的输入，从而得到更好的文档语义表示。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-fee4c00824a52d66ecf6c3c7ebd7d8b7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"166\" class=\"origin_image zh-lightbox-thumb\" width=\"624\" data-original=\"https://pic4.zhimg.com/v2-fee4c00824a52d66ecf6c3c7ebd7d8b7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;624&#39; height=&#39;166&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"166\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"624\" data-original=\"https://pic4.zhimg.com/v2-fee4c00824a52d66ecf6c3c7ebd7d8b7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-fee4c00824a52d66ecf6c3c7ebd7d8b7_b.jpg\"/></figure><p>最后，作者将从文本阅读模块所得的信息进行融合。首先使用一个 co-attention 计算问题和 Bi-LSTM 的隐藏状态的相关度，然后对这些隐藏状态进行加权和，对于文档对应的实体，作者使用均值池化得到最后的表示。最终，使用一个非线性变化和 sigmoid 函数来求得每个实体是否是答案的概率</p><h3>结论与启示</h3><p>作者提出了一个新的 QA 模型，该模型可对不完整的知识库和文本文档进行操作，以回答开放域问题。与不完整的知识库相比，对 WebQSP 基准测试的先前方法产生了持续改进。 </p><p>结果表明：</p><p>（1）利用图注意力技术，可以有效，准确地积累知识库子图中的每个知识库实体中与问题相关的知识；</p><p>（2）设计的门控机制可以在处理文本文档时成功整合编码实体知识。 </p><p>在以后的工作中，作者将把提出的想法扩展到具有多模态证据的其他问答任务，例如，结合用于视觉问答的符号方法。</p><p></p>", 
            "topic": [
                {
                    "tag": "知识库", 
                    "tagLink": "https://api.zhihu.com/topics/19553061"
                }, 
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "问答系统", 
                    "tagLink": "https://api.zhihu.com/topics/19571693"
                }
            ], 
            "comments": [
                {
                    "userName": "竹园主人", 
                    "userLink": "https://www.zhihu.com/people/76d5a32ab87682ca5e1b87dc8a82f421", 
                    "content": "[赞同]知识库的建设和使用是一个引人入胜的课题，过去一对一的匹配还比较容易，一对多则较困难。知识库的新模式为开发使用帶来了方便。", 
                    "likes": 1, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/85864250", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 2, 
            "title": "Transformer 的关键优势是什么？", 
            "content": "<p>本文不是一篇全文解读，仅谈一谈该模型的关键优势，了解我们在构建深度学习模型时使用 Transformer 模型的适用条件是什么。</p><blockquote>什么是 Transformer？</blockquote><p>Transformer 是 Google 的研究者于 2017 年在《Attention Is All You Need》一文中提出的一种用于 seq2seq 任务的模型，它没有 RNN 的循环结构或 CNN 的卷积结构，在机器翻译等任务中取得了一定提升。</p><h3>动机</h3><p>RNN、LSTM 和 GRU 网络已在序列模型、语言建模、机器翻译等应用中取得不错的效果。循环结构 (recurrent) 的语言模型和编码器-解码器体系结构取得了不错的进展。</p><p>但是，RNN 固有的顺序属性阻碍了训练样本间的<b>并行化</b>，对于长序列，内存限制将阻碍对训练样本的批量处理。</p><p><b>注意力机制</b>(attention) 已经成为各类任务中序列建模(sequencem modeling)和转导模型(transduction model)中的组成部分，允许对输入输出序列的依赖项进行建模，而<b>无需考虑它们在序列中的距离</b>。但之前的注意力机制都与 RNN 结合使用。</p><p>本文提出的 Transformer，是一种避免循环(recurrent)的模型结构，完全依赖于注意力机制对输入输出的全局依赖关系进行建模。因为对依赖的建模完全依赖于注意力机制，Transformer 使用的注意力机制被称为自注意力(self-attention)。</p><h3>Transformer 为什么使用了自注意力</h3><p>探讨使用自注意力层构建 Transformer 的原因，就是将自注意力层与循环层或卷积层做比较。</p><ul><li>每层总共的计算复杂度。</li><li>可以并行化的计算量，以所需的最少序列操作数量衡量。</li><li>网络中远程依赖关系之间的路径长度。 在许多序列转导任务中，学习远程依赖性是一项关键挑战。影响学习这种依赖性的能力的一个关键因素是网络中前向和后向信号必须经过的路径长度。输入和输出序列中位置的任意组合之间的这些路径越短，则越容易学习远程依赖性。 在 CNN 类的模型中，通过卷积计算两个位置之间的关联所需的操作次数是随距离增长的。而 Self-attention 计算两个位置之间的关联所需的操作次数是与距离无关的。</li></ul><p>总结说来，个人认为 Transformer 的关键优势至少可以归结为三点：</p><ul><li>突破了 RNN 模型不能并行计算的限制。</li><li>相比 CNN，计算两个位置之间的关联所需的操作次数不随距离增长。</li><li>自注意力可以产生更具可解释性的模型。我们可以从模型中检查注意力分布。各个注意头(attention head)可以学会执行不同的任务。</li></ul><p>另外想提到一点，由于 self-attention 没有循环结构，Transformer 需要一种方式来表示序列中元素的相对或绝对位置关系。Position Embedding (PE) 就是该文提出的方案。但在一些研究中，模型加上 PE 和不加上 PE 并不见得有明显的差异。</p>", 
            "topic": [
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "Transformer", 
                    "tagLink": "https://api.zhihu.com/topics/20746363"
                }, 
                {
                    "tag": "注意力机制", 
                    "tagLink": "https://api.zhihu.com/topics/20682987"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/85502261", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 5, 
            "title": "最先进的知识库问答系统（KBQA）面临的挑战", 
            "content": "<p>内容来自：《Core Techniques of Question Answering Systems over Knowledge Bases: a Survey》</p><p>该文成文自 2016 年，应该来说指出的一些 KBQA 面临的挑战是长期的，到今天仍然有参考价值。但也有一些问题没有再受到研究者的过多关注，或者可能已经被解决得比较好了。</p><ul><li>识别问题类型：包括 wh- 问题、祈使、名词或定义、主题化实体、带形容词或量词的程度（有多大/有多少）。</li><li>词汇空缺：查询和数据库可能无法使用相同的词汇表（同义词）或相同的抽象级别表示。 它需要弥合用户查询中的词汇表和KB词汇表之间的差距。</li><li>多语言 QA：用自己的语言表达信息需求的用户与语义数据之间的中介。</li><li>含糊不清的词汇歧义：可以通过不同的本体论实体或语义上较弱的构造来解释的单词查询。 使用动词（如be / have或轻介词）可以表达不同含义的隐式表达的关系。</li><li>语义间隙/概念复杂性：在知识库中不一定以与问题中相同的方式构造查询。</li><li>时空介词：需要捕获时空介词的领域无关含义。</li><li>形容词修饰语和最高级：最高级修饰符和属性选择符 (how+adj) 要求将每个形容词映射到一个知识库谓词 (例如，最小的区域/人口)，并保持最高级的极性(按照 ASC / DESC 的顺序)。</li><li>聚合，比较和求反运算符：聚集运算符是指计算满足某个特定属性的多个个体的最小值，最大值，总和，平均值或计数的运算符。 比较运算符将数字与给定顺序进行比较。 挑战在于通过逻辑运算符实现量词。</li><li>句法和范围歧义：关于介词短语或相对从句可以附加到（在句子中的最后一个或到一个非先例的组成部分上）或当查询中存在多个作用域量词（最多，全部，每个等）的语法歧义。</li><li>分布式问答实体对帐：跨源合并事实需要在架构级别和实体级别（在给定查询实体的情况下查找语义上等效的数据集实体）进行匹配，以加入部分结果或翻译</li><li>非组合性：问题的一部分不符合任何逻辑形式，需要忽略（例如，最大的城市指的是世界上最大的城市，如果“世界”不是显式的）</li><li>语义易处理性：要回答显式数据集语句不支持的查询（例如，由陈述 x 出演了 y 电影推断实体 x 是女演员）</li><li>超出范围：系统应告知有关该问题超出知识库范围的事实（相对于系统功能而言）</li><li>可移植性：将系统移植到其他来源需要付出的努力程度（例如，手工词典，训练）</li><li>可伸缩性：就KB大小及其数量而言都是必需的，同时保持实时性能</li><li>混合式 QA，语义和文本差距：在一个答案中结合结构化和非结构化信息</li></ul>", 
            "topic": [
                {
                    "tag": "知识库", 
                    "tagLink": "https://api.zhihu.com/topics/19553061"
                }, 
                {
                    "tag": "问答系统", 
                    "tagLink": "https://api.zhihu.com/topics/19571693"
                }, 
                {
                    "tag": "知识图谱", 
                    "tagLink": "https://api.zhihu.com/topics/19838204"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/84989290", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 0, 
            "title": "语义网技术体系 绪论", 
            "content": "<h2>语义网技术体系 绪论</h2><blockquote>语义网与万维网有什么关系？为什么要提出语义网？</blockquote><p>万维网最初追求的是一个互相链接的<b>超文本文件系统</b>，这些文件通过浏览器来查看。随着万维网的发展，人们希望机器能理解和集成万维网上的数据。语义网是 W3C 进一步发展万维网的愿景，它提供一个公共框架，使得<b>数据的共享和复用</b>可以跨越应用系统、企业和社区的边界。</p><blockquote>数据共享的框架是什么？</blockquote><p>W3C 提出<b>资源描述框架</b>（RDF），鼓励人们采用基于 RDF 数据模型的数据格式来构建和发布数据，便于计算机程序按 RDF 数据模型来理解和集成有关数据。</p><p>在构建或生成 RDF 数据时，通常需要特定于领域的<b>词汇表</b>，即一组类和属性。W3C 没有规定词汇表，而是希望人们按照 <b>RDFS 或 OWL 等本体语言</b>来定义或描述他们的词汇表。对于采用相同词汇表的多个 RDF 数据源，其</p><blockquote>什么是本体？</blockquote><p>本体，ontology，源于哲学领域的概念。在计算机科学中，根据维基百科的描述，可理解为“形式化的，对于共享概念体系的明确而又详细的说明”。本体有结构化的特点，便于计算机表示，能反应对象的概念、属性和对象间关系。</p><blockquote>语义网发展到什么程度？</blockquote><p>简单地说，语义网的<b>理论基础</b>已经奠定，W3C 有关语义网的<b>技术规范</b>也逐步完善。<b>链接数据</b>(linked data) 指导原则已成为在万维网上发布 RDF 数据的基本准则。</p><blockquote>语义网技术的具体应用？</blockquote><ul><li>Web of data：一个基于 RDF 数据模型的数据网</li><li>DBpedia：从维基百科中提取的 RDF 数据集，被许多语义网数据链接</li><li>Google 知识图谱</li></ul><h2><b>语义网简介</b></h2><h3><b>语义网的愿景</b></h3><p>经典的万维网是一个互相链接的超媒体文件系统，包括文本、图像和视频的文件是供人们直接浏览的，而计算机难以理解这些文件中的内容，从而难以复用和集成万维网中的数据来提供更有用的信息服务。</p><p>传统万维网只有文档的交换和共享，而语义网提供了这样一种愿景：数据容易被计算机所理解，数据的共享和复用可以跨越应用系统、企业和社区的边界。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0f9c261e788656cb03b31929986c4d3f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"706\" data-rawheight=\"578\" class=\"origin_image zh-lightbox-thumb\" width=\"706\" data-original=\"https://pic4.zhimg.com/v2-0f9c261e788656cb03b31929986c4d3f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;706&#39; height=&#39;578&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"706\" data-rawheight=\"578\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"706\" data-original=\"https://pic4.zhimg.com/v2-0f9c261e788656cb03b31929986c4d3f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0f9c261e788656cb03b31929986c4d3f_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3><b>语义网的技术栈</b></h3><p>语义网以 RDF 作为基石。RDF 是一个公共的数据模型，以 RDF 三元组 (RDF triple) 作为基本的数据单元描述资源的类型和属性。一个 RDF 三元组由主语、谓语和宾语三部分组成。</p><ul><li>URI（统一资源标识符）可以出现在三元组中的任意位置。URI 可以标识任何需要标识的资源，包括信息资源（如网页）、现实事物（如一本书）或人们在社会实践中形成的概念（如书和作者）。</li><li>谓语不能是<b>空白节点</b>。空白节点只能作为局部的资源标识，不具备 URI 的全局标识能力。</li><li><b>字面量</b>(literal) 只能作为宾语。通常用来表示基本类型的数据，如字符串、整数和实数等。</li></ul><h3><b>本体 ontology</b></h3><p><b>本体</b>在语义网中起到重要作用。哲学中，本体论主要讨论事物的基本特征及其分类体系。在人工智能与信息技术中，本体论的概念被用于知识表示上。一个本体是一个共享概念模型的显式的形式化规约。</p><p>本体需要通过语言来表达。W3C 开发了 RDF 词汇描述语言 <b>RDF Schema 和 Web 本体语言 OWL</b>。各组织可使用 RDF Schema 或 OWL 表示其领域的本体，并发布在万维网上共享。RDF Schema 和 OWL 定义了若干<b>推理规则</b>，运用推理技术使信息提供者不必对所有信息全部罗列，应用程序可根据现有数据和推理规则自动派生出蕴含的信息。</p><h3><b>RDF 数据存取规范</b></h3><p>如同关系型数据库与 SQL（结构化查询语言），RDF 数据的存取规范是 SPARQL 协议与 RDF 查询语言。SPARQL 查询语言具有描述跨越数据源的 RDF 数据查询的能力。</p><p>SPARQL 的基本组成是三元组模式，三元组模式与 RDF 三元组类似，区别在于其主语、谓语、宾语位置均可设置为变量。三元组模式通过合取、析取等方式组合成为图模式 (graph pattern)，能够匹配到图模式 RDF 数据便作为查询结果返回。</p><h2><b>语义网应用</b></h2><p>维基百科的知识采用文本表示，知识难以理解，不利于人们深入分享和利用这些知识。DBpedia 从维基百科中提取结构化信息，转化为 RDF 数据，并遵循链接数据指导原则发布到万维网上。这个 RDF 数据集称为 DBpedia。以 DBpedia 为核心的 LOD 项目推动了链接数据的快速增长，拉开了语义网应用的序幕。</p><p>主流搜索引擎正逐步采用语义网技术或类似技术来增强用户体验。例如 Google Rich Snippets 网页内容摘要技术。</p><p>总的来说，语义网技术可以用于从文本和多媒体数据中抽取结构化数据， 形成RDF数据， 或者将关系型数据转换成RDF数据， 或者直接使用RDF数据， 并结合本体的使用， 从而赋予数据良好定义的、机器易理解的含义， 使得信息集成在语法上和语义上都能够畅通进行，以提供更好的信息服务。从这个意义上来讲，<b>对于具有信息集成和搜索等应用需求的领域，只要信息本身适合于表达成结构化数据，语义网技术就可以发挥其作用。</b></p>", 
            "topic": [
                {
                    "tag": "计算机网络", 
                    "tagLink": "https://api.zhihu.com/topics/19572894"
                }, 
                {
                    "tag": "语义网", 
                    "tagLink": "https://api.zhihu.com/topics/19551341"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/84983856", 
            "userName": "Y.Shu", 
            "userLink": "https://www.zhihu.com/people/f3ca6a4373115308f078d44eaa218ded", 
            "upvote": 0, 
            "title": "Linked Data - the Story So Far", 
            "content": "<h2>截止 2019 年 9 月，本文引用量已经超过 5800 次。</h2><p>原文地址：<u><a href=\"https://link.zhihu.com/?target=https%3A//pdfs.semanticscholar.org/9f54/a0057d0694bc7d1dcf69d186e313ca92775c.pdf%3F_ga%3D2.40944161.2047776296.1569919511-704380860.1569919511\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pdfs.semanticscholar.org</span><span class=\"invisible\">/9f54/a0057d0694bc7d1dcf69d186e313ca92775c.pdf?_ga=2.40944161.2047776296.1569919511-704380860.1569919511</span><span class=\"ellipsis\"></span></a></u></p><p>原文作者：</p><ul><li>Christian Bizer, Freie Universität Berlin, Germany</li><li>Tom Heath, Talis Information Ltd, United Kingdom</li><li>Tim Berners-Lee, Massachusetts Institute of Technology, USA</li></ul><h2><b>摘要</b></h2><p>关联数据是指在 Web 上发布和连接结构化数据的一组最佳实践。在过去三年中，越来越多的数据提供者采用了这些最佳实践，从而创建了一个包含数十亿断言的全球数据空间——数据网络。在本文中，我们介绍了关联数据的概念和技术原理，并将它们置于相关技术发展的更广泛的背景下。我们描述了在网络上发布链接数据的最新进展，回顾了利用数据网络开发的应用程序，并为链接数据社区制定了研究议程。</p><p>关键词：链接数据，数据网络，语义网络，数据共享，数据探索</p><p>「本文的内容大致包括：概念、原理、进展、应用和未来方向」</p><h2><b>一 介绍</b></h2><p>作为全球信息空间的一部分，万维网降低了发布和访问文档的障碍，从根本上改变了我们分享知识的方式。超文本链接允许用户使用Web浏览器遍历这个信息空间，而搜索引擎对文档进行索引并分析它们之间的链接结构，以推断与用户搜索查询的潜在相关性(Brin &amp; Page, 1998)。Web的通用、开放和可扩展特性(Jacobs &amp; Walsh, 2004)支持此功能，这也被视为Web无限制增长的一个关键特性。</p><p>尽管Web提供了无可争议的好处，但直到最近，<b>使文档Web蓬勃发展的相同原则还没有应用到数据上</b>。传统上，发布在Web上的数据以原始转储格式(如CSV或XML)提供，或者标记为HTML表，这牺牲了很多结构和语义。在传统的超文本Web中，两个链接文档之间关系的本质是隐式的，因为数据格式(即HTML)的表达能力不足，<b>无法通过与相关实体的类型化链接将特定文档中描述的单个实体连接起来</b>。</p><p>然而，近年来，Web已经从一个链接文档的全球信息空间发展到一个<b>文档和数据都链接的信息空间</b>。支撑这一演变的是一组用于在Web上发布和连接结构化数据(即关联数据)的最佳实践。采用关联数据的最佳实践,与全球数据网络的扩展空间连接数据等来自不同领域的人,公司,书籍,科学出版物、电影、音乐、电视和广播节目,基因、蛋白质、药物和临床试验,在线社区、统计和科学数据,和评论。这种数据网络支持新的应用程序类型。通用的链接数据浏览器允许用户在一个数据源中开始浏览，然后沿着链接导航到相关数据源。有一些链接数据搜索引擎，它们通过跟踪数据源之间的链接在数据Web上爬行，并提供对聚合数据的表达性查询功能，类似于现在查询本地数据库的方式。数据网络也为特定领域的应用程序提供了新的可能性。与针对固定数据源集工作的Web 2.0 mashup不同，链接数据应用程序在无边界的全局数据空间上操作。这使他们能够在Web上出现新的数据源时提供更完整的答案。</p><p>本文其余部分的结构如下。在第2节中，我们将概述关联数据的主要特性。第3节介绍了链接开放数据项目的活动和输出，这是一个社区项目，旨在将链接数据原则应用于在开放许可下发布的数据。第4节回顾了发布关联数据的最新进展，第5节概述了关联数据的应用。第6节将关联数据与其他用于在Web上发布结构化数据的技术进行比较，然后在第7节中讨论正在进行的研究挑战。</p><h2><b>二 什么是链接数据</b></h2><p>总之，链接数据就是<b>使用Web在来自不同数据源的数据之间创建类型化链接</b>。它们可能是由位于不同地理位置的两个组织维护的数据库，也可能是一个组织内部的异构系统，从历史上看，这些系统在数据级别上不容易进行互操作。从技术上讲，链接数据是指以机器可读的方式发布在Web上的数据，它的含义是明确定义的，它链接到其他外部数据集，然后可以从外部数据集链接到这些数据集。</p><p>超文本Web的主要单元是由非类型化超链接连接的HTML(超文本标记语言)文档，而<b>链接数据依赖于包含RDF(资源描述框架)格式数据的文档</b>(Klyne和Carroll, 2004)。然而，与简单地连接这些文档不同的是，<b>链接数据使用RDF来创建类型化语句来链接世界上的任意事物</b>。我们称之为数据网络的结果，可以更准确地描述为世界上的事物网络，由网络上的数据描述。</p><p>Berners-Lee(2006)概述了一套在Web上发布数据的“规则”，所有发布的数据都成为一个单一的全球数据空间的一部分:</p><ol><li>使用 URI 作为事物的名称</li><li>使用 HTTP URI，以便人们可以查找这些名称</li><li>当某人查找URI时，使用标准提供有用的信息 (RDF, SPARQL)</li><li>包括到其他 URI 的链接，以便他们可以发现更多的东西</li></ol><p>这些原则被称为“关联数据原则”，它们为使用Web基础设施发布和连接数据提供了一个基本方法，同时又遵守其体系结构和标准。</p><h3><b>链接数据技能栈</b></h3><p>关联数据依赖于Web的两项基本技术:统一资源标识符(Uniform Resource identifier, URI) (Berners-Lee et al.， 2005)和超文本传输协议(HyperText Transfer Protocol, HTTP) (Fielding et al., 1999)。<b>当统一资源定位器 (URI) 作为文档和其他可以在Web 上找到的实体的地址时，统一资源标识符提供了一种更通用的方法来标识世界上存在的任何实体</b>。</p><p>在实体由使用http://模式的URI标识的地方，<b>可以通过HTTP协议解析对URI的引用来查找这些实体</b>。这样,HTTP协议提供了一个简单而普遍的检索机制的资源可以被序列化为一个流的字节数(如一张狗的照片)，或检索实体的描述自己不能在网络上以这种方式(如狗本身)。</p><p>URI 和 HTTP 由一种对数据 Web 至关重要的技术(前面介绍的RDF)补充。<b>HTML 提供了一种在 Web 上构造和链接文档的方法，而 RDF 提供了一种通用的、基于图的数据模型</b>，用它来构造和链接描述世界上事物的数据。</p><p>RDF模型以<b>主语、谓语、宾语三元组</b>的形式对数据进行编码。三元组的主题和对象都是各自标识资源的URI，或者分别标识URI和字符串文字。谓词指定主题和对象如何相关，并且也由URI表示。</p><p>例如，RDF三元组可以声明两个人A和B，每个人都由URI标识，二者因为A知道B的这样一种关系相关联。类似地，RDF三元组可以将人C与书目数据库中的科学物品D相关联 通过声明C是D的作者。可以从Web上的不同数据集中提取以此方式链接的两个资源，从而允许将一个数据源中的数据链接到另一个数据源中，从而创建一个Web数据。 因此，可以将链接不同数据集中的项目的RDF三元组视为类似于将文档Web捆绑在一起的超文本链接。</p><p>RDF链接(Bizer &amp; Cyganiak &amp; Heath, 2007)采用RDF三元组的形式，<b>三元组的主题是一个数据集名称空间中的URI引用，而三元组的对象是另一个数据集中的URI引用。</b>如图显示了两个RDF链接示例。第一个链接声明URI <u><a href=\"https://link.zhihu.com/?target=http%3A//www.w3.org/People/Berners-Lee/card%23i\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">w3.org/People/Berners-L</span><span class=\"invisible\">ee/card#i</span><span class=\"ellipsis\"></span></a></u>标识的资源是另一个名为<u><a href=\"https://link.zhihu.com/?target=http%3A//dig.csail.mit.edu/data%23DIG\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">dig.csail.mit.edu/data#</span><span class=\"invisible\">DIG</span><span class=\"ellipsis\"></span></a></u>的资源的成员。当通过HTTP协议取消对主题URI的引用时，<a href=\"https://link.zhihu.com/?target=http%3A//dig.csail.mit.edu\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">dig.csail.mit.edu</span><span class=\"invisible\"></span></a>服务器将用已标识资源的RDF描述来回答，在本例中，是MIT分散的信息组。当对象URI被取消引用时，W3C服务器提供描述Tim Berners-Lee的RDF图。对谓词URI <u><a href=\"https://link.zhihu.com/?target=http%3A//xmlns.com/foaf/0.1/member\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">xmlns.com/foaf/0.1/memb</span><span class=\"invisible\">er</span><span class=\"ellipsis\"></span></a></u>进行解引用将生成链接类型成员的定义，该定义是使用RDF词汇表定义语言(RDF Vocabulary definition Language, RDFS)在RDF中描述的，下面将对此进行介绍。第二RDF链接连接描述有关的电影《低俗小说》的电影数据库DBpedia提供的电影的描述,说明URI <u><a href=\"https://link.zhihu.com/?target=http%3A//data.linkedmdb.org/resource/film/77\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">data.linkedmdb.org/reso</span><span class=\"invisible\">urce/film/77</span><span class=\"ellipsis\"></span></a></u>和URI <u><a href=\"https://link.zhihu.com/?target=http%3A//dbpedia.org/resource/Pulp_Fiction_%2528film%2529\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">dbpedia.org/resource/Pu</span><span class=\"invisible\">lp_Fiction_%28film%29</span><span class=\"ellipsis\"></span></a></u>相同的现实世界实体引用——电影《低俗小说》。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-974d7f4a619f38d324107efcec3fd4ef_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1576\" data-rawheight=\"430\" class=\"origin_image zh-lightbox-thumb\" width=\"1576\" data-original=\"https://pic4.zhimg.com/v2-974d7f4a619f38d324107efcec3fd4ef_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1576&#39; height=&#39;430&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1576\" data-rawheight=\"430\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1576\" data-original=\"https://pic4.zhimg.com/v2-974d7f4a619f38d324107efcec3fd4ef_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-974d7f4a619f38d324107efcec3fd4ef_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>RDF词汇表定义语言(RDFS) (Brickley &amp; Guha, 2004)和Web本体语言(OWL) (McGuinness &amp; van Harmelen, 2004)为创建词汇表提供了基础，这些词汇表可用于描述世界上的实体以及它们之间的关系。词汇表是类和属性的集合。词汇表本身用RDF表示，使用来自RDFS和OWL的术语，它们在感兴趣的建模领域提供不同程度的表达。任何人都可以自由地将词汇表发布到数据Web (Berrueta &amp; Phipps, 2008)，而这些词汇表又可以由RDF三元组连接起来，这些三元组将一个词汇表中的类和属性链接到另一个词汇表中的类和属性，从而定义相关词汇表之间的映射。「也就是说，词汇表之间构成了一张图。」</p><p>通过使用 HTTP URI 来标识资源、使用 HTTP 协议作为检索机制、使用 RDF 数据模型来表示资源描述，链接数据直接构建在 Web 的一般体系结构上(Jacobs &amp; Walsh, 2004)。因此，<b>数据网可以被看作是与经典文档网紧密交织的附加层，具有许多相同的属性</b>：</p><ul><li>数据网络是通用的，可以包含任何类型的数据。</li><li>任何人都可以将数据发布到数据网络。</li><li>数据发布者在选择表示数据的词汇方面不受限制。</li><li>实体通过RDF链接连接，创建一个跨数据源的全局数据图，从而能够发现新的数据源。</li></ul><p>从应用程序开发的角度来看，数据网络具有以下特点:</p><ul><li>数据与格式和表示方面严格分离。</li><li>数据是自我描述的。如果使用关联数据的应用程序遇到用不熟悉的词汇表描述的数据，则应用程序可以解析对标识词汇表术语的 URI 的引用，以便找到它们的定义。</li><li>与依赖异构数据模型和访问接口的Web api相比，使用HTTP作为标准数据访问机制和RDF作为标准数据模型简化了数据访问。</li><li>数据的Web是开放的，这意味着应用程序不必针对一组固定的数据源来实现，但是可以通过遵循RDF链接在运行时发现新的数据源。</li></ul><h2><b>三 链接开放数据项目</b></h2><p>采用和应用关联数据原则的最明显的例子是<b>链接开放数据项目</b>，一个草根社区项目，成立于2007年1月，由W3C语义网教育与推广组织支持。该项目最初和正在进行的目标是，通过识别在开放许可下可用的现有数据集，根据关联数据原则将这些数据集转换为RDF，并将它们发布到Web上，从而引导数据Web。</p><p>项目早期阶段的参与者主要是大学研究实验室和小公司的研究人员和开发人员。从那时起，这个项目有了长足的发展，包括BBC、汤森路透(Thomson Reuters)和美国国会图书馆(Library of Congress)等大型机构的大力参与。这种增长是由于项目的开放性，任何人都可以参与其中，只需根据关联数据原则发布一个数据集，并将其与现有数据集互连。图2显示了来自链接开放数据项目的Web数据的范围和规模。从2009年3月开始，云图中的每个节点都代表一个以关联数据形式发布的不同数据集。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4fbaaa91715b1a526ad3b58dfedbd507_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1600\" data-rawheight=\"1306\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic4.zhimg.com/v2-4fbaaa91715b1a526ad3b58dfedbd507_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1600&#39; height=&#39;1306&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1600\" data-rawheight=\"1306\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1600\" data-original=\"https://pic4.zhimg.com/v2-4fbaaa91715b1a526ad3b58dfedbd507_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4fbaaa91715b1a526ad3b58dfedbd507_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>图2中的弧表示两个连接数据集中的项之间存在链接。较重的弧大致对应于两个数据集之间的较大数量的链接，而双向的弧则表示每个数据集中存在到另一个数据集的外部链接。</p><p><b>云的内容在本质上是不同的</b>，包括地理位置数据、人、公司、书籍，科学出版物，电影、音乐、电视和广播节目、基因、蛋白质、药物和临床试验，在线社区，统计数据，普查结果，评论。</p><p>由于许多数据是由现有关系数据库或api周围的包装器生成的，因此在统计或分析数据之前需要先进行抓取，因此计算数据Web的确切大小是一项挑战。或者，可以根据LOD社区在ESW wiki中收集的数据集统计信息来估计数据Web的大小。根据这些统计数据，数据网络目前由47亿个RDF三元组组成，这些三元组由大约1.42亿个RDF链接相互链接(2009年5月)。</p><p>如图2所示，<b>某些数据集充当数据 Web 中的链接中心</b>。例如，DBpedia数据集由从维基百科文章右侧常见的“信息框”中提取的RDF三元组组成，而Geonames [提供了全球数百万地理位置的RDF描述。由于这两个数据集为许多常见实体或概念提供了uri和RDF描述，因此它们在其他更专门的数据集中经常被引用，因此它们已经发展成为连接越来越多的其他数据集的集线器。</p><h2><b>四 在 Web 上发布链接数据</b></h2><p>通过根据关联数据原则在Web上发布数据，数据提供者将其数据添加到一个全局数据空间中，从而允许各种应用程序发现和使用数据。将数据集作为关联数据在网上发布涉及以下三个基本步骤:</p><ol><li>将 URI 分配给数据集所描述的实体，并提供通过HTTP协议将这些 URI 解引用为RDF表示。</li><li>将RDF链接设置为Web上的其他数据源，以便客户机能够通过遵循RDF链接在整个数据Web中导航。</li><li>提供关于发布数据的元数据，以便客户端能够评估发布数据的质量，并在不同的访问方式之间进行选择。</li></ol><p>在下面的文章中，我们将概述这些任务以及为支持每个任务的发布者而开发的工具。</p><h3><b>选择 URI 和 RDF 词汇表</b></h3><p>数据提供者可以在两种HTTP URI使用模式之间进行选择，以识别实体：303 URI和散列URI。这两种模式都确保客户端能够区分标识真实世界实体的 URI 和标识描述这些真实世界实体的 Web 文档的 URI (Sauermann &amp; Cyganiak, 2008)。在像Web这样的开放环境中，<b>不同的信息提供者发布关于同一个真实世界实体的数据</b>，例如地理位置或名人。因为他们可能不认识彼此，所以他们互相介绍不同的 URI 来标识相同的实体。例如，DBpedia使用URI <u><a href=\"https://link.zhihu.com/?target=http%3A//dbpedia.org/resource/Berlin\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">dbpedia.org/resource/Be</span><span class=\"invisible\">rlin</span><span class=\"ellipsis\"></span></a></u>来标识Berlin，而Geonames使用URI <u><a href=\"https://link.zhihu.com/?target=http%3A//sws.geonames.org/2950159/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">sws.geonames.org/295015</span><span class=\"invisible\">9/</span><span class=\"ellipsis\"></span></a></u>来标识Berlin。由于这两个URI都引用同一个现实世界实体，因此它们被称为URI别名。<b>URI别名在数据Web上很常见</b>，因为不能指望所有信息提供者都同意使用相同的URI来标识实体。URI别名还为数据网络提供了一个重要的社会功能，因为它们解引用到同一个真实世界实体的不同描述，因此允许在Web上表达不同的观点和观点。为了仍然能够跟踪不同的信息提供者所谈论的相同实体，信息提供者通常设置owl:sameAs 链接到他们所知道的 URI 别名。</p><p>不同的社区对他们更喜欢用于在Web上发布数据的词汇表有特定的偏好。因此，数据网络对并行使用的任意词汇表都是开放的。尽管具有这种普遍的开放性，但<b>最好还是重用众所周知的RDF词汇表中的术语</b>，如FOAF、SIOC、SKOS、DOAP、vCard、Dublin Core、OAI-ORE或good relations，以便让客户机应用程序更容易地处理链接数据。只有当这些词汇表没有提供所需的术语时，数据发布者才应该定义新的、特定于数据源的术语(Bizer &amp; Cyganiak &amp; Heath, 2007)。如果定义了新的术语，则应该通过使标识术语的 URI 可解引用(Berrueta &amp; Phipps, 2008)来实现自描述。这允许客户端检索术语的RDF模式或OWL定义，以及到其他词汇表的术语映射。因此，数据网络依赖于随用随付的数据集成方法(Das Sarma &amp; Dong &amp; Halevy, 2008)，其基础是<b>混合使用通用词汇表和特定于数据源的术语，必要时通过映射将它们连接起来</b>。</p><p>链接数据的一种常见序列化格式是RDF/XML (Beckett, 2004)。在需要对RDF数据进行人工检查的情况下，Notation3 (Berners-Lee, 1998)及其子集Turtle (Beckett 和 Berners-Lee, 2008)通常作为可选的、可转换的序列化提供，因为这些格式具有更好的可读性。另外，还可以将链接数据序列化为RDFa (Adida等人，2008)，它提供了将RDF三元组嵌入HTML的功能。在第二种情况下，数据发布者应该使用RDFa about属性将 URI 分配给实体，以便允许其他数据提供者设置到实体的RDF链接。</p><h3><b>链接生成</b></h3><p>RDF链接允许客户机应用程序在数据源之间导航并发现其他数据。为了成为数据Web的一部分，数据源应该将RDF链接设置到其他数据源中的相关实体。<b>由于数据源通常提供关于大量实体的信息，因此通常使用自动化或半自动化方法来生成RDF链接。</b></p><p>在不同的领域中，都有公认的命名模式。例如，在出版领域有ISBN和ISSN编号，在金融领域有ISIN标识符，EAN和EPC代码被广泛用于产品识别，在生命科学中存在各种公认的基因、分子和化学物质的识别模式。如果链接源和链接目标数据集已经都支持这些标识模式中的一个，那么可以很容易地将这两个数据集中实体之间的隐式关系显示为RDF链接。这种方法用于在LOD云中的各种数据源之间生成链接。</p><p><b>如果不存在共享命名模式，则常常根据两个数据集中实体的相似性生成RDF链接。</b>这种相似性计算可以建立在数据库社区中的记录链接(Winkler, 2006)和重复检测(Elmagarmid et al.,  2007)以及知识表示社区中的本体匹配(Euzenat &amp; Shvaiko, 2007)等大量相关工作的基础上。在(Raimond et al.,  2008)中给出了一个基于相似性的互连算法的例子。为了在Jamendo和Musicbrainz数据集中的艺术家之间设置RDF链接，作者们使用了一个相似度度量，比较艺术家的名字以及他们的专辑和歌曲的标题。</p><p><b>可以使用各种RDF链接生成框架</b>，这些框架提供了声明性语言，用于指定应该创建哪种类型的RDF链接，应该使用哪种相似度度量的组合来比较实体，以及如何将特定属性的相似度评分聚合为整体评分。Silk框架(Volz et al.， 2009)适用于本地和远程SPARQL [Endnote: <u><a href=\"https://link.zhihu.com/?target=http%3A//www.w3.org/TR/rdf-sparql-query/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">w3.org/TR/rdf-sparql-qu</span><span class=\"invisible\">ery/</span><span class=\"ellipsis\"></span></a></u>]端点，设计用于分布式环境，而不必在本地复制数据集。LinQL框架(Hassanzadeh et al.， 2009)可以在关系数据库上工作，并且可以与数据库到RDF的映射工具(如D2R Server或Virtuoso)一起使用。</p><h3><b>元数据</b></h3><p><b>关联数据应该与几种类型的元数据一起发布，以增加其对数据使用者的效用。</b>为了使客户能够评估发布数据的质量，并确定他们是否想要信任数据，数据应该伴随着关于其创建者、其创建日期以及创建方法的元信息(Hartig, 2009)。可以使用Dublin Core术语或语义Web发布词汇表提供基本的起源元信息(Carroll等，2005)。开放起源模型(Moreau et al.， 2008)提供了描述数据转换工作流的术语。在(Zhao et al.， 2008)中，作者提出了一种为RDF链接提供证据和跟踪RDF链接如何随时间变化的方法。</p><p>为了支持客户选择最有效的方式来访问他们必须执行的特定任务的Web数据，数据发布者可以提供有关其数据集及其与其他数据集的相互关系的其他技术元数据：语义Web爬行站点地图扩展 （Cyganiak等人，2008）允许数据发布者声明除可引用的URI之外还提供了哪些替代的访问方式（SPARQL端点，RDF转储）。 互连数据集的词汇表（Alexander等，2009）定义了术语和最佳做法，以对有关数据集以及连接它们的链接集进行分类并提供统计元信息。</p><h3><b>发布工具</b></h3><p>当前已有各种关联数据发布工具被开发。这些工具要么将RDF存储的内容作为Web上的链接数据提供，要么在非RDF遗留数据源上提供链接数据视图。这些工具使发布者不必处理诸如内容协商等技术细节，并确保根据关联数据社区最佳实践发布数据(Sauermann &amp; Cyganiak, 2008;Berrueta &amp; Phipps, 2008;Bizer &amp; Cyganiak &amp; Heath, 2007)。所有工具都支持将 URI 解引用为RDF描述。此外，一些工具还提供了对服务数据集的SPARQL查询访问，并支持发布RDF转储。</p><ul><li>D2R服务器。D2R服务器(Bizer &amp; Cyganiak, 2006)是一个将非rdf关系数据库作为链接数据发布到Web上的工具。使用声明性映射语言，data publisher定义了数据库的关系模式和目标RDF词汇表之间的映射。基于映射，D2R服务器在数据库上发布一个链接数据视图，并允许客户端通过SPARQL协议查询数据库。</li><li>艺术大师万能服务器。OpenLink Virtuoso服务器[Endnote: <u><a href=\"https://link.zhihu.com/?target=http%3A//www.openlinksw.com/dataspace/dav/wiki/Main/VOSRDF\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">openlinksw.com/dataspac</span><span class=\"invisible\">e/dav/wiki/Main/VOSRDF</span><span class=\"ellipsis\"></span></a></u>]提供通过链接数据接口和SPARQL端点提供RDF数据的服务。RDF数据可以直接存储在Virtuoso中，也可以基于映射从非RDF关系数据库动态创建。</li><li>塔利斯的平台。Talis平台[Endnote: <u><a href=\"https://link.zhihu.com/?target=http%3A//www.talis.com/platform/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">talis.com/platform/</span><span class=\"invisible\"></span></a></u>]以软件形式提供通过HTTP访问的服务，并为RDF/Linked Data提供本机存储。在访问权限允许的情况下，可以通过SPARQL端点和一系列遵循链接数据原则的REST api访问每个Talis平台存储的内容。</li><li>Pubby。Pubby服务器(Cyganiak &amp; Bizer, 2008)可以作为任何支持SPARQL的RDF存储的扩展。Pubby将URI请求重写为SPARQL，描述针对底层RDF存储的查询。除了RDF, Pubby还在数据存储上提供了一个简单的HTML视图，并负责处理两个表示之间的303重定向和内容协商。</li><li>Triplify。Triplify toolkit (Auer et al, 2009)支持开发人员使用链接数据前端扩展现有的Web应用程序。基于SQL查询模板，Triplify在应用程序的数据库上提供一个链接数据和一个JSON视图。</li><li>SparqPlug。SparqPlug (Coetzee, Heath和Motta, 2008)是一种服务，它支持从Web上不包含RDF数据的遗留HTML文档提取链接数据。该服务将HTML DOM序列化为RDF，并允许用户定义SPARQL查询，将其元素转换为他们选择的RDF图。</li><li>OAI2LOD服务器。OAI2LOD (Haslhofer &amp; Schandl, 2008)是支持开放归档OAI-RMH协议的文档服务器的链接数据包装器。</li><li>SIOC出口商。SIOC项目为几个流行的博客引擎、内容管理系统和论坛(如WordPress、Drupal和phpBB)开发了链接数据包装器。</li></ul><p>一种帮助出版商调试其链接数据站点的服务是蒸汽验证服务。验证已发表的数据是否符合关联数据原则和社区最佳实践。</p><h2><b>五 链接数据的应用</b></h2><p>随着大量的关联数据在网络上发布，大量的工作正在进行中，以研究和构建利用这些数据的应用程序。目前，这些工作大致可以分为三类：链接数据浏览器、链接数据搜索引擎和特定领域的链接数据应用程序。在下一节中，我们将研究这些类别。</p><h3><b>链接数据浏览器</b></h3><p>正如传统的Web浏览器允许用户通过跟随超文本链接在HTML页面之间导航一样，链接数据浏览器允许用户通过跟随RDF三元组表示的链接在数据源之间导航。例如，用户可以查看DBpedia对伯明翰市(英国)的RDF描述，跟随“诞生地”链接到的描述 喜剧演员托尼·汉考克(出生在伦敦金融城)，从那时起，他从英国广播公司获得了描述汉考克主演的广播节目的RDF数据。结果是，用户可以在一个数据源中开始导航，并通过跟踪RDF而不是HTML链接逐步遍历Web。Disco超级数据浏览器采用了这种方法，可以看作是超文本导航范例在数据网络中的直接应用。</p><p>然而，数据提供了超文本Web之外的人机交互机会和挑战。人们不仅需要能够浏览项目之间的链接，而且还需要能够大量分析数据。制表法(Berners-Lee et al, 2006;例如，Berners-Lee et al, 2008)允许用户遍历数据网络，并在“大纲模式”中以可控的方式公开数据片段;发现并突出一种兴趣模式;然后在data Web中查询其他类似的模式。查询的结果形成一个表，然后可以使用各种传统的数据表示方法(如分面浏览器、地图、时间轴等)分析该表。</p><p>Tabulator和Marbles (Becker &amp; Bizer, 2008)(见图3)是跟踪数据来源的数据浏览器，同时合并来自不同来源的同一事物的数据。虽然作者(Karger &amp; schraefel, 2006)等面向图视图的使用RDF数据提出质疑,如浏览器如FOAFNaut, (Hastrup Cyganiak &amp; Bojars, 2008)认为,这种接口填补一个重要的利基,并描述他们Fenfire浏览器,遵循这一显示模式。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6566c74e37ae98dc4c5ec30afaccfd4d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1262\" data-rawheight=\"1176\" class=\"origin_image zh-lightbox-thumb\" width=\"1262\" data-original=\"https://pic2.zhimg.com/v2-6566c74e37ae98dc4c5ec30afaccfd4d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1262&#39; height=&#39;1176&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1262\" data-rawheight=\"1176\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1262\" data-original=\"https://pic2.zhimg.com/v2-6566c74e37ae98dc4c5ec30afaccfd4d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6566c74e37ae98dc4c5ec30afaccfd4d_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3><b>链接数据搜索引擎和索引</b></h3><p>在传统的超文本网络中，浏览和搜索通常被视为交互的两种主要模式(Olston &amp; Chi, 2003)。虽然浏览器提供了在信息空间中导航的机制，但搜索引擎通常是导航过程开始的地方。已经开发了许多搜索引擎，它们通过跟随RDF链接从Web中抓取链接数据，并提供聚合数据的查询功能。一般来说，这些服务可以分为两类:面向人的搜索引擎和面向应用的索引。</p><h3>面向人的搜索引擎</h3><p>猎鹰(Cheng &amp; Qu, this issue) 和 SWSE (Hogan et al.， 2007)等搜索引擎提供面向人类用户的基于关键词的搜索服务，并遵循与现有市场领导者(如谷歌和Yahoo)类似的交互模式。用户将看到一个搜索框，可以在其中输入与他们感兴趣的项目或主题相关的关键字，应用程序将返回可能与查询相关的结果列表。然而，SWSE和Falcons并不是简单地提供从搜索结果到提到查询关键字的源文档的链接，而是为用户提供了一个更详细的界面，该界面利用了数据的底层结构。两者都提供了用户从结果列表中选择的实体的摘要，以及从Web上爬取的其他结构化数据和到相关实体的链接。</p><p>Falcons为用户提供了搜索对象、概念和文档的选项，每个选项的结果显示略有不同。虽然对象搜索(图4)适用于搜索人员、位置和其他更具体的项，但概念搜索的目标是在Web上发布的本体中定位类和属性。文档搜索功能提供了更传统的搜索引擎体验，其中结果指向包含指定搜索词的RDF文档。</p><p>值得注意的是，虽然它们可以被称为不同的实体，但文档Web和数据Web形成了一个连接的、可导航的信息空间。例如，用户可以在现有的文档Web中执行搜索，跟踪从HTML文档到数据Web的链接，在这个空间中导航一段时间，然后跟踪链接到另一个HTML文档，等等。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-38c93bf9418cb1c7b3c9a3132e5cb923_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1270\" data-rawheight=\"966\" class=\"origin_image zh-lightbox-thumb\" width=\"1270\" data-original=\"https://pic4.zhimg.com/v2-38c93bf9418cb1c7b3c9a3132e5cb923_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1270&#39; height=&#39;966&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1270\" data-rawheight=\"966\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1270\" data-original=\"https://pic4.zhimg.com/v2-38c93bf9418cb1c7b3c9a3132e5cb923_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-38c93bf9418cb1c7b3c9a3132e5cb923_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>值得注意的是，虽然SWSE和Falcons都使用从Web上爬出的结构化数据，但是它们选择提供非常简单的查询功能，模拟传统Web搜索引擎的查询接口。虽然一个直观地期望额外的结构数据被利用为高级用户提供的查询功能,至少没有被证明是这样到目前为止,除了制表机的查询和在上雕琢平面的浏览界面风格查询优化。SWSE确实通过SPARQL查询语言提供对其底层数据存储的访问，但是这主要适用于了解该语言的应用程序开发人员，而不是希望通过可用的人工接口询问非常具体问题的普通用户。</p><h3>面向应用的索引</h3><p>当SWSE和Falcons提供面向人类的搜索功能时，另一种类型的服务已经开发出来，以满足构建在分布式链接数据之上的应用程序的需求。这些面向应用程序的索引，如Swoogle (Ding et al, 2005)、Sindice (Oren et al, 2008)和Watson (d&#39;Aquin et al, 2008)提供api，通过这些api，链接数据应用程序可以发现Web上引用某个URI或包含某个关键字的RDF文档。这种服务的基本原理是，<b>每个新的关联数据应用程序不应该需要实现自己的基础结构，以便爬行和索引它可能希望使用的Web数据的所有部分</b>。相反，<b>应用程序可以查询这些索引来接收指向潜在相关文档的指针</b>，然后由应用程序本身检索和处理这些文档。尽管有这个共同的主题，这些服务的侧重点略有不同。Sindice更侧重于提供对包含实例数据的文档的访问，而Swoogle和Watson的重点则是寻找提供与查询相关的特定概念的本体。</p><h3><b>领域特定的应用</b></h3><p>虽然上面描述的链接数据浏览器和搜索引擎提供了基本的通用功能，但是已经开发了许多服务，通过“混合”来自各种链接数据源的数据来提供更多领域特定的功能。</p><h3>Revyu</h3><p>Revyu (Heath &amp; Motta, 2008)是一个基于关联数据原则和语义网技术栈的通用评论和评级网站。除了发布链接数据外，Revyu还从网络上获取链接数据，以增强网站用户的体验。例如，当影片在Revyu上被评论时，网站会尝试将这些影片与DBpedia中的相应条目进行匹配。在进行匹配的地方，从DBpedia检索关于电影的附加信息(如导演姓名和电影海报)，并显示在站点的面向人的(HTML)页面中。此外，还在RDF级别上创建到相应项的链接，以确保当人类用户通过从各种来源的数据进行混拼来查看更丰富的项视图时，能够识别数据的链接应用程序会提供对uri的引用，可以从中检索相关数据。类似的原则也适用于将书籍和酒吧等项目与外部数据集中的相应条目相链接，并使用FOAF数据增强用户配置文件。</p><h3>DBpedia Mobile</h3><p>DBpedia Mobile (Becker &amp; Bizer, 2008) 是一款可在iPhone或其他移动设备上运行的位置感知关联数据浏览器。DBpedia Mobile是面向游客探索城市的用例。基于移动设备当前的GPS位置，该应用程序提供了一个以位置为中心的mashup，其中包括来自DBpedia的附近位置、来自Revyu的相关评论，以及通过围绕Flickr照片共享API的链接数据包装器获得的相关照片。图5显示了DBpedia Mobile显示来自DBpedia和Revyu的关于柏林勃兰登堡门的数据。除了访问Web数据，DBpedia Mobile还允许用户将当前位置、图片和评论作为链接数据发布到Web上，以便其他应用程序使用。发布的内容与附近的DBpedia资源相互链接，而不是简单地用地理坐标进行标记，从而为数据网络的整体丰富度做出贡献。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-835fb4a26edfcba4e882c42a9c051791_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1266\" data-rawheight=\"924\" class=\"origin_image zh-lightbox-thumb\" width=\"1266\" data-original=\"https://pic2.zhimg.com/v2-835fb4a26edfcba4e882c42a9c051791_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1266&#39; height=&#39;924&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1266\" data-rawheight=\"924\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1266\" data-original=\"https://pic2.zhimg.com/v2-835fb4a26edfcba4e882c42a9c051791_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-835fb4a26edfcba4e882c42a9c051791_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>Talis Aspire</h3><p>Talis Aspire (Clarke, 2009)是一个基于web的资源列表管理应用程序，部署到大学讲师和学生。当用户通过传统的Web接口创建列表时，应用程序生成RDF三元组，这些三元组被持久化到底层的链接数据兼容存储中。使用关联数据原则，可以使一个列表中的项目透明地链接到其他机构列表中的相应项目，从而通过非专业用户的操作构建学术数据网络。</p><h3>BBC 节目和音乐</h3><p>英国广播公司(BBC)内部使用关联数据作为轻量级数据集成技术。英国广播公司经营着许多广播电台和电视频道。传统上，这些电台和频道使用独立的内容管理系统。因此，BBC开始将关联数据技术与DBpedia和MusicBrainz一起作为受控词汇表来连接不同存储库中相同主题的内容，并使用来自链接开放数据云的附加数据来增加内容。基于这些联系，BBC节目和BBC音乐为其所有音乐和节目相关品牌建立了链接数据站点(Kobilarov等人，2009)。</p><h3>DERI Pipes</h3><p>DERI Pipes (Le Phuoc et al. 2009)以Yahoo Pipes为模板，提供了一个数据级的mashup平台，可以将数据源连接在一起，形成新的数据提要。产生的聚合工作流可能包含复杂的操作，如标识符整合、模式映射、RDFS或OWL推理，使用SPARQL构造操作或XSLT模板表示数据转换。图6显示了在DERI pipes开发环境中集成Tim Berners-Lee数据的工作流的组装。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a057b2315025f51b24e0d281d5de4750_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1198\" data-rawheight=\"916\" class=\"origin_image zh-lightbox-thumb\" width=\"1198\" data-original=\"https://pic1.zhimg.com/v2-a057b2315025f51b24e0d281d5de4750_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1198&#39; height=&#39;916&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1198\" data-rawheight=\"916\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1198\" data-original=\"https://pic1.zhimg.com/v2-a057b2315025f51b24e0d281d5de4750_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a057b2315025f51b24e0d281d5de4750_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>六 相关发展（研究及实践）</b></h2><p>还有其他一些与网络上发生的或相关研究团体正在研究的关联数据相关的发展。在下面几节中，我们将把这些发展与关联数据进行比较。</p><h3><b>微格式</b></h3><p>与关联数据类似，微格式旨在用结构化数据扩展Web。微格式定义了一组通过类属性嵌入到HTML中的简单数据格式。两个主要的微格式和关联数据之间的差异在其RDFa序列化:关联数据并不局限在词汇可以用来表示数据,和词汇发展过程本身是完全开放的,虽然微格式是局限于少量的词汇发展过程紧密地由一个特定的社区。通过微格式包含在HTML页面中的数据项没有自己的标识符。这可以防止跨文档和Web站点断言数据项之间的关系。通过使用uri作为全局标识符和RDF来表示关系，链接数据没有这些限制。</p><h3><b>Web API</b></h3><p>许多主要的网络数据源，如亚马逊，易趣，雅虎!，而谷歌提供通过Web api访问它们的数据。<a href=\"https://link.zhihu.com/?target=http%3A//programableweb.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">programableweb.com</span><span class=\"invisible\"></span></a>网站目前列出了1309个Web api和3966个基于这些api的mashup。使用各种不同的机制访问Web api，从这些api检索到的数据使用各种内容格式表示。相反，链接数据将自己提交给一小组标准化技术:uri和HTTP作为标识和访问机制，RDF作为内容格式。使用单一的技术而不是依赖于不同的接口和结果格式，可以使搜索引擎更容易地抓取数据源，并使用通用的数据浏览器进行访问。除了这些技术细节之外，Web api和链接数据之间还有一个主要的概念上的区别:大多数Web api不为数据项分配全局惟一标识符。因此，不可能在不同数据源中的项之间设置链接，以便将数据连接到全局数据空间。因此，基于这些api的mashup总是针对一组固定的数据源实现。相反，关联数据应用程序可以在一个无限的全局数据空间上工作。他们可以通过跟踪RDF链接发现新的数据源，并在新的数据源出现在Web上时利用它们，而不需要更改应用程序代码。因此，<b>关联数据技术有助于将当前Web上存在的不同数据筒仓连接回单一的全球信息空间</b>。</p><h3>Dataspaces</h3><p>数据库社区中一个非常类似于链接数据的最新概念是dataspaces (Franklin et al. 2005)。数据空间提供了一个目标系统架构，围绕这个架构，正在进行的关于引用协调、模式匹配和映射、数据沿袭、数据质量和信息提取的研究是统一的(Halevy et al.， 2006)。与其他信息集成系统相比，在向系统提供完整的语义映射之前，数据空间系统提供了最佳的解决方案。数据空间的一个关键思想是，随着时间的推移，提供映射的不同方增加了数据空间的语义内聚;数据集成方法与目前出现在数据网络上的方法是一样的。因此，数据网络可以被看作是数据空间概念在全球范围内的实现，它依赖于一组特定的Web标准 与Web的整体架构紧密结合。因此，数据网络很可能会从数据库社区正在进行的数据空间研究中获益。</p><h3>语义网</h3><p>将Web的功能扩展到发布结构化数据的愿望并不是新的，可以追溯到万维网最早的提议和随后关于这个主题的论文(Berners-Lee et al.， 1994)。在Web存在的早期阶段所预见的趋势包括“对象从主要是人类可读的文档到包含更多面向机器的语义信息的演变”(Berners-Lee et al.， 1994)，这可以看作是后来被称为语义Web的思想的种子。 语义网的愿景有许多不同的解释方式(如Berners- Lee, Hendler &amp; Lassila, 2001;马歇尔和希普曼，2003)。然而，尽管在解释上存在这种多样性，构建一个由机器可读数据组成的全球网络的最初目标在关于这个主题的原始文献中仍然是不变的。根据(Berners-Lee, 2000, pp.191)，“第一步是将数据以机器能够自然理解的形式放到Web上，或者将其转换成这种形式。这就产生了我所说的语义网——一个可以被机器直接或间接处理的数据网。因此，语义网或数据网是这一过程的目标或最终结果，而关联数据提供了实现这一目标的手段。 通过发布关联数据，许多个人和团体为构建数据网络做出了贡献，这可以降低重用、集成和应用来自多个、分布式和异构数据源的数据的障碍。随着时间的推移，以关联数据为基础，一些与语义Web远景相关的更复杂的建议，例如智能代理，可能会成为现实。</p><h2><b>七 研究挑战</b></h2><p>通过在Web上发布和链接各种数据源，链接开放数据社区为数据Web创建了一个结晶点，并为链接数据技术提供了一个具有挑战性的测试平台。然而，要实现像使用单一全球数据库一样使用Web的最终目标，必须克服各种尚存的研究挑战。</p><h3><b>用户界面和交互范例</b></h3><p>从用户的角度来看，链接数据的主要好处是提供对来自广泛的分布式和异构数据源的数据的集成访问。根据定义，<b>这可能涉及到集成来自用户没有明确选择的数据源的数据</b>，因为这样做可能会导致不可接受的认知开销。尽管第5节中描述的浏览器在如何开发利用关联数据的应用程序方面展示了很有前景的趋势，但是在理解基于以这种方式动态组装的数据构建的应用程序的适当用户交互范例方面仍然存在许多挑战(Heath, 2008b)。例如，虽然超文本浏览器提供了在以文档为中心的信息空间中向前和向后导航的机制，但是<b>链接数据浏览器中的类似导航控件应该允许用户在实体之间向前和向后移动</b>，从而改变应用程序的焦点。链接数据浏览器还需要提供直观和有效的机制，用于<b>从集成的、以实体为中心的视图中添加和删除数据源</b>。Sigma (Catasta &amp; Cyganiak &amp; Tummarello, 2009)是一个基于Sindice服务的搜索引擎，它给出了如何实现这些功能的提示。然而，当数据源数量在数千或数百万时，如何实现这样的接口是一个迷人的研究挑战。</p><h3><b>应用程序架构</b></h3><p>原则上，可以通过预先爬行和缓存访问链接数据，也可以在应用程序运行时通过链接遍历或联合查询动态访问链接数据。SWSE、Sindice、Falcons和Watson等搜索引擎在数据网络中爬行，并通过api为应用程序提供对爬行数据的访问。关联数据的联邦查询体系结构包括DARQ (Quilitz &amp; Leser, 2008)和SemaPlorer (Schenk et al.， 2008)。语义Web客户端库和SQUIN已经证明，通过依赖运行时链接遍历，表达性查询可以在Web数据上得到回答。这些方法的适当混合始终取决于链接数据应用程序的特定需求。然而,由于可伸缩性问题的可能性与动态链接遍历和联合查询,它可能发生广泛的爬行和缓存将会成为常态,使得数据及时提供给应用程序,而能够利用网络的开放的数据通过链接遍历发现新的数据源。</p><h3><b>模式映射和数据融合</b></h3><p>从分布式数据源检索数据后，必须以有意义的方式对其进行集成，然后才能显示给用户或进一步处理。<b>如今，大多数链接数据应用程序都将来自不同数据源的数据并排显示，但几乎没有进一步集成</b>。为此，需要将来自不同词汇表的术语映射到应用程序目标模式，并通过解决数据冲突来融合来自不同来源的相同实体的数据。 链接数据源要么使用自己的模式，要么混合使用现有的、众所周知的词汇表中的术语，以及特定于特定数据源的自定义术语。为了支持客户端在不同模式之间转换数据，数据源可以在数据Web上发布其本地术语与相关数据源术语之间的对应关系。目前W3C推荐的RDF模式(Brickley &amp; Guha, 2004)和OWL (McGuinness &amp; van Harmelen, 2004)定义了一些基本的术语，如OWL:equivalentClass、OWL:equivalentProperty、rdfs:subClassOf、rdfs:subPropertyOf，它们可以用来发布基本的通信。在许多情况下，<b>这些通信过于粗粒度，无法在模式之间正确转换数据</b>。例如，问题包括结构异构和价值转换。因此，一个开放的研究问题是开发在Web上发布更细粒度模式映射的语言。理想情况下，这样的语言将支持传递映射，并提供对部分映射的组合，以涵盖数据源混合来自不同词汇表的术语的情况。候选技术包括(Haslhofer, 2008)和(Euzenat &amp; Scharffe &amp; Zimmermann, 2007)中提出的对齐语言以及规则交换格式(RIF)。</p><p>除了增强对模式映射的支持之外，还需要在关联数据应用的数据融合领域进行进一步的研究。数据融合是将表示同一真实世界对象的多个数据项集成到单一、一致和干净的表示形式中的过程。<b>数据融合的主要挑战是解决数据冲突，即在多个数据源为对象的同一属性提供不同值的情况下选择一个值</b>。数据库社区中有大量关于数据融合的工作(Bleiholder &amp; Naumann, 2008)，而Web社区中关于身份协调的工作越来越多(Halpin &amp; Thomson, 2008)。将数据网络与其他数据融合场景区分开来的具体要求来自数据源的自主性以及与质量相关的元信息的稀少性和不确定性，为了解决不一致性，需要对数据质量进行评估。融合来自多个来源的关联数据的原型系统包括DERI管道(Le Phuoc et al.， 2009)和KnoFuss体系结构(Nikolov et al.， 2008)。</p><h3><b>链接维护</b></h3><p>链接数据源的内容发生变化:添加关于新实体的数据，更改或删除过时的数据。如今，数据源之间的RDF链接只偶尔更新，这导致指向uri的死链接不再被维护，而潜在的链接在发布新数据时没有被设置。Web体系结构在原则上可以容忍死链接，但是过多的死链接会导致客户端应用程序产生大量不必要的HTTP请求。因此，链接数据社区中当前的一个研究主题是链接维护。提出的方法这个问题范围从定期重新计算链接使用框架如丝绸(中场et al ., 2009)或LinQL (Hassanzadeh et al ., 2009),通过数据源发布更新提要(奥尔et al ., 2009)或通知链接来源变化通过订阅模型中央注册中心如萍的语义Web跟踪新的或变更的数据项。</p><h3><b>许可</b></h3><p>使用Web数据的应用程序必须能够访问数据重用和重新发布的术语的明确规范。<b>要鼓励数据所有者参与数据网络，并向数据消费者保证他们不会以某种方式使用数据而侵犯他人的权利，发布这些规范所需的适当框架是必不可少的</b>。知识共享(Creative Commons)等倡议为创造性作品的开放许可提供了一个框架，并以版权概念为基础。然而，正如(Miller et al.， 2008)所讨论的，版权法并不适用于数据，从法律的角度来看，不同的司法管辖区对数据的处理也不同。因此，社区应该采用开放数据公共领域专用和许可之类的框架来提供这一领域的清晰度。在归属是数据重用条件的情况下，可能还需要进一步的研究来探索如何在合并来自大量数据源的数据的用户界面中实现这一点。</p><h3><b>信任、质量和相关性</b></h3><p>关联数据应用程序需要考虑的一个重要问题是<b>如何确定和提供与用户需求最相关或最适合的数据</b>。例如，在数据质量和可靠性至关重要的场景中，如何启发式地确定这一点，特别是在以前可能没有遇到过数据集的情况下? 在Bizer &amp; Cyganiak, 2009中，概述了不同的基于内容、上下文和评级的技术，这些技术可用于启发式地评估数据的相关性、质量和可信度;希斯,2008)。等价物PageRank算法可能会流行的重要决定粗粒度的措施或特定数据源的意义,作为一个代理或质量相关的数据,但是这种算法需要适应连锁模式出现在网络上的数据。 从接口的角度来看，如何将来自多个数据源的数据表示为集成视图是一个重大的研究挑战。(Berners-Lee, 1997)提出浏览器界面应该用“哦，是吗?”按钮，以协助用户评估在网上遇到的资讯的可靠性。<b>每当用户遇到他们想要验证的一段信息时，按下这样一个按钮就会产生显示信息的可信度的解释。这个目标还没有实现</b>，但是现有的开发，如WIQA (Bizer &amp; Cyganiak, 2009)和InferenceWeb (McGuinness &amp; da Silva, 2003)，可以通过提供关于信息质量的解释以及用于获得查询结果的推理过程，为这一领域的工作做出贡献。</p><h3><b>隐私</b></h3><p>关联数据的最终目标是能够像使用单个全局数据库那样使用Web。实现这一理想将在许多领域带来好处，但也将加剧其他领域的危险。<b>一个有问题的领域是，整合不同来源的数据可能会侵犯隐私。在关联数据上下文中保护隐私可能需要技术和法律手段的结合，以及用户对在何种上下文中提供何种数据的更高认识。</b>在这一领域有趣的研究倡议是Weitzner关于隐私悖论的工作(Weitzner, 2007)和最近TAMI项目关于信息问责的工作(Weitzner等人，2008)。</p><h2><b>结论</b></h2><p>越来越多的数据提供者采用了关联数据原则和实践，从而在Web上创建了一个包含数十亿RDF三元组的全局数据空间。正如Web在文档的发布和使用方面带来了一场革命一样，<b>关联数据也有可能在数据的访问和利用方面带来一场革命</b>。Web api的成功展示了应用程序的强大功能，可以通过混合来自不同Web数据源的内容来创建应用程序。然而，mashup开发人员面临的挑战是扩展他们的开发方法，使其超越固定的预定义数据竖井，从而包含大量具有异构数据模型和访问方法的数据集。相比之下，关联数据实现了将Web发展成全球数据共享的愿景，允许应用程序通过标准化访问机制在一组无限制的数据源上运行。如果上面强调的研究挑战能够得到充分的解决，我们期望关联数据能够在引导网络充分发挥其潜力方面迈出重要的进化一步。</p>", 
            "topic": [
                {
                    "tag": "语义网", 
                    "tagLink": "https://api.zhihu.com/topics/19551341"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }, 
                {
                    "tag": "知识图谱", 
                    "tagLink": "https://api.zhihu.com/topics/19838204"
                }
            ], 
            "comments": []
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/semanticweb"
}

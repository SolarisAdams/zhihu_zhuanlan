{
    "title": "幼年期爬虫", 
    "description": "会在这里放一些疑难爬虫的分享记录", 
    "followers": [
        "https://www.zhihu.com/people/zhang-yi-fan-69", 
        "https://www.zhihu.com/people/xiao-ge-9527", 
        "https://www.zhihu.com/people/cheng-hao-21-24", 
        "https://www.zhihu.com/people/ccf-29-77", 
        "https://www.zhihu.com/people/huang-can-58", 
        "https://www.zhihu.com/people/airyland", 
        "https://www.zhihu.com/people/mrbo-en", 
        "https://www.zhihu.com/people/geekqian", 
        "https://www.zhihu.com/people/youhappyisok", 
        "https://www.zhihu.com/people/zswg", 
        "https://www.zhihu.com/people/tian-zhen-de-xiao-xian-yu", 
        "https://www.zhihu.com/people/liu-yi-ting-45", 
        "https://www.zhihu.com/people/ticktock-47", 
        "https://www.zhihu.com/people/han-si-li-shang", 
        "https://www.zhihu.com/people/gouridezhihu", 
        "https://www.zhihu.com/people/zhang-meng-fei-26-18", 
        "https://www.zhihu.com/people/morrison-86", 
        "https://www.zhihu.com/people/jin-shen-jing-jie", 
        "https://www.zhihu.com/people/li-wei-72-85-63", 
        "https://www.zhihu.com/people/li-fu-62-28", 
        "https://www.zhihu.com/people/guigus", 
        "https://www.zhihu.com/people/huang-he-he-43-44", 
        "https://www.zhihu.com/people/puppy-21-32", 
        "https://www.zhihu.com/people/ni-hao-da-bai-70", 
        "https://www.zhihu.com/people/yi-xu-yan-ge", 
        "https://www.zhihu.com/people/ju-zi-72-30", 
        "https://www.zhihu.com/people/leveapi", 
        "https://www.zhihu.com/people/fu-shi-nuo-2", 
        "https://www.zhihu.com/people/benny-chen-56-97", 
        "https://www.zhihu.com/people/zhao-wei-ya", 
        "https://www.zhihu.com/people/fucktheholl", 
        "https://www.zhihu.com/people/lan-meng-meng-76", 
        "https://www.zhihu.com/people/hui-yi-li-dai-xu-64-30", 
        "https://www.zhihu.com/people/wu-ming-50-31-79", 
        "https://www.zhihu.com/people/shuo-zou-xiang-xia-zai-zou", 
        "https://www.zhihu.com/people/li-jin-qiang-53", 
        "https://www.zhihu.com/people/song-liang-liang-39", 
        "https://www.zhihu.com/people/sun-ye-1-81", 
        "https://www.zhihu.com/people/hou-dong-63-15", 
        "https://www.zhihu.com/people/wan-min-55", 
        "https://www.zhihu.com/people/guoxuequan", 
        "https://www.zhihu.com/people/yqh-29-69", 
        "https://www.zhihu.com/people/sss-zero", 
        "https://www.zhihu.com/people/ban-ma-58-1", 
        "https://www.zhihu.com/people/innocent-61-93", 
        "https://www.zhihu.com/people/xie-wen-60", 
        "https://www.zhihu.com/people/gyoona", 
        "https://www.zhihu.com/people/speaker", 
        "https://www.zhihu.com/people/sun-yu-chen-46-62", 
        "https://www.zhihu.com/people/zhang-zi-cheng-81", 
        "https://www.zhihu.com/people/tu-dou-10-58-24", 
        "https://www.zhihu.com/people/li-ming-kuan-3", 
        "https://www.zhihu.com/people/ye-wang-ran", 
        "https://www.zhihu.com/people/kongyifei", 
        "https://www.zhihu.com/people/iii-62-93", 
        "https://www.zhihu.com/people/zhui-feng-de-sao-nian-007", 
        "https://www.zhihu.com/people/evilbear-22", 
        "https://www.zhihu.com/people/luckyyuu", 
        "https://www.zhihu.com/people/x8335533", 
        "https://www.zhihu.com/people/yang-rui-qian-32", 
        "https://www.zhihu.com/people/jiedong", 
        "https://www.zhihu.com/people/he-he-91-41-72"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/73048271", 
            "userName": "Cookie", 
            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
            "upvote": 16, 
            "title": "爬虫模拟登录知乎并爬取首页信息保存入库--2019最新版", 
            "content": "<p><b>以下内容仅交流学习，请勿用于非法用途</b></p><p><b>微信公众号： 不一不鹗</b></p><p class=\"ztext-empty-paragraph\"><br/></p><p>之前一直在忙毕业的事情，所以很久很久没有更新了。最近呢，鼓足勇气前往北京开始我的北漂生涯，不得不说北京还是不太好混啊。</p><p>好了，我们还是说回正题，之前一直想解决知乎的模拟登陆。奈何一直没有时间，正好最近没有面试闲的慌，我们来讲讲如何破解知乎的反爬，并且实现首页的抓取。</p><p>我们先抓包看看。</p><p>发现我们点击登陆按钮时，知乎后台会post这个（<a href=\"https://www.zhihu.com/api/v3/oauth/sign_in\" class=\"internal\"><span class=\"invisible\">https://www.</span><span class=\"visible\">zhihu.com/api/v3/oauth/</span><span class=\"invisible\">sign_in</span><span class=\"ellipsis\"></span></a>）请求出去，formdata即为下图那般模样，看见这个想都不用想，开始枯燥的js调试吧。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-3d503ffcb996983b08442148d3539a05_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1390\" data-rawheight=\"124\" class=\"origin_image zh-lightbox-thumb\" width=\"1390\" data-original=\"https://pic2.zhimg.com/v2-3d503ffcb996983b08442148d3539a05_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1390&#39; height=&#39;124&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1390\" data-rawheight=\"124\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1390\" data-original=\"https://pic2.zhimg.com/v2-3d503ffcb996983b08442148d3539a05_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-3d503ffcb996983b08442148d3539a05_b.png\"/></figure><p>好的，打开chrome的全局搜索，用sign_in作为搜索的关键字，开始吧</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-cad4823487fd90d657d81af47016a536_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"519\" data-rawheight=\"257\" class=\"origin_image zh-lightbox-thumb\" width=\"519\" data-original=\"https://pic3.zhimg.com/v2-cad4823487fd90d657d81af47016a536_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;519&#39; height=&#39;257&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"519\" data-rawheight=\"257\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"519\" data-original=\"https://pic3.zhimg.com/v2-cad4823487fd90d657d81af47016a536_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-cad4823487fd90d657d81af47016a536_b.jpg\"/></figure><p>熟悉前端的朋友可以看出，这个方法即是构造登陆验证的URL，这里的body可以看出有非常大的问题在！我们在这里打上断点，开始调试，刚接触JS反爬的朋友可能在这里会困扰很久，但是JS反爬就是要有耐心一步一步的进行调试。最终可以找到他的加密函数，即为下图所示。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1d574e85946358c67fa2d08a73f23bcc_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1102\" data-rawheight=\"76\" class=\"origin_image zh-lightbox-thumb\" width=\"1102\" data-original=\"https://pic1.zhimg.com/v2-1d574e85946358c67fa2d08a73f23bcc_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1102&#39; height=&#39;76&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1102\" data-rawheight=\"76\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1102\" data-original=\"https://pic1.zhimg.com/v2-1d574e85946358c67fa2d08a73f23bcc_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-1d574e85946358c67fa2d08a73f23bcc_b.png\"/></figure><p>OK，我们来验证一下结果是否正确，在console中打印出来如下，可以看到和我们之前抓包的formdata非常相似，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-bd5d7fd2768070092306e2d035aa7be1_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1722\" data-rawheight=\"93\" class=\"origin_image zh-lightbox-thumb\" width=\"1722\" data-original=\"https://pic2.zhimg.com/v2-bd5d7fd2768070092306e2d035aa7be1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1722&#39; height=&#39;93&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1722\" data-rawheight=\"93\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1722\" data-original=\"https://pic2.zhimg.com/v2-bd5d7fd2768070092306e2d035aa7be1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-bd5d7fd2768070092306e2d035aa7be1_b.png\"/></figure><p>我们继续看看他传入加密函数的参数是什么</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-e8161c57ddc342d9adb5715dbc76c2d6_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1728\" data-rawheight=\"79\" class=\"origin_image zh-lightbox-thumb\" width=\"1728\" data-original=\"https://pic3.zhimg.com/v2-e8161c57ddc342d9adb5715dbc76c2d6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1728&#39; height=&#39;79&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1728\" data-rawheight=\"79\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1728\" data-original=\"https://pic3.zhimg.com/v2-e8161c57ddc342d9adb5715dbc76c2d6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-e8161c57ddc342d9adb5715dbc76c2d6_b.png\"/></figure><p>我们将他格式化出来看看，其内容基本如下</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-565e12d6beaadbf225d2dbd3864d2864_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"487\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb\" width=\"487\" data-original=\"https://pic1.zhimg.com/v2-565e12d6beaadbf225d2dbd3864d2864_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;487&#39; height=&#39;312&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"487\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"487\" data-original=\"https://pic1.zhimg.com/v2-565e12d6beaadbf225d2dbd3864d2864_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-565e12d6beaadbf225d2dbd3864d2864_b.jpg\"/></figure><p>通过chrome的调试界面我们可以发现signature这个字段，熟悉加密算法的朋友可以看出这是通过sha1散列算法进行加密的， 同样我们在chrome的全局搜索中使用signature作为关键字去查找看看是在哪里生成的这个字段。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c752fc0006fcaca66b656271bb958703_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"601\" data-rawheight=\"255\" class=\"origin_image zh-lightbox-thumb\" width=\"601\" data-original=\"https://pic4.zhimg.com/v2-c752fc0006fcaca66b656271bb958703_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;601&#39; height=&#39;255&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"601\" data-rawheight=\"255\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"601\" data-original=\"https://pic4.zhimg.com/v2-c752fc0006fcaca66b656271bb958703_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c752fc0006fcaca66b656271bb958703_b.jpg\"/></figure><p>打上断点调试后</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-381e9cc6e39f73aa73bd0950d218bed1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"406\" data-rawheight=\"229\" class=\"content_image\" width=\"406\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;406&#39; height=&#39;229&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"406\" data-rawheight=\"229\" class=\"content_image lazy\" width=\"406\" data-actualsrc=\"https://pic2.zhimg.com/v2-381e9cc6e39f73aa73bd0950d218bed1_b.jpg\"/></figure><p>可以看到它需要的值为formdata中的[grantType],[clientId], [source],[timestamp]这四个参数，我们可以在python中使用hmac库来计算signature</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2c829df907adabd47c7a062796424915_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"612\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb\" width=\"612\" data-original=\"https://pic2.zhimg.com/v2-2c829df907adabd47c7a062796424915_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;612&#39; height=&#39;142&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"612\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"612\" data-original=\"https://pic2.zhimg.com/v2-2c829df907adabd47c7a062796424915_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2c829df907adabd47c7a062796424915_b.jpg\"/></figure><p>ok拿到这个关键性的字段之后，我们将知乎的加密函数拷贝到nodejs中进行调试，根据{}可以找到知乎的关键加密函数。我们在nodejs中调试时会遇到很多个坑，这里要感谢以为知友，在他的文章很清楚的指出了这些坑应该如何填，具体可以看他的知乎文章</p><a href=\"https://zhuanlan.zhihu.com/p/57375111\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"internal\">sergiojune：知乎最新版模拟登陆详解，小白也能懂</a><p>只是我在nodejs中调试代码时是使用的jsdom的这包去渲染的window和document</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c489e8dfe35cbebe6a260d99dcbd0727_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"715\" data-rawheight=\"134\" class=\"origin_image zh-lightbox-thumb\" width=\"715\" data-original=\"https://pic4.zhimg.com/v2-c489e8dfe35cbebe6a260d99dcbd0727_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;715&#39; height=&#39;134&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"715\" data-rawheight=\"134\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"715\" data-original=\"https://pic4.zhimg.com/v2-c489e8dfe35cbebe6a260d99dcbd0727_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c489e8dfe35cbebe6a260d99dcbd0727_b.jpg\"/></figure><p>OK，在将这些坑都填完之后，我们拿之前在console中给加密函数传入的参数拿到nodejs中进行调试看看，模拟加密结果是否一致</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-dda5c1f1dc333b06365000893142d9f9_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1442\" data-rawheight=\"105\" class=\"origin_image zh-lightbox-thumb\" width=\"1442\" data-original=\"https://pic2.zhimg.com/v2-dda5c1f1dc333b06365000893142d9f9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1442&#39; height=&#39;105&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1442\" data-rawheight=\"105\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1442\" data-original=\"https://pic2.zhimg.com/v2-dda5c1f1dc333b06365000893142d9f9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-dda5c1f1dc333b06365000893142d9f9_b.png\"/></figure><p>可以看出运行结果与正确结果基本一致。到这里知乎的JS反爬暂时可以告一段落，我们接着分析他的请求，其中在请求头中必须携带以下三个参数否则，知乎后端将返回错误信息</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-8190d421d27b3e59a17c8225f490faa3_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"74\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic4.zhimg.com/v2-8190d421d27b3e59a17c8225f490faa3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;74&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"74\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic4.zhimg.com/v2-8190d421d27b3e59a17c8225f490faa3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-8190d421d27b3e59a17c8225f490faa3_b.png\"/></figure><p>我们都知道知乎是使用python中的django框架进行开发的，而这个xsrf则是防止Xsrf 跨站攻击的一个token验证，在我们清空cookie第一次访问首页时会在response中以cookie的形式返回给我们。</p><p>通过抓包分析可以的出在进行验证码的请求与验证时，知乎发送了三个请求给知乎后端，其中第一个是获取capsion_ticket这个cookie在后续的所有请求中也将携带这个cookie，否则会返回缺少验证码票据这个错误。而第二个验证码请求是PUT请求是知乎用来覆盖之前的验证码请求以修改页面资源。第三个验证码请求是一个POST请求是用来验证码验证码是否正确的</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-8c3af46c021f038eac2ddf369c3460fd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"376\" data-rawheight=\"193\" class=\"content_image\" width=\"376\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;376&#39; height=&#39;193&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"376\" data-rawheight=\"193\" class=\"content_image lazy\" width=\"376\" data-actualsrc=\"https://pic2.zhimg.com/v2-8c3af46c021f038eac2ddf369c3460fd_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c0437262556a5d225bb30cb8f184b759_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"853\" data-rawheight=\"40\" class=\"origin_image zh-lightbox-thumb\" width=\"853\" data-original=\"https://pic2.zhimg.com/v2-c0437262556a5d225bb30cb8f184b759_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;853&#39; height=&#39;40&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"853\" data-rawheight=\"40\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"853\" data-original=\"https://pic2.zhimg.com/v2-c0437262556a5d225bb30cb8f184b759_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c0437262556a5d225bb30cb8f184b759_b.png\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-24fe64a9e0027fdb2dc916168a790990_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"589\" data-rawheight=\"87\" class=\"origin_image zh-lightbox-thumb\" width=\"589\" data-original=\"https://pic1.zhimg.com/v2-24fe64a9e0027fdb2dc916168a790990_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;589&#39; height=&#39;87&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"589\" data-rawheight=\"87\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"589\" data-original=\"https://pic1.zhimg.com/v2-24fe64a9e0027fdb2dc916168a790990_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-24fe64a9e0027fdb2dc916168a790990_b.png\"/></figure><p>将验证码下载下来之后是返回的是通过base64编码后的二进制数据在python中进行解码保存成文件即可。其中验证码后的lang参数为验证码的类型参数“cn”为中文倒转验证码“en”为英文和数字验证码。验证码的操作可以通过python的PIL库进行相关的操作。</p><p>以上即是知乎的模拟登陆操作。</p><p>当我们成功登陆了知乎之后，自然是要下载一些数据的。我们继续抓包以获取知乎登陆成功后的首页数据，我们分析首页的请求是发现</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b6ec3345f8e4f2bda9e0d5bda10d8168_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1077\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb\" width=\"1077\" data-original=\"https://pic1.zhimg.com/v2-b6ec3345f8e4f2bda9e0d5bda10d8168_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1077&#39; height=&#39;222&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1077\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1077\" data-original=\"https://pic1.zhimg.com/v2-b6ec3345f8e4f2bda9e0d5bda10d8168_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b6ec3345f8e4f2bda9e0d5bda10d8168_b.jpg\"/></figure><p>在进行首页请求时知乎是使用的HTTP2.0协议，我们直接使用requests库携带这个请求头会直接给我们报无法解析的错误，所以我们必须使用HTTP2.0的协议去请求，一顿百度过后发现hyperyper这个库可以请求HTTP2.0协议，其用法如下，更多用法请<a href=\"https://link.zhihu.com/?target=https%3A//python-hyper.org/en/latest/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">前往</a>官方文档</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-242bc5efe06d0ffb5c71410a85c679f4_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"625\" data-rawheight=\"75\" class=\"origin_image zh-lightbox-thumb\" width=\"625\" data-original=\"https://pic1.zhimg.com/v2-242bc5efe06d0ffb5c71410a85c679f4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;625&#39; height=&#39;75&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"625\" data-rawheight=\"75\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"625\" data-original=\"https://pic1.zhimg.com/v2-242bc5efe06d0ffb5c71410a85c679f4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-242bc5efe06d0ffb5c71410a85c679f4_b.png\"/></figure><p>最后我们通过lxml进行数据的解析就好了，然后将数据写入MongoDB中</p><p>结果演示</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4ee5b82e38f87562ae534910972881f0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1431\" data-rawheight=\"265\" class=\"origin_image zh-lightbox-thumb\" width=\"1431\" data-original=\"https://pic1.zhimg.com/v2-4ee5b82e38f87562ae534910972881f0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1431&#39; height=&#39;265&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1431\" data-rawheight=\"265\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1431\" data-original=\"https://pic1.zhimg.com/v2-4ee5b82e38f87562ae534910972881f0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-4ee5b82e38f87562ae534910972881f0_b.jpg\"/></figure><p>MongoDB中的数据展示</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5287ec52b4d9476b2a907775df67b57f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"918\" data-rawheight=\"303\" class=\"origin_image zh-lightbox-thumb\" width=\"918\" data-original=\"https://pic4.zhimg.com/v2-5287ec52b4d9476b2a907775df67b57f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;918&#39; height=&#39;303&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"918\" data-rawheight=\"303\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"918\" data-original=\"https://pic4.zhimg.com/v2-5287ec52b4d9476b2a907775df67b57f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5287ec52b4d9476b2a907775df67b57f_b.jpg\"/></figure><p>代码传送门<a href=\"https://link.zhihu.com/?target=https%3A//github.com/AIpha00/zhihu\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">传送</a></p><p>麻烦各位老哥star一下下</p><p>最后的最后感谢一下这二位大佬，前任插秧，后人乘凉。没有二位的指导，知乎的坑不知道要填多久。</p><a href=\"https://zhuanlan.zhihu.com/p/34073256\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-4d184531c23f6c27e6a364334c46f41f_180x120.jpg\" data-image-width=\"1449\" data-image-height=\"689\" class=\"internal\">戴德满：2019年最新 Python 模拟登录知乎  支持验证码</a><a href=\"https://zhuanlan.zhihu.com/p/57375111\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"internal\">sergiojune：知乎最新版模拟登陆详解，小白也能懂</a><p>最后各位大佬，部门要是有坑，给个内推，感谢各位大佬！！！</p><p>如有疑问，可Email我，email：aiphalv0010@gmail.com</p><p>小弟只是一只幼年期爬虫，若有错，还望指出！</p><p>欢迎大家评论区讨论！</p><p>转载需标明出处。</p><p></p>", 
            "topic": [
                {
                    "tag": "python爬虫", 
                    "tagLink": "https://api.zhihu.com/topics/20086364"
                }, 
                {
                    "tag": "Python", 
                    "tagLink": "https://api.zhihu.com/topics/19552832"
                }, 
                {
                    "tag": "爬虫 (计算机网络)", 
                    "tagLink": "https://api.zhihu.com/topics/19577498"
                }
            ], 
            "comments": [
                {
                    "userName": "Zeit", 
                    "userLink": "https://www.zhihu.com/people/eca7c84fa61aa0288ff39afd34ea30cb", 
                    "content": "<p>感谢</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/64434294", 
            "userName": "Cookie", 
            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
            "upvote": 22, 
            "title": "裁判文书网，最新反爬破解", 
            "content": "<p>微信公众号： 不一不鹗</p><p><b>本项目仅用于学习交流------严禁用于非法用途-----若有侵犯，联系删除</b></p><p class=\"ztext-empty-paragraph\"><br/></p><p>四月初，裁判文书做了一次非常大的改版，不难想象这次改版一定会增加很多更难的反爬手段，OK！我们今天就来聊聊裁判文书最新改版的反爬，以及反反爬，这篇文章只讲思路，不会放任何代码。所以伸手党请绕路。</p><p>首先，裁判文书的代理IP封的很厉害，如果使用同一个IP进行多次访问，那么恭喜，你的IP已经被封掉了。所以在进行访问的时候必须要带上代理IP，这一点真的很烦。</p><p>其次，对于裁判文书的反反爬，可以大致分为三种解决办法：</p><p>1、使用phantomjs或者chrome等自动化工具进行抓取（但是牺牲掉的效率是很大的）</p><p>2、使用nodejs去执行，他的JS代码，并拿到我们想要的东西。</p><p>3、找到它的加密函数，使用python进行翻译。</p><p>第一种方法，相对简单但是效率很差， 容错率也很低。第三种方法，不推荐使用。因为在这一次的裁判文书更新之后，JS代码全都被编码过了。所以硬核解码代价非常高。我之前尝试过硬核解码，时间长了人会疯掉的。所以第三种方法。放弃！</p><p>我们主要还是使用第二种方法去进行反反爬。</p><p>OK，让我们进入正题</p><p>进行抓包后发现，第一次进行页面加载的时候他会返回给我们如下的JS，可以看到这段JS代码是进行编码过后的代码，可读性非常的差。如果你觉得有时间可以进行硬核解码，将他的变量名进行替换之后，增加它的可读性。并且使用熟悉的编程语言进行翻译。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e8ee623c71618ebf21620721786cdd93_b.jpg\" data-size=\"normal\" data-rawwidth=\"751\" data-rawheight=\"133\" class=\"origin_image zh-lightbox-thumb\" width=\"751\" data-original=\"https://pic4.zhimg.com/v2-e8ee623c71618ebf21620721786cdd93_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;751&#39; height=&#39;133&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"751\" data-rawheight=\"133\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"751\" data-original=\"https://pic4.zhimg.com/v2-e8ee623c71618ebf21620721786cdd93_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e8ee623c71618ebf21620721786cdd93_b.jpg\"/><figcaption>抓包之后发现，在执行页面刷新操作的时候，它自己发送了一个请求</figcaption></figure><p>这个时候不难发现，在我们清理掉浏览器的cookie之后再执行刷新页面操作，它返回了我们一段JS代码，而这段JS代码就是用来构造一个请求，并且利用JS代码进行一些DOM操作。</p><p>它这样做的原因是因为，再第一次访问的时候，他会给我们一个假的cookie，但是我们必须带着这个假的cookie以及它返回给我们的那段JS代码计算出来的URL，去进行请求，然后它会返回给我们一个真的cookie，那么我们带着这个真的cookie再去请求页面的时候，我们就迈出了第一步。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-54e1bef8fcae740619ba84159783ccd4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1234\" data-rawheight=\"669\" class=\"origin_image zh-lightbox-thumb\" width=\"1234\" data-original=\"https://pic1.zhimg.com/v2-54e1bef8fcae740619ba84159783ccd4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1234&#39; height=&#39;669&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1234\" data-rawheight=\"669\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1234\" data-original=\"https://pic1.zhimg.com/v2-54e1bef8fcae740619ba84159783ccd4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-54e1bef8fcae740619ba84159783ccd4_b.jpg\"/></figure><p>那么，我们已经知道了它的反爬流程。我们只需要去执行这段JS代码，截获它的返回值，而它的返回值就是我们需要的哪个拿到真的cookie的URL。</p><p>重点就是如何去执行它的这段JS代码，并且拿到返回值。最初，我自然是联想到了phantomJS这样的自动化工具，当然使用phantomJS去执行这段代码一样可以获取到我们想要的。但是它的效率就不敢苟同到了。所以我当时选用的是使用nodejs去执行这样的操作。那么这样做效率自然是大大的提升了。</p><p>OK到这里我们带着它第一次给我们的cookie和我们计算出来的URL去拿到真正的cookie。你以为拿到真的cookie就行了吗？万恶的裁判文书自然是不会这么轻松的。当我以为拿到这个cookie去请求的时候裁判文书的后台自然就会给我们返回访问详情链接中的一个最重要的参数DOC_ID了。不得不说这一步是真的恶心。当我们带着真的cookie去请求的时候发现他返回给我们的依然没有我们想要的cookie，通过分析发现它的doc_id是使用JS去异步加载的所以在HTML中我们是无法获取到的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-daa955122b3a59649ce851396a05ffe8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1898\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb\" width=\"1898\" data-original=\"https://pic1.zhimg.com/v2-daa955122b3a59649ce851396a05ffe8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1898&#39; height=&#39;338&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1898\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1898\" data-original=\"https://pic1.zhimg.com/v2-daa955122b3a59649ce851396a05ffe8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-daa955122b3a59649ce851396a05ffe8_b.jpg\"/></figure><p>我们继续分析，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-804e76f786d76900cf3a838b6d75a6a8_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1897\" data-rawheight=\"119\" class=\"origin_image zh-lightbox-thumb\" width=\"1897\" data-original=\"https://pic1.zhimg.com/v2-804e76f786d76900cf3a838b6d75a6a8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1897&#39; height=&#39;119&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1897\" data-rawheight=\"119\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1897\" data-original=\"https://pic1.zhimg.com/v2-804e76f786d76900cf3a838b6d75a6a8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-804e76f786d76900cf3a838b6d75a6a8_b.png\"/></figure><p>这里的wzws_id即是我们之前去获取到的那个真的cookie，在每一步的请求中都必须带着这个cookie才行，可以发现在这里多了一个关键的cookie，vjkl5。再次分析后发现，这个cookie是我们在获取到真的wzws_id之后再次去请求时，他会给我们这个vjkl5这个参数。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bd8b1c03465c92b52bd85d69f1a0c49c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1914\" data-rawheight=\"373\" class=\"origin_image zh-lightbox-thumb\" width=\"1914\" data-original=\"https://pic1.zhimg.com/v2-bd8b1c03465c92b52bd85d69f1a0c49c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1914&#39; height=&#39;373&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1914\" data-rawheight=\"373\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1914\" data-original=\"https://pic1.zhimg.com/v2-bd8b1c03465c92b52bd85d69f1a0c49c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-bd8b1c03465c92b52bd85d69f1a0c49c_b.jpg\"/></figure><p>OK到这里我们所有的cookie都已经拿到了。接下来，带着cookie让我们开开心心的去进行我们的反反爬吧</p><p>不要高兴的太早，后面自然是还有的。当我们要去请求list content这个请求的时候发现，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d3c70bd8b6ae0fdc0dcb2663e0120934_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1881\" data-rawheight=\"437\" class=\"origin_image zh-lightbox-thumb\" width=\"1881\" data-original=\"https://pic1.zhimg.com/v2-d3c70bd8b6ae0fdc0dcb2663e0120934_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1881&#39; height=&#39;437&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1881\" data-rawheight=\"437\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1881\" data-original=\"https://pic1.zhimg.com/v2-d3c70bd8b6ae0fdc0dcb2663e0120934_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d3c70bd8b6ae0fdc0dcb2663e0120934_b.jpg\"/></figure><p>在去请求list content的时候，必须携带两个必要的参数vl5x和guid</p><p>打开chrome的全局搜索找到了这个文件</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b4f5ffa0693724fbc10c22640c36ce4d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"765\" data-rawheight=\"297\" class=\"origin_image zh-lightbox-thumb\" width=\"765\" data-original=\"https://pic2.zhimg.com/v2-b4f5ffa0693724fbc10c22640c36ce4d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;765&#39; height=&#39;297&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"765\" data-rawheight=\"297\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"765\" data-original=\"https://pic2.zhimg.com/v2-b4f5ffa0693724fbc10c22640c36ce4d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b4f5ffa0693724fbc10c22640c36ce4d_b.jpg\"/></figure><p>可以看到它是如构造这个请求的。如何去执行这段JS代码并且获取到相关的参数，这里不再赘述。</p><p>这里主要讲讲如何获取到下图的DocID</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c3a9af88daf7bc33c00f763ec23043c9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"529\" data-rawheight=\"98\" class=\"origin_image zh-lightbox-thumb\" width=\"529\" data-original=\"https://pic2.zhimg.com/v2-c3a9af88daf7bc33c00f763ec23043c9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;529&#39; height=&#39;98&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"529\" data-rawheight=\"98\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"529\" data-original=\"https://pic2.zhimg.com/v2-c3a9af88daf7bc33c00f763ec23043c9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c3a9af88daf7bc33c00f763ec23043c9_b.jpg\"/></figure><p>通过分析发现</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-341ed8b9a76c2759284b695e33c7c75c_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"828\" data-rawheight=\"109\" class=\"origin_image zh-lightbox-thumb\" width=\"828\" data-original=\"https://pic1.zhimg.com/v2-341ed8b9a76c2759284b695e33c7c75c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;828&#39; height=&#39;109&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"828\" data-rawheight=\"109\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"828\" data-original=\"https://pic1.zhimg.com/v2-341ed8b9a76c2759284b695e33c7c75c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-341ed8b9a76c2759284b695e33c7c75c_b.png\"/></figure><p>当我们在点击这个链接的时候，JS帮我们执行了这一段代码其中的参数第一个是，我们之前获取到的DOC_ID这是我们计算真正的doc所必须的参数，我们一步一步往下追，可以找到它的解密方法</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c5a42c0bd201652af22040992fb51fa4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"877\" data-rawheight=\"237\" class=\"origin_image zh-lightbox-thumb\" width=\"877\" data-original=\"https://pic1.zhimg.com/v2-c5a42c0bd201652af22040992fb51fa4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;877&#39; height=&#39;237&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"877\" data-rawheight=\"237\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"877\" data-original=\"https://pic1.zhimg.com/v2-c5a42c0bd201652af22040992fb51fa4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c5a42c0bd201652af22040992fb51fa4_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-83df9346bfdd304e34f653ae55bc744e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"997\" data-rawheight=\"343\" class=\"origin_image zh-lightbox-thumb\" width=\"997\" data-original=\"https://pic3.zhimg.com/v2-83df9346bfdd304e34f653ae55bc744e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;997&#39; height=&#39;343&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"997\" data-rawheight=\"343\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"997\" data-original=\"https://pic3.zhimg.com/v2-83df9346bfdd304e34f653ae55bc744e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-83df9346bfdd304e34f653ae55bc744e_b.jpg\"/></figure><p>一步一步调式发现真正的doc_id是这个方法解密出来的。至此，破解完成。</p><p>如有疑问，欢迎私信！</p><p>小弟只是一只幼年期爬虫，若有错，还望指出！</p><p>欢迎大家评论区讨论！</p><p>转载需标明出处。</p>", 
            "topic": [
                {
                    "tag": "python爬虫", 
                    "tagLink": "https://api.zhihu.com/topics/20086364"
                }
            ], 
            "comments": [
                {
                    "userName": "Shaoq", 
                    "userLink": "https://www.zhihu.com/people/9de36158c6b5a8499b9a5fae8bc3e5ec", 
                    "content": "该评论已删除", 
                    "likes": 3, 
                    "childComments": [
                        {
                            "userName": "侯杰", 
                            "userLink": "https://www.zhihu.com/people/cc5877677fb9a58f3795548bbc7b698b", 
                            "content": "<p>请问下，第一步获取的js代码如何调试？chrome调试每次都直接跳转了，开启连续日志也无法显示第一次请求返回的js代码，fixfore调试可见js代码，但也是无法调试</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Shaoq"
                        }, 
                        {
                            "userName": "Shaoq", 
                            "userLink": "https://www.zhihu.com/people/9de36158c6b5a8499b9a5fae8bc3e5ec", 
                            "content": "禁用js", 
                            "likes": 0, 
                            "replyToAuthor": "侯杰"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>凶残，法院的网站你都下手！！！</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "老程序猿", 
                    "userLink": "https://www.zhihu.com/people/7089365289ff40695920633b8ca0b03b", 
                    "content": "终极大法是付费买数据，共赢😄", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "杭电吴彦祖", 
                    "userLink": "https://www.zhihu.com/people/ae876471e54cbb836837f97ac23aa6c9", 
                    "content": "<p>啥时候来个大佬爬个公安的户籍系统不是美滋滋</p>", 
                    "likes": 3, 
                    "childComments": []
                }, 
                {
                    "userName": "梅林", 
                    "userLink": "https://www.zhihu.com/people/46b5f78422c85203e6d70db4ec474b3c", 
                    "content": "<p>最高法真该直接卖裁判文书数据库，难得现在可以用一下。</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "侯杰", 
                    "userLink": "https://www.zhihu.com/people/cc5877677fb9a58f3795548bbc7b698b", 
                    "content": "<p>请问下，第一步获取的js代码如何调试？chrome调试每次都直接跳转了，开启连续日志也无法显示第一次请求返回的js代码，fixfore调试可见js代码，但也是无法调试</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Cookie", 
                            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
                            "content": "可用webstorm进行调试", 
                            "likes": 0, 
                            "replyToAuthor": "侯杰"
                        }, 
                        {
                            "userName": "巴啦啦小魔仙人掌", 
                            "userLink": "https://www.zhihu.com/people/2d419ae8f524f30b472fcdbe38759d37", 
                            "content": "<p>兄弟 你调试出结果了吗？</p>", 
                            "likes": 0, 
                            "replyToAuthor": "侯杰"
                        }
                    ]
                }, 
                {
                    "userName": "HackPython", 
                    "userLink": "https://www.zhihu.com/people/457479af2348680d074dff7439c6ec1a", 
                    "content": "<p>py可以直接执行js</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "巴啦啦小魔仙人掌", 
                    "userLink": "https://www.zhihu.com/people/2d419ae8f524f30b472fcdbe38759d37", 
                    "content": "<p>。。。 怎么执行那段代码。。。</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "未闻花名", 
                    "userLink": "https://www.zhihu.com/people/08b731473296f6c8688cefa77af73a5d", 
                    "content": "<p>直接爬app不就完事了 不过封ip是事实 app算法基本没改过 </p>", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "Hhhh丶", 
                            "userLink": "https://www.zhihu.com/people/44b73a22a2f4b8dc5b1f1847c0485745", 
                            "content": "<p>请问手机app 是怎么爬取的，我抓包看到的信息好像是需要解码</p>", 
                            "likes": 0, 
                            "replyToAuthor": "未闻花名"
                        }
                    ]
                }, 
                {
                    "userName": "不吃夹生饭", 
                    "userLink": "https://www.zhihu.com/people/ff83fb642310236481845ed0a8868f08", 
                    "content": "<p>这么快就迭代了啊。 我二月份做了一版爬虫，后来业务砍掉也就没有再关注这个网站。当时的大概流程是 先算guid，再算number，拿假cookie算真cookie，算vl5x，请求列表，然后列表id解密，最后再是根据真实案件id去批量下载文书并保存在xxx.zip里。因为用的是瑞数安全的反爬虫策略，算是比较难的。深入js去调试，给你点个赞</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Cookie", 
                            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
                            "content": "今年四月更新的，没有用瑞数了，改换用360的了大致流程没变只是cookie的计算改变了", 
                            "likes": 0, 
                            "replyToAuthor": "不吃夹生饭"
                        }
                    ]
                }, 
                {
                    "userName": "喵总念经", 
                    "userLink": "https://www.zhihu.com/people/d04b3bb4458d9819bbf2b8336cd2bac7", 
                    "content": "求大佬的爬虫代码", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "喵总念经", 
                            "userLink": "https://www.zhihu.com/people/d04b3bb4458d9819bbf2b8336cd2bac7", 
                            "content": "论文想用这个数据[大哭]", 
                            "likes": 0, 
                            "replyToAuthor": "喵总念经"
                        }
                    ]
                }, 
                {
                    "userName": "felix", 
                    "userLink": "https://www.zhihu.com/people/7164c46b8f0706625ca34bc1243338bd", 
                    "content": "<p>大佬，具体该怎么调试阿</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Cookie", 
                            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
                            "content": "Chrome中可以进行调试，想要调试Js代码可以使用nodeJS", 
                            "likes": 0, 
                            "replyToAuthor": "felix"
                        }
                    ]
                }, 
                {
                    "userName": "阿恨", 
                    "userLink": "https://www.zhihu.com/people/584e6d6f7f69843ed3563876e1a1c3ab", 
                    "content": "<p>是不是就是因为你们都用爬虫爬，所以普通用户上裁决文书网才总是登不上去呀？</p>", 
                    "likes": 2, 
                    "childComments": [
                        {
                            "userName": "Cookie", 
                            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
                            "content": "[捂脸][捂脸][捂脸][捂脸][捂脸]", 
                            "likes": 0, 
                            "replyToAuthor": "阿恨"
                        }
                    ]
                }, 
                {
                    "userName": "李咋办", 
                    "userLink": "https://www.zhihu.com/people/3e08a36a48d929262dd1b1835d9339b3", 
                    "content": "<p>恶心   你不是在秀你的手段 你是在拥挤最大的律师群体跟执法人员的必备网站</p>", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "食得咸鱼抵得渴", 
                            "userLink": "https://www.zhihu.com/people/6f2fbfe6d5ef8858c7c34044a5315fc5", 
                            "content": "无能狂怒？", 
                            "likes": 0, 
                            "replyToAuthor": "李咋办"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62269087", 
            "userName": "Cookie", 
            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
            "upvote": 21, 
            "title": "搜狗微信公众号更新反爬，反反爬思路", 
            "content": "<p><b>本项目仅用于学习交流------严禁用于非法用途-----若有侵犯，联系删除</b></p><p><b>微信公众号：不一不鹗</b></p><p class=\"ztext-empty-paragraph\"><br/></p><p>背景：刚入职半个月的实习生，不得不的说这次找实习的过程还蛮顺利的。工作了半个月 每天都写一些简单的爬虫（当时还是有点膨胀的）</p><p>直到上个星期五，我们的产品小姐姐过来找我说让我格式化一下线上爬虫的date字段，我欣然的接受了她的要求。</p><p>然后我花了半个小时格式化了所有的爬虫的date字段，交给测试小哥，测一下我的小小的成果。本以为可以很顺利的完成任务，毕竟认为公司的都是大佬。直到测试小哥找到我说，微信公众号的舆情爬虫数据没有数据。<b>我惊了，我真的只改了两行代码！！！！</b></p><p>没有办法硬着头皮上呗，正巧之前写过微信公众号的爬虫，心里一点都不慌！</p><p>OK，说正题。总所周知，<b><a href=\"https://link.zhihu.com/?target=https%3A//weixin.sogou.com/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">搜狗</a></b>上个版本的反爬手段，只是封掉你的IP让你的爬虫无法访问。anyway，上来先抓个包看看，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c448b76796af39e54dc8cdf2ebabd8c0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"844\" data-rawheight=\"282\" class=\"origin_image zh-lightbox-thumb\" width=\"844\" data-original=\"https://pic1.zhimg.com/v2-c448b76796af39e54dc8cdf2ebabd8c0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;844&#39; height=&#39;282&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"844\" data-rawheight=\"282\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"844\" data-original=\"https://pic1.zhimg.com/v2-c448b76796af39e54dc8cdf2ebabd8c0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c448b76796af39e54dc8cdf2ebabd8c0_b.jpg\"/></figure><p>可以看到他的URL，传统思维是获取到他的href属性拼接一下直接去访问就好了。当我们去点击这个网页的时候出现了以下景象</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c69583a8ec87afc0037cdffac9fae564_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1110\" data-rawheight=\"445\" class=\"origin_image zh-lightbox-thumb\" width=\"1110\" data-original=\"https://pic1.zhimg.com/v2-c69583a8ec87afc0037cdffac9fae564_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1110&#39; height=&#39;445&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1110\" data-rawheight=\"445\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1110\" data-original=\"https://pic1.zhimg.com/v2-c69583a8ec87afc0037cdffac9fae564_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c69583a8ec87afc0037cdffac9fae564_b.jpg\"/></figure><p>WTF？？？？连我本人都反爬？？？</p><p>ok 让我们用fiddler来抓包看看，请求我们搜索的页面</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-470f70c7bb516f1ab2801f98a4bbc400_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"986\" data-rawheight=\"198\" class=\"origin_image zh-lightbox-thumb\" width=\"986\" data-original=\"https://pic1.zhimg.com/v2-470f70c7bb516f1ab2801f98a4bbc400_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;986&#39; height=&#39;198&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"986\" data-rawheight=\"198\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"986\" data-original=\"https://pic1.zhimg.com/v2-470f70c7bb516f1ab2801f98a4bbc400_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-470f70c7bb516f1ab2801f98a4bbc400_b.jpg\"/></figure><p>别问我，为什么会放在这里，一看这么多的cookie准没好事</p><p>OK，我们继续找到请求详情页面的URL，看看他的信息</p><p>观察他的URL（<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/profile%3Fsrc%3D3%26timestamp%3D1555088522%26ver%3D1%26signature%3DVd9nNZn5POoH-EXHFYmynSmyOP8OCjlHseocD8xFrmEDD%2AnUBbODQKO9L1ue%2AbbnGpVupbpBv0CAoBv6KHYJ5w%3D%3D\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">mp.weixin.qq.com/profil</span><span class=\"invisible\">e?src=3&amp;timestamp=1555088522&amp;ver=1&amp;signature=Vd9nNZn5POoH-EXHFYmynSmyOP8OCjlHseocD8xFrmEDD*nUBbODQKO9L1ue*bbnGpVupbpBv0CAoBv6KHYJ5w==</span><span class=\"ellipsis\"></span></a>）</p><p>等等，这玩意儿不对啊，不是我们之前看到的href属性啊</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-2b5a91d716860368b20408844bafd510_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"716\" data-rawheight=\"53\" class=\"origin_image zh-lightbox-thumb\" width=\"716\" data-original=\"https://pic1.zhimg.com/v2-2b5a91d716860368b20408844bafd510_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;716&#39; height=&#39;53&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"716\" data-rawheight=\"53\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"716\" data-original=\"https://pic1.zhimg.com/v2-2b5a91d716860368b20408844bafd510_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-2b5a91d716860368b20408844bafd510_b.png\"/></figure><p>对比过后 不对，有猫腻</p><p>OK！我们继续抓包看，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-54a189ace6c794ddb64fdc73c0578815_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"586\" data-rawheight=\"112\" class=\"origin_image zh-lightbox-thumb\" width=\"586\" data-original=\"https://pic2.zhimg.com/v2-54a189ace6c794ddb64fdc73c0578815_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;586&#39; height=&#39;112&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"586\" data-rawheight=\"112\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"586\" data-original=\"https://pic2.zhimg.com/v2-54a189ace6c794ddb64fdc73c0578815_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-54a189ace6c794ddb64fdc73c0578815_b.jpg\"/></figure><p>嘿，兄弟！你在这里啊。继续看他的返回信息</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-acbd708145199123c5b6265dc66e9dca_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"598\" data-rawheight=\"269\" class=\"origin_image zh-lightbox-thumb\" width=\"598\" data-original=\"https://pic3.zhimg.com/v2-acbd708145199123c5b6265dc66e9dca_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;598&#39; height=&#39;269&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"598\" data-rawheight=\"269\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"598\" data-original=\"https://pic3.zhimg.com/v2-acbd708145199123c5b6265dc66e9dca_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-acbd708145199123c5b6265dc66e9dca_b.jpg\"/></figure><p>好眼熟，好眼熟！！！相信不会JS的朋友也应该看懂这段代码了，这不就是我们要的真实的URL吗？？？</p><p>OK，思路清晰了，通过请求href属性去获取真实的URL。重点即是如何获取真实的URL。当我们拿着href属性中的链接去请求的时候发现，直接302返回验证码了。WTF？？？这不是我想像中的样子啊！！！OK，我们继续分析，把首页的href属性和fiddler抓包的URL，copy出来看一看</p><p>首页URL：/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6EzDJysI4ql5MPrOUp16838dGRMI7NnPq-Z8GDlDaHC679kSlyHm27wwvDqyjOWdzsAcG8HgtN7tLlg-njLaZjqZdMYI6Tll0rkvGkyTBLtrZzoL8p4e2Cxx1Yjqc7l3z0N7bZR100sKltfGGwm9D0_zBX6sIs9NdskJcNu7cHHrdvhvPpnh7VuO00efWrWmm&amp;type=1&amp;query=%E8%82%A1%E6%9D%83</p><p>返回真实url的请求：/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6EzDJysI4ql5MPrOUp16838dGRMI7NnPq-Z8GDlDaHC679kSlyHm27wwvDqyjOWdzdU7fii5plhg15R0iBfeWl48lrnwFM_veclFZ_j6FbZ4Ko2jlRK1f5_Nj66DVc40vyqQG-FxCQpaObERWsEq1JbBXJqzj9-U2z591KK8kKKRUyU5e290P1m4OZCnxixtX&amp;type=1&amp;query=%E8%82%A1%E6%9D%83&amp;k=52&amp;h=S</p><p>等等最后怎么多了两个参数？？？哪里来的？？？？又开始慌了！！！</p><p>没办法了用万能的chrome强大的开发者工具调试吧，找到a标签的点击事件看看是调用了哪个方法，以便找到这两个参数</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-26f386c8f354386c701902d09114740c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"788\" data-rawheight=\"145\" class=\"origin_image zh-lightbox-thumb\" width=\"788\" data-original=\"https://pic1.zhimg.com/v2-26f386c8f354386c701902d09114740c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;788&#39; height=&#39;145&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"788\" data-rawheight=\"145\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"788\" data-original=\"https://pic1.zhimg.com/v2-26f386c8f354386c701902d09114740c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-26f386c8f354386c701902d09114740c_b.jpg\"/></figure><p>一点进来发现，暴露无遗，东西都在。感谢大哥！</p><p>OK，现在用python代码重写一下就行了。</p><div class=\"highlight\"><pre><code class=\"language-text\">    for link in link_list:\n        b = int(random.random() * 100) + 1\n        a = link.find(&#34;url=&#34;)\n        c = link.find(&#34;&amp;k=&#34;)\n        result_link = (link + &#34;&amp;k=&#34; + str(b) + &#34;&amp;h=&#34; + link[a + 4 + 26 + b: a + 4 + 26 + b + 1])</code></pre></div><p>至此，我们终于找到了这个假的URL，OK我们开开心心的去拿我们真实的URL去咯，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-758abf5701940036685ed25052aa7a84_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1495\" data-rawheight=\"237\" class=\"origin_image zh-lightbox-thumb\" width=\"1495\" data-original=\"https://pic1.zhimg.com/v2-758abf5701940036685ed25052aa7a84_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1495&#39; height=&#39;237&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1495\" data-rawheight=\"237\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1495\" data-original=\"https://pic1.zhimg.com/v2-758abf5701940036685ed25052aa7a84_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-758abf5701940036685ed25052aa7a84_b.png\"/></figure><p>等等这是什么？？？为什么不返回真实的URL？？</p><p>好了，现在想起来之前那么多的cookie了。没办法带着去吧。分析发现，它需要这几个cookie</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-138abf3595efa56f368b53197f377c2c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"467\" data-rawheight=\"175\" class=\"origin_image zh-lightbox-thumb\" width=\"467\" data-original=\"https://pic1.zhimg.com/v2-138abf3595efa56f368b53197f377c2c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;467&#39; height=&#39;175&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"467\" data-rawheight=\"175\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"467\" data-original=\"https://pic1.zhimg.com/v2-138abf3595efa56f368b53197f377c2c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-138abf3595efa56f368b53197f377c2c_b.jpg\"/></figure><hr/><p><b>很多朋友带着之前获取的SUV和SUID去请求的时候发现还是会返回验证码</b></p><p>这是因为cookie中的SUV这个参数是通过下面这个这个请求去重新获取的，带着之前请求的SUV自然搜狗后台不会给你返回，所以在最后大家需要构造参数去请求获取真的SUV参数</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-004716844870bee1f37cb614783244c7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"243\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https://pic4.zhimg.com/v2-004716844870bee1f37cb614783244c7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;720&#39; height=&#39;243&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"243\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"720\" data-original=\"https://pic4.zhimg.com/v2-004716844870bee1f37cb614783244c7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-004716844870bee1f37cb614783244c7_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">data = {\n    &#34;uigs_cl&#34;: &#34;first_click&#34;,\n    &#34;uigs_refer&#34;: &#34;&#34;,\n    &#34;uigs_t&#34;: str(int(round(time.time() * 1000))),\n    &#34;uigs_productid&#34;: &#34;vs_web&#34;,\n    &#34;terminal&#34;: &#34;web&#34;,\n    &#34;vstype&#34;: &#34;weixin&#34;,\n    &#34;pagetype&#34;: &#34;result&#34;,\n    &#34;channel&#34;: &#34;result_account&#34;,\n    &#34;s_from&#34;: &#34;&#34;,\n    &#34;sourceid&#34;: &#34;&#34;,\n    &#34;type&#34;: &#34;weixin_search_pc&#34;,\n    &#34;uigs_cookie&#34;: &#34;SUID%2Csct&#34;,\n    &#34;uuid&#34;: uuid.uuid1(),\n    &#34;query&#34;: seed,\n    &#34;weixintype&#34;: &#34;1&#34;,\n    &#34;exp_status&#34;: &#34;-1&#34;,\n    &#34;exp_id_list&#34;: &#34;0_0&#34;,\n    &#34;wuid&#34;: ,\n    &#34;snuid&#34;: snuid,\n    &#34;rn&#34;: &#34;1&#34;,\n    &#34;login&#34;: &#34;0&#34;,\n    &#34;uphint&#34;: &#34;0&#34;,\n    &#34;bottomhint&#34;: &#34;0&#34;,\n    &#34;page&#34;: &#34;1&#34;,\n    &#34;exp_id&#34;: &#34;null_0-null_1-null_2-null_3-null_4-null_5-null_6-null_7-null_8-null_9&#34;,\n    &#34;time&#34;: &#34;20429&#34;,\n}</code></pre></div><p>data中即是这个请求的各种参数，其中的snuid即是cookie中的SUID这个参数，uuid即是通用唯一识别码，通过python中uuid这个库可以计算出这个值，语法如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">import uuid\nuuid.uuid1()</code></pre></div><p>2019年7月30日测试，依然能够成功拿到公众号的title，在请求公众号中的文章是没有反爬的故不再赘述</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0d6f876ea32bf220bc9d6217729ea215_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"336\" data-rawheight=\"401\" class=\"content_image\" width=\"336\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;336&#39; height=&#39;401&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"336\" data-rawheight=\"401\" class=\"content_image lazy\" width=\"336\" data-actualsrc=\"https://pic2.zhimg.com/v2-0d6f876ea32bf220bc9d6217729ea215_b.jpg\"/></figure><p>搜狗还是没有更新的  大家可以开心的抓了！！！</p><p>至此，搜狗微信公众号反反爬虫分析结束。</p><p>如有疑问，欢迎私信！</p><p>小弟只是一只幼年期爬虫，若有错，还望指出！</p><p>若有疑问请Email我， Email：aiphalv0010@gmail.com</p><p>人在北京依旧还没有工作</p><p>转载需标明出处。</p><p>最后还是贴上代码块吧，不是工程代码，各位官老爷将就看！</p><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">import requests\nimport time\nfrom urllib.parse import urlencode,quote\nimport uuid\nfrom lxml import etree\nimport random\nimport re\n\nseed = &#34;贸易&#34;\nquery_url = &#34;https://weixin.sogou.com/weixin?type=1&amp;query={}&#34;.format(quote(seed))\nheaders = {\n    &#34;Accept&#34;: &#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3&#34;,\n    &#34;Accept-Encoding&#34;: &#34;gzip, deflate, br&#34;,\n    &#34;Accept-Language&#34;: &#34;zh-CN,zh;q=0.9&#34;,\n    &#34;Cache-Control&#34;: &#34;no-cache&#34;,\n    &#34;Connection&#34;: &#34;keep-alive&#34;,\n    &#34;Host&#34;: &#34;weixin.sogou.com&#34;,\n    &#34;Pragma&#34;: &#34;no-cache&#34;,\n    &#34;Referer&#34;: query_url,\n    &#34;Upgrade-Insecure-Requests&#34;: &#34;1&#34;,\n    &#34;User-Agent&#34;: &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&#34;,\n}\n\n\ndef get_cookie(url):\n    response = requests.get(url, headers=headers)\n    cookies = response.headers[&#39;Set-Cookie&#39;].split(&#39;;&#39;)\n    res_cookie = []\n    set_cookie = []\n    for cookie in cookies:\n        set_cookie.append(cookie.split(&#39;,&#39;))\n    for sets in set_cookie:\n        for set in sets:\n            if &#39;SNUID&#39; in set or &#39;SUID&#39; in set:\n                res_cookie.append(set)\n            else:\n                continue\n    print(res_cookie)\n    headers[&#39;Cookie&#39;] = &#39;;&#39;.join(res_cookie)\n    html = etree.HTML(response.text)\n    link_list = html.xpath(&#39;.//div[@class=&#34;txt-box&#34;]//a/@href&#39;)\n    get_suv(res_cookie[0])\n    headers_xq = {\n        &#34;Accept&#34;: &#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3&#34;,\n        &#34;Accept-Encoding&#34;: &#34;gzip, deflate, br&#34;,\n        &#34;Accept-Language&#34;: &#34;zh-CN,zh;q=0.9&#34;,\n        &#34;Cache-Control&#34;: &#34;no-cache&#34;,\n        &#34;Connection&#34;: &#34;keep-alive&#34;,\n        &#34;Host&#34;: &#34;mp.weixin.qq.com&#34;,\n        &#34;Pragma&#34;: &#34;no-cache&#34;,\n        &#34;Referer&#34;: query_url,\n        &#34;Upgrade-Insecure-Requests&#34;: &#34;1&#34;,\n        &#34;User-Agent&#34;: &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&#34;,\n    }\n    for link in link_list:\n        # print(link)\n        b = int(random.random() * 100) + 1\n        a = link.find(&#34;url=&#34;)\n        c = link.find(&#34;&amp;k=&#34;)\n        result_link = (link + &#34;&amp;k=&#34; + str(b) + &#34;&amp;h=&#34; + link[a + 4 + 26 + b: a + 4 + 26 + b + 1])\n        print(result_link)\n        resp = requests.get(url= &#34;https://weixin.sogou.com&#34; +result_link, headers=headers)\n        rel_url = re.findall(&#34;\\&#39;(\\S+?)\\&#39;;&#34;, resp.text, re.S)\n        rel_url = &#39;&#39;.join(rel_url)\n        xq_resp = requests.get(url=rel_url, headers=headers_xq)\n        html = etree.HTML(xq_resp.text)\n        title = html.xpath(&#34;normalize-space(.//div[@class=&#39;profile_info&#39;]//strong)&#34;)\n        print(&#39;put successful:{}&#39;.format(title))\n\n\ndef get_suv(snuid):\n    data = {\n        &#34;uigs_cl&#34;: &#34;first_click&#34;,\n        &#34;uigs_refer&#34;: &#34;&#34;,\n        &#34;uigs_t&#34;: str(int(round(time.time() * 1000))),\n        &#34;uigs_productid&#34;: &#34;vs_web&#34;,\n        &#34;terminal&#34;: &#34;web&#34;,\n        &#34;vstype&#34;: &#34;weixin&#34;,\n        &#34;pagetype&#34;: &#34;result&#34;,\n        &#34;channel&#34;: &#34;result_account&#34;,\n        &#34;s_from&#34;: &#34;&#34;,\n        &#34;sourceid&#34;: &#34;&#34;,\n        &#34;type&#34;: &#34;weixin_search_pc&#34;,\n        &#34;uigs_cookie&#34;: &#34;SUID%2Csct&#34;,\n        &#34;uuid&#34;: uuid.uuid1(),\n        &#34;query&#34;: seed,\n        &#34;weixintype&#34;: &#34;1&#34;,\n        &#34;exp_status&#34;: &#34;-1&#34;,\n        &#34;exp_id_list&#34;: &#34;0_0&#34;,\n        &#34;wuid&#34;: &#34;&#34;,\n        &#34;snuid&#34;: snuid.split(&#34;=&#34;)[-1],\n        &#34;rn&#34;: &#34;1&#34;,\n        &#34;login&#34;: &#34;0&#34;,\n        &#34;uphint&#34;: &#34;0&#34;,\n        &#34;bottomhint&#34;: &#34;0&#34;,\n        &#34;page&#34;: &#34;1&#34;,\n        &#34;exp_id&#34;: &#34;null_0-null_1-null_2-null_3-null_4-null_5-null_6-null_7-null_8-null_9&#34;,\n        &#34;time&#34;: &#34;20429&#34;,\n    }\n    suv_url = &#34;https://pb.sogou.com/pv.gif?&#34; + urlencode(data)\n\n    response = requests.get(suv_url)\n    print(response)\n    cookies = response.headers[&#39;Set-Cookie&#39;].split(&#39;;&#39;)\n    res_cookie = []\n    set_cookie = []\n    for cookie in cookies:\n        set_cookie.append(cookie.split(&#39;,&#39;))\n    for sets in set_cookie:\n        for set in sets:\n            if &#39;SUV&#39; in set:\n                res_cookie.append(set)\n            else:\n                continue\n    print(res_cookie)\n    headers[&#39;Cookie&#39;] = (headers[&#39;Cookie&#39;] + &#39;;&#39; + res_cookie[0]).strip()\n    return res_cookie[-1]</code></pre></div><p></p>", 
            "topic": [
                {
                    "tag": "python爬虫", 
                    "tagLink": "https://api.zhihu.com/topics/20086364"
                }, 
                {
                    "tag": "爬虫 (计算机网络)", 
                    "tagLink": "https://api.zhihu.com/topics/19577498"
                }, 
                {
                    "tag": "网页爬虫", 
                    "tagLink": "https://api.zhihu.com/topics/19794679"
                }
            ], 
            "comments": [
                {
                    "userName": "快银 SEO", 
                    "userLink": "https://www.zhihu.com/people/424f86a98a2339649765d0ed3e674dd4", 
                    "content": "建议采用selenium等工具抓取这种页面", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Cookie", 
                            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
                            "content": "<p>太慢了</p>", 
                            "likes": 0, 
                            "replyToAuthor": "快银 SEO"
                        }, 
                        {
                            "userName": "Hhhh丶", 
                            "userLink": "https://www.zhihu.com/people/44b73a22a2f4b8dc5b1f1847c0485745", 
                            "content": "<p>selenium 工具 现在抓也会检测到 换IP 都不行</p>", 
                            "likes": 1, 
                            "replyToAuthor": "快银 SEO"
                        }
                    ]
                }, 
                {
                    "userName": "hongming cao", 
                    "userLink": "https://www.zhihu.com/people/162d0a4b2d99ee3f5cb7ebb30ee49c5c", 
                    "content": "写的不错，给你点赞啦。反爬虫做的好，非常好。", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Cookie", 
                            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
                            "content": "<p>谢谢，之后在工作中遇到一些疑难爬虫，我也会放出来的</p>", 
                            "likes": 0, 
                            "replyToAuthor": "hongming cao"
                        }
                    ]
                }, 
                {
                    "userName": "549233836", 
                    "userLink": "https://www.zhihu.com/people/cf35f1d9f900aa2be56d9e33f4d8f87f", 
                    "content": "老哥  源码可以看一下吗。。。我现在看怎么看不懂呀。。。。", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "专注python的小白", 
                    "userLink": "https://www.zhihu.com/people/3d29e99db7d67f2d972f713101496065", 
                    "content": "<p>大佬请问你这个是什么时候的，我看的不是太懂，能不能讲详细点</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "SuGuoHu", 
                    "userLink": "https://www.zhihu.com/people/83269d5f9fab16c3aafdc28531813d53", 
                    "content": "大佬NB", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "DG哈哈", 
                    "userLink": "https://www.zhihu.com/people/fe5bf21c514e7882208e103bc2a7c550", 
                    "content": "<p>老哥，你是怎么通过a标签的监听事件找到$(\"a\").on(\"mousedown click contextmenu\", function() {</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "zengcity", 
                            "userLink": "https://www.zhihu.com/people/8c15d8c6472b5f9782e4db03c7794f36", 
                            "content": "<p>检查元素，底部点击”event listener“，然后查看点击时间，就能找到了。</p>", 
                            "likes": 1, 
                            "replyToAuthor": "DG哈哈"
                        }
                    ]
                }, 
                {
                    "userName": "DG哈哈", 
                    "userLink": "https://www.zhihu.com/people/fe5bf21c514e7882208e103bc2a7c550", 
                    "content": "<p>这个函数的呢</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "MaoDazhan", 
                    "userLink": "https://www.zhihu.com/people/27821a123ed4f9f1591c62418116d34b", 
                    "content": "谢谢嗷 最近在爬公众号", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "MaoDazhan", 
                    "userLink": "https://www.zhihu.com/people/27821a123ed4f9f1591c62418116d34b", 
                    "content": "搜狗好像又改版了", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "MaoDazhan", 
                    "userLink": "https://www.zhihu.com/people/27821a123ed4f9f1591c62418116d34b", 
                    "content": "为什么cookie只需要那两个参数呢 怎么分析的 可以解释下吗", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Cookie", 
                            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
                            "content": "这两个参数，是经过我测试多次后发现的，其中有一个参数隐藏的较深，之前没有写进去，之后我做一下更新", 
                            "likes": 0, 
                            "replyToAuthor": "MaoDazhan"
                        }, 
                        {
                            "userName": "MaoDazhan", 
                            "userLink": "https://www.zhihu.com/people/27821a123ed4f9f1591c62418116d34b", 
                            "content": "我python只获取到suid的值，suv的值获取不到，请问直接从破解签名signature的角度反爬，难度很大吗", 
                            "likes": 0, 
                            "replyToAuthor": "Cookie"
                        }
                    ]
                }, 
                {
                    "userName": "SD10", 
                    "userLink": "https://www.zhihu.com/people/1677ea14e84e1289126d3d0d097a94c3", 
                    "content": "<p>不需要用SUV，把两个参数拼接出来后，加上SNUID cookie 和 Referer(就是搜索URL)就可以了，当然还需要有 UA.</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Cookie", 
                            "userLink": "https://www.zhihu.com/people/4b8fe145566ce0bfbd22b7ffab9c4011", 
                            "content": "直接搜索文章是不需要的，搜索公众号是需要的", 
                            "likes": 0, 
                            "replyToAuthor": "SD10"
                        }, 
                        {
                            "userName": "SD10", 
                            "userLink": "https://www.zhihu.com/people/1677ea14e84e1289126d3d0d097a94c3", 
                            "content": "<p>昨天发现，我用任何浏览器任何IP，搜狗貌似不给十篇最新文章了，有遇到吗？</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Cookie"
                        }
                    ]
                }, 
                {
                    "userName": "恋之风景", 
                    "userLink": "https://www.zhihu.com/people/ee6ef536db987af28f1eb5f3984b32db", 
                    "content": "<p>能获取阅读数和在看人数吗？</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "zeroing", 
                    "userLink": "https://www.zhihu.com/people/eaff0af5b484b1e287cb447b0704afa9", 
                    "content": "<p>你好，请问cookie中的snuid参数怎么获取的，我用requests请求了你类似上面的那个query_url，但返回中的Set-Cookie中没有snuid这个参数</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "zeroing", 
                    "userLink": "https://www.zhihu.com/people/eaff0af5b484b1e287cb447b0704afa9", 
                    "content": "<p>好像这个思路已经爬不了了，解析出来url加上破解后的两个参数，用破解后的headers好像夜访问不了了。</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "zeroing", 
                    "userLink": "https://www.zhihu.com/people/eaff0af5b484b1e287cb447b0704afa9", 
                    "content": "<p>说错了，破解那两个参数时，改数字了，改成了[a + 4 + 21 + b: a + 4 + 21 + b + 1]，由26改成了21</p>", 
                    "likes": 2, 
                    "childComments": [
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>可以的老铁</p><a class=\"comment_sticker\" href=\"https://pic4.zhimg.com/v2-fa3cb6bc9ec57da84ab53a60f48d0c6f.gif\" data-width=\"\" data-height=\"\">[棒]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "zeroing"
                        }
                    ]
                }
            ]
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/c_1101070718854443008"
}

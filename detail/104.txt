{
    "title": "推荐算法那些事", 
    "description": "分享前沿推荐算法及工业界落地实施经验", 
    "followers": [
        "https://www.zhihu.com/people/yang-hai-juan-71", 
        "https://www.zhihu.com/people/gilbert-chen-42", 
        "https://www.zhihu.com/people/li-you-27-31", 
        "https://www.zhihu.com/people/yu-yang-53-93", 
        "https://www.zhihu.com/people/han-zhen-yu-99", 
        "https://www.zhihu.com/people/li-bai-95-38", 
        "https://www.zhihu.com/people/liu-ya-hui-1-18", 
        "https://www.zhihu.com/people/toby941", 
        "https://www.zhihu.com/people/linddw", 
        "https://www.zhihu.com/people/xu-zi-heng-88", 
        "https://www.zhihu.com/people/dolphin007", 
        "https://www.zhihu.com/people/samurai3701", 
        "https://www.zhihu.com/people/JerusalemC", 
        "https://www.zhihu.com/people/feng-wang-67", 
        "https://www.zhihu.com/people/luoyuxia-53", 
        "https://www.zhihu.com/people/corgi", 
        "https://www.zhihu.com/people/xing-feng-63-44", 
        "https://www.zhihu.com/people/fu-cong-15-11", 
        "https://www.zhihu.com/people/dai-dao", 
        "https://www.zhihu.com/people/hum-75", 
        "https://www.zhihu.com/people/dark-reunion", 
        "https://www.zhihu.com/people/shinysky", 
        "https://www.zhihu.com/people/chen-yi-85-30", 
        "https://www.zhihu.com/people/wu-ji-81", 
        "https://www.zhihu.com/people/eric-30", 
        "https://www.zhihu.com/people/shu-yu-mu-ge-31", 
        "https://www.zhihu.com/people/liu-liang-71-16-18", 
        "https://www.zhihu.com/people/xi-yu-13-36", 
        "https://www.zhihu.com/people/hei-dong-zhi-mi", 
        "https://www.zhihu.com/people/yan-yu-song-40", 
        "https://www.zhihu.com/people/liu-wei-ming-37-41", 
        "https://www.zhihu.com/people/mxjmmmm", 
        "https://www.zhihu.com/people/pinkant-82", 
        "https://www.zhihu.com/people/linkerlin", 
        "https://www.zhihu.com/people/zuo-lun-jiu-shi-wo", 
        "https://www.zhihu.com/people/edward-77-20", 
        "https://www.zhihu.com/people/zhao-yi-li-hua-bai", 
        "https://www.zhihu.com/people/zhao-liang-lsec", 
        "https://www.zhihu.com/people/lei-ming-76-1", 
        "https://www.zhihu.com/people/alahlll", 
        "https://www.zhihu.com/people/lilong007", 
        "https://www.zhihu.com/people/stevenyh", 
        "https://www.zhihu.com/people/wangcheny91", 
        "https://www.zhihu.com/people/long-hong-xing", 
        "https://www.zhihu.com/people/lance-van", 
        "https://www.zhihu.com/people/cutz", 
        "https://www.zhihu.com/people/wdw110", 
        "https://www.zhihu.com/people/soraescape", 
        "https://www.zhihu.com/people/wenjiaYang", 
        "https://www.zhihu.com/people/kyle-chen-15", 
        "https://www.zhihu.com/people/fuckingperfect", 
        "https://www.zhihu.com/people/zhang-dong-bin-60-85", 
        "https://www.zhihu.com/people/li-peng-41-64", 
        "https://www.zhihu.com/people/damon-data", 
        "https://www.zhihu.com/people/wei-jin-jie-32", 
        "https://www.zhihu.com/people/jiang-yun-chao-37", 
        "https://www.zhihu.com/people/good_ad_rd", 
        "https://www.zhihu.com/people/marsishere", 
        "https://www.zhihu.com/people/rg123", 
        "https://www.zhihu.com/people/wu-ye-45-74", 
        "https://www.zhihu.com/people/jifei", 
        "https://www.zhihu.com/people/shui-shou-xin-bo-da-49", 
        "https://www.zhihu.com/people/michaelcao-63", 
        "https://www.zhihu.com/people/wang-rui-ping-26-91", 
        "https://www.zhihu.com/people/wang-lao-ban-75-45", 
        "https://www.zhihu.com/people/obscure-39", 
        "https://www.zhihu.com/people/John-Titor-bak", 
        "https://www.zhihu.com/people/white-water", 
        "https://www.zhihu.com/people/shen-jing-jie-de-gu-du", 
        "https://www.zhihu.com/people/ju-shang-38", 
        "https://www.zhihu.com/people/lbnnewdm", 
        "https://www.zhihu.com/people/mass3711", 
        "https://www.zhihu.com/people/zhang-mou-61-11", 
        "https://www.zhihu.com/people/sq892246139", 
        "https://www.zhihu.com/people/jwzheng", 
        "https://www.zhihu.com/people/wei-zi-jing-60", 
        "https://www.zhihu.com/people/qin-gong-79", 
        "https://www.zhihu.com/people/gabbar-wang", 
        "https://www.zhihu.com/people/95079507", 
        "https://www.zhihu.com/people/sun-fu-wei", 
        "https://www.zhihu.com/people/dan-jia-wei-3", 
        "https://www.zhihu.com/people/zhang-liang-25-79", 
        "https://www.zhihu.com/people/5118.com", 
        "https://www.zhihu.com/people/panpingjun", 
        "https://www.zhihu.com/people/jxzheng95", 
        "https://www.zhihu.com/people/dufime-liu-9", 
        "https://www.zhihu.com/people/she-liang", 
        "https://www.zhihu.com/people/wang-lang-96-64", 
        "https://www.zhihu.com/people/fu-liang-liang", 
        "https://www.zhihu.com/people/raymond-40-48", 
        "https://www.zhihu.com/people/4recommend", 
        "https://www.zhihu.com/people/sj-newbee", 
        "https://www.zhihu.com/people/wang-yan-kai-21", 
        "https://www.zhihu.com/people/niceworld-49-6", 
        "https://www.zhihu.com/people/su-xiao-run", 
        "https://www.zhihu.com/people/shen-chu-duo-mao-mao", 
        "https://www.zhihu.com/people/liu-fei-94-95", 
        "https://www.zhihu.com/people/yy-cc-63-54", 
        "https://www.zhihu.com/people/ni-wei-tai-yang", 
        "https://www.zhihu.com/people/dearest-16", 
        "https://www.zhihu.com/people/song-yi-73-94", 
        "https://www.zhihu.com/people/boney-62", 
        "https://www.zhihu.com/people/hlhl", 
        "https://www.zhihu.com/people/sui-yue-shen-tou-123", 
        "https://www.zhihu.com/people/babylls", 
        "https://www.zhihu.com/people/an-ran-57", 
        "https://www.zhihu.com/people/zhang-sheng-chao-37", 
        "https://www.zhihu.com/people/inextime", 
        "https://www.zhihu.com/people/worhol", 
        "https://www.zhihu.com/people/mattzheng7", 
        "https://www.zhihu.com/people/yu-le-le-83-97", 
        "https://www.zhihu.com/people/zhi-mu-8", 
        "https://www.zhihu.com/people/chun-nuan-hua-kai-34-71", 
        "https://www.zhihu.com/people/mr-lin-82-68", 
        "https://www.zhihu.com/people/yu-shun-zhe", 
        "https://www.zhihu.com/people/rui-32-59-9", 
        "https://www.zhihu.com/people/zhang-xue-ren-20", 
        "https://www.zhihu.com/people/ji-xiao-hei-40", 
        "https://www.zhihu.com/people/xu-yan-gen-99", 
        "https://www.zhihu.com/people/wang-can-jie-95", 
        "https://www.zhihu.com/people/wu-xiao-bai-92", 
        "https://www.zhihu.com/people/ezail-shen", 
        "https://www.zhihu.com/people/pray-90-47", 
        "https://www.zhihu.com/people/wht-buaa", 
        "https://www.zhihu.com/people/xiang578", 
        "https://www.zhihu.com/people/wan-yong-tao", 
        "https://www.zhihu.com/people/xiao-yu-22-71-20", 
        "https://www.zhihu.com/people/da-er-63-97", 
        "https://www.zhihu.com/people/cang-hai-yue-ming-34-7", 
        "https://www.zhihu.com/people/yang-zhi-gang-70-1", 
        "https://www.zhihu.com/people/clcron", 
        "https://www.zhihu.com/people/wang-he-yu-1", 
        "https://www.zhihu.com/people/fang-albert", 
        "https://www.zhihu.com/people/xiaowei-ling", 
        "https://www.zhihu.com/people/feng-gou-52-6", 
        "https://www.zhihu.com/people/xiyao-lin", 
        "https://www.zhihu.com/people/ni-hui-51-23", 
        "https://www.zhihu.com/people/xia-chen-feng", 
        "https://www.zhihu.com/people/yan-ya-chen", 
        "https://www.zhihu.com/people/hai-shui-dao-liu", 
        "https://www.zhihu.com/people/yang-xu-dong-6"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/76570628", 
            "userName": "田峻钢", 
            "userLink": "https://www.zhihu.com/people/8d52d1911243765b9be935b07a76921d", 
            "upvote": 100, 
            "title": "阿里推荐算法（BST）: 将Transformer用于淘宝电商推荐", 
            "content": "<div class=\"highlight\"><pre><code class=\"language-text\">导读：本文为分享深度学习在阿里推荐系统中的应用系列第二篇，上一篇我们分享了MIND 基于动态路由的\n多兴趣网络在用户行为多样兴趣上的表达，本篇持续为大家介绍阿里在深度学习方面的最新进展：首次应用\nTransformer 结构用于捕获用户长历史行为序列中的信号，效果优于谷歌的WDL和深度兴趣网络（DIN）算法。</code></pre></div><h2><b>一、背景：</b></h2><p>    深度学习的方法已经广泛应用于工业推荐系统中（Recommender Systems），主要是受益于深度学习强大的表达能力，能够对原始特征如user id、item id、behavior sequences 等特征进行有效处理,  特别是Attention 机制用于提取用户历史行为序列信号，能更好的表达用户多峰兴趣。而传统处理方法通常是通过embedding 技术将原始ID 类特征映射到低维空间中，然后再输入到MLP 网络中，如WDL、DeepFM、DCN 等模型都满足这一范式。</p><p>    在深度兴趣网络（DIN）模型中，通过引入Attention 机制计算用户历史行为序列与当前Item 的相关程度，来刻画用户多样的兴趣分布。但是仅考虑了行为之间的相关性，没有考虑用户历史行为序列的前后顺序。比如，用户是否点击连衣裙，受近期连衣裙相关商品的行为影响较大，而半个月用户买过鞋子影响就微弱了。受Transformer在自然语言处理中取得巨大的效果启发，本文将应用Transformer 用于提取用户行为序列背后的隐藏信息，同时考虑序列的前后顺序，能够更好的表达用户兴趣。</p><h2><b>二、模型结构：</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-bd8d1c16cc08c7c455aa3805646c8cd5_b.jpg\" data-size=\"normal\" data-rawwidth=\"1646\" data-rawheight=\"994\" class=\"origin_image zh-lightbox-thumb\" width=\"1646\" data-original=\"https://pic2.zhimg.com/v2-bd8d1c16cc08c7c455aa3805646c8cd5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1646&#39; height=&#39;994&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1646\" data-rawheight=\"994\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1646\" data-original=\"https://pic2.zhimg.com/v2-bd8d1c16cc08c7c455aa3805646c8cd5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-bd8d1c16cc08c7c455aa3805646c8cd5_b.jpg\"/><figcaption>Behavior Sequence Transformer Model</figcaption></figure><p>Behavior Sequence Transformer Model (BST) 输入层与其他网络类似，主要输入特征有Item Feature、用户画像、上下文特征、交叉特征经过Embedding 层后concat 在一起。用户行为序列包含Item ID类特征及对应的position 信息，进行Embedding 处理后输入到Transformer 层捕获用户历史行为与Target Item 之间的相互关系得到用户行为兴趣表达，与其他特征embedding 向量concat 在一起，经过三层MLP层计算得到预测的点击率。下面分别介绍每个模块：</p><p><b>2.1  Embedding Layer:</b></p><p>第一层输入为embedding 层，用于对各个高维稀疏的ID类这个映射到的低维embedding空间中，获得固定维度 embedding vector，主要有用户特征、商品特征、上下文特征、交叉特征：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-786dbf554812976c3c00e7988cbc8537_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1108\" data-rawheight=\"316\" class=\"origin_image zh-lightbox-thumb\" width=\"1108\" data-original=\"https://pic4.zhimg.com/v2-786dbf554812976c3c00e7988cbc8537_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1108&#39; height=&#39;316&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1108\" data-rawheight=\"316\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1108\" data-original=\"https://pic4.zhimg.com/v2-786dbf554812976c3c00e7988cbc8537_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-786dbf554812976c3c00e7988cbc8537_b.jpg\"/></figure><p><b>Positional embedding:  </b>DIN 模型中没有考虑用户行为序列的前后顺序，本文借鉴《Attention is all you need》中提出的Positional Encoding 思想，通过序列portion embedding 来捕获句子中的顺序信息。第i个位置的位置特征计算方式为pos(vi)=t(vt)-t(vi)，其中，t(vt) 表示推荐的时间戳，t(vi) 表示用户点击商品vi时的时间戳。</p><p><b>2.2  Transformer Layer:</b></p><p>    简单介绍Transformer结构，Transformer 是基于Attention 机制的经典Encoder-Decoder框架。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d16b4e806acec94ac81c726844ec826b_b.jpg\" data-size=\"normal\" data-rawwidth=\"545\" data-rawheight=\"731\" class=\"origin_image zh-lightbox-thumb\" width=\"545\" data-original=\"https://pic4.zhimg.com/v2-d16b4e806acec94ac81c726844ec826b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;545&#39; height=&#39;731&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"545\" data-rawheight=\"731\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"545\" data-original=\"https://pic4.zhimg.com/v2-d16b4e806acec94ac81c726844ec826b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-d16b4e806acec94ac81c726844ec826b_b.jpg\"/><figcaption>Transformer 架构</figcaption></figure><p>本文主要使用Transformer 的Encoder 部分用来捕获Target Item 与用户行为序列中Item 的相关关系：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2e052ccd0e25186797fb62ae56a40c99_b.jpg\" data-size=\"normal\" data-rawwidth=\"350\" data-rawheight=\"452\" class=\"content_image\" width=\"350\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;350&#39; height=&#39;452&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"350\" data-rawheight=\"452\" class=\"content_image lazy\" width=\"350\" data-actualsrc=\"https://pic2.zhimg.com/v2-2e052ccd0e25186797fb62ae56a40c99_b.jpg\"/><figcaption>Transformer Encoder</figcaption></figure><p>经典Transformer Encoder 部分主要由6个相同的层组成，每层包含如下两部分：</p><ul><li>Multi-Head Attention 多头注意力层</li><li>Feed Forward 全连接层</li></ul><p>以上两部分都包含Residual Connection残差连接、Add&amp;Norm数据归一化。</p><p><b>Attention layer：  </b>使用 Multi-Head Attention 是self-attention 的一种实现，对应输入的Q,k,V 均是相同Item ID Embedding + Positional Embedding:</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-408b612c1a7b9aa23a4c3c318e318e2b_b.jpg\" data-size=\"normal\" data-rawwidth=\"653\" data-rawheight=\"346\" class=\"origin_image zh-lightbox-thumb\" width=\"653\" data-original=\"https://pic4.zhimg.com/v2-408b612c1a7b9aa23a4c3c318e318e2b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;653&#39; height=&#39;346&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"653\" data-rawheight=\"346\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"653\" data-original=\"https://pic4.zhimg.com/v2-408b612c1a7b9aa23a4c3c318e318e2b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-408b612c1a7b9aa23a4c3c318e318e2b_b.jpg\"/><figcaption>Multi-Head Attention</figcaption></figure><p><img src=\"https://www.zhihu.com/equation?tex=Attention%28Q%2CK%2CV%29+%3D+softnmax%28%5Cfrac%7BQK%5ET%7D%7B%5Csqrt%7Bd%7D%7D%29V+%5C%5C+S+%3D+MH%28E%29+%3D+Concat%28head_1%2Chead_2%2C...%2Chead_h%29W%5EH+%5C%5C+head_i+%3D+Attention%28EW%5EQ%2CEW%5EK%2CEW%5EV%29\" alt=\"Attention(Q,K,V) = softnmax(\\frac{QK^T}{\\sqrt{d}})V \\\\ S = MH(E) = Concat(head_1,head_2,...,head_h)W^H \\\\ head_i = Attention(EW^Q,EW^K,EW^V)\" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=W%5EQ%2CW%5EK%2CW%5EV\" alt=\"W^Q,W^K,W^V\" eeimg=\"1\"/> 为 <img src=\"https://www.zhihu.com/equation?tex=Q%2CK%2CV\" alt=\"Q,K,V\" eeimg=\"1\"/> 对应的参数矩阵， <img src=\"https://www.zhihu.com/equation?tex=E\" alt=\"E\" eeimg=\"1\"/> 为输入行为序列中每个Item 的embedding 向量。</p><p><b>Point-wise Feed-Forward Networks：</b>这里主要使用 point-wise Feed-Forward Networks (FFN) 网络来增强模型的非线性能力： </p><p><img src=\"https://www.zhihu.com/equation?tex=F+%3D+F+FN%28S%29\" alt=\"F = F FN(S)\" eeimg=\"1\"/> </p><p>在工业界应用中，训练语料都是大规模上亿级数据，为了避免过拟合这里使用dropout 和LeakyReLU作为激活函数：</p><p><img src=\"https://www.zhihu.com/equation?tex=S%E2%80%B2+%3DLayerNorm%28S+%2B+Dropout%28MH%28S%29%29++%5C%5C+F+%3DLayerNorm%28S%E2%80%B2+%2B+Dropout%28LeakyReLU%28S%E2%80%B2W%5E%7B%281%29%7D+%2B+b%5E%7B%281%29%7D%29W%5E%7B%282%29%7D+%2B+b%5E%7B%282%29%7D%29+\" alt=\"S′ =LayerNorm(S + Dropout(MH(S))  \\\\ F =LayerNorm(S′ + Dropout(LeakyReLU(S′W^{(1)} + b^{(1)})W^{(2)} + b^{(2)}) \" eeimg=\"1\"/> </p><p>W，b 为可学习的参数，LayerNorm 为标准的数据归一化层。</p><p><b>Stacking the self-attention blocks： </b>上述结构为完整的Transformer Encoder Layer，为了能够更有效的学习到用户行为序列背后隐藏的partten，对模型进行堆叠：</p><p><img src=\"https://www.zhihu.com/equation?tex=S%5Eb+%3DSA%28F%5E%7B%28b%E2%88%921%29%7D%29+%5C%5C+F%5Eb+%3DF+FN%28S%5Eb+%29++\" alt=\"S^b =SA(F^{(b−1)}) \\\\ F^b =F FN(S^b )  \" eeimg=\"1\"/> </p><p>b 为Transformer 堆叠的层数。在实验数据集上表明，当b=1 时离线评估AUC 效果最优。</p><p><b>2.3  MLP Layer:</b></p><p>经过Transformer 处理后，我们得到基于用户行为序列提取到用户兴趣表达向量，将其与其他Feature Embedding 向量concat 一起后，经过sigmoid 函数处理得到我们的预估点击率。</p><p>这里主要使用交叉熵作为我们的损失函数：</p><p><img src=\"https://www.zhihu.com/equation?tex=L+%3D+-+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7B%28x%2Cy+%5Cin+D%29%7D%28ylogp%28x%29%2B%281-y%29log%281-p%28x%29%29\" alt=\"L = - \\frac{1}{N}\\sum_{(x,y \\in D)}(ylogp(x)+(1-y)log(1-p(x))\" eeimg=\"1\"/> </p><h2>三、实验结果：</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7fbe4af1f963889cc69f25faa51066a7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"603\" data-rawheight=\"291\" class=\"origin_image zh-lightbox-thumb\" width=\"603\" data-original=\"https://pic4.zhimg.com/v2-7fbe4af1f963889cc69f25faa51066a7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;603&#39; height=&#39;291&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"603\" data-rawheight=\"291\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"603\" data-original=\"https://pic4.zhimg.com/v2-7fbe4af1f963889cc69f25faa51066a7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-7fbe4af1f963889cc69f25faa51066a7_b.jpg\"/></figure><p></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "推荐算法", 
                    "tagLink": "https://api.zhihu.com/topics/19580544"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "Transformer", 
                    "tagLink": "https://api.zhihu.com/topics/20746363"
                }
            ], 
            "comments": [
                {
                    "userName": "yone", 
                    "userLink": "https://www.zhihu.com/people/6c1f7c9d57a6cefb6f2f48749fbcbe66", 
                    "content": "有论文吗？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "田峻钢", 
                            "userLink": "https://www.zhihu.com/people/8d52d1911243765b9be935b07a76921d", 
                            "content": "<p>这篇是阿里19年最新发布的paper，地址 <a href=\"http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1905.06874%3Fcontext%3Dcs.AI\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">arxiv.org/abs/1905.0687</span><span class=\"invisible\">4?context=cs.AI</span><span class=\"ellipsis\"></span></a></p>", 
                            "likes": 2, 
                            "replyToAuthor": "yone"
                        }, 
                        {
                            "userName": "yone", 
                            "userLink": "https://www.zhihu.com/people/6c1f7c9d57a6cefb6f2f48749fbcbe66", 
                            "content": "感谢感谢", 
                            "likes": 0, 
                            "replyToAuthor": "田峻钢"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "自动化推荐，销售？", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/76495890", 
            "userName": "田峻钢", 
            "userLink": "https://www.zhihu.com/people/8d52d1911243765b9be935b07a76921d", 
            "upvote": 9, 
            "title": "阿里推荐算法（MIND）：基于动态路由的用户多兴趣网络", 
            "content": "<h2>一、背景：</h2><p>    工业界推荐系统通常有两个阶段组成：召回（Matching）和排序(Ranking)。召回阶段我们根据用户的兴趣从海量的商品中去检索出相关候选 Item，满足推荐相关性和多样性需求。而排序阶段，依据用户兴趣会对候选集进行打分排序截取TopN Item，最终给用户产生推荐。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-33872224e0e498b79462431775d32e75_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"914\" data-rawheight=\"360\" class=\"origin_image zh-lightbox-thumb\" width=\"914\" data-original=\"https://pic2.zhimg.com/v2-33872224e0e498b79462431775d32e75_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;914&#39; height=&#39;360&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"914\" data-rawheight=\"360\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"914\" data-original=\"https://pic2.zhimg.com/v2-33872224e0e498b79462431775d32e75_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-33872224e0e498b79462431775d32e75_b.jpg\"/></figure><p>     因此，在推荐过程最重要的一环就是如何对用户不同阶段的兴趣进行有效表达。大多数目前的深度网络模型中，都是构建一个用户和Item 统一的向量空间中去获取用户的兴趣表达。如 DIN 模型 (Deep Interest Network)：通过挖掘用户的历史行为，利用Attention 机制捕获用户兴趣分布，表达用户多种多样的兴趣爱好。这类模型都是将用户映射为单个向量以表达用户兴趣，通常不足以捕获用户不同阶段、不同性质的兴趣分布。</p><p><b>本文主要工作：</b></p><ul><li>通过Mulit-Interest Extractor Layer 获取多个向量表达用户兴趣的不同方面；</li><li>提出了具有动态路由的多兴趣网络（MIND），利用Dynamic Routing 以自适应地聚合用户历史行为到用户表达向量中，以处理用户的不同兴趣；</li><li>开发 Label-Aware Attention 标签感知注意力机制，以帮助学习具有多个向量的用户表示。</li></ul><p> 具体而言，我们设计了一种基于胶囊路径机制的多兴趣提取层，适用于聚类历史行为，提取不同的兴趣。</p><h2>二、网络结构：</h2><p>    Multi-Interest Network with Dynamic Routing (MIND) 是通过构建用户和商品向量在统一的向量空间的多个用户兴趣向量，以表达用户多样的兴趣分布。然后通过向量召回技术，利用这多个兴趣向量去检索出TopK个与其近邻的商品向量，得到 TopK个 用户感兴趣的商品。</p><p>    传统 DeepMatch 方法为每个用户生成一个兴趣向量，但在实际的购物场景中，用户的兴趣是多样的，不同兴趣之间甚至可能是不相关的。比如用户可能同时期望购买服装、化妆品、零食，而一个长度有限的向量很难表示用户这样的多个兴趣。我们的 MIND 模型通过 Dynamic Routing 的方法从用户行为和用户属性信息中动态学习出多个表示用户兴趣的向量，更好的捕捉用户的多样兴趣，来提升召回的丰富度和准确度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-aca25a22415fd5c5cdcc75c771e9ffc8_b.jpg\" data-size=\"normal\" data-rawwidth=\"1836\" data-rawheight=\"890\" class=\"origin_image zh-lightbox-thumb\" width=\"1836\" data-original=\"https://pic1.zhimg.com/v2-aca25a22415fd5c5cdcc75c771e9ffc8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1836&#39; height=&#39;890&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1836\" data-rawheight=\"890\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1836\" data-original=\"https://pic1.zhimg.com/v2-aca25a22415fd5c5cdcc75c771e9ffc8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-aca25a22415fd5c5cdcc75c771e9ffc8_b.jpg\"/><figcaption>MIND</figcaption></figure><p><b> 1.  目标函数：</b></p><p>推荐系统召回阶段主要目标是从亿级规模的海量商品中获取与用户兴趣相关的候选集Item，用三元组 <img src=\"https://www.zhihu.com/equation?tex=%EF%BC%88I_u%2CP_u%2CF_i%EF%BC%89\" alt=\"（I_u,P_u,F_i）\" eeimg=\"1\"/> 表示user-item 实例，其中 <img src=\"https://www.zhihu.com/equation?tex=I_u\" alt=\"I_u\" eeimg=\"1\"/> 为用户对Item 产生行为序列集合， <img src=\"https://www.zhihu.com/equation?tex=P_u\" alt=\"P_u\" eeimg=\"1\"/> 为用户基本属性（如性别、年龄、）， <img src=\"https://www.zhihu.com/equation?tex=F_i\" alt=\"F_i\" eeimg=\"1\"/> 为目标Item 的基本属性（如itemid<i>, category_</i>id）. MIND 主要任务就是学习一个函数可以将user-item 实例映射为用户的向量表达：</p><p><img src=\"https://www.zhihu.com/equation?tex=V_u+%3D+f_%7Buser%7D%28I_u%2CP_u%29\" alt=\"V_u = f_{user}(I_u,P_u)\" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=V_u+%3D+%28%5Cbar%7Bv%7D%5E1_u%2C%5Cbar%7Bv%7D%5E2_u%2C...%2C%5Cbar%7Bv%7D%5EK_u%29\" alt=\"V_u = (\\bar{v}^1_u,\\bar{v}^2_u,...,\\bar{v}^K_u)\" eeimg=\"1\"/> , <img src=\"https://www.zhihu.com/equation?tex=V_u\" alt=\"V_u\" eeimg=\"1\"/> 即为用户多兴趣的向量表达，其中K 表示用户K 个兴趣向量。</p><p>同样，目标Item 的向量表达可以表示为：</p><p><img src=\"https://www.zhihu.com/equation?tex=e_i+%3D+f_%7Bitem%7D%28F_i%29\" alt=\"e_i = f_{item}(F_i)\" eeimg=\"1\"/> </p><p>当我们学习到用户和Item 的向量表达后，TopN 候选Item 可以通过dot-product 计算得出：</p><p><img src=\"https://www.zhihu.com/equation?tex=f_score+%28V_u%2C+e_i%29+%3D+max_%7B1%5Cleq+k+%5Cleq+K%7D+e_%7Bi%7D%5E%7BT%7Dv_%7Bu%7D%5E%7Bk%7D\" alt=\"f_score (V_u, e_i) = max_{1\\leq k \\leq K} e_{i}^{T}v_{u}^{k}\" eeimg=\"1\"/> </p><p><b>   2. Embedding &amp; Pooling Layer</b></p><p> MIND 的输入由三部分组成：用户属性 <img src=\"https://www.zhihu.com/equation?tex=P_u\" alt=\"P_u\" eeimg=\"1\"/> 、用户行为序列 <img src=\"https://www.zhihu.com/equation?tex=I_u\" alt=\"I_u\" eeimg=\"1\"/> 、和目标 Item <img src=\"https://www.zhihu.com/equation?tex=F_i\" alt=\"F_i\" eeimg=\"1\"/> 。每组输入都包含了极其稀疏的离散id 类特征，如item id 可能高达10亿维。因此我们采用广泛使用的embeding 技术将这些id特征映射为低维稠密的向量，从而可以显著减少了参数的数量和简化学习过程。对于user id 如年龄、性别等embedding 后通过concat 后作为用户侧特征输入，item id 如类目id、店铺id embedding 后统一经过pooling 层得到item 侧特征输入，而多个item embedding&amp;pooling 后，得到用户行为序列输入 <img src=\"https://www.zhihu.com/equation?tex=E_u+%3D+%5Cleft%5C%7B+e_i%2C+j%5Cin+I_u+%5Cright%5C%7D\" alt=\"E_u = \\left\\{ e_i, j\\in I_u \\right\\}\" eeimg=\"1\"/> 。</p><p><b>3. Multi-Interest Extractor Layer</b></p><p>如果把与用户兴趣各种相关的信息都压缩成为一个表达向量，这会成为用户多样兴趣表达的瓶颈，在推荐召回阶段召回候选集时，对用户不同兴趣的所有信息混合在一起使用，会导致召回Item 的相关性大大降低。因此，我们采用多个向量来表达用户不同的兴趣，将用户的历史行为分组到多个 interest capsules 的过程,  期望属于同一个capsules 的相关Item 共同表达用户兴趣的一个特定方面。</p><p><b> 3.1 Dynamic Routing Revist. </b> </p><p>简单介绍下Capsule，类似传统神经元，其活动向量（activity vector）表示特定实体类型的实例化参数，如对象或对象部分。我们使用活动向量的长度表征实体存在的概率，向量方向表示实例化参数。同一水平的活跃 Capsule 通过变换矩阵对更高级别的 capsule 的实例化参数进行预测。</p><p>     假设我们有两层Capsule，我们从第一层和第二层引用 Capsule分别为低级Capsule和高级Capsule。动态路由(Dynamic Routing) 的目标是在迭代中给出低级别Capsule的值来计算高级别Capsule的值方法。在每轮迭代中，给定一个低阶Capsule 向量 <img src=\"https://www.zhihu.com/equation?tex=c%5El_j+%5Cin+R%5E%7BN_l+%5Ctimes1%7D%2Ci%5Cin%5Cleft%5C%7B+1%2C...%2Cm+%5Cright%5C%7D\" alt=\"c^l_j \\in R^{N_l \\times1},i\\in\\left\\{ 1,...,m \\right\\}\" eeimg=\"1\"/>  和高阶 <img src=\"https://www.zhihu.com/equation?tex=c%5Eh_j+%3D+%5Cin+R%5E%7BN_h%5Ctimes1%7D%2Cj%5Cin%5Cleft%5C%7B+1%2C...%2Cn+%5Cright%5C%7D\" alt=\"c^h_j = \\in R^{N_h\\times1},j\\in\\left\\{ 1,...,n \\right\\}\" eeimg=\"1\"/>.  路由 logit 可以表示为：</p><p><img src=\"https://www.zhihu.com/equation?tex=b_%7Bij%7D+%3D+%28c%5Eh_j%29%5ETS_%7Bij%7Dc%5El_i\" alt=\"b_{ij} = (c^h_j)^TS_{ij}c^l_i\" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=S_%7Bij%7D+\" alt=\"S_{ij} \" eeimg=\"1\"/>  为可被学习参数矩阵。高阶Capsule 候选输出向量为：</p><p><img src=\"https://www.zhihu.com/equation?tex=z_j+%3D+%5Csum_%7BI%3D1%7D%5E%7Bm%7D%7Bw_%7BijS_%7Bij%7Dc%5El_i%7D%7D\" alt=\"z_j = \\sum_{I=1}^{m}{w_{ijS_{ij}c^l_i}}\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=w_%7Bij%7D\" alt=\"w_{ij}\" eeimg=\"1\"/> 为低阶Capsule 连接高阶Capsule 的权重向量，通过sofmax 计算得到：</p><p><img src=\"https://www.zhihu.com/equation?tex=w_%7Bij%7D+%3D+%5Cfrac%7Bexp%28b_%7Bij%7D%29%7D%7B%5Csum_%7Bk%3D1%7D%5E%7Bm%7D%7Bexp%28b_%7Bik%7D%29%7D%7D\" alt=\"w_{ij} = \\frac{exp(b_{ij})}{\\sum_{k=1}^{m}{exp(b_{ik})}}\" eeimg=\"1\"/> </p><p>最终高阶Capsule 输出向量：</p><p><img src=\"https://www.zhihu.com/equation?tex=c%5Eh_j+%3D+squash%28z%5Eh_j%29+%3D+%5Cfrac%7B%7C%7Cz%5Eh_j%7C%7C%5E2%7D%7B1%2B%7C%7Cz%5Eh_j%7C%7C%5E2%7D%5Cfrac%7Bz%5Eh_j%7D%7B%7C%7Cz%5Eh_j%7C%7C%7D\" alt=\"c^h_j = squash(z^h_j) = \\frac{||z^h_j||^2}{1+||z^h_j||^2}\\frac{z^h_j}{||z^h_j||}\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=b_%7Bij%7D\" alt=\"b_{ij}\" eeimg=\"1\"/> 通常初始值为0，通过三次重复路由过程，即输出 <img src=\"https://www.zhihu.com/equation?tex=c%5Eh_j\" alt=\"c^h_j\" eeimg=\"1\"/> 作为下一层的输入。</p><p><b>3.2 B2I Dynamic Routing. </b></p><p>我们主要通过使用Behavior-to Interest（B2I）动态路由来自适应地聚合用户行为到兴趣表示向量：</p><ul><li>共享参数矩阵:  <img src=\"https://www.zhihu.com/equation?tex=b_%7Bij%7D+%3D+u%5ET_jSe_i\" alt=\"b_{ij} = u^T_jSe_i\" eeimg=\"1\"/> </li><li>随机初始路由单元；</li><li>动态调整兴趣数量： <img src=\"https://www.zhihu.com/equation?tex=K%5E%7B%27%7D_u+%3D+max%281%2Cmin%28K%2Clog_2%28%7CI_u%7C%29%29\" alt=\"K^{&#39;}_u = max(1,min(K,log_2(|I_u|))\" eeimg=\"1\"/> </li></ul><p>动态路由详细过程：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-aed5c6ca0a53d57f70e80aacd54710aa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1188\" data-rawheight=\"974\" class=\"origin_image zh-lightbox-thumb\" width=\"1188\" data-original=\"https://pic3.zhimg.com/v2-aed5c6ca0a53d57f70e80aacd54710aa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1188&#39; height=&#39;974&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1188\" data-rawheight=\"974\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1188\" data-original=\"https://pic3.zhimg.com/v2-aed5c6ca0a53d57f70e80aacd54710aa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-aed5c6ca0a53d57f70e80aacd54710aa_b.jpg\"/></figure><p><b>    4. Label-aware Attention Layer.</b></p><p>通过多兴趣提取器层，对用户行为序列embedding 我们得到多个个兴趣Capsule 表达用户多样的兴趣分布，不同的兴趣Capsule表示用户兴趣的不同偏好。为了评估多个兴趣Capsule对目标Item 相关度及贡献度，我们设计标签意识的Attention 机制来衡量目标Item 选择使用哪个兴趣Capsule：</p><p><img src=\"https://www.zhihu.com/equation?tex=v_u+%3D+Attention%28e_i%2CV_u%2CV_u%29+%3D+V_usofmax%28pow%28V%5Et_ue_i%2Cp%29%29+++++++\" alt=\"v_u = Attention(e_i,V_u,V_u) = V_usofmax(pow(V^t_ue_i,p))       \" eeimg=\"1\"/> </p><h2><b>三、 损失函数：</b></h2><p>使交叉熵作为MIND 训练的损失函数：</p><p><img src=\"https://www.zhihu.com/equation?tex=L+%3D+%5Csum_%7B%28u%2Ci%29%5Cin+D%7D%7BlogPr%28i%7Cu%29%7D\" alt=\"L = \\sum_{(u,i)\\in D}{logPr(i|u)}\" eeimg=\"1\"/> </p><p>我们通过softmax 计算用户偏好Item 的概率:</p><p><img src=\"https://www.zhihu.com/equation?tex=Pr%28i%7Cu%29+%3D+Pr%28e_i%7Cv_u%29+%3D++%5Cfrac%7Bexp%28v%5Et_ue_i%29%7D%7B%5Csum_%7Bj%5Cin+I%7D%7Bexp%28v_ue_j%29%7D%7D\" alt=\"Pr(i|u) = Pr(e_i|v_u) =  \\frac{exp(v^t_ue_i)}{\\sum_{j\\in I}{exp(v_ue_j)}}\" eeimg=\"1\"/> </p><p>公开数据集评测结果：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-6055dcfa8a7564cc4bda28255a016bac_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2348\" data-rawheight=\"470\" class=\"origin_image zh-lightbox-thumb\" width=\"2348\" data-original=\"https://pic1.zhimg.com/v2-6055dcfa8a7564cc4bda28255a016bac_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2348&#39; height=&#39;470&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2348\" data-rawheight=\"470\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2348\" data-original=\"https://pic1.zhimg.com/v2-6055dcfa8a7564cc4bda28255a016bac_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-6055dcfa8a7564cc4bda28255a016bac_b.jpg\"/></figure><p>在线CTR 评估效果：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a682e43e5e428acbb81b22f34fc4c843_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1174\" data-rawheight=\"692\" class=\"origin_image zh-lightbox-thumb\" width=\"1174\" data-original=\"https://pic4.zhimg.com/v2-a682e43e5e428acbb81b22f34fc4c843_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1174&#39; height=&#39;692&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1174\" data-rawheight=\"692\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1174\" data-original=\"https://pic4.zhimg.com/v2-a682e43e5e428acbb81b22f34fc4c843_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a682e43e5e428acbb81b22f34fc4c843_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>论文地址：<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1904.08030v1\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Multi-Interest Network with Dynamic Routing for Recommendation at Tmall</a></p><p>《参考资料》：</p><ol><li><a href=\"https://link.zhihu.com/?target=https%3A//yq.aliyun.com/articles/704401%3Futm_content%3Dg_1000060605\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">当你打开天猫的那一刻，推荐系统做了哪些工作？-云栖社区-阿里云</a></li><li> Deep Interest Network for Click-Through Rate Prediction</li></ol>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "Attention-based Model", 
                    "tagLink": "https://api.zhihu.com/topics/20184445"
                }, 
                {
                    "tag": "用户兴趣", 
                    "tagLink": "https://api.zhihu.com/topics/19593760"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/48436359", 
            "userName": "田峻钢", 
            "userLink": "https://www.zhihu.com/people/8d52d1911243765b9be935b07a76921d", 
            "upvote": 0, 
            "title": "Keras API: 便捷、高效的深度学习高级API", 
            "content": "<p></p><h2>Keras API</h2><p> Keras是一个用于构建和训练深度学习模型的高级API。它能够快速设计、产出训练模型，具有三个主要优势：<br/> - 便捷性 - 模块化 - 可扩展性</p><p> Keras API 和TFlearn API 用法基本相似，对于tensorflow 的模型定义，损失函数，训练过程等进行了封装。封装后的整个数据集训练过程包括，数据处理，模型定义和模型训练三个部分。  </p><h2>构建模型</h2><h2>Sequential model</h2><p> 在 Keras 中，你可以通过组装layer 层来快速构建网络模型，最常见的是通过 tf.keras.models.Sequential 来快速构建模型：</p><div class=\"highlight\"><pre><code class=\"language-text\">model = tf.keras.Sequential()\n# 增加Dense 网络，64个节点，使用relu作为激活函数\nmodel.add(layers.Dense(64, activation=&#39;relu&#39;))\n# \nmodel.add(layers.Dense(32, activation=&#39;relu&#39;))\n# 增加 softmax layer 作为输出层\nmodel.add(layers.Dense(16, activation=&#39;softmax&#39;))</code></pre></div><h2>配置网络结构</h2><p>  tf.keras.layers  还提供了一些常见的结构化参数： - activation： 激活函数，如relu,sigmoid,softmax,tanh等，默认不使用激活函数； - estimator：优化器； - kernel_regularizer：正则化；</p><p>  以下代码使用常见参数：</p><div class=\"highlight\"><pre><code class=\"language-text\"># 创建sigmoid 为激活函数的隐层\nlayers.Dense(64, activation=&#39;sigmoid&#39;)\n# Or:\nlayers.Dense(64, activation=tf.sigmoid)\n\n# L1 正则\nlayers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n\n# L2 正则\nlayers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n\n# 正交初始化权重\nlayers.Dense(64, kernel_initializer=&#39;orthogonal&#39;)\n\n# 初始化偏置向量\nlayers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))</code></pre></div><h2>模型训练</h2><p> 构建模型后，我们通过调用 complie 方法设置训练参数</p><div class=\"highlight\"><pre><code class=\"language-text\"># Adam 优化器，分类交叉熵作为损失函数\nmodel.compile(optimizer=tf.train.AdamOptimizer(0.001),\n              loss=&#39;categorical_crossentropy&#39;,\n              metrics=[&#39;accuracy&#39;])</code></pre></div><p> tf.keras.Model.compile 常见重要参数： - optimizer: 优化器，如 tf.train.AdamOptimizer, tf.train.RMSPropOptimizer, or tf.train.GradientDescentOptimizer； - loss:  损失函数，常见损失函数 mean square error (mse), categorical_crossentropy, 和 binary_crossentropy; - metrics: 训练指标，如 MAE,mean_squared_error,categorical_accuracy;</p><p>  下面展示如何使用这些参数</p><div class=\"highlight\"><pre><code class=\"language-text\"># 使用均方差作为损失函数\nmodel.compile(optimizer=tf.train.AdamOptimizer(0.01),\n              loss=&#39;mse&#39;,       # mean squared error\n              metrics=[&#39;mae&#39;])  # mean absolute error\n\n# 使用交叉熵作为损失函数\nmodel.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n              loss=tf.keras.losses.categorical_crossentropy,\n              metrics=[tf.keras.metrics.categorical_accuracy])</code></pre></div><p>  使用 tf.keras.Model.fit 配置迭代参数：</p><div class=\"highlight\"><pre><code class=\"language-text\"># 迭代次数1000 次，batch_size 100\nmodel.fit(data, labels, epochs=1000, batch_size=100)</code></pre></div><h2>模型评估、预测</h2><p>  tensorflow keras 分别提供 tf.keras.Model.evaluate 和 tf.keras.Model.predict 这两个接口作为模型评估和模型预测，对于NumPy 和tf.data.Dateset 这两种数据格式均支持。  </p><div class=\"highlight\"><pre><code class=\"language-text\">data = np.random.random((1000, 32))\nlabels = np.random.random((1000, 10))\n\n# 模型评估\nmodel.evaluate(data, labels, batch_size=32)\n\nmodel.evaluate(dataset, steps=30)\n\n# 模型预测\nresult = model.predict(data, batch_size=32)\nprint(result.shape)</code></pre></div><p> 以下代码展示了如何使用Keras 在MNIST dataset 上实现了简单的DNN 模型.  </p><div class=\"highlight\"><pre><code class=\"language-text\">import tensorflow as tf\nmnist = tf.keras.datasets.mnist\n\n# 加载训练数据\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# 构建模型\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n  tf.keras.layers.Dense(32, activation=tf.nn.relu),\n  tf.keras.layers.Dense(16, activation=tf.nn.softmax)\n])\n\n# 配置训练参数\nmodel.compile(optimizer=&#39;adam&#39;,\n              loss=&#39;sparse_categorical_crossentropy&#39;,\n              metrics=[&#39;accuracy&#39;,&#39;mse&#39;])\n# 模型训练\nmodel.fit(x_train, y_train, epochs=10)\n\n#模型评估\nresult = model.evaluate(x_test, y_test)\nprint (&#34;result is : &#34;, result)</code></pre></div><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "Keras", 
                    "tagLink": "https://api.zhihu.com/topics/20052139"
                }
            ], 
            "comments": []
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/c_1160502680358768640"
}

{
    "title": "有三AI学院-深度学习模型优化", 
    "description": "深剖深度学习模型的发展与优化", 
    "followers": [
        "https://www.zhihu.com/people/shi-cheng-54-28", 
        "https://www.zhihu.com/people/liu-dun-qiang-11", 
        "https://www.zhihu.com/people/li-zuo-le-38", 
        "https://www.zhihu.com/people/jia-shuai-shuai-76", 
        "https://www.zhihu.com/people/spirit-soul", 
        "https://www.zhihu.com/people/amos-chen-77", 
        "https://www.zhihu.com/people/wang-a-fei-37", 
        "https://www.zhihu.com/people/yijiang-48-91", 
        "https://www.zhihu.com/people/luhairong11", 
        "https://www.zhihu.com/people/guanghua-30", 
        "https://www.zhihu.com/people/hu-yang-yang-39-51", 
        "https://www.zhihu.com/people/zhang-jia-hao-70-72", 
        "https://www.zhihu.com/people/wei-meng-41-71", 
        "https://www.zhihu.com/people/xue-hua-piao-man-di-39", 
        "https://www.zhihu.com/people/zhangshulin-48", 
        "https://www.zhihu.com/people/zhihunb", 
        "https://www.zhihu.com/people/zhang-wei-tao-92-11", 
        "https://www.zhihu.com/people/xiao-ma-jia-55-39", 
        "https://www.zhihu.com/people/xing-meng-qing-bei", 
        "https://www.zhihu.com/people/qing-feng-6-69", 
        "https://www.zhihu.com/people/bigenius", 
        "https://www.zhihu.com/people/zhou-yu-6-81", 
        "https://www.zhihu.com/people/guan-su-zi-1", 
        "https://www.zhihu.com/people/astronstar", 
        "https://www.zhihu.com/people/xiao-qi-qi-57", 
        "https://www.zhihu.com/people/su-dao-82", 
        "https://www.zhihu.com/people/liwei46", 
        "https://www.zhihu.com/people/wang-gang-77-27", 
        "https://www.zhihu.com/people/csxz", 
        "https://www.zhihu.com/people/wang-jie-61-38", 
        "https://www.zhihu.com/people/xie-lu-60-97", 
        "https://www.zhihu.com/people/xiao-bai-51-49-59", 
        "https://www.zhihu.com/people/well-rock-12", 
        "https://www.zhihu.com/people/feng-shi-cherish-19", 
        "https://www.zhihu.com/people/weizhongshan", 
        "https://www.zhihu.com/people/hou-wan-ling-14", 
        "https://www.zhihu.com/people/jjdlb", 
        "https://www.zhihu.com/people/WayneZeng", 
        "https://www.zhihu.com/people/jeremy2014", 
        "https://www.zhihu.com/people/shi-dian-7-68", 
        "https://www.zhihu.com/people/guo-yan-chao-64", 
        "https://www.zhihu.com/people/tang-song-he-79", 
        "https://www.zhihu.com/people/albert-huang-50", 
        "https://www.zhihu.com/people/xiaomizhou94", 
        "https://www.zhihu.com/people/cregulu", 
        "https://www.zhihu.com/people/yuan-fang-de-xiao-yu", 
        "https://www.zhihu.com/people/chai-bin-38", 
        "https://www.zhihu.com/people/ran-da-di-de-zhong-shi-xin-tu", 
        "https://www.zhihu.com/people/ceng-qiang-16-57", 
        "https://www.zhihu.com/people/tianyige", 
        "https://www.zhihu.com/people/yi-nian-shi-er-yue", 
        "https://www.zhihu.com/people/chuan-zhao-tuo-xie-guang", 
        "https://www.zhihu.com/people/wang-you-chen-30", 
        "https://www.zhihu.com/people/jianshenggenie", 
        "https://www.zhihu.com/people/dai-wen-65", 
        "https://www.zhihu.com/people/huang-sheng-zhi-92", 
        "https://www.zhihu.com/people/1994m8u2l372012", 
        "https://www.zhihu.com/people/yifdu", 
        "https://www.zhihu.com/people/feng-yi-jiu-15", 
        "https://www.zhihu.com/people/ye-shen-xing-63", 
        "https://www.zhihu.com/people/xiao-qi-14-78-49", 
        "https://www.zhihu.com/people/xu-jun-ping-sheng-zui", 
        "https://www.zhihu.com/people/zhoupan-93", 
        "https://www.zhihu.com/people/xiao-wang-78-2-64", 
        "https://www.zhihu.com/people/littlexue-xue-91", 
        "https://www.zhihu.com/people/melodysmileforever", 
        "https://www.zhihu.com/people/hanzz2007", 
        "https://www.zhihu.com/people/daiyizheng123", 
        "https://www.zhihu.com/people/yunzhongke", 
        "https://www.zhihu.com/people/cheng-shuai-25-51", 
        "https://www.zhihu.com/people/li-li-1-70-77", 
        "https://www.zhihu.com/people/j99999999955555", 
        "https://www.zhihu.com/people/wang-guo-zhu-39-90", 
        "https://www.zhihu.com/people/yu-ren-4-38", 
        "https://www.zhihu.com/people/gan-everything-96", 
        "https://www.zhihu.com/people/dan-zhou-4-88", 
        "https://www.zhihu.com/people/aegency", 
        "https://www.zhihu.com/people/zeldar-xf", 
        "https://www.zhihu.com/people/liang-xiao-shuang-6", 
        "https://www.zhihu.com/people/zhang-ze-yu-33-26-42", 
        "https://www.zhihu.com/people/wang-xin-83", 
        "https://www.zhihu.com/people/hei-se-qi-yue-zhe-14", 
        "https://www.zhihu.com/people/ding-yun-fan-18", 
        "https://www.zhihu.com/people/litan", 
        "https://www.zhihu.com/people/fei-ge-chuan-shu-78", 
        "https://www.zhihu.com/people/feng-ling-gang", 
        "https://www.zhihu.com/people/mamamamabobobo", 
        "https://www.zhihu.com/people/chaos-fractal", 
        "https://www.zhihu.com/people/leng-shu-ling", 
        "https://www.zhihu.com/people/CaptainY_T", 
        "https://www.zhihu.com/people/yao-yuan-de-li-xiang-xiang-1", 
        "https://www.zhihu.com/people/xiao-jiu-wo-60-33", 
        "https://www.zhihu.com/people/joson-liu", 
        "https://www.zhihu.com/people/hui-you-duo-jiu-60", 
        "https://www.zhihu.com/people/fei-zai-tian-kong-zhong-de-yu-47", 
        "https://www.zhihu.com/people/fcq_information", 
        "https://www.zhihu.com/people/jinmin-33", 
        "https://www.zhihu.com/people/jiong-xian-sen-4", 
        "https://www.zhihu.com/people/liao-qian-ying-79", 
        "https://www.zhihu.com/people/er-teng-71", 
        "https://www.zhihu.com/people/ding-ding-82-25", 
        "https://www.zhihu.com/people/chang-gu-niang-30", 
        "https://www.zhihu.com/people/yang-na-chuan", 
        "https://www.zhihu.com/people/qw-wong-17", 
        "https://www.zhihu.com/people/WNQ361", 
        "https://www.zhihu.com/people/ha-ha-8-79-49", 
        "https://www.zhihu.com/people/tian-jia-jie", 
        "https://www.zhihu.com/people/ding-ding-33-32-3", 
        "https://www.zhihu.com/people/linuxcpp", 
        "https://www.zhihu.com/people/ni-cai-15-22", 
        "https://www.zhihu.com/people/settinghead", 
        "https://www.zhihu.com/people/xiao-tian-79-44", 
        "https://www.zhihu.com/people/henry-46-56-28", 
        "https://www.zhihu.com/people/peng-xu-hao-70", 
        "https://www.zhihu.com/people/ECMA", 
        "https://www.zhihu.com/people/Dsssyc-Soku", 
        "https://www.zhihu.com/people/ding-kang-60-91", 
        "https://www.zhihu.com/people/yellowfin", 
        "https://www.zhihu.com/people/kissedbyfire-74", 
        "https://www.zhihu.com/people/chen-cheng-72-9-39", 
        "https://www.zhihu.com/people/sha-ye-bu-zhi-10", 
        "https://www.zhihu.com/people/miao-chen-62", 
        "https://www.zhihu.com/people/the-sky-69-37", 
        "https://www.zhihu.com/people/tu-fei", 
        "https://www.zhihu.com/people/yawu-99", 
        "https://www.zhihu.com/people/zhang-qian-qian-12-91", 
        "https://www.zhihu.com/people/shangzhi-huang", 
        "https://www.zhihu.com/people/you-xia-zhan", 
        "https://www.zhihu.com/people/zhang-feng-82-61-6", 
        "https://www.zhihu.com/people/jingyingxiaoguaiwu", 
        "https://www.zhihu.com/people/lookforward", 
        "https://www.zhihu.com/people/dong-feng-zao-ji", 
        "https://www.zhihu.com/people/yu-hai-long-22", 
        "https://www.zhihu.com/people/xue-gan-82", 
        "https://www.zhihu.com/people/li-si-si-45-66", 
        "https://www.zhihu.com/people/stone-mr-89", 
        "https://www.zhihu.com/people/ning-rain", 
        "https://www.zhihu.com/people/gaoju-zhang", 
        "https://www.zhihu.com/people/mopman-roxton", 
        "https://www.zhihu.com/people/han-han-han-han-han-a-5", 
        "https://www.zhihu.com/people/zhang-mian-66", 
        "https://www.zhihu.com/people/niceworld-49-6", 
        "https://www.zhihu.com/people/keloli", 
        "https://www.zhihu.com/people/zhao-wei-11594", 
        "https://www.zhihu.com/people/liang-deng-xing-zi", 
        "https://www.zhihu.com/people/xin-yu-ge", 
        "https://www.zhihu.com/people/pang-bu-qi", 
        "https://www.zhihu.com/people/catomy", 
        "https://www.zhihu.com/people/ji-kang-39-28", 
        "https://www.zhihu.com/people/xiao-bao-97-10-96", 
        "https://www.zhihu.com/people/yang-troy-89", 
        "https://www.zhihu.com/people/zhi-zhe-zai-cao-mang", 
        "https://www.zhihu.com/people/he-wang-88", 
        "https://www.zhihu.com/people/ni-da-xie-82-49", 
        "https://www.zhihu.com/people/BigCamel", 
        "https://www.zhihu.com/people/long-liu-yi-27", 
        "https://www.zhihu.com/people/qian-nian-lang", 
        "https://www.zhihu.com/people/muzi618", 
        "https://www.zhihu.com/people/brillgold", 
        "https://www.zhihu.com/people/mo-li-1-78-48", 
        "https://www.zhihu.com/people/haoyuachen", 
        "https://www.zhihu.com/people/piginzoo", 
        "https://www.zhihu.com/people/tu-ran-shuai-liao-51", 
        "https://www.zhihu.com/people/fei-zhou-xiao-zhu-13", 
        "https://www.zhihu.com/people/zhu-forrest", 
        "https://www.zhihu.com/people/wei-hua-51", 
        "https://www.zhihu.com/people/liu-xiao-yong-80-42", 
        "https://www.zhihu.com/people/xu-tian-jiao-67", 
        "https://www.zhihu.com/people/li-xin-52-81", 
        "https://www.zhihu.com/people/deng-wei-88-40", 
        "https://www.zhihu.com/people/zgd-64", 
        "https://www.zhihu.com/people/chen-pan-37", 
        "https://www.zhihu.com/people/mengtan", 
        "https://www.zhihu.com/people/la-lian-86", 
        "https://www.zhihu.com/people/ma-yu-xiang-4", 
        "https://www.zhihu.com/people/feijiang1201", 
        "https://www.zhihu.com/people/ren-zai-lv-tu-83", 
        "https://www.zhihu.com/people/kim-74-51", 
        "https://www.zhihu.com/people/upmao", 
        "https://www.zhihu.com/people/xiao-chi-91-40", 
        "https://www.zhihu.com/people/li-zheng-98-38-78", 
        "https://www.zhihu.com/people/yildhd-wang", 
        "https://www.zhihu.com/people/leng-yang-83", 
        "https://www.zhihu.com/people/li-jia-lin-44-82", 
        "https://www.zhihu.com/people/jay-Happy", 
        "https://www.zhihu.com/people/yyqing", 
        "https://www.zhihu.com/people/han-xiao-xu-56", 
        "https://www.zhihu.com/people/O-sen-26", 
        "https://www.zhihu.com/people/liu-fei-94-95", 
        "https://www.zhihu.com/people/lan-lan-lan-lan-96-82", 
        "https://www.zhihu.com/people/hijackjave", 
        "https://www.zhihu.com/people/zhong-er-cheng-xu-yuan", 
        "https://www.zhihu.com/people/NickWey", 
        "https://www.zhihu.com/people/zhi-hu-33-36-95", 
        "https://www.zhihu.com/people/ha-ha-8-37", 
        "https://www.zhihu.com/people/wang-bao-yu-87", 
        "https://www.zhihu.com/people/sun-pan-90-59", 
        "https://www.zhihu.com/people/long-gang-62-42", 
        "https://www.zhihu.com/people/xu-gu-99", 
        "https://www.zhihu.com/people/chen-xun-jiao-47", 
        "https://www.zhihu.com/people/yang-sen-89-61", 
        "https://www.zhihu.com/people/leo-lee-58-57", 
        "https://www.zhihu.com/people/bu-ceng-gai-bian-jet-69", 
        "https://www.zhihu.com/people/lao-bai-de-bai", 
        "https://www.zhihu.com/people/sui-yu-54-58", 
        "https://www.zhihu.com/people/zhouyuangan", 
        "https://www.zhihu.com/people/mark-93-86-98", 
        "https://www.zhihu.com/people/moni-gg", 
        "https://www.zhihu.com/people/al-joseph", 
        "https://www.zhihu.com/people/qian-yin-13", 
        "https://www.zhihu.com/people/li-yi-heng-60-80", 
        "https://www.zhihu.com/people/chendonghao09", 
        "https://www.zhihu.com/people/i-believe-57", 
        "https://www.zhihu.com/people/zhang-zi-yi-31-40", 
        "https://www.zhihu.com/people/liu-meng-yuan-72-95", 
        "https://www.zhihu.com/people/lian-zhi-wen", 
        "https://www.zhihu.com/people/xiao-lang-24-80", 
        "https://www.zhihu.com/people/dailele", 
        "https://www.zhihu.com/people/sha-qing-eternity", 
        "https://www.zhihu.com/people/feng-hao-zhe-66", 
        "https://www.zhihu.com/people/quxiaofeng", 
        "https://www.zhihu.com/people/llf-96", 
        "https://www.zhihu.com/people/mil-bang-bang-bing-63", 
        "https://www.zhihu.com/people/muyuexc", 
        "https://www.zhihu.com/people/wang-chen-91-90", 
        "https://www.zhihu.com/people/yjhua-sheng", 
        "https://www.zhihu.com/people/che-yuan-xiao-zi", 
        "https://www.zhihu.com/people/jluautolab", 
        "https://www.zhihu.com/people/na-lan-56-89", 
        "https://www.zhihu.com/people/kevin-hill", 
        "https://www.zhihu.com/people/gao-shu-60", 
        "https://www.zhihu.com/people/ling-hua-bao-22", 
        "https://www.zhihu.com/people/peng-pai-zhong", 
        "https://www.zhihu.com/people/wang-peng-qiang-66", 
        "https://www.zhihu.com/people/sybil12"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/65772452", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 6, 
            "title": "【两个live同时上线】如何设计性能更好和更加高效的网络", 
            "content": "<p>接下来有两个live同时上线，分别是《如何设计性能更好的网络》和《如何设计性能更高效的网络》，具体的简介大家可以点击去看。</p><a href=\"https://www.zhihu.com/lives/1109786268921278464\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-41f5094bf991163a4166911db2806b1f_ipico.jpg\" data-image-width=\"3179\" data-image-height=\"3179\" class=\"internal\">如何设计性能更强的 CNN 模型？</a><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4bbbbdd13d5c34ecd495b4f75deb9a20_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2562\" data-rawheight=\"980\" class=\"origin_image zh-lightbox-thumb\" width=\"2562\" data-original=\"https://pic1.zhimg.com/v2-4bbbbdd13d5c34ecd495b4f75deb9a20_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2562&#39; height=&#39;980&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2562\" data-rawheight=\"980\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2562\" data-original=\"https://pic1.zhimg.com/v2-4bbbbdd13d5c34ecd495b4f75deb9a20_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-4bbbbdd13d5c34ecd495b4f75deb9a20_b.jpg\"/></figure><a href=\"https://www.zhihu.com/lives/1109785910237028352\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-41f5094bf991163a4166911db2806b1f_ipico.jpg\" data-image-width=\"3179\" data-image-height=\"3179\" class=\"internal\">如何设计性能高效的 CNN 模型结构？</a><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9b9864b5faec995f6e342672d80bd814_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1778\" data-rawheight=\"634\" class=\"origin_image zh-lightbox-thumb\" width=\"1778\" data-original=\"https://pic1.zhimg.com/v2-9b9864b5faec995f6e342672d80bd814_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1778&#39; height=&#39;634&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1778\" data-rawheight=\"634\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1778\" data-original=\"https://pic1.zhimg.com/v2-9b9864b5faec995f6e342672d80bd814_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-9b9864b5faec995f6e342672d80bd814_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "知乎 Live", 
                    "tagLink": "https://api.zhihu.com/topics/20048909"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/80092518", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 8, 
            "title": "【知识星球】模型压缩和优化板块上线", 
            "content": "<p>欢迎大家来到《知识星球》专栏，这里是网络结构1000变小专题，最近星球开始上线模型压缩相关内容。</p><p>作者&amp;编辑 | 言有三</p><h2><b>1 模型优化与压缩</b></h2><p>模型优化与压缩涉及到<b>紧凑模型的设计，量化与剪枝以及相关的工业界使用技巧共3个大方向</b>。最近会集中上线一些内容，已有内容欢迎大家预览。</p><blockquote>Deep Compression</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c0fc4c420604d09d8484e8a95f5871d3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"424\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c0fc4c420604d09d8484e8a95f5871d3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;424&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"424\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c0fc4c420604d09d8484e8a95f5871d3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c0fc4c420604d09d8484e8a95f5871d3_b.jpg\"/></figure><p>Deep Compression是一个模型量化和压缩框架，</p><p>包含剪枝(pruning), 量化(trained quantization)和编码(Huffman coding)三个步骤。</p><p>Deep Compression综合应用了剪枝、量化、编码三个步骤来进行模型压缩，是2016 ICLR最佳论文。在不影响精度的前提下，把500M的VGG压缩到了11M，使得深度卷积网络移植到移动设备上成为可能。</p><p>如上所示，包括三个步骤：</p><p>(1) 网络剪枝</p><p>即移除不重要的连接，包括3个步骤，分别是普通网络训练，删除权重小于一定阈值的连接得到稀疏网络，对稀疏网络再训练，这是一个反复迭代的过程。这一步对于AlexNet和VGG-16模型，分别将参数降低为原来的1/9和1/13。</p><p>(2) 权重量化</p><p>权值量化是把网络的连接权值从高精度转化成低精度的操作过程，例如将32位浮点数float32转化成8位定点数int8或二值化为1bit，转换后的模型准确率等指标与原来相近，但模型大小变小，运行速度加快。一般操作是先训练模型，再进行量化，测试时使用量化后的模型。</p><p>如下图，这是一个4×4的权值矩阵，量化权重为4阶，即2bit，分别对应浮点数-1.0，0，1.5，2.0。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c868370f9f1b8c5f799ee033025908f2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"750\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-c868370f9f1b8c5f799ee033025908f2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;750&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"750\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-c868370f9f1b8c5f799ee033025908f2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c868370f9f1b8c5f799ee033025908f2_b.jpg\"/></figure><p>对weights矩阵采用cluster index进行存储后，原来需要16个32bit float，现在只需要4个32bit float，与16个2bit uint，参数量为原来的(16×2+4×32)/(16×32)=0.31。</p><p>这就完成了存储，那如何对量化值进行更新呢？事实上，文中仅对码字进行更新，也就是量化后的2bit的权重。</p><p>将索引相同的地方梯度求和乘以学习率，叠加到码字，这就是不断求取weights矩阵的聚类中心。原来有成千上万个不同浮点数的weights矩阵，经过一个有效的聚类后，每一个值都用其聚类中心进行替代，作者的研究表明这样并不会降低网络的效果。而聚类的迭代过程，通过BP的反向传播完成。</p><p>(3) 霍夫曼编码</p><p>霍夫曼编码是一种成熟的编码技巧，与CNN无关，它有效地利用了权重的有偏分布，可以进一步减少需要存储的参数体积。</p><p>性能如何呢？下表展示了LeNet，AlexNet，VGG的结果。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-621664d685b171ce307f3853d72b5066_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"364\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-621664d685b171ce307f3853d72b5066_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;364&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"364\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-621664d685b171ce307f3853d72b5066_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-621664d685b171ce307f3853d72b5066_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-84729a92fcbf205de164b2374dccfaa6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"244\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-84729a92fcbf205de164b2374dccfaa6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;244&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"244\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-84729a92fcbf205de164b2374dccfaa6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-84729a92fcbf205de164b2374dccfaa6_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>可知道在不降低精度的前提下，LeNet-5，AlexNet，VGG的压缩倍率分别达到了40，35，49。在卷积层和全连接层的量化阶数分别为8/5，8/4的配置下，模型性能几乎无损，验证了这是一种非常优异的模型压缩技巧。</p><p>[1] Han S, Mao H, Dally W J. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding[J]. arXiv preprint arXiv:1510.00149, 2015.</p><blockquote>DeepRebirth</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-922a18410a5060f31202032b127ff146_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"904\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-922a18410a5060f31202032b127ff146_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;904&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"904\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-922a18410a5060f31202032b127ff146_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-922a18410a5060f31202032b127ff146_b.jpg\"/></figure><p>在深度学习模型中有许多的非tensor网络层虽然参数很少，但是有较大的计算量，因此模型在最终部署到移动端时经常合并这些网络层从而进一步提高推理速度。</p><p>模型压缩有许多的方法，比如使用小卷积，多尺度，去除全连接层，瓶颈结构等思路设计紧凑的网络，也有对权重进行量化剪枝等方法，而DeepRebirth则采用了另外一种思路，即将Non-tensor layer(包括pooling、BN、LRN、ReLU等)合并到tensor层中，因为它们虽然参数不多，但是有很大的计算量，下面首先看看经典网络中这些层的计算时间比例：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-66b5e1005bd5378da720b936ad1c6758_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"313\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-66b5e1005bd5378da720b936ad1c6758_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;313&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"313\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-66b5e1005bd5378da720b936ad1c6758_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-66b5e1005bd5378da720b936ad1c6758_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d0405556960904b89aad74095dc0e548_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"492\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d0405556960904b89aad74095dc0e548_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;492&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"492\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d0405556960904b89aad74095dc0e548_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d0405556960904b89aad74095dc0e548_b.jpg\"/></figure><p>可以看出这些非卷积层占据了很大比例的计算时间，在Intel x86上甚至能占到一半，如果能够将其去除将大幅度的提升模型的运算速度。</p><p>作者提出了两种思路，分别是StreamLine Merging和Branch Merging。</p><p>StreamLine Merging是一种串行的合并方式，如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8ca41db10f82b27eb6474edaee9579da_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"778\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8ca41db10f82b27eb6474edaee9579da_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;778&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"778\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8ca41db10f82b27eb6474edaee9579da_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8ca41db10f82b27eb6474edaee9579da_b.jpg\"/></figure><p>通常来说，就是将Pooling、LRN，BN等网络层与相邻近的Conv层进行合并，上图的案例中经过合并后从153.8ms直接降低到了16.6ms。这里卷积本身的计算时间也大大降低，是因为pool2融合进了conv，使其步长从1变为2。</p><p>现今更为常见的情况是将BN，Scale等网络层和相邻的Conv层合并，也能降低不少计算量。</p><p>Branch Merging是一个分支的合并方式，如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f1d0da089ba2b724e0bc8f9db3d2e76c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-f1d0da089ba2b724e0bc8f9db3d2e76c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;416&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-f1d0da089ba2b724e0bc8f9db3d2e76c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-f1d0da089ba2b724e0bc8f9db3d2e76c_b.jpg\"/></figure><p>如上图，将1*1卷积层以及Pooling层分支分别合并到和它并行的3*3卷积和5*5卷积分支中。另外考虑到3*3卷积和5*5卷积分支输出通道增加会增大参数量和运算量，因此调整这些分支的输入通道进行压缩。</p><p>在进行以上的合并后，模型的性能通常会降低，所以需要重新训练，作者采用的方式是合并得到的新层使用标准的初始化方式，将其他层的参数固定不变，然后将新层的学习率设置为其他层的10倍后进行finetuning。</p><p>那么实验效果如何呢？以GoogLeNet为基准模型的实验结果如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c03f25a23f07261a4c46b6f130fe0204_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"641\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c03f25a23f07261a4c46b6f130fe0204_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;641&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"641\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c03f25a23f07261a4c46b6f130fe0204_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c03f25a23f07261a4c46b6f130fe0204_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-30b2f88bb4dabb8e99d128af7661ba2b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"525\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-30b2f88bb4dabb8e99d128af7661ba2b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;525&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"525\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-30b2f88bb4dabb8e99d128af7661ba2b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-30b2f88bb4dabb8e99d128af7661ba2b_b.jpg\"/></figure><p>上表展示了对不同的网络层使用以上合并策略，可以发现各种网络层的速度都有很大提升，在精度只降低0.4%的时候，能有超过3倍的速度提升。</p><p>这是非常实用且强大的一个提升模型运行速度的方法，在实际进行模型部署时，常常会对BN等网络层进行合并。</p><p>[1] Li D, Wang X, Kong D. Deeprebirth: Accelerating deep neural network execution on mobile devices[C]//Thirty-Second AAAI Conference on Artificial Intelligence. 2018.</p><p>更多可见。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-0690d4d627b31a827bf690b6a7943a90_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1685\" data-rawheight=\"1624\" class=\"origin_image zh-lightbox-thumb\" width=\"1685\" data-original=\"https://pic1.zhimg.com/v2-0690d4d627b31a827bf690b6a7943a90_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1685&#39; height=&#39;1624&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1685\" data-rawheight=\"1624\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1685\" data-original=\"https://pic1.zhimg.com/v2-0690d4d627b31a827bf690b6a7943a90_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-0690d4d627b31a827bf690b6a7943a90_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-11e0927cfbcc87aa2086b804ccd3b52c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"592\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-11e0927cfbcc87aa2086b804ccd3b52c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;592&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"592\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-11e0927cfbcc87aa2086b804ccd3b52c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-11e0927cfbcc87aa2086b804ccd3b52c_b.jpg\"/></figure><h2><b>2 如何掌握网络结构设计和数据使用</b></h2><p>关于如何系统性学习网络结构设计和数据使用，可以阅读我们对星球生态的介绍，有三风格的干货，相信你不会失望。</p><p><u><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649035102%26idx%3D1%26sn%3D6cff850c5ee378a86ba806038a8c798f%26chksm%3D8712af23b065263529a8ef88430840cc0c01a8834aebda6c0f2c2a42a903358486f4f8a07529%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">如何系统性掌握深度学习模型设计和优化</a></u></p><p><u><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649035182%26idx%3D1%26sn%3D31c371f5252164617021477e42e5d796%26chksm%3D8712afd3b06526c54090dfc7b25a03dc2e2c34f2ede6a6b955e142ab5be919760c9ecd3fb301%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">如何系统性掌握深度学习中的数据使用</a></u></p><p>有三AI知识星球的内容非常多，大家可以预览一些内容如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-eed70dbe21dd86d14d8a43a1c4d3413a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"887\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-eed70dbe21dd86d14d8a43a1c4d3413a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;887&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"887\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-eed70dbe21dd86d14d8a43a1c4d3413a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-eed70dbe21dd86d14d8a43a1c4d3413a_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-13ade5d20540bdff1fbd9bf07f217012_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-13ade5d20540bdff1fbd9bf07f217012_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;468&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-13ade5d20540bdff1fbd9bf07f217012_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-13ade5d20540bdff1fbd9bf07f217012_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0ed7284b4182a3986af12cbcf84c2491_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1020\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-0ed7284b4182a3986af12cbcf84c2491_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1020&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1020\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-0ed7284b4182a3986af12cbcf84c2491_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-0ed7284b4182a3986af12cbcf84c2491_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-3c40829a650f96ab57be6975d78f8601_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-3c40829a650f96ab57be6975d78f8601_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-563dd27d711c2951fd685e5a67e70faa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"711\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-563dd27d711c2951fd685e5a67e70faa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;711&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"711\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-563dd27d711c2951fd685e5a67e70faa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-563dd27d711c2951fd685e5a67e70faa_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7f76424fab996a5dfa1c77d9cab67dd3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"778\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-7f76424fab996a5dfa1c77d9cab67dd3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;778&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"778\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-7f76424fab996a5dfa1c77d9cab67dd3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-7f76424fab996a5dfa1c77d9cab67dd3_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-90397ae2f0ce5a783afbcaa1a3f045c5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"2056\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-90397ae2f0ce5a783afbcaa1a3f045c5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;2056&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"2056\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-90397ae2f0ce5a783afbcaa1a3f045c5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-90397ae2f0ce5a783afbcaa1a3f045c5_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-250ef9231b0520fd3d73dd64f6fec628_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"595\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-250ef9231b0520fd3d73dd64f6fec628_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;595&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"595\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-250ef9231b0520fd3d73dd64f6fec628_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-250ef9231b0520fd3d73dd64f6fec628_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a1b82c1fbd8f2d33aecfbf911e507f8f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-a1b82c1fbd8f2d33aecfbf911e507f8f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;468&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-a1b82c1fbd8f2d33aecfbf911e507f8f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a1b82c1fbd8f2d33aecfbf911e507f8f_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">以上所有内容\n加入有三AI知识星球即可获取\n来日方长\n点击加入\n不见不散\n更多精彩\n每日更新</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;930&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/72615427", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 3, 
            "title": "【知识星球】Attention网络结构上新，聚焦才能赢", 
            "content": "<figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\"/></figure><p>继续咱们的<b>“网络结构1000变”</b>板块，最近上新的内容主要是<b>Attention机制相关</b>的网络结构，即网络如何选择真正感兴趣的区域进行处理，下面是一个代表，更多请移步知识星球网络结构1000变板块。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a8d07dbf0e3e1d3778fe8519b0ca71e7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1600\" data-rawheight=\"5889\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pic4.zhimg.com/v2-a8d07dbf0e3e1d3778fe8519b0ca71e7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1600&#39; height=&#39;5889&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1600\" data-rawheight=\"5889\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1600\" data-original=\"https://pic4.zhimg.com/v2-a8d07dbf0e3e1d3778fe8519b0ca71e7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a8d07dbf0e3e1d3778fe8519b0ca71e7_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/72008611", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 3, 
            "title": "【知识星球】动态推理网络结构上新，不是所有的网络都是不变的", 
            "content": "<figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\"/></figure><p>继续咱们的“网络结构1000变”板块，最近上新的内容主要是动态推理的网络结构，即在测试时，对于不同的输入图像，表现不同的网络结构，下面是一个代表。</p><p>通常来说模型训练完之后结构就是固定的，测试时图片沿着固定的通路进行计算。然而测试样本本身有不同的难度，简单的样本只需要少量的计算量就可以完成任务，困难的样本则需要更多的计算量， BranchyNet就实现了不同难度的样本在测试时运行不同网络的想法，其网络结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d07beeb4ecfcbd51bdbce323faa511e1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"842\" data-rawheight=\"1098\" class=\"origin_image zh-lightbox-thumb\" width=\"842\" data-original=\"https://pic2.zhimg.com/v2-d07beeb4ecfcbd51bdbce323faa511e1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;842&#39; height=&#39;1098&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"842\" data-rawheight=\"1098\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"842\" data-original=\"https://pic2.zhimg.com/v2-d07beeb4ecfcbd51bdbce323faa511e1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d07beeb4ecfcbd51bdbce323faa511e1_b.jpg\"/></figure><p>如上图所示，它在正常网络通道上包含了多个旁路分支，这样的思想是基于观察到随着网络的加深，表征能力越来越强，大部分简单的图片可以在较浅层时学习到足以识别的特征，如上图中的Exit 1通道。一些更难的样本需要进一步的学习，如上图中的Exit 2通道，而只有极少数样本需要整个网络，如Exit3通道。这样的思想可以实现精度和计算量的平衡，对于大部分样本，可以用更小的计算量完成任务。</p><p>那么如何判断是否可以提前结束呢？采用分类信息熵就可以了，一旦该通道的分类信息熵低于某一个阈值，说明已经以很高的置信度获得了分类的结果，直到最终的通道。</p><p>在训练的时候，每一个通道都会对损失有贡献，越靠近浅层的网络权重越大。多通道的损失不仅增强了梯度信息，也在一定程度上实现了正则化。</p><p>将BranchyNet的设计思想用于LeNet,AlexNet,ResNet结构后，在不同阈值下的精度，加速比统计如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-04a88e8bcf87d8bc310bbec683bd54a6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"503\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-04a88e8bcf87d8bc310bbec683bd54a6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;503&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"503\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-04a88e8bcf87d8bc310bbec683bd54a6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-04a88e8bcf87d8bc310bbec683bd54a6_b.jpg\"/></figure><p>对于拥有N个分支的网络，需要的就是N-1个阈值，因为最后一个分支不需要阈值。从上表可以看出，在维持性能的前提下，加速效果明显，LeNet系列网络可以让超过90%的样本在第一个分支提前终止，AlexNet也超过一半，ResNet超过了40%。</p><p>更多的相关网络结构，请查阅知识星球最近的“网络结构1000变”的内容！</p><p></p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/76072364", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 46, 
            "title": "【AI不惑境】计算机视觉中注意力机制原理及其模型发展和应用", 
            "content": "<p>大家好，这是专栏<b>《AI不惑境》</b>的第七篇文章，讲述计算机视觉中的注意力(attention)机制。</p><p>进入到不惑境界，就是向高手迈进的开始了，在这个境界需要自己独立思考。如果说学习是一个从模仿，到追随，到创造的过程，那么到这个阶段，应该跃过了模仿和追随的阶段，进入了创造的阶段。从这个境界开始，讲述的问题可能不再有答案，更多的是激发大家一起来思考。</p><p>作者&amp;编辑 | 言有三</p><p>首发于有三AI公众号</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649034948%26idx%3D1%26sn%3Df02b7d42d72cadfa50ab34cfeffb36af%26chksm%3D8712aeb9b06527af4d06105d95503d6f36bd287293e2e8b76e6647858e109a201c1efe763599%26token%3D1296655195%26lang%3Dzh_CN%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】计算机视觉中注意力机制原理及其模型发展和应用</a><p>Attention机制在近几年来在图像，自然语言处理等领域中都取得了重要的突破，被证明有益于提高模型的性能。Attention机制本身也是符合人脑和人眼的感知机制，这里我们主要以计算机视觉领域为例，讲述Attention机制的原理，应用以及模型的发展。</p><h2><b>1 Attention机制与显著图</b></h2><p><b>1.1 何为Attention机制</b></p><p>所谓Attention机制，便是聚焦于局部信息的机制，比如图像中的某一个图像区域。随着任务的变化，注意力区域往往会发生变化。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-01c40fe7cdb085d9508d56b69e693553_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"687\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-01c40fe7cdb085d9508d56b69e693553_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;687&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"687\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-01c40fe7cdb085d9508d56b69e693553_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-01c40fe7cdb085d9508d56b69e693553_b.jpg\"/></figure><p>面对上面这样的一张图，如果你只是从整体来看，只看到了很多人头，但是你拉近一个一个仔细看就了不得了，都是天才科学家。</p><p>图中除了人脸之外的信息其实都是无用的，也做不了什么任务，<b>Attention机制便是要找到这些最有用的信息</b>，可以想见最简单的场景就是从照片中检测人脸了。</p><p><b>1.2 基于Attention的显著目标检测</b></p><p>和注意力机制相伴而生的一个任务便是显著目标检测，即salient object detection。它的输入是一张图，输出是一张概率图，概率越大的地方，代表是图像中重要目标的概率越大，即人眼关注的重点，一个典型的显著图如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a8c2e0d289e88e3ef25f644210bd7677_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"751\" data-rawheight=\"257\" class=\"origin_image zh-lightbox-thumb\" width=\"751\" data-original=\"https://pic4.zhimg.com/v2-a8c2e0d289e88e3ef25f644210bd7677_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;751&#39; height=&#39;257&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"751\" data-rawheight=\"257\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"751\" data-original=\"https://pic4.zhimg.com/v2-a8c2e0d289e88e3ef25f644210bd7677_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a8c2e0d289e88e3ef25f644210bd7677_b.jpg\"/></figure><p>右图就是左图的显著图，在头部位置概率最大，另外腿部，尾巴也有较大概率，这就是图中真正有用的信息。</p><p>显著目标检测需要一个数据集，而这样的数据集的收集便是通过追踪多个实验者的眼球在一定时间内的注意力方向进行平均得到，典型的步骤如下：</p><p>(1) 让被测试者观察图。</p><p>(2) 用eye tracker记录眼睛的注意力位置。</p><p>(3) 对所有测试者的注意力位置使用高斯滤波进行综合。</p><p>(4) 结果以0～1的概率进行记录。</p><p>于是就能得到下面这样的图，第二行是眼球追踪结果，第三行就是显著目标概率图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5c21cf8e76879a1091e93a29f4eebe21_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"527\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5c21cf8e76879a1091e93a29f4eebe21_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;527&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"527\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5c21cf8e76879a1091e93a29f4eebe21_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5c21cf8e76879a1091e93a29f4eebe21_b.jpg\"/></figure><p>上面讲述的都是空间上的注意力机制，即关注的是不同空间位置，而在CNN结构中，还有不同的特征通道，因此不同特征通道也有类似的原理，下面一起讲述。</p><h2><b>2 Attention模型架构</b></h2><p>注意力机制的本质就是定位到感兴趣的信息，抑制无用信息，结果通常都是以概率图或者概率特征向量的形式展示，从原理上来说，主要分为<b>空间注意力模型，通道注意力模型，空间和通道混合注意力模型三种，这里不区分soft和hard attention。</b></p><p><b>2.1 空间注意力模型(spatial attention)</b></p><p>不是图像中所有的区域对任务的贡献都是同样重要的，只有任务相关的区域才是需要关心的，比如分类任务的主体，空间注意力模型就是寻找网络中最重要的部位进行处理。</p><p>我们在这里给大家介绍两个具有代表性的模型，第一个就是Google DeepMind提出的STN网络(Spatial Transformer Network[1])。它通过学习输入的形变，从而完成适合任务的预处理操作，是一种基于空间的Attention模型，网络结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-80684f092d61f4af1d9309cb6f2b6d94_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"509\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-80684f092d61f4af1d9309cb6f2b6d94_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;509&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"509\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-80684f092d61f4af1d9309cb6f2b6d94_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-80684f092d61f4af1d9309cb6f2b6d94_b.jpg\"/></figure><p>这里的Localization Net用于生成仿射变换系数，输入是C×H×W维的图像，输出是一个空间变换系数，它的大小根据要学习的变换类型而定，如果是仿射变换，则是一个6维向量。</p><p>这样的一个网络要完成的效果如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-8fb94cd8e055c5f378d0768d17b677a8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"504\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-8fb94cd8e055c5f378d0768d17b677a8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;504&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"504\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-8fb94cd8e055c5f378d0768d17b677a8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-8fb94cd8e055c5f378d0768d17b677a8_b.jpg\"/></figure><p>即定位到目标的位置，然后进行旋转等操作，使得输入样本更加容易学习。这是一种一步调整的解决方案，当然还有很多迭代调整的方案，感兴趣可以去有三知识星球星球中阅读。</p><p>相比于Spatial Transformer Networks 一步完成目标的定位和仿射变换调整，Dynamic Capacity Networks[2]则采用了两个子网络，分别是低性能的子网络(coarse model)和高性能的子网络(fine model)。低性能的子网络(coarse model)用于对全图进行处理，定位感兴趣区域，如下图中的操作fc。高性能的子网络(fine model)则对感兴趣区域进行精细化处理，如下图的操作ff。两者共同使用，可以获得更低的计算代价和更高的精度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f29fbaba47e1cba576bc57dcede5b9ca_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f29fbaba47e1cba576bc57dcede5b9ca_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;468&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f29fbaba47e1cba576bc57dcede5b9ca_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f29fbaba47e1cba576bc57dcede5b9ca_b.jpg\"/></figure><p>由于在大部分情况下我们感兴趣的区域只是图像中的一小部分，因此空间注意力的本质就是定位目标并进行一些变换或者获取权重。</p><p><b>2.2 通道注意力机制</b></p><p>对于输入2维图像的CNN来说，一个维度是图像的尺度空间，即长宽，另一个维度就是通道，因此基于通道的Attention也是很常用的机制。</p><p>SENet(Sequeeze and Excitation Net)[3]是2017届ImageNet分类比赛的冠军网络，本质上是一个基于通道的Attention模型，它通过建模各个特征通道的重要程度，然后针对不同的任务增强或者抑制不同的通道，原理图如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-67de06bd1370479832c754a554e6ecf1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"251\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-67de06bd1370479832c754a554e6ecf1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;251&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"251\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-67de06bd1370479832c754a554e6ecf1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-67de06bd1370479832c754a554e6ecf1_b.jpg\"/></figure><p>在正常的卷积操作后分出了一个旁路分支，首先进行Squeeze操作(即图中Fsq(·))，它将空间维度进行特征压缩，即每个二维的特征图变成一个实数，相当于具有全局感受野的池化操作，特征通道数不变。</p><p>然后是Excitation操作(即图中的Fex(·))，它通过参数w为每个特征通道生成权重，w被学习用来显式地建模特征通道间的相关性。在文章中，使用了一个2层bottleneck结构(先降维再升维)的全连接层+Sigmoid函数来实现。</p><p>得到了每一个特征通道的权重之后，就将该权重应用于原来的每个特征通道，基于特定的任务，就可以学习到不同通道的重要性。</p><p>将其机制应用于若干基准模型，在增加少量计算量的情况下，获得了更明显的性能提升。作为一种通用的设计思想，它可以被用于任何现有网络，具有较强的实践意义。而后SKNet[4]等方法将这样的通道加权的思想和Inception中的多分支网络结构进行结合，也实现了性能的提升。</p><p>通道注意力机制的本质，在于建模了各个特征之间的重要性，对于不同的任务可以根据输入进行特征分配，简单而有效。</p><p><b>2.3 空间和通道注意力机制的融合</b></p><p>前述的Dynamic Capacity Network是从空间维度进行Attention，SENet是从通道维度进行Attention，自然也可以同时使用空间Attention和通道Attention机制。</p><p>CBAM(Convolutional Block Attention Module)[5]是其中的代表性网络，结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1cabf32d9979813becaefd20d7412c70_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"328\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-1cabf32d9979813becaefd20d7412c70_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;328&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"328\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-1cabf32d9979813becaefd20d7412c70_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-1cabf32d9979813becaefd20d7412c70_b.jpg\"/></figure><p>通道方向的Attention建模的是特征的重要性，结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-81c351c5d01be34fc428b32a1947471b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"268\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-81c351c5d01be34fc428b32a1947471b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;268&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"268\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-81c351c5d01be34fc428b32a1947471b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-81c351c5d01be34fc428b32a1947471b_b.jpg\"/></figure><p>同时使用最大pooling和均值pooling算法，然后经过几个MLP层获得变换结果，最后分别应用于两个通道，使用sigmoid函数得到通道的attention结果。</p><p>空间方向的Attention建模的是空间位置的重要性，结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-90e29a36365aa8747155343fad9cab3d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"382\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-90e29a36365aa8747155343fad9cab3d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;382&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"382\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-90e29a36365aa8747155343fad9cab3d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-90e29a36365aa8747155343fad9cab3d_b.jpg\"/></figure><p>首先将通道本身进行降维，分别获取最大池化和均值池化结果，然后拼接成一个特征图，再使用一个卷积层进行学习。</p><p>这两种机制，分别学习了通道的重要性和空间的重要性，还可以很容易地嵌入到任何已知的框架中。</p><p>除此之外，还有很多的注意力机制相关的研究，比如<b>残差注意力机制，多尺度注意力机制，递归注意力机制等。</b></p><p>感兴趣的同学可以去我们知识星球中阅读相关的网络结构主题。</p><p><b><u><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649034506%26idx%3D2%26sn%3D51d7cb09f5373ef1fb1b945750f05351%26chksm%3D8712b177b065386103b6c74e00d70332e4377dacbac57a1935e66e7c71ea1b06041da1266462%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【知识星球】超3万字的网络结构解读，学习必备</a></u></b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a58a22075fd377d979f8ebc77cda9271_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1035\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-a58a22075fd377d979f8ebc77cda9271_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1035&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1035\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-a58a22075fd377d979f8ebc77cda9271_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a58a22075fd377d979f8ebc77cda9271_b.jpg\"/></figure><p><b>3 Attention机制典型应用场景</b></p><p>从原理上来说，注意力机制在所有的计算机视觉任务中都能提升模型性能，但是有两类场景尤其受益<b>。</b><br/></p><p><b>3.1 细粒度分类</b></p><p>关于细粒度分类的基础内容，可以参考。</p><p><u><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649034832%26idx%3D2%26sn%3D5d66b2d6eec1b05bd6cc95bbd8b0dae1%26chksm%3D8712ae2db065273bc71cffc7decba2f7459f88a60d528f60379d8eb1a99d0b50bd59102ac211%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【图像分类】细粒度图像分类是什么，有什么方法，发展的怎么样</a></u><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ea3a82c065534cf5f484b679cad305d7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"757\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-ea3a82c065534cf5f484b679cad305d7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;757&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"757\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-ea3a82c065534cf5f484b679cad305d7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ea3a82c065534cf5f484b679cad305d7_b.jpg\"/></figure><p>我们知道细粒度分类任务中真正的难题在于如何定位到真正对任务有用的局部区域，如上示意图中的鸟的头部。Attention机制恰巧原理上非常合适，文[1],[6]中都使用了注意力机制，对模型的提升效果很明显。</p><p><b>3.2 显著目标检测/缩略图生成/自动构图</b></p><p>我们又回到了开头，没错，Attention的本质就是重要/显著区域定位，所以在目标检测领域是非常有用的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-75a84985453255a48fa102c6f5dc2a0c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"183\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-75a84985453255a48fa102c6f5dc2a0c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;183&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"183\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-75a84985453255a48fa102c6f5dc2a0c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-75a84985453255a48fa102c6f5dc2a0c_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-e9136d7a3ab76743d6adb5b0bd5112ea_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"183\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-e9136d7a3ab76743d6adb5b0bd5112ea_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;183&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"183\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-e9136d7a3ab76743d6adb5b0bd5112ea_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-e9136d7a3ab76743d6adb5b0bd5112ea_b.jpg\"/></figure><p>上图展示了几个显著目标检测的结果，可以看出对于有显著目标的图，概率图非常聚焦于目标主体，在网络中添加注意力机制模块，可以进一步提升这一类任务的模型。</p><p>除此之外，在视频分析，看图说话等任务中也比较重要，相关内容将在有三AI知识星球中每日更新。</p><p>[1] Jaderberg M, Simonyan K, Zisserman A. Spatial transformer networks[C]//Advances in neural information processing systems. 2015: 2017-2025.</p><p>[2] Almahairi A, Ballas N, Cooijmans T, et al. Dynamic capacity networks[C]//International Conference on Machine Learning. 2016: 2549-2558.</p><p>[3] Hu J, Shen L, Sun G. Squeeze-and-excitation networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 7132-7141.</p><p>[4] Li X, Wang W, Hu X, et al. Selective Kernel Networks[J]. 2019.</p><p>[5] Woo S, Park J, Lee J Y, et al. Cbam: Convolutional block attention module[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 3-19.</p><p>[6] Fu J, Zheng H, Mei T. Look closer to see better: Recurrent attention convolutional neural network for fine-grained image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4438-4446.</p><p><b>总结</b></p><p>注意力机制是一个原理简单而有效的机制，符合人眼的视觉感知原理，在实现上也容易嵌入当前的主流模型架构，是值得采用和学习的技术。</p><p><i>下期预告：深度学习中无监督学习</i></p><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032883%26idx%3D1%26sn%3D9e557cf7bff4bceecb522f28b074c25e%26chksm%3D8712b6ceb0653fd8ec4c7a9f39e5905de421dd08b7dbe49c55bbb25806d7c824089ae36f014a%26token%3D1169783853%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络的宽度如何影响深度学习模型的性能？</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032995%26idx%3D2%26sn%3D28b065415c2d8a11345531f1284413d0%26chksm%3D8712b75eb0653e48f46de857b14d6e029f08a5c0336928fc638eac1f8287aefea01a262be1e2%26token%3D2097035342%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】学习率和batchsize如何影响模型的性能？</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649033134%26idx%3D1%26sn%3D69a5be0c1677e55a0311269b0e481242%26chksm%3D8712b7d3b0653ec5211cfd57364bb7d4b8073e620f00f04de734ae2ae7b2e9179ae9d1468e58%26token%3D1855353646%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】残差网络的前世今生与原理</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649033716%26idx%3D1%26sn%3D71e6bc88057706ce864b30d3b176c863%26chksm%3D8712b589b0653c9f12a59fa81e68414b81e85532daef119e97b091c4abb6c7d4e393c3a695c9%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】移动端高效网络，卷积拆分和分组的精髓</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649034714%26idx%3D1%26sn%3D720a3c5e8189955295745c783be08143%26chksm%3D8712b1a7b06538b1057cc76ca1b1897a64db888e8658045c29143ef756d7aac75286cae58ade%26token%3D1073894756%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】深度学习中的多尺度模型设计</a> </p><p>第八期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649034948%26idx%3D1%26sn%3Df02b7d42d72cadfa50ab34cfeffb36af%26chksm%3D8712aeb9b06527af4d06105d95503d6f36bd287293e2e8b76e6647858e109a201c1efe763599%26token%3D1296655195%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】计算机视觉中注意力机制原理及其模型发展和应用</a></p>", 
            "topic": [
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/74710464", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 39, 
            "title": "【AI不惑境】深度学习中的多尺度模型设计", 
            "content": "<p>大家好，这是专栏<b>《AI不惑境》</b>的第七篇文章，讲述计算机视觉中的多尺度问题。</p><p>进入到不惑境界，就是向高手迈进的开始了，在这个境界需要自己独立思考。如果说学习是一个从模仿，到追随，到创造的过程，那么到这个阶段，应该跃过了模仿和追随的阶段，进入了创造的阶段。从这个境界开始，讲述的问题可能不再有答案，更多的是激发大家一起来思考。</p><p>作者&amp;编辑 | 言有三 </p><p>在计算机视觉中，尺度始终是一个大问题，小物体与超大尺度物体往往都会严重影响性能。</p><h2><b>1 什么是多尺度</b></h2><p><b>1.1 多尺度问题</b></p><p>所谓多尺度，实际上就是对<b>信号的不同粒度的采样</b>，通常在不同的尺度下我们可以观察到不同的特征，从而完成不同的任务。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-73596e3c54593b0cb229fb01c24cddb8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1002\" data-rawheight=\"280\" class=\"origin_image zh-lightbox-thumb\" width=\"1002\" data-original=\"https://pic1.zhimg.com/v2-73596e3c54593b0cb229fb01c24cddb8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1002&#39; height=&#39;280&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1002\" data-rawheight=\"280\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1002\" data-original=\"https://pic1.zhimg.com/v2-73596e3c54593b0cb229fb01c24cddb8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-73596e3c54593b0cb229fb01c24cddb8_b.jpg\"/></figure><p>如上两个图是同样的一维信号在不同采样频率下的结果，这是一条精度曲线。通常来说粒度更小/更密集的采样可以看到更多的细节，粒度更大/更稀疏的采样可以看到整体的趋势，不过此处由于使用了不同的颜色，曲线本身也存在较大的波动，所以粒度更小的右图反而能更直观的看到各个曲线的整体性能比较结果。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-61238de8ec16eca5ef467d65d680871b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"479\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-61238de8ec16eca5ef467d65d680871b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;479&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"479\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-61238de8ec16eca5ef467d65d680871b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-61238de8ec16eca5ef467d65d680871b_b.jpg\"/></figure><p>如上展示了3个尺度的图像，如果要完成的任务只是判断图中是否有前景，那么12×8的图像尺度就足够了。如果要完成的任务是识别图中的水果种类，那么64×48的尺度也能勉强完成。如果要完成的任务是后期合成该图像的景深，则需要更高分辨率的图像，比如640×480。</p><p><b>1.2 图像金字塔</b></p><p>很多时候多尺度的信号实际上已经包含了不同的特征，为了获取更加强大的特征表达，在传统图像处理算法中，有一个很重要的概念，即图像金字塔和高斯金字塔。</p><p>图像金字塔，即一组不同分辨率的图像，如下图，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6858050723667958428f20684faaa076_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"914\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb\" width=\"914\" data-original=\"https://pic3.zhimg.com/v2-6858050723667958428f20684faaa076_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;914&#39; height=&#39;930&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"914\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"914\" data-original=\"https://pic3.zhimg.com/v2-6858050723667958428f20684faaa076_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-6858050723667958428f20684faaa076_b.jpg\"/></figure><p>采样的方式可以是不重叠或者重叠的，如果是不重叠的，采样尺度因子为2，那就是每增加一层，行列分辨率为原来的1/2。</p><p><b>当然，为了满足采样定理，每一个采样层还需要配合平滑滤波器，因此更常用的就是高斯金字塔，每一层内用了不同的平滑参数，在经典的图像算子SIFT中被使用。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5aa4ab9142f869790366c5bcbe2c29b3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"991\" data-rawheight=\"1104\" class=\"origin_image zh-lightbox-thumb\" width=\"991\" data-original=\"https://pic4.zhimg.com/v2-5aa4ab9142f869790366c5bcbe2c29b3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;991&#39; height=&#39;1104&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"991\" data-rawheight=\"1104\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"991\" data-original=\"https://pic4.zhimg.com/v2-5aa4ab9142f869790366c5bcbe2c29b3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5aa4ab9142f869790366c5bcbe2c29b3_b.jpg\"/></figure><p>不过这不是本文要聚焦的内容，请大家去自行了解<b>尺度空间理论</b>，接下来聚焦深度学习中的多尺度模型设计。</p><h2><b>2 计算机视觉中的多尺度模型架构</b></h2><p>卷积神经网络通过逐层抽象的方式来提取目标的特征，其中一个重要的概念就是感受野。如果感受野太小，则只能观察到局部的特征，如果感受野太大，则获取了过多的无效信息，因此研究人员一直都在设计各种各样的多尺度模型架构，主要是图像金字塔和特征金字塔两种方案，但是具体的网络结构可以分为以下几种：(1) 多尺度输入。(2) 多尺度特征融合。(3) 多尺度特征预测融合。(4) 以上方法的组合。</p><p><b>2.1 多尺度输入网络</b></p><p>顾名思义，就是使用<b>多个尺度的图像输入(图像金字塔)</b>，然后将其结果进行融合，传统的人脸检测算法<b>V-J框架</b>就采用了这样的思路。</p><p>深度学习中模型以MTCNN[1]人脸检测算法为代表，其流程如下，在第一步检测PNet中就使用了多个分辨率的输入，各个分辨率的预测结果(检测框)一起作为RNet的输入。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-084965a9fa73838fef5d3595a488bb8b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"452\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-084965a9fa73838fef5d3595a488bb8b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;452&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"452\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-084965a9fa73838fef5d3595a488bb8b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-084965a9fa73838fef5d3595a488bb8b_b.jpg\"/></figure><p>值得一提的是，<b>多尺度模型集成的方案</b>在提高分类任务模型性能方面是不可或缺的，许多的模型仅仅采用多个尺度的预测结果进行<b>平均值融合</b>，就能在ImageNet等任务中提升2%以上的性能。</p><p><b>2.2 多尺度特征融合网络</b></p><p>多尺度特征融合网络常见的有两种，第一种是<b>并行多分支网络</b>，第二种是<b>串行的跳层连接结构</b>，<b>都是在不同的感受野下进行特征提取</b>。</p><p><b>(1) 并行多分支结构</b></p><p>比如Inception网络中的Inception基本模块，包括有四个并行的分支结构，分别是1×1卷积，3×3卷积，5×5卷积，3×3最大池化，最后对四个通道进行组合。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8a0e71d3ad0c7d6467a0b2a3d09c241e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"876\" data-rawheight=\"426\" class=\"origin_image zh-lightbox-thumb\" width=\"876\" data-original=\"https://pic3.zhimg.com/v2-8a0e71d3ad0c7d6467a0b2a3d09c241e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;876&#39; height=&#39;426&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"876\" data-rawheight=\"426\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"876\" data-original=\"https://pic3.zhimg.com/v2-8a0e71d3ad0c7d6467a0b2a3d09c241e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8a0e71d3ad0c7d6467a0b2a3d09c241e_b.jpg\"/></figure><p>除了更高卷积核大小，还可以使用带孔卷积来控制感受野。在图像分割网络Deeplab V3[2]和目标检测网络trident networks[3]中都使用了这样的策略，网络结构如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f2eaef014964e0acb2b815b7f802b0e6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"323\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f2eaef014964e0acb2b815b7f802b0e6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;323&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"323\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f2eaef014964e0acb2b815b7f802b0e6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f2eaef014964e0acb2b815b7f802b0e6_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-cad6c0db5484ee34a8208a6ab7812b9d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"406\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-cad6c0db5484ee34a8208a6ab7812b9d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;406&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"406\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-cad6c0db5484ee34a8208a6ab7812b9d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-cad6c0db5484ee34a8208a6ab7812b9d_b.jpg\"/></figure><p>还有一种比不同大小的卷积核和带孔卷积计算代价更低的控制感受野的方法，即直接使用不同大小的池化操作，被PSPNet[4]采用。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d8af97d7d1538560df7e5c3d0a275af8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"281\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d8af97d7d1538560df7e5c3d0a275af8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;281&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"281\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d8af97d7d1538560df7e5c3d0a275af8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d8af97d7d1538560df7e5c3d0a275af8_b.jpg\"/></figure><p>值得注意的是，这样的多分支结构对于模型压缩也是有益处的，以Big-little Net[5]为代表，它采用不同的尺度对信息进行处理。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0015acfbae6b1c0ab9bd4d90829932ab_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"344\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0015acfbae6b1c0ab9bd4d90829932ab_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;344&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"344\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0015acfbae6b1c0ab9bd4d90829932ab_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0015acfbae6b1c0ab9bd4d90829932ab_b.jpg\"/></figure><p>对于分辨率大的分支，使用更少的卷积通道，对于分辨率小的分支，使用更多的卷积通道，这样的方案能够更加充分地使用通道信息。</p><p><b>(2) 串行多分支结构</b></p><p>串行的多尺度特征结构以FCN[6]，U-Net为代表，需要通过<b>跳层连接</b>来实现特征组合，这样的结构在图像分割/目标检测任务中是非常常见的。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-224ee44fdada046448354b1183dc64a2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"471\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-224ee44fdada046448354b1183dc64a2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;471&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"471\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-224ee44fdada046448354b1183dc64a2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-224ee44fdada046448354b1183dc64a2_b.jpg\"/></figure><p>从上面这些模型可以看出，并行的结构能够在同一层级获取不同感受野的特征，经过融合后传递到下一层，可以更加灵活地平衡计算量和模型能力。串行的结构将不同抽象层级的特征进行融合，对于边界敏感的图像分割任务是不可缺少的。</p><p><b>2.3 多尺度特征预测融合</b></p><p>即在<b>不同的特征尺度进行预测</b>，最后将结果进行融合，以目标检测中的SSD[7]为代表。</p><p>SSD在不同stride不同大小的特征图上进行预测。低层特征图stride较小，尺寸较大，感受野较小，期望能检测到小目标。高层特征图stride较大，尺寸较小，感受野较大，期望能检测到大目标。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-650c91544f00a8fd6705857233dc22be_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"341\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-650c91544f00a8fd6705857233dc22be_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;341&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"341\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-650c91544f00a8fd6705857233dc22be_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-650c91544f00a8fd6705857233dc22be_b.jpg\"/></figure><p>类似的思想还有SSH[8]，从分辨率较大的特征图开始分为多个分支，然后各个分支单独预测不同尺度大小的目标。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-7277ec606374e9f86810952b6aab08c0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"446\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-7277ec606374e9f86810952b6aab08c0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;446&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"446\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-7277ec606374e9f86810952b6aab08c0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-7277ec606374e9f86810952b6aab08c0_b.jpg\"/></figure><p>在多个特征通道进行预测的思想与多个输入的方案其实是异曲同工的，但是它的计算效率更高。</p><p><b>2.4 多尺度特征和预测融合</b></p><p>既然可以将不同尺度的特征进行融合，也可以在不同的尺度进行预测，为何不同时将这两种机制一起使用呢？这样的结构以目标检测中的FPN[9]为代表。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-9f8e1b434bfee8a40d13f201542992d1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"449\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-9f8e1b434bfee8a40d13f201542992d1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;449&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"449\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-9f8e1b434bfee8a40d13f201542992d1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-9f8e1b434bfee8a40d13f201542992d1_b.jpg\"/></figure><p>即将高层的特征添加到相邻的低层组合成新的特征，每一层单独进行预测。当然，也可以反过来将低层的特征也添加到高层，比如PAN[10]。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-e119338b1e6a94fb53f8bf07a4e8f546_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"368\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-e119338b1e6a94fb53f8bf07a4e8f546_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;368&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"368\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-e119338b1e6a94fb53f8bf07a4e8f546_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-e119338b1e6a94fb53f8bf07a4e8f546_b.jpg\"/></figure><p>当然，对于不同尺度的特征图的融合，还可以基于学习的融合方案。</p><h2><b>3 后话</b></h2><p>上面说了这么多的方法，相信动手能力强的同学一定可以基于这些方法进行排列组合和拓展。另外，对于某些领域中的专用技巧，比如<b>目标检测中的不同尺度的Anchor设计，不同尺度的训练技巧</b>，在这里没有讲述。</p><p><b>以上就是多尺度的常用设计方法，从图像分辨率的控制，到卷积核，池化的大小和不同的方案，到不同特征的融合，现在有很多相关的研究，本文不一一详述，作为计算机视觉中的老大难问题，我们会持续关注，相关自动架构搜索的研究也已经出现[11]。</b></p><p>更多相关模型的解读，我们会在<b>有三AI知识星球</b>中进行剖析，每日两篇网络结构解读，感兴趣的可以来。</p><p><u><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649034506%26idx%3D2%26sn%3D51d7cb09f5373ef1fb1b945750f05351%26chksm%3D8712b177b065386103b6c74e00d70332e4377dacbac57a1935e66e7c71ea1b06041da1266462%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【知识星球】超3万字的网络结构解读，学习必备</a></u></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\"/></figure><p>参考文献</p><div class=\"highlight\"><pre><code class=\"language-text\">[1] Zhang K, Zhang Z, Li Z, et al. Joint face detection and alignment using multitask cascaded convolutional networks[J]. IEEE Signal Processing Letters, 2016, 23(10): 1499-1503.\n[2] Chen L C, Papandreou G, Schroff F, et al. Rethinking atrous convolution for semantic image segmentation[J]. arXiv preprint arXiv:1706.05587, 2017.\n[3] Li Y, Chen Y, Wang N, et al. Scale-aware trident networks for object detection[J]. arXiv preprint arXiv:1901.01892, 2019.\n[4] Zhao H, Shi J, Qi X, et al. Pyramid scene parsing network[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 2881-2890.\n[5] Chen C F, Fan Q, Mallinar N, et al. Big-little net: An efficient multi-scale feature representation for visual and speech recognition[J]. arXiv preprint arXiv:1807.03848, 2018.\n[6]Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 3431-3440.\n[7] Liu W, Anguelov D, Erhan D, et al. Ssd: Single shot multibox detector[C]//European conference on computer vision. Springer, Cham, 2016: 21-37.\n[8] Najibi M, Samangouei P, Chellappa R, et al. Ssh: Single stage headless face detector[C]//Proceedings of the IEEE International Conference on Computer Vision. 2017: 4875-4884.\n[9] Lin T Y, Dollár P, Girshick R, et al. Feature pyramid networks for object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 2117-2125.\n[10] Liu S, Qi L, Qin H, et al. Path aggregation network for instance segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 8759-8768.\n[11] Ghiasi G, Lin T Y, Le Q V. Nas-fpn: Learning scalable feature pyramid architecture for object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019: 7036-7045.</code></pre></div><h2><b>总结</b></h2><p>多尺度不仅对检测和分割不同尺度的目标很重要，对于提高模型的参数使用效率也非常关键，是必须深刻理解和掌握的方法。</p><p><i>下期预告：深度学习中的Attention机制</i></p><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032883%26idx%3D1%26sn%3D9e557cf7bff4bceecb522f28b074c25e%26chksm%3D8712b6ceb0653fd8ec4c7a9f39e5905de421dd08b7dbe49c55bbb25806d7c824089ae36f014a%26token%3D1169783853%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络的宽度如何影响深度学习模型的性能？</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032995%26idx%3D2%26sn%3D28b065415c2d8a11345531f1284413d0%26chksm%3D8712b75eb0653e48f46de857b14d6e029f08a5c0336928fc638eac1f8287aefea01a262be1e2%26token%3D2097035342%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】学习率和batchsize如何影响模型的性能？</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649033134%26idx%3D1%26sn%3D69a5be0c1677e55a0311269b0e481242%26chksm%3D8712b7d3b0653ec5211cfd57364bb7d4b8073e620f00f04de734ae2ae7b2e9179ae9d1468e58%26token%3D1855353646%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】残差网络的前世今生与原理</a> </p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649033716%26idx%3D1%26sn%3D71e6bc88057706ce864b30d3b176c863%26chksm%3D8712b589b0653c9f12a59fa81e68414b81e85532daef119e97b091c4abb6c7d4e393c3a695c9%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】移动端高效网络，卷积拆分和分组的精髓</a> </p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649034714%26idx%3D1%26sn%3D720a3c5e8189955295745c783be08143%26chksm%3D8712b1a7b06538b1057cc76ca1b1897a64db888e8658045c29143ef756d7aac75286cae58ade%26token%3D1073894756%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】深度学习中的多尺度模型设计</a></p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "yyfyan", 
                    "userLink": "https://www.zhihu.com/people/e50aeacb60f763a62225c99a7bcdbe3d", 
                    "content": "<p>总觉得深度学习时代的多尺度还是没有解决得非常好，</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "这个问题还是很难", 
                            "likes": 0, 
                            "replyToAuthor": "yyfyan"
                        }
                    ]
                }, 
                {
                    "userName": "少时玩笑", 
                    "userLink": "https://www.zhihu.com/people/e4ade668bfc9c696decc10984ec8fc18", 
                    "content": "<p>作者，您好！我想问您文章中有一句话，我不是很理解，希望得到您的指点，在2.2的（1）中，您说，“对于分辨率大的分支，使用更少的卷积通道，对于分辨率小的分支，使用更多的卷积通道，这样的方案能够更加充分地使用通道信息。”这句话我不是很理解，分辨率越大，语义信息越弱，为什么还使用更少的卷积通道呢？分辨率越小，说明感受野大，语义信息强，为什么还要使用更多的卷积通道呢？您说能够更加充分地使用通道信息，这是什么意思呢？</p><p>感谢您~</p><p><br></p><a class=\"comment_sticker\" href=\"https://pic2.zhimg.com/v2-90359a720808ff45062287127cfa1039.gif\" data-width=\"\" data-height=\"\">[爱心]</a>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "这是一种主观设定，从计算效率来看，分辨率大的应该少用一些通道，因为这样即使它提取的信息少，也有分辨率更小的通道来弥补，反之也是。不过这样的设定很主观，所以目前基于搜索的方法效果就可能更好，参考mixnet，scalenet。", 
                            "likes": 0, 
                            "replyToAuthor": "少时玩笑"
                        }, 
                        {
                            "userName": "少时玩笑", 
                            "userLink": "https://www.zhihu.com/people/e4ade668bfc9c696decc10984ec8fc18", 
                            "content": "<p>还有一个问题，我们可不可以认为，分辨率较大的特征图含有的信息就是冗余的呢？</p>", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "少时玩笑", 
                    "userLink": "https://www.zhihu.com/people/e4ade668bfc9c696decc10984ec8fc18", 
                    "content": "<p>想问作者~在PAN这篇论文里，为什么说绿色的线（less than 10）比红色的线（more than 100）经过的卷积层更少呢？</p><p>希望得到您的回复~</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "少时玩笑", 
                    "userLink": "https://www.zhihu.com/people/e4ade668bfc9c696decc10984ec8fc18", 
                    "content": "<p>我好像有些理解了... 论文里说的绿色的线，是将底层特征图传给N5，而从C2到N5只经过不到10层的卷积。但是从C2到P5，经过了整个骨干网络（resnet），所以就有多于100层的网络。所以说，底层特征传到P5会损失很多信息，而将底层特征传给N5，只需要经过不到10层网络，所以说，绿色的线更能够保留小物体的细节信息。不知道，这样理解是不是正确的。</p><a class=\"comment_sticker\" href=\"https://pic2.zhimg.com/v2-90359a720808ff45062287127cfa1039.gif\" data-width=\"\" data-height=\"\">[爱心]</a>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "这篇我还没细看[飙泪笑]", 
                            "likes": 0, 
                            "replyToAuthor": "少时玩笑"
                        }, 
                        {
                            "userName": "少时玩笑", 
                            "userLink": "https://www.zhihu.com/people/e4ade668bfc9c696decc10984ec8fc18", 
                            "content": "<p>好的~我后来的想法应该是对的~感谢您。</p><a class=\"comment_sticker\" href=\"https://pic2.zhimg.com/v2-90359a720808ff45062287127cfa1039.gif\" data-width=\"\" data-height=\"\">[爱心]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/73479278", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 4, 
            "title": "【知识星球】超3万字的网络结构解读，学习必备", 
            "content": "<p>不知不觉我们<b>每日两更</b>的<b>“网络结构1000变”</b>板块已经有超过30000字的解读了，下面是该模块的汇总清单。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-89cd2d78a36f18c6b9f165b9374e658b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"524\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-89cd2d78a36f18c6b9f165b9374e658b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;524&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"524\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-89cd2d78a36f18c6b9f165b9374e658b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-89cd2d78a36f18c6b9f165b9374e658b_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7224984b64499076e14714e1fb77afa9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"953\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-7224984b64499076e14714e1fb77afa9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;953&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"953\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-7224984b64499076e14714e1fb77afa9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7224984b64499076e14714e1fb77afa9_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-2d71821f382fe7880ba828c0401b1c3a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"648\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-2d71821f382fe7880ba828c0401b1c3a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;648&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"648\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-2d71821f382fe7880ba828c0401b1c3a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-2d71821f382fe7880ba828c0401b1c3a_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-408710d5432d917c4d462f576eefc9a7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"677\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-408710d5432d917c4d462f576eefc9a7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;677&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"677\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-408710d5432d917c4d462f576eefc9a7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-408710d5432d917c4d462f576eefc9a7_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f0d8a6ae34ac98eb3a34262466c88e86_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"505\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f0d8a6ae34ac98eb3a34262466c88e86_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;505&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"505\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f0d8a6ae34ac98eb3a34262466c88e86_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f0d8a6ae34ac98eb3a34262466c88e86_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-84a320ba392e19bed21b88d55fda6cbd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"759\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-84a320ba392e19bed21b88d55fda6cbd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;759&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"759\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-84a320ba392e19bed21b88d55fda6cbd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-84a320ba392e19bed21b88d55fda6cbd_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-75154eb5b4735285b7b68fe224df00bc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"384\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-75154eb5b4735285b7b68fe224df00bc_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;384&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"384\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-75154eb5b4735285b7b68fe224df00bc_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-75154eb5b4735285b7b68fe224df00bc_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5485322fdc72f41cdbd505531ce7aca1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"431\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5485322fdc72f41cdbd505531ce7aca1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;431&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"431\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5485322fdc72f41cdbd505531ce7aca1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5485322fdc72f41cdbd505531ce7aca1_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4b5f941b0a2073f12204b29e584f6948_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"450\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-4b5f941b0a2073f12204b29e584f6948_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;450&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"450\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-4b5f941b0a2073f12204b29e584f6948_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-4b5f941b0a2073f12204b29e584f6948_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e5efcfd1cd04727ae5edd7bd04c29303_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"411\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-e5efcfd1cd04727ae5edd7bd04c29303_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;411&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"411\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-e5efcfd1cd04727ae5edd7bd04c29303_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e5efcfd1cd04727ae5edd7bd04c29303_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-dc2f7c95a1fc0b869a4863dc1369ed9a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-dc2f7c95a1fc0b869a4863dc1369ed9a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;326&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-dc2f7c95a1fc0b869a4863dc1369ed9a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-dc2f7c95a1fc0b869a4863dc1369ed9a_b.jpg\"/></figure><p>该模块的学习形式如下：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ade4115e46fde36fcc72590531e89e55_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1720\" data-rawheight=\"1624\" class=\"origin_image zh-lightbox-thumb\" width=\"1720\" data-original=\"https://pic2.zhimg.com/v2-ade4115e46fde36fcc72590531e89e55_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1720&#39; height=&#39;1624&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1720\" data-rawheight=\"1624\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1720\" data-original=\"https://pic2.zhimg.com/v2-ade4115e46fde36fcc72590531e89e55_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ade4115e46fde36fcc72590531e89e55_b.jpg\"/></figure><p><b>如果心动，就早日加入吧！学习债，越晚还的越多！</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-01e36361c94d1322e1afb254ced686f0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic1.zhimg.com/v2-01e36361c94d1322e1afb254ced686f0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;930&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic1.zhimg.com/v2-01e36361c94d1322e1afb254ced686f0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-01e36361c94d1322e1afb254ced686f0_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/69449808", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 36, 
            "title": "【AI不惑境】移动端高效网络，卷积拆分和分组的精髓", 
            "content": "<p>大家好，这是专栏<b>《AI不惑境》</b>的第六篇文章，讲述卷积拆分和分组卷积的精髓。</p><p>进入到不惑境界，就是向高手迈进的开始了，在这个境界需要自己独立思考。如果说学习是一个从模仿，到追随，到创造的过程，那么到这个阶段，应该跃过了模仿和追随的阶段，进入了创造的阶段。从这个境界开始，讲述的问题可能不再有答案，更多的是激发大家一起来思考。</p><p>作者&amp;编辑 | 言有三 </p><p>在移动端高效的模型设计中，卷积拆分和分组几乎是不可缺少的思想，那么它们究竟是如何高效，本身又有哪些发展呢。</p><h2><b>1 什么是卷积拆分</b><br/></h2><p>一个多通道的普通2D卷积包含了三个维度，分别是通道，长，宽，如下图(a)。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-db0347f7fdb2fe169745c0bff8be776f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"256\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-db0347f7fdb2fe169745c0bff8be776f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;256&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"256\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-db0347f7fdb2fe169745c0bff8be776f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-db0347f7fdb2fe169745c0bff8be776f_b.jpg\"/></figure><p>然后将这个卷积的步骤分解为3个独立的方向[1]，即通道方向，X方向和Y方向，如上图(b)，则具有更低的计算量和参数量。</p><p>假如X是卷积核宽度，Y是卷积核高度，C是输入通道数，如果是正常的卷积，那么输出一个通道，需要的参数量是XYC，经过上图的分解后，参数量变为X+Y+C，一般来说C&gt;&gt;X和Y，所以分解后的参数对比之前的参数约为1/(XY)。</p><p>对于3×3的卷积，相当于参数量降低一个数量级，计算量也是相当，可见这是很高效的操作。</p><p>当然，还可以只分解其中的某些维度，比如在Inception V3的网络结构中，就将7×7的卷积拆分为1×7和7×1两个方向。从另一个角度来看，这还提升了网络的深度。</p><h2><b>2 什么是通道分组</b></h2><p><b>2.1 分组卷积的来源</b></p><p>标准的卷积是使用多个卷积核在输入的所有通道上分别卷积提取特征，而分组卷积，就是将通道进行分组，组与组之间相关不影响，各自得到输出。</p><p>通道分组的思想来自于Laurent Sifre在Google实习的时候提出的separable convolution，相关的内部报告可以参考YouTube视频<a href=\"https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DVhLe-u0M1a8\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://www.</span><span class=\"visible\">youtube.com/watch?</span><span class=\"invisible\">v=VhLe-u0M1a8</span><span class=\"ellipsis\"></span></a>，具体的实现在它的博士论文[2]中，如下示意图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d62fa55753dadf4df6f044cafe4836a0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"344\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d62fa55753dadf4df6f044cafe4836a0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;344&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"344\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d62fa55753dadf4df6f044cafe4836a0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d62fa55753dadf4df6f044cafe4836a0_b.jpg\"/></figure><p>对于平移，旋转等刚体运动来说，它们可以被拆分成不同的维度，因此使用上面的separable convolution，实现起来也很简单，就是先进行通道的分组，这在AlexNet网络中还被当作一个训练技巧。</p><p><b>2.2 从Xception到MobileNet</b></p><p>随着Google的Inception网络提出，这一个相对于VGG更加高效的网络也开始进化。到了Inception V2的时候，已经用上了上面的思想。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3114825ad6c8515068c92ebabda68742_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"922\" data-rawheight=\"562\" class=\"origin_image zh-lightbox-thumb\" width=\"922\" data-original=\"https://pic3.zhimg.com/v2-3114825ad6c8515068c92ebabda68742_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;922&#39; height=&#39;562&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"922\" data-rawheight=\"562\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"922\" data-original=\"https://pic3.zhimg.com/v2-3114825ad6c8515068c92ebabda68742_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-3114825ad6c8515068c92ebabda68742_b.jpg\"/></figure><p>上面就是一个与Inception Module类似的模块，只是每一个通道完全一样，这就可以等价于通道分组了。</p><p><b>假如分组的个数与输入通道数相等，Inception便成为了极致的inception(extreme inception，简称Xception[3])。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-00b73bea6717c99f89c577a883e013f4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"622\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-00b73bea6717c99f89c577a883e013f4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;622&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"622\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-00b73bea6717c99f89c577a883e013f4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-00b73bea6717c99f89c577a883e013f4_b.jpg\"/></figure><p><b>首先经过1×1卷积，然后通道分组进行卷积，这样的一个结构随Tensorflow的流行而流行，名为Depthwise Separable Convolution。</b></p><p><b>随后Google的研究人员提出了MobileNets[4]结构，使用了Depthwise Separable Convolution模块进行堆叠，与Xception中的不同是1×1卷积放置在分组卷积之后。因为有许多这样的模块进行堆叠，所以两者其实是等价的。</b></p><p><b>画成二维图，示意图如下：</b><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-9eeda33bc1b5895929ef2330f0c92ef7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"998\" data-rawheight=\"750\" class=\"origin_image zh-lightbox-thumb\" width=\"998\" data-original=\"https://pic4.zhimg.com/v2-9eeda33bc1b5895929ef2330f0c92ef7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;998&#39; height=&#39;750&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"998\" data-rawheight=\"750\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"998\" data-original=\"https://pic4.zhimg.com/v2-9eeda33bc1b5895929ef2330f0c92ef7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-9eeda33bc1b5895929ef2330f0c92ef7_b.jpg\"/></figure><p>画成三维图，示意图如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-16da10607e65818fde102ed97a81c9f2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"514\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-16da10607e65818fde102ed97a81c9f2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;514&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"514\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-16da10607e65818fde102ed97a81c9f2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-16da10607e65818fde102ed97a81c9f2_b.jpg\"/></figure><p>使用Netscope可视化MobileNet的网络如下，当我们看到这个28层的网络，又经历了残差网络的洗礼后，顿时有种返璞归真的感觉。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-584e857faab564df216317024d3551f8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"471\" data-rawheight=\"4096\" class=\"origin_image zh-lightbox-thumb\" width=\"471\" data-original=\"https://pic1.zhimg.com/v2-584e857faab564df216317024d3551f8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;471&#39; height=&#39;4096&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"471\" data-rawheight=\"4096\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"471\" data-original=\"https://pic1.zhimg.com/v2-584e857faab564df216317024d3551f8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-584e857faab564df216317024d3551f8_b.jpg\"/></figure><p><b>2.3 分组卷积性能如何</b></p><p>令输入blob大小为M×Dk×Dk，输出为N×Dj×Dj，则标准卷积计算量为M×Dk×Dk×N×Dj×Dj，而转换为Depthwise卷积加Pointwise卷积，Depthwise卷积计算量为M×Dk×Dk×Dj×Dj，Pointwise卷积计算量为M×N×Dj×Dj，计算量对比为：(M×Dk×Dk×Dj×Dj+M×N×Dj×Dj)/M×Dk×Dk×N×Dj×Dj= 1/N+1/(Dk×Dk)，由于网络中大量地使用3×3的卷积核，当N比较大时，上面卷积计算量约为普通卷积的1/9，从而降低了一个数量级的计算量。</p><p>性能上也没有让我们失望，在只有VGG16不到1/32的参数量和1/27的计算量的同时还能取得与之相当的性能。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d40c5eb837a49c0d781f8045f030fe6b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-d40c5eb837a49c0d781f8045f030fe6b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;369&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-d40c5eb837a49c0d781f8045f030fe6b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-d40c5eb837a49c0d781f8045f030fe6b_b.jpg\"/></figure><p>关于更多细节的解读和实验对比，此处就不再做介绍了，可以阅读以前的一篇文章。</p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a><br/></li></ul><p><b>2.4 分组卷积性能的进一步提升</b></p><p><b>对于MobileNet这样的网络结构，还可以从两个方向进行提升，第一个是增加分组的信息交流，第二个是更加智能的分组。</b></p><p>简单的分组使得不同通道之间没有交流，可能会导致信息的丢失，Shufflenet[5]重新增加了通道的信息交换。具体来说，对于上一层输出的通道，先做一个Shuffle操作，再分成几个组进入到下一层，示意图如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-aa08e305fd9dfe98869b7d0bdf662d96_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"394\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-aa08e305fd9dfe98869b7d0bdf662d96_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;394&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"394\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-aa08e305fd9dfe98869b7d0bdf662d96_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-aa08e305fd9dfe98869b7d0bdf662d96_b.jpg\"/></figure><p>另一方面，MobileNet的分组是固定，ShuffleNet中的通道的打乱也是一个确定的映射，那是不是可以基于数据来学习到更加合适的分组呢？Condensenets[6]给出了确定的回答。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d7ecda5c339aa5c7463ceea1c4c199eb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-d7ecda5c339aa5c7463ceea1c4c199eb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;312&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-d7ecda5c339aa5c7463ceea1c4c199eb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-d7ecda5c339aa5c7463ceea1c4c199eb_b.jpg\"/></figure><p>更多的解读，我们已经放在了知识星球中，感兴趣的可以关注。</p><h2><b>3 分组卷积结构的发展</b></h2><p><b>ResNet虽然不是残差连接的发明者，但使得这一思想为众人痴狂。MobileNet也不是分组卷积的发明者，但同样是它使分组的思想深入人心，原来这样的网络结构不仅不降低准确率，还能大幅度提升计算效率，尤其适合硬件并行。</b></p><p>自此，分组的思想被不断拓展研究，下面我们主要考虑分组的各个通道存在较大差异的研究。</p><p><b>3.1 多分辨率卷积核通道分组网络</b></p><p>这一类网络以SqueezeNet[7]为代表，它以卷积层conv1开始，接着是8个Fire modules，最后以卷积层conv10结束。</p><p>一个fire module的子结构下图，包含一个squeeze模块加上一个expand模块。Squeeze模块使用1×1卷积进行通道降维，expand模块使用1×1卷积和3×3卷积用于通道升维。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c07e291d2d3aa6aa4726b8afad1999d0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"670\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c07e291d2d3aa6aa4726b8afad1999d0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;670&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"670\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c07e291d2d3aa6aa4726b8afad1999d0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c07e291d2d3aa6aa4726b8afad1999d0_b.jpg\"/></figure><p>Squeezenet的压缩比率是惊人的，只有AlexNet 1/50的参数量，能达到相当的性能。</p><p><b>3.2 多尺度通道分组网络</b></p><p>这一类结构采用不同的尺度对信息进行处理，对于分辨率大的分支，使用更少的卷积通道，对于分辨率小的分支，使用更多的卷积通道，以Big-Little Net[8]为代表，K个分支，尺度分别为1/2^(K-1)，如下图结构。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-034a65ed9489e85790a953af803eb4f3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"345\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-034a65ed9489e85790a953af803eb4f3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;345&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"345\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-034a65ed9489e85790a953af803eb4f3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-034a65ed9489e85790a953af803eb4f3_b.jpg\"/></figure><p>当然，如果两个通道在中间的计算过程中还存在信息的交流，则可以获得更高的性能，比如Octave Convolution[9]。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8d04c78ff4d501ceff96046a241ee9a6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"519\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8d04c78ff4d501ceff96046a241ee9a6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;519&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"519\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8d04c78ff4d501ceff96046a241ee9a6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8d04c78ff4d501ceff96046a241ee9a6_b.jpg\"/></figure><p>卷积核通过因子被分为了高分辨率和低分辨率两部分，低分辨率具有较多的通道，被称为低频分量。高分辨率具有较少的通道，被称为高频分量，两者各自学习，并且进行信息的融合。高分辨率通道通过池化与低分辨率通道融合，低分辨率通过上采样与高分辨率通道融合。最终在22.2GFLOPS的计算量下，ImageNet Top-1的精度达到了82.9%。</p><p><b>3.3 多精度通道分组网络</b></p><p>除了还分辨率和卷积核上做文章，还可以在计算精度上做文章，这一类结构以DSConv[10]为代表，它将卷积核分为两部分，一部分是整数分量VQK，一部分是分数分量KDS，如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0d7ac14476d285b99dff1c86b4c9d18f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"762\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0d7ac14476d285b99dff1c86b4c9d18f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;762&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"762\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0d7ac14476d285b99dff1c86b4c9d18f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0d7ac14476d285b99dff1c86b4c9d18f_b.jpg\"/></figure><p>VQK(Variable Quantizes Kernel)只有整数值，不可训练，它的权重值从预训练模型中计算而来。KDS(kernel distribution shifter)是浮点数，包含一个kernel级别的偏移量，一个channel级别的偏移量。</p><p>这一个模型在ResNet50和ResNet34，AlexNet，MobileNet等基准模型上取得了14x参数量的压缩，10x速度的提升。</p><p>除了上面这些思路外，还有很多可以做的空间，大家可以去多实验写论文填坑，有三就帮到这里了。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>参考文献</h2><p>[1] Jin J, Dundar A, Culurciello E. Flattened convolutional neural networks for feedforward acceleration[J]. arXiv preprint arXiv:1412.5474, 2014.</p><p>[2] Sifre L , Mallat, Stéphane. Rigid-Motion Scattering for Texture Classification[J]. Computer Science, 2014.</p><p>[3] Chollet F. Xception: Deep Learning with Depthwise Separable Convolutions[J]. computer vision and pattern recognition, 2017: 1800-1807.</p><p>[4] Howard A G, Zhu M, Chen B, et al. Mobilenets: Efficient convolutional neural networks for mobile vision applications[J]. arXiv preprint arXiv:1704.04861, 2017.</p><p>[5] Zhang X, Zhou X, Lin M, et al. Shufflenet: An extremely efficient convolutional neural network for mobile devices[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 6848-6856.</p><p>[6] Huang G, Liu S, Van der Maaten L, et al. Condensenet: An efficient densenet using learned group convolutions[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 2752-2761.</p><p>[7] Iandola F N, Han S, Moskewicz M W, et al. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and&lt; 0.5 MB model size[J]. arXiv preprint arXiv:1602.07360, 2016.</p><p>[8] Chen C F, Fan Q, Mallinar N, et al. Big-little net: An efficient multi-scale feature representation for visual and speech recognition[J]. arXiv preprint arXiv:1807.03848, 2018.</p><p>[9] Chen Y, Fang H, Xu B, et al. Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution[J]. arXiv preprint arXiv:1904.05049, 2019.</p><p>[10] Gennari M, Fawcett R, Prisacariu V A. DSConv: Efficient Convolution Operator[J]. arXiv preprint arXiv:1901.01928, 2019.</p><h2><b>总结</b></h2><p>分组卷积之所有有效，一个是因为网络中的空间和通道的冗余计算使得其性能可以保持，而简单的分组并行计算又非常适合于GPU等处理器，因此在移动端高效率模型中广泛使用，是必须掌握的思想。</p><p><i>下期预告：深度学习中的尺度。</i></p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032883%26idx%3D1%26sn%3D9e557cf7bff4bceecb522f28b074c25e%26chksm%3D8712b6ceb0653fd8ec4c7a9f39e5905de421dd08b7dbe49c55bbb25806d7c824089ae36f014a%26token%3D1169783853%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络的宽度如何影响深度学习模型的性能？</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032995%26idx%3D2%26sn%3D28b065415c2d8a11345531f1284413d0%26chksm%3D8712b75eb0653e48f46de857b14d6e029f08a5c0336928fc638eac1f8287aefea01a262be1e2%26token%3D2097035342%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】学习率和batchsize如何影响模型的性能？</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649033134%26idx%3D1%26sn%3D69a5be0c1677e55a0311269b0e481242%26chksm%3D8712b7d3b0653ec5211cfd57364bb7d4b8073e620f00f04de734ae2ae7b2e9179ae9d1468e58%26token%3D1855353646%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】残差网络的前世今生与原理</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649033716%26idx%3D1%26sn%3D71e6bc88057706ce864b30d3b176c863%26chksm%3D8712b589b0653c9f12a59fa81e68414b81e85532daef119e97b091c4abb6c7d4e393c3a695c9%26token%3D661271294%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】移动端高效网络，卷积拆分和分组的精髓</a></p><p></p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }
            ], 
            "comments": [
                {
                    "userName": "Mario", 
                    "userLink": "https://www.zhihu.com/people/045a0c7e886f99beba56c859a68693eb", 
                    "content": "后面的多尺度，多分辨率和多精度就跟不上了[好奇]", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "感兴趣的话，我们星球有更多", 
                            "likes": 0, 
                            "replyToAuthor": "Mario"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/65767386", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 34, 
            "title": "【AI不惑境】残差网络的前世今生与原理", 
            "content": "<p>大家好，这是专栏<b>《AI不惑境》</b>的第五篇文章，讲述残差网络的来龙去脉和背后的原理。</p><p>进入到不惑境界，就是向高手迈进的开始了，在这个境界需要自己独立思考。如果说学习是一个从模仿，到追随，到创造的过程，那么到这个阶段，应该跃过了模仿和追随的阶段，进入了创造的阶段。从这个境界开始，讲述的问题可能不再有答案，更多的是激发大家一起来思考。</p><p>作者&amp;编辑 | 言有三 </p><p>在深度学习模型发展史中，残差网络因其简单而有效的结构与异常有效的结果而占据了非常重要的位置，今天就来仔细说说它的来龙去脉。</p><h2><b>1 残差网络之前的历史</b><br/></h2><p>残差连接的思想起源于中心化，在神经网络系统中，对输入数据等进行中心化转换，即将数据减去均值，被广泛验证有利于加快系统的学习速度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-60e71edeffa3c809e5373028a579db3f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"326\" data-rawheight=\"76\" class=\"content_image\" width=\"326\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;326&#39; height=&#39;76&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"326\" data-rawheight=\"76\" class=\"content_image lazy\" width=\"326\" data-actualsrc=\"https://pic4.zhimg.com/v2-60e71edeffa3c809e5373028a579db3f_b.jpg\"/></figure><p>Schraudolph[1]将这样的思想拓展到了梯度的反向传播中，不仅是输入和隐藏层单元的激活值要中心化，梯度误差以及权重的更新也可以中心化，这便是通过将输入输出进行连接的<b>shortcut connection，也称为跳层连接</b>技术。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-706ff7a4ade7537fb024bba52e25b750_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"502\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-706ff7a4ade7537fb024bba52e25b750_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;502&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"502\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-706ff7a4ade7537fb024bba52e25b750_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-706ff7a4ade7537fb024bba52e25b750_b.jpg\"/></figure><p><b>在1998年的时候，它们提出了将网络分解为biased和centered两个子网络的思想，通过并行训练两个子网络，分别学习线性和非线性变换部分，不仅降低了各个网络的学习难度，也大大提升了梯度下降算法的训练速度。</b></p><p><b>Raiko等人则在论文[2]中更加细致地研究了shortcut connections对模型能力的影响，在网络包含2到5个隐藏层，使用与不使用正则化等各种环境配置下，MNIST和CIFAR图像分类任务和MNIST图像重构任务的结果都表明，这样的技术提高了随机梯度下降算法的学习能力，并且提高了模型的泛化能力。</b></p><p><b>Srivastava等人在2015年的文章[3]中提出了highway network，对深层神经网络使用了跳层连接，明确提出了残差结构，借鉴了来自于LSTM的控制门的思想。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b6dd607f1eb2f9761ce173c3aa7bc89e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"858\" data-rawheight=\"84\" class=\"origin_image zh-lightbox-thumb\" width=\"858\" data-original=\"https://pic3.zhimg.com/v2-b6dd607f1eb2f9761ce173c3aa7bc89e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;858&#39; height=&#39;84&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"858\" data-rawheight=\"84\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"858\" data-original=\"https://pic3.zhimg.com/v2-b6dd607f1eb2f9761ce173c3aa7bc89e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b6dd607f1eb2f9761ce173c3aa7bc89e_b.jpg\"/></figure><p>当T(x,Wt)=0时，y=x，T(x,Wt)=1时，y=H(x,Wh)T(x,Wt)。在该文章中，研究者没有使用特殊的初始化方法等技巧，也能够训练上千层的网络。</p><p>从以上的发展可以看出来，跳层连接由来已久。</p><h2><b>2 残差网络</b></h2><p>何凯明等人在2015年的论文[4]中正式提出了ResNet，简化了highway network中的形式，表达式如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-fda190ea9dac3f37a71510484d71f1b4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"374\" data-rawheight=\"76\" class=\"content_image\" width=\"374\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;374&#39; height=&#39;76&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"374\" data-rawheight=\"76\" class=\"content_image lazy\" width=\"374\" data-actualsrc=\"https://pic1.zhimg.com/v2-fda190ea9dac3f37a71510484d71f1b4_b.jpg\"/></figure><p>相比于之前的卷积和池化相互堆叠的网络，其基本的结构单元如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7205eb8d6f404aa7b2423fbb2e182631_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"977\" data-rawheight=\"561\" class=\"origin_image zh-lightbox-thumb\" width=\"977\" data-original=\"https://pic2.zhimg.com/v2-7205eb8d6f404aa7b2423fbb2e182631_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;977&#39; height=&#39;561&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"977\" data-rawheight=\"561\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"977\" data-original=\"https://pic2.zhimg.com/v2-7205eb8d6f404aa7b2423fbb2e182631_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7205eb8d6f404aa7b2423fbb2e182631_b.jpg\"/></figure><p>当我们直接将一个输入添加到输出的时候，输出y可以明确的拆分为H(x,Wh)和x的线性叠加，从而让梯度多了一条恒等映射通道，这被认为对于深层网络的训练是非常重要的，一个典型的resnet网络结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-cf7250b9c2888e0752a5343917519e7b_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"316\" data-rawheight=\"528\" data-thumbnail=\"https://pic4.zhimg.com/v2-cf7250b9c2888e0752a5343917519e7b_b.jpg\" class=\"content_image\" width=\"316\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;316&#39; height=&#39;528&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"316\" data-rawheight=\"528\" data-thumbnail=\"https://pic4.zhimg.com/v2-cf7250b9c2888e0752a5343917519e7b_b.jpg\" class=\"content_image lazy\" width=\"316\" data-actualsrc=\"https://pic4.zhimg.com/v2-cf7250b9c2888e0752a5343917519e7b_b.gif\"/></figure><p>resnet在当年的ImageNet的多项竞赛中取得冠军，风头一时无两，随后被广泛深扒。关于ResNet的详细解读，大家可以关注我们的往期文章。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9d87295ed7e062eea4e8cae1c22fe16a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"972\" data-rawheight=\"346\" class=\"origin_image zh-lightbox-thumb\" width=\"972\" data-original=\"https://pic3.zhimg.com/v2-9d87295ed7e062eea4e8cae1c22fe16a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;972&#39; height=&#39;346&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"972\" data-rawheight=\"346\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"972\" data-original=\"https://pic3.zhimg.com/v2-9d87295ed7e062eea4e8cae1c22fe16a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9d87295ed7e062eea4e8cae1c22fe16a_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></li></ul><h2><b>3 残差网络结构的发展</b></h2><p>对于残差网络的研究，大部分集中在两个方向<b>，第一个是结构方面的研究，另一个是残差网络原理的研究，首先说几个具有代表性的结构，不会将所有结构都包含进来，如果感兴趣大家可以关注知识星球有三AI。</b></p><p><b>3.1、更密集的跳层连接DenseNet</b></p><p>如果将ResNet的跳层结构发挥到极致，即每两层都相互连接，那么就成为了DenseNet，关于DenseNet的详细解读，可以查看我们的往期文章。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4db7b4790b8a052875a0fe18eba2f791_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"769\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-4db7b4790b8a052875a0fe18eba2f791_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;769&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"769\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-4db7b4790b8a052875a0fe18eba2f791_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4db7b4790b8a052875a0fe18eba2f791_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></li></ul><p>DenseNet是一个非常高效率的网络结构，以更少的通道数更低的计算代价，获得比ResNet更强大的性能。</p><p><b>3.2、更多并行的跳层连接</b></p><p>如果将ResNet和DenseNet分为作为两个通道并行处理，之后再将信息融合，就可以得到Dual Path Network，网络结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4fb91a0092faa745cf1835bbba7d8c5f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"894\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-4fb91a0092faa745cf1835bbba7d8c5f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;894&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"894\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-4fb91a0092faa745cf1835bbba7d8c5f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4fb91a0092faa745cf1835bbba7d8c5f_b.jpg\"/></figure><p>其背后的思想是resnet对于重用信息更有效，而densenet对于学习新的信息更有效，这个结构在最后一届ImageNet竞赛中也取得了很好的成绩，分类比赛的亚军，定位比赛的冠军。类似的结构变种还有如下的结构，不再一一赘述。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-79912feda3009b02300384b38608e31f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"976\" data-rawheight=\"207\" class=\"origin_image zh-lightbox-thumb\" width=\"976\" data-original=\"https://pic4.zhimg.com/v2-79912feda3009b02300384b38608e31f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;976&#39; height=&#39;207&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"976\" data-rawheight=\"207\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"976\" data-original=\"https://pic4.zhimg.com/v2-79912feda3009b02300384b38608e31f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-79912feda3009b02300384b38608e31f_b.jpg\"/></figure><p>当然，还有比上面的Dual Path Network更加简单的并行结构，即直接使用多个完全独立且相同的分支并行处理，然后合并。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9b787adde09c5ee88a521710398b5d8c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"513\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-9b787adde09c5ee88a521710398b5d8c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;513&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"513\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-9b787adde09c5ee88a521710398b5d8c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-9b787adde09c5ee88a521710398b5d8c_b.jpg\"/></figure><p>也有更加复杂的变种，即所谓的resnet in resnet结构，如下图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-94b45877805b9d5872c7f4d9ffc888c6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"413\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-94b45877805b9d5872c7f4d9ffc888c6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;413&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"413\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-94b45877805b9d5872c7f4d9ffc888c6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-94b45877805b9d5872c7f4d9ffc888c6_b.jpg\"/></figure><p>篇幅原因本文不对所有残差网络的结构设计思想和发展做更多解读，感兴趣请移步知识星球《有三AI》。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-91c77f5ae147c9a4d4f66a71d121ff56_b.jpg\"/></figure><h2><b>4 残差网络结构为什么这么好用？</b></h2><p>关于残差网络为什么有效，研究众多，这里我们就集中讲述几个主流的思路。</p><p><b>4.1、简化了学习过程，增强了梯度传播</b></p><p>相比于学习原始的信号，残差网络学习的是信号的差值，这在许多的研究中被验证是更加有效的，它简化了学习的过程。</p><p><b>根据我们前面的内容可知，在一定程度上，网络越深表达能力越强，性能越好。</b></p><p>然而随着网络深度的增加，带来了许多优化相关的问题，比如梯度消散，梯度爆炸。</p><p><b>在残差结构被广泛使用之前，研究人员通过研究更好的优化方法，更好的初始化策略，添加Batch Normalization，提出Relu等激活函数的方法来对深层网络梯度传播面临的问题进行缓解，但是仍然不能解决根本问题。</b></p><p>假如我们有这样一个网络：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-f27687c8a951d11b64086142d60cea61_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"546\" data-rawheight=\"286\" class=\"origin_image zh-lightbox-thumb\" width=\"546\" data-original=\"https://pic2.zhimg.com/v2-f27687c8a951d11b64086142d60cea61_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;546&#39; height=&#39;286&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"546\" data-rawheight=\"286\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"546\" data-original=\"https://pic2.zhimg.com/v2-f27687c8a951d11b64086142d60cea61_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-f27687c8a951d11b64086142d60cea61_b.jpg\"/></figure><p>其中f为卷积操作，g为非线性变换函数，k为分类器，依靠误差的链式反向传播法则，损失loss对f的导数为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0a719ba109d0f75392157eb6dea2a49f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"684\" data-rawheight=\"141\" class=\"origin_image zh-lightbox-thumb\" width=\"684\" data-original=\"https://pic4.zhimg.com/v2-0a719ba109d0f75392157eb6dea2a49f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;684&#39; height=&#39;141&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"684\" data-rawheight=\"141\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"684\" data-original=\"https://pic4.zhimg.com/v2-0a719ba109d0f75392157eb6dea2a49f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0a719ba109d0f75392157eb6dea2a49f_b.jpg\"/></figure><p>如果其中某一个导数很小，多次连乘后梯度可能越来越小，这就是常说的梯度消散，对于深层网络，从靠近输出的深层传到靠近输入的浅层时梯度值非常小，使得浅层无法有效地更新。</p><p><b>如果使用了残差结构，因为导数包含了恒等项，仍然能够有效的反向传播。</b></p><p>举一个非常直观的例子方便理解，假如有一个网络，输入x=1，非残差网络为G，残差网络为H，其中H(x)=F(x)+x，假如有这样的输入关系：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-05eaf91d17bf7f679972d4838b9cecc2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"446\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-05eaf91d17bf7f679972d4838b9cecc2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;446&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"446\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-05eaf91d17bf7f679972d4838b9cecc2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-05eaf91d17bf7f679972d4838b9cecc2_b.jpg\"/></figure><p>因为两者各自是对G的参数和F的参数进行更新，可以看出变化对F的影响远远大于G，说明引入残差后的映射对输出的变化更敏感，这样是有利于网络进行传播的。</p><p><b>4.2、打破了网络的不对称性[5]</b></p><p>虽然残差网络可以通过跳层连接，增强了梯度的流动，从而使得上千层网络的训练成为可能，<b>不过相关的研究表面残差网络的有效性，更加体现在减轻了神经网络的退化</b>。</p><p><b>如果在网络中每个层只有少量的隐藏单元对不同的输入改变它们的激活值，而大部分隐藏单元对不同的输入都是相同的反应，此时整个权重矩阵的秩不高。并且随着网络层数的增加，连乘后使得整个秩变的更低，这就是我们常说的网络退化问题。</b></p><p>虽然权重矩阵是一个很高维的矩阵，但是大部分维度却没有信息，使得网络的表达能力没有看起来那么强大。这样的情况一定程度上来自于网络的对称性，而残差连接打破了网络的对称性。</p><p>下面展示了三种跳层连接恢复网络表达能力的案例，分别是<b>消除输入和权重零奇点，打破对称性，线性依赖性</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-0615cc01d60470a5ab37c2472c284482_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-0615cc01d60470a5ab37c2472c284482_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;238&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-0615cc01d60470a5ab37c2472c284482_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-0615cc01d60470a5ab37c2472c284482_b.jpg\"/></figure><p><b>4.3、增强了网络的泛化能力[6]</b></p><p>有一些研究表明，深层的残差网络可以看做是不同深度的浅层神经网络的ensemble，训练完一个深层网络后，在测试的时候随机去除某个网络层，并不会使得网络的性能有很大的退化,而对于VGG网络来说，删减任何一层都会造成模型的性能奔溃，如下图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0b8f0f3a65f363d8b4624e787895c097_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"376\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0b8f0f3a65f363d8b4624e787895c097_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;376&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"376\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-0b8f0f3a65f363d8b4624e787895c097_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0b8f0f3a65f363d8b4624e787895c097_b.jpg\"/></figure><p>甚至去除和打乱一些网络层，性能的下降也是一个很平滑的过程。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-569a8a8389dac48822d960481d31063a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"436\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-569a8a8389dac48822d960481d31063a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;436&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"436\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-569a8a8389dac48822d960481d31063a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-569a8a8389dac48822d960481d31063a_b.jpg\"/></figure><p><b>以上都证明了残差结构其实是多个更浅的网络的集成，所以它的有效深度看起来表面的那么深，因此优化自然也没有那么难了。</b></p><p>关于残差，还有需要的研究，大家可以持续关注我们公众号和知乎，以及星球。</p><p>参考文献</p><p>[1] Schraudolph N. Accelerated gradient descent by factor-centering decomposition[J]. Technical report/IDSIA, 1998, 98.</p><p>[2] Raiko T, Valpola H, LeCun Y. Deep learning made easier by linear transformations in perceptrons[C]//Artificial intelligence and statistics. 2012: 924-932.</p><p>[3] Srivastava R K, Greff K, Schmidhuber J. Training very deep networks[C]//Advances in neural information processing systems. 2015: 2377-2385.</p><p>[4] He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.</p><p>[5] Orhan A E, Pitkow X. Skip Connections Eliminate Singularities[J]. international conference on learning representations, 2018.</p><p>[6] Veit A, Wilber M J, Belongie S. Residual networks behave like ensembles of relatively shallow networks[C]//Advances in neural information processing systems. 2016: 550-558.</p><p><b>总结</b></p><p>通过跳层连接而来的残差网络虽然结构非常简单，但是却异常有用，在很多的应用领域中都被广泛使用，其原理也在被进一步广泛研究中，大家可以持续关注，更多的内容我们会在知识星球《有三AI》中展示。</p><p><i>下期预告：深度学习中的多尺度设计与应用。</i></p><p><b><u>近期直播</u></b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ace53ac05056cd73d61a3a3598b64726_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"371\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic3.zhimg.com/v2-ace53ac05056cd73d61a3a3598b64726_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;371&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"371\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic3.zhimg.com/v2-ace53ac05056cd73d61a3a3598b64726_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ace53ac05056cd73d61a3a3598b64726_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-fb8cd49c0deca0a3498edef4b915dc4d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-fb8cd49c0deca0a3498edef4b915dc4d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-fb8cd49c0deca0a3498edef4b915dc4d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-fb8cd49c0deca0a3498edef4b915dc4d_b.jpg\"/></figure><p><b><u>有三AI纪念版扑克牌预售</u></b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-df0f294a39d3dcff7797780b10b9ea90_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1668\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-df0f294a39d3dcff7797780b10b9ea90_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1668&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1668\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-df0f294a39d3dcff7797780b10b9ea90_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-df0f294a39d3dcff7797780b10b9ea90_b.jpg\"/></figure><p><i>下期预告：跳层连接对网络性能的影响。</i></p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032883%26idx%3D1%26sn%3D9e557cf7bff4bceecb522f28b074c25e%26chksm%3D8712b6ceb0653fd8ec4c7a9f39e5905de421dd08b7dbe49c55bbb25806d7c824089ae36f014a%26token%3D1169783853%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络的宽度如何影响深度学习模型的性能？</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032995%26idx%3D2%26sn%3D28b065415c2d8a11345531f1284413d0%26chksm%3D8712b75eb0653e48f46de857b14d6e029f08a5c0336928fc638eac1f8287aefea01a262be1e2%26token%3D2097035342%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】学习率和batchsize如何影响模型的性能？</a> </p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649033134%26idx%3D1%26sn%3D69a5be0c1677e55a0311269b0e481242%26chksm%3D8712b7d3b0653ec5211cfd57364bb7d4b8073e620f00f04de734ae2ae7b2e9179ae9d1468e58%26token%3D1855353646%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】残差网络的前世今生与原理</a></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/64864995", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 164, 
            "title": "【AI不惑境】学习率和batchsize如何影响模型的性能？", 
            "content": "<p>大家好，这是专栏<b>《AI不惑境》</b>的第四篇文章，讲述学习率以及batchsize与模型性能的关系。</p><p>进入到不惑境界，就是向高手迈进的开始了，在这个境界需要自己独立思考。如果说学习是一个从模仿，到追随，到创造的过程，那么到这个阶段，应该跃过了模仿和追随的阶段，进入了创造的阶段。从这个境界开始，讲述的问题可能不再有答案，更多的是激发大家一起来思考。</p><p>作者&amp;编辑 | 言有三 </p><p><br/>前几期我们讲述了数据，模型的深度，宽度对深度学习模型性能的影响，这一次我们讲述<b>学习率和batchsize对模型性能的影响，在实践中这两个参数往往一起调整</b>。</p><h2><b>1 为什么说学习率和batchsize</b><br/></h2><p>目前深度学习模型多采用批量随机梯度下降算法进行优化，随机梯度下降算法的原理如下，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ad229aeae91bdc7a73b54052fa264cbf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1066\" data-rawheight=\"272\" class=\"origin_image zh-lightbox-thumb\" width=\"1066\" data-original=\"https://pic4.zhimg.com/v2-ad229aeae91bdc7a73b54052fa264cbf_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1066&#39; height=&#39;272&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1066\" data-rawheight=\"272\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1066\" data-original=\"https://pic4.zhimg.com/v2-ad229aeae91bdc7a73b54052fa264cbf_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ad229aeae91bdc7a73b54052fa264cbf_b.jpg\"/></figure><p>n是批量大小(batchsize)，η是学习率(learning rate)。可知道除了梯度本身，<b>这两个因子直接决定了模型的权重更新</b>，从优化本身来看它们是影响模型性能收敛最重要的参数。</p><p><b>学习率直接影响模型的收敛状态，batchsize则影响模型的泛化性能</b>，两者又是分子分母的直接关系，相互也可影响，因此这一次来详述它们对模型性能的影响。</p><h2><b>2 学习率如何影响模型性能？</b></h2><p>通常我们都需要合适的学习率才能进行学习，要达到一个强的凸函数的最小值，学习率的调整应该满足下面的条件，i代表第i次更新。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-670b48d82d100c9b745871b024aeee9f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"364\" data-rawheight=\"340\" class=\"content_image\" width=\"364\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;364&#39; height=&#39;340&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"364\" data-rawheight=\"340\" class=\"content_image lazy\" width=\"364\" data-actualsrc=\"https://pic4.zhimg.com/v2-670b48d82d100c9b745871b024aeee9f_b.jpg\"/></figure><p>第一个式子决定了不管初始状态离最优状态多远，总是可以收敛。第二个式子约束了学习率随着训练进行有效地降低，保证收敛稳定性，各种自适应学习率算法本质上就是不断在调整各个时刻的学习率。</p><p>学习率决定了权重迭代的步长，因此是一个非常敏感的参数，它对模型性能的影响体现在两个方面，<b>第一个是初始学习率的大小，第二个是学习率的变换方案。</b></p><p><b>2.1、初始学习率大小对模型性能的影响</b></p><p>初始的学习率肯定是有一个最优值的，过大则导致模型不收敛，过小则导致模型收敛特别慢或者无法学习，下图展示了不同大小的学习率下模型收敛情况的可能性，图来自于cs231n。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d9640b0170f3371f97d16683f0a39594_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"459\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb\" width=\"459\" data-original=\"https://pic1.zhimg.com/v2-d9640b0170f3371f97d16683f0a39594_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;459&#39; height=&#39;414&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"459\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"459\" data-original=\"https://pic1.zhimg.com/v2-d9640b0170f3371f97d16683f0a39594_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d9640b0170f3371f97d16683f0a39594_b.jpg\"/></figure><p>那么在不考虑具体的优化方法的差异的情况下，怎样确定最佳的初始学习率呢？</p><p>通常可以采用最简单的搜索法，即从小到大开始训练模型，然后记录损失的变化，通常会记录到这样的曲线。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-0ec63261a52e342113964e853708e7ca_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"390\" data-rawheight=\"266\" class=\"content_image\" width=\"390\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;390&#39; height=&#39;266&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"390\" data-rawheight=\"266\" class=\"content_image lazy\" width=\"390\" data-actualsrc=\"https://pic3.zhimg.com/v2-0ec63261a52e342113964e853708e7ca_b.jpg\"/></figure><p>随着学习率的增加，损失会慢慢变小，而后增加，而最佳的学习率就可以从其中损失最小的区域选择。</p><p>有经验的工程人员常常根据自己的经验进行选择，比如0.1，0.01等。</p><p>随着学习率的增加，模型也可能会从欠拟合过度到过拟合状态，在大型数据集上的表现尤其明显，笔者之前在Place365上使用DPN92层的模型进行过实验。随着学习率的增强，模型的训练精度增加，直到超过验证集。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-3d4d656ce650ce528fe00ac3e80693ec_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"306\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-3d4d656ce650ce528fe00ac3e80693ec_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;306&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"306\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-3d4d656ce650ce528fe00ac3e80693ec_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-3d4d656ce650ce528fe00ac3e80693ec_b.jpg\"/></figure><p><b>2.2、学习率变换策略对模型性能的影响</b></p><p>学习率在模型的训练过程中很少有不变的，通常会有两种方式对学习率进行更改，一种是<b>预设规则学习率变化法</b>，一种是<b>自适应学习率变换方法</b>。</p><p><b>2.2.1 预设规则学习率变化法</b></p><p>常见的策略包括fixed，step，exp，inv，multistep，poly，sigmoid等，集中展示如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-43288f39babd0de96f337c69f361f2ce_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb\" width=\"619\" data-original=\"https://pic3.zhimg.com/v2-43288f39babd0de96f337c69f361f2ce_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;619&#39; height=&#39;477&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"619\" data-original=\"https://pic3.zhimg.com/v2-43288f39babd0de96f337c69f361f2ce_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-43288f39babd0de96f337c69f361f2ce_b.jpg\"/></figure><p>笔者之前做过一个实验来观察在SGD算法下，各种学习率变更策略对模型性能的影响，具体的结果如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a049b58d49f744f80a9d9f0ac29c9918_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-a049b58d49f744f80a9d9f0ac29c9918_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-a049b58d49f744f80a9d9f0ac29c9918_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a049b58d49f744f80a9d9f0ac29c9918_b.jpg\"/></figure><p>从结果来看：</p><ul><li>step，multistep方法的收敛效果最好，这也是我们平常用它们最多的原因。虽然学习率的变化是最离散的，但是并不影响模型收敛到比较好的结果。</li><li>其次是exp，poly。它们能取得与step，multistep相当的结果，也是因为学习率以比较好的速率下降，虽然变化更加平滑，但是结果也未必能胜过step和multistep方法，在这很多的研究中都得到过验证，离散的学习率变更策略不影响模型的学习。</li><li>inv和fixed的收敛结果最差。这是比较好解释的，因为fixed方法始终使用了较大的学习率，而inv方法的学习率下降过程太快。</li></ul><p>关于以上内容的完整分析结果，可以查看往期文章：</p><p><u><b><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030692%26idx%3D1%26sn%3D6322e8eec12d8a8b60f578a9ebb4b42c%26chksm%3D8712be59b065374f00dc9b3715e6453e2de5d05262ee4eac47ef5efe6d167703af67f5882029%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型训练】如何选择最适合你的学习率变更策略</a></b></u></p><p>从上面的结果可以看出，对于采用非自适应学习率变换的方法，学习率的绝对值对模型的性能有较大影响，研究者常使用step变化策略。</p><p>目前学术界也在探索一些最新的研究方法，比如cyclical learning rate，示意图如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0bb7ad82f7cd1c23d96e66fcbccaa533_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"912\" data-rawheight=\"564\" class=\"origin_image zh-lightbox-thumb\" width=\"912\" data-original=\"https://pic4.zhimg.com/v2-0bb7ad82f7cd1c23d96e66fcbccaa533_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;912&#39; height=&#39;564&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"912\" data-rawheight=\"564\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"912\" data-original=\"https://pic4.zhimg.com/v2-0bb7ad82f7cd1c23d96e66fcbccaa533_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0bb7ad82f7cd1c23d96e66fcbccaa533_b.jpg\"/></figure><p><b>实验证明通过设置上下界，让学习率在其中进行变化，可以在模型迭代的后期更有利于克服因为学习率不够而无法跳出鞍点的情况。</b></p><p>确定学习率上下界的方法则可以使用LR range test方法，即使用不同的学习率得到精度曲线，然后获得精度升高和下降的两个拐点，或者将精度最高点设置为上界，下界设置为它的1/3大小。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d93b708210d81d896e3d0b8349b3d66d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"866\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-d93b708210d81d896e3d0b8349b3d66d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;866&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"866\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-d93b708210d81d896e3d0b8349b3d66d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d93b708210d81d896e3d0b8349b3d66d_b.jpg\"/></figure><p>SGDR方法则是比cyclical learning rate变换更加平缓的周期性变化方法，如下图，效果与cyclical learning rate类似。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-317cd6d9bbaa0c6a7b74016a03f68d1d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"592\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"592\" data-original=\"https://pic2.zhimg.com/v2-317cd6d9bbaa0c6a7b74016a03f68d1d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;592&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"592\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"592\" data-original=\"https://pic2.zhimg.com/v2-317cd6d9bbaa0c6a7b74016a03f68d1d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-317cd6d9bbaa0c6a7b74016a03f68d1d_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>2.2.2 自适应学习率变化法</b></p><p>自适应学习率策略以Adagrad，Adam等为代表，我们在公众号已经说得非常多了，这里就不再做原理上的讲述，可以查看往期介绍：</p><p><u><b><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></b></u></p><p>原理上各种改进的自适应学习率算法都比SGD算法更有利于性能的提升，但实际上精细调优过的SGD算法可能取得更好的结果，在很多的论文[3-4]中都得到过验证，我们在实验中也多次证明过这一点，如下图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ba0df33ec3c9e3eced3d1576f8fe2107_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"944\" data-rawheight=\"707\" class=\"origin_image zh-lightbox-thumb\" width=\"944\" data-original=\"https://pic4.zhimg.com/v2-ba0df33ec3c9e3eced3d1576f8fe2107_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;944&#39; height=&#39;707&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"944\" data-rawheight=\"707\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"944\" data-original=\"https://pic4.zhimg.com/v2-ba0df33ec3c9e3eced3d1576f8fe2107_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ba0df33ec3c9e3eced3d1576f8fe2107_b.jpg\"/></figure><p><b>2.3、小结</b></p><p>不考虑其他任何因素，学习率的大小和迭代方法本身就是一个非常敏感的参数。如果经验不够，还是考虑从Adam系列方法的默认参数开始，如果经验丰富，可以尝试更多的实验配置。</p><h2><b>3 Batchsize如何影响模型性能？</b></h2><p>模型性能对batchsize虽然没有学习率那么敏感，但是在进一步提升模型性能时，batchsize就会成为一个非常关键的参数。</p><p><b>3.1 大的batchsize减少训练时间，提高稳定性</b></p><p>这是肯定的，同样的epoch数目，大的batchsize需要的batch数目减少了，所以可以减少训练时间，目前已经有多篇公开论文在1小时内训练完ImageNet数据集。另一方面，大的batch size梯度的计算更加稳定，因为模型训练曲线会更加平滑。在微调的时候，大的batch size可能会取得更好的结果。</p><p><b>3.2 大的batchsize导致模型泛化能力下降</b></p><p>在一定范围内，增加batchsize有助于收敛的稳定性，但是随着batchsize的增加，模型的性能会下降，如下图，来自于文[5]。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e9ebb41acf19d7502646e99b909a0bd4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"599\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-e9ebb41acf19d7502646e99b909a0bd4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;599&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"599\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-e9ebb41acf19d7502646e99b909a0bd4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e9ebb41acf19d7502646e99b909a0bd4_b.jpg\"/></figure><p>这是研究者们普遍观测到的规律，虽然可以通过一些技术缓解。这个导致性能下降的batch size在上图就是8000左右。</p><p>那么这是为什么呢？</p><p><b>研究[6]表明大的batchsize收敛到sharp minimum，而小的batchsize收敛到flat minimum，后者具有更好的泛化能力。</b>两者的区别就在于变化的趋势，一个快一个慢，如下图，造成这个现象的主要原因是小的batchsize带来的噪声有助于逃离sharp minimum。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-0c8205e13546eb21f0739f156fc083f6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"462\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-0c8205e13546eb21f0739f156fc083f6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;462&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"462\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-0c8205e13546eb21f0739f156fc083f6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-0c8205e13546eb21f0739f156fc083f6_b.jpg\"/></figure><p>Hoffer[7]等人的研究表明，<b>大的batchsize性能下降是因为训练时间不够长，本质上并不少batchsize的问题</b>，在同样的epochs下的参数更新变少了，因此需要更长的迭代次数。</p><p><b>3.3 小结</b></p><p>batchsize在变得很大(超过一个临界点)时，会降低模型的泛化能力。在此临界点之下，模型的性能变换随batch size通常没有学习率敏感。</p><h2><b>4 学习率和batchsize的关系</b></h2><p><b>通常当我们增加batchsize为原来的N倍时，要保证经过同样的样本后更新的权重相等，按照线性缩放规则，学习率应该增加为原来的N倍[5]。但是如果要保证权重的方差不变，则学习率应该增加为原来的sqrt(N)倍[7]，目前这两种策略都被研究过，使用前者的明显居多。</b></p><p>从两种常见的调整策略来看，学习率和batchsize都是同时增加的。学习率是一个非常敏感的因子，不可能太大，否则模型会不收敛。同样batchsize也会影响模型性能，那实际使用中都如何调整这两个参数呢？</p><p>研究[8]表明，<b>衰减学习率可以通过增加batchsize来实现类似的效果</b>，这实际上从SGD的权重更新式子就可以看出来两者确实是等价的，文中通过充分的实验验证了这一点。</p><p>研究[9]表明，<b>对于一个固定的学习率，存在一个最优的batchsize能够最大化测试精度</b>，这个batchsize和学习率以及训练集的大小正相关。</p><p>对此实际上是有两个建议：</p><ul><li><b>如果增加了学习率，那么batch size最好也跟着增加，这样收敛更稳定。</b></li><li><b>尽量使用大的学习率，因为很多研究都表明更大的学习率有利于提高泛化能力。</b>如果真的要衰减，可以尝试其他办法，比如增加batch size，学习率对模型的收敛影响真的很大，慎重调整。</li></ul><p>关于学习率和batch size这次就说这么多，感兴趣可以自行拓展阅读。</p><p>参考文献</p><p>[1] Smith L N. Cyclical learning rates for training neural networks[C]//2017 IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE, 2017: 464-472.</p><p>[2] Loshchilov I, Hutter F. Sgdr: Stochastic gradient descent with warm restarts[J]. arXiv preprint arXiv:1608.03983, 2016.</p><p>[3] Reddi S J, Kale S, Kumar S. On the convergence of adam and beyond[J]. 2018.</p><p>[4] Keskar N S, Socher R. Improving generalization performance by switching from adam to sgd[J]. arXiv preprint arXiv:1712.07628, 2017.</p><p>[5] Goyal P, Dollar P, Girshick R B, et al. Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour.[J]. arXiv: Computer Vision and Pattern Recognition, 2017.</p><p>[6] Keskar N S, Mudigere D, Nocedal J, et al. On large-batch training for deep learning: Generalization gap and sharp minima[J]. arXiv preprint arXiv:1609.04836, 2016.</p><p>[7] Hoffer E, Hubara I, Soudry D. Train longer, generalize better: closing the generalization gap in large batch training of neural networks[C]//Advances in Neural Information Processing Systems. 2017: 1731-1741.</p><p>[8] Smith S L, Kindermans P J, Ying C, et al. Don&#39;t decay the learning rate, increase the batch size[J]. arXiv preprint arXiv:1711.00489, 2017.</p><p>[9] Smith S L, Le Q V. A bayesian perspective on generalization and stochastic gradient descent[J]. arXiv preprint arXiv:1710.06451, 2017.</p><h2>总结：</h2><p>学习率和batchsize是影响模型性能极其重要的两个参数，我们应该非常谨慎地对待。</p><p>对于学习率算法，可以选择Adam等自适应学习率策略先训练模型看看收敛结果，再考虑使用SGD等算法进一步提升性能。对于Batchsize，大部分人并不会使用几千上万的batchsize，因此也不用担心模型性能的下降，用大一点(比如128)的batchsize吧，这样需要的迭代次数更少，结果也更加稳定。</p><p><i>下期预告：跳层连接对网络性能的影响。</i></p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032883%26idx%3D1%26sn%3D9e557cf7bff4bceecb522f28b074c25e%26chksm%3D8712b6ceb0653fd8ec4c7a9f39e5905de421dd08b7dbe49c55bbb25806d7c824089ae36f014a%26token%3D1169783853%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络的宽度如何影响深度学习模型的性能？</a> </p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032995%26idx%3D2%26sn%3D28b065415c2d8a11345531f1284413d0%26chksm%3D8712b75eb0653e48f46de857b14d6e029f08a5c0336928fc638eac1f8287aefea01a262be1e2%26token%3D2097035342%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】学习率和batchsize如何影响模型的性能？</a> </p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649033134%26idx%3D1%26sn%3D69a5be0c1677e55a0311269b0e481242%26chksm%3D8712b7d3b0653ec5211cfd57364bb7d4b8073e620f00f04de734ae2ae7b2e9179ae9d1468e58%26token%3D1855353646%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】残差网络的前世今生与原理</a></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "图像识别", 
                    "tagLink": "https://api.zhihu.com/topics/19588774"
                }
            ], 
            "comments": [
                {
                    "userName": "DayNight", 
                    "userLink": "https://www.zhihu.com/people/11650692acfa467931c044ae2b99a9aa", 
                    "content": "一般是梯度和除以batch size吧，这样求的是平均值，这样还能和学习率是线性关系吗？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<p>不是吗？</p>", 
                            "likes": 0, 
                            "replyToAuthor": "DayNight"
                        }, 
                        {
                            "userName": "DayNight", 
                            "userLink": "https://www.zhihu.com/people/11650692acfa467931c044ae2b99a9aa", 
                            "content": "就是学习率乘以梯度平均值，平均的值越多，学习率就该越大？", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>finding flatter minima with SGD 这里面经验地讨论了BS和LR的匹配关系</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<p>嗯，那个我也看过</p>", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "Tensor", 
                    "userLink": "https://www.zhihu.com/people/9b2cc768e3e3d4d21924d17a458447fc", 
                    "content": "<p>adam永不为奴</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<a class=\"comment_sticker\" href=\"https://pic3.zhimg.com/v2-cb8443f07a41298e45191cef11b90fd2.gif\" data-width=\"\" data-height=\"\">[干杯]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "Tensor"
                        }
                    ]
                }, 
                {
                    "userName": "toyama", 
                    "userLink": "https://www.zhihu.com/people/afb0f77b1c30b25f57df608ee77cf8b7", 
                    "content": "那用adam优化的话学习率衰减还有必要吗", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>Adam 也需要调学习率：<a href=\"http://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1705.08292.pdf\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">arxiv.org/pdf/1705.0829</span><span class=\"invisible\">2.pdf</span><span class=\"ellipsis\"></span></a></p><p></p>", 
                            "likes": 0, 
                            "replyToAuthor": "toyama"
                        }, 
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "[握手][握手][握手]", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "落寞也倾城", 
                    "userLink": "https://www.zhihu.com/people/1de0147175e4d8d0f90a9cad823ff94a", 
                    "content": "<p>最开始的欠拟合为什么会导致accuracy比val_acc一直少一大截呢？我的数据也一直有这个问题...</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "GorgeousShar", 
                    "userLink": "https://www.zhihu.com/people/dee078e628df73c1ff18ca1034c1417d", 
                    "content": "所说的大致方向没问题，但是相对于大学习大批次，实际上是因为lr没有降低到小数量级之前已经完成批次迭代，只是因为相比highrate lowbatch之下 参与的数据更多了。我更倾向二者都低才是增加泛化性能，最重要的一点是第一种不一定会收敛。", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>尽量使用大的学习率-&gt;有利于提高泛化性能；增加了学习率，就要同时增加batch size，大的batch size会导致泛化性能下降。这两者不是矛盾吗。。</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "不矛盾噢，单独只是增加batchsize，到一定阈值后会下降。而提高学习率提高batch说的是两者一起调整更好。", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/64219398", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 38, 
            "title": "【AI不惑境】网络宽度对模型性能有什么影响？", 
            "content": "<p>大家好，这是专栏<b>《AI不惑境》</b>的第三篇文章，讲述模型宽度与模型性能的关系。</p><p>进入到不惑境界，就是向高手迈进的开始了，在这个境界需要自己独立思考。如果说学习是一个从模仿，到追随，到创造的过程，那么到这个阶段，应该跃过了模仿和追随的阶段，进入了创造的阶段。从这个境界开始，讲述的问题可能不再有答案，更多的是激发大家一起来思考。</p><p>作者&amp;编辑 | 言有三 </p><p>上一期咱们说到深度学习模型之所以在各种任务中取得了成功，足够的网络深度起到了很关键的作用。</p><p>在一定的程度上，网络越深，性能越好。这一次我们来考虑另一个维度，<b>宽度，即通道(channel)的数量</b>。注意我们这里说的和宽度学习一类的模型没有关系，而是特指深度卷积神经网络的宽度。</p><h2><b>1 为什么需要足够的宽度</b></h2><p>网络更深带来的一个非常大的好处，就是逐层的抽象，不断精炼提取知识，如下图第一层学习到了边缘，第二层学习到了简单的形状，第三层开始学习到了目标的形状，更深的网络层能学习到更加复杂的表达。如果只有一层，那就意味着要学习的变换非常的复杂，这很难做到。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5a3d2cdf4e51ba3f99c46143bb214ef3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"996\" data-rawheight=\"1278\" class=\"origin_image zh-lightbox-thumb\" width=\"996\" data-original=\"https://pic4.zhimg.com/v2-5a3d2cdf4e51ba3f99c46143bb214ef3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;996&#39; height=&#39;1278&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"996\" data-rawheight=\"1278\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"996\" data-original=\"https://pic4.zhimg.com/v2-5a3d2cdf4e51ba3f99c46143bb214ef3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5a3d2cdf4e51ba3f99c46143bb214ef3_b.jpg\"/></figure><p><b>而宽度就起到了另外一个作用，那就是让每一层学习到更加丰富的特征，比如不同方向，不同频率的纹理特征。</b></p><p>下面是AlexNet模型的第一个卷积层的96个通道，尽管其中有一些形状和纹理相似的卷积核(这将成为优化宽度的关键)，还是可以看到各种各种的模式。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-7b6b463fd8c108253f92fa6045d62f40_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"668\" class=\"origin_image zh-lightbox-thumb\" width=\"700\" data-original=\"https://pic1.zhimg.com/v2-7b6b463fd8c108253f92fa6045d62f40_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;700&#39; height=&#39;668&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"668\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"700\" data-original=\"https://pic1.zhimg.com/v2-7b6b463fd8c108253f92fa6045d62f40_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-7b6b463fd8c108253f92fa6045d62f40_b.jpg\"/></figure><p>因为该卷积层的输入是RGB彩色图，所以这里就将其可视化为3通道的彩色图，每一个大小是11*11。</p><p><b>有的是彩色有的是灰色，说明有的侧重于提取纹理信息，有的侧重于提取颜色信息。</b></p><p>可以发现卷积核可视化之后和Gabor特征算子其实很像。Gabor特征算子就是使用一系列不同频率的Gabor滤波核与图像卷积，得到图像上的每个点和附近区域的频率分布。通常有8个方向，5个尺度。</p><p>太窄的网络，每一层能捕获的模式有限，此时网络再深都不可能提取到足够的信息往下层传递。</p><h2><b>2 网络到底需要多宽</b></h2><p>那么一个网络是越宽越好吗？我们又该如何利用好宽度呢？</p><p><b>2.1、网络宽度的下限在哪？</b></p><p>就算一个网络越宽越好，我们也希望效率越高越好，因为宽度带来的计算量是成平方数增长的。我们知道对于一个模型来说，浅层的特征非常重要，因此网络浅层的宽度是一个非常敏感的系数，那么发展了这么久，那些经典的网络第一个卷积层的宽度都是多少呢？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-0ee0221afc4e36f23f3617b14f02d3aa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1360\" data-rawheight=\"512\" class=\"origin_image zh-lightbox-thumb\" width=\"1360\" data-original=\"https://pic3.zhimg.com/v2-0ee0221afc4e36f23f3617b14f02d3aa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1360&#39; height=&#39;512&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1360\" data-rawheight=\"512\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1360\" data-original=\"https://pic3.zhimg.com/v2-0ee0221afc4e36f23f3617b14f02d3aa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-0ee0221afc4e36f23f3617b14f02d3aa_b.jpg\"/></figure><p>从AlexNet的96层到Vgg，Resnet等多数网络使用的64层，到高效网络Mobilenet的32层和Shufflenet的24层，似乎已经探到了下限，再往下性能就无法通过其他的方法来弥补了。</p><p>前次我们说过有许多的研究都验证了网络必须具有足够的深度才能逼近一些函数，比如文[1]中构造的3层网络，如果想要2层网络能够逼近表达能力，宽度会是指数级的增加。</p><p><b>那么反过来，是不是也有一些函数只有足够宽才能够表达呢？</b></p><p>针对网络宽度的研究虽不如网络深度多，但是也有学者做了相关研究。文[2]中就提出了任何Lebesgue-integrable函数，不能被一个宽度小于n的ReLU网络逼近，n是输入的维度，Lebesgue-integrable函数就是满足下面积分条件的函数。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7640a3af4fdbaed3ca7a8acc0953221d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"490\" data-rawheight=\"206\" class=\"origin_image zh-lightbox-thumb\" width=\"490\" data-original=\"https://pic2.zhimg.com/v2-7640a3af4fdbaed3ca7a8acc0953221d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;490&#39; height=&#39;206&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"490\" data-rawheight=\"206\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"490\" data-original=\"https://pic2.zhimg.com/v2-7640a3af4fdbaed3ca7a8acc0953221d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7640a3af4fdbaed3ca7a8acc0953221d_b.jpg\"/></figure><p><b>不过与深度不同的是，这样的一些函数宽度减少后，用于补偿模型性能的深度不是呈指数级增长，而是多项式增长，这似乎反应了宽度并没有深度那么重要。</b></p><p>不过不管怎么样，当前研究者们都从理论上探索了宽度和深度的下限，表明宽度和深度是缺一不可的。</p><p><b>2.2、网络宽度对模型性能的影响</b></p><p>网络的宽度自然也不是越宽越好，下面我们看看网络的宽度带来的性能提升。</p><p>我们看一下Mobilenet网络的结果，Mobilenet研究了网络的宽度对性能的影响，通过一个乘因子来对每一层的宽度进行缩放，它们试验了1, 0.75, 0.5和0.25共4个值。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-52bc5d0b8d6d6c92e560e939f04382c1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-52bc5d0b8d6d6c92e560e939f04382c1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;414&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"414\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-52bc5d0b8d6d6c92e560e939f04382c1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-52bc5d0b8d6d6c92e560e939f04382c1_b.jpg\"/></figure><p>从上面结果可以看得出来，性能是持续下降的。</p><p>那么，是不是网络越宽越好呢？下面我们还是通过几个实验来证明就是了。公开论文中使用的ImageNet等数据集研究者已经做过很多实验了，我们另外选了两个数据集和一个全卷积模型。</p><p>第一个数据集是GHIM数据集，第二个数据集是从Place20中选择了20个类别，可见两者一个比较简单，一个比较困难。</p><p>使用全卷积模型的基准结构，包含5层卷积和一个全连接层， 因此我们称其为allconv6吧，表示深度为6的一个卷积网络。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-843c5646b3288ee09d65badd26ce6d8e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"1242\" class=\"origin_image zh-lightbox-thumb\" width=\"624\" data-original=\"https://pic3.zhimg.com/v2-843c5646b3288ee09d65badd26ce6d8e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;624&#39; height=&#39;1242&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"1242\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"624\" data-original=\"https://pic3.zhimg.com/v2-843c5646b3288ee09d65badd26ce6d8e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-843c5646b3288ee09d65badd26ce6d8e_b.jpg\"/></figure><p>对这个网络的各个卷积层，我们也设置了不同的参数配置如下，每一个卷积层的stride都等于2。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-aed0eb019b13de2a394060bb122c7c30_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"475\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-aed0eb019b13de2a394060bb122c7c30_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;475&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"475\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-aed0eb019b13de2a394060bb122c7c30_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-aed0eb019b13de2a394060bb122c7c30_b.jpg\"/></figure><p>首先我们比较Allconv6_1，Allconv6_2，Allconv6_3，Allconv6_4这4个模型和基准模型的结果，它们是以Allconv6_1为基础的模型。</p><p><b>Allconv6_1是各个通道数为baseline的四分之一的网络</b>，而Allconv6_2，Allconv6_3，Allconv6_4分别是将Allconv6_1的第1，2层，第3，4层，第5层卷积通道数加倍的网络。</p><p>在GHIM数据集上的收敛结果如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a0c744fb65500882a4396f3238ffdf5c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"939\" data-rawheight=\"523\" class=\"origin_image zh-lightbox-thumb\" width=\"939\" data-original=\"https://pic1.zhimg.com/v2-a0c744fb65500882a4396f3238ffdf5c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;939&#39; height=&#39;523&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"939\" data-rawheight=\"523\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"939\" data-original=\"https://pic1.zhimg.com/v2-a0c744fb65500882a4396f3238ffdf5c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a0c744fb65500882a4396f3238ffdf5c_b.jpg\"/></figure><p>从上图结果可以看出，基准模型allconv6的性能最好，allconv6_2，allconv6_3，allconv6_4的模型性能都超过allconv6_1，说明此时增加任何一个网络层的通道数都有益于模型性能的提升，而且性能仍旧未超过基准模型。</p><p>然后我们再看allconv6_5，allconv6_6，allconv6_7，allconv6_8与基准模型的对比，<b>allconv6_5的各层的通道数只有baseline模型的一半</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-624e57241f5396412344ebf8df78a0ad_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"918\" data-rawheight=\"543\" class=\"origin_image zh-lightbox-thumb\" width=\"918\" data-original=\"https://pic2.zhimg.com/v2-624e57241f5396412344ebf8df78a0ad_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;918&#39; height=&#39;543&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"918\" data-rawheight=\"543\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"918\" data-original=\"https://pic2.zhimg.com/v2-624e57241f5396412344ebf8df78a0ad_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-624e57241f5396412344ebf8df78a0ad_b.jpg\"/></figure><p>从上图可以看出，模型的性能相差不大，这说明allconv6_5已经有足够好的宽度，再增加无益于性能的提升。这一点可以通过Place20上的实验结果进行证明，结果如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-057cf65b97506b15585283fa5228f7c1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"927\" data-rawheight=\"534\" class=\"origin_image zh-lightbox-thumb\" width=\"927\" data-original=\"https://pic2.zhimg.com/v2-057cf65b97506b15585283fa5228f7c1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;927&#39; height=&#39;534&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"927\" data-rawheight=\"534\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"927\" data-original=\"https://pic2.zhimg.com/v2-057cf65b97506b15585283fa5228f7c1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-057cf65b97506b15585283fa5228f7c1_b.jpg\"/></figure><p><b>2.3、网络宽度和深度谁更加重要？</b></p><p>这个问题目前没有答案，两者都很重要，不过目前的研究是模型性能对深度更加敏感，而调整宽度更加有利于提升模型性能。</p><p>Mobilenet的作者们将深层更窄的网络和浅层更宽的网络进行了对比，去掉了conv5_2到conv5_6这5层不改变分辨率的depth seperable卷积块，结果对比如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c2f3c6a3a88eb479beee77d5fbed8f43_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"319\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c2f3c6a3a88eb479beee77d5fbed8f43_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;319&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"319\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c2f3c6a3a88eb479beee77d5fbed8f43_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c2f3c6a3a88eb479beee77d5fbed8f43_b.jpg\"/></figure><p><b>更窄的网络拥有了更少的参数和更好的性能，这似乎验证了增加网络的深度比增加网络的宽度更有利于提升性能。</b></p><p>在Wide Resnet网络中，作者们在CIFAR10和CIFAR100上用参数只是稍微增加的一个16层的宽网络取得了比1000层的窄网络更好的性能，而且计算代价更低。在ImageNet上50层的宽Resnet在参数增加少量的基础上，也比相应的ResNet152层的性能更好。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a615f3cbeaa686dfc189d2c347966fb3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"239\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-a615f3cbeaa686dfc189d2c347966fb3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;239&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"239\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-a615f3cbeaa686dfc189d2c347966fb3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a615f3cbeaa686dfc189d2c347966fb3_b.jpg\"/></figure><p>另一方面，宽度相对于深度对GPU更加友好，因为GPU是并行处理的，许多研究也表明加宽网络比加深网络也更加容易训练。</p><p>这两个例子，一个网络深度影响更大，一个网络宽度影响更大，应该说无法比较谁更加重要，网络深度和宽度都很重要！倒是可以从这几个方向来看：</p><p>(1)深度相关计算量是O(N)，宽度则是O(N*N)，宽度更加敏感；(2)弥补深度不足需要的代价更高，而增加宽度提升性能更快；(3)增加宽度对GPU更加友好</p><p><b>根据笔者的经验，我们应该优先调整网络的宽度。</b></p><h2><b>3 如何更加有效地利用宽度？</b></h2><p>从前面的结果我们可知，网络的宽度是非常关键的参数，它体现在两个方面：(1) 宽度对计算量的贡献非常大。(2)宽度对性能的影响非常大。</p><p>我们的追求当然是越窄同时性能越高的网络，确实很贪婪，不过这是要实现的目标，可以从以下几个方向入手。</p><p><b>3.1、提高每一层通道的利用率</b></p><p>宽度既然这么重要，那么每一个通道就要好好利用起来，所以，第一个发力点，便是提高每一层的通道利用率。下面我们首先观察一下AlexNet网络的第一个卷积层。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-bc1eab3209280f724d42cb47e70afcc9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"724\" data-rawheight=\"702\" class=\"origin_image zh-lightbox-thumb\" width=\"724\" data-original=\"https://pic2.zhimg.com/v2-bc1eab3209280f724d42cb47e70afcc9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;724&#39; height=&#39;702&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"724\" data-rawheight=\"702\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"724\" data-original=\"https://pic2.zhimg.com/v2-bc1eab3209280f724d42cb47e70afcc9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-bc1eab3209280f724d42cb47e70afcc9_b.jpg\"/></figure><p>看出来了吧，有些卷积核很相似，相互之间可以通过反转得到，比如前面两个，那么就只需要学习一个就行了，这便是网络参数互补现象，如果将减半后的通道补上它的反，会基本上相当于原有的模型。</p><p>基于这个原理，文[3]便是通过输入通道取反和输入通道进行concat的方式来扩充通道。这样仅仅以原来一半的计算量便维持了原来的网络宽度和性能。</p><p><b>3.2、用其他通道的信息来补偿</b></p><p>这个思想在DenseNet网络中被发挥地淋漓尽致。DenseNet网络通过各层之间进行concat，可以在输入层保持非常小的通道数的配置下，实现高性能的网络。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4db7b4790b8a052875a0fe18eba2f791_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"769\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-4db7b4790b8a052875a0fe18eba2f791_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;769&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"769\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-4db7b4790b8a052875a0fe18eba2f791_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4db7b4790b8a052875a0fe18eba2f791_b.jpg\"/></figure><p>这一次的网络宽度对模型性能的影响就说到这里，更多请大家至我的知乎live中交流。</p><a href=\"https://www.zhihu.com/lives/1104173238430556160\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-41f5094bf991163a4166911db2806b1f_ipico.jpg\" data-image-width=\"3179\" data-image-height=\"3179\" class=\"internal\">如何设计性能更强的 CNN 网络结构？</a><p>参考文献</p><p>[1] Eldan R, Shamir O. The power of depth for feedforward neural networks[C]//Conference on learning theory. 2016: 907-940.</p><p>[2] Lu Z, Pu H, Wang F, et al. The expressive power of neural networks: A view from the width[C]//Advances in Neural Information Processing Systems. 2017: 6231-6239.</p><p>[3] Shang W, Sohn K, Almeida D, et al. Understanding and improving convolutional neural networks via concatenated rectified linear units[C]//international conference on machine learning. 2016: 2217-2225.</p><p>[4] Huang G, Liu Z, Van Der Maaten L, et al. Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4700-4708.</p><p><b>总结</b></p><p>深度学习成功的关键在于深，但是我们也不能忘了它的宽度，即通道数目，这对于模型性能的影响不亚于深度，在计算量上的影响甚至尤比深度更加重要。</p><p><i>下期预告：学习率和batchsize如何影响模型的性能。</i></p><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a> </p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032883%26idx%3D1%26sn%3D9e557cf7bff4bceecb522f28b074c25e%26chksm%3D8712b6ceb0653fd8ec4c7a9f39e5905de421dd08b7dbe49c55bbb25806d7c824089ae36f014a%26token%3D1169783853%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络的宽度如何影响深度学习模型的性能？</a></p><p></p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/63560913", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 22, 
            "title": "【AI不惑境】网络深度对深度学习模型性能有什么影响？", 
            "content": "<p>大家好，这是专栏<b>《AI不惑境》</b>的第二篇文章，讲述模型深度与模型性能的关系。</p><p>进入到不惑境界，就是向高手迈进的开始了，在这个境界需要自己独立思考。如果说学习是一个从模仿，到追随，到创造的过程，那么到这个阶段，应该跃过了模仿和追随的阶段，进入了创造的阶段。从这个境界开始，讲述的问题可能不再有答案，更多的是激发大家一起来思考。</p><p>作者&amp;编辑 | 言有三  </p><p><br/>深度学习模型之所以在各种任务中取得了成功，足够的网络深度起到了很关键的作用，那么是不是模型越深，性能就越好呢？</p><h2><b>1 为什么加深可以提升性能</b></h2><p>Bengio和LeCun在2017年的文章[1]中有这么一句话，&#34;We claim that most functions that can be represented compactly by deep architectures cannot be represented by a compact shallow architecture&#34;，大体意思就是大多数函数如果用一个深层结构刚刚好解决问题，那么就不可能用一个更浅的同样紧凑的结构来解决。</p><p>要解决比较复杂的问题，要么增加深度，要么增加宽度，而增加宽度的代价往往远高于深度。</p><p>Ronen Eldan等人甚至设计了一个能被小的3层网络表示，而不能被任意的2层网络表示的函数。总之，一定的深度是必要的。</p><p>那么随着模型的加深，到底有哪些好处呢？</p><p><b>1.1、更好拟合特征。</b></p><p>现在的深度学习网络结构的主要模块是卷积，池化，激活，这是一个标准的非线性变换模块。<b>更深的模型，意味着更好的非线性表达能力，可以学习更加复杂的变换，从而可以拟合更加复杂的特征输入。</b></p><p>看下面的一个对比图[2]，实线是一个只有一层，20个神经元的模型，虚线是一个2层，每一层10个神经元的模型。从图中可以看出，2层的网络有更好的拟合能力，这个特性也适用于更深的网络。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-bf3e0176b7c5cc55033c56d4b0d0fb01_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-bf3e0176b7c5cc55033c56d4b0d0fb01_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;312&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-bf3e0176b7c5cc55033c56d4b0d0fb01_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-bf3e0176b7c5cc55033c56d4b0d0fb01_b.jpg\"/></figure><p>1.2、<b>网络更深，每一层要做的事情也更加简单了。</b></p><p>每一个网络层各司其职，我们从zfnet反卷积看一个经典的网络各个网络层学习到的权重。</p><p>第一层学习到了边缘，第二层学习到了简单的形状，第三层开始学习到了目标的形状，更深的网络层能学习到更加复杂的表达。如果只有一层，那就意味着要学习的变换非常的复杂，这很难做到。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5a3d2cdf4e51ba3f99c46143bb214ef3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"996\" data-rawheight=\"1278\" class=\"origin_image zh-lightbox-thumb\" width=\"996\" data-original=\"https://pic4.zhimg.com/v2-5a3d2cdf4e51ba3f99c46143bb214ef3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;996&#39; height=&#39;1278&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"996\" data-rawheight=\"1278\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"996\" data-original=\"https://pic4.zhimg.com/v2-5a3d2cdf4e51ba3f99c46143bb214ef3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5a3d2cdf4e51ba3f99c46143bb214ef3_b.jpg\"/></figure><h2><b>2 如何定量评估深度与模型性能</b></h2><p>上面就是网络加深带来的两个主要好处，更强大的表达能力和逐层的特征学习。</p><p>理论上一个2层的网络可以拟合任何有界的连续函数，但是需要的宽度很大，这在实际使用中不现实，因此我们才会使用深层网络。</p><p>我们知道一个模型越深越好，但是怎么用一个指标直接定量衡量模型的能力和深度之间的关系，就有了<b>直接法和间接法两种方案</b>。</p><p><b>直接法便是定义指标理论分析网络的能力，间接法便是通过在任务中的一系列指标比如准确率来进行比较等。</b></p><p><b>2.1、直接法</b></p><p>早期对浅层网络的研究，通过研究函数的逼近能力，和布尔电路的比较，网络的VC维度等进行评估，但是并不适用于深层网络。</p><p>目前直接评估网络性能一个比较好的研究思路是线性区间(linear regions)。可以将神经网络的表达看作是一个分段线性函数，如果要完美的拟合一个曲线，就需要无数多的线性区间(linear regions)。线性区间越多，说明网络越灵活。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-2f16aabdf6ee2c375a584e216b6b5b87_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"758\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-2f16aabdf6ee2c375a584e216b6b5b87_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;758&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"758\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-2f16aabdf6ee2c375a584e216b6b5b87_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-2f16aabdf6ee2c375a584e216b6b5b87_b.jpg\"/></figure><p>Yoshua Bengio等人就通过<b>线性区间的数量来衡量模型的灵活性。一个更深的网络，可以将输入空间分为更多的线性响应空间，它的能力是浅层网络的指数级倍。</b></p><p>对于一个拥有n0个输入，n个输出，kn个隐藏层的单层网络，其最大数量为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c21eb186be71362e4a63125f5d89aa5e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"406\" data-rawheight=\"118\" class=\"content_image\" width=\"406\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;406&#39; height=&#39;118&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"406\" data-rawheight=\"118\" class=\"content_image lazy\" width=\"406\" data-actualsrc=\"https://pic3.zhimg.com/v2-c21eb186be71362e4a63125f5d89aa5e_b.jpg\"/></figure><p>对于拥有同样多的参数，n0个输入，n个输出，k个隐藏层，每一层n个节点的多层网络，其最大数量为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-1e2cc6bf78ef66d73001661a7e99c2d1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"528\" data-rawheight=\"244\" class=\"origin_image zh-lightbox-thumb\" width=\"528\" data-original=\"https://pic2.zhimg.com/v2-1e2cc6bf78ef66d73001661a7e99c2d1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;528&#39; height=&#39;244&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"528\" data-rawheight=\"244\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"528\" data-original=\"https://pic2.zhimg.com/v2-1e2cc6bf78ef66d73001661a7e99c2d1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-1e2cc6bf78ef66d73001661a7e99c2d1_b.jpg\"/></figure><p>因为n0通常很小，所以多层网络的数量是单层的指数倍(体现在k上)，计算方法是通过计算几何学来完成，大家可以参考论文[3]。</p><p>除此之外还有一些其他的研究思路，比如monica binachini[4]等使用的betti number，Maithra Raghu等提出的trajectory length[5]。</p><p>虽然在工程实践中这些指标没有多少意义甚至不一定有效，但是为我们理解深度和模型性能的关系提供了理论指导。</p><p><b>2.2、间接法</b></p><p>间接法就是展现实验结果了，网络的加深可以提升模型的性能，这几乎在所有的经典网络上都可以印证。比较不同的模型可能不够公平，那就从同一个系列的模型来再次感受一下，看看VGG系列模型，ResNet系列模型，结果都是从论文中获取。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-ffb71cefd16048ec170199d7aa0044ec_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"920\" data-rawheight=\"354\" class=\"origin_image zh-lightbox-thumb\" width=\"920\" data-original=\"https://pic1.zhimg.com/v2-ffb71cefd16048ec170199d7aa0044ec_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;920&#39; height=&#39;354&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"920\" data-rawheight=\"354\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"920\" data-original=\"https://pic1.zhimg.com/v2-ffb71cefd16048ec170199d7aa0044ec_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-ffb71cefd16048ec170199d7aa0044ec_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-91c9c9f1021cdc57f916223f07663fff_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"912\" data-rawheight=\"378\" class=\"origin_image zh-lightbox-thumb\" width=\"912\" data-original=\"https://pic4.zhimg.com/v2-91c9c9f1021cdc57f916223f07663fff_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;912&#39; height=&#39;378&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"912\" data-rawheight=\"378\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"912\" data-original=\"https://pic4.zhimg.com/v2-91c9c9f1021cdc57f916223f07663fff_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-91c9c9f1021cdc57f916223f07663fff_b.jpg\"/></figure><p>在一定的范围内，网络越深，性能的确越好。</p><h2><b>3 加深就一定更好吗？</b></h2><p>前面说到加深在一定程度上可以提升模型性能，但是未必就是网络越深越越好，我们从性能提升和优化两个方面来看。</p><p><b>3.1、加深带来的优化问题</b></p><p>ResNet为什么这么成功，就是因为它使得深层神经网络的训练成为可行。虽然好的初始化，BN层等技术也有助于更深层网络的训练，但是很少能突破30层。</p><p>VGGNet19层，GoogleNet22层，MobileNet28层，经典的网络超过30层的也就是ResNet系列常见的ResNet50，ResNet152了。虽然这跟后面ImageNet比赛的落幕，大家开始追求更加高效实用的模型有关系，另一方面也是训练的问题。</p><p>深层网络带来的<b>梯度不稳定，网络退化</b>的问题始终都是存在的，可以缓解，没法消除。这就有可能出现网络加深，性能反而开始下降。</p><p><b>3.2、网络加深带来的饱和</b></p><p>网络的深度不是越深越好，下面我们通过几个实验来证明就是了。公开论文中使用的ImageNet等数据集研究者已经做过很多实验了，我们另外选了两个数据集和两个模型。</p><p><b>第一个数据集是GHIM数据集，第二个数据集是从Place20中选择了20个类别，可见两者一个比较简单，一个比较困难。</b></p><p><b>第一个模型就是简单的卷积+激活的模型，第二个就是mobilenet模型。</b></p><p>首先我们看一下第一个模型的基准结构，包含5层卷积和一个全连接层， 因此我们称其为allconv6吧，表示深度为6的一个卷积网络。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-843c5646b3288ee09d65badd26ce6d8e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"1242\" class=\"origin_image zh-lightbox-thumb\" width=\"624\" data-original=\"https://pic3.zhimg.com/v2-843c5646b3288ee09d65badd26ce6d8e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;624&#39; height=&#39;1242&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"1242\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"624\" data-original=\"https://pic3.zhimg.com/v2-843c5646b3288ee09d65badd26ce6d8e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-843c5646b3288ee09d65badd26ce6d8e_b.jpg\"/></figure><p>接下来我们试验各种配置，从深度为5到深度为8，下面是每一个网络层的stride和通道数的配置。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9022351561f6852c7e369cdf9e4b504e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1620\" data-rawheight=\"878\" class=\"origin_image zh-lightbox-thumb\" width=\"1620\" data-original=\"https://pic3.zhimg.com/v2-9022351561f6852c7e369cdf9e4b504e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1620&#39; height=&#39;878&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1620\" data-rawheight=\"878\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1620\" data-original=\"https://pic3.zhimg.com/v2-9022351561f6852c7e369cdf9e4b504e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9022351561f6852c7e369cdf9e4b504e_b.jpg\"/></figure><p>我们看结果，优化都是采用了同一套参数配置，而且经过了调优，具体细节篇幅问题就不多说了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-125a9a9c6e92ae0a86cade1b65284c0b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"580\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-125a9a9c6e92ae0a86cade1b65284c0b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;580&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"580\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-125a9a9c6e92ae0a86cade1b65284c0b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-125a9a9c6e92ae0a86cade1b65284c0b_b.jpg\"/></figure><p>看的出来网络加深性能并未下降，但是也没有多少提升了。allconv5的性能明显更差，深度肯定是其中的一个因素。</p><p>我们还可以给所有的卷积层后添加BN层做个试验，结果如下，从allconv7_1和allconv8_1的性能相当且明显优于allconv6可以得出与刚才同样的结论。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fa566f8a0cc7840d8c15ff57241d9f62_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"507\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fa566f8a0cc7840d8c15ff57241d9f62_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;507&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"507\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fa566f8a0cc7840d8c15ff57241d9f62_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fa566f8a0cc7840d8c15ff57241d9f62_b.jpg\"/></figure><p>那么，对于更加复杂的数据集，表现又是如何呢？下面看在place20上的结果，更加清晰了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4c876275e0c66a27122a87786fa40fe3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-4c876275e0c66a27122a87786fa40fe3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-4c876275e0c66a27122a87786fa40fe3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4c876275e0c66a27122a87786fa40fe3_b.jpg\"/></figure><p>allconv5，allconv6结果明显比allconv7，allconv8差，而allconv7和allconv8性能相当。所以从allconv这个系列的网络结构来看，随着深度增加到allconv7，之后再简单增加深度就难以提升了。</p><p>接下来我们再看一下<b>不同深度的mobilenet在这两个数据集上的表现</b>，原始的mobilenet是28层的结构。</p><p>不同深度的MobileNet在GHIM数据集的结果如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-31359ffdb19f096e892edcfdbcb09fbd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"586\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-31359ffdb19f096e892edcfdbcb09fbd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;586&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"586\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-31359ffdb19f096e892edcfdbcb09fbd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-31359ffdb19f096e892edcfdbcb09fbd_b.jpg\"/></figure><p>看得出来当模型到16层左右后，基本就饱和了。</p><p>不同深度的MobileNet在Place20数据集的结果如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2eb5dc71761cba7f3716271e85039ea1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-2eb5dc71761cba7f3716271e85039ea1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-2eb5dc71761cba7f3716271e85039ea1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2eb5dc71761cba7f3716271e85039ea1_b.jpg\"/></figure><p>与GHIM的结果相比，深度带来的提升更加明显一些，不过也渐趋饱和。</p><p>这是必然存在的问题，哪有一直加深一直提升的道理，只是如何去把握这个深度，尚且无法定论，只能依靠更多的实验了。</p><p>除此之外，模型加深还可能出现的一些问题是<b>导致某些浅层的学习能力下降</b>，限制了深层网络的学习，这也是跳层连接等结构能够发挥作用的很重要的因素。</p><p>关于网络深度对模型性能的影响，这次就先说这么多。更多请大家至我的知乎live中交流。</p><a href=\"https://www.zhihu.com/lives/1104173238430556160\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-41f5094bf991163a4166911db2806b1f_ipico.jpg\" data-image-width=\"3179\" data-image-height=\"3179\" class=\"internal\">如何设计性能更强的 CNN 网络结构？</a><p>[1] Bengio Y, LeCun Y. Scaling learning algorithms towards AI[J]. Large-scale kernel machines, 2007, 34(5): 1-41.</p><p>[2] Montufar G F, Pascanu R, Cho K, et al. On the number of linear regions of deep neural networks[C]//Advances in neural information processing systems. 2014: 2924-2932.</p><p>[3] Pascanu R, Montufar G, Bengio Y. On the number of response regions of deep feed forward networks with piece-wise linear activations[J]. arXiv preprint arXiv:1312.6098, 2013.</p><p>[4] Bianchini M, Scarselli F. On the complexity of neural network classifiers: A comparison between shallow and deep architectures[J]. IEEE transactions on neural networks and learning systems, 2014, 25(8): 1553-1565.</p><p>[5] Raghu M, Poole B, Kleinberg J, et al. On the expressive power of deep neural networks[C]//Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017: 2847-2854.</p><p><b>总结</b></p><p>深度学习的名字中就带着“深”，可见深度对模型的重要性。这一次我们讲述了深度对模型带来提升的原理，如何定量地评估深度对模型性能的贡献，以及加深网络会遇到的问题。</p><p><i>下期预告：模型的宽度对性能的影响。</i></p><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a> </p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a> </p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032883%26idx%3D1%26sn%3D9e557cf7bff4bceecb522f28b074c25e%26chksm%3D8712b6ceb0653fd8ec4c7a9f39e5905de421dd08b7dbe49c55bbb25806d7c824089ae36f014a%26token%3D1169783853%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络的宽度如何影响深度学习模型的性能？</a></p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/63405958", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 265, 
            "title": "【完结】深度学习CV算法工程师从入门到初级面试有多远，大概是25篇文章的距离", 
            "content": "<figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-3a39306b6312586cb31ad2052f7c6395_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"671\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-3a39306b6312586cb31ad2052f7c6395_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;671&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"671\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-3a39306b6312586cb31ad2052f7c6395_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-3a39306b6312586cb31ad2052f7c6395_b.jpg\"/></figure><p>文/编辑 | 言有三</p><p><b>一直有同学希望我在公众号写写面试相关的东西，一直没写。我们不会开相关的板块，因为没有标准，容易引起争议，而且可能会加重大家的浮躁和焦虑。</b></p><p><b>不过关于面试，有三还是有一些话可以说的，下面分两部分道来。</b></p><h2><b>1 老板喜欢什么人</b></h2><p>假如我是老板或者诚心为公司招聘优秀人才的面试官，我会喜欢拥有以下特质的人。这里说的是招聘一个算法工程师，一个能够为公司创造收益的人，简单起见就不分社招校招。</p><p><b>1.1、忠诚度，这很重要。</b>一个不忠诚的员工，能力再大，也不能要。所以如果看到一份简历满满当当的都是跳槽和实习简历，两个月换一个实习，半年换一份工作，除非你说出很充分客观的理由，否则我可能不会通过这份简历。</p><p><b>1.2、编码能力，这是一切的前提。</b>前面说了，我们这里要招聘的是一个计算机视觉领域(CV)算法工程师，招进来是要干活的。公司不会招聘一个只会Matlab或者python都用不熟的人来做项目开发，做纯算法研究都不行，一个不能实现自己想法的牛人我还没见过。见过的牛人不仅算法好，编程能力也强大。</p><p>说起编程能力，有几点基本要求：</p><p><b>(1) linux得熟。</b></p><p>现在不是若干年前开源项目还不多的时代，大家还在Windows下面吭哧吭哧用Matlab和VS仿真，都9102年了，Linux都不熟，效率如何让老大放心。</p><p><b>(2) python得熟，c++得会</b>。</p><p>如果连python这样简单的语言还用不熟，那真是无话可说。c/c++ 这是一门基础课吧，理工科的学校没开过应该很罕见，CV领域的工业界部署和算法优化都离不开C++。</p><p><b>(3) 编程习惯得好。</b></p><p>虽然说代码写的烂，不会真有同事拿gun突突突你，但是好的编程习惯不仅仅提高效率，而且看着也舒服，不会被别人鄙视。</p><p>这里说的习惯包括：<b>多写写类和函数封装，组织好项目目录结构，好好命名</b>等等。可以不会写多么牛逼炫酷的代码，但是要<b>保证代码具有良好的可拓展性，方便他人阅读移植</b>，具体要求以后再说。</p><p><b>3、算法基础，这决定了潜力。</b>没做过检测？没事，没做过分割？没事。边做边学，快速跟进就是了，这本就是公司开发的常态。</p><p>人的精力有限，没做过的多了去了。但是如果CNN的一些基础傻傻说不清楚，图像的基础概念一问三不知，这就有事了。因为你交给他一个项目，可能会犯一些低级错误而不自知，老大心里也慌，还要陪着检查和普及基础知识。</p><p><b>以上就是三个基本要求，每一家公司肯定都是这样要求的，我觉得如果通过了这三个考验，那至少就是一个可以培养的候选人，我会愿意给他机会进入下一轮的PK。</b></p><p><b>踏实(基础好)，靠谱(稳定)，能干活(能写代码)，这3个基本前提比什么都重要，其他的都可以在项目学习。</b></p><h2><b>2 准备哪些知识</b></h2><p>接下来就该说说具体怎么办了，这就是我开<b>《AI修行之路》</b>这个专栏的原因了，如果你有耐心，不妨接着看下去，我们也是再<b>重新回顾总结</b>一下之前的文章，每一篇文章的开设都有充分的理由。</p><p><b>2.1、为什么要用Linux</b></p><p>在以前，你可能觉得Linux并非刚需，用着自己的Windows电脑，也不需要与人共享操作系统，硬件和磁盘。但是如果你们团队一起使用服务器，不可能不用Linux。</p><p>所以这是对还没有在Linux上面真正进行日常开发工作的小朋友说的，要正式进入AI行业发展，Linux是必备和唯一的操作系统，“软”兵器，我还没有听过哪家公司在Windows或者Mac上面训练模型的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e64cf650182139ccfb54ddcf9e55d568_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-e64cf650182139ccfb54ddcf9e55d568_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-e64cf650182139ccfb54ddcf9e55d568_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e64cf650182139ccfb54ddcf9e55d568_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030167%26idx%3D1%26sn%3D143472a846f5884c40d52d5daabba330%26chksm%3D8713406ab064c97ce534bca0a845571ac30cda4e21e7099c55d9de0bbc22442311913cf01751%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【学习·求职必备】入行深度学习之前，应该做好哪些准备</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a><br/></li></ul><p><b>2、提高开发效率</b></p><p>编程习惯，工作效率很重要，很重要！Linux下一个熟练的工程师，会比Windows下工作效率高很多，提高写代码效率可以从终端多任务管理，熟练使用shell命令，熟练使用vim等开发环境，熟练使用git命令等地方入手。</p><p><b>shell命令是Linux的操作基础</b>，也是学习使用Linux的开始，而慢慢熟悉高级的shell命令在将来的工作中会带来很大的效率提升。</p><p>vim是Linux下最常用的编辑器，从小白到高手都可以使用，而它的<b>列编辑，查找替换，自动补全</b>等功能都是效率的保证，或许从visual studio等环境切换过来的同学刚开始会有些许不适应，但是时间久了就会越来越明白VIM的好。</p><p><b>git是程序员必备的素养</b>，慢慢学会维护几个自己的代码库，等到将来出问题的时候就明白了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-951d477347ee97b8591ad8dcf154bf2c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1004\" data-rawheight=\"504\" class=\"origin_image zh-lightbox-thumb\" width=\"1004\" data-original=\"https://pic1.zhimg.com/v2-951d477347ee97b8591ad8dcf154bf2c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1004&#39; height=&#39;504&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1004\" data-rawheight=\"504\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1004\" data-original=\"https://pic1.zhimg.com/v2-951d477347ee97b8591ad8dcf154bf2c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-951d477347ee97b8591ad8dcf154bf2c_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032197%26idx%3D1%26sn%3D5abb299cc6502c2c5f4ddf015dae8e84%26chksm%3D8712b878b065316ee86073d20adff8ac1afe9ad48d1f1157b3c2a3237e71a530049b3bcde3fd%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】提升写代码效率不得不做的三件事</a><br/></li></ul><p><b>3、python基础和编程习惯</b></p><p>在机器学习领域，python可谓是一骑绝尘，学习python需要掌握好基础的语法包括函数，类设计，掌握大量的开源矩阵库Numpy等。</p><p><b>python简单吗？简单。真的简单吗？看看大神们写的项目吧。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-844604c11f717930bf17fe2371c26b57_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"404\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-844604c11f717930bf17fe2371c26b57_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;404&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"404\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-844604c11f717930bf17fe2371c26b57_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-844604c11f717930bf17fe2371c26b57_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032609%26idx%3D1%26sn%3D98fa92d22758074d206c1d41982fc5f6%26chksm%3D8712b9dcb06530ca1980e24e44c60b740d08aeb6df6e76628accee820357260eb480f3c5956d%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】优秀的深度学习从业者都有哪些优秀的习惯</a></li></ul><p><b>4、图像基础</b></p><p>深度学习有一个最大的问题，就是太好用了。导致什么图像基础和传统算法都不需要懂，也能项目做的风生水起。</p><p>但是如果没有好的图像基础，总有一天遇到CNN解决不了的问题，或者无法单独解决的问题，就不知所措了。很多的新技术都是从传统算法中获得灵感或者相互结合的，不懂图像基础，就仿佛埋了一颗定时炸弹，一般没事，炸了就炸了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-65b5a50b61cf2e87d6b50c2cc883c8c1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"365\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-65b5a50b61cf2e87d6b50c2cc883c8c1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;365&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"365\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-65b5a50b61cf2e87d6b50c2cc883c8c1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-65b5a50b61cf2e87d6b50c2cc883c8c1_b.jpg\"/></figure><p><b>图像基础</b></p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030618%26idx%3D1%26sn%3D307ae3a79161ebcbaa10c4a73b31c724%26chksm%3D871341a7b064c8b11227917d71cfd260b35d220f31d04ce60b369323a2f4608ee6289455fa57%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】图像与CNN发家简史，集齐深度学习三巨头</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></li></ul><p><b>5、OpenCV基础</b></p><p>如果说图像处理领域有什么库是绕不过去的，那一定是OpenCV，这一个开源计算机视觉库堪称最优秀的计算机视觉库，不仅可以学术和商业免费使用，而且跨平台，高性能。需要掌握的基础内容包括：如何部署，基本数据结构的熟悉与使用，基本模块的了解。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d92bcf7e330311b391c600fe7783eac3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1330\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-d92bcf7e330311b391c600fe7783eac3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1330&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1330\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-d92bcf7e330311b391c600fe7783eac3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-d92bcf7e330311b391c600fe7783eac3_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030642%26idx%3D1%26sn%3D67b1aa7668777198d5738d9087715ec7%26chksm%3D8713418fb064c899a1f7f37ef0c71c8ab1f5a9333b7461935348f93655bd7af8feeeaf3fe422%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI基础】OpenCV，PIL，Skimage你pick谁</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></li></ul><p><b>6、CMake编译</b></p><p>python是脚本语言，而当前大量的AI算法都部署在移动端嵌入式平台，需要使用c/c++/java语言，g++，CMake和Makefile正是Linux下编译C系代码的工具。</p><p>实际上一些python，matlab开源项目也需要预编译，更多的等到了工作岗位自然懂。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-dacd48cf3c404646358d1a5c76eebf49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"410\" data-rawheight=\"232\" class=\"content_image\" width=\"410\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;410&#39; height=&#39;232&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"410\" data-rawheight=\"232\" class=\"content_image lazy\" width=\"410\" data-actualsrc=\"https://pic2.zhimg.com/v2-dacd48cf3c404646358d1a5c76eebf49_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></li></ul><p><b>7、爬虫基础</b></p><p>深度学习项目开发中最重要的是什么，当然是数据！实际的项目你经常没有足够多的数据，这个时候就需要自己去想办法获取了。</p><p>互联网是一个什么资源都有的大宝库，学会使用好爬虫，你将可能成为时代里最有“资源”的人，这也很可能是项目成功的开始。</p><p>本文最后的一个实际项目就需要用到。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-59df3ec79a07f505202f5d0b258021ce_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"502\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-59df3ec79a07f505202f5d0b258021ce_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;502&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"502\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-59df3ec79a07f505202f5d0b258021ce_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-59df3ec79a07f505202f5d0b258021ce_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032306%26idx%3D1%26sn%3Dbdaeaebd630f55689b5a5eaf218c27ab%26chksm%3D8712b80fb0653119aff7156cf62b26c29e52874be5233c1c8849434e72bac023bf46dd9415ee%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【杂谈】深度学习必备，各路免费爬虫一举拿下</a></li></ul><p><b>8、数据可视化</b></p><p>爬取完数据之后就应该进行处理了，一个很常用的手段是数据可视化。在深度学习项目中，常需要的数据可视化操作包括原始图片数据的可视化，损失和精度的可视化等。</p><p>除了对数据可视化，我们还需要对模型进行可视化，方便调试和感知。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-fa49d0d1ae3876ab00b0d4f19889618f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"690\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-fa49d0d1ae3876ab00b0d4f19889618f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;690&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"690\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-fa49d0d1ae3876ab00b0d4f19889618f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-fa49d0d1ae3876ab00b0d4f19889618f_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030051%26idx%3D1%26sn%3Dd3f561d640ae976fecd4e1a6f1751b3f%26chksm%3D871343deb064cac87de927ffb92f32e17bcf0af63bf7a2f5b6b8c4dea5aaf9c3feefb166fd20%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】“看透”神经网络</a></li></ul><p><b>9、数学基础</b></p><p>虽然对于大部分来说，做项目不需要多么强悍的数学基础，但是你会需要看懂别人论文，也会经常需要进行简单的推导和算法改进。</p><p>从线性代数，概率论与统计学到微积分和最优化，都是需要掌握的。不过数学的学习是一个非常漫长的过程，不要急于求成，也不是靠跟着视频或者书本就能完全学会的，重要的是用起来。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-6be2634f8b3fc5ccceae7ecdf5ec1f60_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-6be2634f8b3fc5ccceae7ecdf5ec1f60_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-6be2634f8b3fc5ccceae7ecdf5ec1f60_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-6be2634f8b3fc5ccceae7ecdf5ec1f60_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></li></ul><p><b>10、计算机视觉研究方向</b></p><p>学习和做项目都需要一个方向，在前面这些基础都掌握好了，就要好好了解一下计算机视觉的各大研究方向及其特点，方便自己选题和项目方案定型了。</p><p>从图像分类，分割，目标检测，跟踪，到图像滤波与降噪，增强，风格化，三维重建，图像检索，GANs，相信总有你喜欢或者项目涉及的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-ae9729c9a2c782a361179ea5c0710458_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"498\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-ae9729c9a2c782a361179ea5c0710458_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;498&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"498\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-ae9729c9a2c782a361179ea5c0710458_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-ae9729c9a2c782a361179ea5c0710458_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></li></ul><p><b>11、应用方向</b></p><p>学习最终是为了解决实际问题，AI已经渗入到了我们生活的方方面面。从自动驾驶汽车、图像美颜，到聊天机器人，金融支付等，因此好好了解下当前AI在各大领域的应用没错的，这次就不仅仅限于计算机视觉了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-acd756bbce98c19249b3bb14abb966fa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"866\" data-rawheight=\"509\" class=\"origin_image zh-lightbox-thumb\" width=\"866\" data-original=\"https://pic3.zhimg.com/v2-acd756bbce98c19249b3bb14abb966fa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;866&#39; height=&#39;509&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"866\" data-rawheight=\"509\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"866\" data-original=\"https://pic3.zhimg.com/v2-acd756bbce98c19249b3bb14abb966fa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-acd756bbce98c19249b3bb14abb966fa_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】AI+，都加在哪些应用领域了</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029301%26idx%3D1%26sn%3D4d5db235e5a593fa920a148553427139%26chksm%3D871344c8b064cddea8e05b446b5ea61e6a62525f1370d38447bef5e3eaba8007ccaa3afe1268%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【行业进展】哪些公司在搞“新零售”了</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029421%26idx%3D1%26sn%3D3e5e1c1072384ede09137e4948c3525a%26chksm%3D87134550b064cc46ec84c658ff1b6b174a322989c38cc01a808370d1bafcdb49261fc6866267%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【行业进展】AI：新药研发的新纪元</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029532%26idx%3D1%26sn%3Df37927110efaedf216ad89240786127d%26chksm%3D871345e1b064ccf71829f1c789878117f1ed2e3adb865fce14fe266525c115cae3473a5bd415%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【行业进展】国内自动驾驶发展的怎么样了？</a></li></ul><p><b>12、认识学术大咖</b></p><p>要想真正融入行业圈子，紧跟技术发展，就必须要时刻了解大佬们的状态，他们就是行业发展的风向标。</p><p>不管是学术界还是工业界，不管是老师傅还是青年才俊，让我们一起见贤思齐吧。</p><p><b>我们开源了大佬研究方向的项目，欢迎follow。</b></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/longpeng2008/Awesome_DNN_Researchers</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-db8f2a0b83bf0a5b20363169e177d468_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"798\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-db8f2a0b83bf0a5b20363169e177d468_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;798&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"798\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-db8f2a0b83bf0a5b20363169e177d468_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-db8f2a0b83bf0a5b20363169e177d468_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032536%26idx%3D1%26sn%3D47bc7ee27424ec12e5bc0bf6af82b3aa%26chksm%3D8712b925b06530338c702f3fb6e8661409a8dfb2c4a74abff2e8cdea25e442d30df4c7dd33b6%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI大咖】认真认识一代AI教父Hinton</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a>  </li></ul><p><br/><b>13、人工智能简史</b></p><p>基础打好了，接下来就是正式学习AI相关的知识，不管是在哪个课堂或者教材，都是让大家先了解先贤们。</p><p>从图灵与机器智能，冯诺伊曼与类脑计算引发的人工智能启蒙，到三次浪潮的曲折和技术的成长史，值得每一个从事该行业的人阅读。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"855\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;855&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"855\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></li></ul><p><b>14、神经网络基础</b></p><p>深度学习研究问题的方法就是仿造大脑，根基是神经网络。从感受野，到MP模型，到感知机，到反向传播，要很熟悉全连接神经网络的劣势，卷积神经网络的特点，核心技术和优势，这是学习深度学习最重要的基础。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e0ae45153253af7efd63e17db14c4bdd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"726\" data-rawheight=\"426\" class=\"origin_image zh-lightbox-thumb\" width=\"726\" data-original=\"https://pic2.zhimg.com/v2-e0ae45153253af7efd63e17db14c4bdd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;726&#39; height=&#39;426&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"726\" data-rawheight=\"426\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"726\" data-original=\"https://pic2.zhimg.com/v2-e0ae45153253af7efd63e17db14c4bdd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e0ae45153253af7efd63e17db14c4bdd_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></li></ul><p><b>15、了解领域的突破</b></p><p>既然学深度学习，就必须要了解深度学习的重要进展。</p><p>在前深度学习时代，视觉机制的发现，第一个卷积神经网络Neocognitron的提出，反向传播算法的流行，促进了LeNet5和MNIST数据集的诞生。</p><p>随着新理论的成熟，大数据的积累，GPU的普世，以卷积神经网络为代表的技术在图像分类，目标检测等基础领域取得重大突破，随着AlphaGo的成功同时在业内和业外人士的心目中种下了深度学习/人工智能技术的种子，从此焕发勃勃生机。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"851\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb\" width=\"851\" data-original=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;851&#39; height=&#39;476&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"851\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"851\" data-original=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></li></ul><p><b>16、激活函数</b></p><p>深度学习的机制模仿于人脑，人脑的细胞接受刺激从而产生活动需要一定的阈值，这便是激活函数根本性的由来。</p><p>激活函数肩负着网络非线性表达能力的提升，从早期平滑的sigmoid和tanh激活函数，到后来的ReLU和各类ReLU的变种(LReLU，PReLU，RReLU，ELU，SELU，GELU等等)，Maxout，研究者一直试图让网络拥有更好的表达能力。</p><p>随着技术的发展，利用增强学习等算法从函数池中学习新的激活函数如swish等，成为了当下的研究主流，激活函数也走上了数据驱动的道路。</p><p>激活机制看似简单，实则不易，大家一定多跟进了解了解。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b29f71ae5e565916a17542513eb0dc5a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"595\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"595\" data-original=\"https://pic3.zhimg.com/v2-b29f71ae5e565916a17542513eb0dc5a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;595&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"595\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"595\" data-original=\"https://pic3.zhimg.com/v2-b29f71ae5e565916a17542513eb0dc5a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b29f71ae5e565916a17542513eb0dc5a_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></li></ul><p><b>17、参数初始化</b></p><p>参数初始化，一个看似很简单的问题，却实实在在地困住了神经网络的优化很久，2006年Hinton等人在science期刊上发表了论文“Reducing the dimensionality of data with neural networks”，揭开了新的训练深层神经网络算法的序幕，仍旧被认为是当前第三次人工智能热潮的纪元。</p><p>从全零初始化和随机初始化，到标准初始化，Xavier初始化，He初始化，时至今日上千层网络的训练都已经成为了现实，初始化似乎已经不再是那么重要的课题了，但是谁说就没有思考的空间了呢。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-90ee28d8429887401aa7344db0eb1d5c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"376\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-90ee28d8429887401aa7344db0eb1d5c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;376&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"376\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-90ee28d8429887401aa7344db0eb1d5c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-90ee28d8429887401aa7344db0eb1d5c_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></li></ul><p><b>18、归一化</b></p><p>我们总是希望所研究的统计问题能够满足固定的分布，而且这样也的确会降低问题的难度。</p><p>在深度学习中，因为网络的层数非常多，如果数据分布在某一层开始有明显的偏移，随着网络的加深这一问题会加剧，进而导致模型优化的难度增加。</p><p>归一化便是致力于解决这个问题，从数据到权重，从限定在同一样本的一个特征通道到不同样本的所有通道，各类归一化方法以简单的方式，优雅地解决了深度学习模型训练容易陷入局部解的难题，顺带提升训练速度提高泛化能力，这是一定要掌握的理论和工程技巧。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"681\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;681&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"681\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></li></ul><p><b>19、池化</b></p><p>大脑学习知识靠抽象，从图像中抽象知识是一个“从大到小”过滤提炼信息的过程。从视觉机制中来的pooling即池化，正是对信息进行抽象的过程。</p><p>池化增加了网络对于平移的不变性，提升了网络的泛化能力，大家已经习惯了使用均值池化mean pooling和最大池化(max pooling)，虽然可以用带步长的卷积进行替代。</p><p>尽管池化究竟起到了多大的作用开始被研究者怀疑，但是池化机制仍然是网络中必备的结构，所以你一定要熟悉它，而且基于数据驱动的池化机制值得研究。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7196234f6ee339d2f22235717857699e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"353\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic3.zhimg.com/v2-7196234f6ee339d2f22235717857699e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;800&#39; height=&#39;353&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"353\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"800\" data-original=\"https://pic3.zhimg.com/v2-7196234f6ee339d2f22235717857699e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-7196234f6ee339d2f22235717857699e_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></li></ul><p><b>20、最优化</b></p><p>模型的学习需要通过优化方法才能具体实现。深度学习模型的优化是一个非凸优化问题，尽管一阶二阶方法都可以拿来解决它，但是当前随机梯度下降SGD及其各类变种仍然是首选。</p><p>从SGD开始，有的致力于提高它的优化速度如Momentum动量法和Nesterov accelerated gradient法，有的致力于让不同的参数拥有不同的学习率如Adagrad，Adadelta与Rmsprop法，有的希望大家从调参中解脱如Adam方法及其变种，有的致力于让收敛过程更加稳定如Adafactor方法和Adabound方法。</p><p>没有一个方法是完美的，训练的时候总归要试试。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-fee139096c3a523e12fa8fc6befa1eed_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"464\" data-thumbnail=\"https://pic2.zhimg.com/v2-fee139096c3a523e12fa8fc6befa1eed_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-fee139096c3a523e12fa8fc6befa1eed_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;464&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"464\" data-thumbnail=\"https://pic2.zhimg.com/v2-fee139096c3a523e12fa8fc6befa1eed_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-fee139096c3a523e12fa8fc6befa1eed_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-fee139096c3a523e12fa8fc6befa1eed_b.gif\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030739%26idx%3D1%26sn%3D96a2850020f99050f4440caee3b152a7%26chksm%3D8712be2eb0653738eace8cceb8923edeac0c2e96a7ae1d0ca1f942ea20ae51ff95e40829a408%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型训练】SGD的那些变种，真的比SGD强吗</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030692%26idx%3D1%26sn%3D6322e8eec12d8a8b60f578a9ebb4b42c%26chksm%3D8712be59b065374f00dc9b3715e6453e2de5d05262ee4eac47ef5efe6d167703af67f5882029%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型训练】如何选择最适合你的学习率变更策略</a></li></ul><p><b>21、泛化能力</b></p><p>如果一个模型只能在训练集上起作用，那是没有用的。</p><p>因此我们总是希望模型不仅仅是对于已知的数据(训练集)性能表现良好，对于未知的数据(测试集)也表现良好，即具有良好的泛化能力，通过添加正则项来实现。</p><p>从直接提供正则化约束的参数正则化方法如L1/L2正则化，工程上的技巧如训练提前终止和模型集成，以及隐式的正则化方法如数据增强等，研究人员在这方面投入的精力非常多，大家一定要时刻关注。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"830\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"830\" data-original=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;830&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"830\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"830\" data-original=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></li></ul><p><b>22、模型评估</b></p><p>口说无凭，用数据说话才是研究者们进行PK的正确姿态。计算机视觉的任务何其多，从分类，回归，质量评估到生成模型，我们当然需要掌握科学的评估方法。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-cee439f5da77ce26e4efc468b6c79398_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"339\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-cee439f5da77ce26e4efc468b6c79398_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;339&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"339\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-cee439f5da77ce26e4efc468b6c79398_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-cee439f5da77ce26e4efc468b6c79398_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></li></ul><p><b>23、损失目标</b></p><p>模型的学习需要指导，这正是损失函数的责任，它往往对模型最终表现如何影响巨大。</p><p>这一篇文章就重点总结分类问题，回归问题，生成对抗网络中使用的损失目标，为大家设计更好的优化目标奠定理论基础。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4e3eb80097817cd33f4a5c34dd892360_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"526\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-4e3eb80097817cd33f4a5c34dd892360_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;526&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"526\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-4e3eb80097817cd33f4a5c34dd892360_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-4e3eb80097817cd33f4a5c34dd892360_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></li></ul><p><b>24、如何开始训练你的模型</b></p><p>磨刀不误砍柴工，当我们开始训练自己的模型的时候，总归要想清楚一些事儿再动手。</p><p>第一步知道你要做的任务是一个什么任务，找到竞争对手做好预期，想好你需要什么样的数据。第二步确定好框架，基准模型，准备好数据。然后才是第三步开始训练，从输入输出，数据的预处理到维持正确地训练姿势。</p><p>这是我总结出来的经验，想必总是有点用的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"764\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;764&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"764\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手做项目的10个建议</a></li></ul><p><b>25、认真做一个项目</b></p><p>到了最后，相信大家都拥有了基本技能了，那我们就来开始一个真正的项目吧，实现形色识花App的部分功能。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6bad0a93ccfe6702551f91593a5ac899_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"973\" data-rawheight=\"1955\" class=\"origin_image zh-lightbox-thumb\" width=\"973\" data-original=\"https://pic2.zhimg.com/v2-6bad0a93ccfe6702551f91593a5ac899_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;973&#39; height=&#39;1955&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"973\" data-rawheight=\"1955\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"973\" data-original=\"https://pic2.zhimg.com/v2-6bad0a93ccfe6702551f91593a5ac899_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6bad0a93ccfe6702551f91593a5ac899_b.jpg\"/></figure><p>在这里不会教大家如何完成，因为这个项目一点都不简单，是个很难的分类项目，不是给一个现有的数据集和一个模型就能解决的，至少有以下问题需要考虑，每一个都有很多工程细节需要解决。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5d6f361368906c6ff9f04ecc6dea9f4c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1289\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5d6f361368906c6ff9f04ecc6dea9f4c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1289&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1289\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5d6f361368906c6ff9f04ecc6dea9f4c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5d6f361368906c6ff9f04ecc6dea9f4c_b.jpg\"/></figure><p><b>如果你能独立将这个任务的整个流程完成，识别20种包含远近景的花，做到95%的精度，那么我相信你完全有能力去应聘计算机视觉算法工程师了。</b></p><p><b>如果在框架上有什么问题，可以参考我们开源的12个主流的开源框架在各类任务中的使用git项目。</b></p><p><b>开源框架</b></p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032257%26idx%3D1%26sn%3D4b34be53841f6d4ecbec5056fb48880c%26chksm%3D8712b83cb065312a6e0730d277ecd67ed96799d98ebd7675174cba733b7d18bb3f4e9e1721e2%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】给新手的12大深度学习开源框架快速入门项目</a></li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-0e21c9ff9ffc0fcba1003955177fc544_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"630\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-0e21c9ff9ffc0fcba1003955177fc544_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;630&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"630\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-0e21c9ff9ffc0fcba1003955177fc544_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-0e21c9ff9ffc0fcba1003955177fc544_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/longpeng2008/yousan.ai</code></pre></div><p><b>以上内容，我在网易云有配套的视频讲解，也包含更多的细节补充，如果有需要可以自取，目前还有一些优惠券。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b26c363a06b002e87d73e55fafb541d5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b26c363a06b002e87d73e55fafb541d5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b26c363a06b002e87d73e55fafb541d5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b26c363a06b002e87d73e55fafb541d5_b.jpg\"/></figure><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032257%26idx%3D2%26sn%3Dcaaccb9fd9430568c79c08ea64d595b6%26chksm%3D8712b83cb065312a24c98d19e25477c11f954b76058fd2e02ca70d7d1422d522b77b1bea9a5a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【公开课】“有三说深度学习”上线</a> </li></ul><p><br/><b><u>有三AI生态</u></b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ff08fdab8c9c51b8911aa94a88b0851b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"647\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-ff08fdab8c9c51b8911aa94a88b0851b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;647&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"647\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-ff08fdab8c9c51b8911aa94a88b0851b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ff08fdab8c9c51b8911aa94a88b0851b_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f7504ce15b9013ef653c3942b89327c4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"854\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-f7504ce15b9013ef653c3942b89327c4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;854&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"854\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-f7504ce15b9013ef653c3942b89327c4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-f7504ce15b9013ef653c3942b89327c4_b.jpg\"/></figure><p>一些往期文章：</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032553%26idx%3D1%26sn%3D22ed241a40e034f57de670102c7ff942%26chksm%3D8712b914b06530027707a24b28491c0aece16af47ded8eee38888f67380cf44bbfb806190ca0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI产品】产品小姐姐分析抖音背后的计算机视觉技术</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031371%26idx%3D1%26sn%3D2954af734607abf72b7b7a665ed6306d%26chksm%3D8712bcb6b06535a0c9279d564e0a5c4f1447deb18e33d2029f0883ccf6e8f06eda569f71cd77%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】听完这12次分享，你应该完成了AI小白的蜕变</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032174%26idx%3D1%26sn%3D4eae7dbbad1bed09cc2a0dbfbd2f68e5%26chksm%3D8712bb93b0653285e5862654890351785d3a9e8f16a6f09902c5f0e942a18b3fea9581b61d21%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】12篇文章告诉你深度学习理论应该学到什么水平</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032609%26idx%3D1%26sn%3D98fa92d22758074d206c1d41982fc5f6%26chksm%3D8712b9dcb06530ca1980e24e44c60b740d08aeb6df6e76628accee820357260eb480f3c5956d%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】优秀的深度学习从业者都有哪些优秀的习惯</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032257%26idx%3D1%26sn%3D4b34be53841f6d4ecbec5056fb48880c%26chksm%3D8712b83cb065312a6e0730d277ecd67ed96799d98ebd7675174cba733b7d18bb3f4e9e1721e2%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】给新手的12大深度学习开源框架快速入门项目</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031450%26idx%3D1%26sn%3D3f7f159458e5f1621531ee107be11a98%26chksm%3D8712bd67b0653471c052e32b9d18a26f4d6a07852f56b50f6589b3baa7a46e1e44f302204a4e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】总结12大CNN主流模型架构设计思想</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031435%26idx%3D1%26sn%3Dcc349f988219b911c12518ed5fd94f3d%26chksm%3D8712bd76b065346056595cd43c2d8b61197c578ce5a324f494415b29b4bfe5706d2917f6c39a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】中国12大AI研究院，高调的低调的你pick谁</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649028860%26idx%3D1%26sn%3Dec1056fce8a00d14ad43cc0ac9c39b84%26chksm%3D87134681b064cf9742cd52dc5e68d585ac143fc237393e14d892c40d559621a682e467416312%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】一文道尽softmax loss及其变种</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029723%26idx%3D1%26sn%3D555a2d45fa210a1c5c5c703de54899a4%26chksm%3D87134226b064cb30f070ea5a2368f1c5bb6679d0f13e7e84b3f6374be33c549ce81a665d6e25%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】闲聊图像分割这件事儿</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030461%26idx%3D1%26sn%3D1ac88e15db361ebaefe8db609c48ae94%26chksm%3D87134140b064c85672c3de4b623d8b9471fae188f28fcac5dc1345795e1a9fc578ee2644a15c%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】万字长文详解Faster RCNN源代码</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031994%26idx%3D1%26sn%3Dae04649c15e8971a4a7156a607844164%26chksm%3D8712bb47b0653251b4a5895978c78538afa8b4f7a73f74384b8636774c72f3faa335633d8b6e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】基于弱监督深度学习的图像分割方法综述</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031947%26idx%3D1%26sn%3Dadf212fd818d30b73ac8fce88bb619b7%26chksm%3D8712bb76b0653260c1844b1df5eb6cea2b180ec8c7421283332a3d778179cb08ba8787fe0e85%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">免费GPU刷比赛，拿奖金，第100名也能赢！</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032522%26idx%3D1%26sn%3D036420c91bec27ed9a6201b0afdd51b5%26chksm%3D8712b937b0653021d8c407629db19fffac25a7293ecf7cce686b7e3beeada17c3da95d13239c%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">有三AI VIP会员发售，你的私人AI顾问已上线</a></p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031789%26idx%3D1%26sn%3D6ffd3ec9cb53241139fb0bc54292c01a%26chksm%3D8712ba10b0653306536efadd74921663bca3ec43fec611e078f6a03d0de4ef1e4364ceee3149%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">重新解释“季”划 &amp; 为什么我不是在搞培训</a></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "面试技巧", 
                    "tagLink": "https://api.zhihu.com/topics/19591490"
                }
            ], 
            "comments": [
                {
                    "userName": "Cheney", 
                    "userLink": "https://www.zhihu.com/people/afb534fdfd93b65291148a0f748c2eca", 
                    "content": "老哥，写的太好了吧！支持支持", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "多谢🙏🙏", 
                            "likes": 0, 
                            "replyToAuthor": "Cheney"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>看得眼泪都要出来了</p><a class=\"comment_sticker\" href=\"https://pic3.zhimg.com/v2-cb8443f07a41298e45191cef11b90fd2.gif\" data-width=\"\" data-height=\"\">[干杯]</a>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<p>😂，谢谢，有收获就好</p>", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "写的太好了大哥[赞同]", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "谢谢，有用就好！", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "Q-light", 
                    "userLink": "https://www.zhihu.com/people/6d9ee4a2f1cf3f79b6e94da7afff3faf", 
                    "content": "非常有收获[赞][赞]", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "[握手][握手][握手]", 
                            "likes": 0, 
                            "replyToAuthor": "Q-light"
                        }
                    ]
                }, 
                {
                    "userName": "chen", 
                    "userLink": "https://www.zhihu.com/people/cc36c7046f0ea3fc04fe35d82836d241", 
                    "content": "太棒了", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "谢谢🙏", 
                            "likes": 0, 
                            "replyToAuthor": "chen"
                        }
                    ]
                }, 
                {
                    "userName": "如故", 
                    "userLink": "https://www.zhihu.com/people/689fd2dca4fe95f5cf0d53d4b7825397", 
                    "content": "写的很好(✪▽✪)啊，感觉就像是行进路途中多了一盏明灯", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "[机智][机智]", 
                            "likes": 0, 
                            "replyToAuthor": "如故"
                        }
                    ]
                }, 
                {
                    "userName": "zaf赵", 
                    "userLink": "https://www.zhihu.com/people/4a13a2358d6303d063335f0c8fcc4b72", 
                    "content": "写的很全，但是面也太广，能做到你说的全部精通少之又少，所以得分清重点和主次，没有那么多精力。", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "先知全貌嘛，后面再深耕", 
                            "likes": 0, 
                            "replyToAuthor": "zaf赵"
                        }
                    ]
                }, 
                {
                    "userName": "fool bird", 
                    "userLink": "https://www.zhihu.com/people/685ca7594670221b7c8b33b5ec8e273f", 
                    "content": "Very good", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "[握手][握手]", 
                            "likes": 0, 
                            "replyToAuthor": "fool bird"
                        }
                    ]
                }, 
                {
                    "userName": "领衔主演", 
                    "userLink": "https://www.zhihu.com/people/ad0ed739a8c785dc9d01be5d3693794e", 
                    "content": "给大佬点赞[赞]", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "[耶][耶]", 
                            "likes": 0, 
                            "replyToAuthor": "领衔主演"
                        }
                    ]
                }, 
                {
                    "userName": "丁歌", 
                    "userLink": "https://www.zhihu.com/people/a31d4f812840e0021b7648099f9d720e", 
                    "content": "<p>偶尔的机会看到了这篇文章，写的太好了，感谢大佬</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "[握手][握手]", 
                            "likes": 0, 
                            "replyToAuthor": "丁歌"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/60845159", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 162, 
            "title": "【完结】12篇文章告诉你深度学习理论应该学到什么水平", 
            "content": "<p>专栏《AI初识境》正式完结了，在这一个专题中，我们给大家从<b>神经网络背景与基础</b>，讲到了<b>深度学习中的激活函数，池化，参数初始化，归一化，优化方法，正则项与泛化能力</b>，讲到了深度学习中的<b>评测指标，优化目标</b>，以及新手开始做训练时的<b>注意事项</b>。</p><p>消化完这12期文章后，你肯定具备了扎实的深度学习理论基础，接下来就大胆地往前走吧，下面再次回顾提炼一下主要内容。</p><p>                                                                                                                            作者&amp;编辑 | 言有三<br/></p><h2><b>1、人工智能简史</b></h2><p>按照中国古代思想家荀子在《荀子·正名篇》的说法：“所以知之在人者谓之知，知有所合谓之智。所以能之在人者谓之能，能有所合谓之能”。老人家认为，智能包含了两层含义，当然这是站在哲学的角度。</p><p>霍华德·加德纳的多元智能理论中将人类的智能分成七种能力：</p><p>(1) 语言 (Verbal/Linguistic) </p><p>(2) 逻辑 (Logical/Mathematical) </p><p>(3) 空间 (Visual/Spatial) </p><p>(4) 肢体运作 (Bodily/Kinesthetic) </p><p>(5) 音乐 (Musical/Rhythmic) </p><p>(6) 人际 (Inter-personal/Social) </p><p>(7) 内省 (Intra-personal/Introspective)</p><p>基本覆盖了现在人工智能的研究领域，包括计算机视觉，语音识别，自然语言处理等。</p><p>在这一篇文章里，会从图灵与机器智能，冯诺伊曼与类脑计算，约翰·麦卡锡（John McCarthy）、马文·闵斯基（Marvin Minsky，人工智能与认知学专家）、克劳德·香农（Claude Shannon，信息论的创始人）、艾伦·纽厄尔（Allen Newell，计算机科学家）、赫伯特·西蒙（Herbert Simon，诺贝尔经济学奖得主），塞弗里奇(Oliver Selfridge)等科学家参与的达特茅斯会议讲起。</p><p>从人工智能的启蒙，到三次浪潮的曲折和技术的成长史，值得每一个从事该行业的人阅读。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"855\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;855&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"855\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-05b0ebd17b2b1748d4a24ed6e695f623_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/56679585\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/v2-c838c0fedc57d7355c532d543a257aa4_180x120.jpg\" data-image-width=\"2280\" data-image-height=\"1805\" class=\"internal\">龙鹏-言有三：【AI初识境】从3次人工智能潮起潮落说起</a><h2><b>2、神经网络</b></h2><p>人工智能的研究派系分为两大阵营。</p><p><b>第一大阵营，被称为符号派。</b>他们用统计逻辑和符号系统来研究人工智能。<b>第二大阵营是统计派。</b>现在的深度学习就属于这一派，研究问题的方法就是仿造大脑。</p><p>这一篇从感受野，到MP模型，到感知机，到反向传播开始讲起，历数全连接神经网络的劣势，然后讲述卷积神经网络的特点，核心技术和优势，是学习深度学习最重要的基础。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fe210c865a491c5b51119b7d3c8eae0e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fe210c865a491c5b51119b7d3c8eae0e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fe210c865a491c5b51119b7d3c8eae0e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fe210c865a491c5b51119b7d3c8eae0e_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57004263\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-0677a0f6d88f26e186cb7262faeb8912_ipico.jpg\" data-image-width=\"800\" data-image-height=\"800\" class=\"internal\">龙鹏-言有三：【AI初识境】从头理解神经网络-内行与外行的分水岭</a><h2><b>3、图像领域的突破</b></h2><p>既然学深度学习，就必须要了解深度学习的重要进展。</p><p>在前深度学习时代，视觉机制的发现，第一个卷积神经网络Neocognitron的提出，反向传播算法的流行，促进了LeNet5和MNIST数据集的诞生。</p><p>随着新理论的成熟，大数据的积累，GPU的普世，以卷积神经网络为代表的技术在图像分类，目标检测等基础领域取得重大突破，随着AlphaGo的成功同时在业内和业外人士的心目中种下了深度学习/人工智能技术的种子，从此焕发勃勃生机。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"851\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb\" width=\"851\" data-original=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;851&#39; height=&#39;476&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"851\" data-rawheight=\"476\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"851\" data-original=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e1a625d4d0c93622dc333f443ac4c233_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57258501\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-dc794684fce2037f11dba0a0d699a476_180x120.jpg\" data-image-width=\"851\" data-image-height=\"476\" class=\"internal\">龙鹏-言有三：【AI初识境】近20年深度学习在图像领域的重要进展节点</a><h2><b>4、激活函数</b></h2><p>深度学习的机制模仿于人脑，人脑的细胞接受刺激从而产生活动需要一定的阈值，这便是激活函数根本性的由来。</p><p>激活函数肩负着网络非线性表达能力的提升，从早期平滑的sigmoid和tanh激活函数，到后来的ReLU和各类ReLU的变种(LReLU，PReLU，RReLU，ELU，SELU，GELU等等)，Maxout，研究者一直试图让网络拥有更好的表达能力。</p><p>随着技术的发展，利用增强学习等算法从函数池中学习新的激活函数如swish等，成为了当下的研究主流，激活函数也走上了数据驱动的道路。</p><p>激活机制看似简单，实则不易，大家不妨多了解了解。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d22f63d3427b234510e0f9d50a7367ab_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"850\" data-rawheight=\"632\" class=\"origin_image zh-lightbox-thumb\" width=\"850\" data-original=\"https://pic4.zhimg.com/v2-d22f63d3427b234510e0f9d50a7367ab_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;850&#39; height=&#39;632&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"850\" data-rawheight=\"632\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"850\" data-original=\"https://pic4.zhimg.com/v2-d22f63d3427b234510e0f9d50a7367ab_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-d22f63d3427b234510e0f9d50a7367ab_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57258642\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-d77be8239bcac6884448f021ca7eba29_180x120.jpg\" data-image-width=\"602\" data-image-height=\"325\" class=\"internal\">龙鹏-言有三：【AI初识境】激活函数：从人工设计(sigmoid,relu)到自动搜索(swish)</a><h2><b>5、初始化</b></h2><p>参数初始化，一个看似很简单的问题，却实实在在地困住了神经网络的优化很久，2006年Hinton等人在science期刊上发表了论文“Reducing the dimensionality of data with neural networks”，揭开了新的训练深层神经网络算法的序幕，仍旧被认为是当前第三次人工智能热潮的纪元。</p><p>从全零初始化和随机初始化，到标准初始化，Xavier初始化，He初始化，时至今日上千层网络的训练都已经成为了现实，初始化似乎已经不再是那么重要的课题了，但是谁说就没有思考的空间了呢。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;372&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f9232ca150d2dffeefad60b0465df25e_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57454669\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-6cf5bc9885e71e3eb71843e5b8d9ffaa_180x120.jpg\" data-image-width=\"1592\" data-image-height=\"554\" class=\"internal\">龙鹏-言有三：【AI初识境】什么是深度学习成功的开始？参数初始化（xavier，he等）</a><h2><b>6、归一化</b></h2><p>我们总是希望所研究的统计问题能够满足固定的分布，而且这样也的确会降低问题的难度。</p><p>在深度学习中，因为网络的层数非常多，如果数据分布在某一层开始有明显的偏移，随着网络的加深这一问题会加剧，进而导致模型优化的难度增加。</p><p>归一化便是致力于解决这个问题，从数据到权重，从限定在同一样本的一个特征通道到不同样本的所有通道，各类归一化方法以简单的方式，优雅地解决了深度学习模型训练容易陷入局部解的难题，顺带提升训练速度提高泛化能力，这是一定要掌握的理论和工程技巧。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"681\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;681&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"681\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-1e548ada32c40c0175ef5bc58024e5ca_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57609506\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-1aa8a8e9ff5ebb7bc4ec740ec52f503d_180x120.jpg\" data-image-width=\"1380\" data-image-height=\"870\" class=\"internal\">龙鹏-言有三：【AI初识境】深度学习模型中的Normalization，你懂了多少？</a><h2><b>7、池化</b></h2><p>大脑学习知识靠抽象，从图像中抽象知识是一个“从大到小”过滤提炼信息的过程。从视觉机制中来的pooling即池化，正是对信息进行抽象的过程。</p><p>池化增加了网络对于平移的不变性，提升了网络的泛化能力，大家已经习惯了使用均值池化mean pooling和最大池化(max pooling)，虽然可以用带步长的卷积进行替代。</p><p>尽管池化究竟起到了多大的作用开始被研究者怀疑，但是池化机制仍然是网络中必备的结构，所以你一定要熟悉它，而且基于数据驱动的池化机制值得研究。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b75c85872f6bc39cbe8701efa323d3ee_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1022\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb\" width=\"1022\" data-original=\"https://pic3.zhimg.com/v2-b75c85872f6bc39cbe8701efa323d3ee_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1022&#39; height=&#39;338&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1022\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1022\" data-original=\"https://pic3.zhimg.com/v2-b75c85872f6bc39cbe8701efa323d3ee_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b75c85872f6bc39cbe8701efa323d3ee_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/58381421\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-54d338dbb40ee32579e7806cf3488ef5_180x120.jpg\" data-image-width=\"1017\" data-image-height=\"503\" class=\"internal\">龙鹏-言有三：【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化(pooling)，到底是什么？</a><h2><b>8、最优化</b></h2><p>模型的学习需要通过优化方法才能具体实现。深度学习模型的优化是一个非凸优化问题，尽管一阶二阶方法都可以拿来解决它，但是当前随机梯度下降SGD及其各类变种仍然是首选。</p><p>从SGD开始，有的致力于提高它的优化速度如Momentum动量法和Nesterov accelerated gradient法，有的致力于让不同的参数拥有不同的学习率如Adagrad，Adadelta与Rmsprop法，有的希望大家从调参中解脱如Adam方法及其变种，有的致力于让收敛过程更加稳定如Adafactor方法和Adabound方法。</p><p>没有一个方法是完美的，训练的时候总归要试试。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b3b26baa046f4c61f75d4358f02e869d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"773\" data-rawheight=\"547\" class=\"origin_image zh-lightbox-thumb\" width=\"773\" data-original=\"https://pic2.zhimg.com/v2-b3b26baa046f4c61f75d4358f02e869d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;773&#39; height=&#39;547&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"773\" data-rawheight=\"547\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"773\" data-original=\"https://pic2.zhimg.com/v2-b3b26baa046f4c61f75d4358f02e869d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b3b26baa046f4c61f75d4358f02e869d_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/57860231\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-ef9968db2cb4a05e712ef17a8b53bc71_180x120.jpg\" data-image-width=\"773\" data-image-height=\"547\" class=\"internal\">龙鹏-言有三：【AI初识境】为了围剿SGD大家这些年想过的那十几招(从momentum到Adabound)</a><h2><b>9、泛化能力</b></h2><p>如果一个模型只能在训练集上起作用，那不就成为了书呆子要其何用。</p><p>因此我们总是希望模型不仅仅是对于已知的数据(训练集)性能表现良好，对于未知的数据(测试集)也表现良好，即具有良好的泛化能力，通过添加正则项来实现。</p><p>从直接提供正则化约束的参数正则化方法如L1/L2正则化，工程上的技巧如训练提前终止和模型集成，以及隐式的正则化方法如数据增强等，研究人员在这方面投入的精力非常多，大家一定要时刻关注。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"830\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"830\" data-original=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;830&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"830\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"830\" data-original=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-0574c6f9664547b3c7118a39640ac00d_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/58903870\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/v2-98891186659ff40f86c5fcd27cb5f624_180x120.jpg\" data-image-width=\"1168\" data-image-height=\"558\" class=\"internal\">龙鹏-言有三：【AI初识境】如何增加深度学习模型的泛化能力(L1/L2正则化，dropout，数据增强等等)</a><h2><b>10、模型评估</b></h2><p>口说无凭，用数据说话才是研究者们进行PK的正确姿态。计算机视觉的任务何其多，从分类，回归，质量评估到生成模型，这篇文章就全部都来说一遍。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5c70412d959e0594a78102fbd9daa2b3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"827\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-5c70412d959e0594a78102fbd9daa2b3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;827&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"827\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-5c70412d959e0594a78102fbd9daa2b3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5c70412d959e0594a78102fbd9daa2b3_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/59481933\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-cf839c9a3bbee4fddf4fe86782f59396_180x120.jpg\" data-image-width=\"1200\" data-image-height=\"919\" class=\"internal\">龙鹏-言有三：【AI初识境】深度学习模型评估方法，从分类，回归，质量评价到生成模型</a><h2><b>11、损失函数</b></h2><p>模型的学习需要指导，这正是损失函数的责任，它往往对模型最终表现如何影响巨大。</p><p>这一篇文章就重点总结分类问题，回归问题，生成对抗网络中使用的损失目标，为大家设计更好的优化目标奠定理论基础。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c574f0635b2f51e7ab72eacf751a5ddf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"487\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c574f0635b2f51e7ab72eacf751a5ddf_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;487&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"487\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c574f0635b2f51e7ab72eacf751a5ddf_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c574f0635b2f51e7ab72eacf751a5ddf_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/60302475\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-719f196bca887827213781b5cd65c0d1_180x120.jpg\" data-image-width=\"1884\" data-image-height=\"850\" class=\"internal\">龙鹏-言有三：【AI初识境】深度学习中常用的损失函数有哪些（覆盖分类，回归，风格化，GAN等任务）？</a><h2><b>12、如何开始训练你的模型</b></h2><p>磨刀不误砍柴工，当我们开始训练自己的模型的时候，总归要想清楚一些事儿再动手。</p><p>第一步知道你要做的任务是一个什么任务，找到竞争对手做好预期，想好你需要什么样的数据。第二步确定好框架，基准模型，准备好数据。然后才是第三步开始训练，从输入输出，数据的预处理到维持正确地训练姿势。</p><p>既然是总结出来的经验，想必总是有用的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"764\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;764&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"764\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c8b56daa4d21e31fd8a3b0fbe23594a8_b.jpg\"/></figure><a href=\"https://zhuanlan.zhihu.com/p/60546840\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-214b997ad0cf9fa313090f57579d8052_180x120.jpg\" data-image-width=\"4096\" data-image-height=\"2896\" class=\"internal\">龙鹏-言有三：【AI初识境】给深度学习新手开始项目时的10条建议</a><h2><b>总结</b></h2><p>相信经过这一个系列后，大家应该都夯实了自己的深度学习基础，从此向着更高的目标前进。</p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": [
                {
                    "userName": "杨雨林", 
                    "userLink": "https://www.zhihu.com/people/166c730319d89371b757cfea149edad8", 
                    "content": "赞", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "🤝🤝", 
                            "likes": 0, 
                            "replyToAuthor": "杨雨林"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "非常好👍", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "谢谢", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/60546840", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 33, 
            "title": "【AI初识境】给深度学习新手开始项目时的10条建议", 
            "content": "<p>这是专栏《AI初识境》的第12篇文章。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>在成为合格的深度学习算法工程师，尤其是工业界能够实战的调参选手之前，总会踏足很多的坑。</p><p>今天就来说说那些需要掌握的基本技巧，如何避开那些新手常见的坑，以计算机视觉中的图像分类任务为例。</p><p><b>请注意，这篇文章不是教你如何调参，而是教你不要在调参之前胡搞。</b></p><p>                                                                                                                          作者&amp;编辑  | 言有三</p><h2><br/><b>1 项目开发之前应该做什么</b></h2><p><b>在你真正开始撸代码之前，送大家一句话，“磨刀不误砍柴工”。</b></p><p>拿到一个任务的时候，先不要上来就开始训模型，而是做好三件事。</p><p><b>1.1、知道你要做的任务是一个什么任务。</b></p><p>以图像分类为例，猫狗分类是一个分类任务，随便找个什么模型都能完成。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-cab22c883a6255b2e229ac727f54d7ad_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-cab22c883a6255b2e229ac727f54d7ad_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;608&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"608\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-cab22c883a6255b2e229ac727f54d7ad_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-cab22c883a6255b2e229ac727f54d7ad_b.jpg\"/></figure><p>鸟类分类也是一个分类任务，但是不简单，不是随随便便拿个模型就能搞定。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-69df96246715e9733d398e1392174f79_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"419\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-69df96246715e9733d398e1392174f79_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;419&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"419\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-69df96246715e9733d398e1392174f79_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-69df96246715e9733d398e1392174f79_b.jpg\"/></figure><p>表情识别最终也是一个分类，但是这不仅仅是一个分类问题，而是检测+分类问题。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5936fea7190e080f859bc70a7beea5e4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"550\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5936fea7190e080f859bc70a7beea5e4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;550&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"550\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5936fea7190e080f859bc70a7beea5e4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5936fea7190e080f859bc70a7beea5e4_b.jpg\"/></figure><p>产品经理们只会告诉你要实现什么功能，而不会告诉你用什么方案，对于简单任务来说这可能不需要思考，但是复杂任务一定要先充分调研认识。</p><p>你说上面的这个例子很简单，一眼就明白，那么我再举出几个例子，你是否一下子就能明白背后的核心技术？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d50425c20dc25c5717a779a24423740a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"982\" data-rawheight=\"424\" class=\"origin_image zh-lightbox-thumb\" width=\"982\" data-original=\"https://pic3.zhimg.com/v2-d50425c20dc25c5717a779a24423740a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;982&#39; height=&#39;424&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"982\" data-rawheight=\"424\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"982\" data-original=\"https://pic3.zhimg.com/v2-d50425c20dc25c5717a779a24423740a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d50425c20dc25c5717a779a24423740a_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c7976b7c87a19b605eca04810489a7a2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-c7976b7c87a19b605eca04810489a7a2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;416&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"416\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-c7976b7c87a19b605eca04810489a7a2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c7976b7c87a19b605eca04810489a7a2_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f14ebb0d23b8eb6be8e8196239e8e80b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"460\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic4.zhimg.com/v2-f14ebb0d23b8eb6be8e8196239e8e80b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;800&#39; height=&#39;460&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"460\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"800\" data-original=\"https://pic4.zhimg.com/v2-f14ebb0d23b8eb6be8e8196239e8e80b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f14ebb0d23b8eb6be8e8196239e8e80b_b.jpg\"/></figure><p><b>1.2、找到竞争对手，做好预期。</b></p><p>比如你要做一个表情识别API，要做一个美颜算法，一定要先看看你的竞争对手做的怎么样了，就算最后你做出来跟别人还差十万八千里，也不至于到最后一刻才发觉。<b>这叫知人之明和自知之明，一定要先有。</b></p><p>在这个过程中，基本上就能确定要走的路，<b>第一条路是追随模仿别人，第二条路是超越别人</b>，这两者是不一样的。</p><p>前者，只要把已有成熟的资料收集到位，经验足够丰富，必定能成功，否则就是个人能力和资源问题。这样的一条路，相信老大们会给你布置一个明确的时间节点。</p><p>比如表情识别，很成熟，那你做出来也不能比别人差太多。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a315ca7304e3d089890bdfe6543f71f5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https://pic2.zhimg.com/v2-a315ca7304e3d089890bdfe6543f71f5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;720&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"720\" data-original=\"https://pic2.zhimg.com/v2-a315ca7304e3d089890bdfe6543f71f5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a315ca7304e3d089890bdfe6543f71f5_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>如果是第二条路，那么就意味着没有参考者，或者参考者做的也不行。那么最难的是什么，就是预期能做到什么水平。</p><p><b>可能技术已经成熟了，没人做，恭喜你，赶紧搞。</b></p><p><b>可能技术比较前沿，能做技术储备，但是还无法落地。</b></p><p><b>可能根本就还做不了。</b></p><p><b>1.3、想好你需要什么样的数据，从源头上降低任务的难度。</b></p><p>在公司干了四年活，大部分项目都需要自己准备数据，不会有现成的数据可以使用，而如何准备数据，这是需要经验的。</p><p>举个最简单的例子，假如我们需要开发一个分类算法来分析一张图片中的人是不是在笑，图像可能是这样。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-e18b83dce5a4ed99a5a1e9c905f41e06_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-e18b83dce5a4ed99a5a1e9c905f41e06_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;312&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"312\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-e18b83dce5a4ed99a5a1e9c905f41e06_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-e18b83dce5a4ed99a5a1e9c905f41e06_b.jpg\"/></figure><p>你会爬取或者从数据集中拿到很多不同表情的数据然后就直接开干吗？显然那是错误的路子。</p><p>开始一个任务后我们首先就应该想怎么降低任务的难度，对于此任务，起作用的只有嘴唇这块区域，那么我们完全可以基于嘴唇区域来训练一个分类模型。</p><p>高精度成熟的人脸检测和关键点检测算法是很多的，所以你可能需要准备的训练数据是这样的。当然，如果你直接基于关键点的结果来做也是可以的，这就回到了第一个问题了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ca5ac475f5f660a6c3b7acff350fd716_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"159\" class=\"origin_image zh-lightbox-thumb\" width=\"514\" data-original=\"https://pic3.zhimg.com/v2-ca5ac475f5f660a6c3b7acff350fd716_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;514&#39; height=&#39;159&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"159\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"514\" data-original=\"https://pic3.zhimg.com/v2-ca5ac475f5f660a6c3b7acff350fd716_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ca5ac475f5f660a6c3b7acff350fd716_b.jpg\"/></figure><p>这样至少有两个好处，(1) 明显这个分类更加简单了。(2) 可以使用更小的输入图完成任务，计算代价也更低。</p><h2><b>2 训练模型从哪里开始</b></h2><p>很少有一个任务可以拿现有的模型使用，你通常是需要训练自己的模型的，那么在训练一个模型的时候，应该怎么样开始。</p><p>这里牵涉到3个问题，框架，基准模型和数据，其中任何一环都有可能有问题。</p><p><b>2.1、首先确定框架</b></p><p>没有一个深度学习任务不需要一个框架来训练，很多的时候你不得不在不同的框架之间进行切换。比如做分类分割或者检测，caffe都很好用。做风格化搞GAN，就得上tensorflow或者pytorch了，你一定要先选择一个工具，不然很可能会陷入找到了很多中github方案，这个试了遇到困难换下一个，下一个又遇到困难。</p><p>有自己最拿手的一个框架，选定项目就坚定地干，遇到了问题就去解决。</p><p>关于框架，大家可以从我们的系列文章中开始快速上手。</p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029896%26idx%3D1%26sn%3Df3f7b9cf69c514f45d1d14205f879270%26chksm%3D87134375b064ca6323354c40f3e55b02ff0d1d24f3dacfc980190d51f20ec9ec16e60c1a4741%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【Keras速成】Keras图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029887%26idx%3D1%26sn%3D645b97809c24922352a0b39f19c9ef0c%26chksm%3D87134282b064cb9441af68124d205d9c7dedcaeb09788f4d586b949584e556eddd3a72217f69%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【paddlepaddle速成】paddlepaddle图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029881%26idx%3D1%26sn%3D3c869fcee3b48d3582952ab9a0683ea6%26chksm%3D87134284b064cb924c5e7231b3f2c36ba27e3a689b067f569f2e086f62b18413bcebc5987a07%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【pytorch速成】Pytorch图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029846%26idx%3D2%26sn%3D7c2582243bcd8f8b491e8e466a21978f%26chksm%3D871342abb064cbbd0cba24b408ceda2b64a7c8b6baa07f9f8f56cd4d1233caa0b80fe357753e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【tensorflow速成】Tensorflow图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029846%26idx%3D1%26sn%3D0c343cfd0ede5c8ae1405bd6348aefad%26chksm%3D871342abb064cbbd7fe31fb3c55f23875f27e48fb8354e9855823b1701f1227c71b4eb00de50%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【caffe速成】caffe图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029904%26idx%3D1%26sn%3D0bdc6947f5ac68e7f68426b9d076b4ab%26chksm%3D8713436db064ca7b3b2a2a1d6a8d24c15069f72655e2c39e2498051fa0e56bbcf6fe9c332d5b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【mxnet速成】mxnet图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030976%26idx%3D1%26sn%3D0befc170a93d365b780c5f05b2f510a4%26chksm%3D8712bf3db065362b0aeaae82bdbac467be5697b34cac2797e2ee15cdcb97474c08640482bf07%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【cntk速成】cntk图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032012%26idx%3D1%26sn%3Df74c7084621f367adb2518ebec61ca42%26chksm%3D8712bb31b06532270b9ca9550ab48ff78adaad7d38c73645cfb8888218b8e177bebd5d401aa9%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【DL4J速成】Deeplearning4j图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031911%26idx%3D2%26sn%3Da95856836c0d8832b9e5fe49704c6313%26chksm%3D8712ba9ab065338c28d86ff10bff58bcda404bfc0efc68f0a9c0ba20a2126d917cc701c6b4ae%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【chainer速成】chainer图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032109%26idx%3D2%26sn%3Da6ff48ec0ae5d8e7a494df7e564d9ac9%26chksm%3D8712bbd0b06532c61d98c786ba1773c29c3dcf1291f9c3cd052c5643e24699eef28481e94b8e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【MatConvnet速成】MatConvnet图像分类从模型自定义到测试</a></li></ul><p><b>2.2、然后确定基准模型</b></p><p>最终工业级部署的时候，你往往需要一个效率更高的模型。但是除非你是老司机，否则不应该在还没有确定方案是否可行的时候就想自己的模型，而是应该<b>从一个绝对可靠的模型开始</b>，比如resnet18，比如mobilenet，正确地使用好它们，得到还不错的结果，将它的结果作为你自己算法要PK的对象。</p><p>关于基准模型，我们已经把最主要的模型全部解读了一遍，可以从中选择。</p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031450%26idx%3D1%26sn%3D3f7f159458e5f1621531ee107be11a98%26chksm%3D8712bd67b0653471c052e32b9d18a26f4d6a07852f56b50f6589b3baa7a46e1e44f302204a4e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【完结】总结12大CNN主流模型架构设计思想</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D2%26sn%3Da8adb80cc4270662a087334c63a982d1%26chksm%3D8712bc72b0653564d4c0c149d51643d2df245774f8a69bc61d2d792abdd9bb191d109ff80632%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从2D卷积到3D卷积，都有什么不一样</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D2%26sn%3D90755895232f413d1594fc43a43c4830%26chksm%3D8712bcc6b06535d0d7e0ad1d9625deb2c729cb7d5f4d4164a5ce1f1ffb7bfcad652a7b2a4bbf%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】浅析RNN到LSTM</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031435%26idx%3D2%26sn%3D402ad26ffeac98d3a4710bef0e8adbfb%26chksm%3D8712bd76b0653460d4a5fd1176b87bf534085f85ae9494eb204725b3a5836588f3bf5158cc41%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】历数GAN的5大基本结构</a></li></ul><p><b>2.3、最后准备好数据</b></p><p>在前面你想好自己需要的数据了，接下来就是去采集到这些数据。完成一个项目，就是不断迭代模型和数据的过程。</p><p>刚开始的时候，你不需要数据都到位，但是要考虑好以下因素。这里我们不管数据是自己采集的还是从公开数据集中获取的。</p><p><b>(1) 准备大小合适的数据量</b>。以二分类任务为例，你不能拿500张图就开始干，没任何意义。你不能苛求一开始就有50000万数据，也不合理，万一搞失败了还浪费资源。笔者先后做过10余个分类任务，完成任务上线从3000到10万都用过，我的建议是，尽量先准备个3000数据再开干，不然就太没诚意了。</p><p><b>(2) 从简单数据开始</b>。以人脸识别为例，各种公开数据集不要混着用，分布不一致难度也不相同，你应该先专注简单的属于同一个分布的，比如找10000个正脸或者姿态小的数据，方案验证通过之后再增加难度。</p><p>很多的时候，你还要考虑覆盖各种场景(光照，背景)等。以上的这些东西，书不会告诉你，培训也没法教你，需要的是自己的积累，厚积薄发。</p><p>培养对数据的敏感性，可以从咱们的数据相关的文章开始看。</p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030010%26idx%3D1%26sn%3D76e0123bf24064c4cb1eb7acacac86fd%26chksm%3D87134307b064ca1169f6412000bd44da1852ca2854f659fb341356d2d1e61a1c883a555fb0ca%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【数据】深度学习从“数据集”开始</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029110%26idx%3D1%26sn%3D4debbbe890b48ab739fec5967868746b%26chksm%3D8713478bb064ce9da68dd57b419ddebd22884c05747abb9286c1e5bc6563702f2a1fd4bcac64%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】深度学习中的数据增强（下）</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029048%26idx%3D1%26sn%3Dec708683cb6a3c2ed048a945a7150b79%26chksm%3D871347c5b064ced3fd3d57c5c79df0087890efb10898076efb14e9ece8ddf38906dbaf33af2c%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[综述类] 一文道尽深度学习中的数据增强方法（上）</a></li></ul><h2><b>3 正确训练模型的基本常识</b></h2><p>终于讲到训练模型了，程序员干活从来不会一帆风顺，你的小模型不会这么听话，以下是一些必须要注意的事项，不管用什么框架都适用。</p><p><b>3.1 注意网络的输入大小</b></p><p>你极有可能是从finetune其他的模型开始，以图像分类为例，公开的模型大多是以224*224为尺度，而你的任务未必也需要这样。</p><p>如果你想要区分不同种类的鸟，那么因为细节在鸟的局部身体部位，你的输入恐怕是要更大一些才能提取到好的特征，比如放大一倍，用448*448，这也是论文中常用的。</p><p>如果你只是要区分不同表情，用上了上面的嘴唇数据，那224*224纯属浪费，你可能只需要一个48*48的输入就足以很高准确率完成任务。</p><p>对于图像分割和目标检测，标准又不太一样。究竟使用多大的输入，这需要你依靠经验来确定，而且还和能给你多少资源，以及自己优化模型的能力相关。</p><p><b>3.2 注意特征输出大小</b></p><p>前面说了输入，这里再说输出，包括最后一层卷积的大小和通道数等。</p><p>首先看大小，对于一个分类任务来说，最后卷积层抽象为一个k*k的特征图，然后进行池化，全连接。如果这个特征图太大，知识根本就没有抽象出来，如果太小，表征能力又可能不够。</p><p>根据不同的难度，3*3，5*5，7*7我都用过，但是没有用过9*9以上的，试过分类性能会下降，计算量还增加。imagenet竞赛的那些网络基本上都是7*7，兼顾了性能。</p><p>这个输出大小，就由<b>输入大小和网络的全局stride</b>来决定，不断遇到很多同学没有注意这个问题，结果模型性能很差的，这是基本素质。</p><p><b>3.3 正确地使用数据</b></p><p>前面已经准备了一些好的数据，别在用的时候却搞错了，对于图像分类来说有以下几个准则</p><p><b>(1) 随机打乱你的数据。</b></p><p>否则每个batch给的是同样类别的数据，不一定能保证模型学的正常。</p><p><b>(2) 在线做一些基本的数据预处理和增强。</b></p><p><b>图像缩放操作</b>，你要想好是用有变形的缩放，即统一缩放到固定大小。还是等比例缩放，即把短边缩放到一定尺度。</p><p><b>裁剪操作</b>，随机裁剪是最简单有效的数据增强方案，一开始就可以做起来，比如256*256随机裁剪224*224，不必要过于复杂。</p><p><b>镜像操作</b>，也就是mirror参数，不是所有的任务都可以翻转的，根据自己任务使用。</p><p><b>减均值和归一化操作</b>，其实这一步倒并非必要，因为网络自然可以学习到这一点。不过你做一下，通常不会有副作用。</p><p>更多的数据增强先不要急着做，因为那会增加网络优化的难度和时间。</p><p>这些操作都要在线做而不是离线准备好存入本地文件，这是很低效的。</p><p><b>3.4 正确地进行训练</b></p><p>接下来就开始训练，你可能会遇到各种与自己期望不相符的结果，其中一些很可能是你自己的错误造成的，因此有一些基本的训练参数需要注意。</p><p><b>(1) 用好学习率策略。</b></p><p>如果你没有经验，就不要一开始就使用SGD，虽然它可能取得更好的结果。直接用Adam，并且使用它的默认参数m1=0.9，m2=0.999，lr=0.001，学习率可以调整，其他两个参数基本不需要动。更多比较可以参考我们之前的文章。如果你的学习率搞的不好，很可能出现梯度爆炸或者不收敛。</p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030692%26idx%3D1%26sn%3D6322e8eec12d8a8b60f578a9ebb4b42c%26chksm%3D8712be59b065374f00dc9b3715e6453e2de5d05262ee4eac47ef5efe6d167703af67f5882029%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型训练】如何选择最适合你的学习率变更策略</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030739%26idx%3D1%26sn%3D96a2850020f99050f4440caee3b152a7%26chksm%3D8712be2eb0653738eace8cceb8923edeac0c2e96a7ae1d0ca1f942ea20ae51ff95e40829a408%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型训练】SGD的那些变种，真的比SGD强吗</a></li></ul><p><b>(2) 正确使用正则项。</b></p><p>weight decay是一个非常敏感的参数，如果你不是很有经验，从一个很小或者为0的值开始。</p><p>训练的时候可以用dropout，测试的时候是不需要用的。</p><p><b>(3) 正确使用BN层。</b></p><p>Batch Normalization是一个好东西，加快训练速度降低过拟合，但是你要注意它在训练的时候和测试的时候是不一样的。</p><p>use_global_stats这个参数在训练时是false，测试时是true，如果你没用对，那么可能训练无法进行，或者测试结果不对。</p><p>在训练过程中，你可能会遇到各种各样奇葩的问题。</p><p><b>比如网络loss不正常，怎么调都不管用。</b></p><p><b>比如训练好好的，测试就是结果不对。</b></p><p><b>bug天天有，深度学习算法工程师遇到的特别多，如果你想交流更多，就来有三AI知识星球实时提问交流吧，大咖众多，总有能解决你问题的。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;930&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"930\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-063252f2545670235045a5dd8c5a7426_b.jpg\"/></figure><p>初识境界到此基本就结束了，这一系列是为大家奠定扎实的深度学习基础，希望学习完后大家能有收获<i>。</i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a> </p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a> </p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/60302475", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 113, 
            "title": "【AI初识境】深度学习中常用的损失函数有哪些（覆盖分类，回归，风格化，GAN等任务）？", 
            "content": "<p>这是专栏《AI初识境》的第11篇文章。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>今天来说说深度学习中常见的损失函数(loss)，覆盖分类，回归任务以及生成对抗网络，有了目标才能去优化一个模型。</p><p>                                                                                                                           作者&amp;编辑 | 言有三<br/></p><h2><b>1 什么是损失函数</b></h2><p>在机器学习中，损失函数（loss function）是用来估量模型的预测值f(x)与真实值Y的不一致程度，损失函数越小，一般就代表模型的鲁棒性越好，正是损失函数指导了模型的学习。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-037ced7898e9c980d894d4745438160f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-037ced7898e9c980d894d4745438160f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-037ced7898e9c980d894d4745438160f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-037ced7898e9c980d894d4745438160f_b.jpg\"/></figure><p>机器学习的任务本质上是两大类，分类问题与回归问题，再加上综合了判别模型和生成模型后在各类图像任务中大展拳脚的生成对抗网络，这一次我们就重点讲述这些内容。<br/></p><h2><b>2 分类任务损失 </b></h2><p><b>2.1、0-1 loss</b></p><p>0-1 loss是最原始的loss，它直接比较输出值与输入值是否相等，对于样本i，它的loss等于：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-5567ae011f65d087d29138ac9139fb6a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"158\" class=\"origin_image zh-lightbox-thumb\" width=\"678\" data-original=\"https://pic3.zhimg.com/v2-5567ae011f65d087d29138ac9139fb6a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;678&#39; height=&#39;158&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"158\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"678\" data-original=\"https://pic3.zhimg.com/v2-5567ae011f65d087d29138ac9139fb6a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-5567ae011f65d087d29138ac9139fb6a_b.jpg\"/></figure><p>当标签与预测类别相等时，loss为0，否则为1。可以看出，0-1 loss无法对x进行求导，这在依赖于反向传播的深度学习任务中，无法被使用，0-1 loss更多的是启发新的loss的产生。</p><p><b>2.2、熵与交叉熵loss</b></p><p>在物理学有一个概念，就是熵，它表示一个热力学系统的无序程度。为了解决对信息的量化度量问题，香农在1948年提出了“信息熵”的概念，它使用对数函数表示对不确定性的测量。熵越高，表示能传输的信息越多，熵越少，表示传输的信息越少，我们<b>可以直接将熵理解为信息量</b>。</p><p>按照香农的理论，熵背后的原理是任何信息都存在冗余，并且冗余大小与信息中每个符号（数字、字母或单词）的出现概率或者说<b>不确定性</b>有关。概率大，出现机会多，则不确定性小，这个关系就用对数函数来表征。</p><p>为什么选择对数函数而不是其他函数呢？首先，不确定性必须是概率P的单调递降函数，假设一个系统中各个离散事件互不相关，要求其总的不确定性等于各自不确定性之和，对数函数是满足这个要求的。将不确定性f定义为log(1/p)=-log(p)，其中p是概率。</p><p>对于单个的信息源，信源的平均不确定性就是单个符号不确定性-logpi的统计平均值，信息熵的定义如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ab11be35c3e07380e225e5c4009a5f29_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"344\" data-rawheight=\"90\" class=\"content_image\" width=\"344\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;344&#39; height=&#39;90&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"344\" data-rawheight=\"90\" class=\"content_image lazy\" width=\"344\" data-actualsrc=\"https://pic2.zhimg.com/v2-ab11be35c3e07380e225e5c4009a5f29_b.jpg\"/></figure><p>假设有两个概率分布p(x)和q(x)，其中p是已知的分布，q是未知的分布，则其交叉熵函数是两个分布的互信息，可以反应其相关程度。</p><p><b>从这里，就引出了分类任务中最常用的loss，即log loss，又名交叉熵loss，后面我们统一称为交叉熵：</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4f2006551c8165f35265c668fff2123f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"628\" data-rawheight=\"80\" class=\"origin_image zh-lightbox-thumb\" width=\"628\" data-original=\"https://pic4.zhimg.com/v2-4f2006551c8165f35265c668fff2123f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;628&#39; height=&#39;80&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"628\" data-rawheight=\"80\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"628\" data-original=\"https://pic4.zhimg.com/v2-4f2006551c8165f35265c668fff2123f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4f2006551c8165f35265c668fff2123f_b.jpg\"/></figure><p>n对应于样本数量，m是类别数量，yij 表示第i个样本属于分类j的标签，它是0或者1。对于单分类任务，只有一个分类的标签非零。f(xij) 表示的是样本i预测为j分类的概率。loss的大小完全取决于分类为正确标签那一类的概率，当所有的样本都分类正确时，loss=0，否则大于0。</p><p><b>2.3、softmax loss及其变种</b></p><p>假如log loss中的f(xij)的表现形式是softmax概率的形式，那么交叉熵loss就是我们熟知的softmax with cross-entropy loss，简称softmax loss，所以说softmax loss只是交叉熵的一个特例。</p><p>softmax loss被广泛用于分类分割等任务，而且发展出了很多的变种，有针对不平衡样本问题的weighted softmax loss，  focal loss，针对蒸馏学习的soft softmax loss，促进类内更加紧凑的L-softmax Loss等一系列改进，<b>早在一年前就撰写过综述如下：</b></p><p><u><b><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649028860%26idx%3D1%26sn%3Dec1056fce8a00d14ad43cc0ac9c39b84%26chksm%3D87134681b064cf9742cd52dc5e68d585ac143fc237393e14d892c40d559621a682e467416312%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】一文道尽softmax loss及其变种</a></b></u><br/></p><p><b>2.4、KL散度</b></p><p>Kullback和Leibler定义了KL散度用于估计两个分布的相似性，定义如下；</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-ceb779737b050b52b1b852c5afd23084_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"506\" data-rawheight=\"118\" class=\"origin_image zh-lightbox-thumb\" width=\"506\" data-original=\"https://pic1.zhimg.com/v2-ceb779737b050b52b1b852c5afd23084_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;506&#39; height=&#39;118&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"506\" data-rawheight=\"118\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"506\" data-original=\"https://pic1.zhimg.com/v2-ceb779737b050b52b1b852c5afd23084_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-ceb779737b050b52b1b852c5afd23084_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>Dkl是非负的，只有当p与q处处相等时，才会等于0。上面的式子也等价于</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-cea0df64735ca467ab50e6dfb99274d0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1062\" data-rawheight=\"84\" class=\"origin_image zh-lightbox-thumb\" width=\"1062\" data-original=\"https://pic1.zhimg.com/v2-cea0df64735ca467ab50e6dfb99274d0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1062&#39; height=&#39;84&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1062\" data-rawheight=\"84\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1062\" data-original=\"https://pic1.zhimg.com/v2-cea0df64735ca467ab50e6dfb99274d0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-cea0df64735ca467ab50e6dfb99274d0_b.jpg\"/></figure><p>其中l(p,p)是分布p的熵，而l(p,q)就是p和q的交叉熵。假如p是一个已知的分布，则熵是一个常数，此时dkl(p|q)与l(p,q)也就是交叉熵只有一个常数的差异，两者是等价的。</p><p>同时值得注意的是，KL散度并不是一个对称的loss，即dkl(p|q) != dkl(q|p)，KL散度常被用于生成式模型。</p><p><b>2.5、Hinge loss</b></p><p>Hinge loss主要用于支持向量机中，它的称呼来源于损失的形状，定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-77b276f533be11eecc97a2776faa3d33_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"614\" data-rawheight=\"80\" class=\"origin_image zh-lightbox-thumb\" width=\"614\" data-original=\"https://pic4.zhimg.com/v2-77b276f533be11eecc97a2776faa3d33_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;614&#39; height=&#39;80&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"614\" data-rawheight=\"80\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"614\" data-original=\"https://pic4.zhimg.com/v2-77b276f533be11eecc97a2776faa3d33_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-77b276f533be11eecc97a2776faa3d33_b.jpg\"/></figure><p>如果分类正确，loss=0，如果错误则为1-f(x)，所以它是一个分段不光滑的曲线。Hinge loss被用来解SVM问题中的间距最大化问题。</p><p><b>2.6、Exponential loss与Logistic loss</b></p><p>Exponential loss是一个指数形式的loss，它的特点就是梯度比较大，主要用于Adaboost集成学习算法中，定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b7535cc67a7790e7c7ff6fe9eede2b28_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"462\" data-rawheight=\"96\" class=\"origin_image zh-lightbox-thumb\" width=\"462\" data-original=\"https://pic1.zhimg.com/v2-b7535cc67a7790e7c7ff6fe9eede2b28_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;462&#39; height=&#39;96&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"462\" data-rawheight=\"96\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"462\" data-original=\"https://pic1.zhimg.com/v2-b7535cc67a7790e7c7ff6fe9eede2b28_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b7535cc67a7790e7c7ff6fe9eede2b28_b.jpg\"/></figure><p>logistic loss取了Exponential loss的对数形式，它的定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c97c8ebb0267ef63ab4e58a3c6cbd467_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"658\" data-rawheight=\"112\" class=\"origin_image zh-lightbox-thumb\" width=\"658\" data-original=\"https://pic4.zhimg.com/v2-c97c8ebb0267ef63ab4e58a3c6cbd467_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;658&#39; height=&#39;112&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"658\" data-rawheight=\"112\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"658\" data-original=\"https://pic4.zhimg.com/v2-c97c8ebb0267ef63ab4e58a3c6cbd467_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c97c8ebb0267ef63ab4e58a3c6cbd467_b.jpg\"/></figure><p>logistic loss 梯度相对变化更加平缓。</p><p>此外还有sigmoid cross_entropy_loss，可以被用于多标签分类任务或者不需要创建类间竞争机制的分类任务，在Mask RCNN中就被用了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-cea5dd8c6ee8f4ca116dd7c72d03a8e6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"83\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-cea5dd8c6ee8f4ca116dd7c72d03a8e6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;83&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"83\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-cea5dd8c6ee8f4ca116dd7c72d03a8e6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-cea5dd8c6ee8f4ca116dd7c72d03a8e6_b.jpg\"/></figure><p><b>以上就涵盖了大部分常用的分类任务损失，多半都是对数的形式，这是由信息熵的定义，参数似然估计的本质决定的。</b></p><h2><b>3 回归任务损失</b></h2><p>在回归任务中，回归的结果是一些整数或者实数，并没有先验的概率密度分布，常使用的loss是L1 loss和L2 loss。</p><p><b>3.1、L1 loss</b></p><p>Mean absolute loss(MAE)也被称为L1 Loss，是以绝对误差作为距离：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a0b523d851c102d5501cb7aef907f7f7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"506\" data-rawheight=\"120\" class=\"origin_image zh-lightbox-thumb\" width=\"506\" data-original=\"https://pic4.zhimg.com/v2-a0b523d851c102d5501cb7aef907f7f7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;506&#39; height=&#39;120&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"506\" data-rawheight=\"120\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"506\" data-original=\"https://pic4.zhimg.com/v2-a0b523d851c102d5501cb7aef907f7f7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a0b523d851c102d5501cb7aef907f7f7_b.jpg\"/></figure><p>由于L1 loss具有稀疏性，为了惩罚较大的值，因此常常将其作为正则项添加到其他loss中作为约束。L1 loss的最大问题是梯度在零点不平滑，导致会跳过极小值。</p><p><b>3.2、L2 loss</b></p><p>Mean Squared Loss/ Quadratic Loss(MSE loss)也被称为L2 loss，或欧氏距离，它以误差的平方和作为距离：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4aee62067aee16dca0e6c5ac8f026ea5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"124\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic2.zhimg.com/v2-4aee62067aee16dca0e6c5ac8f026ea5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;124&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"124\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic2.zhimg.com/v2-4aee62067aee16dca0e6c5ac8f026ea5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4aee62067aee16dca0e6c5ac8f026ea5_b.jpg\"/></figure><p>L2 loss也常常作为正则项。当预测值与目标值相差很大时, 梯度容易爆炸，因为梯度里包含了x−t。</p><p><b>3.3、L1 loss与L2 loss的改进</b></p><p>原始的L1 loss和L2 loss都有缺陷，比如L1 loss的最大问题是梯度不平滑，而L2 loss的最大问题是容易梯度爆炸，所以研究者们对其提出了很多的改进。</p><p>在faster rcnn框架中，使用了smooth L1 loss来综合L1与L2 loss的优点，定义如下:</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-8f19e8b3856aa9a2c8dd85b8d282ded1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"772\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb\" width=\"772\" data-original=\"https://pic2.zhimg.com/v2-8f19e8b3856aa9a2c8dd85b8d282ded1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;772&#39; height=&#39;128&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"772\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"772\" data-original=\"https://pic2.zhimg.com/v2-8f19e8b3856aa9a2c8dd85b8d282ded1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-8f19e8b3856aa9a2c8dd85b8d282ded1_b.jpg\"/></figure><p>在x比较小时，上式等价于L2 loss，保持平滑。在x比较大时，上式等价于L1 loss，可以限制数值的大小。</p><p>为了增强L2 loss对噪声(离群点)的鲁棒性，研究者提出了Huber loss，定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2a33388f0f5910b949830ef74f64613d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"754\" data-rawheight=\"194\" class=\"origin_image zh-lightbox-thumb\" width=\"754\" data-original=\"https://pic2.zhimg.com/v2-2a33388f0f5910b949830ef74f64613d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;754&#39; height=&#39;194&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"754\" data-rawheight=\"194\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"754\" data-original=\"https://pic2.zhimg.com/v2-2a33388f0f5910b949830ef74f64613d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2a33388f0f5910b949830ef74f64613d_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>Huber对于离群点非常的有效，它同时结合了L1与L2的优点，不过多出来了一个delta参数需要进行训练。</p><p>除此之外还有Log-Cosh Loss等损失，大家可以自己了解，也欢迎补充。</p><p><b>从上面可以看出，L1/L2各有优劣，设计一个通用的框架同时满足L1/L2损失的优点是研究重点，我见过的最夸张的是这样的。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-067e77dac81e039d31a587359df13c2e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"880\" data-rawheight=\"376\" class=\"origin_image zh-lightbox-thumb\" width=\"880\" data-original=\"https://pic3.zhimg.com/v2-067e77dac81e039d31a587359df13c2e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;880&#39; height=&#39;376&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"880\" data-rawheight=\"376\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"880\" data-original=\"https://pic3.zhimg.com/v2-067e77dac81e039d31a587359df13c2e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-067e77dac81e039d31a587359df13c2e_b.jpg\"/></figure><p><b>3.4、perceptual loss</b></p><p>对于图像风格化，图像超分辨率重建等任务来说，早期都使用了图像像素空间的L2 loss，但是L2 loss与人眼感知的图像质量并不匹配，恢复出来的图像往往细节表现不好。</p><p>现在的研究中，<b>L2 loss逐步被人眼感知loss所取代。人眼感知loss也被称为perceptual loss（感知损失）</b>，它与MSE采用图像像素进行求差的不同之处在于所计算的空间不再是图像空间。</p><p>研究者们常使用VGG等网络的特征，令φ来表示损失网络，Cj表示网络的第j层，CjHjWj表示第j层的特征图的大小，感知损失的定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-5550027e2f77540666d64b33909292ba_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"718\" data-rawheight=\"120\" class=\"origin_image zh-lightbox-thumb\" width=\"718\" data-original=\"https://pic3.zhimg.com/v2-5550027e2f77540666d64b33909292ba_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;718&#39; height=&#39;120&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"718\" data-rawheight=\"120\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"718\" data-original=\"https://pic3.zhimg.com/v2-5550027e2f77540666d64b33909292ba_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-5550027e2f77540666d64b33909292ba_b.jpg\"/></figure><p>可以看出，它有与L2 loss同样的形式，只是计算的空间被转换到了特征空间。</p><h2><b>4 生成对抗网络损失</b></h2><p>生成对抗网络即Generative Adversarial Networks，简称GAN，它是2014年以后兴起的无监督学习网络，现在有非常多的解读了，我们一年前也解读过，欢迎移步，适合初学者。</p><p><u><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029396%26idx%3D1%26sn%3D2d92874e0b94dd2174d216ce1da4f1ce%26chksm%3D87134569b064cc7f5f2476fdc87df968b353c2eae24f6820a5af2ee983ca49be55d34588c19e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】有三说GANs（上）</a></u></p><p>原始的用于生成图片的GAN的损失函数包括了生成式模型和判别式模型两部分，如今GAN被用于各类任务，其他的各种损失也加入了进来，不过我们这里还是专门针对GAN的基本损失进行讲述。</p><p><b>4.1、GAN的基本损失</b></p><p>GAN是在生成模型和判别模型的相互博弈中进行迭代优化，它的优化目标如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c60c8682098c8df4e8696ecc0f8c6892_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"67\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-c60c8682098c8df4e8696ecc0f8c6892_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;67&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"67\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-c60c8682098c8df4e8696ecc0f8c6892_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c60c8682098c8df4e8696ecc0f8c6892_b.jpg\"/></figure><p>从中可以看出，包括两个部分，Ex∼pdata(x)[logD(x)]和Ez∼pz(z)[log(1−D(G(z)))]要求最大化判别模型对真实样本的概率估计，最小化判别模型对生成的样本的概率估计，生成器则要求最大化D(G(z))，即最大化判别模型对生成样本的误判，这个loss是对数log的形式。</p><p>原始的GAN的损失使用了JS散度，两个分布之间越接近，它们的JS散度越小，但实际上这并不适合衡量生成数据分布和真实数据分布的距离，相关的分析已经非常的多了，本文如果展开就太长了，因此直接给解决方案。</p><p><b>4.2、-log D trick</b></p><p>Ian Goodfellow提出了-log D trick，即把生成器loss改成如下，使得生成器的损失不依赖于生成器G</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6817b083fe4d933d29138408f0c9581e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"323\" data-rawheight=\"74\" class=\"content_image\" width=\"323\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;323&#39; height=&#39;74&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"323\" data-rawheight=\"74\" class=\"content_image lazy\" width=\"323\" data-actualsrc=\"https://pic3.zhimg.com/v2-6817b083fe4d933d29138408f0c9581e_b.jpg\"/></figure><p>这个等价最小化目标存在两个严重的问题。第一是它同时要最小化生成分布与真实分布的KL散度，却又要最大化两者的JS散度，这是矛盾的会导致梯度不稳定。第二，因为KL散度不是对称的，导致此时loss不对称，对于正确样本误分和错误样本误分的惩罚是不一样的。第一种错误对应的是“生成器没能生成真实的样本”，即多样性差，惩罚微小；第二种错误对应的是“生成器生成了不真实的样本”，即准确性低，惩罚巨大。这样造成生成器生成多样性很差的样本，出现了常说的模式崩塌(collapse mode)问题。</p><p><b>4.3、Wasserstein GAN(简称wgan)等改进方案</b></p><p>wgan采用了Earth-Mover距离(EM距离)作为loss，它是在最优路径规划下的最小消耗，计算的是在联合分布γ下，样本对距离的期望值：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a19b8009522f22fc3e4423681ab95360_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"342\" data-rawheight=\"84\" class=\"content_image\" width=\"342\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;342&#39; height=&#39;84&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"342\" data-rawheight=\"84\" class=\"content_image lazy\" width=\"342\" data-actualsrc=\"https://pic1.zhimg.com/v2-a19b8009522f22fc3e4423681ab95360_b.jpg\"/></figure><p>与原始的GAN的loss形式相比，其实wgan就是生成器和判别器的loss不取log。wessertein距离相比KL散度和JS散度的优势在于，即使两个分布的支撑集没有重叠或者重叠非常少，仍然能反映两个分布的远近。而JS散度在此情况下是常量，KL散度可能无意义。</p><p>wgan有一些问题，wgan-gp改进了wgan连续性限制的条件，后面还有一些研究，大家可以自行跟进，我们后面也会讲述。</p><p><b>4.4、LS-GAN</b></p><p>LS-GAN即Least Squares Generative Adversarial Networks。它的原理部分可以一句话概括，即使用了最小二乘损失函数代替了GAN的损失函数，相当于最小化P和Q之间的Pearson卡方散度（divergence），这属于f-divergence的一种，有效地缓解了GAN训练不稳定和生成图像质量差多样性不足的问题。作者认为使用JS散度并不能拉近真实分布和生成分布之间的距离，使用最小二乘可以将图像的分布尽可能的接近决策边界，其损失函数定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b92b630f00049b4e8aa420b69bedbde8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"104\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b92b630f00049b4e8aa420b69bedbde8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;104&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"104\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b92b630f00049b4e8aa420b69bedbde8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b92b630f00049b4e8aa420b69bedbde8_b.jpg\"/></figure><p>以交叉熵作为损失，它的特点是会使得生成器不会再优化那些被判别器识别为真实图片的生成图片，即使这些生成图片距离判别器的决策边界仍然很远，也就是距真实数据比较远，这意味着生成器的生成图片质量并不高。而要想最小二乘损失比较小，则在混淆判别器的前提下还得让生成器把距离决策边界比较远的生成图片拉向决策边界，这就是LS-GAN的优势。</p><p><b>4.5、Loss-sensitive-GAN</b></p><p>在原始的GAN的损失函数后添加了一个约束项来直接限定GAN的建模能力，它的损失函数如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a8c4326c71a4c219a54be6b1257b46b0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"92\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-a8c4326c71a4c219a54be6b1257b46b0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;92&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"92\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-a8c4326c71a4c219a54be6b1257b46b0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a8c4326c71a4c219a54be6b1257b46b0_b.jpg\"/></figure><p>优化将通过最小化这个目标来得到一个“损失函数&#34; (下文称之为L函数)。L函数在真实样本上越小越好，在生成的样本上越大越好。它是以真实样本x和生成样本的一个度量为各自L函数的目标间隔，把x和生成样本分开。好处是如果生成的样本和真实样本已经很接近，就不必要求他们的L函数有个固定间隔，因为生成的样本已经很好。这样就可以集中力量提高那些距离真实样本还很远，真实度不那么高的样本，能更合理地使用LS-GAN的建模能力，被称为“按需分配”。</p><p><b>关于GAN的损失优化，这是一个不小的研究领域，下面是一个简单的汇总。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-6bf6a3839f08ccba68ed0b729217cbb4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1012\" data-rawheight=\"1248\" class=\"origin_image zh-lightbox-thumb\" width=\"1012\" data-original=\"https://pic1.zhimg.com/v2-6bf6a3839f08ccba68ed0b729217cbb4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1012&#39; height=&#39;1248&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1012\" data-rawheight=\"1248\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1012\" data-original=\"https://pic1.zhimg.com/v2-6bf6a3839f08ccba68ed0b729217cbb4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-6bf6a3839f08ccba68ed0b729217cbb4_b.jpg\"/></figure><p>如果你对GAN还有更多兴趣，那就看这个参考网址吧，<b><a href=\"https://link.zhihu.com/?target=https%3A//hollobit.github.io/All-About-the-GAN/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">hollobit.github.io/All-</span><span class=\"invisible\">About-the-GAN/</span><span class=\"ellipsis\"></span></a>，不多不多，也就几千篇文章</b>，我大概看了1000篇的摘要，等闲下来再跟大家搞GAN，是Generative Adversarial Networks噢。</p><p>本文讲述了深度学习领域中常见的损失，学习灵活运用和设计损失本来不是初识境界的要求，不过还是让大家先有个基本感知吧。</p><p><i>下一期预告：如何晋级为合格的初阶深度学习模型训练师。</i></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }, 
                {
                    "tag": "优化", 
                    "tagLink": "https://api.zhihu.com/topics/19570512"
                }
            ], 
            "comments": [
                {
                    "userName": "moon", 
                    "userLink": "https://www.zhihu.com/people/fe9b2ece8efa4a2e0f91facb1d0d3110", 
                    "content": "学习了", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<a class=\"comment_sticker\" href=\"https://pic4.zhimg.com/v2-ba306425d0a7aee2c7260381f1bf7b97.gif\" data-width=\"\" data-height=\"\">[欢呼]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "moon"
                        }
                    ]
                }, 
                {
                    "userName": "Invision麦浪", 
                    "userLink": "https://www.zhihu.com/people/dc505c8630e71f2a031626d943a7f567", 
                    "content": "其实很多都是传统机器学习的损失，楼主还是总结的很到位，可以把相关的权值约束也加进去", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "好的，谢谢补充", 
                            "likes": 0, 
                            "replyToAuthor": "Invision麦浪"
                        }, 
                        {
                            "userName": "Invision麦浪", 
                            "userLink": "https://www.zhihu.com/people/dc505c8630e71f2a031626d943a7f567", 
                            "content": "看了你的书，写的很好，最近可能也会专门从事AI的工作了，可以参考", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>“不确定性必须是概率P的单调递降函数”有问题吧，是随p先增后减</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "犁氏楷", 
                    "userLink": "https://www.zhihu.com/people/cd06d4fb491ea7592ee2217137010e5b", 
                    "content": "perceptual loss 学习了", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/59481933", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 28, 
            "title": "【AI初识境】深度学习模型评估方法，从分类，回归，质量评价到生成模型", 
            "content": "<p>这是《AI初识境》第10篇，这次我们说说深度学习模型常用的评价指标。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>凡是用数据说话，一个深度学习模型在各类任务中的表现都需要定量的指标进行评估，才能够进行横向的PK比较，今天就来说说分类，回归，质量评估，生成模型中常用的指标，以计算机视觉任务为例。</p><p>                                                                                                                           作者&amp;编辑  | 言有三<br/></p><h2><b>1 分类评测指标</b></h2><p>图像分类是计算机视觉中最基础的一个任务，也是几乎所有的基准模型进行比较的任务，从最开始比较简单的10分类的灰度图像手写数字识别mnist，到后来更大一点的10分类的cifar10和100分类的cifar100，到后来的imagenet，图像分类任务伴随着数据库的增长，一步一步提升到了今天的水平。现在在Imagenet这样的超过1000万图像，2万类的数据集中，计算机的图像分类水准已经超过了人类。</p><p>图像分类，顾名思义就是一个模式分类问题，它的目标是将不同的图像，划分到不同的类别，实现最小的分类误差，这里我们只考虑单标签分类问题，即每一个图片都有唯一的类别。</p><p><b>对于单个标签分类的问题，评价指标主要有Accuracy，Precision，Recall，F-score，PR曲线，ROC和AUC。</b></p><p>在计算这些指标之前，我们先计算几个基本指标，这些指标是基于二分类的任务，也可以拓展到多分类。计标签为正样本，分类为正样本的数目为True Positive，简称TP。标签为正样本，分类为负样本的数目为False Negative，简称FN。标签为负样本，分类为正样本的数目为False Positive，简称FP。标签为负样本，分类为负样本的数目为True Negative，简称TN。</p><p>判别是否为正例只需要设一个概率阈值T，预测概率大于阈值T的为正类，小于阈值T的为负类，默认就是0.5。如果我们减小这个阀值T，更多的样本会被识别为正类，这样可以提高正类的召回率，但同时也会带来更多的负类被错分为正类。如果增加阈值T，则正类的召回率降低，精度增加。如果是多类，比如ImageNet1000分类比赛中的1000类，预测类别就是预测概率最大的那一类。</p><p><b>1. 准确率Accuracy</b></p><p>单标签分类任务中每一个样本都只有一个确定的类别，预测到该类别就是分类正确，没有预测到就是分类错误，因此最直观的指标就是Accuracy，也就是准确率。</p><p>Accuracy=(TP+TN)/(TP+FP+TN+FN)，表示的就是所有样本都正确分类的概率，可以使用不同的阈值T。</p><p>在ImageNet中使用的Accuracy指标包括Top_1 Accuracy和Top_5 Accuracy，Top_1 Accuracy就是前面计算的Accuracy。</p><p>记样本xi的类别为yi，类别种类为(0,1,…,C)，预测类别函数为f，则Top-1的计算方法如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d434872c78b850cab4b97447ce7fd56d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"504\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb\" width=\"504\" data-original=\"https://pic2.zhimg.com/v2-d434872c78b850cab4b97447ce7fd56d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;504&#39; height=&#39;128&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"504\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"504\" data-original=\"https://pic2.zhimg.com/v2-d434872c78b850cab4b97447ce7fd56d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d434872c78b850cab4b97447ce7fd56d_b.jpg\"/></figure><p>如果给出概率最大的5个预测类别，只要包含了真实的类别，则判定预测正确，计算出来的指标就是Top-5。</p><p>目前在ImageNet上，Top-5的指标已经超过95%，而Top-1的指标还在80%左右。</p><p><b>2.  精确度Precision和召回率Recall</b></p><p>如果我们只考虑正样本的指标，有两个很常用的指标，精确度和召回率。</p><p>正样本精确率为：Precision=TP/(TP+FP)，表示的是召回为正样本的样本中，到底有多少是真正的正样本。</p><p>正样本召回率为：Recall=TP/(TP+FN)，，表示的是有多少样本被召回类。当然，如果对负样本感兴趣的，也可以计算对应的精确率和召回率，这里记得区分精确率和准确率的分别。</p><p>通常召回率越高，精确度越低，根据不同的值可以绘制Recall-Precision曲线，如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-280c25eb092ca471e94e4227f039d488_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-280c25eb092ca471e94e4227f039d488_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-280c25eb092ca471e94e4227f039d488_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-280c25eb092ca471e94e4227f039d488_b.jpg\"/></figure><p>横轴就是recall，纵轴就是precision，曲线越接近右上角，说明其性能越好，可以用该曲线与坐标轴包围的面积来定量评估，值在0～1之间。</p><p><b>3. F1 score</b></p><p>有的时候我们不仅关注正样本的准确率，也关心其召回率，但是又不想用Accuracy来进行衡量，一个折中的指标是采用F-score。</p><p>F1 score=2·Precision·Recall/(Precision+Recall)，只有在召回率Recall和精确率Precision都高的情况下，F1 score才会很高，因此F1 score是一个综合性能的指标。</p><p><b>4.混淆矩阵</b></p><p>如果对于每一类，我们想知道类别之间相互误分的情况，查看是否有特定的类别之间相互混淆，就可以用混淆矩阵画出分类的详细预测结果。对于包含多个类别的任务，混淆矩阵很清晰的反映出各类别之间的错分概率，如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-2bb09634f94a0c7dcd22fa71633f77de_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"713\" data-rawheight=\"618\" class=\"origin_image zh-lightbox-thumb\" width=\"713\" data-original=\"https://pic3.zhimg.com/v2-2bb09634f94a0c7dcd22fa71633f77de_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;713&#39; height=&#39;618&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"713\" data-rawheight=\"618\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"713\" data-original=\"https://pic3.zhimg.com/v2-2bb09634f94a0c7dcd22fa71633f77de_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-2bb09634f94a0c7dcd22fa71633f77de_b.jpg\"/></figure><p>这是一个包含20个类别的分类任务，混淆矩阵为20*20的矩阵，其中第i行第j列，表示第i类目标被分类为第j类的概率，可以知道，越好的分类器对角线上的值更大，其他地方应该越小。</p><p><b>5.ROC曲线与AUC指标</b></p><p>以上的准确率Accuracy，精确度Precision，召回率Recall，F1 score，混淆矩阵都只是一个单一的数值指标，如果我们想观察分类算法在不同的参数下的表现情况，就可以使用一条曲线，即ROC曲线，全称为receiver operating characteristic。</p><p>ROC曲线可以用于评价一个分类器在不同阈值下的表现情况。</p><p>在ROC曲线中，每个点的横坐标是false positive rate(FPR)，纵坐标是true positive rate(TPR)，描绘了分类器在True Positive和False Positive间的平衡，两个指标的计算如下：</p><p>TPR=TP/(TP+FN)，代表分类器预测的正类中实际正实例占所有正实例的比例。</p><p>FPR=FP/(FP+TN)，代表分类器预测的正类中实际负实例占所有负实例的比例，FPR越大，预测正类中实际负类越多。</p><p>ROC曲线通常如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-02761e05ca584f212a8a9a8dc11845b7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1081\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-02761e05ca584f212a8a9a8dc11845b7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1081&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1081\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-02761e05ca584f212a8a9a8dc11845b7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-02761e05ca584f212a8a9a8dc11845b7_b.jpg\"/></figure><p>其中有4个关键的点：</p><p>点(0,0)：FPR=TPR=0，分类器预测所有的样本都为负样本。</p><p>点(1,1)：FPR=TPR=1，分类器预测所有的样本都为正样本。</p><p>点(0,1)：FPR=0, TPR=1，此时FN＝0且FP＝0，所有的样本都正确分类。</p><p>点(1,0)：FPR=1，TPR=0，此时TP＝0且TN＝0，最差分类器，避开了所有正确答案。</p><p><b>ROC曲线相对于PR曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变，即对正负样本不均衡问题不敏感。</b></p><p>比如负样本的数量增加到原来的10倍，TPR不受影响，FPR的各项也是成比例的增加，并不会有太大的变化。所以不均衡样本问题通常选用ROC作为评价标准。</p><p>ROC曲线越接近左上角，该分类器的性能越好，若一个分类器的ROC曲线完全包住另一个分类器，那么可以判断前者的性能更好。</p><p>如果我们想通过两条ROC曲线来定量评估两个分类器的性能，就可以使用<b>AUC指标</b>。</p><p>AUC（Area Under Curve）为ROC曲线下的面积，它表示的就是一个概率，这个面积的数值不会大于1。随机挑选一个正样本以及一个负样本，AUC表征的就是有多大的概率，分类器会对正样本给出的预测值高于负样本，当然前提是正样本的预测值的确应该高于负样本。</p><p><b>6. TAR，FRR，FAR</b></p><p>这几个指标在人脸验证中被广泛使用，人脸验证即匹配两个人是否是同一个人，通常用特征向量的相似度进行描述，如果相似度概率大于阈值T，则被认为是同一个人。</p><p>TAR（True Accept Rate）表示正确接受的比例，多次取同一个人的两张图像，统计该相似度值超过阈值T的比例。FRR（False Reject Rate）就是错误拒绝率，把相同的人的图像当做不同人的了，它等于1-TAR。</p><p>与之类似，FAR（False Accept Rate）表示错误接受的比例，多次取不同人的两张图像，统计该相似度值超过T的比例。</p><p>增大相似度阈值T，FAR和TAR都减小，意味着正确接受和错误接受的比例都降低，错误拒绝率FRR会增加。减小相似度阈值T，FAR和TAR都增大，正确接受的比例和错误接受的比例都增加，错误拒绝率FRR降低。</p><h2><br/><b>2 检索与回归指标</b></h2><p><b>1.IoU</b></p><p>IoU全称Intersection-over-Union， 即交并比，在目标检测领域中，定义为两个矩形框面积的交集和并集的比值，IoU=A∩B/A∪B。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-41fb624a6d54135d3329c4ab357ee915_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"827\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-41fb624a6d54135d3329c4ab357ee915_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;827&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"827\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-41fb624a6d54135d3329c4ab357ee915_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-41fb624a6d54135d3329c4ab357ee915_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>如果完全重叠，则IoU等于1，是最理想的情况。一般在检测任务中，IoU大于等于0.5就认为召回，如果设置更高的IoU阈值，则召回率下降，同时定位框也越更加精确。</p><p>在图像分割中也会经常使用IoU，此时就不必限定为两个矩形框的面积。比如对于二分类的前背景分割，那么IoU=(真实前景像素面积∩预测前景像素面积)/(真实前景像素面积∪预测前景像素面积)，这一个指标，通常比直接计算每一个像素的分类正确概率要低，也对错误分类更加敏感。</p><p><b>2.AP和mAP</b></p><p>Average Precision简称AP，这是一个在检索任务和回归任务中经常使用的指标，实际等于Precision-Recall曲线下的面积，这个曲线在上一小节已经说过，下面针对目标检测中举出一个例子进行计算，这一个例子在网上也是广泛流传。</p><p>假如一幅图像，有10个人脸，检索出来了20个目标框，每一个目标框的概率以及真实的标签如下，真实标签的计算就用检测框与真实标注框的IoU是否大于0.5来计算。</p><p>第一步，就是根据模型得到概率，计算IoU得到下面的表。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-bb919b687e73e5fad3e0d5963a8c29e9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"590\" data-rawheight=\"1130\" class=\"origin_image zh-lightbox-thumb\" width=\"590\" data-original=\"https://pic2.zhimg.com/v2-bb919b687e73e5fad3e0d5963a8c29e9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;590&#39; height=&#39;1130&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"590\" data-rawheight=\"1130\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"590\" data-original=\"https://pic2.zhimg.com/v2-bb919b687e73e5fad3e0d5963a8c29e9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-bb919b687e73e5fad3e0d5963a8c29e9_b.jpg\"/></figure><p>第二步，将上面的表按照概率进行排序</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-92968f59d32fdc951b2a5be4743889d5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"592\" data-rawheight=\"1136\" class=\"origin_image zh-lightbox-thumb\" width=\"592\" data-original=\"https://pic2.zhimg.com/v2-92968f59d32fdc951b2a5be4743889d5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;592&#39; height=&#39;1136&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"592\" data-rawheight=\"1136\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"592\" data-original=\"https://pic2.zhimg.com/v2-92968f59d32fdc951b2a5be4743889d5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-92968f59d32fdc951b2a5be4743889d5_b.jpg\"/></figure><p>Precision的计算如下，以返回的top-5结果为例：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-078282f134e7d6e7067165962cc3a761_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"592\" data-rawheight=\"1136\" class=\"origin_image zh-lightbox-thumb\" width=\"592\" data-original=\"https://pic2.zhimg.com/v2-078282f134e7d6e7067165962cc3a761_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;592&#39; height=&#39;1136&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"592\" data-rawheight=\"1136\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"592\" data-original=\"https://pic2.zhimg.com/v2-078282f134e7d6e7067165962cc3a761_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-078282f134e7d6e7067165962cc3a761_b.jpg\"/></figure><p>在这个例子中，true positives就是真正的人脸，从Label一栏可以看出，指的是id = 4，2，7，9，16，20的样本。</p><p>前5个概率值最大的id中13，19，6是false positives。所以此时的Precision=2/5=40%，即选定了5个人脸，但是只有两个是对的。recall=2/6=33.3%，即总共有6个人脸，但是只召回了2个。</p><p>在一个实际的目标检测任务中，目标的数量不一定是5个，所以不能只通过top-5来来衡量一个模型的好坏，选定的id越多，recall就越高，precision整体上则会呈现出下降趋势，因为排在前面的概率高的，一般更有可能是真实的样本，而后面概率低的更有可能是负样本。</p><p>令N是所有id，如果从top-1到top-N都统计一遍，得到了对应的precision和recall，以recall为横坐标，precision为纵坐标，则得到了检测中使用的precision-recall曲线，虽然整体趋势和意义与分类任务中的precision-recall曲线相同，计算方法却有很大差别。</p><p>在PASCAL VOC 2010年以前的比赛中，AP的具体计算方法如下：</p><p>设置11个阈值[0, 0.1, 0.2, ... , 1]，计算recall大于等于每一个阈值时的最大precision，AP就是这11个值的平均值。根据上表中的计算方法，选择不同的N时会有不同的precision和recall，所以也有可能有不同的N落在同样的recall区间，此时就需要选择其中最大的精度值，这时候曲线上的点就不一定对应同一个阈值时的recall。</p><p>AP就是这11个precision的平均值，将所有类别的AP再取平均，就得到了mAP。</p><p>PASCAL VOC 2010年提出了一个更好的指标，去除了11点的设定，对于样本不均衡的类的计算更加有效。</p><p>假设有N个id，其中有M个label，则取M个recall节点，从0到1按照1/M的等间距，对于每个recall值，计算出大于该recall值的最大precision，然后对这M个precision值取平均得到最后的AP值，mAP的计算方法不变。</p><p>AP衡量的是学出来的模型在一个类别上的好坏，mAP衡量的是学出的模型在所有类别上的好坏。</p><h2><br/><b>3 图像质量评价指标</b></h2><p>图像在获取，压缩，存储，传输，解压缩，显示，甚至打印的过程中，都有可能受到环境的干扰造成质量下降。图像的质量，通常跟图像噪声，模糊，对比度，美学等有关系。</p><p>在图像质量评估的指标中，根据对原始无损图像的要求，通常分为三大类[1-2]，分别是<b>Full Reference Image Quality Assessment(FR-IQA)全参考图像评价，Reduced Reference Image Quality Assessment(FR-IQA)半参考图像评价，No Reference Image Quality Assessment(FR-IQA)无参考图像评价</b>。</p><p><b>Full Reference Image Quality Assessment(FR-IQA)全参考图像评价</b>，需要原始的高质量的图像。常见的(FR-IQA)包括峰值信噪比PSNR，结构一致性相似因子structural similarity index measurement(SSIM)，视觉信息保真度 (Visual information fidelity, VIF)，视觉信噪比 (Visual signal-to-noise ratio, VSPR)，最显著失真 (Most apparent distortion, MAD)等。</p><p><b>Reduced Reference Image Quality Assessment(RR-IQA)半参考图像评价，</b>不需要原始图像本身，但是需要一些特征，在卫星和遥感图像中被使用的较多。RR-IQA类方法常常在不同的特征空间中使用，主要思路是对FR-IQA类评价指标进行近似。</p><p><b>No Reference Image Quality Assessment(NR-IQA)无参考图像评价，</b>完全基于图像本身，不再需要原始图。不过由于没有原始的图像，需要对原始的图像进行统计建模，同时还要兼顾人眼的视觉特征，本来这就有一定的主观和不确定性。虽然研究人员提出了数十个NR-IQA指标，但是真正广泛使用的没有几个。另外无参考的美学质量评估也是当前比较开放的一个问题，它需要更多考虑摄影学等因素。</p><p>质量评价因子非常的多，本小节只介绍其中的4个，后续会专门撰写综述来讲解。</p><p><b>3.1.信噪比SNR与峰值信噪比PSNR</b></p><p>信噪比，即SNR(SIGNAL-NOISE RATIO)，是信号处理领域广泛使用的定量描述指标。它原是指一个电子设备或者电子系统中信号与噪声的比例，计量单位是dB，其计算方法是10*lg(Ps/Pn)，其中Ps和Pn分别代表信号和噪声的有效功率，也可以换算成电压幅值的比率关系：20*lg(Vs/Vn)，Vs和Vn分别代表信号和噪声电压的“有效值”。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>在图像处理领域，更多的是采用峰值信噪比PSNR (Peak Signal to NoiseRatio)，它是原图像与处理图像之间均方误差(Mean Square Error)相对于(2^n-1)^2 的对数值，其中n是每个采样值的比特数，8位图像即为256。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-16235ff7f8c46a2a91a2308efc0955f1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"404\" data-rawheight=\"118\" class=\"content_image\" width=\"404\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;404&#39; height=&#39;118&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"404\" data-rawheight=\"118\" class=\"content_image lazy\" width=\"404\" data-actualsrc=\"https://pic2.zhimg.com/v2-16235ff7f8c46a2a91a2308efc0955f1_b.jpg\"/></figure><p>PSNR越大表示失真越小，均方误差的计算如下：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-3bbe8ec61a50f71551bb21b485d8bea5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"548\" data-rawheight=\"228\" class=\"origin_image zh-lightbox-thumb\" width=\"548\" data-original=\"https://pic2.zhimg.com/v2-3bbe8ec61a50f71551bb21b485d8bea5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;548&#39; height=&#39;228&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"548\" data-rawheight=\"228\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"548\" data-original=\"https://pic2.zhimg.com/v2-3bbe8ec61a50f71551bb21b485d8bea5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-3bbe8ec61a50f71551bb21b485d8bea5_b.jpg\"/></figure><p>其中M，N为图像的行与列数，μi,j是像素灰度平均值，fi,j即像素灰度值。</p><p>下面展示了JPEG和JPEG2000算法在不同压缩率下的PSNR，通常PSNR大于35的图像质量会比较好。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-092b647fed1710ba5e785df3dba9493b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"565\" data-rawheight=\"397\" class=\"origin_image zh-lightbox-thumb\" width=\"565\" data-original=\"https://pic4.zhimg.com/v2-092b647fed1710ba5e785df3dba9493b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;565&#39; height=&#39;397&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"565\" data-rawheight=\"397\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"565\" data-original=\"https://pic4.zhimg.com/v2-092b647fed1710ba5e785df3dba9493b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-092b647fed1710ba5e785df3dba9493b_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>3.2.结构一致性相似因子SSIM</b></p><p>PSNR从底层信噪的角度来评估图像的质量，但是人眼对质量的评价关注的层次其实更高。根据Human visual system model，人眼观察图像有几个特点：</p><p><b>(1)低通过滤器特性，即人眼对于过高的频率难以分辨。(2)人眼对亮度的敏感大于对颜色的敏感。(3)对亮度的响应不是线性变换的，在平均亮度大的区域，人眼对灰度误差不敏感。(4)边缘和纹理敏感，有很强的局部观察能力。</b></p><p><b>structural similarity index measurement(SSIM)是一种建立在人眼的视觉特征基础上的用于衡量两幅图像相似度的指标，结果在0～1之间。</b></p><p>结构相似性理论认为自然图像信号是高度结构化的，空域像素间有很强的相关性并蕴含着物体结构的重要信息。它没有试图通过累加与心理物理学简单认知模式有关的误差来估计图像质量，而是直接估计两个复杂结构信号的结构改变，并将失真建模为亮度、对比度和结构三个不同因素的组合。用均值作为亮度的估计，标准差作为对比度的估计，协方差作为结构相似程度的度量。</p><p>PSNR忽略了人眼对图像不同区域的敏感度差异，在不同程度上降低了图像质量评价结果的可靠性，而SSIM能突显轮廓和细节等特征信息。</p><p>SSIM具体的计算如下：首先结构信息不应该受到照明的影响，因此在计算结构信息时需要去掉亮度信息，即需要减掉图像的均值；其次结构信息不应该受到图像对比度的影响，因此计算结构信息时需要归一化图像的方差。</p><p>通常使用的计算方法如下，其中C1，C2，C3用来增加计算结果的稳定性，光度L，对比度C，结构对比度S计算如下： </p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-fd6aabef83a158e4499991a7539f4949_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"382\" data-rawheight=\"126\" class=\"content_image\" width=\"382\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;382&#39; height=&#39;126&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"382\" data-rawheight=\"126\" class=\"content_image lazy\" width=\"382\" data-actualsrc=\"https://pic2.zhimg.com/v2-fd6aabef83a158e4499991a7539f4949_b.jpg\"/></figure><p>ux，uy为图像的均值</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-77ebea2446fef2a87750a2f4f317fad1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"402\" data-rawheight=\"124\" class=\"content_image\" width=\"402\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;402&#39; height=&#39;124&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"402\" data-rawheight=\"124\" class=\"content_image lazy\" width=\"402\" data-actualsrc=\"https://pic2.zhimg.com/v2-77ebea2446fef2a87750a2f4f317fad1_b.jpg\"/></figure><p>dx，dy为图像的方差</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-633c74e4ec5cf46d8cb496a9a3bb705d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"366\" data-rawheight=\"124\" class=\"content_image\" width=\"366\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;366&#39; height=&#39;124&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"366\" data-rawheight=\"124\" class=\"content_image lazy\" width=\"366\" data-actualsrc=\"https://pic2.zhimg.com/v2-633c74e4ec5cf46d8cb496a9a3bb705d_b.jpg\"/></figure><p>d(x,y)为图像x，y的协方差。而图像质量SSIM = L(x,y)^aC(x,y)^bS(x,y)^c，其中a，b，c分别用来控制三个要素的重要性，为了计算方便可以均选择为1，C1，C2，C3为比较小的数值，通常C1=(K1×L)^2, C2=(K2×L)^2，C3 = C2/2， K1 &lt;&lt; 1， K2 &lt;&lt; 1，L为像素的最大值(通常为255)。当a，b，c都等于1，C3=C2/2时，SSIM的定义式就为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-7c412e585b166431417a3e829c50db50_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"620\" data-rawheight=\"134\" class=\"origin_image zh-lightbox-thumb\" width=\"620\" data-original=\"https://pic1.zhimg.com/v2-7c412e585b166431417a3e829c50db50_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;620&#39; height=&#39;134&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"620\" data-rawheight=\"134\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"620\" data-original=\"https://pic1.zhimg.com/v2-7c412e585b166431417a3e829c50db50_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-7c412e585b166431417a3e829c50db50_b.jpg\"/></figure><p>SSIM发展出了许多的改进版本，其中较好的包括Fast SSIM，Multi-scale SSIM。</p><p><b>3.3.无参考锐化因子CPBD</b></p><p>上面说的这两个，都是需要参考图像才能进行评价的，而CPBD即cumulative probability of blur detection (CPBD)，是一种无参考的图像锐化定量指标评价因子。它是基于模糊检测的累积概率来进行定义，是基于分类的方法。</p><p>首先要说Just-noticeable-distortion-model，简称JND模型，即恰可察觉失真模型，它建模人眼能够察觉的图像底层特征，只有超过一定的阈值才会被察觉为失真图像。如果在空间域计算，一般会综合考虑亮度，纹理等因素，比如用像素点处局部平均背景亮度值作为亮度对比度阈值，用各个方向的梯度作为纹理阈值。如果在变换域计算，则可以使用小波系数等，这里对其计算方法就不再详述。</p><p>在给定一个对比度高于JND (Just Noticeable Difference)参考的情况下，定义JNB (Just-noticeable-blue)指标为感知到的模糊像素的最小数目，边缘处像素的模糊概率定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a8f9e1177b3e6f41ae284847593e12e2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"612\" data-rawheight=\"158\" class=\"origin_image zh-lightbox-thumb\" width=\"612\" data-original=\"https://pic3.zhimg.com/v2-a8f9e1177b3e6f41ae284847593e12e2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;612&#39; height=&#39;158&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"612\" data-rawheight=\"158\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"612\" data-original=\"https://pic3.zhimg.com/v2-a8f9e1177b3e6f41ae284847593e12e2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a8f9e1177b3e6f41ae284847593e12e2_b.jpg\"/></figure><p>其中分子是基于局部对比度的JNB边缘宽度，而分母是计算出的边缘宽度。对于每一幅图像，取子块大小为64×64，然后将其分为边缘块与非边缘块，非边缘块不做处理。对于每一个边缘块，计算出块内每个边缘像素的宽度。当pblur&lt;63%，该像素即作为有效的像素，用于计算CPBD指标，定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b177ed59b8e75a63e0a91a92e136bc21_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"652\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb\" width=\"652\" data-original=\"https://pic2.zhimg.com/v2-b177ed59b8e75a63e0a91a92e136bc21_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;652&#39; height=&#39;142&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"652\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"652\" data-original=\"https://pic2.zhimg.com/v2-b177ed59b8e75a63e0a91a92e136bc21_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b177ed59b8e75a63e0a91a92e136bc21_b.jpg\"/></figure><p>CPBD的作者采用了高斯模糊的图像与JPEG压缩图像进行实验，表明CPBD是符合人类视觉特性的图像质量指标，值越大，所反映出的细节越清晰，模糊性越弱。因此，可以将此指标用于定量评判滤波后的图像的锐化质量。关于该指标和PSNR和SSIM的对比，大家可以去阅读笔者的硕士论文[3]。</p><p>图像质量评价这个领域的坑太大，水太多，如果只是感兴趣，就建议不要入了。</p><h2><br/><b>4 图像生成评价指标</b></h2><p>当我们要评估一个生成模型的性能的时候，有2个最重要的衡量指标。</p><p>(1) 确定性：生成模型生成的样本一定属于特定的类别，也就是真实的图像，而且必须要是所训练的图片集，不能用人脸图像训练得到了手写数字。</p><p>(2) 多样性：样本应该各式各样，如果用mnist进行训练，在没有条件限制的条件下，应该生成0，1，2，3…，而不是都是0，生成的各个数字也应该具有不同的笔触，大小等。</p><p>除此之外，还会考虑分辨率等，因此评价生成模型也需要从这几个方向着手。</p><p><b>4.1.inception score</b></p><p>inception score是最早的用于GAN生成的图像多样性评估的指标，它利用了google的inception模型来进行评估，背后的思想就完美满足上面的两个衡量指标。</p><p>Inception图像分类模型预测结果是一个softmax后的向量，即概率分布p(y|x)。一个好的分类模型，该向量分布的熵应该尽可能地小，也就是样本必须明确符合某一个类，其中的一个值很大，剩下的值很小。另外，如果把softmax后的向量组合并在一起形成另一个概率分布p(y)，为了满足多样性，这个分布的熵应该是越大越好，也就是各种类别的样本都有。</p><p>具体实现就是让p(y|x)和p(y)之间的KL散度越大越好，连续形式的表达如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-3fde35a78a1962ce383dfaf64b25a621_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"140\" class=\"origin_image zh-lightbox-thumb\" width=\"678\" data-original=\"https://pic2.zhimg.com/v2-3fde35a78a1962ce383dfaf64b25a621_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;678&#39; height=&#39;140&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"678\" data-rawheight=\"140\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"678\" data-original=\"https://pic2.zhimg.com/v2-3fde35a78a1962ce383dfaf64b25a621_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-3fde35a78a1962ce383dfaf64b25a621_b.jpg\"/></figure><p>实际的计算就是将积分换成求和：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-8fe3976f80be336b3a22cd170bf54c3f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"738\" data-rawheight=\"244\" class=\"origin_image zh-lightbox-thumb\" width=\"738\" data-original=\"https://pic4.zhimg.com/v2-8fe3976f80be336b3a22cd170bf54c3f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;738&#39; height=&#39;244&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"738\" data-rawheight=\"244\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"738\" data-original=\"https://pic4.zhimg.com/v2-8fe3976f80be336b3a22cd170bf54c3f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-8fe3976f80be336b3a22cd170bf54c3f_b.jpg\"/></figure><p>Inception Score是一个非常好的评价指标，它同时评估生成图像的质量和多样性，前段时间大火的BigGAN，就是将Inception Score提升为原来最好模型的3倍不止。</p><p>不过Inception Score也有缺陷，因为它仅评估图像生成模型，没有评估生成的图像与原始训练图像之间的相似度，因此虽然鼓励模型学习了质量好，多样性好的图像，但是却不能保证是我们想要的图像。Mode分数对其进行了改进，增加了KL散度来度量真实分布P_r与生成分布P_g之间的差异。</p><p><b>4.2.Kernel MMD</b></p><p>最大平均差异maximum mean discrepancy Kernel也是一个用于判断两个分布p和q是否相同的指标。它的基本假设就是如果两个样本分布相似，那么通过寻找在样本空间上的连续函数f，求不同分布的样本f函数的均值，计算均值的差作为两个分布在f函数下的平均差异，选择其中最大值就是MMD。</p><p>对于深度学习任务来说，可以选择各种预训练模型的特征空间，比如性能很好的ResNet。</p><p>MMD方法的样本复杂度和计算复杂度都比较低，不过是有偏的，关键就在于用于选择的函数空间是否足够丰富。</p><p>除了以上指标外，还有Wasserstein距离，Fréchet Inception距离等，以后再开篇详述。</p><p>今天就说到这吧，作为初识篇，了解这些就足够了。<br/><br/></p><p>参考文献</p><p>[1] Yuan Y, Guo Q, Lu X, et al. Image quality assessment[J]. Neurocomputing, 2015: 227-241.</p><p>[2] Kamble V, Bhurchandi K M. No-reference image quality assessment algorithms: A survey[J]. Optik, 2015, 126(11): 1090-1097.</p><p>[3] 龙鹏. MRI医学图像增强与分割新方法[D]. 中国科学院大学, 2015.</p><p>[4] Xu Q , Huang G , Yuan Y , et al. An empirical study on evaluation metrics of generative adversarial networks[J]. 2018.</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/58903870", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 36, 
            "title": "【AI初识境】如何增加深度学习模型的泛化能力(L1/L2正则化，dropout，数据增强等等)", 
            "content": "<p>这是专栏《AI初识境》的第9篇文章。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>今天来说说深度学习中的generalization问题，也就是泛化和正则化有关的内容。</p><p>                                                                                                                           作者&amp;编辑 | 言有三</p><h2><b>1 什么是generalization</b></h2><p>机器学习方法训练出来一个模型，希望它不仅仅是对于已知的数据(训练集)性能表现良好，对于未知的数据(测试集)也应该表现良好，也就是具有良好的<b>generalization能力</b>，这就是<b>泛化能力。测试集的误差，也被称为泛化误差</b>。</p><p>举个例子来说，我们在ImageNet上面训练分类模型，希望这个模型也能正确地分类我们自己拍摄的照片。</p><p>在机器学习中，泛化能力的好坏，最直观表现出来的就是模型的<b>过拟合(overfitting)与欠拟合(underfitting)。</b></p><p>过拟合和欠拟合是用于描述模型在训练过程中的两种状态，一般来说，训练会是这样的一个曲线。下面的training error，generalization error分别是训练集和测试集的误差。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-fe6d05d36dd545d9b81505c7d94299d8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"830\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb\" width=\"830\" data-original=\"https://pic1.zhimg.com/v2-fe6d05d36dd545d9b81505c7d94299d8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;830&#39; height=&#39;447&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"830\" data-rawheight=\"447\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"830\" data-original=\"https://pic1.zhimg.com/v2-fe6d05d36dd545d9b81505c7d94299d8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-fe6d05d36dd545d9b81505c7d94299d8_b.jpg\"/></figure><p>训练刚开始的时候，模型还在学习过程中，训练集和测试集的性能都比较差，这个时候，模型还没有学习到知识，处于欠拟合状态，曲线落在<b>underfitting zone</b>，随着训练的进行，训练误差和测试误差都下降。</p><p>随着模型的进一步训练，在训练集上表现的越来越好，终于在突破一个点之后，训练集的误差下降，测试集的误差上升了，这个时候就进入了过拟合区间<b>overfitting zone</b>。</p><p>不过也不是说什么训练过程，都会满足上面的曲线。</p><p><b>(1) 模型训练过程中，训练集的误差一定一直低于测试集吗？未必。</b></p><p>如果这两个集合本来就取自于同样的数据分布，比如从一个数据集中随机采样，那么有可能测试的误差从一开始就低于训练集。不过，总体的趋势肯定是不变的，两者从一开始慢慢下降直到最后过拟合，训练集的误差低于测试集。</p><p><b>(2) 模型的训练一定会过拟合吗？这也不一定！</b></p><p>如果数据集足够大，很可能模型的能力不够始终都不会过拟合。另一方面，有很多的方法可以阻止，或者减缓模型的过拟合，比如正则化，这就是下面第二部分要说的。</p><h2><b>2 什么是Regularization </b></h2><p>Regularization即正则化，它本是代数几何中的一个概念，我们不说因为说不好。放到机器学习里面来说，所谓正则化，它的目标就是要同时让<b>经验风险和模型复杂度较小</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d59f9b8f253989e112eba2b673f71be4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"106\" class=\"origin_image zh-lightbox-thumb\" width=\"524\" data-original=\"https://pic1.zhimg.com/v2-d59f9b8f253989e112eba2b673f71be4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;524&#39; height=&#39;106&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"106\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"524\" data-original=\"https://pic1.zhimg.com/v2-d59f9b8f253989e112eba2b673f71be4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d59f9b8f253989e112eba2b673f71be4_b.jpg\"/></figure><p>以上是我们的优化目标，V就是损失函数，它表示的是当输入xi预测输出为f(xi)，而真实标签为yi时，应该给出多大的损失。那么我们不禁要问，有这一项不就行了吗？为什么还需要后面的那一项呢？R(f)又是什么呢？</p><p>这就是回到上面的泛化误差和过拟合的问题了，一个机器学习系统，学习的是从输入到输出的关系，<b>只要一个模型足够复杂，它是不是可以记住所有的训练集合样本之间的映射，代价就是模型复杂，带来的副作用就是没见过的只是略有不同的样本可能表现地就很差，就像下面这张图，只是更改了一个像素，预测就从Dog变成了Cat。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-5f5a9c3e74c3c577b1447dd9b7e01a5a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"612\" class=\"origin_image zh-lightbox-thumb\" width=\"474\" data-original=\"https://pic3.zhimg.com/v2-5f5a9c3e74c3c577b1447dd9b7e01a5a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;474&#39; height=&#39;612&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"612\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"474\" data-original=\"https://pic3.zhimg.com/v2-5f5a9c3e74c3c577b1447dd9b7e01a5a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-5f5a9c3e74c3c577b1447dd9b7e01a5a_b.jpg\"/></figure><p>造成这种情况的问题就是学的太过，参数拟合的太好以致于超过了前面那个训练曲线的最低泛化误差临界点，究其根本原因是模型的表达能力足够强大到过拟合数据集。</p><p>式子中的R(f)，正是为了约束模型的表达能力，f是模型，R是一个跟模型复杂度相关的函数，单调递增。</p><p><b>有同学可能会说，模型的表达能力跟模型大小，也就是参数量有关，限制模型的表达能力不是应该去调整模型大小吗？这里咱们从另一个角度来看模型的能力问题。</b></p><p>如果我们限制一层神经网络的参数只能为0或者1，它的表达能力肯定不如不做限制，所以同样的参数量，模型的表达能力与参数本身也有关系，正则项就可以在参数上做文章。</p><p>所以说正则化就用于提高模型的泛化能力，这里所说的仅仅是狭义上的参数正则化，而广义上的正则化方法众多，第3部分进行介绍。</p><p><b>正则化的最终目标用一句土话来说，就是让网络学的不要太死，否则变成僵硬的书呆子。</b></p><h2><b>3 正则化方法有哪些</b></h2><p>正则化方法，根据具体的使用策略不同，有直接提供正则化约束的<b>参数正则化方法如L1/L2正则化</b>，以及通过工程上的技巧来实现更低泛化误差的方法，比如训练提前终止和模型集成，我将其称为<b>经验正则化</b>，也有<b>不直接提供约束的隐式正则化方法</b>如数据增强等，下面就从这三类进行讲述。</p><p><b>1、经验正则化方法</b></p><p>这里主要包含两种方法，即<b>提前终止和模型集成</b>。</p><p><b>(1) 提前终止</b></p><p>前面我们看的训练曲线随着不断迭代训练误差不断减少，但是泛化误差减少后开始增长。假如我们在泛化误差指标不再提升后，提前结束训练，也是一种正则化方法，这大概是最简单的方法了。</p><p><b>(2) 模型集成</b></p><p>另一种方法就是模型集成(essemable)，也就是通过训练多个模型来完成该任务，它可以是不同网络结构，不同的初始化方法，不同的数据集训练的模型，也可以是用不同的测试图片处理方法，总之，采用多个模型进行投票的策略。</p><p><b>在这一类方法中，有一个非常有名的方法，即Dropout。</b></p><p>Dropout在2014年被H提出后在深度学习模型的训练中被广泛使用。它在训练过程中，随机的丢弃一部分输入，此时丢弃部分对应的参数不会更新。所谓的丢弃，其实就是让激活函数的输出为0。结构示意图如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-00fb14883c113b3fcb5215739b428674_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"725\" data-rawheight=\"334\" class=\"origin_image zh-lightbox-thumb\" width=\"725\" data-original=\"https://pic1.zhimg.com/v2-00fb14883c113b3fcb5215739b428674_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;725&#39; height=&#39;334&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"725\" data-rawheight=\"334\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"725\" data-original=\"https://pic1.zhimg.com/v2-00fb14883c113b3fcb5215739b428674_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-00fb14883c113b3fcb5215739b428674_b.jpg\"/></figure><p>因而，对于一个有n个节点的神经网络，有了dropout后，就可以看做是2^n个模型的集合了，使用的时候当然不能用2^n个模型来进行推理，而是采用了近似方法，即在使用的时候不进行权重丢弃。根据丢弃比例的不同，在测试的时候会给输出乘以相应的系数，比如某一层在训练的时候只保留50%的权重，在测试的时候是需要用到所有参数的，这个时候就给该层的权重乘以0.5。</p><p>关于dropout的有效性，从结构上来说，它消除或者减弱了神经元节点间的联合，降低了网络对单个神经元的依赖，从而增强了泛化能力。不过也有另外的一些研究从数据增强的角度来思考这个问题。</p><p>那么，就真的不担心dropout会把一些非常重要的神经元删除吗？最新的神经科学的研究以及DeepMind等研究人员通过对神经元进行随机删除来研究网络性能，发现虽然某些神经元确实很重要，它们会选择性激活特定输入，比如只对输入猫图特别敏感，对其他输入则完全不感冒，但是删除这一类神经元仍然不影响网络能识别到猫。</p><p>这说明网络中未必少了谁就不行。不过反过来，上面说到的单个像素的攻击，则说明又有某些神经元至关重要。关于这其中的关系，仍然是研究热门，还是不断跟进更多最新的研究吧。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-de2442c7e2ee544e30a1fbfd6152ed02_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"347\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-de2442c7e2ee544e30a1fbfd6152ed02_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;347&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"347\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-de2442c7e2ee544e30a1fbfd6152ed02_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-de2442c7e2ee544e30a1fbfd6152ed02_b.jpg\"/></figure><p>总之一句话，不怕删了谁。就dropout的使用方法而言，我们平常只更改dropout的比例，作者对此还有更多的建议。</p><p><b>(1) 因为dropout降低了模型的性能，所以对于原本需要容量为N的网络才能解决的问题，现在需要N/p，p就是保留该节点的概率，这个概率通常在0.5～0.9之间，p=1就是普通的网络了。</b></p><p><b>(2) 因为dropout相当于增加了噪声，造成梯度的损失，所以需要使用更大的学习率和动量项。与此同时，对权重进行max-norm等权重约束方法，使其不超过某个值。</b></p><p><b>(3) 训练更久，很好理解。</b></p><p>对dropout方法，还有很多的变种，包括<b>dropout connect，maxout，stochastic depth</b>等。</p><p>一个神经元的输出实际上是由输入以及参数来共同决定，dropout把神经元的值设置为0了，那是不是也可以把参数设置为0呢？这就是drop connect，而且它可以比dropout更加灵活，可视为Dropout的一般化形式，从模型集成的角度来看，Dropout是2^n个模型的平均，那DropConnect呢？它应该更多，因为权重连接的数目比节点数本身更多，所以DropConnect模型平均能力更强。</p><p>Drop Connect和Dropout均引入了稀疏性，不同之处在于Drop Connect引入的是权重的稀疏而不是层的输出向量的稀疏。</p><p><b>另外，在dropout这一个思路上做相关文章的还有一些，比如maxout，是一种激活函数，它对N个输入选择最大的作为激活输出。比如随机pooling，是一种池化方法。比如stochastic depth，它用在带有残差结构的网络中，将某些res block直接设置为等价映射。还有backdrop，在前向的时候不drop，在梯度反传的时候才做。</b></p><p><b>在这里不禁想给大家提两个问题</b></p><p><b>(1) 你还能想到多少种drop方法？想不到就等我们下次专门说。</b></p><p><b>(2) dropout应该怎么跟其他的方法结合，比如batch normalization，会强强联合得到更好的结果吗？</b></p><p><b>2、参数正则化方法</b></p><p>L2/L1正则化方法，就是最常用的正则化方法，它直接来自于传统的机器学习。</p><p>L2正则化方法如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9ea53de5f72560766bb33c5f319ec744_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"100\" class=\"origin_image zh-lightbox-thumb\" width=\"498\" data-original=\"https://pic1.zhimg.com/v2-9ea53de5f72560766bb33c5f319ec744_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;498&#39; height=&#39;100&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"100\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"498\" data-original=\"https://pic1.zhimg.com/v2-9ea53de5f72560766bb33c5f319ec744_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-9ea53de5f72560766bb33c5f319ec744_b.jpg\"/></figure><p>L1正则化方法如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-dcbca4092b1e0b05d9d9f345c885d574_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"78\" class=\"origin_image zh-lightbox-thumb\" width=\"524\" data-original=\"https://pic1.zhimg.com/v2-dcbca4092b1e0b05d9d9f345c885d574_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;524&#39; height=&#39;78&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"78\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"524\" data-original=\"https://pic1.zhimg.com/v2-dcbca4092b1e0b05d9d9f345c885d574_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-dcbca4092b1e0b05d9d9f345c885d574_b.jpg\"/></figure><p>那它们俩有什么区别呢？最流行的一种解释方法来自于模式识别和机器学习经典书籍，下面就是书中的图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8f4e101672363f1ab5e89be082e61dd2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8f4e101672363f1ab5e89be082e61dd2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;420&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-8f4e101672363f1ab5e89be082e61dd2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8f4e101672363f1ab5e89be082e61dd2_b.jpg\"/></figure><p>这么来看上面的那张图，参数空间(w1,w2)是一个二维平面，蓝色部分是一个平方损失函数，黄色部分是正则项。</p><p>蓝色的那个圈，中心的点其实代表的就是损失函数最优的点，而同心圆则代表不同的参数相同的损失，可见随着圆的扩大，损失增大。黄色的区域也类似，周边的红色线表示的是损失相同点的轮廓。</p><p>正则项的红色轮廓线示平方损失的蓝色轮廓线总要相交，才能使得两者加起来的损失最小，两者的所占区域的相对大小，是由权重因子决定的。不管怎么说，它们总有一个交叉点。</p><p>对于L2正则化，它的交点会使得w1或者w2的某一个维度特别小，而L1正则化则会使得w1或者w2的某一个维度等于0，因此获得所谓的稀疏化。</p><p>在深度学习框架中，大家比起L1范数，更钟爱L2范数，因为它更加平滑和稳定。</p><p><b>3、隐式正则化方法</b></p><p>前面说了两种正则化方法，第一种，通过对网络结构的修改或者在使用方法上进行调整。第二种，直接对损失函数做了修改。这两种方法，其实都应该算作<b>显式的正则化方法</b>，因为在做这件事的过程中， 我们是有意识地知道自己在做正则化。</p><p>但是还有另一种正则化方法，它是<b>隐式的正则化方法</b>，并非有意识地直接去做正则化，却甚至能够取得更好的效果，这便是数据有关的操作，包括归一化方法和数据增强，扰乱标签。</p><p>关于数据增强的方法，我们以前已经有过几期文章讲述，从有监督方法到无监督方法。关于归一化方法，以batch normalization为代表，我们以前也详细地讲过。参考链接就放这里了，大家自取。</p><p><u><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></u><br/><u><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029110%26idx%3D1%26sn%3D4debbbe890b48ab739fec5967868746b%26chksm%3D8713478bb064ce9da68dd57b419ddebd22884c05747abb9286c1e5bc6563702f2a1fd4bcac64%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】深度学习中的数据增强（下）</a></u><br/><u><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029048%26idx%3D1%26sn%3Dec708683cb6a3c2ed048a945a7150b79%26chksm%3D871347c5b064ced3fd3d57c5c79df0087890efb10898076efb14e9ece8ddf38906dbaf33af2c%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[综述类] 一文道尽深度学习中的数据增强方法（上）</a></u><br/></p><p><b>实验表明，隐式的方法比显式的方法更强，从batch normalization的使用替换掉了dropout，以及数据扩增碾压一切trick就可以看出。另外，批量随机梯度算法本身，也可以算是一种隐式的正则化方法，它随机选择批量样本而不是整个数据集，与上面的dropout方法其实也有异曲同工之妙。</b></p><p><b>这么看来，其实data dependent方法更好，咱们前面的几期都说过，不要闷着头设计，从数据中学习才是王道。</b></p><h2><b>4 深度学习泛化能力到底好不好</b></h2><p><b>你说深度学习的泛化能力是强还是不强，感觉完全可以打一架。</b></p><p>一方面，深度学习方法已经在各行各业落地，说泛化能力不好谁都不信，都已经经得起工业界的考验。关于如何定量的衡量泛化能力，目前从模型复杂度的角度有一些指标，可以参考[1]。</p><p>但是另一方面，有许多的研究[2-3]都表明，仅仅是对图像作出小的改动，甚至是一个像素的改动，都会导致那些强大的网络性能的急剧下降，这种不靠谱又让人心慌，在实际应用的过程中，笔者也一直遇到这样的问题，比如下图<b>微小的平移操作对输出概率的严重影响，真的挺常见。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-b9706d9a4363e8a165ae24c5d531d91f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"265\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-b9706d9a4363e8a165ae24c5d531d91f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;265&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"265\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-b9706d9a4363e8a165ae24c5d531d91f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-b9706d9a4363e8a165ae24c5d531d91f_b.jpg\"/></figure><p>正则化方法可以完美解决吗？甚至最强的数据增强方法能做的都是有限的，一个网络可以记忆住样本和它的随机标签[4]，做什么正则化都没有作用。说起来神经网络一直在力求增强各种不变性，但是却往往搞不定偏移，尺度缩放。这就是为什么在刷比赛的时候，仅仅是对图像采用不同的crop策略，就能胜过任何其他方法的原因，从这一点来说，是一件非常没有意思的事情。</p><p>或许，关于正则化，再等等吧。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>参考文献</p><p>[1] Neyshabur B, Bhojanapalli S, Mcallester D A, et al. Exploring Generalization in Deep Learning[J]. neural information processing systems, 2017: 5947-5956.</p><p>[2] Su J, Vargas D V, Sakurai K, et al. One Pixel Attack for Fooling Deep Neural Networks[J]. IEEE Transactions on Evolutionary Computation, 2019: 1-1.</p><p>[3] Azulay A, Weiss Y. Why do deep convolutional networks generalize so poorly to small image transformations[J]. arXiv: Computer Vision and Pattern Recognition, 2018.</p><p>[4] Zhang C, Bengio S, Hardt M, et al. Understanding deep learning requires rethinking generalization[J]. international conference on learning representations, 2017.</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "泛化", 
                    "tagLink": "https://api.zhihu.com/topics/20683021"
                }, 
                {
                    "tag": "最优化", 
                    "tagLink": "https://api.zhihu.com/topics/19616819"
                }
            ], 
            "comments": [
                {
                    "userName": "Nirvana", 
                    "userLink": "https://www.zhihu.com/people/ff7d431b5176a0e48ab10a36e3f9b4ec", 
                    "content": "不错", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<a class=\"comment_sticker\" href=\"https://pic3.zhimg.com/v2-cb8443f07a41298e45191cef11b90fd2.gif\" data-width=\"\" data-height=\"\">[干杯]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "Nirvana"
                        }
                    ]
                }, 
                {
                    "userName": "anunknownworld", 
                    "userLink": "https://www.zhihu.com/people/31b94aa210050d1b88874ea6c2eaa522", 
                    "content": "好东西，对正则化有了全面的了解", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "有帮助就好", 
                            "likes": 0, 
                            "replyToAuthor": "anunknownworld"
                        }
                    ]
                }, 
                {
                    "userName": "知立方", 
                    "userLink": "https://www.zhihu.com/people/37ca0df3c466adeab55fa08674a29e49", 
                    "content": "同样的参数和数据集，为什么复现不了别人的结果！！", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "[捂脸]", 
                            "likes": 0, 
                            "replyToAuthor": "知立方"
                        }
                    ]
                }, 
                {
                    "userName": "肖东海", 
                    "userLink": "https://www.zhihu.com/people/0c4fe9b97d375959102ff3235f982501", 
                    "content": "写得真好，期待作者后续的佳作~[赞同]", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "必须的[握手][握手][握手]", 
                            "likes": 0, 
                            "replyToAuthor": "肖东海"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/58381421", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 68, 
            "title": "【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化(pooling)，到底是什么？", 
            "content": "<p>这是专栏《AI初识境》的第8篇文章。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>今天来说说深度学习中的池化问题，包含池化的种类，作用机制以及最新的思考。</p><p>                                                                                                                          作者&amp;编辑 | 言有三</p><h2><b>1 池化还要不要了</b></h2><p>这一次咱们反着来，说说学术界对池化的最新观点。通常我们认为，<b>池化可以增加网络对于平移的不变性，对于网络的泛化能力的提升是非常关键的</b>。不过，到底能起到多大的正向作用，却是被很多人怀疑的。</p><p>首先是Hinton，还记得Hinton提出的Capsule Module吧。他认为池化的使用就是一个大错误，而它有效又反而是一个大灾难。池化固然可以提供一些平移和旋转不变性，但是也破坏了图像中的姿态和空间等信息，对检测分割等高级任务有影响，所以才提出胶囊网络(CapsuleNetwork)。至于这个发展的怎么样了，笔者没有关注，但是从大佬敢于革自己的“本命”这一点，就说明这个问题确实有点严重。</p><p>Hinton虽然指出了pooling的坏影响，但是无法否定其好处，那么池化是不是真的能够提升网络的泛化能力呢？</p><p>首先站出来好好回答这个问题的是斯坦福大学Eric Kauderer-Abrams的研究【1】，它们通过一个平移敏感图来进行研究。</p><p>这个平移敏感图长下面这样，它评估的就是一个网络的输出对于输入的平移的敏感度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-28421ed8dab4dcaf65523f2cf12b6497_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"932\" data-rawheight=\"920\" class=\"origin_image zh-lightbox-thumb\" width=\"932\" data-original=\"https://pic4.zhimg.com/v2-28421ed8dab4dcaf65523f2cf12b6497_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;932&#39; height=&#39;920&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"932\" data-rawheight=\"920\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"932\" data-original=\"https://pic4.zhimg.com/v2-28421ed8dab4dcaf65523f2cf12b6497_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-28421ed8dab4dcaf65523f2cf12b6497_b.jpg\"/></figure><p>上面这个图是这么算的，首先用原图计算预测特征分数，然后用平移过的图计算预测特征分数，最后计算两者的归一化分数，越亮说明越相关。x和y分别就是偏移量，可以看到x，y都接近0的时候越亮，说明越相关，然后就随着距离的增强而降低。</p><p>这就是说平移越大之后，对性能的影响越大，毕竟一个网络不可能拥有完全的平移不变性。</p><p>在这个基础上，他们就做实验了，结果如下，c表示卷积，p表示pooling，aug表示数据增强，所以这里就是比较pooling和aug对性能的影响，结果表明<b>池化不池化的，好像没有什么用，而数据增强做不做得好，才是关键。结果说明CNN本身没什么平移不变性，是靠数据学来的。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ee9cb47eebf358ee238ce50de3746602_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"727\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ee9cb47eebf358ee238ce50de3746602_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;727&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"727\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ee9cb47eebf358ee238ce50de3746602_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ee9cb47eebf358ee238ce50de3746602_b.jpg\"/></figure><p><b>上面做了实验，但是没有更深层次地分析，为什么池化就没有用了呢，这可是违反我们的常识的。</b></p><p>DeepMind的研究【2】给出了一个比较有说服力的解答，实验的设置差不多，使用非池化和各种池化的网络结构。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c2dc7dbb6b5a6b86bd4b3a9e714ebcad_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"302\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c2dc7dbb6b5a6b86bd4b3a9e714ebcad_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;302&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"302\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-c2dc7dbb6b5a6b86bd4b3a9e714ebcad_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c2dc7dbb6b5a6b86bd4b3a9e714ebcad_b.jpg\"/></figure><p>总之结论就是：看上面的4个图。<b>(a) 刚开始的时候池化确实有利于提高抗变形能力。(b) 不管池化不池化，模型最后学习完都能获得同样的抗变形能力。(c) 初始化的时候不同的池化方法是有差异的。(d) 学习完之后不管什么池化方法效果都差不多。</b></p><p>那总得有个理由吧？他们给出的理由是卷积核本身参数越平滑才越能提高对平移的稳定性，文中在卷积操作后面串接平滑操作，实验对比如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-cf5abd3cde422fe7023a445ae7ab41a0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"680\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-cf5abd3cde422fe7023a445ae7ab41a0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;680&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"680\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-cf5abd3cde422fe7023a445ae7ab41a0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-cf5abd3cde422fe7023a445ae7ab41a0_b.jpg\"/></figure><p>这也没毛病对吧，卷积核都平滑了，当然就没有那么敏感了。</p><p><b>暂且先总结一下吧：池化什么的不重要了，搞数据增强才是正道。</b></p><h2><b>2 什么是池化</b></h2><p>上面都这么说了，接下来说池化略有点尴尬，但是作为知识体系的重要一环，还是有必要讲述。</p><p>pooling，小名池化，思想来自于视觉机制，是对信息进行抽象的过程。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5e403c7127de4e86a84c8cebd4cc1a70_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"369\" data-thumbnail=\"https://pic1.zhimg.com/v2-5e403c7127de4e86a84c8cebd4cc1a70_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-5e403c7127de4e86a84c8cebd4cc1a70_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;369&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"369\" data-thumbnail=\"https://pic1.zhimg.com/v2-5e403c7127de4e86a84c8cebd4cc1a70_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic1.zhimg.com/v2-5e403c7127de4e86a84c8cebd4cc1a70_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5e403c7127de4e86a84c8cebd4cc1a70_b.gif\"/></figure><p>上图就是一个池化的示意图，用了一个10*10的卷积核，对20*20的图像分块不重叠的进行了池化，池化之后featuremap为2*2的大小。</p><p>pooling有什么用呢？或者说为什么需要pooling呢？原因有几个：</p><p><b>1、增大感受野</b></p><p>所谓感受野，即一个像素对应回原图的区域大小，假如没有pooling，一个3*3，步长为1的卷积，那么输出的一个像素的感受野就是3*3的区域，再加一个stride=1的3*3卷积，则感受野为5*5。</p><p>假如我们在每一个卷积中间加上3*3的pooling呢？很明显感受野迅速增大，这就是pooling的一大用处。感受野的增加对于模型的能力的提升是必要的，正所谓“一叶障目则不见泰山也”。</p><p><b>2、平移不变性</b></p><p>我们希望目标的些许位置的移动，能得到相同的结果。因为pooling不断地抽象了区域的特征而不关心位置，所以pooling一定程度上增加了平移不变性。</p><p><b>3、降低优化难度和参数</b></p><p>我们可以用步长大于1的卷积来替代池化，但是池化每个特征通道单独做降采样，与基于卷积的降采样相比，不需要参数，更容易优化。全局池化更是可以大大降低模型的参数量和优化工作量。</p><h2><b>3 池化有哪些</b></h2><p><b>1、平均池化和最大池化</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-b387cfa3bccc4d2f3390e4ff7ca73bd3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1022\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb\" width=\"1022\" data-original=\"https://pic4.zhimg.com/v2-b387cfa3bccc4d2f3390e4ff7ca73bd3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1022&#39; height=&#39;338&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1022\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1022\" data-original=\"https://pic4.zhimg.com/v2-b387cfa3bccc4d2f3390e4ff7ca73bd3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-b387cfa3bccc4d2f3390e4ff7ca73bd3_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-72b21cd21ca7faa42a0360a584900ce7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1068\" data-rawheight=\"596\" class=\"origin_image zh-lightbox-thumb\" width=\"1068\" data-original=\"https://pic4.zhimg.com/v2-72b21cd21ca7faa42a0360a584900ce7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1068&#39; height=&#39;596&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1068\" data-rawheight=\"596\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1068\" data-original=\"https://pic4.zhimg.com/v2-72b21cd21ca7faa42a0360a584900ce7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-72b21cd21ca7faa42a0360a584900ce7_b.jpg\"/></figure><p>这是我们最熟悉的，通常认为如果选取区域均值(mean pooling)，往往能保留整体数据的特征，较好的突出背景信息；如果选取区域最大值(max pooling)，则能更好保留纹理特征。</p><p><b>2、stochastic pooling/mixed pooling</b></p><p>stochastic pooling对feature map中的元素按照其概率值大小随机选择，元素被选中的概率与其数值大小正相关，这就是一种正则化的操作了。mixed pooling就是在max/average pooling中进行随机选择。</p><p><b>3、Data Driven/Detail-Preserving Pooling</b></p><p>上面的这些方法都是手动设计，而现在深度学习各个领域其实都是往自动化的方向发展。</p><p>我们前面也说过，从激活函数到归一化都开始研究数据驱动的方案，池化也是如此，每一张图片都可以学习到最适合自己的池化方式。</p><p>此外还有一些变种如weighted max pooling，Lp pooling，generalization max pooling就不再提了，还有global pooling。</p><h2><b>4 总结</b></h2><p>带步长的卷积虽然不需要池化，却没有了灵活的激活机制。平均池化稳扎稳打，却丢失了细节。最大池化克服了平均池化的缺点，却打断了梯度回传。</p><p>最终发现，池化也还是要学的好，所谓随机应变，盖莫如此。另外，如何选择好用于池化的区域，也是一门学问。<br/></p><p>参考文献</p><p>[1] Kaudererabrams E. Quantifying Translation-Invariance in Convolutional Neural Networks.[J]. arXiv: Computer Vision and Pattern Recognition, 2018.</p><p>[2] Ruderman A, Rabinowitz N C, Morcos A S, et al. Pooling is neither necessary nor sufficient for appropriate deformation stability in CNNs[J]. arXiv: Computer Vision and Pattern Recognition, 2018.</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "池化", 
                    "tagLink": "https://api.zhihu.com/topics/20682798"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": [
                {
                    "userName": "「已注销」", 
                    "userLink": "https://www.zhihu.com/people/d353336bdf8bf7edde12f3cf4de99b5c", 
                    "content": "可不可以理解为少用池化呢？<a href=\"https://pic4.zhimg.com/v2-b789d8e597d920061dcd4efb585cd343.gif\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"951517104261255168\">[思考]</a>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "li kknd", 
                            "userLink": "https://www.zhihu.com/people/664e6a401f0b5fbd2aeeba76fc45dc33", 
                            "content": "NIN就是不用池化", 
                            "likes": 0, 
                            "replyToAuthor": "「已注销」"
                        }, 
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<p>哈哈，用了个最大的</p>", 
                            "likes": 0, 
                            "replyToAuthor": "li kknd"
                        }
                    ]
                }, 
                {
                    "userName": "qqyy", 
                    "userLink": "https://www.zhihu.com/people/72cf3e0863b1903378f3fc0d420ff9e7", 
                    "content": "<p>请问，为什么最大池化，会打断梯度回传？</p><p></p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "只传回了最大值那个节点，其他节点没了", 
                            "likes": 0, 
                            "replyToAuthor": "qqyy"
                        }
                    ]
                }, 
                {
                    "userName": "qqyy", 
                    "userLink": "https://www.zhihu.com/people/72cf3e0863b1903378f3fc0d420ff9e7", 
                    "content": "<p>哦哦，明白了，十分感谢</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<p>不客气</p>", 
                            "likes": 0, 
                            "replyToAuthor": "qqyy"
                        }
                    ]
                }, 
                {
                    "userName": "言简意赅", 
                    "userLink": "https://www.zhihu.com/people/f0d1cb943815f5d419ac2433c55279ec", 
                    "content": "<p>暂且先总结一下吧：池化什么的不重要了，搞数据增强才是正道。</p><p><br></p><p>看Alexnet原文，说重叠池化改善了结果，搜了半天，想知道这东西现在还有没有人用了。然后看到这里.....</p>", 
                    "likes": 1, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/57860231", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 168, 
            "title": "【AI初识境】为了围剿SGD大家这些年想过的那十几招(从momentum到Adabound)", 
            "content": "<p>这是《AI初识境》第7篇，这次我们说说常用的优化算法。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>深度学习框架目前基本上都是使用一阶的梯度下降算法及其变种进行优化，在此基础上也发展出了很多的改进算法。另外，近年来二阶的优化算法也开始慢慢被研究起来。</p><p>今天就来说说神经网络的优化相关的内容。</p><p>                                                                                                                          作者&amp;编辑  | 言有三</p><h2><br/><b>1 优化简述</b></h2><p>深度学习模型的优化是一个非凸优化问题，这是与凸优化问题对应的。</p><p>对于凸优化来说，任何局部最优解即为全局最优解。用贪婪算法或梯度下降法都能收敛到全局最优解，损失曲面如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-774a4a3826832389e63f650998dbcc01_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"768\" data-rawheight=\"461\" class=\"origin_image zh-lightbox-thumb\" width=\"768\" data-original=\"https://pic2.zhimg.com/v2-774a4a3826832389e63f650998dbcc01_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;768&#39; height=&#39;461&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"768\" data-rawheight=\"461\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"768\" data-original=\"https://pic2.zhimg.com/v2-774a4a3826832389e63f650998dbcc01_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-774a4a3826832389e63f650998dbcc01_b.jpg\"/></figure><p>而非凸优化问题则可能存在无数个局部最优点，损失曲面如下，可以看出有非常多的极值点，有极大值也有极小值。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ca690dce2667a8bbeba5a587a8324b19_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"560\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb\" width=\"560\" data-original=\"https://pic2.zhimg.com/v2-ca690dce2667a8bbeba5a587a8324b19_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;560&#39; height=&#39;420&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"560\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"560\" data-original=\"https://pic2.zhimg.com/v2-ca690dce2667a8bbeba5a587a8324b19_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ca690dce2667a8bbeba5a587a8324b19_b.jpg\"/></figure><p>除了极大极小值，还有一类值为“鞍点”，简单来说，它就是在某一些方向梯度下降，另一些方向梯度上升，形状似马鞍，如下图<b>红点就是鞍点</b>。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-efbc2069c83948d1aad2d99e1f15334a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"403\" class=\"origin_image zh-lightbox-thumb\" width=\"1024\" data-original=\"https://pic3.zhimg.com/v2-efbc2069c83948d1aad2d99e1f15334a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1024&#39; height=&#39;403&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"403\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1024\" data-original=\"https://pic3.zhimg.com/v2-efbc2069c83948d1aad2d99e1f15334a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-efbc2069c83948d1aad2d99e1f15334a_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>对于深度学习模型的优化来说，<b>鞍点比局部极大值点或者极小值点带来的问题更加严重</b>。</p><p>目前常用的优化方法分为一阶和二阶，这里的阶对应导数，一阶方法只需要一阶导数，二阶方法需要二阶导数。<br/></p><p><b>常用的一阶算法就是：随机梯度下降SGD及其各类变种了。</b></p><p><b>常用的二阶算法就是：牛顿法等。</b></p><p>我们这里主要还是说一阶方法，二阶方法因为计算量的问题，现在还没有被广泛地使用。</p><h2><b>2 梯度下降算法</b></h2><p>本文目标不是为了从零开始讲清楚优化算法，所以有些细节和基础就略过。</p><p>梯度下降算法，即通过梯度的反方向来进行优化，<b>批量梯度下降（Batch gradient descent）</b>用公式表述如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-1effedcb9fcd26017a94b85704973d73_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"506\" data-rawheight=\"100\" class=\"origin_image zh-lightbox-thumb\" width=\"506\" data-original=\"https://pic4.zhimg.com/v2-1effedcb9fcd26017a94b85704973d73_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;506&#39; height=&#39;100&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"506\" data-rawheight=\"100\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"506\" data-original=\"https://pic4.zhimg.com/v2-1effedcb9fcd26017a94b85704973d73_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-1effedcb9fcd26017a94b85704973d73_b.jpg\"/></figure><p>写成伪代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">for i in range(nb_epochs):\n    params_grad = evaluate_gradient(loss_function, data, params) \n    params = params - learning_rate * params_grad</code></pre></div><p>上面的梯度下降算法用到了数据集所有的数据，这在解决实际问题时通常是不可能，想想Imagenet1000有100G以上的图像，内存装不下，速度也很慢。</p><p>我们需要在线能够实时计算，于是一次取一个样本，就有了<b>随机梯度下降（Stochastic gradient descent），简称sgd</b>。</p><p>公式如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4ce6022ff55dc8d781a87cba61aa7997_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"566\" data-rawheight=\"108\" class=\"origin_image zh-lightbox-thumb\" width=\"566\" data-original=\"https://pic4.zhimg.com/v2-4ce6022ff55dc8d781a87cba61aa7997_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;566&#39; height=&#39;108&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"566\" data-rawheight=\"108\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"566\" data-original=\"https://pic4.zhimg.com/v2-4ce6022ff55dc8d781a87cba61aa7997_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4ce6022ff55dc8d781a87cba61aa7997_b.jpg\"/></figure><p>写成伪代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">for i in range(nb_epochs): \n    np.random.shuffle(data)\n    for example in data:\n        params_grad = evaluate_gradient(loss_function , example , params) \n        params = params - learning_rate * params_grad</code></pre></div><p>sgd方法缺点很明显，梯度震荡，所以就有了后来大家常用的<b>小批量梯度下降算法（Mini-batch gradient descent）</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5497306546d1f573eee0b43376998238_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"122\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic1.zhimg.com/v2-5497306546d1f573eee0b43376998238_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;122&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"122\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic1.zhimg.com/v2-5497306546d1f573eee0b43376998238_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5497306546d1f573eee0b43376998238_b.jpg\"/></figure><p>伪代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">for i in range(nb_epochs): \n    np.random.shuffle(data)\n    for batch in get_batches(data, batch_size=50):\n        params_grad = evaluate_gradient(loss_function, batch, params) \n        params = params - learning_rate * params_grad</code></pre></div><p>下面我们要形成共识，<b>说sgd算法，实际上指的就是mini-batch gradient descent算法，没有人会去一次拿整个数据集或者一个样本进行优化。</b></p><p>当然还是要总结一下SGD算法的毛病。</p><p>(1) 学习率大小和策略选择困难，想必动手经验丰富的自然懂。</p><p>(2) 学习率不够智能，对参数的各个维度一视同仁。</p><p>(3) 同时面临局部极值和鞍点的问题。</p><h2><b>3 梯度下降算法改进</b></h2><blockquote><b>1 Momentum 动量法</b></blockquote><p><b>在所有的改进算法中，我觉得真正最有用的就是它。</b></p><p>前面说了梯度下降算法是按照梯度的反方向进行参数更新，但是<b>刚开始的时候梯度不稳定呀，方向改变是很正常的</b>，梯度就是抽疯了似的一下正一下反，导致做了很多无用的迭代。</p><p>而动量法做的很简单，<b>相信之前的梯度</b>。如果梯度方向不变，就越发更新的快，反之减弱当前梯度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-46c6f5f721da0a889f682c96caeed19d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"132\" class=\"origin_image zh-lightbox-thumb\" width=\"480\" data-original=\"https://pic2.zhimg.com/v2-46c6f5f721da0a889f682c96caeed19d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;480&#39; height=&#39;132&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"132\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"480\" data-original=\"https://pic2.zhimg.com/v2-46c6f5f721da0a889f682c96caeed19d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-46c6f5f721da0a889f682c96caeed19d_b.jpg\"/></figure><p>画成图就是这样。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-89c399745343352e1254d9fb3992d60c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"356\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-89c399745343352e1254d9fb3992d60c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;356&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"356\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-89c399745343352e1254d9fb3992d60c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-89c399745343352e1254d9fb3992d60c_b.jpg\"/></figure><p>效果对比就这意思。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-561afd062cfb56512e0776e58e08a8ae_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"269\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-561afd062cfb56512e0776e58e08a8ae_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;269&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"269\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-561afd062cfb56512e0776e58e08a8ae_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-561afd062cfb56512e0776e58e08a8ae_b.jpg\"/></figure><blockquote><b>2 Nesterov accelerated gradient法 ，简称NAG算法   </b></blockquote><p>仍然是动量法，只是它要求这个下降更加智能。</p><p>既然动量法已经把前一次的梯度和当前梯度融合，那何不更进一步，直接先按照前一次梯度方向更新一步将它作为当前的梯度，看下面的式子就明白了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5d2a407eb27baa7352aa5722b82ca275_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"704\" data-rawheight=\"174\" class=\"origin_image zh-lightbox-thumb\" width=\"704\" data-original=\"https://pic2.zhimg.com/v2-5d2a407eb27baa7352aa5722b82ca275_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;704&#39; height=&#39;174&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"704\" data-rawheight=\"174\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"704\" data-original=\"https://pic2.zhimg.com/v2-5d2a407eb27baa7352aa5722b82ca275_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5d2a407eb27baa7352aa5722b82ca275_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-9c04d2b8f554379bc2bcabf8cfc46afb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"916\" data-rawheight=\"438\" class=\"origin_image zh-lightbox-thumb\" width=\"916\" data-original=\"https://pic4.zhimg.com/v2-9c04d2b8f554379bc2bcabf8cfc46afb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;916&#39; height=&#39;438&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"916\" data-rawheight=\"438\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"916\" data-original=\"https://pic4.zhimg.com/v2-9c04d2b8f554379bc2bcabf8cfc46afb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-9c04d2b8f554379bc2bcabf8cfc46afb_b.jpg\"/></figure><p>如上图，计算B点下一步更新动量时，先达到提前点C，然后根据A点带来的动量项和C点的梯度进行更新，得到D点。nesterov的好处就是，当梯度方向快要改变的时候，它提前获得了该信息，从而减弱了这个过程，再次减少了无用的迭代。</p><blockquote><b>3 Adagrad法</b></blockquote><p>思路很简单，<b>不同的参数是需要不同的学习率的</b>，有的要慢慢学，有的要快快学，所以就给了一个权重咯，而且是用了历史上所有的梯度幅值。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-aa63a633716fc23cc1448d7255e7b8be_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"568\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb\" width=\"568\" data-original=\"https://pic3.zhimg.com/v2-aa63a633716fc23cc1448d7255e7b8be_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;568&#39; height=&#39;152&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"568\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"568\" data-original=\"https://pic3.zhimg.com/v2-aa63a633716fc23cc1448d7255e7b8be_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-aa63a633716fc23cc1448d7255e7b8be_b.jpg\"/></figure><blockquote>4 Adadelta与Rmsprop</blockquote><p>Adagrad用了所有的梯度，问题也就来了，累加的梯度幅值是越来越大的。导致学习率前面的乘因子越来越小，后来就学不动了呀。</p><p>Adadelta就只是动了一丢丢小心思，用移动平均的方法计算累加梯度，只累加了一个窗口的梯度，而且计算方法也更有效。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d0c4328325b7a4a35eb3924e4d3a4b22_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"676\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb\" width=\"676\" data-original=\"https://pic3.zhimg.com/v2-d0c4328325b7a4a35eb3924e4d3a4b22_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;676&#39; height=&#39;110&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"676\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"676\" data-original=\"https://pic3.zhimg.com/v2-d0c4328325b7a4a35eb3924e4d3a4b22_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d0c4328325b7a4a35eb3924e4d3a4b22_b.jpg\"/></figure><p>并且，将学习率用前一时刻参数的平方根来代替，最终更新算法变成了这样。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-117a71d8abd58d5b8ba1ccff9315c08a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"210\" class=\"origin_image zh-lightbox-thumb\" width=\"498\" data-original=\"https://pic3.zhimg.com/v2-117a71d8abd58d5b8ba1ccff9315c08a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;498&#39; height=&#39;210&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"210\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"498\" data-original=\"https://pic3.zhimg.com/v2-117a71d8abd58d5b8ba1ccff9315c08a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-117a71d8abd58d5b8ba1ccff9315c08a_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d039325dfdfd4f519eaf54df0e04fc8a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"614\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb\" width=\"614\" data-original=\"https://pic3.zhimg.com/v2-d039325dfdfd4f519eaf54df0e04fc8a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;614&#39; height=&#39;128&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"614\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"614\" data-original=\"https://pic3.zhimg.com/v2-d039325dfdfd4f519eaf54df0e04fc8a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d039325dfdfd4f519eaf54df0e04fc8a_b.jpg\"/></figure><p>RMSprop方法的不同就在于分子上还是使用学习率η而不是Adadelta中的</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f7ff94b8001c7d71d4da6cb564e6fe3f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"92\" class=\"origin_image zh-lightbox-thumb\" width=\"524\" data-original=\"https://pic4.zhimg.com/v2-f7ff94b8001c7d71d4da6cb564e6fe3f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;524&#39; height=&#39;92&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"92\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"524\" data-original=\"https://pic4.zhimg.com/v2-f7ff94b8001c7d71d4da6cb564e6fe3f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f7ff94b8001c7d71d4da6cb564e6fe3f_b.jpg\"/></figure><p>这个方法在Hinton的课程中使用，没有发表成论文，毕竟有Adadelta了没有发表必要。</p><blockquote><b>5 Adam方法</b></blockquote><p><b>Adam算法可能是除了SGD算法之外大家最熟悉的了，无脑使用，不需调参。</b></p><p>Adam对梯度的一阶和二阶都进行了估计与偏差修正，使用梯度的一阶矩估计和二阶矩估计来动态调整每个参数的学习率。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e59ac9dd66d7c2a6dae1b2f62f029d3c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"596\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb\" width=\"596\" data-original=\"https://pic1.zhimg.com/v2-e59ac9dd66d7c2a6dae1b2f62f029d3c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;596&#39; height=&#39;188&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"596\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"596\" data-original=\"https://pic1.zhimg.com/v2-e59ac9dd66d7c2a6dae1b2f62f029d3c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e59ac9dd66d7c2a6dae1b2f62f029d3c_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f43c3c29ffa67e78e11c95c6b0943c68_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"348\" data-rawheight=\"244\" class=\"content_image\" width=\"348\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;348&#39; height=&#39;244&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"348\" data-rawheight=\"244\" class=\"content_image lazy\" width=\"348\" data-actualsrc=\"https://pic1.zhimg.com/v2-f43c3c29ffa67e78e11c95c6b0943c68_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-167e83f2923198e6d7f9ea90bf716bb8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"502\" data-rawheight=\"148\" class=\"origin_image zh-lightbox-thumb\" width=\"502\" data-original=\"https://pic1.zhimg.com/v2-167e83f2923198e6d7f9ea90bf716bb8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;502&#39; height=&#39;148&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"502\" data-rawheight=\"148\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"502\" data-original=\"https://pic1.zhimg.com/v2-167e83f2923198e6d7f9ea90bf716bb8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-167e83f2923198e6d7f9ea90bf716bb8_b.jpg\"/></figure><p>看出来了吧，与Adadelta和Rmsprop如出一辙，与Momentum SGD也颇为相似。上面的式子根据梯度对参数更新的幅度进行了动态调整，所以Adam对学习率没有那么敏感。</p><p>Adam每次迭代参数的学习步长都有一个确定的范围，不会因为很大的梯度导致很大的学习步长，参数的值比较稳定，但是它也并非真的是参数不敏感的，学习率在训练的后期可仍然可能不稳定导致无法收敛到足够好的值，泛化能力较差，这在文[3]中有非常详细的研究，后面也会简单说一下。</p><blockquote><b>6 AdaMax</b></blockquote><p>将Adam使用的二阶矩变成更高阶，就成了Adamax算法。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4fe88a650aed23f82fa8886769bd71f5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"642\" data-rawheight=\"168\" class=\"origin_image zh-lightbox-thumb\" width=\"642\" data-original=\"https://pic2.zhimg.com/v2-4fe88a650aed23f82fa8886769bd71f5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;642&#39; height=&#39;168&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"642\" data-rawheight=\"168\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"642\" data-original=\"https://pic2.zhimg.com/v2-4fe88a650aed23f82fa8886769bd71f5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4fe88a650aed23f82fa8886769bd71f5_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-09ac982d4f1b845271b85baa62d2a56e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"384\" data-rawheight=\"158\" class=\"content_image\" width=\"384\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;384&#39; height=&#39;158&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"384\" data-rawheight=\"158\" class=\"content_image lazy\" width=\"384\" data-actualsrc=\"https://pic3.zhimg.com/v2-09ac982d4f1b845271b85baa62d2a56e_b.jpg\"/></figure><blockquote><b>7 Nadam法</b></blockquote><p>Nag加上Adam，就成了Nadam方法，即带有动量项的Adam，所以形式也很简单，如下，可以将其分别与Adam算法和NAG算法的式子比较看看。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-88b536deaa0d0340a34daf7fb5ceb872_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"858\" data-rawheight=\"194\" class=\"origin_image zh-lightbox-thumb\" width=\"858\" data-original=\"https://pic3.zhimg.com/v2-88b536deaa0d0340a34daf7fb5ceb872_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;858&#39; height=&#39;194&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"858\" data-rawheight=\"194\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"858\" data-original=\"https://pic3.zhimg.com/v2-88b536deaa0d0340a34daf7fb5ceb872_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-88b536deaa0d0340a34daf7fb5ceb872_b.jpg\"/></figure><blockquote><b>8 AMSgrad方法</b></blockquote><p>ICLR 2018最佳论文提出了AMSgrad方法，研究人员观察到Adam类的方法之所以会不能收敛到好的结果，是因为在优化算法中广泛使用的指数衰减方法会使得梯度的记忆时间太短。</p><p>在深度学习中，每一个mini-batch对结果的优化贡献是不一样的，有的产生的梯度特别有效，但是也一视同仁地被时间所遗忘。</p><p>具体的做法是使用过去平方梯度的最大值来更新参数，而不是指数平均。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-0c09e09a0db73810fb07f5225d69941e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"918\" data-rawheight=\"328\" class=\"origin_image zh-lightbox-thumb\" width=\"918\" data-original=\"https://pic3.zhimg.com/v2-0c09e09a0db73810fb07f5225d69941e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;918&#39; height=&#39;328&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"918\" data-rawheight=\"328\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"918\" data-original=\"https://pic3.zhimg.com/v2-0c09e09a0db73810fb07f5225d69941e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-0c09e09a0db73810fb07f5225d69941e_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><blockquote><b>9 Adafactor方法</b></blockquote><p>Adam算法有两个参数，beta1和beta2，相关研究表明beta2的值对收敛结果有影响，如果较低，衰减太大容易不收敛，反之就容易收敛不稳定。Adafactor是通过给beta1和beta2本身也增加了一个衰减。 </p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-faecaecc6b5594b61b195dddb796c7d2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"354\" data-rawheight=\"166\" class=\"content_image\" width=\"354\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;354&#39; height=&#39;166&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"354\" data-rawheight=\"166\" class=\"content_image lazy\" width=\"354\" data-actualsrc=\"https://pic3.zhimg.com/v2-faecaecc6b5594b61b195dddb796c7d2_b.jpg\"/></figure><p>beta2的值刚开始是0，之后随着时间的增加而逼近预设值。</p><blockquote><b>10 Adabound方法</b></blockquote><p>上面说了，beta2的值造成Adam算法有可能不收敛或者不稳定而找不到全局最优解，落实到最后的优化参数那就是不稳定和异常(过大或者过小)的学习率。Adabound采用的解决问题的方式就非常的简单了，那就是限制最大和最小值范围，约束住学习率的大小。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-442ebe46eb66d71acb6bffc35f35c26b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"448\" data-rawheight=\"94\" class=\"origin_image zh-lightbox-thumb\" width=\"448\" data-original=\"https://pic4.zhimg.com/v2-442ebe46eb66d71acb6bffc35f35c26b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;448&#39; height=&#39;94&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"448\" data-rawheight=\"94\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"448\" data-original=\"https://pic4.zhimg.com/v2-442ebe46eb66d71acb6bffc35f35c26b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-442ebe46eb66d71acb6bffc35f35c26b_b.jpg\"/></figure><p>ηl(t)和ηu(t)分别是一个随着时间单调递增和递减的函数，最后两者收敛到同一个值。</p><p>说了这么多，对上面各种方法从一个鞍点开始优化，表现如何的预期效果图如下，参考文[1]。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"620\" data-rawheight=\"480\" data-thumbnail=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"620\" data-original=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;620&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"620\" data-rawheight=\"480\" data-thumbnail=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"620\" data-original=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_b.gif\"/></figure><p>理论上，就是上面这样的。文章作者会告诉你对于数据稀疏的问题，用自适应学习率算法就好了，而且使用人家推荐的参数就好。其中，Adam会最佳。</p><h2><b>4 总结</b></h2><blockquote><b>4.1 改进方法是否都比SGD算法强？</b></blockquote><p>上面说了这么多理论，分析起来头头是道，各种改进版本似乎各个碾压SGD算法。但是否真的如此。笔者曾经做过一个简单的实验，结果如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a091391c64d3786395b193f13ceefeee_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"769\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-a091391c64d3786395b193f13ceefeee_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;769&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"769\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-a091391c64d3786395b193f13ceefeee_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a091391c64d3786395b193f13ceefeee_b.jpg\"/></figure><p>所有方法都采用作者们的默认配置，并且进行了参数调优，不好的结果就不拿出来了。</p><ul><li>nesterov方法，与sgd算法同样的配置。</li><li>adam算法，m1=0.9，m2=0.999，lr=0.001。</li><li>rms算法，rms_decay=0.9，lr=0.001。</li><li>adagrad，adadelta学习率不敏感。</li></ul><p><b>看起来好像都不如SGD算法，实际上这是一个很普遍的现象，各类开源项目和论文[3-4]都能够印证这个结论。</b></p><p><b>总体上来说，改进方法降低了调参工作量，只要能够达到与精细调参的SGD相当的性能，就很有意义了，这也是Adam流行的原因。但是，改进策略带来的学习率和步长的不稳定还是有可能影响算法的性能，因此这也是一个研究的方向，不然哪来这么多Adam的变种呢。</b></p><blockquote><b>4.2 二阶方法研究的怎么样了呢？</b></blockquote><p>二阶的方法因为使用了导数的二阶信息，因此其优化方向更加准确，速度也更快，这是它的优势。</p><p>但是它的劣势也极其明显，使用二阶方法通常需要直接计算或者近似估计Hessian 矩阵，一阶方法一次迭代更新复杂度为O(N)，二阶方法就是O(N*N)，深层神经网络中变量实在是太多了，搞不动的。</p><p>不过，还是有研究者去研究的。比如东京工业大学和NVIDIA在[5]中使用的K-FAC方法，用1024块Tesla V100豪无人性地在10分钟内把ImageNet在35个epoch内训练到75%的top-1精度。K-FAC已经在CNN的训练中很常用了，感兴趣的可以去了解。</p><p>其他的二阶方法笔者也关注到了一些，以后等有了比较多稳定靠谱的研究，再来分享吧。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>[1] Ruder S. An overview of gradient descent optimization algorithms[J]. arXiv preprint arXiv:1609.04747, 2016.</p><p>[2] Reddi S J, Kale S, Kumar S. On the convergence of adam and beyond[J]. 2018.</p><p>[3] Bottou L, Curtis F E, Nocedal J. Optimization methods for large-scale machine learning[J]. Siam Review, 2018, 60(2): 223-311.</p><p>[4] Keskar N S, Socher R. Improving generalization performance by switching from adam to sgd[J]. arXiv preprint arXiv:1712.07628, 2017.</p><p>[5] Osawa K, Tsuji Y, Ueno Y, et al. Second-order Optimization Method for Large Mini-batch: Training ResNet-50 on ImageNet in 35 Epochs[J]. arXiv preprint arXiv:1811.12019, 2018.</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "最优化", 
                    "tagLink": "https://api.zhihu.com/topics/19616819"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": [
                {
                    "userName": "骆梁宸", 
                    "userLink": "https://www.zhihu.com/people/c0809289d5c531a966accaf034c96966", 
                    "content": "4.1 那个图具体是什么实验什么setting呀", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<p>可以先参考这篇文章<a href=\"http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030692%26idx%3D1%26sn%3D6322e8eec12d8a8b60f578a9ebb4b42c%26chksm%3D8712be59b065374f00dc9b3715e6453e2de5d05262ee4eac47ef5efe6d167703af67f5882029%26token%3D1791371720%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型训练】如何选择最适合你的学习率变更策略</a>，后面会补全</p>", 
                            "likes": 0, 
                            "replyToAuthor": "骆梁宸"
                        }, 
                        {
                            "userName": "骆梁宸", 
                            "userLink": "https://www.zhihu.com/people/c0809289d5c531a966accaf034c96966", 
                            "content": "<p>thx</p>", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "匿各用户", 
                    "userLink": "https://www.zhihu.com/people/d67ee185c975baea76cf8d401876f9d3", 
                    "content": "<p>这里有一个问题，一般而言，对于过参数化网络，参数总是收敛到初始化附近的点，但是显然不同策略得到不同的结果，但是这些结果对于单纯的误差而言几乎都是等价的，那么明显的loss landscape在这一点的locus是一个高维连续空间，我觉得考察这个空间的构造才是解决优化问题的核心，毕竟从概率上，随机初始化附近得到的解，对于参数空间而言成为整个参数空间真正的最优点的可能性是低的，考察这个空间的结构有助于理解解的分布。</p>", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "Starr Wang", 
                            "userLink": "https://www.zhihu.com/people/c8acf1992d344c1f3a9d79ca2671e619", 
                            "content": "<p>要用到微分流型那一套了吧？</p>", 
                            "likes": 0, 
                            "replyToAuthor": "匿各用户"
                        }, 
                        {
                            "userName": "匿各用户", 
                            "userLink": "https://www.zhihu.com/people/d67ee185c975baea76cf8d401876f9d3", 
                            "content": "<p>不一定，考察locus的结构，特别是非线性系统，很麻烦。物理里面考察线性的系统都非常困难，那里可以用矩阵做，这里有了非线性，而且有类似混沌的特征，很麻烦。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "Starr Wang"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/57609506", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 38, 
            "title": "【AI初识境】深度学习模型中的Normalization，你懂了多少？", 
            "content": "<p>这是《AI初识境》第6篇，这次我们说说Normalization。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>数据经过归一化和标准化后可以加快梯度下降的求解速度，这就是Batch Normalization等技术非常流行的原因，它使得可以使用更大的学习率更稳定地进行梯度传播，甚至增加网络的泛化能力。</p><p>今天就来说说和Batch Normalization相关的概念。</p><p>                                                                                                                          作者&amp;编辑  | 言有三</p><h2><br/><b>1 什么是归一化/标准化</b></h2><p>Normalization是一个统计学中的概念，我们可以叫它<b>归一化或者规范化</b>，它并不是一个完全定义好的数学操作(如加减乘除)。它通过将数据进行偏移和尺度缩放调整，在数据预处理时是非常常见的操作，在网络的中间层如今也很频繁的被使用。</p><p><b>1. 线性归一化</b></p><p>最简单来说，归一化是指将数据约束到固定的分布范围，比如8位图像的0～255像素值，比如0～1。</p><p>在数字图像处理领域有一个很常见的线性对比度拉伸操作：</p><p>X=(x-xmin)/(xmax-xmin)</p><p>它常常可以实现下面的增强对比度的效果。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6fcffc5dc883e4f6295907f3273bcb81_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"765\" class=\"origin_image zh-lightbox-thumb\" width=\"1024\" data-original=\"https://pic2.zhimg.com/v2-6fcffc5dc883e4f6295907f3273bcb81_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1024&#39; height=&#39;765&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"765\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1024\" data-original=\"https://pic2.zhimg.com/v2-6fcffc5dc883e4f6295907f3273bcb81_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6fcffc5dc883e4f6295907f3273bcb81_b.jpg\"/></figure><p><b>不过以上的归一化方法有个非常致命的缺陷，当X最大值或者最小值为孤立的极值点，会影响性能。</b></p><p><b>2. 零均值归一化/Z-score标准化</b></p><p>零均值归一化也是一个常见的归一化方法，被称为标准化方法，即每一变量值与其平均值之差除以该变量的标准差。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4c89956d0de6c023390964ae2196e408_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"238\" data-rawheight=\"120\" class=\"content_image\" width=\"238\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;238&#39; height=&#39;120&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"238\" data-rawheight=\"120\" class=\"content_image lazy\" width=\"238\" data-actualsrc=\"https://pic1.zhimg.com/v2-4c89956d0de6c023390964ae2196e408_b.jpg\"/></figure><p>经过处理后的数据符合均值为0，标准差为1的分布，<b>如果原始的分布是正态分布，那么z-score标准化就将原始的正态分布转换为标准正态分布</b>，机器学习中的很多问题都是基于正态分布的假设，这是更加常用的归一化方法。</p><p>以上两种方法都是线性变换，对输入向量X按比例压缩再进行平移，操作之后原始有量纲的变量变成无量纲的变量。不过它们不会改变分布本身的形状，下面以一个指数分布为例：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-430a0926985d0ba77cb6b5788df81355_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-430a0926985d0ba77cb6b5788df81355_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-430a0926985d0ba77cb6b5788df81355_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-430a0926985d0ba77cb6b5788df81355_b.jpg\"/></figure><p>如果要改变分布本身的形状，下面也介绍两种。</p><p><b>3.正态分布Box-Cox变换</b></p><p>box-cox变换可以将一个非正态分布转换为正态分布，使得分布具有对称性，变换公式如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-87b882d7a9c92667be524dc85d77a1bd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"404\" data-rawheight=\"196\" class=\"content_image\" width=\"404\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;404&#39; height=&#39;196&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"404\" data-rawheight=\"196\" class=\"content_image lazy\" width=\"404\" data-actualsrc=\"https://pic2.zhimg.com/v2-87b882d7a9c92667be524dc85d77a1bd_b.jpg\"/></figure><p>在这里lamda是一个基于数据求取的待定变换参数，Box-Cox的效果如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b4e766817fbb31fc7117a6de32814ce0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b4e766817fbb31fc7117a6de32814ce0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b4e766817fbb31fc7117a6de32814ce0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b4e766817fbb31fc7117a6de32814ce0_b.jpg\"/></figure><p><b>4. 直方图均衡化</b></p><p>直方图均衡也可以将某一个分布归一化到另一个分布，它通过图像的灰度值分布，即图像直方图来对图像进行对比度进调整，可以增强局部的对比度。</p><p>它的变换步骤如下：</p><p>(1)计算概率密度和累积概率密度。</p><p>(2)创建累积概率到灰度分布范围的单调线性映射T。</p><p>(3)根据T进行原始灰度值到新灰度值的映射。</p><p>直方图均衡化将任意的灰度范围映射到全局灰度范围之间，对于8位的图像就是(0,255)，它相对于直接线性拉伸，让分布更加均匀，对于增强相近灰度的对比度很有效，如下图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-cfabdc3f1e9d54ea10cd6e9ef3c9c44f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"561\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb\" width=\"561\" data-original=\"https://pic4.zhimg.com/v2-cfabdc3f1e9d54ea10cd6e9ef3c9c44f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;561&#39; height=&#39;420&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"561\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"561\" data-original=\"https://pic4.zhimg.com/v2-cfabdc3f1e9d54ea10cd6e9ef3c9c44f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-cfabdc3f1e9d54ea10cd6e9ef3c9c44f_b.jpg\"/></figure><p>综上，归一化数据的目标，是为了让数据的分布变得更加符合期望，增强数据的表达能力。</p><p><b>在深度学习中，因为网络的层数非常多，如果数据分布在某一层开始有明显的偏移，随着网络的加深这一问题会加剧(这在BN的文章中被称之为internal covariate shift)，进而导致模型优化的难度增加，甚至不能优化。所以，归一化就是要减缓这个问题。</b></p><h2><b>2 Batch Normalization</b></h2><ol><li><b>基本原理</b></li></ol><p>现在一般采用批梯度下降方法对深度学习进行优化，这种方法把数据分为若干组，按组来更新参数，一组中的数据共同决定了本次梯度的方向，下降时减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也下降了很多。</p><p>Batch Normalization(简称BN)中的batch就是批量数据，即每一次优化时的样本数目，通常BN网络层用在卷积层后，用于重新调整数据分布。假设神经网络某层一个batch的输入为X=[x1,x2,...,xn]，其中xi代表一个样本，n为batch size。</p><p>首先，我们需要求得mini-batch里元素的均值：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-96dbd384b2c89a94f424acd5d27ef98a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"256\" data-rawheight=\"150\" class=\"content_image\" width=\"256\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;256&#39; height=&#39;150&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"256\" data-rawheight=\"150\" class=\"content_image lazy\" width=\"256\" data-actualsrc=\"https://pic3.zhimg.com/v2-96dbd384b2c89a94f424acd5d27ef98a_b.jpg\"/></figure><p>接下来，求取mini-batch的方差：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2a91c4f6642d9204c38176e01a2db0dd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"392\" data-rawheight=\"148\" class=\"content_image\" width=\"392\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;392&#39; height=&#39;148&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"392\" data-rawheight=\"148\" class=\"content_image lazy\" width=\"392\" data-actualsrc=\"https://pic2.zhimg.com/v2-2a91c4f6642d9204c38176e01a2db0dd_b.jpg\"/></figure><p>这样我们就可以对每个元素进行归一化。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-12aaf988de09568adc175416e70ee7db_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"304\" data-rawheight=\"144\" class=\"content_image\" width=\"304\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;304&#39; height=&#39;144&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"304\" data-rawheight=\"144\" class=\"content_image lazy\" width=\"304\" data-actualsrc=\"https://pic4.zhimg.com/v2-12aaf988de09568adc175416e70ee7db_b.jpg\"/></figure><p>最后进行尺度缩放和偏移操作，这样可以变换回原始的分布，实现恒等变换，这样的目的是为了补偿网络的非线性表达能力，因为经过标准化之后，偏移量丢失。具体的表达如下，yi就是网络的最终输出。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5fd40f01da675c1d40063a95189e1cfc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"332\" data-rawheight=\"94\" class=\"content_image\" width=\"332\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;332&#39; height=&#39;94&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"332\" data-rawheight=\"94\" class=\"content_image lazy\" width=\"332\" data-actualsrc=\"https://pic1.zhimg.com/v2-5fd40f01da675c1d40063a95189e1cfc_b.jpg\"/></figure><p>假如gamma等于方差，beta等于均值，就实现了恒等变换。</p><p>从某种意义上来说，gamma和beta代表的其实是输入数据分布的方差和偏移。对于没有BN的网络，这两个值与前一层网络带来的非线性性质有关，而经过变换后，就跟前面一层无关，变成了当前层的一个学习参数，这更加有利于优化并且不会降低网络的能力。</p><p>对于CNN，BN的操作是在各个特征维度之间单独进行，也就是说各个通道是分别进行Batch Normalization操作的。</p><p>如果输出的blob大小为(N,C,H,W)，那么在每一层normalization就是基于<b>N*H*W个数值进行求平均以及方差的操作</b>，记住这里我们后面会进行比较。</p><p><b>2.BN带来的好处。</b></p><p>(1) 减轻了对参数初始化的依赖，这是利于调参的朋友们的。</p><p>(2) 训练更快，可以使用更高的学习率。</p><p>(3) BN一定程度上增加了泛化能力，dropout等技术可以去掉。</p><p><b>3.BN的缺陷</b></p><p>从上面可以看出，batch normalization依赖于batch的大小，当batch值很小时，计算的均值和方差不稳定。研究表明对于ResNet类模型在ImageNet数据集上，batch从16降低到8时开始有非常明显的性能下降，在训练过程中计算的均值和方差不准确，而在测试的时候使用的就是训练过程中保持下来的均值和方差。</p><p>这一个特性，导致batch normalization不适合以下的几种场景。</p><p>(1)batch非常小，比如训练资源有限无法应用较大的batch，也比如在线学习等使用单例进行模型参数更新的场景。</p><p>(2)rnn，因为它是一个动态的网络结构，同一个batch中训练实例有长有短，导致每一个时间步长必须维持各自的统计量，这使得BN并不能正确的使用。在rnn中，对bn进行改进也非常的困难。不过，困难并不意味着没人做，事实上现在仍然可以使用的，不过这超出了咱们初识境的学习范围。</p><p><b>4.BN的改进</b></p><p>针对BN依赖于batch的这个问题，BN的作者亲自现身提供了改进，即在原来的基础上增加了一个仿射变换。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-82cc24a6e3c15367c99072b327e2c241_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"430\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb\" width=\"430\" data-original=\"https://pic2.zhimg.com/v2-82cc24a6e3c15367c99072b327e2c241_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;430&#39; height=&#39;150&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"430\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"430\" data-original=\"https://pic2.zhimg.com/v2-82cc24a6e3c15367c99072b327e2c241_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-82cc24a6e3c15367c99072b327e2c241_b.jpg\"/></figure><p>其中参数r，d就是仿射变换参数，它们本身是通过如下的方式进行计算的</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-3d1887d906c259e5c20bcf2f2033ae67_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"340\" data-rawheight=\"102\" class=\"content_image\" width=\"340\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;340&#39; height=&#39;102&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"340\" data-rawheight=\"102\" class=\"content_image lazy\" width=\"340\" data-actualsrc=\"https://pic4.zhimg.com/v2-3d1887d906c259e5c20bcf2f2033ae67_b.jpg\"/></figure><p>其中参数都是通过滑动平均的方法进行更新</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1dbb58c3416884a34ca04d37d4ed60c8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"328\" data-rawheight=\"120\" class=\"content_image\" width=\"328\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;328&#39; height=&#39;120&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"328\" data-rawheight=\"120\" class=\"content_image lazy\" width=\"328\" data-actualsrc=\"https://pic1.zhimg.com/v2-1dbb58c3416884a34ca04d37d4ed60c8_b.jpg\"/></figure><p>所以r和d就是一个跟样本有关的参数，通过这样的变换来进行学习，这两个参数在训练的时候并不参与训练。</p><p>在实际使用的时候，先使用BN进行训练得到一个相对稳定的移动平均，网络迭代的后期再使用刚才的方法，称为Batch Renormalization，当然r和d的大小必须进行限制。</p><h2><b>3 Batch Normalization的变种</b></h2><p>Normalization思想非常简单，为深层网络的训练做出了很大贡献。因为有依赖于样本数目的缺陷，所以也被研究人员盯上进行改进。说的比较多的就是<b>Layer Normalization与Instance Normalization，Group Normalization了。</b></p><p>前面说了Batch Normalization各个通道之间是独立进行计算，如果抛弃对batch的依赖，也就是每一个样本都单独进行normalization，同时各个通道都要用到，就得到了<b>Layer Normalization</b>。</p><p>跟Batch Normalization仅针对单个神经元不同，Layer Normalization考虑了神经网络中一层的神经元。如果输出的blob大小为(N,C,H,W)，那么在每一层Layer Normalization就是基于<b>C*H*W个数值进行求平均以及方差的操作</b>。</p><p>Layer Normalization把每一层的特征通道一起用于归一化，如果每一个特征层单独进行归一化呢？也就是限制在某一个特征通道内，那就是<b>instance normalization了</b>。</p><p>如果输出的blob大小为(N,C,H,W)，那么在每一层Instance Normalization就是基于<b>H*W个数值进行求平均以及方差的操作</b>。对于风格化类的图像应用，Instance Normalization通常能取得更好的结果，它的使用本来就是风格迁移应用中提出。</p><p><b>Group Normalization</b>是Layer Normalization和Instance Normalization 的中间体， Group Normalization将channel方向分group，然后对每个Group内做归一化，算其均值与方差。</p><p>如果输出的blob大小为(N,C,H,W)，将通道C分为G个组，那么Group  Normalization就是基于<b>G*H*W个数值进行求平均以及方差的操作</b>。我只想说，你们真会玩，要榨干所有可能性。</p><p>在Batch Normalization之外，有人提出了通用版本<b>Generalized Batch Normalization</b>，有人提出了硬件更加友好的<b>L1-Norm Batch Normalization</b>等，不再一一讲述。</p><p>另一方面，以上的Batch Normalization，Layer Normalization，Instance Normalization都是将规范化应用于输入数据x，Weight normalization则是对权重进行规范化，感兴趣的可以自行了解，使用比较少，也不在我们的讨论范围。</p><p>这么多的Normalization怎么使用呢？有一些基本的建议吧，不一定是正确答案。</p><p>(1) 正常的处理图片的CNN模型都应该使用Batch Normalization。只要保证batch size较大(不低于32)，并且打乱了输入样本的顺序。如果batch太小，则优先用Group Normalization替代。</p><p>(2)对于RNN等时序模型，有时候同一个batch内部的训练实例长度不一(不同长度的句子)，则不同的时态下需要保存不同的统计量，无法正确使用BN层，只能使用Layer Normalization。</p><p>(3) 对于图像生成以及风格迁移类应用，使用Instance Normalization更加合适。</p><h2><b>4 Batch Normalization的思考</b></h2><p>最后是关于Batch Normalization的思考，应该说，normalization机制至今仍然是一个非常open的问题，相关的理论研究一直都有，大家最关心的是Batch Normalization怎么就有效了。</p><p>之所以只说Batch Normalization，是因为上面的这些方法的差异主要在于计算normalization的元素集合不同。Batch Normalization是N*H*W，Layer Normalization是C*H*W，Instance Normalization是H*W，Group Normalization是G*H*W。</p><p>关于Normalization的有效性，有以下几个主要观点：</p><p>(1) 主流观点，Batch Normalization调整了数据的分布，不考虑激活函数，它让每一层的输出归一化到了均值为0方差为1的分布，这保证了梯度的有效性，目前大部分资料都这样解释，比如BN的原始论文认为的缓解了Internal Covariate Shift(ICS)问题。</p><p>(2) 可以使用更大的学习率，文[2]指出BN有效是因为用上BN层之后可以使用更大的学习率，从而跳出不好的局部极值，增强泛化能力，在它们的研究中做了大量的实验来验证。</p><p>(3) 损失平面平滑。文[3]的研究提出，BN有效的根本原因不在于调整了分布，因为即使是在BN层后模拟ICS，也仍然可以取得好的结果。它们指出，BN有效的根本原因是平滑了损失平面。之前我们说过，Z-score标准化对于包括孤立点的分布可以进行更平滑的调整。</p><p>算了，让大佬先上吧。</p><p>[1] Ioffe S, Szegedy C. Batch normalization: Accelerating deep network training by reducing internal covariate shift[J]. arXiv preprint arXiv:1502.03167, 2015.</p><p>[2] Bjorck N, Gomes C P, Selman B, et al. Understanding batch normalization[C]//Advances in Neural Information Processing Systems. 2018: 7705-7716.</p><p>[3] Santurkar S, Tsipras D, Ilyas A, et al. How does batch normalization help optimization?[C]//Advances in Neural Information Processing Systems. 2018: 2488-2498.</p><p>BN层技术的出现确实让网络学习起来更加简单了，降低了调参的工作量，不过它本身的作用机制还在被广泛研究中。几乎就像是深度学习中没有open问题的一个缩影，BN到底为何，还无定论，如果你有兴趣和时间，不妨也去踩一坑。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }
            ], 
            "comments": [
                {
                    "userName": "王凡", 
                    "userLink": "https://www.zhihu.com/people/fd77ada118f283dd816a62a415678ed5", 
                    "content": "关于bn的结论没有证明，太武断，不如直接看文章", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "正是如此，所以请参考文末", 
                            "likes": 0, 
                            "replyToAuthor": "王凡"
                        }
                    ]
                }, 
                {
                    "userName": "匿各用户", 
                    "userLink": "https://www.zhihu.com/people/d67ee185c975baea76cf8d401876f9d3", 
                    "content": "<p>BN实际是对解空间加了约束，这个约束一方面是降低了参数空间的体积，一方面定义了最终的网络配置特征是满足一个好的解（平滑的低复杂度的）的条件的，所以使得收敛和泛化能力同时得到提高。但是要说替代dropout我是不同意的，因为尽管他们有重合的地方，但是dropout更多是面向鲁棒性，虽然BN定义的解的确具有好的鲁棒性，但是不能完全替代dropout的约束。</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "bluestyle", 
                    "userLink": "https://www.zhihu.com/people/6573fe0148f32cd9cb9a4314202d3dae", 
                    "content": "线性归一话公式打错了，xmin打成了mxin", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "好的，多谢", 
                            "likes": 0, 
                            "replyToAuthor": "bluestyle"
                        }
                    ]
                }, 
                {
                    "userName": "反正不是白痴", 
                    "userLink": "https://www.zhihu.com/people/4598605965f440db6a895b9f0a873b18", 
                    "content": "零均值归一化会不会破坏数据原本的结构（分布的特性）？毕竟除了标准差", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/57454669", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 23, 
            "title": "【AI初识境】什么是深度学习成功的开始？参数初始化（xavier，he等）", 
            "content": "<p>这是《AI初识境》第5篇，这次我们说说初始化。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>神经网络要优化一个非常复杂的非线性模型，而且基本没有全局最优解，初始化在其中扮演着非常重要的作用，尤其在没有BN等技术的早期，它直接影响模型能否收敛。</p><p>可以说万事开头难，没有好的初始化的深度学习模型训练起来更难。</p><p>                                                                                                                           作者&amp;编辑  | 言有三</p><h2><b>01 初始化的重要性</b></h2><p>2006年Hinton等人在science期刊上发表了论文“Reducing the dimensionality of data with neural networks”，揭开了新的训练深层神经网络算法的序幕。</p><p>利用无监督的RBM网络来进行预训练，进行图像的降维，取得比PCA更好的结果，通常这被认为是<b>深度学习兴起的开篇</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c78308031a3a18690a409148f67c7117_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"908\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c78308031a3a18690a409148f67c7117_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;908&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"908\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-c78308031a3a18690a409148f67c7117_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c78308031a3a18690a409148f67c7117_b.jpg\"/></figure><p><b>这么看来，是因为好的初始化方法的出现，才有了深层神经网络工程化落地的可能性。</b></p><p>好的初始化应该满足以下两个条件：</p><p>(1) 让神经元各层激活值不会出现饱和现象；</p><p>(2) 各层激活值也不能为0。</p><p><b>也就是激活值不要太大，也不要太小，应该刚刚好，当然这还只是最基本的要求。</b></p><p>我们都知道在早期，sigmoid激活函数是多层感知器模型的标配，上面这篇文章同样也是用sigmoid激活函数，没有那么多问题，是因为使用了预训练。</p><p>如果不使用预训练会如何？在Xavier Glorot和Yoshua Bengio提出xavier初始化方法的论文【1】中就对不同的激活函数使用不同的数据集做过实验。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7366cbc910dea439376f1c85692fdbbe_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-7366cbc910dea439376f1c85692fdbbe_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;372&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-7366cbc910dea439376f1c85692fdbbe_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-7366cbc910dea439376f1c85692fdbbe_b.jpg\"/></figure><p>上面是一个四层的神经网络在sigmoid函数激活下的训练过程，可以看到最深的layer4层刚开始的时候很快就进入了饱和区域(激活值很低)，其他几层则比较平稳，在训练的后期才能进行正常的更新。</p><p>为什么会这样呢？网络中有两类参数需要学习，一个是权重，一个是偏置。对于上面的结果作者们提出了一个假设，就是在网络的学习过程中，偏置项总是学的更快，网络真正的输出就是直接由layer4决定的，输出就是softmax(b+Wh)。既然偏置项学的快，那Wh就没有这么重要了，所以激活值可以低一点。</p><p>解释虽然比较牵强，但是毕竟实验结果摆在那里，从tanh函数的激活值来看会更直观。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1627c694b9e753588fe228fcee03a6e0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"431\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-1627c694b9e753588fe228fcee03a6e0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;431&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"431\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-1627c694b9e753588fe228fcee03a6e0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-1627c694b9e753588fe228fcee03a6e0_b.jpg\"/></figure><p>这个图有个特点是，0，1和-1的值都不少，而中间段的就比较少。在0值，逼近线性函数，它不能为网络的非线性能力作出贡献。对于1，-1，则是饱和区，没有用。</p><h2><b>02 常用的初始化方法</b></h2><p><b>1、全零初始化和随机初始化</b></p><p>如果神经元的权重被初始化为0， 在第一次更新的时候，除了输出之外，所有的中间层的节点的值都为零。一般神经网络拥有对称的结构，那么在进行第一次误差反向传播时，更新后的网络参数将会相同，在下一次更新时，相同的网络参数学习提取不到有用的特征，因此深度学习模型都不会使用0初始化所有参数。</p><p>而随机初始化就是搞一些很小的值进行初始化，实验表明大了就容易饱和，小的就激活不动，再说了这个没技术含量，不必再讨论。</p><p><b>2.标准初始化</b></p><p>对于均匀分布，X～U(a,b)，概率密度函数等于：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-bd473fc260936fa41f6a016e84f977fa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"442\" data-rawheight=\"146\" class=\"origin_image zh-lightbox-thumb\" width=\"442\" data-original=\"https://pic3.zhimg.com/v2-bd473fc260936fa41f6a016e84f977fa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;442&#39; height=&#39;146&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"442\" data-rawheight=\"146\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"442\" data-original=\"https://pic3.zhimg.com/v2-bd473fc260936fa41f6a016e84f977fa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-bd473fc260936fa41f6a016e84f977fa_b.jpg\"/></figure><p>它的期望等于0，方差等于(b-a)^2/12，如果b=1，a=-1，就是1/3。</p><p>下面我们首先计算一下，输出输入以及权重的方差关系公式：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-876c71e9030ae8e4611fe4edc5869437_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"343\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-876c71e9030ae8e4611fe4edc5869437_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;343&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"343\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-876c71e9030ae8e4611fe4edc5869437_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-876c71e9030ae8e4611fe4edc5869437_b.jpg\"/></figure><p>如果我们希望每一层的激活值是稳定的，w就应该用n的平方根进行归一化，n为每个神经元的输入数量。</p><p>所以标准的初始化方法其权重参数就是以下分布：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3a9e3b1dfc60d7168097fc158e54f87a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"546\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb\" width=\"546\" data-original=\"https://pic3.zhimg.com/v2-3a9e3b1dfc60d7168097fc158e54f87a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;546&#39; height=&#39;142&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"546\" data-rawheight=\"142\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"546\" data-original=\"https://pic3.zhimg.com/v2-3a9e3b1dfc60d7168097fc158e54f87a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-3a9e3b1dfc60d7168097fc158e54f87a_b.jpg\"/></figure><p>它保证了参数均值为0，方差为常量1/3，和网络的层数无关。<br/></p><p><b>3.Xavier初始化</b></p><p>首先有一个共识必须先提出：神经网络如果保持每层的信息流动是同一方差，那么会更加有利于优化。不然大家也不会去争先恐后地研究各种normalization方法。</p><p>不过，Xavier Glorot认为还不够，应该增强这个条件，好的初始化应该使得<b>各层的激活值和梯度的方差在传播过程中保持一致，这个被称为Glorot条件。</b></p><p>如果反向传播每层梯度保持近似的方差，则信息能反馈到各层。而前向传播激活值方差近似相等，有利于平稳地学习。</p><p>当然为了做到这一点，对激活函数也必须作出一些约定。</p><p>(1) 激活函数是线性的，至少在0点附近，而且导数为1。</p><p>(2) 激活值关于0对称。</p><p>这两个都不适用于sigmoid函数和ReLU函数，而适合tanh函数。</p><p>要满足上面的两个条件，就是下面的式子。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e96945f37133fadafc6bbd1bdb6837e8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"394\" data-rawheight=\"156\" class=\"content_image\" width=\"394\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;394&#39; height=&#39;156&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"394\" data-rawheight=\"156\" class=\"content_image lazy\" width=\"394\" data-actualsrc=\"https://pic1.zhimg.com/v2-e96945f37133fadafc6bbd1bdb6837e8_b.jpg\"/></figure><p>推导可以参考前面标准初始化的方法，这里的ni，ni+1分别就是输入和输出的神经元个数了，因为输入输出不相等，作为一种权衡，文中就建议使用输入和输出的均值来代替。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-992ef2e2967609778bba722505a85bbf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"502\" data-rawheight=\"116\" class=\"origin_image zh-lightbox-thumb\" width=\"502\" data-original=\"https://pic4.zhimg.com/v2-992ef2e2967609778bba722505a85bbf_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;502&#39; height=&#39;116&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"502\" data-rawheight=\"116\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"502\" data-original=\"https://pic4.zhimg.com/v2-992ef2e2967609778bba722505a85bbf_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-992ef2e2967609778bba722505a85bbf_b.jpg\"/></figure><p>再带入前面的均匀分布的方差(b-a)^2/12，就得到了对于tanh函数的xavier初始化方法。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-b71b108715380750e7d8428c07ccd68b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"766\" data-rawheight=\"120\" class=\"origin_image zh-lightbox-thumb\" width=\"766\" data-original=\"https://pic4.zhimg.com/v2-b71b108715380750e7d8428c07ccd68b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;766&#39; height=&#39;120&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"766\" data-rawheight=\"120\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"766\" data-original=\"https://pic4.zhimg.com/v2-b71b108715380750e7d8428c07ccd68b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-b71b108715380750e7d8428c07ccd68b_b.jpg\"/></figure><p>下面这两个图分别是标准初始化和xavier初始化带来的各层的反传梯度方差，可以看出xavier确实保持了一致性。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ede86f286bffd9c75a8360de82691376_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"852\" data-rawheight=\"644\" class=\"origin_image zh-lightbox-thumb\" width=\"852\" data-original=\"https://pic3.zhimg.com/v2-ede86f286bffd9c75a8360de82691376_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;852&#39; height=&#39;644&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"852\" data-rawheight=\"644\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"852\" data-original=\"https://pic3.zhimg.com/v2-ede86f286bffd9c75a8360de82691376_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ede86f286bffd9c75a8360de82691376_b.jpg\"/></figure><p><b>4.He初始化</b></p><p>Xavier初始化虽然美妙，但它是针对tanh函数设计的，而激活函数现在是ReLU的天下，ReLU只有一半的激活，另一半是不激活的，所以前面的计算输入输出的方差的式子多了一个1/2，如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-6b9d70ca8f21f3c9ea2e84b70752c7ac_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"804\" data-rawheight=\"202\" class=\"origin_image zh-lightbox-thumb\" width=\"804\" data-original=\"https://pic1.zhimg.com/v2-6b9d70ca8f21f3c9ea2e84b70752c7ac_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;804&#39; height=&#39;202&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"804\" data-rawheight=\"202\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"804\" data-original=\"https://pic1.zhimg.com/v2-6b9d70ca8f21f3c9ea2e84b70752c7ac_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-6b9d70ca8f21f3c9ea2e84b70752c7ac_b.jpg\"/></figure><p>因为这一次没有使用均匀初始化，而是使用了正态分布，所以对下面这个式子：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5fc1aa3a0d89855ffd40f47d37e1c064_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"598\" data-rawheight=\"178\" class=\"origin_image zh-lightbox-thumb\" width=\"598\" data-original=\"https://pic1.zhimg.com/v2-5fc1aa3a0d89855ffd40f47d37e1c064_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;598&#39; height=&#39;178&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"598\" data-rawheight=\"178\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"598\" data-original=\"https://pic1.zhimg.com/v2-5fc1aa3a0d89855ffd40f47d37e1c064_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5fc1aa3a0d89855ffd40f47d37e1c064_b.jpg\"/></figure><p>需要的就是这样的正态分布。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a7badca296d1566a5b8c4862db162e89_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"228\" data-rawheight=\"152\" class=\"content_image\" width=\"228\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;228&#39; height=&#39;152&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"228\" data-rawheight=\"152\" class=\"content_image lazy\" width=\"228\" data-actualsrc=\"https://pic2.zhimg.com/v2-a7badca296d1566a5b8c4862db162e89_b.jpg\"/></figure><p>综上，对于两大最经典的激活函数，各自有了对应的初始化方法。虽然后面还提出了一些其他的初始化方法，但是在我们这个系列中就不再详述了。</p><h2><b>03 关于初始化的一些思考</b></h2><p>初始化这个问题明显比较麻烦，不然大家也不会这么喜欢用<b>pretrained模型</b>了。</p><p>从前面我们可以看到，大家努力的方向有这么几个。</p><p><b>(1) 预训练啊。</b></p><p>机智地一比，甩锅给别人，😄。</p><p><b>(2) 从激活函数入手，让梯度流动起来不要进入饱和区，则什么初始化咱们都可以接受。</b></p><p>这其实就要回到上次我们说的激活函数了，ReLU系列的激活函数天生可以缓解这个问题，反过来，像何凯明等提出的方法，也是可以反哺激活函数ReLU。</p><p><b>(3) 归一化，让每一层的输入输出的分布比较一致，降低学习难度。</b></p><p>回想一下，这不就是BN干的活吗？所以才会有了BN之后，初始化方法不再需要小心翼翼地选择。假如不用BN，要解决这个问题有几个思路，我觉得分为两派。</p><p>首先<b>是理论派</b>，就是咱们从理论上分析出设计一个怎么样的函数是最合适的。</p><p>对于Sigmoid等函数，xavier设计出了xavier初始化方法，对于ReLU函数，何凯明设计了he初始化方法。</p><p>在此之上，有研究者分别针对零点平滑的激活函数和零点不平滑的激活函数提出了统一的框架，见文【2】，比如对于sigmoid，tanh等函数，方差和导数的关系如此。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-46b40df06e957c75763ede7af7fe0e5a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"538\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb\" width=\"538\" data-original=\"https://pic3.zhimg.com/v2-46b40df06e957c75763ede7af7fe0e5a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;538&#39; height=&#39;150&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"538\" data-rawheight=\"150\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"538\" data-original=\"https://pic3.zhimg.com/v2-46b40df06e957c75763ede7af7fe0e5a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-46b40df06e957c75763ede7af7fe0e5a_b.jpg\"/></figure><p>然后是<b>实践派</b>，在训练的时候手动将权重归一化的，见文【3】，这就是向归一化方法靠拢了，下期咱们再讲。</p><p>好的初始化方法就是赢在起跑线，不过现在的初始化方法也不是对什么数据集都有效，毕竟不同数据集的分布不同，咱们以后再谈。</p><p><u><i>下期预告：论深度学习中的归一化</i></u></p><p>[1] Glorot X, Bengio Y. Understanding the difficulty of training deep feedforward neural networks[C]//Proceedings of the thirteenth international conference on artificial intelligence and statistics. 2010: 249-256.</p><p>[2] Kumar S K. On weight initialization in deep neural networks[J]. arXiv preprint arXiv:1704.08863, 2017.</p><p>[3] Mishkin D, Matas J. All you need is a good init[J]. arXiv preprint arXiv:1511.06422, 2015.</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "最优化", 
                    "tagLink": "https://api.zhihu.com/topics/19616819"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/57258642", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 22, 
            "title": "【AI初识境】激活函数：从人工设计(sigmoid,relu)到自动搜索(swish)", 
            "content": "<p>这是专栏《AI初识境》的第4篇文章。所谓初识，就是对相关技术有基本了解，掌握了基本的使用方法。</p><p>在神经网络中，有一个看似不起眼但是非常重要的概念，那就是激活函数。激活函数模型固然理解起来简单，但是也经历了从人工设计到自动探索的长足发展历程。</p><p>                                                                                                                          作者&amp;编辑  | 言有三</p><h2><b>01 无处不在的激活函数</b></h2><p>我们都知道人工神经网络是用于模拟神经元的，那么提起激活函数，自然是要从那里去挖掘原因。</p><p>在正说深度学习中的激活函数之前，我想说<b>其实激活函数无处不在</b>。</p><p>(1) 上班需要激活函数。早上10点上班，你8点到也好，9点到也好都一样，但是10点零1分到不行，性质就变了，考勤系统留下迟到的记录，全勤奖再无希望。</p><p>它的激活函数应该是这样的，x是打卡时间。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-689e459147629645ec3fb4374fd866ea_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"338\" data-rawheight=\"124\" class=\"content_image\" width=\"338\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;338&#39; height=&#39;124&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"338\" data-rawheight=\"124\" class=\"content_image lazy\" width=\"338\" data-actualsrc=\"https://pic3.zhimg.com/v2-689e459147629645ec3fb4374fd866ea_b.jpg\"/></figure><p>这是一个阶跃函数，类似于如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-f42909e7bede5b06049c77706415dfed_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-f42909e7bede5b06049c77706415dfed_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;540&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-f42909e7bede5b06049c77706415dfed_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-f42909e7bede5b06049c77706415dfed_b.jpg\"/></figure><p>(2) 最近看上了一个跳槽过来的喜欢吃甜品的女同事，不过听说有男朋友，不过又听说好像正在慢慢闹分手。</p><p>那么如果要追这个女同事，什么时候送甜品能带来友情的升华？假如预判她和对象第t天后拜拜。</p><p>它的激活函数可能是这样的，x是送甜品的日子。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f2f9b75230813531d9f33c14e7bb461c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"314\" data-rawheight=\"130\" class=\"content_image\" width=\"314\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;314&#39; height=&#39;130&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"314\" data-rawheight=\"130\" class=\"content_image lazy\" width=\"314\" data-actualsrc=\"https://pic1.zhimg.com/v2-f2f9b75230813531d9f33c14e7bb461c_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-07854c90c94d932400e3cb452e0d13e9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-07854c90c94d932400e3cb452e0d13e9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;540&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-07854c90c94d932400e3cb452e0d13e9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-07854c90c94d932400e3cb452e0d13e9_b.jpg\"/></figure><p>在刚分手的时候(也就是第t天，对应曲线斜率最大的地方)送甜品带来的好感激增度是最高的，再往后虽然随着相互之间越来越熟友谊持续升温，但是增长率下降了啊。而且到后来可能被其他人追走了，这个函数还只在一定期限内有效。</p><p>(3) 最近项目要加班，不过好在加班费是按小时(可以有分数)算的，那么当天的工资，就应该是这样算的。它的激活函数可能是这样的，x是工作时长。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-07328b5dcae050853f3f404786906904_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"548\" data-rawheight=\"126\" class=\"origin_image zh-lightbox-thumb\" width=\"548\" data-original=\"https://pic1.zhimg.com/v2-07328b5dcae050853f3f404786906904_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;548&#39; height=&#39;126&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"548\" data-rawheight=\"126\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"548\" data-original=\"https://pic1.zhimg.com/v2-07328b5dcae050853f3f404786906904_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-07328b5dcae050853f3f404786906904_b.jpg\"/></figure><p>形状长这样，超过一个阈值后是线性增加的，低于阈值则是常量。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a2dab5be2bf58d115152b0d5d7a1ff5a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-a2dab5be2bf58d115152b0d5d7a1ff5a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;540&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-a2dab5be2bf58d115152b0d5d7a1ff5a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a2dab5be2bf58d115152b0d5d7a1ff5a_b.jpg\"/></figure><p>(4) 不是单身狗？OK你是有老婆的人，那么下班回家陪老婆看电视总需要吧。不过到底陪不陪看，是不是陪就一定能得到老婆大人喜欢，这个可能是个周期性质的东西。</p><p>假如x是当天日历，那么激活函数可能是这样。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e855e971430c5101d28c47afac54906c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"192\" data-rawheight=\"74\" class=\"content_image\" width=\"192\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;192&#39; height=&#39;74&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"192\" data-rawheight=\"74\" class=\"content_image lazy\" width=\"192\" data-actualsrc=\"https://pic1.zhimg.com/v2-e855e971430c5101d28c47afac54906c_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-749a23df1ae9f8b58a53fc8c503fe0a2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-749a23df1ae9f8b58a53fc8c503fe0a2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;540&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-749a23df1ae9f8b58a53fc8c503fe0a2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-749a23df1ae9f8b58a53fc8c503fe0a2_b.jpg\"/></figure><p>这么想想，是不是感觉激活函数无处不在，上面的这几种都是有正儿八经对应的激活函数的。</p><p><b>回转正题，之所以需要激活函数，从生物学上来说，是因为人脑的细胞接受刺激从而产生活动，首先需要一定的阈值，没有达到阈值，几乎没用。而不同的刺激产生的输出也是不同的，达到一定值后就饱和了，再加大也没用。</b></p><p><b>作为模拟人脑的人工神经网络，自然是需要某种机制来模拟这一种活动，这便是激活函数根本性的由来。</b></p><h2><b>02 激活函数到底有什么用</b></h2><p>一个复杂的神经网络，是有许多层的，其中最基本的单位便是神经元。</p><p>一个线性神经元，输入x输出y的变换关系如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-99ba453c27a61a6bc7e4f430d70edb41_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"262\" data-rawheight=\"124\" class=\"content_image\" width=\"262\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;262&#39; height=&#39;124&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"262\" data-rawheight=\"124\" class=\"content_image lazy\" width=\"262\" data-actualsrc=\"https://pic2.zhimg.com/v2-99ba453c27a61a6bc7e4f430d70edb41_b.jpg\"/></figure><p>可以看到输出y与x是一个线性关系。如果再增加一层，把y作为中间层，输出为z呢？</p><p>如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-cb46bb5c78854be150e0d0566f7d7936_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"290\" data-rawheight=\"110\" class=\"content_image\" width=\"290\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;290&#39; height=&#39;110&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"290\" data-rawheight=\"110\" class=\"content_image lazy\" width=\"290\" data-actualsrc=\"https://pic3.zhimg.com/v2-cb46bb5c78854be150e0d0566f7d7936_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-e6c77062da897d9b64c2af80197a2efa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"116\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-e6c77062da897d9b64c2af80197a2efa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;116&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"116\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-e6c77062da897d9b64c2af80197a2efa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-e6c77062da897d9b64c2af80197a2efa_b.jpg\"/></figure><p>可以看出，最终的输出z仍然与x是线性关系，也就是说这样堆叠下去，永远都是线性关系。</p><p>人们期望神经网络可以模拟任意的函数，怎么可能用一个线性函数来完成呢？所以才会在线性神经元的输出后添加非线性的函数，添加的越多，变换自然就越复杂了。</p><p>而不同的非线性映射函数的选择，就是激活函数的研究课题了。</p><h2><b>03 各种激活函数</b></h2><p><a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Activation_function\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">en.wikipedia.org/wiki/A</span><span class=\"invisible\">ctivation_function</span><span class=\"ellipsis\"></span></a></p><p>关于激活函数的种类，有三这一次就偷个懒，大家可以去wiki 百科上面看，非常的详细，下面摘录其中的一些。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d095e383b41a74b1f195decf5135b38f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1210\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-d095e383b41a74b1f195decf5135b38f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1210&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1210\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-d095e383b41a74b1f195decf5135b38f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-d095e383b41a74b1f195decf5135b38f_b.jpg\"/></figure><p>这些人工设计的激活函数有这么多，那么什么激活函数最好，是ReLU吗？还是各类ReLU的变种(LReLU，PReLU，RReLU，ELU，SELU，GELU等等)，Maxout，又或者是某大神自己在搞的很复杂的激活函数，这是没有答案的，只能说有一些通用的大家认可的结论，下面也只能覆盖到一些。</p><p><b>(1) sigmoid和tanh激活函数。</b></p><p>为什么最早的时候大家用sigmoid函数呢？因为它不管输入处于多大的范围，输出是处于0～1的，机器学习里要解决的问题很多都是概率，用sigmoid不是很自然吗？</p><p>就算它有所谓的饱和问题导致梯度很小，那也是在函数的尾部才会发生，或者是在多级连乘之后才明显。所以很早期的比较浅的神经网络，用sigmoid没毛病，现在在LSTM这一类需要计算开关概率的网络中，sigmoid仍然是很常见的。</p><p>那tanh函数又如何呢？它相比sigmoid来说，将输出映射到(-1,1)之间了，拓展了一倍的值域。激活有负值之后，网络的表达能力可以得到提升，但未必一定需要这么做的，因为权重本身是可以为负的，而在最早期的神经网络中，用模拟信号处理问题，甚至连权重都没有非负的，一样有效。不过一般来说tanh总不至于比sigmoid差的，它毕竟通过零点，输出期望不会漂移。</p><p><b>(2)ReLU激活函数。</b></p><p>好处是很明显的。首先它简单，这个简单不仅在于导数恒定，更在于它将低于一定阈值的信号丢弃了。深度学习要解决的是工程问题，工程问题很多时候都是稀疏性的，往往简单的解决方案是最有效和稳定的。不过ReLU输出没有负数的问题确实有一定负作用，这也是其他方法对ReLU的改进空间所在。</p><p><b>(3)ReLU的一大堆变种(LReLU，PReLU，RReLU，ELU，SELU，GELU等等)。</b></p><p>我相信这些变种是有用的，但是我没怎么用过。不用因为是首先它们还没有表现出一定比ReLU强，在如今有BN等技术以及好的初始化方法后，ReLU的缺点没有那么明显了。另一方面是，没时间去一个一个试，解决问题的过程中还有很多其他因素更加需要去探索。不过，还是建议大家去仔细了解一下的，用不用的着再说。</p><p>正因如此，在对ReLU改进的差不多之后，激活函数的人工设计就没有这么多热情了。</p><h2><b>04 自动搜索</b></h2><p>不过坑还没有填完，还是有人没有忘记这个问题的，比如谷歌。谷歌开了许多深度学习领域的自动化的工作，比如自动设计网络NASNet，自动数据增强AutoAugment等工作，也做了自动搜索最优的激活函数的工作。</p><p>文[1]就在一系列<b>一元函数和二元函数组成的搜索空间</b>中，进行了比较细致的组合搜索实验。</p><p>结论是好用的激活函数都比较简单，不会超过两个基本函数的乘的组合。搜到了一些比Relu表现更好的函数，最好的是一个这样的函数：x · σ(βx)，被称为Swish，它在某个特定的参数下也和ReLU及其变种类似，看看图就知道了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-661da961f17045aea3fedb0279dfdd63_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"850\" data-rawheight=\"632\" class=\"origin_image zh-lightbox-thumb\" width=\"850\" data-original=\"https://pic4.zhimg.com/v2-661da961f17045aea3fedb0279dfdd63_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;850&#39; height=&#39;632&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"850\" data-rawheight=\"632\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"850\" data-original=\"https://pic4.zhimg.com/v2-661da961f17045aea3fedb0279dfdd63_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-661da961f17045aea3fedb0279dfdd63_b.jpg\"/></figure><p>顺便说一下该方法做实验时的一元函数和二元函数的搜索空间：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-15aa800553426d66aa369cfea4fc0581_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-15aa800553426d66aa369cfea4fc0581_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;238&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-15aa800553426d66aa369cfea4fc0581_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-15aa800553426d66aa369cfea4fc0581_b.jpg\"/></figure><p>已经覆盖我们能想到的一些简单的函数了。</p><p>类似地也有其他的研究人员通过遗传算法学习到一些新的激活函数，包括<b>EliSH，HardEliSH[2]</b>，感兴趣的可以去看论文。</p><p>这个坑就挖给你了，还可以填。</p><p>[1] Ramachandran P, Zoph B, Le Q V. Searching for activation functions[J]. arXiv preprint arXiv:1710.05941, 2017.</p><p>[2] Basirat M , Roth P M . The Quest for the Golden Activation Function[J]. 2018.</p><p>[3] Nwankpa C , Ijomah W , Gachagan A , et al. Activation Functions: Comparison of trends in Practice and Research for Deep Learning[J]. 2018. </p><p>深度学习各个维度的理论正处于全面被研究中，如果你想有所建树，那么必须要深入思考以前那些看似习以为常的东西，激活函数就是一个例子。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3999&#39; height=&#39;2250&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3999\" data-rawheight=\"2250\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"3999\" data-original=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5cca297aa9a47760ed51196be67b9d49_b.jpg\"/></figure><blockquote>AI白身境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030781%26idx%3D1%26sn%3D8425674df68425e622f114d043239c2b%26chksm%3D8712be00b0653716ca9c97057d9c6e393d471d6160b28c783cb6e001bae55c09ac69a2adec62%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习从弃用windows开始</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030809%26idx%3D1%26sn%3D512513678a99218392260d3d5763e09a%26chksm%3D8712bee4b06537f2253b469fda709698f90e23bf91387ceea4af313766125ea4b9119c015c58%26token%3D1400726199%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】Linux干活三板斧，shell、vim和git</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030876%26idx%3D1%26sn%3D75710e10e1503c9c6bab16cc83b73ef0%26chksm%3D8712bea1b06537b7977c67676122f544c9a3d09abe77362556403252c173c5bca0bee10f7351%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学AI必备的python基础</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030907%26idx%3D1%26sn%3D79f1123869a14254e31b21f57961b524%26chksm%3D8712be86b06537907c5664f1244f6bca2ce6e9f6a2593440c57dfff646038cf46fe3afd0d49b%26token%3D739981443%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习必备图像基础</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030969%26idx%3D1%26sn%3Dec1cabf9fa52ece790f8a5ab19f2458b%26chksm%3D8712bf44b06536524b97130198905b1fdda03c4432f4e136f665a1a3b93bd9f806eeaedef155%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】搞计算机视觉必备的OpenCV入门基础</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031006%26idx%3D1%26sn%3Dc2bbb57e95ccf651eec22fe378160095%26chksm%3D8712bf23b0653635fb1a932aa33dea5a5f6d75e4767cdbebd4b8809b108c8b2f4339b215f8ea%26token%3D667764862%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】只会用Python？g++，CMake和Makefile了解一下</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031056%26idx%3D1%26sn%3D6f8f5a6e7bc236e928f3a5d4211b4f84%26chksm%3D8712bfedb06536fbd94ee4322cc35b3377ddf39a2abdc073d5001f1766fdb52d09f83a08c357%26token%3D1377716633%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】学深度学习你不得不知的爬虫基础</a></p><p>第八期： <a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031147%26idx%3D1%26sn%3D99491d39e880c68597c2a29a307652d6%26chksm%3D8712bf96b0653680a41817c899a49ad351b6f375e78e25871422cc4c068831cce0fc7820c88b%26token%3D795591801%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】深度学习中的数据可视化</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D1%26sn%3D4f31ef67460c371ccc93296d21993771%26chksm%3D8712bc72b065356461668bca8b1e14ba1e6d953b7be83878a2f983fecb541b4b3be8c3e51ebf%26token%3D1281762331%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】入行AI需要什么数学基础：左手矩阵论，右手微积分</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031231%26idx%3D1%26sn%3D8371deedfe05be36f8d727aa6737b59f%26chksm%3D8712bc42b0653554ce727cfb3339ae735ca2945605d412f622cde7372c1181b89219cdfdf772%26token%3D1392937622%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】一文览尽计算机视觉研究方向</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031322%26idx%3D1%26sn%3Db933534e39e22e4dff2d60716db612e8%26chksm%3D8712bce7b06535f14beb2b50c06a363aee7f91abf13f22f795b3a1de4582ab8fde63ba6deb52%26token%3D580500824%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">第十一期：【AI白身境】AI+，都加在哪些应用领域了</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D1%26sn%3Dac22f4d25c91657055db93a27415f433%26chksm%3D8712bcc6b06535d0150ea2082fad7465632d31b5fc130151377f5cb91f30e647886756ee70d4%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI白身境】究竟谁是paper之王，全球前10的计算机科学家</a></p><blockquote>AI初识境系列完整阅读</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031475%26idx%3D1%26sn%3D381e5ff44a9d724134d167aaab93393e%26chksm%3D8712bd4eb06534584d0f9dfe9840ca0a9afba5890c6935c63f2886b3a29adec0bc8ccef2ef6a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从3次人工智能潮起潮落说起</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031503%26idx%3D1%26sn%3D52124c89fd52d197db4e3f089bceec3a%26chksm%3D8712bd32b0653424acdbdb1515ec009741bfe1a189eb44690cf71017ff0def71520534a4e5b3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】从头理解神经网络-内行与外行的分水岭</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031524%26idx%3D1%26sn%3D564750aea2c3c7cc03b6532852d1efe3%26chksm%3D8712bd19b065340f9fd87034bca58ec77a27ec75ef50accbcc807061135ddeff6ef34bdd55e0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】近20年深度学习在图像领域的重要进展节点</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031541%26idx%3D1%26sn%3Db1fac1a1bce8cb27727ffea2b77b1689%26chksm%3D8712bd08b065341e0b4078dbd994f864dbd274571668968961881efb4a52ed0822c32a4742ba%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】激活函数：从人工设计到自动搜索</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031561%26idx%3D1%26sn%3D8de2f0e398c1df0bdaebda99138dc22b%26chksm%3D8712bdf4b06534e2979cca8558f2817d4547676a768f3fc895dd578afda941999e48efd3cafb%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】什么是深度学习成功的开始？参数初始化</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031599%26idx%3D1%26sn%3Df06df4fe57024e7652ac6f6062253b32%26chksm%3D8712bdd2b06534c456f046d76f5f71696f294de6ce0f84736e0cea173eaa970c0a2d0015d72b%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型中的Normalization，你懂了多少？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031658%26idx%3D1%26sn%3Dfd1b54b24b607a9d28dc4e83ecc480fb%26chksm%3D8712bd97b065348132d8261907c56ce14077646dfc9c7531a4c3f1ecf6da1a488450428e4580%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】为了围剿SGD大家这些年想过的那十几招</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031740%26idx%3D1%26sn%3D2766cf718daf57a9c7f1556885cf35e9%26chksm%3D8712ba41b065335751aa0a50b6bbb1d6e230ed2f3d9a72914f1eb178ba0c2ecd9f77068fc0c0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】被Hinton，DeepMind和斯坦福嫌弃的池化，到底是什么？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031822%26idx%3D1%26sn%3D2f5c0485ce54f9e1347bec48ee638072%26chksm%3D8712baf3b06533e5d89b949c3b5232665f428842f6712449785b20ba5dbc73ebf2a0f3f481e3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】如何增加深度学习模型的泛化能力</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031923%26idx%3D1%26sn%3Dbcc3cef468f44d0a6de5b87ea00e5e5b%26chksm%3D8712ba8eb065339829ee84e7398e23d85dd7c4c7c154b96caead73c8815f887bb3c1bb7de063%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习模型评估，从图像分类到生成模型</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032086%26idx%3D1%26sn%3Dfad93a8867bcc1c5b8e6b8db0260fe24%26chksm%3D8712bbebb06532fd8a1cd02df87db32ea17f07011405a00da844b160f88792b0581030e26565%26token%3D598159941%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】深度学习中常用的损失函数有哪些？</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032137%26idx%3D1%26sn%3D486dd16dec9a1df9b25aee23765e3f67%26chksm%3D8712bbb4b06532a21b8068e80c94be95b2148e3009abe816146ffc532a96a5aecd8e1dd9fcb0%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI初识境】给深度学习新手开始项目时的10条建议</a></p><blockquote>AI不惑境系列完整阅读：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032394%26idx%3D1%26sn%3D1e5b111d5ab05942d25af85836901bbd%26chksm%3D8712b8b7b06531a1e388ae741720386d1004193c2145b4b633a875b08d37f7eb810a33bae831%26token%3D1720669728%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】数据压榨有多狠，人工智能就有多成功</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649032714%26idx%3D1%26sn%3D12c2e66a8de5e9e5a3d6667382f1bafa%26chksm%3D8712b677b0653f612dd0d11a297e32e5900581f3b8964a7278bd30d4bac039b027d1d16cad9f%26token%3D1268963984%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【AI不惑境】网络深度对深度学习模型性能有什么影响？</a></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "激活函数", 
                    "tagLink": "https://api.zhihu.com/topics/20682949"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "igloo", 
                    "userLink": "https://www.zhihu.com/people/7e9df4b0bdd36939f62144dd6c9bd4c1", 
                    "content": "这个swish看起来好奇怪啊。为什么会有local minimum？", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/56094906", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 215, 
            "title": "【完结】总结12大CNN主流模型架构设计思想", 
            "content": "<p>专栏《CNN模型解读》正式完结了，在这一个专栏中，我们给大家回顾了深度学习中的各类具有代表性的CNN模型，详细分析了各类模型的特点，设计思想。当然，这一个系列不可能包含所有的模型，但是我们可以从中洞见最核心的思想。如果有必要，以后我们还会进行补充的。</p><p>                                                                                                                                     作者 | 言有三<br/>                                                                                                                                     编辑 | 言有三</p><h2><b>1 从LeNet5到VGG</b></h2><p><b>LeNet5</b>不是CNN的起点，但却是它的hello world，让大家看到了卷积神经网络商用的前景。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-64d34ee58628919255fa99900b245a9c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"311\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-64d34ee58628919255fa99900b245a9c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;311&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"311\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-64d34ee58628919255fa99900b245a9c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-64d34ee58628919255fa99900b245a9c_b.jpg\"/></figure><p><b>AlexNet</b>是CNN向大规模商用打响的第一枪，夺得ImageNet 2012年分类冠军，宣告神经网络的王者归来。<b>VGG</b>以其简单的结构，在提出的若干年内在各大计算机视觉领域都成为了最广泛使用的benchmark。<br/></p><p>它们都有着简单而又优雅的结构，同出一门。诠释了增加深度是如何提高了深度学习模型的性能。详细解读如下：</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a><br/></p><h2><b>2 1*1卷积</b></h2><p><b>1*1</b>卷积本身只是N*N卷积的卷积核大小退化为1时的特例，但是由于它以较小的计算代价增强了网络的非线性表达能力，给网络结构在横向和纵向拓展提供了非常好的工具，常用于升维和降维操作，尤其是在深层网络和对计算效率有较高要求的网络中广泛使用。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-640b4ffddd0159e929be4b1afb5b5f4b_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"517\" data-thumbnail=\"https://pic4.zhimg.com/v2-640b4ffddd0159e929be4b1afb5b5f4b_b.jpg\" class=\"content_image\" width=\"400\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;400&#39; height=&#39;517&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"517\" data-thumbnail=\"https://pic4.zhimg.com/v2-640b4ffddd0159e929be4b1afb5b5f4b_b.jpg\" class=\"content_image lazy\" width=\"400\" data-actualsrc=\"https://pic4.zhimg.com/v2-640b4ffddd0159e929be4b1afb5b5f4b_b.gif\"/></figure><p>详细解读如下：</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a><br/></p><h2><b>3 GoogLeNet</b></h2><p>GoogLeNet夺得ImageNet2014年分类冠军，也被称为<b>Inception V1</b>。Inception V1有22层深，参数量为5M。同一时期的VGGNet性能和Inception V1差不多，但是参数量却远大于Inception V1。Inception的优良特性得益于Inception Module，结构如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6a24288c0b6009f50cf7ffa7eb8af281_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"876\" data-rawheight=\"422\" class=\"origin_image zh-lightbox-thumb\" width=\"876\" data-original=\"https://pic2.zhimg.com/v2-6a24288c0b6009f50cf7ffa7eb8af281_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;876&#39; height=&#39;422&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"876\" data-rawheight=\"422\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"876\" data-original=\"https://pic2.zhimg.com/v2-6a24288c0b6009f50cf7ffa7eb8af281_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6a24288c0b6009f50cf7ffa7eb8af281_b.jpg\"/></figure><p>由1*1卷积，3*3卷积，5*5卷积，3*3最大池化四个并行通道运算结果进行融合，提取图像不同尺度的信息。详细解读如下：</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a><br/></p><h2><b>4 MobileNets</b></h2><p>脱胎于<b>Xception</b>的网络结构MobileNets使用<b>Depthwise Separable Convolution</b>(深度可分离卷积)构建了轻量级的28层神经网络，成为了移动端上的高性能优秀基准模型。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d949356ac18e366af81f4139c90e1526_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"998\" data-rawheight=\"750\" class=\"origin_image zh-lightbox-thumb\" width=\"998\" data-original=\"https://pic3.zhimg.com/v2-d949356ac18e366af81f4139c90e1526_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;998&#39; height=&#39;750&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"998\" data-rawheight=\"750\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"998\" data-original=\"https://pic3.zhimg.com/v2-d949356ac18e366af81f4139c90e1526_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d949356ac18e366af81f4139c90e1526_b.jpg\"/></figure><p>一个depthwise convolution，专注于该通道内的空间信息，一个pointwise convolution，专注于跨通道的信息融合，两者共同努力，然后强大，在此基础上的一系列模型如shufflenet等都是后话。详细解读如下：</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a><br/></p><h2><b>5 残差网络</b></h2><p>当深层网络陷身于梯度消失等问题而导致不能很有效地训练更深的网络时，脱胎于<b>highway network</b>的残差网络应运而生，附带着MSRA和何凯明的学术光环，诠释了因为简单，所以有效，但你未必能想到和做到的朴素的道理。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bc88ce9d1f45720932dc4db9f5b03608_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"977\" data-rawheight=\"561\" class=\"origin_image zh-lightbox-thumb\" width=\"977\" data-original=\"https://pic1.zhimg.com/v2-bc88ce9d1f45720932dc4db9f5b03608_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;977&#39; height=&#39;561&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"977\" data-rawheight=\"561\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"977\" data-original=\"https://pic1.zhimg.com/v2-bc88ce9d1f45720932dc4db9f5b03608_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-bc88ce9d1f45720932dc4db9f5b03608_b.jpg\"/></figure><p>详细解读如下：</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a><br/></p><h2><b>6 非正常卷积</b></h2><p>谁说卷积一定要规规矩矩四四方方呢？MSRA总是一个出新点子的地方，在spatial transform network和active convolution的铺垫下，可变形卷积<b>deformable convolution network</b>如期而至。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-28207230d8f5d05476645a93a0f32ff3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1020\" data-rawheight=\"724\" class=\"origin_image zh-lightbox-thumb\" width=\"1020\" data-original=\"https://pic4.zhimg.com/v2-28207230d8f5d05476645a93a0f32ff3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1020&#39; height=&#39;724&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1020\" data-rawheight=\"724\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1020\" data-original=\"https://pic4.zhimg.com/v2-28207230d8f5d05476645a93a0f32ff3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-28207230d8f5d05476645a93a0f32ff3_b.jpg\"/></figure><p>文章依旧写的很简单，这是一个致力于提升CNN对具有不同几何形变物体识别能力的模型，关键在于可变的感受野。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a><br/></p><h2><b>7 密集连接网络</b></h2><p>说起来，<b>DenseNet</b>只不过是残差网络的升级版，将网络中的每一层都直接与其前面层相连，把残差做到了极致，提高了特征的利用率；因为可以把网络的每一层设计得很窄，提高计算性能。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-decdd9a0540fbad2ff7b8007e0746376_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"769\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-decdd9a0540fbad2ff7b8007e0746376_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;769&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"769\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-decdd9a0540fbad2ff7b8007e0746376_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-decdd9a0540fbad2ff7b8007e0746376_b.jpg\"/></figure><p>虽然还是那句话，就算你能想到，也未必能做到，我们还是单独详细解读如下：</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】全连接的卷积网络，有什么好？</a><br/></p><h2><b>8 非局部神经网络</b></h2><p>卷积神经网络因为局部连接和权重共享而成功，但是它的感受野是有限的。为了这样，我们不得不使用更深的网络，由此带来了三个问题。(1) 计算效率不高。(2) 感知效率不高。(3) 增加优化难度。这一次又是学神凯明带队出发，从传统降噪算法Non-Local中完成借鉴。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b67df953afe994628a2e4a5f8b625eb4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"689\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b67df953afe994628a2e4a5f8b625eb4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;689&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"689\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-b67df953afe994628a2e4a5f8b625eb4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b67df953afe994628a2e4a5f8b625eb4_b.jpg\"/></figure><p>虽非真主流，了解一下也无妨。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a><br/></p><h2><b>9 多输入网络</b></h2><p>见惯了输入一个图像或者视频序列，输出分类，分割，目标检测等结果的网络，是否会想起输入两张，或者多张图片来完成一些任务呢，这就是多输入网络结构。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f626ec00e0553dd900c5c08372f03773_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"517\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-f626ec00e0553dd900c5c08372f03773_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;517&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"517\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-f626ec00e0553dd900c5c08372f03773_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f626ec00e0553dd900c5c08372f03773_b.jpg\"/></figure><p>从检索，比对，到排序，跟踪，它可以做的事情有很多，你应该了解一下。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a><br/></p><h2><b>10 3D卷积</b></h2><p>2D卷积玩腻了，该跳到更加高维的卷积了，常见的也就是3D卷积了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"650\" data-thumbnail=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;650&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"650\" data-thumbnail=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_b.gif\"/></figure><p>虽然3D带来了暴涨的计算量，但是想想可以用于视频分类和分割，3D点云，想想也是有些小激动呢。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D2%26sn%3Da8adb80cc4270662a087334c63a982d1%26chksm%3D8712bc72b0653564d4c0c149d51643d2df245774f8a69bc61d2d792abdd9bb191d109ff80632%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从2D卷积到3D卷积，都有什么不一样</a><br/></p><h2><b>11 RNN和LSTM</b></h2><p>不是所有的输入都是一张图片，有很多的信息是非固定长度或者大小的，比如视频，语音，此时就轮到RNN，LSTM出场了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-876596294f0a5933bb7ff7b0ed65ad12_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"360\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-876596294f0a5933bb7ff7b0ed65ad12_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;360&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"360\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-876596294f0a5933bb7ff7b0ed65ad12_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-876596294f0a5933bb7ff7b0ed65ad12_b.jpg\"/></figure><p>话不多说，好好学：</p><p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D2%26sn%3D90755895232f413d1594fc43a43c4830%26chksm%3D8712bcc6b06535d0d7e0ad1d9625deb2c729cb7d5f4d4164a5ce1f1ffb7bfcad652a7b2a4bbf%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】浅析RNN到LSTM</a><br/></p><h2><b>12 GAN</b></h2><p>近几年来无监督学习领域甚至是深度学习领域里最大的进展非生成对抗网络GAN莫属，被誉为下一代深度学习，不管是研究热度还是论文数量，已经逼近甚至超越传统判别式的CNN架构。在研究者们的热情下，GAN已经从刚开始的一个生成器一个判别器发展到了多个生成器多个判别器等各种各样的结构。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7876af8591afba7209c84f4dffef9019_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"206\" class=\"origin_image zh-lightbox-thumb\" width=\"474\" data-original=\"https://pic2.zhimg.com/v2-7876af8591afba7209c84f4dffef9019_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;474&#39; height=&#39;206&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"206\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"474\" data-original=\"https://pic2.zhimg.com/v2-7876af8591afba7209c84f4dffef9019_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7876af8591afba7209c84f4dffef9019_b.jpg\"/></figure><p>快上车，因为真的快来不及了。</p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote>模型解读系列文章：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D2%26sn%3Da8adb80cc4270662a087334c63a982d1%26chksm%3D8712bc72b0653564d4c0c149d51643d2df245774f8a69bc61d2d792abdd9bb191d109ff80632%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从2D卷积到3D卷积，都有什么不一样</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D2%26sn%3D90755895232f413d1594fc43a43c4830%26chksm%3D8712bcc6b06535d0d7e0ad1d9625deb2c729cb7d5f4d4164a5ce1f1ffb7bfcad652a7b2a4bbf%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】浅析RNN到LSTM</a></p><p>第十三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031435%26idx%3D2%26sn%3D402ad26ffeac98d3a4710bef0e8adbfb%26chksm%3D8712bd76b0653460d4a5fd1176b87bf534085f85ae9494eb204725b3a5836588f3bf5158cc41%26token%3D1010392025%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】历数GAN的5大基本结构</a> </p><p></p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "生成对抗网络（GAN）", 
                    "tagLink": "https://api.zhihu.com/topics/20070859"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "诺侠", 
                    "userLink": "https://www.zhihu.com/people/a3c4779768fded50f0d81f8f053f0f63", 
                    "content": "<p>例行点赞。。。</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "哈哈哈", 
                            "likes": 0, 
                            "replyToAuthor": "诺侠"
                        }
                    ]
                }, 
                {
                    "userName": "淮漠", 
                    "userLink": "https://www.zhihu.com/people/6cd20b256664e87e371afbc1e8d35a8e", 
                    "content": "您好，我现在正在看专栏之前论述的GNN图卷积。想知道这个GAN和GNN什么关系，哪个是未来热点？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "两者没有任何关系噢", 
                            "likes": 0, 
                            "replyToAuthor": "淮漠"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/56076752", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 19, 
            "title": "【模型解读】历数GAN的5大基本结构", 
            "content": "<p>生成对抗网络是近几年来无监督学习领域里最大的进展，被誉为下一代深度学习，不管是研究热度还是论文数量，已经逼近甚至超越传统判别式的CNN架构。</p><p>这一次我们简单介绍一下生成对抗网络的主流模型结构，从一个生成器一个判别器到多个生成器多个判别器。</p><p>                                                                                                                                     作者 | 言有三<br/>                                                                                                                                     编辑 | 言有三</p><h2><b>01 单判别器单生成器</b></h2><p>我们这一期文章不打算从头开始讲述GAN，所以如果大家没有相关基础的，就先看一下我们上一期GAN的介绍。</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029396%26idx%3D1%26sn%3D2d92874e0b94dd2174d216ce1da4f1ce%26chksm%3D87134569b064cc7f5f2476fdc87df968b353c2eae24f6820a5af2ee983ca49be55d34588c19e%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg\" data-image-width=\"732\" data-image-height=\"462\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】有三说GANs（上）</a><p>一个基本的用于生成图像的GAN的结构就是这样的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7876af8591afba7209c84f4dffef9019_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"206\" class=\"origin_image zh-lightbox-thumb\" width=\"474\" data-original=\"https://pic2.zhimg.com/v2-7876af8591afba7209c84f4dffef9019_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;474&#39; height=&#39;206&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"206\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"474\" data-original=\"https://pic2.zhimg.com/v2-7876af8591afba7209c84f4dffef9019_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7876af8591afba7209c84f4dffef9019_b.jpg\"/></figure><p>Generator就是生成器，它输入噪声，输出产生的图像。通常噪声就是一个一维的向量，经过reshape为二维图像，然后利用若干个反卷积层来学习上采样。</p><p>如全卷积的DCGAN模型[1]，输入就是1*100的向量，然后经过一个全连接层学习，reshape到4*4*1024的张量，再经过4个上采样的反卷积网络，生成64*64的图。</p><p>Discrimator就是普通的CNN分类器，输入真实样本或者生成的假样本进行分类，在DCGAN中也是4个卷积层。</p><h2><b>02 多判别器单生成器</b></h2><p>采用多个判别器[2]的好处带来了类似于boosting的优势，训练一个过于好的判别器，会损坏生成器的性能，这是GAN面临的一个大难题。如果能够训练多个没有那么强的判别器，然后进行boosting，可以取得不错的效果，甚至连dropout技术都可以应用进来。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c074556ea6de9a92825594b8bac79d7d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"462\" data-rawheight=\"295\" class=\"origin_image zh-lightbox-thumb\" width=\"462\" data-original=\"https://pic2.zhimg.com/v2-c074556ea6de9a92825594b8bac79d7d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;462&#39; height=&#39;295&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"462\" data-rawheight=\"295\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"462\" data-original=\"https://pic2.zhimg.com/v2-c074556ea6de9a92825594b8bac79d7d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c074556ea6de9a92825594b8bac79d7d_b.jpg\"/></figure><p>多个判别器还可以相互进行分工，比如在图像分类中，一个进行粗粒度的分类，一个进行细粒度的分类。在语音任务中，各自用于不同声道的处理。</p><h2><b>03 单判别器多生成器</b></h2><p>一般来说，生成器相比判别器要完成的任务更难，因为它要完成数据概率密度的拟合，而判别器只需要进行判别，导致影响GAN性能的一个问题就是模式坍塌，即生成高度相似的样本。</p><p>采用多个生成器单个判别器的方法，可以有效地缓解这个问题。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-afe2bc28e5eef370ad7706e526ad6d5f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"506\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-afe2bc28e5eef370ad7706e526ad6d5f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;506&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"506\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-afe2bc28e5eef370ad7706e526ad6d5f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-afe2bc28e5eef370ad7706e526ad6d5f_b.jpg\"/></figure><p>从上图结构可以看出，多个生成器采用同样的结构，在网络的浅层还共享权重。</p><h2><b>04 增加分类器</b></h2><p>在利用GAN进行半监督的图像分类任务时，判别器需要同时担任两个角色，即判别生成的假样本，以及预测类别，这对判别器提出了较高的要求。通过增加一个分类器可以分担判别器的工作量，即将捕捉样本和标签的条件分布这一任务交给生成器和分类器，而判别器只专注于区分真实样本和生成的样本。</p><p>这一类结构以Triple Generative Adversarial Nets为代表，下图是它的网络结构。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-607f83bf70d07214dc0ea70bc13539e8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"412\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-607f83bf70d07214dc0ea70bc13539e8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;412&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"412\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-607f83bf70d07214dc0ea70bc13539e8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-607f83bf70d07214dc0ea70bc13539e8_b.jpg\"/></figure><h2><b>05 多个生成器多个判别器</b></h2><p>多个生成器和多个判别器就又有几种。</p><p><b>5.1 级联结构[5]</b></p><p>早期以DCGAN为代表的网络生成的图片分辨率太低，质量不够好，都不超过100×100，在32×32或者64×64左右。这是因为难以一次性学习到生成高分辨率的样本，收敛过程容易不稳定。</p><p>类似的问题在图像分割，目标检测中都存在。在目标检测中，级联网络被广泛使用，即采用从粗到精的方法依次改进检测器的性能。在图像分割中进行上采样时也采用学习小倍率的放大而不是大倍率的方法，如利用两个2倍上采样替换一个4倍的上采样，不仅可以增强网络的表达能力，还降低了学习难度。</p><p>基于此，金字塔GAN结构被提出并广泛使用，它参考图像领域里面的金字塔结构由粗到精一步一步生成图像，并添加残差进行学习。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-22a2cf287efb97ca459710749b44d0f1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"425\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-22a2cf287efb97ca459710749b44d0f1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;425&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"425\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-22a2cf287efb97ca459710749b44d0f1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-22a2cf287efb97ca459710749b44d0f1_b.jpg\"/></figure><p>上图就是它的结构，从低分辨率z3开始，逐级提升，最终生成I0，这是一个金字塔形状的结构，以下符号较多用图片代替。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-08e2f8c505c51c00025e36233857062b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"363\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-08e2f8c505c51c00025e36233857062b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;363&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"363\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-08e2f8c505c51c00025e36233857062b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-08e2f8c505c51c00025e36233857062b_b.jpg\"/></figure><p><b>5.2 并行与循环结构[6]</b></p><p>GAN有一大应用就是风格化，实现两个域之间的风格互换，以CycleGAN[6]为典型代表。它包含了多个生成器和多个判别器。Cycle的典型结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-39005682b78d5c336a39d2adc69d4a6d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"860\" data-rawheight=\"602\" class=\"origin_image zh-lightbox-thumb\" width=\"860\" data-original=\"https://pic2.zhimg.com/v2-39005682b78d5c336a39d2adc69d4a6d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;860&#39; height=&#39;602&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"860\" data-rawheight=\"602\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"860\" data-original=\"https://pic2.zhimg.com/v2-39005682b78d5c336a39d2adc69d4a6d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-39005682b78d5c336a39d2adc69d4a6d_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f7b6760003bd274c6304186fc0bf627e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"453\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f7b6760003bd274c6304186fc0bf627e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;453&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"453\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-f7b6760003bd274c6304186fc0bf627e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f7b6760003bd274c6304186fc0bf627e_b.jpg\"/></figure><p>X和Y分别表示两个域的图像，可知这里存在两个生成器G和F，分别用于从X到Y的生成和Y到X到生成，包含两个判别器，分别是Dx和Dy。而损失本身也增加了一个循环损失，感兴趣读者可以去细读文章。</p><p>另外在cross domain学习中也常用到多判别器多生成器多结构，分别学习不同的域。而且各个域的判别器和生成器通常会共享一些权重，如下图是CoGAN[7]的网络结构。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fcc0f005574f85f377cc8df9eed0b9aa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"304\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fcc0f005574f85f377cc8df9eed0b9aa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;304&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"304\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fcc0f005574f85f377cc8df9eed0b9aa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fcc0f005574f85f377cc8df9eed0b9aa_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>另外还有一些零零散散的结构，比如3D GAN，RNN GAN，由于都是上面这几类的变种，不再统一介绍。</p><p>[1] Radford A, Metz L, Chintala S, et al. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks[J]. international conference on learning representations, 2016.</p><p>[2] Durugkar I P, Gemp I, Mahadevan S, et al. Generative Multi-Adversarial Networks[J]. international conference on learning representations, 2017.</p><p>[3] Ghosh A, Kulharia V, Namboodiri V P, et al. Multi-Agent Diverse Generative Adversarial Networks[J]. computer vision and pattern recognition, 2018: 8513-8521.</p><p>[4] Chongxuan L I, Xu T, Zhu J, et al. Triple Generative Adversarial Nets[J]. neural information processing systems, 2017: 4088-4098.</p><p>[5] Denton E L, Chintala S, Szlam A, et al. Deep generative image models using a Laplacian pyramid of adversarial networks[J]. neural information processing systems, 2015: 1486-1494.</p><p>[6] Zhu J, Park T, Isola P, et al. Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks[J]. international conference on computer vision, 2017: 2242-2251.</p><p>[7] Liu M, Tuzel O. Coupled Generative Adversarial Networks[J]. neural information processing systems, 2016: 469-477. </p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote>模型解读系列文章：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D2%26sn%3Da8adb80cc4270662a087334c63a982d1%26chksm%3D8712bc72b0653564d4c0c149d51643d2df245774f8a69bc61d2d792abdd9bb191d109ff80632%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从2D卷积到3D卷积，都有什么不一样</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D2%26sn%3D90755895232f413d1594fc43a43c4830%26chksm%3D8712bcc6b06535d0d7e0ad1d9625deb2c729cb7d5f4d4164a5ce1f1ffb7bfcad652a7b2a4bbf%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】浅析RNN到LSTM</a></p><p>第十三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031435%26idx%3D2%26sn%3D402ad26ffeac98d3a4710bef0e8adbfb%26chksm%3D8712bd76b0653460d4a5fd1176b87bf534085f85ae9494eb204725b3a5836588f3bf5158cc41%26token%3D1010392025%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】历数GAN的5大基本结构</a> </p><p></p>", 
            "topic": [
                {
                    "tag": "生成对抗网络（GAN）", 
                    "tagLink": "https://api.zhihu.com/topics/20070859"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55949716", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 13, 
            "title": "【模型解读】浅析RNN到LSTM", 
            "content": "<p>卷积神经网络使用固定大小的矩阵作为输入（比如一张图片），然后输出一个固定大小的向量（比如不同分类的概率），适合于图像分类，目标检测，图像分割等。但是除了图像外，还有非常多的信息是非固定长度或者大小的，比如视频，语音，此时更加适合用来处理这些时序信号的网络就是一些时间序列模型。</p><p>常见的时间序列模型包括RNN，LSTM等，今天简单说一说</p><p>                                                                                                                                     作者 | 言有三</p><p>                                                                                                                                     编辑 | 言有三</p><h2><b>01 RNN</b></h2><p>我们通常所说的RNN实际上有两种，一种是Recurrent Neural Networks，即<b>循环神经网络</b>，一种是Recursive Neural Networks，即<b>递归神经网络</b>。</p><p>循环神经网络是首先被提出的，它是一种<b>时间上进行线性递归</b>的神经网络，也就是我们通常所说的RNN。</p><p>递归神经网络（recursive neural network）被视为循环神经网络（recurrent neural network）的推广，这是一种在<b>结构上进行递归</b>的神经网络，常用于自然语言处理中的序列学习，它的输入数据本质不一定是时序的，但结构却往往更加复杂，我们这里只说循环神经网络。</p><p>一个RNN的结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-876596294f0a5933bb7ff7b0ed65ad12_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"360\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-876596294f0a5933bb7ff7b0ed65ad12_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;360&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"360\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-876596294f0a5933bb7ff7b0ed65ad12_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-876596294f0a5933bb7ff7b0ed65ad12_b.jpg\"/></figure><p>左侧就是模型的基本结构，右侧就是它在时间上进行展开的示意图。xt是时刻t的输入，相应的ht，ot分别是对应时刻t的隐藏层和输出层。</p><p>上面我们可以看出，一个RNN的输入包括了两个：一个是<b>当前时刻输入xt，用于实时更新状态，另一个是上一时刻隐藏层的状态ht-1，用于记忆状态，而不同时刻的网络共用的是同一套参数。</b></p><p>RNN中常用的激活函数是tanh，所以上面的式子写成公式，就是：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-412a2de22934dfa5f1663f6da653733d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"472\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb\" width=\"472\" data-original=\"https://pic2.zhimg.com/v2-412a2de22934dfa5f1663f6da653733d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;472&#39; height=&#39;128&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"472\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"472\" data-original=\"https://pic2.zhimg.com/v2-412a2de22934dfa5f1663f6da653733d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-412a2de22934dfa5f1663f6da653733d_b.jpg\"/></figure><p>w就是要学习的权重，用几句代码表示RNN就是。</p><div class=\"highlight\"><pre><code class=\"language-text\">class RNN: \n   def step(self, x): \n      self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x)) #更新隐藏层\n      y = np.dot(self.W_hy, self.h) #得到输出\n   return y</code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><p>普通卷积神经网络的优化使用的是反向传播，那么RNN使用的是什么呢？最常见的还是反向传播，不过是带时序的版本，即<b>BPFT（backpropagation through time）</b>，它与BP的原理是完全一样的，只不过计算过程与时间有关。</p><p>与普通的反向传播算法一样，它重复地使用链式法则，区别在于损失函数不仅依赖于当前时刻的输出层，也依赖于下一时刻。所以参数W在更新梯度时，必须考虑当前时刻的梯度和下一时刻的梯度，传播示意图如下；</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-56e1fd0163ba62894ea9a3c605c00171_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"638\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-56e1fd0163ba62894ea9a3c605c00171_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;638&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"638\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-56e1fd0163ba62894ea9a3c605c00171_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-56e1fd0163ba62894ea9a3c605c00171_b.jpg\"/></figure><p>具体的公式我们就不编辑了，大家可以找书看，之所以有后续的LSTM等，就是因为RNN有大问题：因为t时刻的导数会传播到t-1，t-2，... ，1时刻，这样就有了连乘的系数。</p><p>连乘一直带来了两个问题：<b>梯度爆炸和消失</b>。而且，在前向过程中，开始时刻的输入对后面时刻的影响越来越小，这就是长距离依赖问题。这样一来，就失去了<b>“记忆”</b>的能力，要知道生物的神经元拥有对过去时序状态很强的记忆能力。</p><h2><b>02 LSTM</b></h2><p>前面说的RNN有两个问题，长短期记忆（Long short-term memory, LSTM）就是要解决这两个问题，通过引入若干门来解决，相比RNN多了一个<b>状态cell state</b>。</p><p>这个cell state承载着之前所有状态的信息，每到新的时刻，就有相应的操作来决定舍弃什么旧的信息以及添加什么新的信息。这个状态与隐藏层状态h不同，在更新过程中，它的更新是缓慢的，而隐藏层状态h的更新是迅速的。</p><p>LSTM的网络结构图如下，输入包括ht-1，xt，输出ht，状态为ct-1，ct。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b3db4ade55bc96d6a3ca3d630ded4c22_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"581\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-b3db4ade55bc96d6a3ca3d630ded4c22_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;581&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"581\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-b3db4ade55bc96d6a3ca3d630ded4c22_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b3db4ade55bc96d6a3ca3d630ded4c22_b.jpg\"/></figure><p><b>2.1  遗忘门与遗忘阶段</b></p><p>遗忘门决定了要从上一个状态中舍弃什么信息，它输入上一状态的输出ht-1、当前状态输入信息xt到一个Sigmoid函数中，产生一个介于0到1之间的数值，与上一个时刻的状态ct-1相乘之后来确定舍弃（保留）多少信息。0 表示“完全舍弃”，1 表示“完全保留”，这个阶段完成了对上一个节点cell state进行选择性忘记，遗忘门和它的输出公式如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-3016dcb099ae6c7cb660bce858255820_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"241\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-3016dcb099ae6c7cb660bce858255820_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;241&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"241\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-3016dcb099ae6c7cb660bce858255820_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-3016dcb099ae6c7cb660bce858255820_b.jpg\"/></figure><p><b>2.2 输入门与选择记忆阶段</b></p><p>选择记忆阶段，也就是对输入有选择性地进行“记忆”，重要的记录下来，不重要的少记一些，它决定了要往当前状态中保存什么新的信息。它输入上一状态的输出ht-1、当前输入信息xt到一个Sigmoid函数中，产生一个介于0到1之间的数值it来确定需要保留多少的新信息。</p><p>“候选新信息”则通过输入上一状态的输出、当前状态输入信息和一个tanh激活函数生成。有了遗忘门和输入门之后，就得到了完整的下一时刻的状态Ct，它将用于产生下一状态的隐藏层ht，也就是当前单元的输出。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-8510bce845a1729ca231fd0643bb054b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"942\" data-rawheight=\"102\" class=\"origin_image zh-lightbox-thumb\" width=\"942\" data-original=\"https://pic4.zhimg.com/v2-8510bce845a1729ca231fd0643bb054b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;942&#39; height=&#39;102&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"942\" data-rawheight=\"102\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"942\" data-original=\"https://pic4.zhimg.com/v2-8510bce845a1729ca231fd0643bb054b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-8510bce845a1729ca231fd0643bb054b_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5e5407926317261006d39a5f542c9dc0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"115\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5e5407926317261006d39a5f542c9dc0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;115&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"115\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5e5407926317261006d39a5f542c9dc0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5e5407926317261006d39a5f542c9dc0_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-56010fdccf71dfbfe1282b9158a03aeb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"992\" data-rawheight=\"114\" class=\"origin_image zh-lightbox-thumb\" width=\"992\" data-original=\"https://pic4.zhimg.com/v2-56010fdccf71dfbfe1282b9158a03aeb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;992&#39; height=&#39;114&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"992\" data-rawheight=\"114\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"992\" data-original=\"https://pic4.zhimg.com/v2-56010fdccf71dfbfe1282b9158a03aeb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-56010fdccf71dfbfe1282b9158a03aeb_b.jpg\"/></figure><p><b>2.3 输出门与输出阶段</b></p><p>输出门决定了要从cell state中输出什么信息。与之前类似，会先有一个Sigmoid函数产生一个介于0到1之间的数值Ot来确定我们需要输出多少cell state中的信息。cell state的信息在与Ot相乘时首先会经过一个tanh层进行“激活”，得到的就是这个LSTM block的输出信息ht。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-052c2805ad934666046063e3a01479e0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"682\" data-rawheight=\"140\" class=\"origin_image zh-lightbox-thumb\" width=\"682\" data-original=\"https://pic1.zhimg.com/v2-052c2805ad934666046063e3a01479e0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;682&#39; height=&#39;140&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"682\" data-rawheight=\"140\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"682\" data-original=\"https://pic1.zhimg.com/v2-052c2805ad934666046063e3a01479e0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-052c2805ad934666046063e3a01479e0_b.jpg\"/></figure><p>以上就是LSTM的基本原理，它通过门控状态来对信息进行选择性的记忆，满足了需要长时间记忆信息和遗忘信息的需求。</p><p>当然，随之而来的就是大量的参数，因此后续就有了GRU。另外，RNN和LSTM不止有单向的，还有双向的，这些就留给读者自己去学习了。</p><p>时序模型在语音，视频以及自然语言处理等领域有不可替代的作用，虽然相比普通的CNN，模型的复杂度和训练难度都增加了不少，但是在进阶之路上也是需要好好掌握的。</p><blockquote>模型解读系列文章：</blockquote><p>第一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p>第二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p>第三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p>第四期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p>第五期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p>第六期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p>第七期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p>第八期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p>第九期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p>第十期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>第十一期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031183%26idx%3D2%26sn%3Da8adb80cc4270662a087334c63a982d1%26chksm%3D8712bc72b0653564d4c0c149d51643d2df245774f8a69bc61d2d792abdd9bb191d109ff80632%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从2D卷积到3D卷积，都有什么不一样</a></p><p>第十二期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031355%26idx%3D2%26sn%3D90755895232f413d1594fc43a43c4830%26chksm%3D8712bcc6b06535d0d7e0ad1d9625deb2c729cb7d5f4d4164a5ce1f1ffb7bfcad652a7b2a4bbf%26token%3D677571606%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】浅析RNN到LSTM</a></p><p>第十三期：<a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031435%26idx%3D2%26sn%3D402ad26ffeac98d3a4710bef0e8adbfb%26chksm%3D8712bd76b0653460d4a5fd1176b87bf534085f85ae9494eb204725b3a5836588f3bf5158cc41%26token%3D1010392025%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】历数GAN的5大基本结构</a> </p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "LSTM", 
                    "tagLink": "https://api.zhihu.com/topics/20023220"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55567098", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 22, 
            "title": "【模型解读】从2D卷积到3D卷积，都有什么不一样", 
            "content": "<p>接着模型解读系列，在中国科幻作家刘慈欣的科幻小说《三体Ⅲ·死神永生》中，首次提出了降维打击这个概念，这是本质上区别于同一维度的攻击，破坏性也更大。</p><p>而现在我们要说的是从二维卷积升级到三维卷积，它相比2D卷积是否会有不一样呢？</p><p>                                                                                                                            作者&amp;编辑 | 言有三</p><h2><b>01 3D卷积</b></h2><p>首先看一下二维卷积，一个3*3的卷积核，在单通道图像上进行卷积，得到输出。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8a6695c2e086525ac5a61610348739b2_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"395\" data-rawheight=\"449\" data-thumbnail=\"https://pic3.zhimg.com/v2-8a6695c2e086525ac5a61610348739b2_b.jpg\" class=\"content_image\" width=\"395\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;395&#39; height=&#39;449&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"395\" data-rawheight=\"449\" data-thumbnail=\"https://pic3.zhimg.com/v2-8a6695c2e086525ac5a61610348739b2_b.jpg\" class=\"content_image lazy\" width=\"395\" data-actualsrc=\"https://pic3.zhimg.com/v2-8a6695c2e086525ac5a61610348739b2_b.gif\"/></figure><p>然后我们再看一下3维卷积，一个3*3*3的卷积核在立方体上进行卷积，得到输出。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"650\" data-thumbnail=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;650&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"650\" data-thumbnail=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-86e2bd970d07f9d6e1d921b248e45a3a_b.gif\"/></figure><p>就是这样，没什么其他花样了。</p><p>可能有人会问，这跟多通道卷积有什么区别呢？</p><p>有。</p><p>多通道卷积<b>不同的通道上的卷积核的参数是不同的</b>，而3D卷积则由于卷积核本身是3D的，所以这个由于“深度”造成的看似不同通道上用的就是同一个卷积，权重共享嘛。</p><p>总之，多了一个<b>深度通道</b>，这个深度可能是<b>视频上的连续帧</b>，也可能是<b>立体图像中的不同切片</b>。</p><h2><b>02 3D卷积的应用</b></h2><p>上面也说了，3D卷积就是多了一个深度通道，而这个深度通道可能是视频上的连续帧，也可能是立体图像中的不同切片，所以从应用上来说，主要就是两大主要方向。</p><p><b>2.1 视频分类</b></p><p>相比于2D图像，什么数据多了一个维度呢？当然就是视频了，视频的帧数，就是完美的另一个深度维度，将3D卷积用于视频的分类，再自然不过，关键就是看谁先来干。</p><p>据我所知，文【1】是最早的，看看他们使用的网络结构。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-490c7f5742da5ba31eb5259729d471c2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"356\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-490c7f5742da5ba31eb5259729d471c2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;356&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"356\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-490c7f5742da5ba31eb5259729d471c2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-490c7f5742da5ba31eb5259729d471c2_b.jpg\"/></figure><p>网络很浅，只有3个卷积层和1个全连接层，2个池化层，这样的网络规模和LeNet5可以称兄道弟了。不过3D多了一个维度，计算量自然是多了很多。</p><p>这里有两个3D卷积层，卷积核大小分别是7x7x3，7x6x3，前两维是空间的卷积，后一维是时间的卷积，看得出来，不需要保持一致，而且通常空间的卷积核大小和时间就不会一致，毕竟处理的“分辨率”不同。</p><p>这个网络结构在视频分类数据集UCF-101上的top-1精度为63.3%，别看这个指标不高，其他的比如LSTM，双流网络等也差不太多，而普通的2D卷积或者传统方法则要低于这个指标。</p><p>更细致的三维卷积在视频分类中应用的网络结构的探索在文【2】中，感兴趣读者可以自取。</p><p><b>2.2 图像分割</b></p><p>既然可以用于分类，自然也可以用于分割。不过对视频使用3D卷积似乎优势并不大，而在医学领域的应用前景更大一些。</p><p>医学数据通常都是3D的，比如CT扫描的数据，虽然我们看的片子是2D的，但其实那只是一个切片，真正的扫描数据是3D的。</p><p>而如果要分割出一些病变组织，比如肿瘤，也必须是3D的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a07d072e386750218c269c5639d3ad68_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-a07d072e386750218c269c5639d3ad68_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-a07d072e386750218c269c5639d3ad68_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a07d072e386750218c269c5639d3ad68_b.jpg\"/></figure><p>具体的网络结构就是将U-Net改为3D的形式。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ad9c4aac1bc33c7baee2dd53fa15c36b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"613\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-ad9c4aac1bc33c7baee2dd53fa15c36b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;613&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"613\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-ad9c4aac1bc33c7baee2dd53fa15c36b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ad9c4aac1bc33c7baee2dd53fa15c36b_b.jpg\"/></figure><p>就讲这么多，未完待续。</p><p>【1】Ji S, Xu W, Yang M, et al. 3D convolutional neural networks for human action recognition[J]. IEEE transactions on pattern analysis and machine intelligence, 2013, 35(1): 221-231.</p><p>【2】Tran D, Bourdev L, Fergus R, et al. Learning spatiotemporal features with 3d convolutional networks[C]//Proceedings of the IEEE international conference on computer vision. 2015: 4489-4497.</p><p>【3】Casamitjana A, Puch S, Aduriz A, et al. 3D Convolutional Neural Networks for Brain Tumor Segmentation: a comparison of multi-resolution architectures[C]//International Workshop on Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. Springer, Cham, 2016: 150-161.</p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "卷积", 
                    "tagLink": "https://api.zhihu.com/topics/19678959"
                }
            ], 
            "comments": [
                {
                    "userName": "George", 
                    "userLink": "https://www.zhihu.com/people/8b6c7ad5422c96c61083909daed4739c", 
                    "content": "<p>妙啊，，感觉有点东西</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "[耶]", 
                            "likes": 0, 
                            "replyToAuthor": "George"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>\"多通道卷积不同的通道上的卷积核的参数是不同的，而3D卷积则由于卷积核本身是3D的，所以这个由于“深度”造成的看似不同通道上用的就是同一个卷积\"</p><p>我觉得这句话好像没说清楚二者在参数上到底有何差别?</p><a class=\"comment_sticker\" href=\"https://pic2.zhimg.com/v2-5cc3f8dc72f94dc7e30391d104ec5319.gif\" data-width=\"\" data-height=\"\">[疑惑]</a>", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "刘锐", 
                            "userLink": "https://www.zhihu.com/people/44bbb1388f10615a44bb4b48d3bec749", 
                            "content": "对啊，感觉没说清楚，反而把读者搞糊涂了", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }, 
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "哈哈，那现在理解了吗", 
                            "likes": 0, 
                            "replyToAuthor": "刘锐"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/55254100", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 12, 
            "title": "【模型解读】siamese network和triplet network原理与应用", 
            "content": "<p>继续我们之前的专栏<b>《模型解读》</b>，今天说多输入网络，很久没写了因为实在是有更重要的事情。</p><p>平常我们所见的深度学习模型，都是输入一个图像或者视频序列，输出分类，分割，目标检测等结果，但是还有一种模型需要输入两张，或者多张图片，这就是多输入网络结构。</p><p>                                                                                                                                      作者 | 言有三<br/>                                                                                                                                      编辑 | 言有三</p><h2><b>1 多输入网络的应用背景</b></h2><p>首先我们说说在什么情况下，需要多个输入，只以纯图像应用为例。</p><p><b>1.1 图像验证与匹对</b></p><p>早在上个世纪90年代的时候，LeCun等研究人员就开始利用神经网络陆续进行一些研究，比如我们熟知的大名鼎鼎的LeNet5，但这绝不是唯一，今天我们来说他们的另一种网络结构，<b>Siamese Network</b>，网络细节我们后面这些，这里先说应用背景。</p><p><b>签名验证：</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-06cb9496169e75fb582b3b4aa0dbb0e7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"990\" data-rawheight=\"988\" class=\"origin_image zh-lightbox-thumb\" width=\"990\" data-original=\"https://pic4.zhimg.com/v2-06cb9496169e75fb582b3b4aa0dbb0e7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;990&#39; height=&#39;988&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"990\" data-rawheight=\"988\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"990\" data-original=\"https://pic4.zhimg.com/v2-06cb9496169e75fb582b3b4aa0dbb0e7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-06cb9496169e75fb582b3b4aa0dbb0e7_b.jpg\"/></figure><p>无独有偶，还是从手写字开始，同样是用于银行，用于验证签名是否一致。两个网络都是同样规格的图像输入，最后输出一个相似度。</p><p>看到这里，你应该能够想起来如今它的更加广泛的应用，没错，就是<b>人脸验证，或者说人脸识别</b>了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fa81598af1a6e6eb5fd47802c5e32496_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"815\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fa81598af1a6e6eb5fd47802c5e32496_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;815&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"815\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-fa81598af1a6e6eb5fd47802c5e32496_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fa81598af1a6e6eb5fd47802c5e32496_b.jpg\"/></figure><p>其实用的时候都不需要两个输入，因为可以建立一个离线数据集专门用于检索匹配。</p><p>而且，你可以在此基础上拓展出非常多的玩法，什么夫妻脸之类的。</p><p><b>1.2 目标跟踪</b></p><p>目标跟踪是一个什么过程？就是在<b>时序帧中搜索目标</b>的过程，本质上就是检索。</p><p>不管是传统的目标跟踪中的生成模型和判别模型，还是用深度学习来做目标跟踪，本质上都是来求取<b>目标区域与搜索区域的相似度</b>，这就是典型的多输入。</p><p>用深度学习来做，就是一个小图像和一个大图像分别输入网络，输出相似度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f626ec00e0553dd900c5c08372f03773_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"517\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-f626ec00e0553dd900c5c08372f03773_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;517&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"517\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-f626ec00e0553dd900c5c08372f03773_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f626ec00e0553dd900c5c08372f03773_b.jpg\"/></figure><p><b>1.3 排序</b></p><p>还有一类问题，可以用多输入网络来做，那就是排序。有的时候，我们很难估计一个人的实际年龄或者颜值，但是<b>估计相对年龄和颜值</b>就简单多了。</p><p>而且，在此之上，做些什么谁更可爱，谁更成熟之类的，可以想出无数花样，解释的通就行了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-347ba1cace157794f5fef947e71d5760_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"868\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-347ba1cace157794f5fef947e71d5760_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;868&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"868\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-347ba1cace157794f5fef947e71d5760_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-347ba1cace157794f5fef947e71d5760_b.jpg\"/></figure><h2>02 <b>多输入网络</b></h2><p>在这里，给大家介绍两个常见的网络，一个是siamese网络，一个是triplet网络。</p><p><b>2.1 siamese network                        </b></p><p>Siamese本意是“暹罗”人或“泰国”人，后在英语中指“孪生”、“连体”，这是一个外来词，来源于十九世纪泰国出生的一对连体婴儿，具体的故事我们就不说了，挺有看头，大家可以自己去了解。</p><p>顾名思义，有两个输入，两个网络，根据这两个网络是否共享权重，可以分为<b>真孪生网络siamese network和伪孪生网络pseudo-siamese network</b>。</p><p>真孪生网络siamese network的结构示意图如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-33ae7d3697827f1fd135bc24b0f1a905_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1072\" data-rawheight=\"922\" class=\"origin_image zh-lightbox-thumb\" width=\"1072\" data-original=\"https://pic2.zhimg.com/v2-33ae7d3697827f1fd135bc24b0f1a905_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1072&#39; height=&#39;922&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1072\" data-rawheight=\"922\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1072\" data-original=\"https://pic2.zhimg.com/v2-33ae7d3697827f1fd135bc24b0f1a905_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-33ae7d3697827f1fd135bc24b0f1a905_b.jpg\"/></figure><p>伪孪生网络pseudo-siamese network的结构示意图如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-62aa55eda686d71b540eeaed2237f838_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"986\" data-rawheight=\"932\" class=\"origin_image zh-lightbox-thumb\" width=\"986\" data-original=\"https://pic1.zhimg.com/v2-62aa55eda686d71b540eeaed2237f838_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;986&#39; height=&#39;932&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"986\" data-rawheight=\"932\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"986\" data-original=\"https://pic1.zhimg.com/v2-62aa55eda686d71b540eeaed2237f838_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-62aa55eda686d71b540eeaed2237f838_b.jpg\"/></figure><p>可以看出差别就<b>在于是否共享权重，loss的选择就多了</b>，相似度计算方法就多少，它的计算方法就有多少，交叉熵，欧式距离，余弦距离等都很常用。</p><p>那么是否需要共享权重呢？这就看研究的问题而定了，很明显不共享权重有更大的发挥空间，这个问题本文不展开讲。</p><p><b>2.2</b> <b>triplet network</b></p><p>如果将上面的二输入拓展为三输入怎么样？做人脸识别的同学想必不陌生。</p><p>没错，就是triplet network。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b853d804e814ee24868de42af31ada20_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1006\" data-rawheight=\"860\" class=\"origin_image zh-lightbox-thumb\" width=\"1006\" data-original=\"https://pic1.zhimg.com/v2-b853d804e814ee24868de42af31ada20_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1006&#39; height=&#39;860&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1006\" data-rawheight=\"860\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1006\" data-original=\"https://pic1.zhimg.com/v2-b853d804e814ee24868de42af31ada20_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b853d804e814ee24868de42af31ada20_b.jpg\"/></figure><p>大家都知道，训练人脸识别网络的时候需要输入图像对来判断是不是同一个人，loss是两个样本之间的相似度。不过，光是相似度是不够的。</p><p>我们以前有一篇文章，专门讲述了人脸识别中的softmax损失的变种，可以回顾。</p><a href=\"https://zhuanlan.zhihu.com/p/34044634\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-250016bc1e7e898c11192cb24786f719_180x120.jpg\" data-image-width=\"5473\" data-image-height=\"3868\" class=\"internal\">龙鹏：【技术综述】一文道尽softmax loss及其变种</a><p>大家在研究的是同一个问题，如果想得到更优良的性能，不仅要将正负样本区分开，<b>还要让类内更加紧凑（方差小），类间更加疏远（方差大）</b>。</p><p>triplet network将输入改成三个，训练的时候使用一个正例+两个负例，或者一个负例+两个正例。</p><p>训练的目标就是上面的：同类别间的距离尽可能的小，不同类别间的距离尽可能的大。</p><p>基准样本x和负样本x-之间的距离定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-24fbedf0e1783773344d866378b3a8db_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"912\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb\" width=\"912\" data-original=\"https://pic4.zhimg.com/v2-24fbedf0e1783773344d866378b3a8db_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;912&#39; height=&#39;188&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"912\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"912\" data-original=\"https://pic4.zhimg.com/v2-24fbedf0e1783773344d866378b3a8db_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-24fbedf0e1783773344d866378b3a8db_b.jpg\"/></figure><p>基准样本x和正样本x+之间的距离定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-64ff7848abb852bd2b9738b8dad7a1da_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"936\" data-rawheight=\"218\" class=\"origin_image zh-lightbox-thumb\" width=\"936\" data-original=\"https://pic3.zhimg.com/v2-64ff7848abb852bd2b9738b8dad7a1da_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;936&#39; height=&#39;218&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"936\" data-rawheight=\"218\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"936\" data-original=\"https://pic3.zhimg.com/v2-64ff7848abb852bd2b9738b8dad7a1da_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-64ff7848abb852bd2b9738b8dad7a1da_b.jpg\"/></figure><p>然后优化目标就等于：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-b7d1e6da74eca7e8c1e6911b727c777f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"580\" data-rawheight=\"118\" class=\"origin_image zh-lightbox-thumb\" width=\"580\" data-original=\"https://pic4.zhimg.com/v2-b7d1e6da74eca7e8c1e6911b727c777f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;580&#39; height=&#39;118&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"580\" data-rawheight=\"118\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"580\" data-original=\"https://pic4.zhimg.com/v2-b7d1e6da74eca7e8c1e6911b727c777f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-b7d1e6da74eca7e8c1e6911b727c777f_b.jpg\"/></figure><p>我们假如网络训练的特别好，令margin=1，此时</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-082bfda2c994165f1c5ca63f6ed67c92_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"936\" data-rawheight=\"132\" class=\"origin_image zh-lightbox-thumb\" width=\"936\" data-original=\"https://pic3.zhimg.com/v2-082bfda2c994165f1c5ca63f6ed67c92_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;936&#39; height=&#39;132&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"936\" data-rawheight=\"132\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"936\" data-original=\"https://pic3.zhimg.com/v2-082bfda2c994165f1c5ca63f6ed67c92_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-082bfda2c994165f1c5ca63f6ed67c92_b.jpg\"/></figure><p>那么上面的距离：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a3a5ffdda87e3ce81ce1209265bce760_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"362\" data-rawheight=\"86\" class=\"content_image\" width=\"362\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;362&#39; height=&#39;86&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"362\" data-rawheight=\"86\" class=\"content_image lazy\" width=\"362\" data-actualsrc=\"https://pic1.zhimg.com/v2-a3a5ffdda87e3ce81ce1209265bce760_b.jpg\"/></figure><p>损失也就趋向于0，当然这种要求是不可能达到的，也不合理，因为<b>有的正样本的确不那么相似，有的负样本的确很相似，强行学习过拟合风险就增加了</b>。</p><p>所以实际用的时候，这个margin应该取一个合理的值，而且样本的选择也很有技巧，所以triplet network没有看起来那么好训练。Anyway，这还是很优雅的思想的。</p><p>今天就这么多，更多的并行的输入也是有的，就作为大家的延伸阅读吧。<br/></p><p><b>总结：</b></p><p>好像文章越写越简单了，不过这是好事，这个咱们这个系列的完整目录：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a> </p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a>  </p><p>另外：咱们还有一个专栏专门讲述：</p><a href=\"https://zhuanlan.zhihu.com/c_1005865351275573248\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-f32626bd7c13e7b9d294ad9ba0e7fb9e_ipico.jpg\" data-image-width=\"500\" data-image-height=\"500\" class=\"internal\">有三AI学院-深度学习模型优化</a><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }, 
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/53082275", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 53, 
            "title": "【模型训练】SGD的那些变种，真的比SGD强吗", 
            "content": "<p>深度学习框架目前基本上都是使用梯度下降算法及其变种进行优化，通常意义上大家会认为原始的梯度下降算法是最弱的，但事实上并非如此。</p><p>很多的论文依然采用了原始的梯度下降算法而不采用更高级的算法，今天就以一个实践例子来给大家展示一下各类算法的比较，所有内容参考文章【An overview of gradient descent optimization algorithms】。</p><blockquote>0 <b>梯度下降算法</b></blockquote><p>本文目标不是为了从零开始讲清楚优化算法，所以有些细节和基础就略过。</p><p>梯度下降算法，即通过梯度的反方向来进行优化，<b>批量梯度下降（Batch gradient descent）</b>用公式表述如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-1effedcb9fcd26017a94b85704973d73_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"506\" data-rawheight=\"100\" class=\"origin_image zh-lightbox-thumb\" width=\"506\" data-original=\"https://pic4.zhimg.com/v2-1effedcb9fcd26017a94b85704973d73_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;506&#39; height=&#39;100&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"506\" data-rawheight=\"100\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"506\" data-original=\"https://pic4.zhimg.com/v2-1effedcb9fcd26017a94b85704973d73_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-1effedcb9fcd26017a94b85704973d73_b.jpg\"/></figure><p>写成伪代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">for i in range(nb_epochs):\n    params_grad = evaluate_gradient(loss_function, data, params) \n    params = params - learning_rate * params_grad</code></pre></div><p>上面的梯度下降算法用到了数据集所有的数据，这在解决实际问题时通常是不可能，想想imagenet1000有100G以上的图像，内存装不下，速度也很慢。</p><p>我们需要在线能够实时计算，于是一次取一个样本，就有了<b>随机梯度下降（Stochastic gradient descent），简称sgd</b>。</p><p>公式如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4ce6022ff55dc8d781a87cba61aa7997_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"566\" data-rawheight=\"108\" class=\"origin_image zh-lightbox-thumb\" width=\"566\" data-original=\"https://pic4.zhimg.com/v2-4ce6022ff55dc8d781a87cba61aa7997_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;566&#39; height=&#39;108&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"566\" data-rawheight=\"108\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"566\" data-original=\"https://pic4.zhimg.com/v2-4ce6022ff55dc8d781a87cba61aa7997_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4ce6022ff55dc8d781a87cba61aa7997_b.jpg\"/></figure><p>写成伪代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">for i in range(nb_epochs): \n    np.random.shuffle(data)\n    for example in data:\n        params_grad = evaluate_gradient(loss_function , example , params) \n        params = params - learning_rate * params_grad</code></pre></div><p>sgd方法缺点很明显，梯度震荡，所以就有了后来大家常用的<b>小批量梯度下降算法（Mini-batch gradient descent）</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5497306546d1f573eee0b43376998238_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"122\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic1.zhimg.com/v2-5497306546d1f573eee0b43376998238_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;122&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"122\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic1.zhimg.com/v2-5497306546d1f573eee0b43376998238_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5497306546d1f573eee0b43376998238_b.jpg\"/></figure><p>伪代码如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">for i in range(nb_epochs): \n    np.random.shuffle(data)\n    for batch in get_batches(data, batch_size=50):\n        params_grad = evaluate_gradient(loss_function, batch, params) \n        params = params - learning_rate * params_grad</code></pre></div><p>下面我们要形成共识，<b>说sgd算法，实际上指的就是mini-batch gradient descent算法，没有人会去一次拿整个数据集或者一个样本进行优化。</b></p><p>当然还是要总结一下SGD算法的毛病。</p><ul><li>学习率大小和策略选择困难，想必动手经验丰富的自然懂。</li><li>学习率不够智能，对所有参数一视同仁。</li><li>同时面临局部极值和鞍点的问题。</li></ul><p>可能有同学不知道鞍点怎么回事，简单来说，它就是在某一些方向梯度下降，另一些方向梯度上升，形状似马鞍，抄来一张图如下，<b>红点就是鞍点</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-efbc2069c83948d1aad2d99e1f15334a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"403\" class=\"origin_image zh-lightbox-thumb\" width=\"1024\" data-original=\"https://pic3.zhimg.com/v2-efbc2069c83948d1aad2d99e1f15334a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1024&#39; height=&#39;403&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1024\" data-rawheight=\"403\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1024\" data-original=\"https://pic3.zhimg.com/v2-efbc2069c83948d1aad2d99e1f15334a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-efbc2069c83948d1aad2d99e1f15334a_b.jpg\"/></figure><blockquote>02 <b>梯度下降方法改进</b></blockquote><div class=\"highlight\"><pre><code class=\"language-text\">1.1 动量法            </code></pre></div><p><b>改进方法那么多，我觉得真正最有用的就是它。</b></p><p>前面说了梯度下降算法是按照梯度的反方向进行参数更新，但是<b>刚开始的时候梯度不稳定呀，方向改变是很正常的</b>，梯度就是抽疯了似的一下正一下反，导致做了很多无用的迭代。</p><p>而动量法做的很简单，<b>相信之前的梯度</b>。如果梯度方向不变，就越发更新的快，反之减弱当前梯度。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-46c6f5f721da0a889f682c96caeed19d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"132\" class=\"origin_image zh-lightbox-thumb\" width=\"480\" data-original=\"https://pic2.zhimg.com/v2-46c6f5f721da0a889f682c96caeed19d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;480&#39; height=&#39;132&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"132\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"480\" data-original=\"https://pic2.zhimg.com/v2-46c6f5f721da0a889f682c96caeed19d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-46c6f5f721da0a889f682c96caeed19d_b.jpg\"/></figure><p>画成图就是这样。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-89c399745343352e1254d9fb3992d60c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"356\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-89c399745343352e1254d9fb3992d60c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;356&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"356\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-89c399745343352e1254d9fb3992d60c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-89c399745343352e1254d9fb3992d60c_b.jpg\"/></figure><p>效果对比就这意思。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-561afd062cfb56512e0776e58e08a8ae_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"269\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-561afd062cfb56512e0776e58e08a8ae_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;269&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"269\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-561afd062cfb56512e0776e58e08a8ae_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-561afd062cfb56512e0776e58e08a8ae_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">1.2 nesterov动量法  </code></pre></div><p>仍然是动量法，只是它要求这个下降更加智能。</p><p>既然动量法已经把前一次的梯度和当前梯度融合，那何不更进一步，直接先按照前一次梯度方向更新一步将它作为当前的梯度，看下面的式子就明白了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5d2a407eb27baa7352aa5722b82ca275_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"704\" data-rawheight=\"174\" class=\"origin_image zh-lightbox-thumb\" width=\"704\" data-original=\"https://pic2.zhimg.com/v2-5d2a407eb27baa7352aa5722b82ca275_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;704&#39; height=&#39;174&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"704\" data-rawheight=\"174\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"704\" data-original=\"https://pic2.zhimg.com/v2-5d2a407eb27baa7352aa5722b82ca275_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5d2a407eb27baa7352aa5722b82ca275_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-9c04d2b8f554379bc2bcabf8cfc46afb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"916\" data-rawheight=\"438\" class=\"origin_image zh-lightbox-thumb\" width=\"916\" data-original=\"https://pic4.zhimg.com/v2-9c04d2b8f554379bc2bcabf8cfc46afb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;916&#39; height=&#39;438&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"916\" data-rawheight=\"438\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"916\" data-original=\"https://pic4.zhimg.com/v2-9c04d2b8f554379bc2bcabf8cfc46afb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-9c04d2b8f554379bc2bcabf8cfc46afb_b.jpg\"/></figure><p>如上图，计算B点下一步更新动量时，先达到提前点C，然后根据A点带来的动量项和C点的梯度进行更新，得到D点。</p><p>nesterov的好处就是，当梯度方向快要改变的时候，它提前获得了该信息，从而减弱了这个过程，再次减少了无用的迭代。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.3 Adagrad法   </code></pre></div><p>思路很简单，<b>不同的参数是需要不同的学习率的</b>，有的要慢慢学，有的要快快学，所以就给了一个权重咯，而且是用了历史上所有的梯度幅值。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-aa63a633716fc23cc1448d7255e7b8be_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"568\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb\" width=\"568\" data-original=\"https://pic3.zhimg.com/v2-aa63a633716fc23cc1448d7255e7b8be_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;568&#39; height=&#39;152&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"568\" data-rawheight=\"152\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"568\" data-original=\"https://pic3.zhimg.com/v2-aa63a633716fc23cc1448d7255e7b8be_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-aa63a633716fc23cc1448d7255e7b8be_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">1.4 Adadelta与Rmsprop      </code></pre></div><p>adagrad用了所有的梯度，问题也就来了，累加的梯度幅值是越来越大的。导致学习率前面的乘因子越来越小，后来就学不动了呀。</p><p>Adadelta就只是动了一丢丢小心思，用移动平均的方法计算累加梯度，只累加了一个窗口的梯度，而且计算方法也更有效。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d0c4328325b7a4a35eb3924e4d3a4b22_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"676\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb\" width=\"676\" data-original=\"https://pic3.zhimg.com/v2-d0c4328325b7a4a35eb3924e4d3a4b22_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;676&#39; height=&#39;110&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"676\" data-rawheight=\"110\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"676\" data-original=\"https://pic3.zhimg.com/v2-d0c4328325b7a4a35eb3924e4d3a4b22_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d0c4328325b7a4a35eb3924e4d3a4b22_b.jpg\"/></figure><p>并且，将学习率用前一时刻参数的平方根来代替，最终更新算法变成了这样。  </p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-117a71d8abd58d5b8ba1ccff9315c08a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"210\" class=\"origin_image zh-lightbox-thumb\" width=\"498\" data-original=\"https://pic3.zhimg.com/v2-117a71d8abd58d5b8ba1ccff9315c08a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;498&#39; height=&#39;210&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"498\" data-rawheight=\"210\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"498\" data-original=\"https://pic3.zhimg.com/v2-117a71d8abd58d5b8ba1ccff9315c08a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-117a71d8abd58d5b8ba1ccff9315c08a_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d039325dfdfd4f519eaf54df0e04fc8a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"614\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb\" width=\"614\" data-original=\"https://pic3.zhimg.com/v2-d039325dfdfd4f519eaf54df0e04fc8a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;614&#39; height=&#39;128&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"614\" data-rawheight=\"128\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"614\" data-original=\"https://pic3.zhimg.com/v2-d039325dfdfd4f519eaf54df0e04fc8a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d039325dfdfd4f519eaf54df0e04fc8a_b.jpg\"/></figure><p>RMSprop方法的不同就在于分子上还是使用学习率η而不是Adadelta中的</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f7ff94b8001c7d71d4da6cb564e6fe3f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"92\" class=\"origin_image zh-lightbox-thumb\" width=\"524\" data-original=\"https://pic4.zhimg.com/v2-f7ff94b8001c7d71d4da6cb564e6fe3f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;524&#39; height=&#39;92&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"92\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"524\" data-original=\"https://pic4.zhimg.com/v2-f7ff94b8001c7d71d4da6cb564e6fe3f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f7ff94b8001c7d71d4da6cb564e6fe3f_b.jpg\"/></figure><p>这个方法在Hinton的课程中使用，没有发表成论文，毕竟有Adadelta了没有发表必要。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.5 adam法                  </code></pre></div><p>最后就是这个adam算法，作为最晚出现的，当然是集大成者。</p><p>adam对梯度的一阶和二阶都进行了<b>估计与偏差修正</b>，使用梯度的一阶矩估计和二阶矩估计来动态调整每个参数的学习率。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e59ac9dd66d7c2a6dae1b2f62f029d3c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"596\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb\" width=\"596\" data-original=\"https://pic1.zhimg.com/v2-e59ac9dd66d7c2a6dae1b2f62f029d3c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;596&#39; height=&#39;188&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"596\" data-rawheight=\"188\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"596\" data-original=\"https://pic1.zhimg.com/v2-e59ac9dd66d7c2a6dae1b2f62f029d3c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e59ac9dd66d7c2a6dae1b2f62f029d3c_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f43c3c29ffa67e78e11c95c6b0943c68_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"348\" data-rawheight=\"244\" class=\"content_image\" width=\"348\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;348&#39; height=&#39;244&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"348\" data-rawheight=\"244\" class=\"content_image lazy\" width=\"348\" data-actualsrc=\"https://pic1.zhimg.com/v2-f43c3c29ffa67e78e11c95c6b0943c68_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-167e83f2923198e6d7f9ea90bf716bb8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"502\" data-rawheight=\"148\" class=\"origin_image zh-lightbox-thumb\" width=\"502\" data-original=\"https://pic1.zhimg.com/v2-167e83f2923198e6d7f9ea90bf716bb8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;502&#39; height=&#39;148&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"502\" data-rawheight=\"148\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"502\" data-original=\"https://pic1.zhimg.com/v2-167e83f2923198e6d7f9ea90bf716bb8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-167e83f2923198e6d7f9ea90bf716bb8_b.jpg\"/></figure><p>看出来了吧，与adadelta和rmsprop如出一辙，与momentum sgd也颇为相似。上面的式子根据梯度对参数更新的幅度进行了动态调整，所以adam对学习率没有那么敏感。</p><div class=\"highlight\"><pre><code class=\"language-text\">1.6 adamax </code></pre></div><p>将adam使用的<b>二阶矩变成更高阶</b>，就成了adamax算法。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4fe88a650aed23f82fa8886769bd71f5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"642\" data-rawheight=\"168\" class=\"origin_image zh-lightbox-thumb\" width=\"642\" data-original=\"https://pic2.zhimg.com/v2-4fe88a650aed23f82fa8886769bd71f5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;642&#39; height=&#39;168&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"642\" data-rawheight=\"168\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"642\" data-original=\"https://pic2.zhimg.com/v2-4fe88a650aed23f82fa8886769bd71f5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4fe88a650aed23f82fa8886769bd71f5_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-09ac982d4f1b845271b85baa62d2a56e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"384\" data-rawheight=\"158\" class=\"content_image\" width=\"384\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;384&#39; height=&#39;158&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"384\" data-rawheight=\"158\" class=\"content_image lazy\" width=\"384\" data-actualsrc=\"https://pic3.zhimg.com/v2-09ac982d4f1b845271b85baa62d2a56e_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">1.7 nadam法    </code></pre></div><p>nag加上adam，就成了nadam方法，即<b>带有动量项的adam</b>，所以形式也很简单，如下，可以将其分别与adam算法和nag算法的式子比较看看。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-88b536deaa0d0340a34daf7fb5ceb872_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"858\" data-rawheight=\"194\" class=\"origin_image zh-lightbox-thumb\" width=\"858\" data-original=\"https://pic3.zhimg.com/v2-88b536deaa0d0340a34daf7fb5ceb872_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;858&#39; height=&#39;194&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"858\" data-rawheight=\"194\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"858\" data-original=\"https://pic3.zhimg.com/v2-88b536deaa0d0340a34daf7fb5ceb872_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-88b536deaa0d0340a34daf7fb5ceb872_b.jpg\"/></figure><p>说了这么多，对上面各种方法从一个鞍点开始优化，表现如何的预期效果图如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"620\" data-rawheight=\"480\" data-thumbnail=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"620\" data-original=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;620&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"620\" data-rawheight=\"480\" data-thumbnail=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"620\" data-original=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_b.gif\"/></figure><p>理论上，就是上面这样的。文章作者会告诉你对于数据稀疏的问题，用自适应学习率算法就好了，而且使用人家推荐的参数就好。其中，adam会最佳。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-1eae56e6ed0e4a97f407cad99456a27a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"300\" data-rawheight=\"281\" class=\"content_image\" width=\"300\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;300&#39; height=&#39;281&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"300\" data-rawheight=\"281\" class=\"content_image lazy\" width=\"300\" data-actualsrc=\"https://pic3.zhimg.com/v2-1eae56e6ed0e4a97f407cad99456a27a_b.jpg\"/></figure><blockquote>03 <b>各种方法表现究竟如何</b></blockquote><p>上面说了这么多理论，分析起来头头是道，各种改进版本似乎各个碾压SGD算法，然而根据笔者经验，很多时候<b>仔细调优后的SGD算法绝对吊打其他算法</b>。</p><p>实验结果看下图，基础任务模型和数据集上次已经说过，此处不再赘述。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a091391c64d3786395b193f13ceefeee_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"769\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-a091391c64d3786395b193f13ceefeee_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;769&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"769\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-a091391c64d3786395b193f13ceefeee_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a091391c64d3786395b193f13ceefeee_b.jpg\"/></figure><p>所有方法都采用作者们的默认配置，并且进行了比较，不好的结果就不拿出来了。</p><ul><li>nesterov方法，与sgd算法同样的配置。</li><li>adam算法，m1=0.9，m2=0.999，lr=0.001。</li><li>rms算法，rms_decay=0.9，lr=0.001。</li><li>adagrad，adadelta学习率不敏感。</li></ul><p><b>怎么着，好像都不如SGD算法呀。为什么呢？留言讨论吧。</b></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "最优化", 
                    "tagLink": "https://api.zhihu.com/topics/19616819"
                }, 
                {
                    "tag": "调参", 
                    "tagLink": "https://api.zhihu.com/topics/20682988"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "实践证明恐怕变种还是好一些", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "我这可不就是实践", 
                            "likes": 2, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "卡利姆多的风", 
                    "userLink": "https://www.zhihu.com/people/06a3518ec132abab04207e08016111c6", 
                    "content": "<p>据说语言模型里不带动量的SGD效果最好，但是我做了一下收敛的太慢了，感觉时间和资源受限的情况下还是ADAM最好用 </p><a class=\"comment_sticker\" href=\"https://pic4.zhimg.com/v2-db92f653a2ec17ea3ff309d6d56e8507.gif\" data-width=\"\" data-height=\"\">[吃瓜]</a>", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "哈哈哈，adam准是能收敛", 
                            "likes": 0, 
                            "replyToAuthor": "卡利姆多的风"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>确实有这样类似的结论，ICLR出过一篇有关Adam可能存在学习率不收敛的论文，而且在图像方向的话，大家还是普遍喜欢SGD+Momentum，因为结果确实比Adam、RMSprop这一类自适应学习率方法好</p>", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "嗯，有耐心就调调sgd", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "为啥不用自然梯度？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "余学辉", 
                            "userLink": "https://www.zhihu.com/people/3797ec1361334d53509366e6f37bb1b6", 
                            "content": "为了更快收敛加跳过一些局部最优", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/52608023", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 18, 
            "title": "【模型训练】如何选择最适合你的学习率变更策略", 
            "content": "<p>首发于《有三AI》</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030692%26idx%3D1%26sn%3D6322e8eec12d8a8b60f578a9ebb4b42c%26chksm%3D8712be59b065374f00dc9b3715e6453e2de5d05262ee4eac47ef5efe6d167703af67f5882029%26token%3D769460193%26lang%3Dzh_CN%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/v2-4d9edba28be2ca49be87d6a64b3088dc_180x120.jpg\" data-image-width=\"732\" data-image-height=\"459\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型训练】如何选择最适合你的学习率变更策略</a><p>如果让我投票给深度学习中，最不想调试，但又必须要小心调试的参数，毫无疑问会投给学习率，今天就来说说这个。</p><blockquote><b>01 项目背景</b></blockquote><p>我们选择了GHIM-10k数据集，这是一个图像检索数据集，包含20个类别，分别是日落，船舶，花卉，建筑物，汽车，山脉，昆虫等自然图像，各个类别拥有较好的多样性，而类别之间也有比较好的区分度。数据集共10000张图像，每个类别包含500张JPEG格式的大小为400×300或300×400的图像。</p><p>如下图就是其中的烟花类别。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d72cd8cb53b8dee4d7435ae76cee1a36_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"599\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-d72cd8cb53b8dee4d7435ae76cee1a36_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;599&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"599\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-d72cd8cb53b8dee4d7435ae76cee1a36_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d72cd8cb53b8dee4d7435ae76cee1a36_b.jpg\"/></figure><p>定义了一个6层的卷积神经网络，网络结构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-cf9dbe3de86edcba41ccfbf0023da3ad_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"878\" data-rawheight=\"1504\" class=\"origin_image zh-lightbox-thumb\" width=\"878\" data-original=\"https://pic2.zhimg.com/v2-cf9dbe3de86edcba41ccfbf0023da3ad_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;878&#39; height=&#39;1504&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"878\" data-rawheight=\"1504\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"878\" data-original=\"https://pic2.zhimg.com/v2-cf9dbe3de86edcba41ccfbf0023da3ad_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-cf9dbe3de86edcba41ccfbf0023da3ad_b.jpg\"/></figure><p>细节咱就不多说，如果你想复现本文结果，可以发送<b>关键词“有三AI训练营12-16”</b>到后台获取网络配置等文件。</p><blockquote><b>02 学习率变更策略</b></blockquote><p>学习率是一个非常重要的参数，可以直接影响模型的收敛与否。不同的学习率变更策略也会影响最终的迭代结果。</p><p>下面以sgd优化方法，来介绍各种策略。caffe框架中的策略包括fixed，step，exp，inv，multistep，poly，sigmoid。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-ef44f2defcf253623f5d6872375b17c8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"533\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-ef44f2defcf253623f5d6872375b17c8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;533&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"533\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-ef44f2defcf253623f5d6872375b17c8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-ef44f2defcf253623f5d6872375b17c8_b.jpg\"/></figure><p><b>2.1 fixed</b></p><p>fixed，即固定学习率，这是最简单的一种配置，只需要一个参数。</p><div class=\"highlight\"><pre><code class=\"language-text\">lr_policy: &#34;fixed&#34;\nbase_lr: 0.01</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-2e3274f4bc46c25e8b33472332c9c7ea_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"632\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb\" width=\"632\" data-original=\"https://pic3.zhimg.com/v2-2e3274f4bc46c25e8b33472332c9c7ea_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;632&#39; height=&#39;477&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"632\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"632\" data-original=\"https://pic3.zhimg.com/v2-2e3274f4bc46c25e8b33472332c9c7ea_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-2e3274f4bc46c25e8b33472332c9c7ea_b.jpg\"/></figure><p>如上图，在整个的优化过程中学习率不变，这是非常少使用的策略，因为随着向全局最优点逼近，学习率应该越来越小才能避免跳过最优点。<br/></p><p><b>2.2 step</b></p><p>采用均匀降低的方式，比如每次降低为原来的0.1倍</p><div class=\"highlight\"><pre><code class=\"language-text\">lr_policy: &#34;step&#34;\nbase_lr: 0.01\nstepsize: 10000\ngamma:0.1</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-aa526bd2d805ce0dbbd1082c6cbe7392_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb\" width=\"619\" data-original=\"https://pic3.zhimg.com/v2-aa526bd2d805ce0dbbd1082c6cbe7392_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;619&#39; height=&#39;477&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"619\" data-original=\"https://pic3.zhimg.com/v2-aa526bd2d805ce0dbbd1082c6cbe7392_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-aa526bd2d805ce0dbbd1082c6cbe7392_b.jpg\"/></figure><p>这是非常常用的一个学习率迭代策略，每次将学习率降低为原来的一定倍数，属于非连续型的变换，使用简单，而且效果通常较好。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>不过从上图也可以看出，其实学习率的变化一点都不平滑。</p><p><b>2.3  multistep</b></p><p>采用非均匀降低策略，指定降低的step间隔，每次降低为原来的一定倍数。</p><div class=\"highlight\"><pre><code class=\"language-text\">lr_policy: &#34;multistep&#34;\ngamma: 0.5\nstepvalue: 10000\nstepvalue: 30000\nstepvalue: 60000</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-946ed5a1dcb7f82cd02ebbc3c0efc38b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"607\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb\" width=\"607\" data-original=\"https://pic4.zhimg.com/v2-946ed5a1dcb7f82cd02ebbc3c0efc38b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;607&#39; height=&#39;477&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"607\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"607\" data-original=\"https://pic4.zhimg.com/v2-946ed5a1dcb7f82cd02ebbc3c0efc38b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-946ed5a1dcb7f82cd02ebbc3c0efc38b_b.jpg\"/></figure><p>这是比step更加复杂的策略，也是采用非连续型的变换，但是变换的迭代次数不均匀，也是非常常用的策略，需要经验。</p><p><b>2.4 exp</b></p><p>这是一种指数变化，new_lr = base_lr * (gamma^iter)，可知这是连续变化，学习率的衰减非常的快，gamma越大则衰减越慢，但是因为caffe中的实现使用了iter作为指数，而iter通常都是非常大的值，所以学习率衰减仍然非常快。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-76d209acd99c13e36b59daebb4c252af_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb\" width=\"619\" data-original=\"https://pic4.zhimg.com/v2-76d209acd99c13e36b59daebb4c252af_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;619&#39; height=&#39;477&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"619\" data-original=\"https://pic4.zhimg.com/v2-76d209acd99c13e36b59daebb4c252af_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-76d209acd99c13e36b59daebb4c252af_b.jpg\"/></figure><p><b>2.5 inv</b></p><p>new_lr = base_lr * (1 + gamma * iter) ^ (- power)，可以看出，也是一种指数变换，参数gamma控制曲线下降的速率，而参数power控制曲线在饱和状态下学习率达到的最低值。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-eb7e562c87c1e5af70e7a69d3d33f591_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb\" width=\"619\" data-original=\"https://pic2.zhimg.com/v2-eb7e562c87c1e5af70e7a69d3d33f591_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;619&#39; height=&#39;477&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"619\" data-original=\"https://pic2.zhimg.com/v2-eb7e562c87c1e5af70e7a69d3d33f591_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-eb7e562c87c1e5af70e7a69d3d33f591_b.jpg\"/></figure><p><b>2.6 poly</b></p><p>new_lr = base_lr * (1 – iter/maxiter) ^ (power)，可以看出，学习率曲线的形状主要由参数power的值来控制。当power = 1的时候，学习率曲线为一条直线。当power &lt; 1的时候，学习率曲线是凸的，且下降速率由慢到快。当power &gt; 1的时候，学习率曲线是凹的，且下降速率由快到慢。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-30812dcf000a977a60fec508b5d50775_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb\" width=\"619\" data-original=\"https://pic2.zhimg.com/v2-30812dcf000a977a60fec508b5d50775_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;619&#39; height=&#39;477&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"619\" data-original=\"https://pic2.zhimg.com/v2-30812dcf000a977a60fec508b5d50775_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-30812dcf000a977a60fec508b5d50775_b.jpg\"/></figure><p><b>2.7 sigmoid</b></p><p>new_lr = base_lr *( 1/(1 + exp(-gamma * (iter - stepsize))))</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0e55e2c99f66ac42c8de95bc8ff82311_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb\" width=\"619\" data-original=\"https://pic2.zhimg.com/v2-0e55e2c99f66ac42c8de95bc8ff82311_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;619&#39; height=&#39;477&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"619\" data-original=\"https://pic2.zhimg.com/v2-0e55e2c99f66ac42c8de95bc8ff82311_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-0e55e2c99f66ac42c8de95bc8ff82311_b.jpg\"/></figure><p>参数gamma控制曲线的变化速率。gamma必须小于0才能下降，而这在caffe中并不被支持。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>究竟这些策略的实际表现结果如何呢？请看下面的实验结果。</p><blockquote><b>03 实验结果</b></blockquote><p>下面就展示以上的学习率策略下的实验结果，由于type=sigmoid不能进行学习率的下降，所以不进行对比。学习率的具体变更方式如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d5ed450cc4d9708c961d7f19e4817251_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb\" width=\"619\" data-original=\"https://pic2.zhimg.com/v2-d5ed450cc4d9708c961d7f19e4817251_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;619&#39; height=&#39;477&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"477\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"619\" data-original=\"https://pic2.zhimg.com/v2-d5ed450cc4d9708c961d7f19e4817251_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d5ed450cc4d9708c961d7f19e4817251_b.jpg\"/></figure><p>训练数据集大小9000，batchsize=64，可知10000次迭代时，epoch=64*10000/9000&gt;70，在该学习率下应该已经充分训练了，实验结果如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-3b4c8a4c1e4de1abce9829aef01b0b2c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-3b4c8a4c1e4de1abce9829aef01b0b2c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-3b4c8a4c1e4de1abce9829aef01b0b2c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-3b4c8a4c1e4de1abce9829aef01b0b2c_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-45f52e181453e4a6fc34c2bb084e9c73_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-45f52e181453e4a6fc34c2bb084e9c73_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-45f52e181453e4a6fc34c2bb084e9c73_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-45f52e181453e4a6fc34c2bb084e9c73_b.jpg\"/></figure><p>收敛的结果如上，可知道都得到了收敛，但是效果不同。我们在这里要下几个结论，虽然只有一个案例，但是根据笔者多年使用经验，确实如此。</p><p class=\"ztext-empty-paragraph\"><br/></p><ul><li><b>step，multistep方法的收敛效果最好</b>，这也是我们平常用它们最多的原因。虽然学习率的变化是最离散的，但是并不影响模型收敛到比较好的结果。</li><li>其次是<b>exp，poly</b>。它们能取得与step，multistep相当的结果，也是因为学习率以比较好的速率下降，<b>操作的确很骚，不过并不见得能干过step和multistep。</b></li><li>inv和fixed的收敛结果最差。这是比较好解释的，因为fixed方法始终使用了较大的学习率，而inv方法的学习率下降过程太快，这一点，当我们直接使用0.001固定大小的学习率时可以得到验证，最终收敛结果与inv相当。</li></ul><p class=\"ztext-empty-paragraph\"><br/></p><p><b>在此问大家一个问题，你觉得上面的模型，收敛到最好的状态了吗？不妨后台留言讨论。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-50f4a8726aa049f481734afd61e6e900_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"350\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic1.zhimg.com/v2-50f4a8726aa049f481734afd61e6e900_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;800&#39; height=&#39;350&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"350\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"800\" data-original=\"https://pic1.zhimg.com/v2-50f4a8726aa049f481734afd61e6e900_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-50f4a8726aa049f481734afd61e6e900_b.jpg\"/></figure><blockquote><b>04 总结</b></blockquote><p>今天只是小试牛刀，<b>也挖了很多的坑给大家（我们以后会填上的）</b>。如果不是为了刷指标，很多时候，学习率变更策略不太需要精挑细选，比如上面的step和multistep，实际表现差不多，笔者常使用multistep，虽然这确实是个经验活儿，不过再白痴也总不能傻到用fixed策略去训练。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>否则，其他的提高精度的措施做的再到位，也很可能因此而废。至于exp，inv，poly什么的，鄙人经验，<b>貌似中看不中用。</b></p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>那adam怎么样呢？</b></p>", 
            "topic": [
                {
                    "tag": "凸优化", 
                    "tagLink": "https://api.zhihu.com/topics/19602355"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "Caffe（深度学习框架）", 
                    "tagLink": "https://api.zhihu.com/topics/20019488"
                }
            ], 
            "comments": [
                {
                    "userName": "云海果子", 
                    "userLink": "https://www.zhihu.com/people/36bcccf2c3e89adecd2ab92011fe1848", 
                    "content": "<p>有没有收敛到最好状态我的判断标准是前后epoch的acc相差在一个阈值范围之类就认为已经可以了 这里的阈值为0是理想情况 一般根据需求误差在0.005左右肯定OK了</p><a class=\"comment_sticker\" href=\"https://pic4.zhimg.com/v2-db92f653a2ec17ea3ff309d6d56e8507.gif\" data-width=\"\" data-height=\"\">[吃瓜]</a>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "云海果子", 
                    "userLink": "https://www.zhihu.com/people/36bcccf2c3e89adecd2ab92011fe1848", 
                    "content": "<p>貌似有个bug, step和multistep中有stepsize=10000后衰减学习律，此时根据数据集有9000，那么此时64*10000/9000&gt;70epoch了， 难道是70个epoch才衰减一次？或者你这里写错了应该是stepsize=1000?</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "manzp", 
                    "userLink": "https://www.zhihu.com/people/77e3eb18a38e285cb4a14ad3d304c433", 
                    "content": "<p>你好，像 Adam、RMSProp、Adadelta 等自适应调整学习率的参数学习算法，其在 caffe 中的学习率是不是要设置成 fixed ？</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "是的", 
                            "likes": 0, 
                            "replyToAuthor": "manzp"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/52069387", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 28, 
            "title": "【技术综述】图像与CNN发家简史，集齐深度学习三巨头", 
            "content": "<p>没有一个经典的发现会是突然之间横空出世，它总是需要一些积淀。</p><p>提起卷积神经网络，我们总会从LeNet5开始说起，但是LeNet5不是起点也不是终点，这一期<b>扒一下图像和CNN的发家历史</b>。</p><h2><b>01 图像</b></h2><div class=\"highlight\"><pre><code class=\"language-text\">1.1 什么是图像</code></pre></div><p>人们睁眼看世界，看的就是图像。图像的英文名是image，来于拉丁文imago，image如果用英文来定义，包含&#34;representation, reflection, apparition, semblance, copy, visible form&#34;等。</p><p>图像有图有像，两者是有差别的。<b>图，是客观世界的存在，从物理上说，是物体反射或透射光的分布。而像，则是人的视觉系统所接受的图在人脑中形成的认识。</b></p><p>所以先有图，后有像。</p><p>人类的文明历史，经过了从<b>结绳记事，文字记事，到如今的图片，视频记事的发展历史</b>，正所谓一图胜千言，我们不妨将图片的发展史看作人类文明的发展史的一个缩影，并不过分。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d2e0aa81726160060dd7a77f292f53fd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"361\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-d2e0aa81726160060dd7a77f292f53fd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;361&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"361\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-d2e0aa81726160060dd7a77f292f53fd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d2e0aa81726160060dd7a77f292f53fd_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">1.2 模拟图像</code></pre></div><p>所谓模拟图像：就是通过某种<b>物理量（如光、电等）的强弱变化</b>来记录图像亮度信息。</p><p>模拟图像的出现应该从1826年前后法国科学家Joseph Nicéphore Niépce发明<b>第一张可以永久记录的照片</b>开始，到如今已将近两百年，那一张图片如下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-bc386223f6061ac1654628d082f587d6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"269\" data-rawheight=\"187\" class=\"content_image\" width=\"269\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;269&#39; height=&#39;187&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"269\" data-rawheight=\"187\" class=\"content_image lazy\" width=\"269\" data-actualsrc=\"https://pic3.zhimg.com/v2-bc386223f6061ac1654628d082f587d6_b.jpg\"/></figure><p>从19世纪30年代到20世纪中期计算机的出现，中间有一百多年的历史。那时候的图像的发展史，<b>实际上差不多就是摄影的发展史，所以我为什么要玩摄影呢？</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c5c2842f80c1d669b7418bffba3f88f6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1049\" data-rawheight=\"590\" class=\"origin_image zh-lightbox-thumb\" width=\"1049\" data-original=\"https://pic3.zhimg.com/v2-c5c2842f80c1d669b7418bffba3f88f6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1049&#39; height=&#39;590&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1049\" data-rawheight=\"590\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1049\" data-original=\"https://pic3.zhimg.com/v2-c5c2842f80c1d669b7418bffba3f88f6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c5c2842f80c1d669b7418bffba3f88f6_b.jpg\"/></figure><p>当然，年纪大一点的肯定看过模拟电视。那一种<b>没有信号就拍一拍</b>的感觉，自己懂。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9fe6aaca80481f55e53c951cc4c83108_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"350\" data-rawheight=\"277\" class=\"content_image\" width=\"350\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;350&#39; height=&#39;277&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"350\" data-rawheight=\"277\" class=\"content_image lazy\" width=\"350\" data-actualsrc=\"https://pic1.zhimg.com/v2-9fe6aaca80481f55e53c951cc4c83108_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">1.3 数字图像</code></pre></div><p>数字图像的诞生并不与计算机完全挂钩。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-32f90a461d5a233b6139e4975ca53b8f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"440\" data-rawheight=\"273\" class=\"origin_image zh-lightbox-thumb\" width=\"440\" data-original=\"https://pic4.zhimg.com/v2-32f90a461d5a233b6139e4975ca53b8f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;440&#39; height=&#39;273&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"440\" data-rawheight=\"273\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"440\" data-original=\"https://pic4.zhimg.com/v2-32f90a461d5a233b6139e4975ca53b8f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-32f90a461d5a233b6139e4975ca53b8f_b.jpg\"/></figure><p>战争往往是催生技术发展的最好外部因素，在第一次世界大战（1914年7月28日至1918年11月11日）后的两年，也就是1920年数字图像被发明了，用于报纸行业。</p><p>当时为了传输这一幅图像，<b>巴特兰有线电视图像传输系统</b><br/><b>（Bartlane cable picture transmission system）</b>被发明，实际上主体就是一根海底电缆，从英国伦敦连接到美国纽约。</p><p><b>1921年实现了第一幅数字图像的传送</b>，耗时3小时，编码解码都是用打印机来完成的。</p><p>当时用了5个灰度级进行编码，大家知道现在用的是8个灰度级。</p><p><b>为什么是5个灰度级呢</b>，实际上这是因为人眼就只能分辨这么多，分的再细也没有用，可以感受一下下图，5个灰度级和6个灰度级的差别。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-43962e29c9b0ac14ffbdddc49b155659_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"507\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-43962e29c9b0ac14ffbdddc49b155659_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;507&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"507\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-43962e29c9b0ac14ffbdddc49b155659_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-43962e29c9b0ac14ffbdddc49b155659_b.jpg\"/></figure><p>20世纪50年代电子计算机被发明，人们开始利用计算机来处理图像，数字图像处理则开始正式作为一门学科在20世纪60年代初期诞生。</p><p>早期的图像处理的目的是改善图像的质量，美国喷气推进实验室（JPL）对航天探测器徘徊者7号在1964年发回的几千张月球照片使用了图像处理技术，包括几何校正、灰度变换、去除噪声等方法进行处理，成功地绘制出月球表面地图，这可以算是最早的数字图像处理了。</p><p><b>然后慢慢的全世界人民就一起研究图像了。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-05c9d7bd040058f120fdc66feca86b3f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1035\" data-rawheight=\"1017\" class=\"origin_image zh-lightbox-thumb\" width=\"1035\" data-original=\"https://pic4.zhimg.com/v2-05c9d7bd040058f120fdc66feca86b3f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1035&#39; height=&#39;1017&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1035\" data-rawheight=\"1017\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1035\" data-original=\"https://pic4.zhimg.com/v2-05c9d7bd040058f120fdc66feca86b3f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-05c9d7bd040058f120fdc66feca86b3f_b.jpg\"/></figure><p>模拟图像和数字图像的区别，大家可以感受一下。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d541b9f66c8b7dfa18a339bfa7a7266e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-d541b9f66c8b7dfa18a339bfa7a7266e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;338&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-d541b9f66c8b7dfa18a339bfa7a7266e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d541b9f66c8b7dfa18a339bfa7a7266e_b.jpg\"/></figure><p>扯的有点多，总之图像就是这么来的。</p><h2><b>02 视觉机制</b></h2><p>图像被发明了，接下来就需要解析人眼到底是如何分析图像，这个非常复杂。我们不做过多的讲述，只描述与咱们的主题，也就是<b>计算机视觉和神经网络</b>有关的部分。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.1 感受野</code></pre></div><p>现在每个人都知道卷积神经网络中的感受野，但是要研究并证实到这一点，并不是谁都能做到。</p><p>大脑的基本感知单元就是神经元，<b>一个神经元所影响的刺激区域就叫做神经元的感受野</b>，即receptive field，不同神经元感受野的大小和性质都不同。</p><p>视觉感受野的研究来自于美国神经科学家哈特兰（Keffer Hartline）和匈牙利裔美国神经科学家库夫勒（Stephen W. Kuffler），1953年他们发现猫视网膜神经节细胞的感受野具有同心圆结构。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4afc07b5cf306083813376b147b68588_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"403\" data-rawheight=\"737\" class=\"content_image\" width=\"403\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;403&#39; height=&#39;737&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"403\" data-rawheight=\"737\" class=\"content_image lazy\" width=\"403\" data-actualsrc=\"https://pic1.zhimg.com/v2-4afc07b5cf306083813376b147b68588_b.jpg\"/></figure><p>很简单很直观是吧，但是需要验证。如果今天你说你的眼睛或者某卷积核的感受野的不是一个中心对称的形状，那么恭喜你，可能要从源头挖了计算机视觉的根了。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.2 朝向敏感</code></pre></div><p>尽管有了感受野，但是视觉感知的机制仍然没有被得到更深刻地理解，直到视觉功能柱的发现。</p><p>加拿大神经生理学家David Hunter Hubel和瑞典神经科学家Torsten Nils Wiesel在20世纪50年代和60年代开始研究视觉机制，他们发现：<b>有些细胞对某些处在一个角度上的线条或者明显的边缘线有特别的反应，这就是绝大多数视皮层细胞都具有的强烈的方位选择性。</b></p><p>不仅如此，要引起这个细胞反应，<b>直线的朝向还只能落在一个很小的角度范围里，也就是该细胞的感受野内。</b></p><p><b>相邻的细胞还具有相似且重叠的感受野，随着感受野的大小和位置在皮质上系统地变化，就形成了完整的视觉空间图。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d260ce524b7210a183f5997f169b2784_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"784\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d260ce524b7210a183f5997f169b2784_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;784&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"784\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-d260ce524b7210a183f5997f169b2784_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d260ce524b7210a183f5997f169b2784_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>听起来有点拗口，但是如果你愿意去看论文【1】，会有收获。</p><p><b>结论就是，猫眼对于灰度的绝对值不敏感，对于边缘和朝向很敏感，这一点就是 “Marr视觉分层机制” 的基础。</b></p><p>从1960年到1980年，两人合作了20多年，细致科学地研究了人眼视觉的机制，因此他们被认为是<b>现代视觉科学之父</b>，并于1981年一起获得了<b>诺贝尔生理学与医学奖</b>。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.3 总结</code></pre></div><p>David Hunter Hubel和Torsten Nils Wiesel在1968年发表的论文确定了大脑中两种基本的视觉细胞类型:</p><p>(1)简单单元，感知具有特定方向的特征，对应LeNet5中的S卷积网络层。</p><p>(2)复杂细胞，对简单单元的结果做出反应，提高对位置，旋转的不变性，对应LeNet5中的C池化层。</p><p><b>总之，视觉机制揭示了视觉的本质。感知是通过从低层细胞到高层细胞不断抽象来完成，更高层的细胞，拥有更高级的感受野，并且对一些偏移等具有一定的不变性。</b></p><p>MIT的科学家马尔（David Marr）基于此提出了他的视觉分层理论，即视觉包含初级视觉、中级视觉和高级视觉三个层次，感兴趣可以自行了解。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-cf9236f838d1fc46aaeab174833533a7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"274\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-cf9236f838d1fc46aaeab174833533a7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;274&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"274\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-cf9236f838d1fc46aaeab174833533a7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-cf9236f838d1fc46aaeab174833533a7_b.jpg\"/></figure><h2><b>03 卷积神经网络发家</b></h2><p>我们在这里，不说神经网络的基础，因为一说，就又需要扯一大堆的东西。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-42b29325ea3495e4c24ace9ba0c8cfdd_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"354\" data-rawheight=\"354\" data-thumbnail=\"https://pic2.zhimg.com/v2-42b29325ea3495e4c24ace9ba0c8cfdd_b.jpg\" class=\"content_image\" width=\"354\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;354&#39; height=&#39;354&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"354\" data-rawheight=\"354\" data-thumbnail=\"https://pic2.zhimg.com/v2-42b29325ea3495e4c24ace9ba0c8cfdd_b.jpg\" class=\"content_image lazy\" width=\"354\" data-actualsrc=\"https://pic2.zhimg.com/v2-42b29325ea3495e4c24ace9ba0c8cfdd_b.gif\"/></figure><p>直接上卷积神经网络。</p><div class=\"highlight\"><pre><code class=\"language-text\">3.1 neocognitron【2】</code></pre></div><p>neocognitron也是有前身，但那个就不说了。1980年推出的neocognitron是<b>第一个真正意义上的级联卷积神经网络</b>，不过它并不完全是现在的卷积的形式。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-48516ae2dfd99c8bd928a4c71c3010fb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"612\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-48516ae2dfd99c8bd928a4c71c3010fb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;612&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"612\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-48516ae2dfd99c8bd928a4c71c3010fb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-48516ae2dfd99c8bd928a4c71c3010fb_b.jpg\"/></figure><p>麻雀虽小，该有的其实都有了。</p><p>从上图可以看出，这是一个cascade结构，按照S，C模块进行重复串接，而且，<b>信号的幅度是模拟的，即具有非负性</b>。</p><p>它已经有了卷积神经网络的基本特征，比如输入是原始的图像信号，大小为19*19，说明学习是一个无监督的过程。</p><p>第一个S层，大小为19*19*12，通道数为12，卷积的大小为5*5。<br/>第一个C层，大小为21*21*8，可知道进行了一个像素的边界补齐，从S层到C层，进行了通道的融合，输入通道为12，输出为8。</p><p>依次串接S层和C层，直到最终的输入1*10，即分类结果，这是用于识别0～9的手写数字。</p><p>值得注意的从，从S到C层，输入输出神经元的连接并不是通过一个标准的滑动窗口的卷积来完成，下图展示了其中的一个案例。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ef2f616a98ecb8c0c14d36ea20664ca6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"809\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ef2f616a98ecb8c0c14d36ea20664ca6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;809&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"809\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ef2f616a98ecb8c0c14d36ea20664ca6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ef2f616a98ecb8c0c14d36ea20664ca6_b.jpg\"/></figure><p><b>neocognitron对于要识别目标的小的形状变化和位移拥有不变性，S层提取的局部特征被输入C层，完成了低层局部特征到高层的整合。</b><br/><br/>从提出后，neocognitron也进行了多次的迭代。1988年为时间信号开发了新版本，1998年进行了改进，在2003年形成了通用版本并在同一年简化。如果你感兴趣，不妨去读以前的文章，别有一番风味。<br/></p><div class=\"highlight\"><pre><code class=\"language-text\">3.2 TDNN【3】</code></pre></div><p>深度学习的突破其实是从语音开始的，卷积神经网络早期一样被用于语音。</p><p>时间延迟神经网络（TDNN）是<b>第一个用于声音信号处理的卷积网络，被Hinton组于1989年提出</b>，三巨头被称为三巨头，自然是有历史功绩的。</p><p>网络结构如下，其实就是想办法将语音信号变成图像，这里就是一个频谱图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e6ce11ca56872b28dce8b86791516171_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"902\" data-rawheight=\"1274\" class=\"origin_image zh-lightbox-thumb\" width=\"902\" data-original=\"https://pic2.zhimg.com/v2-e6ce11ca56872b28dce8b86791516171_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;902&#39; height=&#39;1274&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"902\" data-rawheight=\"1274\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"902\" data-original=\"https://pic2.zhimg.com/v2-e6ce11ca56872b28dce8b86791516171_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e6ce11ca56872b28dce8b86791516171_b.jpg\"/></figure><p>正好笔者最近开始做语音，有时间，我回来细讲。</p><div class=\"highlight\"><pre><code class=\"language-text\">3.3 LeNet-1【4】</code></pre></div><p>终于，到了1989年，<b>Yann LeCun和Y. Bengio等人（集齐三巨头了吧）</b>开始认真研究卷积神经网络。后来10年的时间里，<b>LeNet系列网络</b>开始迭代，直到最后1998年的LeNet5。</p><p>LeNet5大家早就说烂了，我们也说过，下面就说说LeNet1吧。</p><p>其实LeNet1之前还有一个网络，使用的输入大小为16*16，有9298个样本，网络结构共包含3个隐藏层，分别是H1，H2，H3，感兴趣可以去对应文末参考链接找资料。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bd0b594053c6cb62388178ef3413d52c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"381\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-bd0b594053c6cb62388178ef3413d52c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;381&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"381\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-bd0b594053c6cb62388178ef3413d52c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-bd0b594053c6cb62388178ef3413d52c_b.jpg\"/></figure><p>LeNet1的结构长上面这样，一看就是<b>“LeCun亲生的儿子”</b>，和大家见惯不惯的LeNet5很像了吧，下面把LeNet5也放出来看看。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"320\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;320&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"320\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5d47fc499da107020dc0203bd49ff0c5_b.jpg\"/></figure><p>无非就是输入图像大小，网络宽度，深度的调整，这其实反映了当时束缚神经网络发展的一个关键，<b>硬件计算能力，因为反向传播理论早就成熟了。</b></p><p><b>看来，出来混，还得有一身好装备。</b><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4f37b8457c53ebef7506ca28c7525a69_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"550\" data-rawheight=\"368\" class=\"origin_image zh-lightbox-thumb\" width=\"550\" data-original=\"https://pic2.zhimg.com/v2-4f37b8457c53ebef7506ca28c7525a69_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;550&#39; height=&#39;368&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"550\" data-rawheight=\"368\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"550\" data-original=\"https://pic2.zhimg.com/v2-4f37b8457c53ebef7506ca28c7525a69_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4f37b8457c53ebef7506ca28c7525a69_b.jpg\"/></figure><p>后面要说的，就不在这篇文章里了，尽情期待。</p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote>参考资料</blockquote><p>[1] Hubel D H, Wiesel T N. Receptive fields, binocular interaction and functional architecture in the cat&#39;s visual cortex[J]. The Journal of physiology, 1962, 160(1): 106-154.</p><p>[2] Fukushima K. Neocognitron: A hierarchical neural network capable of visual pattern recognition[J]. Neural networks, 1988, 1(2): 119-130.</p><p>[3] Waibel A, Hanazawa T, Hinton G, et al. Phoneme recognition using time-delay neural networks[M]//Readings in speech recognition. 1990: 393-404.</p><p>[4] <a href=\"https://link.zhihu.com/?target=https%3A//medium.com/%40sh.tsang/paper-brief-review-of-lenet-1-lenet-4-lenet-5-boosted-lenet-4-image-classification-1f5f809dbf17\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">medium.com/@sh.tsang/pa</span><span class=\"invisible\">per-brief-review-of-lenet-1-lenet-4-lenet-5-boosted-lenet-4-image-classification-1f5f809dbf17</span><span class=\"ellipsis\"></span></a></p>", 
            "topic": [
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }, 
                {
                    "tag": "图像处理", 
                    "tagLink": "https://api.zhihu.com/topics/19556376"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/49315281", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 12, 
            "title": "【技术综述】深度学习新手如何开始合适的“调参”任务", 
            "content": "<p>首发于微信公众号《与有三学AI》</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030265%26idx%3D1%26sn%3D06f47c6bd9859e42bc67f921a7b40e3e%26chksm%3D87134004b064c912474e4f7b3e9c1832e5b03dee348c4086066bb24dbf970864f2b201aad193%26token%3D1621903202%26lang%3Dzh_CN%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】深度学习新手如何开始合适的“调参”任务</a><p><br/>深度学习工程师被称为“炼丹工程师”，自然是因为在日常工作中需要各种各样的调参工作。虽然因为Google的研究使得AutoML这两年大热，但是对于大部分人来说，还没有机器玩得起AutoML，而且手动调参数也是一门必备的技能。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>试问：连调试参数都要交给电脑了，就你那三脚猫的python语言基础和弱不禁风的数学基础，端得起一碗高薪的饭吗！</b></p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote><b>1 任务选择</b></blockquote><p>要学习调试参数，必须有一个比较好的任务，它一定是要有一定的难度，但是不能太难。<b>它能体现出不同参数的差异，但又不能太敏感</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>这里我给大家选了一个任务，<b>细粒度图像分类，方法选择双线性网络</b>，参考git链接</p><p><a href=\"https://link.zhihu.com/?target=https%3A//github.com/gy20073/compact_bilinear_pooling\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/gy20073/comp</span><span class=\"invisible\">act_bilinear_pooling</span><span class=\"ellipsis\"></span></a>。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>所谓细粒度图像分类，就是要将不同子类区分，通常来说，有不同种类的猫，不同种类的花等等，这里我们选择了一个公开数据集，选择的数据集为<b>Caltech-UCSD Birds-200-2011</b>，它包括200类鸟，共11788张图片，每一个类约60个样本，图片的分辨率大小不等，长度都在400分辨率左右。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>将数据集均匀分为训练集和测试集，各<b>10597和1192张图</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-eb3a9d6b29e1691890599192a193e1f3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"419\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-eb3a9d6b29e1691890599192a193e1f3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;419&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"419\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-eb3a9d6b29e1691890599192a193e1f3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-eb3a9d6b29e1691890599192a193e1f3_b.jpg\"/></figure><p>它的任务就是要区分上面的鸟，特点就是<b>有效的信息只存在于很细小的局部区域中</b>。关于分类任务，更多的信息请关注我们上一篇文章，图像分类绝对不是一个简单的任务，请重视。</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030111%26idx%3D1%26sn%3D77e67f92dbf172bcf5bac96576864782%26chksm%3D871343a2b064cab4e05f5380345b51dc8f14e8f09d0c789e9218df828445685bc2cacfc378da%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】你真的了解图像分类吗？</a><p>话不多说，开始吧。</p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote><b>2 开始调参</b></blockquote><p>深度学习参数真的太多了，这个参数不是说神经元的参数，而是说用于训练网络的参数。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7189dd8e1f6d12055bc528178c379d65_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"926\" data-rawheight=\"442\" class=\"origin_image zh-lightbox-thumb\" width=\"926\" data-original=\"https://pic2.zhimg.com/v2-7189dd8e1f6d12055bc528178c379d65_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;926&#39; height=&#39;442&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"926\" data-rawheight=\"442\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"926\" data-original=\"https://pic2.zhimg.com/v2-7189dd8e1f6d12055bc528178c379d65_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7189dd8e1f6d12055bc528178c379d65_b.jpg\"/></figure><p>上图只是展示了其中一些比较重要的参数，实际上随便数数20个以上是没有问题的。咱们时间机器有限不可能所有的都调试，今天就来调试其中的几个最重要的，<b>迁移学习，分辨率以及正则项</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>2.1 迁移学习</b></p><p><b>如果你想快速训练好一个任务，那么请从迁移学习开始，不要从头开始训练，尤其是新手。</b></p><p>一个好的初始化太重要了，迁移学习就是给你提供了一个<b>绝佳的初始化</b>。</p><p>咱们这个任务是非常难的，因为类别多，数据少，而且类内方差很大，所以我们开始进行迁移学习的时候，不妨保守一点，只学习全连接层。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8ac88824c3413cb7a35a12a610513a1e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"682\" class=\"origin_image zh-lightbox-thumb\" width=\"800\" data-original=\"https://pic3.zhimg.com/v2-8ac88824c3413cb7a35a12a610513a1e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;800&#39; height=&#39;682&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"800\" data-rawheight=\"682\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"800\" data-original=\"https://pic3.zhimg.com/v2-8ac88824c3413cb7a35a12a610513a1e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8ac88824c3413cb7a35a12a610513a1e_b.jpg\"/></figure><p>注意这个任务的最后几层如上，分别是一个双线性网络层和两个归一化层，一个全连接层，训练参数如下，完整的网络配置请参照git。<br/></p><div class=\"highlight\"><pre><code class=\"language-text\">test_iter: 300\ntest_interval: 600\ndisplay: 100\nmax_iter: 60000\nlr_policy: &#34;multistep&#34;\nbase_lr: 0.1\ngamma: 0.25\nstepvalue: 20000\nstepvalue: 30000\nstepvalue: 40000\nstepvalue: 50000\nmomentum: 0.9\nweight_decay: 0\nsnapshot: 10000\nsnapshot_prefix: &#34;snapshot/ft_last_layer&#34;\nnet: &#34;ft_last_layer.prototxt&#34;\niter_size: 4</code></pre></div><p>经过了60000次迭代后，查看下训练的准确率迭代曲线和损失迭代曲线如下</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-815bb31561cc5fd5b76afb107b95cc49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-815bb31561cc5fd5b76afb107b95cc49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-815bb31561cc5fd5b76afb107b95cc49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-815bb31561cc5fd5b76afb107b95cc49_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-ced0c89beeb542ba35947bad742d9ae0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-ced0c89beeb542ba35947bad742d9ae0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-ced0c89beeb542ba35947bad742d9ae0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-ced0c89beeb542ba35947bad742d9ae0_b.jpg\"/></figure><p>可以看出，网络发生了过拟合，这也是在预料之中，因为训练集中每一类的图像只有60张左右，而数据增强只做了随机裁剪，而且是在全图经过了缩放之后的裁剪操作。</p><p>最后，我们对数据集进行了测试，准确率为74.5%。</p><p>我们再放开所有网络层进行学习，具体配置如下</p><div class=\"highlight\"><pre><code class=\"language-text\">test_iter: 300\ntest_interval: 100\ndisplay: 100\nmax_iter: 20000\nlr_policy: &#34;fixed&#34;\nbase_lr: 0.001\nmomentum: 0.9\nweight_decay: 0.0005\nsnapshot: 10000\nsnapshot_prefix: &#34;snapshot/ft_all&#34;\nnet: &#34;ft_all.prototxt&#34;</code></pre></div><p>结果如下</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-90025035db927f11c317cbda733c5223_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-90025035db927f11c317cbda733c5223_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-90025035db927f11c317cbda733c5223_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-90025035db927f11c317cbda733c5223_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ede40b3a886dfdad99e717ce910138be_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ede40b3a886dfdad99e717ce910138be_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ede40b3a886dfdad99e717ce910138be_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ede40b3a886dfdad99e717ce910138be_b.jpg\"/></figure><p>可以看到，损失继续降低，同时精度也继续提升，20000次迭代后准确率从<b>74.5%</b>提升到<b>86.8%</b>。当然，模型仍然是过拟合的，这是因为样本数据集是在太小，只有增加数据集，实验更多的数据增强方法才能更好的解决这个问题。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>关于数据集和数据增强方法，请查看往期文章。</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030010%26idx%3D1%26sn%3D76e0123bf24064c4cb1eb7acacac86fd%26chksm%3D87134307b064ca1169f6412000bd44da1852ca2854f659fb341356d2d1e61a1c883a555fb0ca%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【数据】深度学习从“数据集”开始</a><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029048%26idx%3D1%26sn%3Dec708683cb6a3c2ed048a945a7150b79%26chksm%3D871347c5b064ced3fd3d57c5c79df0087890efb10898076efb14e9ece8ddf38906dbaf33af2c%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[综述类] 一文道尽深度学习中的数据增强方法（上）</a><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029110%26idx%3D1%26sn%3D4debbbe890b48ab739fec5967868746b%26chksm%3D8713478bb064ce9da68dd57b419ddebd22884c05747abb9286c1e5bc6563702f2a1fd4bcac64%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】深度学习中的数据增强（下）</a><p><br/>那可不可以直接对所有层进行学习呢，没问题，可以收敛的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-85f6218c7f20ba535174c13d3ff39345_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-85f6218c7f20ba535174c13d3ff39345_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-85f6218c7f20ba535174c13d3ff39345_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-85f6218c7f20ba535174c13d3ff39345_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-0b8a8474fef110120af262874531dc08_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-0b8a8474fef110120af262874531dc08_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;810&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"810\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-0b8a8474fef110120af262874531dc08_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-0b8a8474fef110120af262874531dc08_b.jpg\"/></figure><p>但是效果就要差一些了，最终只能到<b>0.79</b>。</p><p><b>那不用双线性模型，直接使用分类模型如何？我的实验结果是很差，惨不忍睹，这里就不放出来了，而且非常难调参。</b></p><p>从这一次的调参至少可以得到一个结论，<b>迁移学习是很重要的，妥妥的提升性能</b>。而且其中的技巧非常多，只能多去练手了，看文章是学不到的。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>2.2 输入输出分辨率</b></p><p>如果你的模型没毛病，但是效果始终不好，<b>不如提高分辨率，当然这意味着更大的计算量。</b></p><p>通常来说，更大的输入分辨率总是可以取得更好的效果，尤其是对于检测和分割等任务。在我们这个任务中，还可以调整双线性网络的输出特征维度大小，这可以认为是输出维度，也可能是一个比较关键的参数。</p><p>所以我们<b>同时对输入分辨率和双线性网络的输出层的维度</b>进行一系列实验，输入尺度分别选用448，336，224这3个，输出维度分别选用8192，4096，2048，1024，保持其他参数不变，迭代60000次，测试结果如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a75d2619391b977a61886d82a5a39d75_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"305\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-a75d2619391b977a61886d82a5a39d75_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;305&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"305\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-a75d2619391b977a61886d82a5a39d75_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a75d2619391b977a61886d82a5a39d75_b.jpg\"/></figure><p>可以看出，图像的分辨率对模型性能的影响非常大，从448降低到224之后，准确率下降了将近10%。双线性输出特征层的维度，从8192降低到1024后，只有微小的下降，几乎对性能没有影响，当然这并不意味着其他的任务也是如此，事实上对于图像分割和目标检测任务来说，<b>最后一层卷积输出的特征图大小是最重要的参数</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>2.3 正则化因子</b></p><p>当模型在训练集上的表现明显优于测试集的时候，说明发生了过拟合，缓解过拟合最简单的方法是增加数据。当增加数据的方案行不通的时候，可以通过添加L1，L2，dropout等正则化方案，这分别是隐式正则化和显式正则化方法。</p><p>在caffe框架中，通过调整Weight_decay来实现，默认使用的是L2正则化方法。Weight_decay是乘在正则化项的因子，这一般可以提高模型的能力，一定程度上缓解模型的过拟合，但是视不同任务而定，我们在前面训练模型的时候没有加正则项。</p><p>分别比较weight_decay=0，weight_decay=0.00001, weight_decay=0.001对结果的影响，其中weight_decay=0对应的就是第一个训练的基准模型。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-cc5cab3b63f748a1736bd63b0f2b9287_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"234\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-cc5cab3b63f748a1736bd63b0f2b9287_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;234&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"234\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-cc5cab3b63f748a1736bd63b0f2b9287_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-cc5cab3b63f748a1736bd63b0f2b9287_b.jpg\"/></figure><p>没有取得我们预期的效果，可能是wr的参数试的不够多，可能是其他的参数需要调试。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-98d6e79342c1b950b2634ee0de1b8a0d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-98d6e79342c1b950b2634ee0de1b8a0d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;480&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"480\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-98d6e79342c1b950b2634ee0de1b8a0d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-98d6e79342c1b950b2634ee0de1b8a0d_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f8369300683de4dba9e09153dd12473c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"616\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-f8369300683de4dba9e09153dd12473c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;616&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"616\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-f8369300683de4dba9e09153dd12473c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-f8369300683de4dba9e09153dd12473c_b.jpg\"/></figure><p>wr=0.001的时候曲线如上，可以看到模型相比于上面的一些更好的模型，提前收敛了，但是却收敛到了不好的效果，过拟合情况更加严重。</p><p>这个时候应该怎么做呢？在数据集不能变的情况下，调节学习率？还是继续调节正则化因子，只有实验结果才能验证了。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>除去上面这些参数，还有<b>学习率大小与迭代方法，batch size大小，初始化方法与各种优化方法，数据增强</b>等各种参数，其中有一些参数对结果还是很有影响的，就留着读者自己去调试吧。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>更多任务与参数调试，可以参考以前的一篇文章。</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649028744%26idx%3D1%26sn%3D49425665ad69c96f33a60e6f0fe50cde%26chksm%3D871346f5b064cfe393445c6fc8ffa0b159df03eecf007dfa4ba4866dac0fa644ef92cf2bf80a%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">如何步入深度学习刷榜第一重境界</a><p class=\"ztext-empty-paragraph\"><br/></p><p><i><b>最后说一下我的感受，纸上得来终觉浅，绝知此事要躬行，虽然调参数有一定的指导，但是唯有多练手才能熟能生巧。</b></i></p><p class=\"ztext-empty-paragraph\"><br/></p><p>时间原因，以后我不可能每天产出高质量文章，还请大家耐心等待，另外更多的经历在一对一指导学习“济”划和“稷”划，感兴趣可以了解。</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029953%26idx%3D1%26sn%3D87bc2c98d88373b33c495c101ebf46d3%26chksm%3D8713433cb064ca2ae619da27f865ff94f411315f45290624afe0ecf38b301b9d3c6af5bf2a75%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">有三AI“【济】划”，从图像基础到深度学习</a><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030212%26idx%3D1%26sn%3D1531ba86f0387085ffc54bdb02b746cf%26chksm%3D87134039b064c92f67643736e928c5a9d437b6fa1ae462eb4723a70e75cff3b8f01cfdb9bc9d%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">有三AI“十一月【稷】划”，从调参大法到3D重建</a><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029945%26idx%3D1%26sn%3D68c889bf9f99f69d53cb090b3e90fba9%26chksm%3D87134344b064ca52fd5fdf75d62ad2696093410855a556ff5942d45f264a290251ae6b37b336%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">有三AI“十月【稷】划”，从自动驾驶到模型优化</a><p><b>深度学习网易公开课</b>已经上线，看有三从不一样的视角来解读深度学习，<b>特价2折，仅限今天。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6f778d632b96a5019658eabc88481d0d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"880\" data-rawheight=\"2339\" class=\"origin_image zh-lightbox-thumb\" width=\"880\" data-original=\"https://pic2.zhimg.com/v2-6f778d632b96a5019658eabc88481d0d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;880&#39; height=&#39;2339&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"880\" data-rawheight=\"2339\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"880\" data-original=\"https://pic2.zhimg.com/v2-6f778d632b96a5019658eabc88481d0d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6f778d632b96a5019658eabc88481d0d_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>有三精选</b></p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030051%26idx%3D1%26sn%3Dd3f561d640ae976fecd4e1a6f1751b3f%26chksm%3D871343deb064cac87de927ffb92f32e17bcf0af63bf7a2f5b6b8c4dea5aaf9c3feefb166fd20%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】“看透”神经网络</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030061%26idx%3D1%26sn%3D94ebe6abb84f8147f650a50832ba6923%26chksm%3D871343d0b064cac6bedad8cdcb4bc39dd8aaefe330153d2ffe59c95ce78ad077677859e36de1%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【有三说图像】图像简史与基础</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029723%26idx%3D1%26sn%3D555a2d45fa210a1c5c5c703de54899a4%26chksm%3D87134226b064cb30f070ea5a2368f1c5bb6679d0f13e7e84b3f6374be33c549ce81a665d6e25%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】闲聊图像分割这件事儿</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649028860%26idx%3D1%26sn%3Dec1056fce8a00d14ad43cc0ac9c39b84%26chksm%3D87134681b064cf9742cd52dc5e68d585ac143fc237393e14d892c40d559621a682e467416312%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】一文道尽softmax loss及其变种</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029920%26idx%3D1%26sn%3D91b85918937936fc2f9ad8732dbd3230%26chksm%3D8713435db064ca4b3f1ae51a9e464cdf930084f2202b7659930c9fd4d5becc8db751aaa31f6f%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【总结】这半年，有三AI都做了什么</a></li></ul><p><b>往期学员分享</b></p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029493%26idx%3D1%26sn%3D3a6442bfbc2f1a917420adc3eed91272%26chksm%3D87134508b064cc1ed0e23cee897946f7a7bd4dbd43e8516cc74a6760431229da7909006bf40a%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】人脸表情识别研究</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029732%26idx%3D1%26sn%3Da561a279eb8508482b8924d18dea1b03%26chksm%3D87134219b064cb0f02f5e81664ebc72eae590893d1780af91424e0618b7af5d77e26c4d8d819%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">一课道尽人脸图像算法，你值得拥有</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029586%26idx%3D1%26sn%3D0656db9c8fbc46cd7730618b44cae4d6%26chksm%3D871345afb064ccb9da37071f47d1ed109cbfcb6b476cce93dd220c6bcd1c7d287150357e6b2d%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">如何降低遮挡对人脸识别的影响</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029259%26idx%3D1%26sn%3D4a981973b57fd1ba77049163bd886683%26chksm%3D871344f6b064cde0003d960ad49ea27d89497e38fd4af555ab9e2c9b6c72c46f186c770e9edf%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【技术综述】人脸颜值研究综述</a></li></ul><p><b>往期开源框架</b></p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029881%26idx%3D1%26sn%3D3c869fcee3b48d3582952ab9a0683ea6%26chksm%3D87134284b064cb924c5e7231b3f2c36ba27e3a689b067f569f2e086f62b18413bcebc5987a07%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【pytorch速成】Pytorch图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029887%26idx%3D1%26sn%3D645b97809c24922352a0b39f19c9ef0c%26chksm%3D87134282b064cb9441af68124d205d9c7dedcaeb09788f4d586b949584e556eddd3a72217f69%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【paddlepaddle速成】paddlepaddle图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029846%26idx%3D1%26sn%3D0c343cfd0ede5c8ae1405bd6348aefad%26chksm%3D871342abb064cbbd7fe31fb3c55f23875f27e48fb8354e9855823b1701f1227c71b4eb00de50%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【caffe速成】caffe图像分类从模型自定义到测试</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029846%26idx%3D2%26sn%3D7c2582243bcd8f8b491e8e466a21978f%26chksm%3D871342abb064cbbd0cba24b408ceda2b64a7c8b6baa07f9f8f56cd4d1233caa0b80fe357753e%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【tensorflow速成】Tensorflow图像分类从模型自定义到测试</a></li></ul><p><b>往期行业分析</b></p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029532%26idx%3D1%26sn%3Df37927110efaedf216ad89240786127d%26chksm%3D871345e1b064ccf71829f1c789878117f1ed2e3adb865fce14fe266525c115cae3473a5bd415%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【行业进展】国内自动驾驶发展的怎么样了？</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029421%26idx%3D1%26sn%3D3e5e1c1072384ede09137e4948c3525a%26chksm%3D87134550b064cc46ec84c658ff1b6b174a322989c38cc01a808370d1bafcdb49261fc6866267%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【行业进展】AI：新药研发的新纪元</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029301%26idx%3D1%26sn%3D4d5db235e5a593fa920a148553427139%26chksm%3D871344c8b064cddea8e05b446b5ea61e6a62525f1370d38447bef5e3eaba8007ccaa3afe1268%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【行业进展】哪些公司在搞“新零售”</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649030156%26idx%3D1%26sn%3D49ebcd54a675245d6319ac9973891efb%26chksm%3D87134071b064c96754130ef87ade7af0002fea94e1e5f21e8796a076ce9ae1355c1182b52fbf%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【行业趋势】国内这10个AI研究院，你想好去哪个了吗？</a></li></ul><p><b>往期模型解读</b></p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></li></ul>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "Caffe（深度学习框架）", 
                    "tagLink": "https://api.zhihu.com/topics/20019488"
                }, 
                {
                    "tag": "人工智能算法", 
                    "tagLink": "https://api.zhihu.com/topics/19691108"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>请教一下鹏哥，第一组曲线，怎么看出过拟合了，感觉最后还是有下降的？</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<p>从训练集和测试集的精度来看，存在较大的过拟合</p>", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "高体红", 
                    "userLink": "https://www.zhihu.com/people/6ae3487f5d63421653760db909ad8531", 
                    "content": "您好，请教两个问题，<br>1,最后两个图中，验证损失(或精度)和测试损失（或精度）开始叠加，并且一直持续叠加状态，为什么还是过拟合呢？<br>2.最后调整的wr是什么意思呢？<br>谢谢。", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "wr就是weight decay，其实训练集测试集还是有差异的", 
                            "likes": 0, 
                            "replyToAuthor": "高体红"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/46059911", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 2, 
            "title": "【模型解读】从“局部连接”回到“全连接”的Non-Local神经网络", 
            "content": "<p>文章首发于《有三AI》</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D791966861%26lang%3Dzh_CN%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a><p>这是深度学习模型解读第9篇，本篇我们简单介绍非局部神经网络。</p><p>与全连接神经网络相比，卷积神经网络在每一层是局部的，采用了较小的卷积核，感受实际对应到原始图像空间较大的区域，而且随着网络的加深，感受野增加。但是感受野毕竟不是全图，在降采样的过程中也会丢失信息。</p><p>那为什么还要这么做呢？首先这是计算量的限制，卷积核越大计算量越大，而且会存在非常多的冗余。另外，这也是模仿人眼的分层视觉理论，即不断加深抽象层级。</p><p>虽然网络结构从全连接进化到局部连接后才有了现在的发展，但并不意味着拥有更大视野的全连接就没有用了，至少Non-local networks又开始重新思考这个问题。</p><h2><b>1 什么是Non-Local Networks</b></h2><p>这背后的核心思想是non-local，说到non-local又得提一下经典的non-local means滤波算法。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-75b7bdfd0cc2742d22111ba81bb71b7d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"932\" data-rawheight=\"274\" class=\"origin_image zh-lightbox-thumb\" width=\"932\" data-original=\"https://pic2.zhimg.com/v2-75b7bdfd0cc2742d22111ba81bb71b7d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;932&#39; height=&#39;274&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"932\" data-rawheight=\"274\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"932\" data-original=\"https://pic2.zhimg.com/v2-75b7bdfd0cc2742d22111ba81bb71b7d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-75b7bdfd0cc2742d22111ba81bb71b7d_b.jpg\"/></figure><p>假设输入是f，输出是g，一个经典的局部滤波算子如上，它是只在一个邻域内的加权平均，所以称之为local滤波方法，实际上上面是双边滤波的公式。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-16e024598767ee52ee7fe728c170e6f3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1038\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-16e024598767ee52ee7fe728c170e6f3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1038&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1038\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-16e024598767ee52ee7fe728c170e6f3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-16e024598767ee52ee7fe728c170e6f3_b.jpg\"/></figure><p>而non-local顾名思义，将这个邻域扩展到全图。如上图p作为中心像素，q1，q2，q3对p的滤波都有贡献，实际上图像上任意一个点都有贡献。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-16e024598767ee52ee7fe728c170e6f3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1038\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-16e024598767ee52ee7fe728c170e6f3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1038&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1038\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-16e024598767ee52ee7fe728c170e6f3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-16e024598767ee52ee7fe728c170e6f3_b.jpg\"/></figure><p>借用论文中的公式如上，很简单，关键就在这个f如何定义。传统的最好的图像降噪算法BM3D，就是non-local means方法，它通过计算不同图像块的相似性来获得权重。</p><h2><b>2 为什么需要Non-local </b></h2><p>在正式说如何实现时，先来总结一下为什么我们需要这个non-local连接。</p><p>首先我们要看现在的CNN是怎么做的，为了能够捕捉到更大的感受野，现在的CNN是通过不断加深网络，逐步增加感受野的方案，RNN则是通过循环的方式处理序列输入（如视频帧序列或者图片上一行一列等空间序列），从而融合非局部的信息，它们都有几个缺点。</p><p><b>(1)  计算效率不高，这是肯定的，明明可以一步到位，却去增加了网络深度。</b></p><p><b>(2)  感知效率不高，虽然感受野可以通过深度增加，但这个增加是有限的，实际上感受野并没有理论计算出来那么大，很多的长程的信息依然获取不到。</b></p><p><b>(3)  增加优化难度，我们知道随着网络的加深，网络的优化会面对各种梯度问题。</b></p><p>而更大的感受野对于视频图像中的场景理解，跟踪，语音识别等时序问题都是必要的。因此我们需要一个Non-Local连接，而non-local也有理由表现得更好，就好比Non-Local means方法比local filter方法去噪更强，dense crf比普通的crf更强一样。</p><h2><b>3 怎么实现</b></h2><p>首先要说明的是，non-local可以是只在图像空间上的non-local，也可以是不同时间帧上的non-local，甚至是两者的融合，不过理解起来都是一样的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3a941a621a6f314b6b855e305fe7f17e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"887\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-3a941a621a6f314b6b855e305fe7f17e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;887&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"887\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-3a941a621a6f314b6b855e305fe7f17e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-3a941a621a6f314b6b855e305fe7f17e_b.jpg\"/></figure><p>上面展示的是一个视频数据的block，首先我们要注意，non-local-block可以作为基础的block嵌入到现有的模块，因为它的输入与输出相等，都是T*H*W*1024。</p><p>其中1024是通道数，T就是时间帧数。⊗是矩阵乘法，⊕是逐像素相加。</p><p>我们看上面的图，f的操作，对应的就是输入T*H*W*512与512*THW矩阵相乘输出THW*THW的模块。可以看到，f(.)的操作就是每个通道上每个点的特征向量进行内积，空间信息保留了下来，输出还是HxW大小。</p><p>另外上面的设计采用了残差的方式，所以可以轻松地嵌入现有的任何网络。</p><p>一如既往，咱们没有贴实践效果。从理论猜想和作者的实验结果都可以看出，对于视频分类non-local比对应的local网络效果会更好，这是必然的，视频中的主体空间移动速度非常快，如果没有大的感受野未必能很鲁棒的捕捉一个动作到底是跳高还是跳水。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b937080fff94844208fb2f9acb2b90c5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"358\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b937080fff94844208fb2f9acb2b90c5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;358&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"358\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-b937080fff94844208fb2f9acb2b90c5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b937080fff94844208fb2f9acb2b90c5_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5e4b19c8451bdd207a26b99b1295c8a3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-5e4b19c8451bdd207a26b99b1295c8a3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;326&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-5e4b19c8451bdd207a26b99b1295c8a3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5e4b19c8451bdd207a26b99b1295c8a3_b.jpg\"/></figure><p>依据作者们的结论，在网络浅层效果会更好，我想这也是可以理解的，毕竟随着网络深度增加，感受野增加了。</p><p>更多的实践，放心，随着咱们这个系列接近尾声，实践也快来了，不过你可能需要补一补以前的知识了。</p><p>参考文献</p><p>【1】Wang X, Girshick R, Gupta A, et al. Non-local neural networks[C]//The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2018.</p><p><b>十月开始，我们有三AI学院开启了“济”划，帮助想入行以及想取得更多实战经验的同学。内容覆盖从自动驾驶到美颜直播等领域的实战项目，从图像基础到深度学习理论的系统知识，欢迎关注。</b></p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029953%26idx%3D1%26sn%3D87bc2c98d88373b33c495c101ebf46d3%26chksm%3D8713433cb064ca2ae619da27f865ff94f411315f45290624afe0ecf38b301b9d3c6af5bf2a75%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">有三AI“【济】划”，从图像基础到深度学习</a><p class=\"ztext-empty-paragraph\"><br/></p><p>咱们这个系列的完整目录：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>另外：咱们还有一个专栏专门讲述：</p><a href=\"https://zhuanlan.zhihu.com/c_1005865351275573248\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-f32626bd7c13e7b9d294ad9ba0e7fb9e_ipico.jpg\" data-image-width=\"500\" data-image-height=\"500\" class=\"internal\">有三AI学院-深度学习模型优化</a><p></p><p></p>", 
            "topic": [
                {
                    "tag": "模型", 
                    "tagLink": "https://api.zhihu.com/topics/19579715"
                }, 
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/44650570", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 9, 
            "title": "【模型解读】“全连接”的DenseNet卷积网络，有什么好？", 
            "content": "<p>这是深度学习模型解读第8篇，本篇我们简单介绍Densenet。</p><h2><b>1 从skip connect到dense connect</b></h2><p>我们知道，曾经深度网络训练不好收敛，Resnet的出现打破了这一僵局，背后的思想仅仅只是拉了一个skip connect，也就是将输入和输出相连相加，下面是一个resnet18的展示。这个输入输出，可以是刚好相邻的两个卷积block，也可以是跳过若干层的两个。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-993352ed01f7ae24fee772f7fa9d3060_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"578\" data-rawheight=\"1528\" class=\"origin_image zh-lightbox-thumb\" width=\"578\" data-original=\"https://pic1.zhimg.com/v2-993352ed01f7ae24fee772f7fa9d3060_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;578&#39; height=&#39;1528&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"578\" data-rawheight=\"1528\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"578\" data-original=\"https://pic1.zhimg.com/v2-993352ed01f7ae24fee772f7fa9d3060_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-993352ed01f7ae24fee772f7fa9d3060_b.jpg\"/></figure><p>假如，我们再进一步，将这个思想发挥到极致，会怎样？把所有层都与其他所有层相连，也就是说N层的网络，会有(N*N-1)/2个连接，如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-62099a5416b79395be4bd4f66cb98bbd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"753\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-62099a5416b79395be4bd4f66cb98bbd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;753&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"753\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-62099a5416b79395be4bd4f66cb98bbd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-62099a5416b79395be4bd4f66cb98bbd_b.jpg\"/></figure><p>这就是densenet【1】，CVPR 2017最佳论文，可以看作是一个发挥到极致的resnet。</p><h2><b>2 为什么会设计densenet？</b></h2><p>大家如果对resnet理解不够深的话，可以回过头去读我们的上一期对resnet的解读。残差连接的必要性和有效性，在那篇文章中做了很详细的解读。</p><a href=\"https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a><p><br/>神经网络越深，网络的能力越强，就越有可能过度学习数据集，导致过拟合。大家应该还记得，作为第一个深层网络Alexnet网络，它提出了重要的策略dropout，对于提高模型的泛化能力非常有效。alexnet网络至今仍然可以用于很多的任务，这足以说明其鲁棒性。后来BN和数据增强等正则化策略替代dropout也在一定程度上缓解了过拟合的问题。文【2】是densenet作者们早期的研究，它们通过训练时随机丢掉一些网络层，提高了ResNet的泛化性能。</p><p>从这里可以看出来一个重要特性，这也是神经网络中大家比较关心的问题，<b>网络的冗余性绝对是存在的，而且不小</b>，通过探索dropout值的比例对性能的影响可以去估算这个冗余。</p><p>既然丢掉某些层间连接或者整个层不影响性能，就说明这一层学习到的非线性转变很小，既然转变很小，那么每一层学习几百个通道，还有必要吗？这几百个通道，正是万恶的计算量所在。</p><p><b>考虑到这一点，densenet就同时做了两件事情，一是将网络中的每一层都直接与其前面层相连，提高特征的利用率；二是把网络的每一层设计得很窄，也就是卷积的输出通道数通常很小，只有几十，该层学习非常少的特征图并与输入concat使用。</b></p><p>这实现了资源的最大化利用和计算量的压缩。ImageNet分类数据集上达到同样的准确率，DenseNet 所需的参数量不到ResNet的一半，所需的计算量也只有ResNet的一半左右。</p><p>思想就是这么简单，当然，我们在使用的时候，不会真的这么夸张去将所有层都连接起来，更多的是将网络的后面一些层做dense连接。毕竟网络设计的通用思想是网络越深宽度更宽，这里做dense连接对于减小计算量更有意义。</p><h2><b>3 简单思考</b></h2><p><b>人类对深度学习模型只有三个要求，运行速度快，网络模型小，性能好。</b></p><p>提升网络性能，最朴素的方法就是加深加宽网络，但这与前面两者是冲突的。所以，工程师们都在想方设法压榨每一个通道的性能，但又要避免网络发生过拟合。</p><p>既要没用的网络层减少，又要有用的网络层不能太灵敏，那就只有一条路可以走了。充分压榨已有的网络层的性能，让他们充分交流。</p><p>网络发展到现在，早已经不是Lenet，Alexnet，Vggnet这样简单的网络加深的路线，网络各层之间信息的融合，在图像分割（FCN），目标检测(FPN)等任务中都至关重要，看看下面的网络图就知道。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d6f83e6df80629c430539ebf99ae1a19_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"575\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-d6f83e6df80629c430539ebf99ae1a19_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;575&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"575\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-d6f83e6df80629c430539ebf99ae1a19_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d6f83e6df80629c430539ebf99ae1a19_b.jpg\"/></figure><p>                                                                   FCN结构</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-7cc7098cd828af766365e2be241bf2c0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"553\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-7cc7098cd828af766365e2be241bf2c0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;553&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"553\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-7cc7098cd828af766365e2be241bf2c0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-7cc7098cd828af766365e2be241bf2c0_b.jpg\"/></figure><p>                                                                  FPN结构</p><p>不同层之间的连接，融合不同抽象层级的信息，融合不同尺度的信息，densenet将这个发挥到了极致，就这么简单。</p><p><br/>参考文献</p><p>【1】Huang G, Liu Z, Van Der Maaten L, et al. Densely Connected Convolutional Networks[C]//CVPR. 2017, 1(2): 3.</p><p>【2】Huang G, Sun Y, Liu Z, et al. Deep networks with stochastic depth[C]//European Conference on Computer Vision. Springer, Cham, 2016: 646-661.</p><p>这个咱们这个系列的完整目录：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>另外：咱们还有一个专栏专门讲述：</p><a href=\"https://zhuanlan.zhihu.com/c_1005865351275573248\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-f32626bd7c13e7b9d294ad9ba0e7fb9e_ipico.jpg\" data-image-width=\"500\" data-image-height=\"500\" class=\"internal\">有三AI学院-深度学习模型优化</a><p></p>", 
            "topic": [
                {
                    "tag": "卷积", 
                    "tagLink": "https://api.zhihu.com/topics/19678959"
                }, 
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/44388548", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 6, 
            "title": "【模型解读】“不正经”的deformable卷积神经网络", 
            "content": "<p>这是深度学习模型解读第7篇，本篇我们将介绍不规则形状的卷积。</p><h2><b>1 卷积中的不变性</b></h2><p>图像任务，都需要识别出图像中的主体，用于分类，检测，分割，比如下面的验证码识别。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-87505428a14b09c53bc90b1731000afa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"309\" data-rawheight=\"163\" class=\"content_image\" width=\"309\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;309&#39; height=&#39;163&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"309\" data-rawheight=\"163\" class=\"content_image lazy\" width=\"309\" data-actualsrc=\"https://pic3.zhimg.com/v2-87505428a14b09c53bc90b1731000afa_b.jpg\"/></figure><p>但是同样的目标，在不同的图片中，<b>会存在位置的偏移，角度的旋转，尺度的大小</b>。卷积神经网络要能够应对这些情况，比如分类任务，对于同样的目标在不同图像中的偏移，旋转，尺度，要输出同样的结果。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-50d1f3dd1817a222a2e635d716d4b4f2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"865\" data-rawheight=\"526\" class=\"origin_image zh-lightbox-thumb\" width=\"865\" data-original=\"https://pic3.zhimg.com/v2-50d1f3dd1817a222a2e635d716d4b4f2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;865&#39; height=&#39;526&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"865\" data-rawheight=\"526\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"865\" data-original=\"https://pic3.zhimg.com/v2-50d1f3dd1817a222a2e635d716d4b4f2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-50d1f3dd1817a222a2e635d716d4b4f2_b.jpg\"/></figure><p>这便是我们常说的<b>旋转，平移，尺度不变性了</b>。</p><p>cnn有这个能力吗？有。</p><p>前面我们说过pooling，它有一定的平移不变性，而且网络越深，越强大。但是，它的这个能力仍然是有限的，受卷积核大小和感受野大小的约束。</p><p>尺度不变性和旋转不变性呢？很遗憾，几乎没有，不然Hinton也不会搞capsule。</p><p>我们通常做的随机裁剪，旋转，缩放等操作，就是利用了cnn强大的学习能力，制造出了各种版本的图片供其学习。为了模型的鲁棒性，需要生成大量的数据。</p><p><b>一句话，网络模型对于物体几何形变的适应能力几乎完全来自于数据本身所具有的多样性。</b></p><h2><b>2 为什么呢？</b></h2><p>前面我们说了问题，那为什么会这样呢？因为cnn就没有显式地学习这些信息，而卷积操作本身具有非常固定的几何结构，标准的卷积操作是一个非常规矩的采样，通常是正方形。</p><p>那，能不能不规矩呢？首先我们看什么是不规矩，下图来自于【1】。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-991c9dcbd46b098141dd3ded28110185_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"834\" data-rawheight=\"261\" class=\"origin_image zh-lightbox-thumb\" width=\"834\" data-original=\"https://pic2.zhimg.com/v2-991c9dcbd46b098141dd3ded28110185_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;834&#39; height=&#39;261&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"834\" data-rawheight=\"261\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"834\" data-original=\"https://pic2.zhimg.com/v2-991c9dcbd46b098141dd3ded28110185_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-991c9dcbd46b098141dd3ded28110185_b.jpg\"/></figure><p>a图大家很熟悉，标准的3*3卷积核，而b，c，d虽然也是9个采样点，但是每个采样点相对于中心点的偏移与a很不一样。b是一个通用的展示，即完全没有规律。c，d是b的特例。</p><p><b>我们将这样的卷积，称为（deformable convolutional networks）可变形卷积，笔者更喜欢称之为“不正经卷积”。</b></p><p>这种“不正经卷积”的特点，1是采样视野大于对应版本的标准卷积（带孔卷积不算），2是它的感受野是不规则的形状。</p><p>有什么好处呢？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-636977caa2e8dd3b7e64ba66b54bf870_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"615\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-636977caa2e8dd3b7e64ba66b54bf870_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;615&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"615\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-636977caa2e8dd3b7e64ba66b54bf870_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-636977caa2e8dd3b7e64ba66b54bf870_b.jpg\"/></figure><p>我们看上面的一张图，假如我们有一个分割任务，要分割出图中的尺度不同的动物。</p><p>我们先看左边的图，标准的卷积，感受野必然是一个方方正正的区域。顶图有一个中心像素，它的感受野是3*3，到了中间的图，周围四个角点又可以进一步扩展感受野，直到底部的图。</p><p>所以对于顶部目标的中心像素，经历了两次3*3卷积，它的感受野是固定的5*5，与动物本身的形状并不匹配。而同样的两个3*3的卷积，右边的“不正经卷积”，则由于灵活的感受野，所覆盖的区域更大，也更匹配了目标本身的形状。</p><p>这是一个非常通用的问题，标准卷积对目标的形状感受野不够灵活，卷积的效率自然也就下降。而可变形卷积则利用了不规则可变化的形状，改善了这两个问题。</p><h2><b>3 怎么实现？</b></h2><p>可变形卷积这么灵活，实现起来麻烦吗？答案是不麻烦，只需要增加一个偏移量即可，具体来说看下图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-28207230d8f5d05476645a93a0f32ff3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1020\" data-rawheight=\"724\" class=\"origin_image zh-lightbox-thumb\" width=\"1020\" data-original=\"https://pic4.zhimg.com/v2-28207230d8f5d05476645a93a0f32ff3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1020&#39; height=&#39;724&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1020\" data-rawheight=\"724\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1020\" data-original=\"https://pic4.zhimg.com/v2-28207230d8f5d05476645a93a0f32ff3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-28207230d8f5d05476645a93a0f32ff3_b.jpg\"/></figure><p>与标准卷积核相比，一个可变形卷积核，用于卷积的像素相对于中心像素各自的x，y方向上的偏移没有了规律，如果我们学习到了这个规律<b>（实际就是用卷积核来记录它）</b>，就完成这件事情了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-3662db1c5a84c4a11ea5860cdc644f29_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"561\" data-rawheight=\"580\" class=\"origin_image zh-lightbox-thumb\" width=\"561\" data-original=\"https://pic2.zhimg.com/v2-3662db1c5a84c4a11ea5860cdc644f29_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;561&#39; height=&#39;580&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"561\" data-rawheight=\"580\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"561\" data-original=\"https://pic2.zhimg.com/v2-3662db1c5a84c4a11ea5860cdc644f29_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-3662db1c5a84c4a11ea5860cdc644f29_b.jpg\"/></figure><p>实际实现就是多了一个offset层，通过offset输出通道数，我们可以控制要学习的变形的种类。当然，这个通道数一定是2N的，因为要同时记录x和y方向。</p><h2><b>4 总结</b></h2><p>做一个简单的总结，首先我们说说好处。(1)增加了网络的空间变形适应性，这也是网络要解决的本质问题。(2)不增加额外的标注信息和训练代价，仍然是原来的数据就可以训练，而且同时训练卷积系数和偏移量。(3)对于复杂的任务提升效果明显，具体的实验结果指标，可以至论文中看，也可以自己训着看。</p><p>坏处主要是增加了参数量与计算量，不过这个计算量其实不大，可以通过分组进行控制。</p><p>值得注意的是，可变形卷积并非是第一个研究这个问题的，在STN【2】中，已经通过Spatial Transformer Layer来实现了对旋转平移缩放等信息的学习。Active Convolution，Atrous convolution等都试图解决类似问题，在此就不一一讲解了，大家可以自己拓展学习。</p><p>参考文献</p><p>【1】Dai J, Qi H, Xiong Y, et al. Deformable convolutional networks[J]. CoRR, abs/1703.06211, 2017, 1(2): 3.</p><p>【2】Jaderberg M, Simonyan K, Zisserman A. Spatial transformer networks[C]//Advances in neural information processing systems. 2015: 2017-2025.</p><p>这个系列的完整目录：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>另外：咱们还有一个专栏专门讲述：</p><a href=\"https://zhuanlan.zhihu.com/c_1005865351275573248\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-f32626bd7c13e7b9d294ad9ba0e7fb9e_ipico.jpg\" data-image-width=\"500\" data-image-height=\"500\" class=\"internal\">有三AI学院-深度学习模型优化</a><p></p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/42833949", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 56, 
            "title": "【模型解读】resnet中的残差连接，你确定真的看懂了？", 
            "content": "<p>这是深度学习模型解读第6篇，本篇我们将介绍深度学习模型中的残差连接。</p><h2><b>1 残差连接</b></h2><p>想必做深度学习的都知道skip connect，也就是残差连接，那什么是skip connect呢？如下图</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bc88ce9d1f45720932dc4db9f5b03608_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"977\" data-rawheight=\"561\" class=\"origin_image zh-lightbox-thumb\" width=\"977\" data-original=\"https://pic1.zhimg.com/v2-bc88ce9d1f45720932dc4db9f5b03608_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;977&#39; height=&#39;561&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"977\" data-rawheight=\"561\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"977\" data-original=\"https://pic1.zhimg.com/v2-bc88ce9d1f45720932dc4db9f5b03608_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-bc88ce9d1f45720932dc4db9f5b03608_b.jpg\"/></figure><p>上面是来自于resnet【1】的skip block的示意图。我们可以使用一个非线性变化函数来描述一个网络的输入输出，即输入为X，输出为F(x)，F通常包括了卷积，激活等操作。</p><p>当我们强行将一个输入添加到函数的输出的时候，虽然我们仍然可以用G(x)来描述输入输出的关系，但是这个G(x)却可以明确的拆分为F(x)和X的线性叠加。</p><p><b>这就是skip connect的思想，将输出表述为输入和输入的一个非线性变换的线性叠加，没用新的公式，没有新的理论，只是换了一种新的表达。</b></p><p>它解决了深层网络的训练问题，作者的原论文中达到了上千层。</p><p>残差连接是何的首创吗？当然不是，传统的神经网络中早就有这个概念，文【2】中则明确提出了残差的结构，这是来自于LSTM的控制门的思想。</p><p>y = H(x,WH)•T(x,WT) + X•(1- T(x,WT))</p><p>可以看出，当T(x,WT) = 0，y=x，当T(x,WT) = 1，y= H(x,WH) 。关于LSTM相关的知识，大家可以去其他地方补。</p><p>在该文章中，研究者没有使用特殊的初始化方法等，也能够训练上千层的网络。但为什么这篇文章没有resnet火呢？原因自然有很多了，何的文章做了更多的实验论证，简化了上面的式子，得了cvpr best paper，以及何的名气更大等等因素。</p><p>总之，为我们所知道的就是下面的式子</p><p><b>y = H(x,WH) + X，此所谓残差连接，skip connection。</b></p><h2><b>2 为什么要skip connect</b></h2><p>那为什么要这么做呢？首先大家已经形成了一个通识，在一定程度上，网络越深表达能力越强，性能越好。<br/>不过，好是好了，随着网络深度的增加，带来了许多问题，梯度消散，梯度爆炸；在resnet出来之前大家没想办法去解决吗？当然不是。更好的优化方法，更好的初始化策略，BN层，Relu等各种激活函数，都被用过了，但是仍然不够，改善问题的能力有限，直到残差连接被广泛使用。</p><p>大家都知道深度学习依靠误差的链式反向传播来进行参数更新，假如我们有这样一个函数：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e84734ed0dedfb9e180f5ccb5893a508_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"426\" data-rawheight=\"242\" class=\"origin_image zh-lightbox-thumb\" width=\"426\" data-original=\"https://pic1.zhimg.com/v2-e84734ed0dedfb9e180f5ccb5893a508_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;426&#39; height=&#39;242&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"426\" data-rawheight=\"242\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"426\" data-original=\"https://pic1.zhimg.com/v2-e84734ed0dedfb9e180f5ccb5893a508_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e84734ed0dedfb9e180f5ccb5893a508_b.jpg\"/></figure><p>其中的f，g，k大家可以自行脑补为卷积，激活，分类器。</p><p>cost对f的导数为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5bfa00259ad50b2bcdc7f553dd283079_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"586\" data-rawheight=\"144\" class=\"origin_image zh-lightbox-thumb\" width=\"586\" data-original=\"https://pic2.zhimg.com/v2-5bfa00259ad50b2bcdc7f553dd283079_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;586&#39; height=&#39;144&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"586\" data-rawheight=\"144\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"586\" data-original=\"https://pic2.zhimg.com/v2-5bfa00259ad50b2bcdc7f553dd283079_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5bfa00259ad50b2bcdc7f553dd283079_b.jpg\"/></figure><p>它有隐患，一旦其中某一个导数很小，多次连乘后梯度可能越来越小，<b>这就是常说的梯度消散</b>，对于深层网络，传到浅层几乎就没了。但是如果使用了残差，<b>每一个导数就加上了一个恒等项1，dh/dx=d(f+x)/dx=1+df/dx</b>。此时就算原来的导数df/dx很小，这时候误差仍然能够有效的反向传播，这就是核心思想。</p><p>我们举个例子直观理解一下：<br/>假如有一个网络，输入x=1，非残差网络为G，残差网络为H，其中H=F(x)+x</p><p>有这样的一个输入输出关系：</p><p>在t时刻：</p><p>非残差网络G(1)=1.1， </p><p>残差网络H(1)=1.1, H(1)=F(1)+1, F(1)=0.1</p><p>在t+1时刻：</p><p>非残差网络G’(1)=1.2， </p><p>残差网络H’(1)=1.2, H’(1)=F’(1)+1, F’(1)=0.2</p><p>这时候我们看看：</p><p>非残差网络G的梯度  = (1.2-1.1)/1.1</p><p>而残差网络F的梯度 = (0.2-0.1)/0.1</p><p>因为两者各自是对G的参数和F的参数进行更新，可以看出这一点变化对F的影响远远大于G，说明引入残差后的映射对输出的变化更敏感，输出是什么？不就是反应了与真值的误差吗？</p><p>所以，这么一想想，残差就应该是有效的，各方实验结果也证明了。</p><h2><b>3 skip connect就只是这样吗</b></h2><p>上面我们解释了skip connect改善了反向传播过程中的梯度消散问题，因此可以使得训练深层网络变得容易，但研究者们表示NoNoNo，没这么简单。</p><p>如今在国内的研究人员，大公司，产品，都醉心于将深度学习用于网络直播和短视频，把整个环境搞的浮躁不堪的情况下，国外有很多的大拿都在潜心研究深度学习理论基础，水平高低之分，可见一斑。文【3】的研究直接表明训练深度神经网络失败的原因并不是梯度消失，而是权重矩阵的退化，所以这是直接从源头上挖了根？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c5e741a03e6392d2f62035d52205ea00_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"461\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c5e741a03e6392d2f62035d52205ea00_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;461&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"461\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-c5e741a03e6392d2f62035d52205ea00_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c5e741a03e6392d2f62035d52205ea00_b.jpg\"/></figure><p>当然，resnet有改善梯度消失的作用，文中也做了实验对比如上：但不仅仅不如此，下图是一个采用残差连接（蓝色曲线）和随机稠密的正交连接矩阵的比对，看得出来残差连接并不有效。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ad4f4437dbd63c8455cc5762290780b2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ad4f4437dbd63c8455cc5762290780b2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;540&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"540\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-ad4f4437dbd63c8455cc5762290780b2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ad4f4437dbd63c8455cc5762290780b2_b.jpg\"/></figure><p>结合上面的实验，<b>作者们认为神经网络的退化才是难以训练深层网络根本原因所在，而不是梯度消散。</b>虽然梯度范数大，但是如果网络的可用自由度对这些范数的贡献非常不均衡，<b>也就是每个层中只有少量的隐藏单元对不同的输入改变它们的激活值，而大部分隐藏单元对不同的输入都是相同的反应，此时整个权重矩阵的秩不高。并且随着网络层数的增加，连乘后使得整个秩变的更低。</b></p><p>这也是我们常说的网络退化问题，虽然是一个很高维的矩阵，但是大部分维度却没有信息，表达能力没有看起来那么强大。</p><p><b>残差连接正是强制打破了网络的对称性。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a2e2f2e3d5548367c77739d49e726a7d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-a2e2f2e3d5548367c77739d49e726a7d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;238&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-a2e2f2e3d5548367c77739d49e726a7d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a2e2f2e3d5548367c77739d49e726a7d_b.jpg\"/></figure><p>第1种(图a)，输入权重矩阵(灰色部分)完全退化为0，则输出W已经失去鉴别能力，此时加上残差连接(蓝色部分)，网络又恢复了表达能力。第2种(图b),输入对称的权重矩阵，那输出W一样不具备这两部分的鉴别能力，添加残差连接(蓝色部分)可打破对称性。第3种(图c)是图b的变种，不再说明。</p><p>总的来说一句话，打破了网络的对称性，提升了网络的表征能力，关于对称性引发的特征退化问题，大家还可以去参考更多的资料【4】。</p><p>对于skip连接的有效性的研究【5-6】，始终并未停止，至于究竟能到什么地步，大家还是多多关注吧学术研究，<b>也可以多关注我们呀</b>！</p><p class=\"ztext-empty-paragraph\"><br/></p><p>参考文献</p><p>【1】He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.</p><p>【2】Srivastava R K, Greff K, Schmidhuber J. Highway networks[J]. arXiv preprint arXiv:1505.00387, 2015.</p><p>【3】Orhan A E, Pitkow X. Skip connections eliminate singularities[J]. arXiv preprint arXiv:1701.09175, 2017.</p><p>【4】Shang W, Sohn K, Almeida D, et al. Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units[J]. 2016:2217-2225.</p><p>【5】Greff K, Srivastava R K, Schmidhuber J. Highway and Residual Networks learn Unrolled Iterative Estimation[J]. 2017.</p><p>【6】Jastrzebski S, Arpit D, Ballas N, et al. Residual connections encourage iterative inference[J]. arXiv preprint arXiv:1710.04773, 2017.</p><p class=\"ztext-empty-paragraph\"><br/></p><p>咱们这个系列的完整目录：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>另外：咱们还有一个专栏专门讲述：</p><a href=\"https://zhuanlan.zhihu.com/c_1005865351275573248\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-f32626bd7c13e7b9d294ad9ba0e7fb9e_ipico.jpg\" data-image-width=\"500\" data-image-height=\"500\" class=\"internal\">有三AI学院-深度学习模型优化</a><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "ResNet", 
                    "tagLink": "https://api.zhihu.com/topics/20084849"
                }, 
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }
            ], 
            "comments": [
                {
                    "userName": "GaryLIU", 
                    "userLink": "https://www.zhihu.com/people/02d9507df71399cbaa1fe2ffcaa556fa", 
                    "content": "龙大哥，文章写得很好。我想问个问题，权重矩阵的退化和剃度消失，是不是矛盾了？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "为什么呢？并无关系呀", 
                            "likes": 0, 
                            "replyToAuthor": "GaryLIU"
                        }, 
                        {
                            "userName": "GaryLIU", 
                            "userLink": "https://www.zhihu.com/people/02d9507df71399cbaa1fe2ffcaa556fa", 
                            "content": "按照梯度下降，梯度越大，权重改变的越大。但是如果梯度消失，权重就几乎没怎么改变，那权重矩阵还会退化吗？", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "曲松", 
                    "userLink": "https://www.zhihu.com/people/5912815a279a6c2708123afc9cddd7d1", 
                    "content": "感觉可以 但是依然看不懂", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "那就再看看", 
                            "likes": 0, 
                            "replyToAuthor": "曲松"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/42741086", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 12, 
            "title": "【模型解读】pooling去哪儿了", 
            "content": "<p>这是深度学习模型解读第5篇，本篇我们将介绍深度学习模型中的pooling。</p><h2><b>01 概述</b></h2><p>相信大家都记得，LeNet5，AlexNet，Vgg系列的核心思想，是convolution+pooling的核心结构。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d28045de7fb09f2b88dfc346dd39deb1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"166\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-d28045de7fb09f2b88dfc346dd39deb1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;166&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"166\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-d28045de7fb09f2b88dfc346dd39deb1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d28045de7fb09f2b88dfc346dd39deb1_b.jpg\"/></figure><p>但是，不知道从何时开始，pooling没了，对，就是没了。这是mobilenet【1】可视化后的部分结构图，懒得去画block图了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f98e064bbe123d48d1a3c150f225b73e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"510\" data-rawheight=\"1368\" class=\"origin_image zh-lightbox-thumb\" width=\"510\" data-original=\"https://pic3.zhimg.com/v2-f98e064bbe123d48d1a3c150f225b73e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;510&#39; height=&#39;1368&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"510\" data-rawheight=\"1368\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"510\" data-original=\"https://pic3.zhimg.com/v2-f98e064bbe123d48d1a3c150f225b73e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f98e064bbe123d48d1a3c150f225b73e_b.jpg\"/></figure><p>如今大部分情况下，pooling就出现在网络的最后，或者一些需要concat/add不同通道的block里面，为何？本文从3个方面来说说。<br/></p><p><b>02 pooling是什么</b></p><p>pooling，小名池化。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a4fdb8bd4d390dc183e947175bffaaa9_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"369\" data-thumbnail=\"https://pic2.zhimg.com/v2-a4fdb8bd4d390dc183e947175bffaaa9_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-a4fdb8bd4d390dc183e947175bffaaa9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;369&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"369\" data-thumbnail=\"https://pic2.zhimg.com/v2-a4fdb8bd4d390dc183e947175bffaaa9_b.jpg\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic2.zhimg.com/v2-a4fdb8bd4d390dc183e947175bffaaa9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a4fdb8bd4d390dc183e947175bffaaa9_b.gif\"/></figure><p>上图就是一个池化的示意图，用了一个10*10的卷积核，对20*20的图像分块不重叠的进行了池化，池化之后featuremap为2*2的大小。</p><p><b>pooling有什么用呢？或者说为什么需要pooling呢？</b>原因有几个：</p><p>(1) 增大感受野</p><p>所谓感受野，即一个像素对应回原图的区域大小，假如没有pooling，一个3*3，步长为1的卷积，那么输出的一个像素的感受野就是3*3的区域，再加一个stride=1的3*3卷积，则感受野为5*5，我们看左上角像素的传播就明白了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2fd2391b36dfe9aba891334e8eaaf1b9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"884\" data-rawheight=\"362\" class=\"origin_image zh-lightbox-thumb\" width=\"884\" data-original=\"https://pic2.zhimg.com/v2-2fd2391b36dfe9aba891334e8eaaf1b9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;884&#39; height=&#39;362&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"884\" data-rawheight=\"362\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"884\" data-original=\"https://pic2.zhimg.com/v2-2fd2391b36dfe9aba891334e8eaaf1b9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2fd2391b36dfe9aba891334e8eaaf1b9_b.jpg\"/></figure><p>依次，再多一个卷积，则为7*7，如果想看到224*224的全图，大家可以算算需要多少卷积层。</p><p>假如我们在每一个卷积中间加上3*3的pooling呢？很明显感受野迅速增大，这就是pooling的一大用处。感受野的增加对于模型的能力的提升是必要的，正所谓“一叶障目则不见泰山也”。</p><p>(2) 平移不变性</p><p>我们希望目标的些许位置的移动，能得到相同的结果。因为pooling不断地抽象了区域的特征而不关心位置，所以pooling一定程度上增加了平移不变性。</p><p>(3) 容易优化，pooling是每个featuremap单独做降采样，与基于卷积的降采样相比，不需要参数，更容易优化。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>03 如何去除pooling</b></p><p>那pooling是必要的吗？答案已经很明了了，不需要。文【2】做了详细的实验，在cifar，imagenet等多个数据集上实验结果表明，完全没有必要。因为我们可以用步长大于1的卷积来替代。</p><p>当步长不为1时，降采样的速度将变快。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-1181f3053eac61cb4db32a206dfa92db_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"610\" data-rawheight=\"339\" class=\"origin_image zh-lightbox-thumb\" width=\"610\" data-original=\"https://pic4.zhimg.com/v2-1181f3053eac61cb4db32a206dfa92db_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;610&#39; height=&#39;339&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"610\" data-rawheight=\"339\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"610\" data-original=\"https://pic4.zhimg.com/v2-1181f3053eac61cb4db32a206dfa92db_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-1181f3053eac61cb4db32a206dfa92db_b.jpg\"/></figure><p>当stride，也就是步长等于2，上面的5*5一次卷积后就为2*2了。这其实还减轻了重叠的卷积操作，通过卷积来学习了降采样，看起来好处还是不少的。</p><p>实验结果也佐证了这一点。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f1183c6f865413f165640a1e47c42fd4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"532\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-f1183c6f865413f165640a1e47c42fd4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;532&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"532\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-f1183c6f865413f165640a1e47c42fd4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-f1183c6f865413f165640a1e47c42fd4_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a8f6d0ebeb888884116772cd55ab7c30_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"806\" data-rawheight=\"644\" class=\"origin_image zh-lightbox-thumb\" width=\"806\" data-original=\"https://pic1.zhimg.com/v2-a8f6d0ebeb888884116772cd55ab7c30_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;806&#39; height=&#39;644&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"806\" data-rawheight=\"644\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"806\" data-original=\"https://pic1.zhimg.com/v2-a8f6d0ebeb888884116772cd55ab7c30_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a8f6d0ebeb888884116772cd55ab7c30_b.jpg\"/></figure><p>就是作者的实验结果，all-cnn-c相比convpool-cnn-c，就是在同等卷积层的基础上，去掉了pooling，结果B和C系列模型效果都是提升的，关于A，B，C系列具体细节大家可以参考文章。</p><p>总之，不管是文献的研究结果，以及大家的实际使用经验，都已经完全使用带步长的卷积替换掉了pooling这一降采用的操作。</p><h2><b>04 pooling没用了吗？</b></h2><p>答案是有，因为pooling相对于带步长的卷积操作，毕竟减少了计算量，所以对于很多需要concat/add featuremap通道的小模型，pooling仍然可以以小搏大。比如下面的shufflenet的block。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ffe30ac5ac49308c3c889c3cd428a7c5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"898\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-ffe30ac5ac49308c3c889c3cd428a7c5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;898&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"898\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-ffe30ac5ac49308c3c889c3cd428a7c5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ffe30ac5ac49308c3c889c3cd428a7c5_b.jpg\"/></figure><p>不过总的来说，pooling，走好。</p><p>参考文献</p><p>【1】Howard A G, Zhu M, Chen B, et al. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications[J]. 2017.</p><p>【2】Springenberg J T, Dosovitskiy A, Brox T, et al. Striving for Simplicity: The All Convolutional Net[J]. Eprint Arxiv, 2014.</p><p>【3】Zhang X, Zhou X, Lin M, et al. ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices[J]. 2017.</p><p>这个咱们这个系列的完整目录：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>另外：咱们还有一个专栏专门讲述：</p><a href=\"https://zhuanlan.zhihu.com/c_1005865351275573248\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-f32626bd7c13e7b9d294ad9ba0e7fb9e_ipico.jpg\" data-image-width=\"500\" data-image-height=\"500\" class=\"internal\">有三AI学院-深度学习模型优化</a><p></p>", 
            "topic": [
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/42186606", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 5, 
            "title": "【模型解读】说说移动端基准模型MobileNets", 
            "content": "<p>这是深度学习模型解读第4篇，本篇我们将介绍MobileNets。</p><h2><b>01 概述</b></h2><p>Google开发的MobileNets【1】是用于嵌入式平台计算机视觉应用的基准模型。MobileNets是流线型的架构，它使用depthwise sparable convolution(深度可分离卷积)来构建轻量级的深层神经网络。通过引入两个简单的全局超参数，可实现在速度和准确度之间有效地进行平衡。这两个超参数允许模型构建者根据问题的约束条件，为其应用选择合适大小的模型。MobileNets应用在广泛的场景中，包括物体检测，细粒度分类，人脸属性等。</p><h2><b>02 Mobilenets结构</b></h2><p>Mobilenets基本组成单元是depthwise sparable convolution+pointwise convolution，下图是其组成结构图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-1ce89231c629460467744f7748fd4ce6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"320\" data-rawheight=\"422\" class=\"content_image\" width=\"320\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;320&#39; height=&#39;422&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"320\" data-rawheight=\"422\" class=\"content_image lazy\" width=\"320\" data-actualsrc=\"https://pic3.zhimg.com/v2-1ce89231c629460467744f7748fd4ce6_b.jpg\"/></figure><p>我们可以看到它由3*3的通道分组卷积（depthwise separable convolution）加1*1的普通卷积（point wise convolution）组成。它的组成结构本质上就是Xception结构，如下图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d54313d2a36cfe1145f000c9a5d6fc93_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"440\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-d54313d2a36cfe1145f000c9a5d6fc93_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;440&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"440\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-d54313d2a36cfe1145f000c9a5d6fc93_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-d54313d2a36cfe1145f000c9a5d6fc93_b.jpg\"/></figure><p><b>从图中可以看出，经过3*3深度卷积，每个通道的输出信息只和之前的对应通道信息相关，而普通3*3卷积每个通道输出信息和之前所有通道信息相关，这是它们的本质区别。</b></p><p>下面我们计算一下depthwise sparable convolution和普通卷积之间的计算量的比较，便于我们客观理解depthwise sparable convolution的有效性。</p><p>假设输入图片是DF*DF*M，输出图片是DF*DF*N，卷积核尺度是DK*DK。</p><p>普通卷积计算量：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-acdcfd906187a5516f9c797f56a6f1ef_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"682\" data-rawheight=\"68\" class=\"origin_image zh-lightbox-thumb\" width=\"682\" data-original=\"https://pic4.zhimg.com/v2-acdcfd906187a5516f9c797f56a6f1ef_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;682&#39; height=&#39;68&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"682\" data-rawheight=\"68\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"682\" data-original=\"https://pic4.zhimg.com/v2-acdcfd906187a5516f9c797f56a6f1ef_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-acdcfd906187a5516f9c797f56a6f1ef_b.jpg\"/></figure><p>depthwise sparable convolution计算量：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-94730c61446f695dbb4d71a2b705b92d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"654\" data-rawheight=\"58\" class=\"origin_image zh-lightbox-thumb\" width=\"654\" data-original=\"https://pic2.zhimg.com/v2-94730c61446f695dbb4d71a2b705b92d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;654&#39; height=&#39;58&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"654\" data-rawheight=\"58\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"654\" data-original=\"https://pic2.zhimg.com/v2-94730c61446f695dbb4d71a2b705b92d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-94730c61446f695dbb4d71a2b705b92d_b.jpg\"/></figure><p>两个比值为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c2faf7c8ffa8078461eefb4b651a229a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"760\" data-rawheight=\"202\" class=\"origin_image zh-lightbox-thumb\" width=\"760\" data-original=\"https://pic3.zhimg.com/v2-c2faf7c8ffa8078461eefb4b651a229a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;760&#39; height=&#39;202&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"760\" data-rawheight=\"202\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"760\" data-original=\"https://pic3.zhimg.com/v2-c2faf7c8ffa8078461eefb4b651a229a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c2faf7c8ffa8078461eefb4b651a229a_b.jpg\"/></figure><p>一般情况下N比较大，当DK=3时，depthwise sparable convolution计算量仅为普通卷积计算量的1/9。</p><p>Mobilenets结构就是由这些depthwise  convolution+pointwise convolution线性叠加构成的。结构如下图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-6aeeb273ac47c710519c8d2fe4cc1b2f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"880\" data-rawheight=\"940\" class=\"origin_image zh-lightbox-thumb\" width=\"880\" data-original=\"https://pic4.zhimg.com/v2-6aeeb273ac47c710519c8d2fe4cc1b2f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;880&#39; height=&#39;940&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"880\" data-rawheight=\"940\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"880\" data-original=\"https://pic4.zhimg.com/v2-6aeeb273ac47c710519c8d2fe4cc1b2f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-6aeeb273ac47c710519c8d2fe4cc1b2f_b.jpg\"/></figure><p>从图中可以看出先是一个3*3普通卷积，然后是叠加depthwise sparable convolution+pointwise convolution，之后是全局均值池化，接着是全连接层，最后Softmax输出。</p><p>下图是MobileNets和各个网络的比较。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-083b22c327aaf1a140e3fbc23ae09c64_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"808\" data-rawheight=\"550\" class=\"origin_image zh-lightbox-thumb\" width=\"808\" data-original=\"https://pic1.zhimg.com/v2-083b22c327aaf1a140e3fbc23ae09c64_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;808&#39; height=&#39;550&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"808\" data-rawheight=\"550\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"808\" data-original=\"https://pic1.zhimg.com/v2-083b22c327aaf1a140e3fbc23ae09c64_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-083b22c327aaf1a140e3fbc23ae09c64_b.jpg\"/></figure><p>可以看出在参数量减小的领先优势之下，还能取的很高的准确率。</p><h2><b>03 模型压缩</b></h2><p>可以通过定义width multiplier α（宽度乘数）和resolution multiplier ρ （分辨率乘数）两个超参数，来实现不同版本的mobilenets，从而实现不同要求的模型压缩。</p><p>1.第一个参数α主要是按比例减少通道数，其取值范围为(0,1)，α ∈ {1, 0.75, 0.5, 0.25} 的测试效果如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ef202626b866c50fef5165888860ff6f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"850\" data-rawheight=\"298\" class=\"origin_image zh-lightbox-thumb\" width=\"850\" data-original=\"https://pic4.zhimg.com/v2-ef202626b866c50fef5165888860ff6f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;850&#39; height=&#39;298&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"850\" data-rawheight=\"298\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"850\" data-original=\"https://pic4.zhimg.com/v2-ef202626b866c50fef5165888860ff6f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ef202626b866c50fef5165888860ff6f_b.jpg\"/></figure><p>可以看出随着α减小，准确率下降，参数量减小，速度提升。</p><p>2.第二个超参数ρ 主要是按比例改变输入数据的分辨率。ρ 如果为{1，6/7，5/7，4/7}，则对应输入分辨率为{224，192，160，128}。测试效果如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-caa488decd3a2d3c025d0444bd7e6b40_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"830\" data-rawheight=\"302\" class=\"origin_image zh-lightbox-thumb\" width=\"830\" data-original=\"https://pic1.zhimg.com/v2-caa488decd3a2d3c025d0444bd7e6b40_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;830&#39; height=&#39;302&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"830\" data-rawheight=\"302\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"830\" data-original=\"https://pic1.zhimg.com/v2-caa488decd3a2d3c025d0444bd7e6b40_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-caa488decd3a2d3c025d0444bd7e6b40_b.jpg\"/></figure><p>可以看出，随着分辨率下降，准确率下降，随之速度加快。日常应用中，可以通过这两个参数的选取来综合考虑选择模型。</p><p><b>模型分享到了第四篇，实习也到了尾声即将杀入校招大军，非常感谢鹏哥的帮助和指导。如果有朋友提供好的机会，欢迎后台留言。</b></p><p>参考文献</p><p>【1】Howard A G, Zhu M, Chen B, et al. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications[J]. 2017.</p><p>好像文章越写越简单了，不过这是好事，这个咱们这个系列的完整目录：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>另外：咱们还有一个专栏专门讲述：</p><a href=\"https://zhuanlan.zhihu.com/c_1005865351275573248\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-f32626bd7c13e7b9d294ad9ba0e7fb9e_ipico.jpg\" data-image-width=\"500\" data-image-height=\"500\" class=\"internal\">有三AI学院-深度学习模型优化</a><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "嵌入式系统", 
                    "tagLink": "https://api.zhihu.com/topics/19565752"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/41691301", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 5, 
            "title": "【模型解读】Inception结构，你看懂了吗", 
            "content": "<p>这是深度学习模型解读第3篇，本篇我们将介绍GoogLeNet v1到v3。</p><h2><b>1 Inception V1【1】</b></h2><p>GoogLeNet首次出现在2014年ILSVRC 比赛中获得冠军。这次的版本通常称其为Inception V1。Inception V1有22层深，参数量为5M。同一时期的VGGNet性能和Inception V1差不多，但是参数量也是远大于Inception V1。</p><p>Inception Module是GoogLeNet的核心组成单元。结构如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3eb368c5ad460af964ed9307d258c192_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"353\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-3eb368c5ad460af964ed9307d258c192_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;353&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"353\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-3eb368c5ad460af964ed9307d258c192_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-3eb368c5ad460af964ed9307d258c192_b.jpg\"/></figure><p>Inception Module基本组成结构有四个成分。1*1卷积，3*3卷积，5*5卷积，3*3最大池化。最后对四个成分运算结果进行通道上组合。这就是Inception Module的核心思想。<b>通过多个卷积核提取图像不同尺度的信息，最后进行融合，可以得到图像更好的表征</b>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fb626301e50733f662f2065e4bec84de_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"269\" class=\"content_image\" width=\"400\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;400&#39; height=&#39;269&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"400\" data-rawheight=\"269\" class=\"content_image lazy\" width=\"400\" data-actualsrc=\"https://pic3.zhimg.com/v2-fb626301e50733f662f2065e4bec84de_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-830823e745bc37eaaea69117d9163a87_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"766\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-830823e745bc37eaaea69117d9163a87_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;766&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"766\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-830823e745bc37eaaea69117d9163a87_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-830823e745bc37eaaea69117d9163a87_b.jpg\"/></figure><p>如上图所示，假设我们要提取猫脸特征，而上面两张图的猫脸占比显然不一样，那么我们就得用不同卷积核提取不同信息。信息分布比较全局性的图像采用大卷积核，信息分布比较局部性的图像采用小卷积核。</p><p>图b是对图a的改进，即在3*3卷积，5*5卷积前加1*1卷积，目的是为了先进行降维，相比较于原来结构减少了较多参数。而把1*1卷积放在3*3最大池化之后，相比较放在前面，也是为了参数量的减少。</p><p>由Inception Module组成的GoogLeNet如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-23d077105e9f28aa56afa9e50975b69a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"684\" data-rawheight=\"2486\" class=\"origin_image zh-lightbox-thumb\" width=\"684\" data-original=\"https://pic3.zhimg.com/v2-23d077105e9f28aa56afa9e50975b69a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;684&#39; height=&#39;2486&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"684\" data-rawheight=\"2486\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"684\" data-original=\"https://pic3.zhimg.com/v2-23d077105e9f28aa56afa9e50975b69a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-23d077105e9f28aa56afa9e50975b69a_b.jpg\"/></figure><p>对上图做如下说明：</p><p>1.  采用模块化结构，方便增添和修改。其实网络结构就是叠加Inception Module。</p><p>2.采用Network in Network中用Averagepool来代替全连接层的思想。实际在最后一层还是添加了一个全连接层，是为了大家做finetune。</p><p>3.依然使用Dropout层，防止过拟合。</p><p>4.另外增加了两个辅助的softmax分支，作用有两点，一是为了避免梯度消失，用于向前传导梯度。反向传播时如果有一层求导为0，链式求导结果则为0。二是将中间某一层输出用作分类，起到模型融合作用。最后的loss=loss_2 + 0.3 * loss_1 + 0.3 * loss_0。实际测试时，这两个辅助softmax分支会被去掉。</p><h2><b>2 Inception V2【2】</b></h2><p>1.学习VGGNet的特点，用两个3*3卷积代替5*5卷积，可以降低参数量。</p><p>2.提出BN算法。BN算法是一个正则化方法，可以提高大网络的收敛速度。简单介绍一下BN算法。就是对输入层信息分布标准化处理，使得规范化为N(0,1)的高斯分布，收敛速度大大提高。</p><h2><b>3 Inception V3【3】</b></h2><p>学习Factorization into small convolutions的思想，将一个二维卷积拆分成两个较小卷积，例如将7*7卷积拆成1*7卷积和7*1卷积。这样做的好处是降低参数量。paper中指出，通过这种非对称的卷积拆分，比对称的拆分为几个相同的卷积效果更好，可以处理更多，更丰富的空间特征。</p><p>本来还有Inception V4【4】的，考虑到借鉴了微软的ResNet网络结构思想，在后面介绍Resnet中的残差结构时再做介绍。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>参考文献</p><p>【1】Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]// IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2015:1-9.</p><p>Ioffe S, Szegedy C. </p><p>【2】Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift[J]. 2015:448-456.</p><p>【3】Szegedy C, Vanhoucke V, Ioffe S, et al. Rethinking the Inception Architecture for Computer Vision[J]. 2015:2818-2826.</p><p>【4】Szegedy C, Ioffe S, Vanhoucke V, et al. Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning[J]. 2016.</p><p>好像文章越写越简单了，不过这是好事，这个咱们这个系列的完整目录：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>另外：咱们还有一个专栏专门讲述：</p><a href=\"https://zhuanlan.zhihu.com/c_1005865351275573248\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-f32626bd7c13e7b9d294ad9ba0e7fb9e_ipico.jpg\" data-image-width=\"500\" data-image-height=\"500\" class=\"internal\">有三AI学院-深度学习模型优化</a><p></p><p></p>", 
            "topic": [
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/41590396", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 9, 
            "title": "【模型解读】NIN中的1*1卷积，你懂了吗", 
            "content": "<p>这是深度学习模型解读第2篇，本篇我们将介绍Network In Network。</p><p>Network In Network 是发表于2014年ICLR的一篇paper。这篇文章采用较少参数就取得了Alexnet的效果，Alexnet参数大小为230M，而Network In Network仅为29M，这篇paper主要两大亮点：</p><h2><b>1 提出MLP卷积层</b></h2><p>下图是传统卷积结构：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-d2dd1bde737dc3d6d731976660fa6d7f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"309\" data-rawheight=\"246\" class=\"content_image\" width=\"309\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;309&#39; height=&#39;246&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"309\" data-rawheight=\"246\" class=\"content_image lazy\" width=\"309\" data-actualsrc=\"https://pic4.zhimg.com/v2-d2dd1bde737dc3d6d731976660fa6d7f_b.jpg\"/></figure><p>使用relu的一个非线性变换操作为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e8287e463f0a56aa453d429be00a134d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"577\" data-rawheight=\"43\" class=\"origin_image zh-lightbox-thumb\" width=\"577\" data-original=\"https://pic2.zhimg.com/v2-e8287e463f0a56aa453d429be00a134d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;577&#39; height=&#39;43&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"577\" data-rawheight=\"43\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"577\" data-original=\"https://pic2.zhimg.com/v2-e8287e463f0a56aa453d429be00a134d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e8287e463f0a56aa453d429be00a134d_b.jpg\"/></figure><p>i,j表示像素下标，xi,j表示像素值，wk表示卷积参数，k就是下标的索引。</p><p>MLP卷积层结构如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-03362ce99b476f4364b6f646d26a412e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"369\" data-rawheight=\"226\" class=\"content_image\" width=\"369\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;369&#39; height=&#39;226&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"369\" data-rawheight=\"226\" class=\"content_image lazy\" width=\"369\" data-actualsrc=\"https://pic3.zhimg.com/v2-03362ce99b476f4364b6f646d26a412e_b.jpg\"/></figure><p>mlpconv层的计算公式为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6012252c1a44668fa41fe754b77520a2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"582\" data-rawheight=\"133\" class=\"origin_image zh-lightbox-thumb\" width=\"582\" data-original=\"https://pic3.zhimg.com/v2-6012252c1a44668fa41fe754b77520a2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;582&#39; height=&#39;133&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"582\" data-rawheight=\"133\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"582\" data-original=\"https://pic3.zhimg.com/v2-6012252c1a44668fa41fe754b77520a2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-6012252c1a44668fa41fe754b77520a2_b.jpg\"/></figure><p>i,j表示像素下标，xi,j表示像素值，wk,n表示第n层卷积卷积参数。</p><p>从以上可以看出，MLP卷积层通过叠加&#34;micro network&#34;网络，提高非线性表达，而其中的&#34;micro network&#34;基本组成单元是1*1卷积网路，说到这，就要解释一下1*1卷积了，该篇论文是首次提出1*1卷积，具有划时代的意义，之后的Googlenet借鉴了1*1卷积，还专门致谢过这篇论文。</p><p><b>1*1卷积的意义：</b></p><p>1. 实现了不同通道同一位置的信息融合</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-2ac8e3fb81f2f95ae00f9bcb8a798e52_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"432\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-2ac8e3fb81f2f95ae00f9bcb8a798e52_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;432&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"432\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-2ac8e3fb81f2f95ae00f9bcb8a798e52_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-2ac8e3fb81f2f95ae00f9bcb8a798e52_b.jpg\"/></figure><p>如上图，C2融合了C1不同通道同一位置的信息。</p><h2><b>2. 可以实现通道数的降维或升维</b></h2><p>首先让我们看下Network In Network的网络结构，如下图。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-477d51f73d7b696c19d7e36041133475_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"784\" data-rawheight=\"231\" class=\"origin_image zh-lightbox-thumb\" width=\"784\" data-original=\"https://pic2.zhimg.com/v2-477d51f73d7b696c19d7e36041133475_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;784&#39; height=&#39;231&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"784\" data-rawheight=\"231\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"784\" data-original=\"https://pic2.zhimg.com/v2-477d51f73d7b696c19d7e36041133475_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-477d51f73d7b696c19d7e36041133475_b.jpg\"/></figure><p>上图看出，该网络结构有三个MLP卷积层组成，每个MLP卷积层分别是一个普通卷积，加两个1*1卷积。以1000分类为例，最后一个1*1卷积输出的featuremap大小为6*6*1000。之后每个featuremap采用全局均值池化，输出1000个分类。由于没有全连接的大量参数，使用全局均值池化不需要参数，极大的降低了参数量。</p><p>如下图是在CIFAR-10 数据集中 Global average pooling 和 fully connected测试对比图， 从下图可以看出无参数的Global average pooling层 相比较于有参数的全连接层错误率更低。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f3dcacac89716b1d49d02f49035d18b4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"688\" data-rawheight=\"148\" class=\"origin_image zh-lightbox-thumb\" width=\"688\" data-original=\"https://pic1.zhimg.com/v2-f3dcacac89716b1d49d02f49035d18b4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;688&#39; height=&#39;148&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"688\" data-rawheight=\"148\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"688\" data-original=\"https://pic1.zhimg.com/v2-f3dcacac89716b1d49d02f49035d18b4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-f3dcacac89716b1d49d02f49035d18b4_b.jpg\"/></figure><h2><b>3 总结</b></h2><p>Network In Network通过创新的创建MLP卷积层，提高了网络的非线性表达同时降低了参数量，用全局均值池化代替全连接层，极大的降低了参数量。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>参考文献</p><p>[1] Lin M, Chen Q, Yan S. Network In Network[J]. Computer Science, 2014</p><p>咱们这个系列的完整目录：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>另外：咱们还有一个专栏专门讲述：</p><a href=\"https://zhuanlan.zhihu.com/c_1005865351275573248\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-f32626bd7c13e7b9d294ad9ba0e7fb9e_ipico.jpg\" data-image-width=\"500\" data-image-height=\"500\" class=\"internal\">有三AI学院-深度学习模型优化</a><p></p><p></p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/40791280", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 10, 
            "title": "【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构", 
            "content": "<p>从本篇开始，我们将带领大家解读深度学习中的网络的发展。<br/>这是深度学习模型解读第一篇，本篇我们将介绍LeNet，AlexNet，VGGNet，它们都是卷积+池化串联的基本网络结构。</p><h2>1 LeNet5      </h2><p>LeNet5【1】有3个卷积层，2个池化层，2个全连接层。卷积层的卷积核都为5*5，stride=1，池化层都为Max pooling，激活函数为Sigmoid，具体网络结构如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-544adf02edea3801bcc5c2342054258a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"336\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-544adf02edea3801bcc5c2342054258a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;336&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"336\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-544adf02edea3801bcc5c2342054258a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-544adf02edea3801bcc5c2342054258a_b.jpg\"/></figure><p>下面我们详细解读一下网络结构，先约定一些称呼。</p><p><b>我们先约定一些叫法，比如featuremap为28*28*6，卷积参数大小为(5*5*1)*6。其中28*28是featuremap的高度，宽度，6是featuremap的通道数。(5*5*1)*6卷积核表示5*5的高度，宽度，通道数为1的卷积核有6个。你可以把(5*5*1)想象成一个厚度为1，长度，宽度各为5的卷积块，以下依此类推。</b></p><p>1.Input<br/>   输入图像统一归一化为32*32。</p><p>2.C1卷积层<br/>   经过(5*5*1)*6卷积核，stride=1, 生成featuremap为28*28*6。</p><p>3.S2池化层<br/>   经过(2*2)采样核，stride=2，生成featuremap为14*14*6。</p><p>4.C3卷积层<br/>   经过(5*5*6)*16卷积核，stride=1，生成featuremap为10*10*16。</p><p>5.S4池化层<br/>    经过(2*2)采样核，stride=2，生成featuremap为5*5*16。</p><p>6.C5卷积层    <br/>   经过(5*5*16)*120卷积核，stride=1， 生成featuremap为1*1*120。</p><p>7.F6全连接层<br/>   输入为1*1*120，输出为1*1*84，总参数量为120*84。</p><p>8.Output全连接层 。  <br/>   输入为1*1*84，输出为1*1*10，总参数量为84*10。10就是分类的类别数。</p><h2>2 AlexNet</h2><p>2012年，Imagenet比赛冠军—Alexnet （以第一作者Alex命名）【2】直接刷新了ImageNet的识别率，奠定了深度学习在图像识别领域的优势地位。网络结构如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-725e0f7e1a2389023455a0991bf0df6f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"366\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-725e0f7e1a2389023455a0991bf0df6f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;366&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"366\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-725e0f7e1a2389023455a0991bf0df6f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-725e0f7e1a2389023455a0991bf0df6f_b.jpg\"/></figure><p>1.Input<br/>   输入图像为224*224*3。</p><p>2.Conv1<br/>   经过(11*11*3)*96卷积核，stride=4， (227-11)/4+2=55，生成featuremap为55*55*96。</p><p>3.Pool1<br/>   经过3*3的池化核，stride=2，(55-3)/2+1=27，生成featuremap为27*27*96。</p><p>4.Norm1<br/>   local_size=5，生成featuremap为27*27*96。</p><p>5.Conv2<br/>   经过(5*5*96)*256的卷积核，pad=2，group=2，(27+2*2-5)/1+1=27，生成featuremap为27*27*256。</p><p>6.Pool2<br/>   经过3*3的池化核，stride=2，(27-3)/2+1=13，生成featuremap为13*13*256。</p><p>7.Norm2<br/>   local_size=5, 生成featuremap为13*13*256。</p><p>8.Conv3<br/>   经过(3*3*256)*384卷积核，pad=1， (13+1*2-3)/1+1=13，生成featuremap为13*13*384。</p><p>9.Conv4<br/>   经过(3*3*384)*384卷积核，pad=1，(13+1*2-3)/1+1=13，生成featuremap为13*13*384。</p><p>10.Conv5<br/>     经过(3*3*384)*256卷积核，pad=1，(13+1*2-3)/1+1=13，生成featuremap为13*13*256。</p><p>11.Pool5<br/>     经过(3*3)的池化核，stride=2，(13-3)/2+1=6，生成featuremap为6*6*256。</p><p>12.Fc6<br/>     输入为(6*6*256)*4096全连接，生成featuremap为1*1*4096。</p><p>13.Dropout6<br/>     在训练的时候以1/2概率使得隐藏层的某些神经元的输出为0，这样就丢掉了一半节点的输出，BP的时候也不更新这些节点，以下Droupout同理。</p><p>14.Fc7<br/>     输入为1*1*4096，输出为1*1*4096，总参数量为4096*4096。</p><p>15.Dropout7<br/>     生成featuremap为1*1*4096。</p><p>16.Fc8<br/>     输入为1*1*4096，输出为1000，总参数量为4096*1000。</p><p>总结：</p><p>1.网络比LeNet更深，包括5个卷积层和3个全连接层。</p><p>2.使用relu激活函数，收敛很快，解决了Sigmoid在网络较深时出现的梯度弥散问题。</p><p>3.加入了dropout层，防止过拟合。</p><p>4.使用了LRN归一化层，对局部神经元的活动创建竞争机制，抑制反馈较小的神经元放大反应大的神经元，增强了模型的泛化能力。</p><p>5.使用裁剪翻转等操作做数据增强，增强了模型的泛化能力。预测时使用提取图片四个角加中间五个位置并进行左右翻转一共十幅图片的方法求取平均值，这也是后面刷比赛的基本使用技巧。</p><p>6.分块训练，当年的GPU没有这么强大，Alexnet创新地将图像分为上下两块分别训练，然后在全连接层合并在一起。</p><p>7.总体的数据参数大概为240M。</p><h2>3 VGG</h2><p>VGGNet【3】主要的贡献是利用带有很小卷积核（3*3）的网络结构对逐渐加深的网络进行评估，结果表明通过加深网络深度至16-19层可以极大地改进前人的网络结构。这些发现也是参加2014年ImageNet比赛的基础，并且在这次比赛中，分别在定位和分类跟踪任务中取得第一名和第二名。VGGNet的网络结构如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-1913afc4b87ddef6df4aa3d64bb2797d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1044\" data-rawheight=\"988\" class=\"origin_image zh-lightbox-thumb\" width=\"1044\" data-original=\"https://pic2.zhimg.com/v2-1913afc4b87ddef6df4aa3d64bb2797d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1044&#39; height=&#39;988&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1044\" data-rawheight=\"988\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1044\" data-original=\"https://pic2.zhimg.com/v2-1913afc4b87ddef6df4aa3d64bb2797d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-1913afc4b87ddef6df4aa3d64bb2797d_b.jpg\"/></figure><p>类型从A到E。此处重点讲解VGG16。也就是图中的类型D。如图中所示，共有13个卷积层，3个全连接层。其全部采用3*3卷积核，步长为1，和2*2最大池化核，步长为2。</p><p>1.Input层<br/>   输入图片为224*224*3。</p><p>2.CONV3-64<br/>   经过（3*3*3）*64卷积核，生成featuremap为224*224*64。</p><p>3.CONV3-64<br/>   经过（3*3*64）*64卷积核，生成featuremap为224*224*64。</p><p>4.Max pool<br/>   经过（2*2）max pool核，生成featuremap为112*112*64。</p><p>5.CONV3-128。<br/>   经过（3*3*64）*128卷积核，生成featuremap为112*112*128。</p><p>6. CONV3-128<br/>    经过（3*3*128）*128卷积，生成featuremap为112*112*128。</p><p>7.Max pool<br/>   经过（2*2）maxpool，生成featuremap为56*56*128。</p><p>8.CONV3-256<br/>   经过（3*3*128）*256卷积核，生成featuremap为56*56*256。</p><p>9.CONV3-256<br/>   经过（3*3*256）*256卷积核，生成featuremap为56*56*256。</p><p>10.CONV3-256<br/>     经过（3*3*256）*256卷积核，生成featuremap为56*56*256。</p><p>11.Max pool<br/>     经过（2*2）maxpool，生成featuremap为28*28*256</p><p>12.CONV3-512<br/>     经过（3*3*256）*512卷积核，生成featuremap为28*28*512</p><p>13.CONV3-512<br/>     经过（3*3*512）*512卷积核，生成featuremap为28*28*512。</p><p>14.CONV3-512<br/>     经过（3*3*512）*512卷积核，生成featuremap为28*28*512。</p><p>15.Max pool<br/>     经过（2*2）maxpool,生成featuremap为14*14*512。</p><p>16.CONV3-512<br/>     经过（3*3*512）*512卷积核，生成featuremap为14*14*512。</p><p>17.CONV3-512<br/>    经过（3*3*512）*512卷积核，生成featuremap为14*14*512。</p><p>18.CONV3-512<br/>    经过（3*3*512）*512卷积核，生成featuremap为14*14*512。</p><p>19.Max pool<br/>    经过2*2卷积，生成featuremap为7*7*512。</p><p>20.FC-4096<br/>    输入为7*7*512，输出为1*1*4096，总参数量为7*7*512*4096。</p><p>21.FC-4096<br/>    输入为1*1*4096，输出为1*1*4096，总参数量为4096*4096。</p><p>22.FC-1000<br/>    输入为1*1*4096，输出为1000，总参数量为4096*1000。<br/><br/>总结：</p><p>1. 共包含参数约为550M。</p><p>2. 全部使用3*3的卷积核和2*2的最大池化核。</p><p>3. 简化了卷积神经网络的结构。04总结LeNet5是早期用于工程应用的网络结构，发展到AlexNet，激活函数从sigmoid变为relu，加入了Dropout层等操作，引起了新一轮的深度学习热潮。VGG基本是AlexNet的加强版，深度上是其2倍，参数量大小也是两倍多。<br/><br/><b>这三个网络结构本质上都是（卷积+池化）堆叠的网络结构，是深度学习复兴以来的第一个有重大工程意义的网络设计系列。</b></p><p><br/>参考文献<br/>【1】Lécun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11):2278-2324.<br/>【2】Krizhevsky A, Sutskever I, Hinton G E. ImageNet classification with deep convolutional neural networks[C]// International Conference on Neural Information Processing Systems. Curran Associates Inc. 2012:1097-1105.<br/>【3】Simonyan K, Zisserman A. Very Deep Convolutional Networks for Large-Scale Image Recognition[J]. Computer Science, 2014.</p><p>这个咱们这个系列的完整目录：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029512%26idx%3D1%26sn%3Da46fc10de7daba25694bda75a916aa91%26chksm%3D871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029550%26idx%3D1%26sn%3D13a3f1e12815694c595b9ee88708af1a%26chksm%3D871345d3b064ccc547637ad3daa56565c25c234686452228b052e10589740d697f55e8945fe9%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】network in network中的1*1卷积，你懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029565%26idx%3D1%26sn%3D330e398a4007b7b24fdf5203a5bf5d91%26chksm%3D871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】GoogLeNet中的inception结构，你看懂了吗</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029611%26idx%3D1%26sn%3D391331148aa14050a840e2db309f6a06%26chksm%3D87134596b064cc80f7dfe82ef61488cb6f0a183e15991e81425bba10826c700f8ac3a24836c3%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】说说移动端基准模型MobileNets</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029637%26idx%3D1%26sn%3D9466af9df27b9e2fbde6f385bbdd6cbd%26chksm%3D87134278b064cb6e698174bd73b79e9280996fbe9364b99cdd4435d946eb5218c62e5e1930f2%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】pooling去哪儿了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】resnet中的残差连接，你确定真的看懂了？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029777%26idx%3D1%26sn%3Dcbc6ddcea0fae539aca5f66d32f73c95%26chksm%3D871342ecb064cbfafd624f873fa53807391bdb3cf855c0df09ccf83422b87e37d4312c6f3909%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“不正经”的卷积神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】“全连接”的卷积网络，有什么好？</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029975%26idx%3D1%26sn%3D5724d16c16679ec426f64afaa30cfde1%26chksm%3D8713432ab064ca3cdd0f7d7902966b5cb96af0daa832be0f50010297fe2002c288aab5c2a2a5%26token%3D1879088111%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】从“局部连接”回到“全连接”的神经网络</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649031080%26idx%3D1%26sn%3Df052fbbfc9408d569865342867be03ea%26chksm%3D8712bfd5b06536c38c5df21ce227280b0684415e807a3ba1b3266e0223f8c3b49ecaa105c941%26token%3D1722907341%26lang%3Dzh_CN%23rd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【模型解读】深度学习网络只能有一个输入吗</a></p><p>另外：咱们还有一个专栏专门讲述：</p><a href=\"https://zhuanlan.zhihu.com/c_1005865351275573248\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-f32626bd7c13e7b9d294ad9ba0e7fb9e_ipico.jpg\" data-image-width=\"500\" data-image-height=\"500\" class=\"internal\">有三AI学院-深度学习模型优化</a><p></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "卷积", 
                    "tagLink": "https://api.zhihu.com/topics/19678959"
                }, 
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/34455109", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 35, 
            "title": "【技术综述】如何Finetune一个小网络到移动端(时空性能分析篇)", 
            "content": "<h2><b>0 引言</b></h2><p>现在很多的图像算法都是离线计算的，而学术界刷榜单那些模型，什么vgg16，resnet152是不能直接拿来用的，所以，对于一个深度学习算法工程师来说，如果在这些模型的基础上，设计出一个又小又快的满足业务需求的模型，是必备技能，今天就来简单讨论一下这个问题。</p><p>首先，祭出一个baseline，来自Google的mobilenet，算是学术界祭出的真正有意义的移动端模型。</p><p>当然，这里我们要稍微修改一下，毕竟原始的mobilenet是分类模型过于简单无法展开更多，我们以更加复杂通用的一个任务开始，分割，同时修改一下初始输入尺度，毕竟224这个尺度在移动端不一定被采用，我们以更小的一个尺度开始，以MacBookPro为计算平台。</p><p>在原有mobilenet的基础上添加反卷积，输入网络尺度160*160，网络结构参考mobilenet，只是在最后加上反卷积如下</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-66cd74ab71aa0f1c02956570dadb3173_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"304\" data-rawheight=\"936\" class=\"content_image\" width=\"304\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;304&#39; height=&#39;936&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"304\" data-rawheight=\"936\" class=\"content_image lazy\" width=\"304\" data-actualsrc=\"https://pic4.zhimg.com/v2-66cd74ab71aa0f1c02956570dadb3173_b.jpg\"/></figure><p>如果谁有可以可视化caffe网络结构图并保存成高清图片的方法，请告诉我一下，netscope不能保存图，graphviz的图又效果很差，所以这里没有放完整结构图。</p><p>不过，大家可以去参考mobilenet，然后我们在mac上跑一遍，看看时间代价如下：</p><p>其中黄色高亮是统计的每一个module的时间和。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-be3d5894459071fe9c4473ab84734bca_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"718\" data-rawheight=\"2908\" class=\"origin_image zh-lightbox-thumb\" width=\"718\" data-original=\"https://pic3.zhimg.com/v2-be3d5894459071fe9c4473ab84734bca_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;718&#39; height=&#39;2908&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"718\" data-rawheight=\"2908\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"718\" data-original=\"https://pic3.zhimg.com/v2-be3d5894459071fe9c4473ab84734bca_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-be3d5894459071fe9c4473ab84734bca_b.jpg\"/></figure><p>准备工作完毕，接下来开始干活。</p><h2><b>1 分析网络的性能瓶颈</b></h2><blockquote>1.1 运行时间和计算代价分析</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-5482c3b56cd3b0d8a927f03119520e56_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"460\" data-rawheight=\"719\" class=\"origin_image zh-lightbox-thumb\" width=\"460\" data-original=\"https://pic3.zhimg.com/v2-5482c3b56cd3b0d8a927f03119520e56_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;460&#39; height=&#39;719&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"460\" data-rawheight=\"719\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"460\" data-original=\"https://pic3.zhimg.com/v2-5482c3b56cd3b0d8a927f03119520e56_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-5482c3b56cd3b0d8a927f03119520e56_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-23185e46236e57cc50a72dfe2ddf5113_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"535\" data-rawheight=\"716\" class=\"origin_image zh-lightbox-thumb\" width=\"535\" data-original=\"https://pic4.zhimg.com/v2-23185e46236e57cc50a72dfe2ddf5113_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;535&#39; height=&#39;716&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"535\" data-rawheight=\"716\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"535\" data-original=\"https://pic4.zhimg.com/v2-23185e46236e57cc50a72dfe2ddf5113_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-23185e46236e57cc50a72dfe2ddf5113_b.jpg\"/></figure><p>上面两图分别是网络的计算时间和计算量，从上面我们总结几条规律：</p><p>(1) 耗时前5，conv2_1_sep，conv6_sep，conv3_1_sep，conv3_1_dw，conv2_1_dw。</p><p>我们看看为什么，</p><p>conv2_1_dw计算量，32*80*80*3*3*1=1843200</p><p>conv2_1_sep计算量，32*80*80*1*1*64=13107200</p><p>conv3_1_dw计算量，128*40*40*3*3*1=1843200</p><p>conv3_1_sep计算量，128*40*40*1*1*128=26214400</p><p>conv6_sep计算量，1024*5*5*1*1*1024=26214400</p><p>上面可以看出，计算量最大的是conv6_sep，conv2_1_sep，理论上conv2_1_dw计算量与conv2_1_sep不在一个量级，但是实际上相当，这是库实现的问题。</p><p>(2) 从conv5_1到conv5_5，由于尺度不发生变化，通道数不发生变化，所以耗时都是接近的，且dw模块/sep模块耗时比例约为1:3。</p><p>前者计算量：512*10*10*3*3</p><p>后者计算量：512*10*10*1*1*512</p><p>这一段网络结构是利用网络深度增加了非线性，所以对于复杂程度不同的问题，我们可以缩减这一段的深度。</p><blockquote>1.2 网络参数量分析</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ddb1e554d35964cdedf608ac5638b26e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"504\" data-rawheight=\"683\" class=\"origin_image zh-lightbox-thumb\" width=\"504\" data-original=\"https://pic3.zhimg.com/v2-ddb1e554d35964cdedf608ac5638b26e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;504&#39; height=&#39;683&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"504\" data-rawheight=\"683\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"504\" data-original=\"https://pic3.zhimg.com/v2-ddb1e554d35964cdedf608ac5638b26e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-ddb1e554d35964cdedf608ac5638b26e_b.jpg\"/></figure><p>从上面我们可以看出，参数量集中在conv6_sep，conv5_6_sep，conv5_1~5_5，所以要压缩模型，应该从这里地方入手。</p><p>当我们想设计更小的mobilenet网络时，有3招是基本的，一定要用。</p><p>(1) 降低输入分辨率，根据实际问题来设定。</p><p>(2) 调整网络宽度，也就是channel数量。</p><p>(3) 调整网络深度，比如从conv4_2到conv5_6这一段，都可以先去试一试。</p><h2><b>2 开始调整网络</b></h2><p>在做这件事之前，我们先看看经典网络结构的一些东西，更具体可以参考之前的文章。</p><a href=\"https://zhuanlan.zhihu.com/p/25797790\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-250016bc1e7e898c11192cb24786f719_180x120.jpg\" data-image-width=\"5473\" data-image-height=\"3868\" class=\"internal\">龙鹏：【技术综述】为了压榨CNN模型，这几年大家都干了什么</a><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d21494f9b590caff586f6567620d98f9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1729\" data-rawheight=\"376\" class=\"origin_image zh-lightbox-thumb\" width=\"1729\" data-original=\"https://pic2.zhimg.com/v2-d21494f9b590caff586f6567620d98f9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1729&#39; height=&#39;376&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1729\" data-rawheight=\"376\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1729\" data-original=\"https://pic2.zhimg.com/v2-d21494f9b590caff586f6567620d98f9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d21494f9b590caff586f6567620d98f9_b.jpg\"/></figure><p>从上面的表看，主流网络第一个卷积，kernel=3，stride=2，featuremap=64，mobilenet系列已经降到了32。</p><p>第1层是提取边缘等信息的，当然是featuremap数量越大越好，但是其实边缘检测方向是有限的，很多信息是冗余的， 由于mobilenet优异的性能，事实证明，最底层的卷积featuremap channel=32已经够用。</p><p>实际的任务中，大家可以看conv1占据的时间来调整，不过大部分情况下只需要选择好输入尺度大小做训练，然后套用上面的参数即可，毕竟这一层占据的时间和参数，都不算多，32已经足够好足够优异，不太需要去调整的。</p><p>自从任意的卷积可以采用3*3替代且计算量更小后，网络结构中现在只剩下3*3和1*1的卷积，其他的尺寸可以先不考虑。</p><p>采用80*80输入，砍掉conv5_6和conv6，得到的模型各层花费时间如下</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e468e7f3159c88653adcf7a521af5557_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"648\" data-rawheight=\"2908\" class=\"origin_image zh-lightbox-thumb\" width=\"648\" data-original=\"https://pic4.zhimg.com/v2-e468e7f3159c88653adcf7a521af5557_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;648&#39; height=&#39;2908&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"648\" data-rawheight=\"2908\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"648\" data-original=\"https://pic4.zhimg.com/v2-e468e7f3159c88653adcf7a521af5557_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e468e7f3159c88653adcf7a521af5557_b.jpg\"/></figure><p>总共274ms，我们称这个模型为<b>mobilenet_v0</b>。</p><blockquote><b>2.1 如何决定输入尺度</b></blockquote><p>输入尺度绝对是任务驱动的，不同的任务需要不同的输入尺度，分割比分类需要尺度一般更大，检测又比分割所需要的尺度更大，在这里，我们限定一个比较简单的分割任务，然后将输入尺度定为80*80，就将该任务称为A吧。</p><blockquote><b>2.2 如何调整网络宽度与深度</b></blockquote><p>通道数决定网络的宽度，对时间和网络大小的贡献是一个乘因子，这是优化模型首先要做的，下面开始做。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.2.1 反卷积</code></pre></div><p>看上面的模型我们可以看出，反卷积所占用时间远远大于前面提取特征的卷积，这是因为我们没有去优化过这个参数。那么，到底选择多少才合适呢？</p><p>在这里经验就比较有用了。卷积提取特征的过程，是featuremap尺度变小，channel变大，反卷积正好相反，featuremap不断变大，通道数不断变小。这里有4次放大2倍的卷积，考虑到每次缩放一倍，所以第一次的channel数量不能小于2^4=16，一不做二不休，我们干脆就干为16。</p><p>我们称这个模型为mobilenet_v1</p><p>我们看下时间对比</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b98dc35e80cc49cd2d96b8df0d2bef00_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1729\" data-rawheight=\"273\" class=\"origin_image zh-lightbox-thumb\" width=\"1729\" data-original=\"https://pic1.zhimg.com/v2-b98dc35e80cc49cd2d96b8df0d2bef00_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1729&#39; height=&#39;273&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1729\" data-rawheight=\"273\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1729\" data-original=\"https://pic1.zhimg.com/v2-b98dc35e80cc49cd2d96b8df0d2bef00_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b98dc35e80cc49cd2d96b8df0d2bef00_b.jpg\"/></figure><p>再看下性能对比。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-7bbdbf9bf0991bd0b4fd1b7ca967f490_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"204\" class=\"origin_image zh-lightbox-thumb\" width=\"1617\" data-original=\"https://pic1.zhimg.com/v2-7bbdbf9bf0991bd0b4fd1b7ca967f490_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1617&#39; height=&#39;204&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"204\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1617\" data-original=\"https://pic1.zhimg.com/v2-7bbdbf9bf0991bd0b4fd1b7ca967f490_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-7bbdbf9bf0991bd0b4fd1b7ca967f490_b.jpg\"/></figure><p>这样，一举将模型压缩5倍，时间压缩5倍，而且现在反卷积的时间代价几乎已经可以忽略。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.2.2 粗暴地减少网络宽度</code></pre></div><p>接下来我们再返回第1部分，conv5_1到conv5_5的计算量和时间代价都是不小的，且这一部分featuremap大小不再发生变化。这意味着什么？这意味着这一部分，纯粹是为了增加网络的非线性性。</p><p>下面我们直接将conv5_1到conv5_5的featuremap从512全部干到256，称其为mobilenet2.1.1，再看精度和时间代价。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0982789dc5be9462540d469aeac8c773_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"204\" class=\"origin_image zh-lightbox-thumb\" width=\"1617\" data-original=\"https://pic4.zhimg.com/v2-0982789dc5be9462540d469aeac8c773_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1617&#39; height=&#39;204&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"204\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1617\" data-original=\"https://pic4.zhimg.com/v2-0982789dc5be9462540d469aeac8c773_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0982789dc5be9462540d469aeac8c773_b.jpg\"/></figure><p>时间代价和网络大小又有了明显下降，不过精度也有下降。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.2.3 粗暴地减少网络深度</code></pre></div><p>网络层数决定网络的深度，在一定的范围内，深度越深，网络的性能就越优异。但是从第一张图我们可看出来了，网络越深，featureamap越小，channel数越多，这个时候的计算量也是不小的。</p><p>所以，针对特定的任务去优化模型的时候，我们有必要去优化网络的深度，当然是在满足精度的前提下，越小越好。</p><p>我们从一个比较好的起点开始，从mobilenet_v1开始吧，直接砍掉conv5_5这个block，将其称为mobilenet_v2.1.2。</p><p>下面来看看比较。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c53166d440f1babb38cf876f47faab31_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"204\" class=\"origin_image zh-lightbox-thumb\" width=\"1617\" data-original=\"https://pic2.zhimg.com/v2-c53166d440f1babb38cf876f47faab31_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1617&#39; height=&#39;204&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"204\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1617\" data-original=\"https://pic2.zhimg.com/v2-c53166d440f1babb38cf876f47faab31_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c53166d440f1babb38cf876f47faab31_b.jpg\"/></figure><p>从结果来看，精度下降尚且不算很明显，不过时间的优化很有限，模型大小压缩也有限。</p><p>下面在集中看一下同时粗暴地减少网络深度和宽度的结果，称其为mobilenet_v2.1.3</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c967f91c0928276abf5617aee860ecee_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"204\" class=\"origin_image zh-lightbox-thumb\" width=\"1617\" data-original=\"https://pic3.zhimg.com/v2-c967f91c0928276abf5617aee860ecee_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1617&#39; height=&#39;204&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"204\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1617\" data-original=\"https://pic3.zhimg.com/v2-c967f91c0928276abf5617aee860ecee_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c967f91c0928276abf5617aee860ecee_b.jpg\"/></figure><p>以损失将近1%的代价，将模型压缩到2.7m，40ms以内，这样的结果，得看实际应用能不能满足要求了。</p><p>总之，粗暴地直接减小深度和宽度，都会造成性能的下降。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.2.4 怎么弥补通道的损失</code></pre></div><p>从上面我们可以看出，减少深度和宽度，虽然减小了模型，但是都带来了精度的损失，很多时候这种精度损失导致模型无法上线。所以，我们需要一些其他方法来解决这个问题。</p><div class=\"highlight\"><pre><code class=\"language-text\">2.2.4.1 crelu通道补偿</code></pre></div><p>从上面可以看出，网络宽度对结果的影响非常严重，如果我们可以想办法维持原来的网络宽度，且不显著增加计算量，那就完美了。正好有这样的方法，来源于这篇文章《Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units》，它指出网络的参数有互补的现象，如果将减半后的通道补上它的反，会基本上相当于原有的模型，虽然原文针对的是网络浅层有这样的现象，不过深层我们不妨一试，将其用于参数量和计算代价都比较大的conv5_1到conv5_4，我们直接从mobilenet_v2.1.3开始，增加conv5_1到conv5_4的网络宽度，称之为mobilenet_v2.1.4。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-08fc41322d5747c5d602921f94ef1277_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"204\" class=\"origin_image zh-lightbox-thumb\" width=\"1617\" data-original=\"https://pic4.zhimg.com/v2-08fc41322d5747c5d602921f94ef1277_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1617&#39; height=&#39;204&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"204\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1617\" data-original=\"https://pic4.zhimg.com/v2-08fc41322d5747c5d602921f94ef1277_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-08fc41322d5747c5d602921f94ef1277_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">2.2.4.2 skip connect，融合不同层的信息</code></pre></div><p>这是说的不能再多，用的不能再多了的技术。从FCN开始，为了恢复分割细节，从底层添加branch到高层几乎就是必用的技巧了，它不一定能在精度指标上有多少提升，但是对于分割的细节一般是正向的。</p><p>我们直接从mobilenet_v2.1.3开始，添加3个尺度的skip connection。由于底层的channel数量较大，deconv后的channel数量较小，因此我们添加1*1卷积改变通道，剩下来就有了两种方案，1，concat。2，eltwise。</p><p>针对这两种方案，我们分别进行试验。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c75474d954402352ed4dc0cb6a0ff5e7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"271\" class=\"origin_image zh-lightbox-thumb\" width=\"1617\" data-original=\"https://pic4.zhimg.com/v2-c75474d954402352ed4dc0cb6a0ff5e7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1617&#39; height=&#39;271&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1617\" data-rawheight=\"271\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1617\" data-original=\"https://pic4.zhimg.com/v2-c75474d954402352ed4dc0cb6a0ff5e7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c75474d954402352ed4dc0cb6a0ff5e7_b.jpg\"/></figure><p>从上表可以看出，两个方案都不错，时间代价和模型大小增加都很小，而精度提升较大。</p><p>现在反过头回去看刚开始的模型v0，在精确度没有下降的情况下，我们已经把速度优化了5倍以上，模型大小压缩到原来的1/10，已经满足一个通用的线上模型了。</p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote>当然，我们不可能道尽所有的技术，而接着上面的思路，也还有很多可以做的事情，本篇的重点，是让大家<b>学会分析性能网络的性能瓶颈，从而针对性的去优化网络</b>。更多类似技巧和实验，作为技术人员，自己尝试去吧。</blockquote><p class=\"ztext-empty-paragraph\"><br/></p><p><b>更多请移步</b></p><blockquote>1，我的gitchat达人课</blockquote><a href=\"https://link.zhihu.com/?target=http%3A//gitbook.cn/gitchat/column/5a6011fbbd5ff2623773394c\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-778539fd0d72d5e46ebabd371db4df83_180x120.jpg\" data-image-width=\"1920\" data-image-height=\"1080\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">龙鹏的达人课</a><blockquote>2，AI技术公众号,《与有三学AI》</blockquote><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649028681%26idx%3D1%26sn%3D44147bf8c9006c5d72dd51ed2f2871ba%26chksm%3D87134634b064cf22501feda3afff66beec38a09ec0ff91ac58c70a4f8c00da83b8ecfbf50175%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">一文说说这十多年来计算机玩摄影的历史</a><blockquote>3，以及摄影号，《有三工作室》</blockquote><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzczNzY0Mw%3D%3D%26mid%3D2648543699%26idx%3D1%26sn%3Da17c65aac9a2d07af0af141b4c0048bb%26chksm%3D87234517b054cc01458e30468906cc59010a1fd0a74db8b3a935ef0d83e7d17b163f274a23c2%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-8a86f4fc840333cf9e0dea9544dc9dde_ipico.jpg\" data-image-width=\"640\" data-image-height=\"640\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【摄影大咖2】论自拍，我只服这位悬崖上的自拍狂</a><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "AI技术", 
                    "tagLink": "https://api.zhihu.com/topics/20106982"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }
            ], 
            "comments": [
                {
                    "userName": "kaka366", 
                    "userLink": "https://www.zhihu.com/people/d6fb841aea355166ad9038ae8be941a9", 
                    "content": "用caffe？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "嗯，用caffe", 
                            "likes": 0, 
                            "replyToAuthor": "kaka366"
                        }
                    ]
                }, 
                {
                    "userName": "Big Fish", 
                    "userLink": "https://www.zhihu.com/people/d934ea45b23f9992a71acbeb17777902", 
                    "content": "实用！", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "不灌水不写虚头巴脑的东西😁", 
                            "likes": 0, 
                            "replyToAuthor": "Big Fish"
                        }
                    ]
                }, 
                {
                    "userName": "不懂就要问", 
                    "userLink": "https://www.zhihu.com/people/8e6a22c52c8d36531a760bb728e1f95b", 
                    "content": "<p>很厉害 有github链接吗 </p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "最近比较忙还没放，五一之前放上去", 
                            "likes": 0, 
                            "replyToAuthor": "不懂就要问"
                        }
                    ]
                }, 
                {
                    "userName": "花好月圆", 
                    "userLink": "https://www.zhihu.com/people/be89ae99b2185a8de57d2e10fd560e26", 
                    "content": "来个github链接吧，多谢！", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "五一前一定放上去", 
                            "likes": 0, 
                            "replyToAuthor": "花好月圆"
                        }
                    ]
                }, 
                {
                    "userName": "荷叶卷", 
                    "userLink": "https://www.zhihu.com/people/f2b01896a4e6d17e775a7b28be65e215", 
                    "content": "<p>期待 github 链接嘻嘻嘻</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "会随新书以及gitchat课程一起上线", 
                            "likes": 0, 
                            "replyToAuthor": "荷叶卷"
                        }, 
                        {
                            "userName": "雨人", 
                            "userLink": "https://www.zhihu.com/people/ceac4d25e23c74565fadc3d1a57c6d19", 
                            "content": "<p>新书好像没有第八章的代码？</p>", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "小灰灰超", 
                    "userLink": "https://www.zhihu.com/people/56d8f862c20782123fff71af1758a0b5", 
                    "content": "想问一下 那个时间开销是用什么工具统计的", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "mac上自己写代码", 
                            "likes": 0, 
                            "replyToAuthor": "小灰灰超"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/25797790", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 216, 
            "title": "【技术综述】为了压缩CNN模型，这几年大家都干了什么", 
            "content": "<p>本文于2017-3-12日首发于公众号《有三AI》，很多技术已经更新了，请大家及时关注</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649028648%26idx%3D1%26sn%3D79b16adfdea5e21fdde27b557212ac66%26chksm%3D87134655b064cf43f98162d9f44d41a3d6ca850be33c8517745cea3bbeddd52fb15d770e97db%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-2d9ceed78978badf52f685b50ced44c6_ipico.jpg\" data-image-width=\"358\" data-image-height=\"358\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">为了压榨CNN模型，这几年大家都干了什么</a><p>如果从2006年算，深度学习从产生到火爆已经<b>十年了</b>，在工业界已经产生了很多落地的应用。现在网络的深度已经可达1000层以上，下面我们关注一个问题：</p><p>这些年大家是<b><u>怎么“压榨”CNN模型的</u>。</b></p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a4bc9ccabc0706f0af16b39086d7486f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"281\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic4.zhimg.com/v2-a4bc9ccabc0706f0af16b39086d7486f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;281&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"281\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic4.zhimg.com/v2-a4bc9ccabc0706f0af16b39086d7486f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a4bc9ccabc0706f0af16b39086d7486f_b.jpg\"/></figure><p>首先回顾一下几个经典模型，我们主要看看<b><u>深度和caffe模型大小</u>。</b></p><b><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-b25242551ac5ed4b9c3bdfefb327cd2d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"829\" data-rawheight=\"234\" class=\"origin_image zh-lightbox-thumb\" width=\"829\" data-original=\"https://pic2.zhimg.com/v2-b25242551ac5ed4b9c3bdfefb327cd2d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;829&#39; height=&#39;234&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"829\" data-rawheight=\"234\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"829\" data-original=\"https://pic2.zhimg.com/v2-b25242551ac5ed4b9c3bdfefb327cd2d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-b25242551ac5ed4b9c3bdfefb327cd2d_b.jpg\"/></figure></b><p>当然，在实际应用中，各自调试出的version会有出入，网络的大小也不止和深度有关系，此处想说明的问题是：好像<b><u>模型大小(参数量)和模型的深浅并非是正相关</u>。</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a137e98b5c3d5eaa44c792cdd733820c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"500\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic1.zhimg.com/v2-a137e98b5c3d5eaa44c792cdd733820c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;500&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"500\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic1.zhimg.com/v2-a137e98b5c3d5eaa44c792cdd733820c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a137e98b5c3d5eaa44c792cdd733820c_b.jpg\"/></figure><p><b>下面言归正传，这里要讲的压榨主要是将模型变小，以便在ARM，FPGA，ASIC等存储空间有限的平台应用。</b></p><p>从2个方面进行回顾。第一条是<b><u>经典模型的设计路线</u></b>，可以看得出本身就在不断压缩模型。第二条是在<b><u>网络结构基本不变</u></b>的情况下，对<b><u>模型参数的压缩</u></b>。</p><blockquote><b>1.经典模型进阶路</b></blockquote><ul><li><b>Fully connect to local connect</b> </li></ul><p>这里我们仍然放这张经典的比较图，从最早的<b>全连接神经网络到卷积神经网络</b>本身就是一场大的参数压缩革命。</p><p>按照全连接神经网络的思想，1000×1000的图像，如果隐藏层也是同样大小(1000*1000个)的神经元，那么由于神经元和图像每一个像素连接，则会有参数1000×1000×1000×1000。光是一层网络，就已经有10^12个参数。<br/></p><p>而如果采用卷积神经网络，则由于<b>权值共享</b>，对于同样多的隐藏层，假如每个神经元只和输入10×10的局部patch相连接，且卷积核移动步长为10，则参数为：1000×1000×100，降低了4个数量级。<br/></p><p>至于为什么可以这么做，读者可以自己去关注卷积神经网络的由来，主要原理在于<b>图像的局部patch可以与全图有类似的统计特性</b>。<br/></p><p><b>这第一招，也是最厉害的一招，一举将神经网络的参数减小许多个数量级，才能有深度学习的发展。</b></p><b><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a77c19e03d25d7006c160ad0fcd372ee_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"671\" data-rawheight=\"251\" class=\"origin_image zh-lightbox-thumb\" width=\"671\" data-original=\"https://pic3.zhimg.com/v2-a77c19e03d25d7006c160ad0fcd372ee_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;671&#39; height=&#39;251&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"671\" data-rawheight=\"251\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"671\" data-original=\"https://pic3.zhimg.com/v2-a77c19e03d25d7006c160ad0fcd372ee_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a77c19e03d25d7006c160ad0fcd372ee_b.jpg\"/></figure></b><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><ul><li><b>NIN 1×1卷积使用</b> </li></ul><p>Alexnet[1]是一个8层的卷积神经网络，有约60M个参数，如果采用32bit float存下来有200M。值得一提的是，AlexNet中仍然有3个全连接层，其参数量占比参数总量超过了90%。<br/></p><p>NIN[2]是一个4层的网络结构，其直接对标对象就是AlexNet，那么为什么模型大小只有前者的1/10呢？</p><p>除了去掉了全连接层外(<b>这也是模型变小的关键</b>)，提出了<b>1×1的卷积核</b>，后来被广泛用于GoogLeNet[3]和ResNet[4]。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-3ee90532fbe77abf416f4c532c0154b7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"399\" data-rawheight=\"300\" class=\"content_image\" width=\"399\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;399&#39; height=&#39;300&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"399\" data-rawheight=\"300\" class=\"content_image lazy\" width=\"399\" data-actualsrc=\"https://pic4.zhimg.com/v2-3ee90532fbe77abf416f4c532c0154b7_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>下面举一个例子，假如输入为28×28×192，输出feature map通道数为128。那么，直接接3×3卷积，参数量为3×3×192×128=221184。</p><p>如果先用1×1卷积进行降维到96个通道，然后再用3×3升维到128，则参数量为：1×1×192×96+3×3×96×128=129024，参数量减少一半。虽然参数量减少不是很明显，但是如果1×1输出维度降低到48呢？则参数量又减少一半。对于上千层的大网络来说，效果还是很明显了。</p><p>移动端对模型大小很敏感。下载一个100M的app与50M的app，首先用户心理接受程度就不一样。</p><p>到此你可能有一个疑问？<b>原则上降低通道数是会降低性能的，这里为什么却可以降维呢？</b></p><p>笔者没有能力去完整回答这个问题，但是我们可以从很多embedding技术，比如PCA等中得到思考，<b>降低一定的维度可以去除冗余数据，损失的精度其实很多情况下都不会对我们解决问题有很大影响。</b></p><p>当然了该文章最重要的贡献<b>应该是通过这种内嵌的结构，在通道之间组合信息从而增强了网络的非线性表达能力</b>。</p><p>一句话：1×1卷积，在 GoogLeNet Inception v1[3]以及后续版本，ResNet[4]中都大量得到应用，有减少模型参数的作用。</p><ul><li><b>卷积拆分</b> </li></ul><p>(1) VGG</p><p>VGG可以认为是AlexNet的增强版，<b>两倍的深度，两倍的参数量</b>。不过，也提出了一个模型压缩的trick，后来也被广泛借鉴。</p><p>那就是，对于5×5的卷积，使用两个3×3的卷积串联，可以得到同样的感受野，但参数量却有所降低，为3×3×2/(5×5)=0.72，同样的道理3个3×3卷积代替一个7×7，则参数压缩比3×3×3/(7×7)=0.55，降低一倍的参数量，也是很可观的。</p><p>(2) GoogLeNet[3]<br/>GoogleLet Inception v2就借鉴了VGG上面的思想。而到了Inception V3[3]网络，则更进一步，将<b>大卷积分解(Factorization)为小卷积</b>。</p><p>比如7×7的卷积，拆分成1×7和7×1的卷积后。参数量压缩比为1×7×2/(7×7)=0.29，比上面拆分成3个3×3的卷积，更加节省参数了。</p><p>问题是这种<b>非对称的拆分，居然比对称地拆分成几个小卷积核改进效果更明显</b>，增加了特征多样性。</p><p>只能说<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-1c15107239a15553d9b485e318a05fc7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"254\" class=\"origin_image zh-lightbox-thumb\" width=\"700\" data-original=\"https://pic4.zhimg.com/v2-1c15107239a15553d9b485e318a05fc7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;700&#39; height=&#39;254&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"254\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"700\" data-original=\"https://pic4.zhimg.com/v2-1c15107239a15553d9b485e318a05fc7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-1c15107239a15553d9b485e318a05fc7_b.jpg\"/></figure><p>后来的Resnet就不说了，也是上面这些trick。到现在，<b>基本上网络中都是3×3卷积和1×1卷积</b>，5×5很少见，7×7几乎不可见。</p><p>(3) SqueezeNet[7]</p><p>squeezenet将上面1×1降维的思想进一步拓展。通过减少3×3的filter数量，将其一部分替换为1×1来实现压缩。</p><p>具体的一个子结构如下：<b>一个squeeze模块加上一个expand模块</b>，使squeeze中的通道数量，少于expand通道数量就行。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-042aa4ffa0e252277c6bccd51322a6d6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"477\" data-rawheight=\"288\" class=\"origin_image zh-lightbox-thumb\" width=\"477\" data-original=\"https://pic3.zhimg.com/v2-042aa4ffa0e252277c6bccd51322a6d6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;477&#39; height=&#39;288&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"477\" data-rawheight=\"288\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"477\" data-original=\"https://pic3.zhimg.com/v2-042aa4ffa0e252277c6bccd51322a6d6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-042aa4ffa0e252277c6bccd51322a6d6_b.jpg\"/></figure><p>举上面那个例子，假如输入为M维，如果直接接3×3卷积，输出为8个通道，则参数量：M×3×3×8.</p><p>如果按上图的做法，则参数量为M×1×1×3+3×4×1×1+3×4×3×3，压缩比为：(40+M)/24M, 当M比较大时，约0.04.</p><p>文章最终将<b>AlexNet压缩到原来1/50</b>，而性能几乎不变。<br/></p><p>据我所知的在卷积结构上做文章的，基本上都在这里，当然怎么训练出本来就小的模型不算。</p><blockquote><b>2.模型参数压缩方法</b></blockquote><p><b>2.1 SVD分解法</b></p><p>有研究表明，<b>一层的weights，可以通过其子集进行精确预测</b>，所以可以使用奇异值分解(SVD分解)来对<b>每一层进行低秩近似</b>，下面只提一下基本原理和结论。</p><p>原理：对于一个m×k维的实数矩阵W，其可以进行奇异值分解为W=USV，其中U维度为m×m，S维度为m×k，V维度为k×k。S是<b>非负实数对角矩阵</b>，如果<b>将其对角线的值降序排列并发现其值衰减很快</b>，则只需要前面几维就能保持W的绝大多数信息不丢失，这也是PCA的原理。</p><p>假如只保留t维，那么原来的计算复杂度为O(m×k)，现在则变成了O(m×t+t×t+t×k)，对于足够小的t，O(m×t+t×t+t×k)远小于O(m×k)。</p><p>不过这个方法实际的<b>模型压缩比并不明显</b>，在文章[8]中为2～3的左右，加速比也是2～3左右。所以同类的方法，就不再深究。</p><p><b>2.2 权重参数量化与剪枝</b> </p><p>下面是近两年比较有代表性的研究，主要是通过<b>权重剪枝，量化编码</b>等方法来实现模型压缩。其实最早也有直接对每个权重独立量化的研究[9]，但是效果显然是不如下面的结果的。<br/></p><p><b>(1) DeepCompresion</b> </p><p>这是2016 ICLR最佳论文。文章早期的工作，是Network Pruning，就是去除网络中权重低于一定阈值的参数后，重新finetune一个稀疏网络。在这篇文章中，则进一步添加了量化和编码，思路很清晰简单如下。</p><p><b>（1） 网络剪枝：移除不重要的连接；</b></p><p><b>（2） 权重量化与共享：让许多连接共享同一权重，使原始存储整个网络权重变为只需要存储码本(有效的权重)和索引；</b></p><p><b>（3） 霍夫曼编码：更高效利用了权重的有偏分布；</b></p><p>第一部分很好理解，就是如下流程：</p><p><b>（1） 普通网络训练；</b></p><p><b>（2） 删除权重小于一定阈值的连接得到稀疏网络；</b></p><p><b>（3） 对稀疏网络再训练；</b></p><p>霍夫曼编码是一种成熟的编码技巧与cnn无关。下面只说说第二部分，这是从文章摘取的图，对于一个4×4的权值矩阵，量化权重为4阶（-1.0，0，1.5，2.0）。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-17057aa29fbc659cb674ab45ef2d4a38_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"755\" data-rawheight=\"461\" class=\"origin_image zh-lightbox-thumb\" width=\"755\" data-original=\"https://pic1.zhimg.com/v2-17057aa29fbc659cb674ab45ef2d4a38_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;755&#39; height=&#39;461&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"755\" data-rawheight=\"461\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"755\" data-original=\"https://pic1.zhimg.com/v2-17057aa29fbc659cb674ab45ef2d4a38_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-17057aa29fbc659cb674ab45ef2d4a38_b.jpg\"/></figure><p>那么索引表就是：</p><p>0：-1.0</p><p>1：0</p><p>2：1.5</p><p>3：2.0</p><p>对weights采用cluster index进行存储后，原来需要<b>16个32bit float</b>，现在只需要<b>4个32bit float码字，与16个2bit uint索引</b>，参数量为原来的(16×2+4×32)/(16×32)=0.31。</p><p>存储是没问题了，那如何对量化值进行更新呢？事实上，文中仅对码字进行更新。如上图：将<b>索引相同的地方梯度求和乘以学习率，叠加到码字</b>。</p><p>这样的效果，就等价于<b>不断求取weights的聚类中心</b>。原来有成千上万个weights，现在经过一个有效的聚类后，每一个weights都用其聚类中心进行替代，作者的研究表明这样并不会降低网络的效果。而聚类的迭代过程，通过BP的反向传播完成，不得不说，想法非常plain和beautiful，难怪能得best paper。</p><p>看下表就知道最终的压缩效率非常可观，把500M的VGG干到了11M。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2fdd38145a76efe8d1e1d07692c32175_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1006\" data-rawheight=\"333\" class=\"origin_image zh-lightbox-thumb\" width=\"1006\" data-original=\"https://pic2.zhimg.com/v2-2fdd38145a76efe8d1e1d07692c32175_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1006&#39; height=&#39;333&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1006\" data-rawheight=\"333\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1006\" data-original=\"https://pic2.zhimg.com/v2-2fdd38145a76efe8d1e1d07692c32175_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2fdd38145a76efe8d1e1d07692c32175_b.jpg\"/></figure><p>文中还比较了如果只用剪枝或者只用量化对结果的影响，表明各自都对压缩比低于一定阈值时很敏感，如下。而<b>combine两个trick，则在压缩比达到5%时，仍然性能不降</b>。当然了还有如<b>卷积层对压缩比比全连接层更敏感</b>等结论，感兴趣可以自己去读。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-fae874e95550981e74f2ba0ab5758c94_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"818\" data-rawheight=\"346\" class=\"origin_image zh-lightbox-thumb\" width=\"818\" data-original=\"https://pic1.zhimg.com/v2-fae874e95550981e74f2ba0ab5758c94_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;818&#39; height=&#39;346&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"818\" data-rawheight=\"346\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"818\" data-original=\"https://pic1.zhimg.com/v2-fae874e95550981e74f2ba0ab5758c94_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-fae874e95550981e74f2ba0ab5758c94_b.jpg\"/></figure><p><b>(2) Binarized Neural Networks</b> </p><p>如果说deep compression是<b>float到uint的压缩</b>，那么这篇就是<b>uint到bool</b>的压缩了。前者只是将weights进行量化，而这个，权重只有+1或者-1二值。</p><p>将<b>权重和每层的激活值全部</b>二值化。如此一来大部分数学运算都是位运算。</p><p>二值化的方法也很简单，文章提到了两种，第一种就是符号函数，即x&gt;0，则f(x)=1，x&lt;0，则f(x)=-1。另一种是以一定的概率赋值，是不是想起了dropout？文中就是，只有在激活函数时，才采用第二种二值化方法，其余都采用符号函数。</p><p>其实大问题就是一个，<b>符号函数的导数并不连续</b>，那怎么进行梯度传播？文中将sign(x)进行放松，在-1到1之间采用了线性函数。</p><p><b>f(x) = max(-1，min(1,x))</b></p><p>主要事项：</p><p>(1) <b>在训练过程中还是需要保存实数的参数的</b>。</p><p>(2)在进行<b>权重参数更新时，裁剪超出[-1,1]的部分</b>，保证权重参数始终是[-1,1]之间的实数。</p><p>而在<b>使用参数时，则将参数进行二值化</b>。</p><p>最终效果到底如何？在一些比较小的数据集，比如MNIST，CIFAR-10上，精度稍微有所下降但不明显，模型大学降低为原来的1/32，32bit的float变成1 bit。对于时间代价可见下图，第2个直方图是MNIST数据集的结果，作者的优化将速度相对于cublas提升了约3.4倍，而精度不变(第三个直方图)。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5b167037b8f20394ec00f4d8018c6014_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"469\" data-rawheight=\"389\" class=\"origin_image zh-lightbox-thumb\" width=\"469\" data-original=\"https://pic1.zhimg.com/v2-5b167037b8f20394ec00f4d8018c6014_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;469&#39; height=&#39;389&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"469\" data-rawheight=\"389\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"469\" data-original=\"https://pic1.zhimg.com/v2-5b167037b8f20394ec00f4d8018c6014_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5b167037b8f20394ec00f4d8018c6014_b.jpg\"/></figure><p>类似的还有什么<b>XORnet，YodaNet</b>，感兴趣的可以去选读。</p><p>就这么多，本文主要关注的是<b>模型压缩</b>，这跟<b>计算量压缩</b>不等价，<b>跟加速</b>也不等价，希望不要搞混淆。</p><p>如有疏漏，错误，请批评指正，谢谢！</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5c292d0d10dc53700ded8b66aefbbced_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"960\" data-rawheight=\"635\" class=\"origin_image zh-lightbox-thumb\" width=\"960\" data-original=\"https://pic2.zhimg.com/v2-5c292d0d10dc53700ded8b66aefbbced_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;960&#39; height=&#39;635&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"960\" data-rawheight=\"635\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"960\" data-original=\"https://pic2.zhimg.com/v2-5c292d0d10dc53700ded8b66aefbbced_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5c292d0d10dc53700ded8b66aefbbced_b.jpg\"/></figure><blockquote><b>时隔一年，以mobilenet为代表的很多技术已经更新了，我会找时间再来补上，等不及的大家自己去学习吧。</b></blockquote><p>【1】Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.</p><p>【2】Lin M, Chen Q, Yan S. Network in network[J]. arXiv preprint arXiv:1312.4400, 2013.</p><p>【3】Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 1-9.</p><p>【4】He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 770-778.</p><p>【5】Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.</p><p>【6】Szegedy C, Vanhoucke V, Ioffe S, et al. Rethinking the inception architecture for computer vision[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: <a href=\"tel:2818-2826\">2818-2826</a>.</p><p>【7】Iandola F N, Han S, Moskewicz M W, et al. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and&lt; 0.5 MB model size[J]. arXiv preprint arXiv:1602.07360, 2016.</p><p>【8】Denton E L, Zaremba W, Bruna J, et al. Exploiting linear structure within convolutional networks for efficient evaluation[C]//Advances in Neural Information Processing Systems. 2014: 1269-1277.</p><p>【9】Vanhoucke V, Senior A, Mao M Z. Improving the speed of neural networks on CPUs[C]//Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop. 2011, 1: 4.</p><p>【10】Han S, Mao H, Dally W J. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding[J]. arXiv preprint arXiv:1510.00149, 2015.</p><p>【11】Hubara I, Courbariaux M, Soudry D, et al. Binarized neural networks[C]//Advances in Neural Information Processing Systems. 2016: <a href=\"tel:4107-4115\">4107-4115</a>.</p>", 
            "topic": [
                {
                    "tag": "卷积神经网络（CNN）", 
                    "tagLink": "https://api.zhihu.com/topics/20043586"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": [
                {
                    "userName": "蔡世勋", 
                    "userLink": "https://www.zhihu.com/people/430463befe88a88fae38e793e9e44241", 
                    "content": "该评论已删除", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "😄", 
                            "likes": 1, 
                            "replyToAuthor": "蔡世勋"
                        }
                    ]
                }, 
                {
                    "userName": "蔡世勋", 
                    "userLink": "https://www.zhihu.com/people/430463befe88a88fae38e793e9e44241", 
                    "content": "<p>压缩数据量，是模型应用到手机端的关键。</p>", 
                    "likes": 1, 
                    "childComments": []
                }, 
                {
                    "userName": "蔡世勋", 
                    "userLink": "https://www.zhihu.com/people/430463befe88a88fae38e793e9e44241", 
                    "content": "<p><a href=\"http://link.zhihu.com/?target=http%3A//www.leiphone.com/news/201704/03JshwfumoRwunlw.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">谭洪贺：AI 芯片怎么降功耗？从 另外一个维度讲了如何压榨神经网络</a></p>", 
                    "likes": 1, 
                    "childComments": []
                }, 
                {
                    "userName": "蔡世勋", 
                    "userLink": "https://www.zhihu.com/people/430463befe88a88fae38e793e9e44241", 
                    "content": "<a href=\"https://zhuanlan.zhihu.com/p/26528060\" class=\"internal\">GAN隐空间维数选择</a>，文章说了压榨也是有极限的", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "霍华德", 
                    "userLink": "https://www.zhihu.com/people/4a0d3a504b9859139f2c003005230717", 
                    "content": "干货满满", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<p>哈哈，有收获就好</p>", 
                            "likes": 0, 
                            "replyToAuthor": "霍华德"
                        }, 
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "有点用就好😬", 
                            "likes": 0, 
                            "replyToAuthor": "霍华德"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>有个小建议，\"假如每个神经元只和输入10×10的局部patch相连接，则参数为：1000×1000×100，降低了4个数量级\"： 应该补充下这句话成立的前提：卷积核移动的步长=10</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<p>才看到，谢谢指正！</p>", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "Jize", 
                    "userLink": "https://www.zhihu.com/people/7e34cbc0f8cbb1f54a58b2011662f15a", 
                    "content": "下面举一个例子，假如输入为28×28×192，输出feature map通道数为128。那么，直接接3×3卷积，参数量为3×3×192×128=221184。   这句话，想问下，为啥参数量不是3×3×128，需要多加个192", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "因为每一个输出通道是和每一个输入通道相连接的，参数不一样", 
                            "likes": 0, 
                            "replyToAuthor": "Jize"
                        }
                    ]
                }, 
                {
                    "userName": "max poon", 
                    "userLink": "https://www.zhihu.com/people/2605a702944ec1c63ce73e8bc4f9c3b8", 
                    "content": "在squeeze net那部分你举的例子中，为什么expand部分有8个输出通道而不是7个？", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "那个是笔误，谢谢指正!", 
                            "likes": 0, 
                            "replyToAuthor": "max poon"
                        }, 
                        {
                            "userName": "max poon", 
                            "userLink": "https://www.zhihu.com/people/2605a702944ec1c63ce73e8bc4f9c3b8", 
                            "content": "不客气，应该是我们读者谢谢你的良心总结^_^", 
                            "likes": 0, 
                            "replyToAuthor": "言有三-龙鹏"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>感谢分享！</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "谢谢", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }, 
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "<p>😄</p>", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>文中好像少了一个一级标题：2.模型参数压缩方法</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "言有三-龙鹏", 
                            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
                            "content": "好的，我晚点看看", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/33076280", 
            "userName": "言有三-龙鹏", 
            "userLink": "https://www.zhihu.com/people/0c847e12ed6e97608c7377bcef7b837d", 
            "upvote": 12, 
            "title": "【技术综述】如何步入深度学习刷榜第一重境界", 
            "content": "<p>本文首发于微信公众号《与有三学AI》</p><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649028744%26idx%3D1%26sn%3D49425665ad69c96f33a60e6f0fe50cde%26chksm%3D871346f5b064cfe393445c6fc8ffa0b159df03eecf007dfa4ba4866dac0fa644ef92cf2bf80a%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/v2-25ebd31d3f8c97e0429d01a94d0d1e2c_ipico.jpg\" data-image-width=\"225\" data-image-height=\"225\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">如何步入深度学习刷榜第一重境界</a><p>实际上笔者也没多少刷榜经验，毕竟不擅长之前老大也没有任务指派，今年10月份得闲了个把月，没那么多事所以也就参加了一个场景分类的比赛，链接如下，</p><p><a href=\"https://link.zhihu.com/?target=https%3A//challenger.ai/competition/scene/leaderboard/test_a\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">全球AI挑战赛场景分类</a>，</p><p>刷了一个月之后最好成绩也就杀进前15然后就接着干项目去了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f954aca506a416aaae3993640397f52b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"698\" data-rawheight=\"609\" class=\"origin_image zh-lightbox-thumb\" width=\"698\" data-original=\"https://pic4.zhimg.com/v2-f954aca506a416aaae3993640397f52b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;698&#39; height=&#39;609&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"698\" data-rawheight=\"609\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"698\" data-original=\"https://pic4.zhimg.com/v2-f954aca506a416aaae3993640397f52b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f954aca506a416aaae3993640397f52b_b.jpg\"/></figure><p>与第一名差一个点，7000张，80类，基本上每一类差1张图。到比赛结束的时候排在第20名左右，与第一名还是差一个点。</p><p>说出去好像是有点不太好意思，但是作为第一次刷比赛，一个月也不能白费，毕竟绩效打在那里。现在的比赛听说还有专业刷榜团队的，也是666。</p><p>下面也简单分享一下。</p><div class=\"highlight\"><pre><code class=\"language-text\">0 刷的是什么比赛？</code></pre></div><p>场景分类，80类日常生活中比较多的场景，这个在以后的社交应用中还是有需求的，相关最大的比赛是place365，有兴趣可以去看。眼下这个，是创新工场，今日头条，搜狗等一起搞的比赛，train数据集就不大，只有50000+，测试数据集7000+。</p><p>下面举10类吧</p><p>0/航站楼：airport_terminal</p><p>1/停机坪：landing_field</p><p>2/机舱：airplane_cabin</p><p>3/游乐场：amusement_park</p><p>4/冰场：skating_rink</p><p>5/舞台：arena/performance</p><p>6/艺术室：art_room</p><p>7/流水线：assembly_line</p><p>8/棒球场：baseball_field</p><p>9/橄榄球场：football_field</p><p>10/足球场：soccer_field</p><div class=\"highlight\"><pre><code class=\"language-text\">1 为什么叫第一境界？</code></pre></div><p>我觉得怎么着刷榜这事也得有个三个境界，像笔者这样，<b>一个人拿现有的模型，4块K40，兼职刷上一个月，最后提交也只融合了两个模型的</b>，怎么看都是处于刚入门的第一境界，大部分人其实也就是这个境界。</p><p>而到了第二三境界，至少得有个集群，得有一群人来尝试各种方案，而顶尖的团队对网络结构肯定是需要调优设计的，历年夺冠的那些网络alexnet，googlenet，resnet，senet无一例外。</p><p>不过设计强大的网络结构从时间代价，计算资源代价和算法能力都有比较高的要求，大部分人可能就是从<b>数据层面</b>做文章了，比如清洗数据，数据增强，搞搞不均衡样本等。</p><div class=\"highlight\"><pre><code class=\"language-text\">2 怎么一步刷到比较优的单模型？</code></pre></div><p>这是最关键的第一步。</p><p>有几点一定是要形成共识的。</p><p>(1) 由于我是只有4个卡，用caffe或者tensorflow都是不可能的，我用了mxnet，并且在训练的过程中都放开了所有参数，实际上也做过固定某些参数的实验，但是效果并不好。224的尺度，放开全部训练的话，4块卡resnet152 batchsize可以到96。在实验的过程中，batchsize越大，指标就越高，几个网络都能观测到相关结论。</p><p>(2) 由于训练数据少，使用当前数据从头训练大模型不太现实，所以，先找到相关数据集比赛finetune过的大网络，resnet系列找了一个resnet152，dpn系列找了一个dpn92，各自先训练。</p><p>(3) <b>从尽量大的模型开始</b>，机器啃得动的就行，毕竟这个任务里面有很多类还是很难的，小网络搞不定，resnet系至少得50层以上。</p><p>在刷这个比赛的时候，从imagenet mxnet<br/>model的模型fine-tune过来，链接在下面。</p><p><a href=\"https://link.zhihu.com/?target=http%3A//data.mxnet.io/models/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">data.mxnet.io/models/</span><span class=\"invisible\"></span></a></p><p>实验了18，50，152层的网络，使用本比赛50000+的数据进行简单的参数调优，</p><p>解释一下，lr是学习率，Lr=0.01(10)代表在10个epochs后下降一个数量级，从0.01到0.001，实际上在10个epoch以后都收敛了，所以后面没有做更多step lr的比较，大家感兴趣可以去尝试。w是weight decay，m是momentum，bs是batch size，单个k40 gpu。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0e61d91710797949d8d57b7226fc4abd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1286\" data-rawheight=\"304\" class=\"origin_image zh-lightbox-thumb\" width=\"1286\" data-original=\"https://pic2.zhimg.com/v2-0e61d91710797949d8d57b7226fc4abd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1286&#39; height=&#39;304&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1286\" data-rawheight=\"304\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1286\" data-original=\"https://pic2.zhimg.com/v2-0e61d91710797949d8d57b7226fc4abd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-0e61d91710797949d8d57b7226fc4abd_b.jpg\"/></figure><p>从上面可以看出，从18层到152层精度毫无疑问是提升的。虽然参数没有调到各自最优，但基本能反应问题。尤其注意的是res18我加了weight decay来增加模型复杂度，不然没有上90%的可能。从resent152到resent200指标就没什么提升了，而且res200远远没有res152参数好调。</p><p>单模型单个crop 94%的精度已经差不多了，</p><p>(4) 理论上随着训练尺度增加，在一定范围内性能也会增加，但是训练尺度的增加会导致能使用的batchsize减小，所以笔者最后统一采用224这个尺度。听说有人用到了700以上的尺度，只能说，真土豪也。</p><p>(5) 单个模型，多个crop会对结果有所提升，有的团队用到了上百个crop，笔者最后用了10个crop，没有去尝试更多，毕竟测试也是很花时间，这点资源一个人搞不过来。</p><p>有了以上的共识后，那就开始干起来，过段时间我会重新整理把项目git传上去，前段时间服务器意外格式化丢了全部训练文件，一时还没有恢复。如果对此感兴趣，请持续关注。</p><p>总结：单模型，以resent152为例。</p><p>训练尺度224*224，数据增强采用了水平flip和随机crop，random<br/>resize参数照搬googlenet那套，放开所有参数，使用resnet152-place365，即在place365数据集上进行训练过的模型，然后使用当前的训练数据集进行finetune，validation数据集进行测试。</p><p>数据增强参数偷懒截个图，实际上这些mxnet全部都已经集成好了，直接设置开关即可。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4d9f2149c9dd9a4e1aa85323d5f09a27_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"656\" data-rawheight=\"467\" class=\"origin_image zh-lightbox-thumb\" width=\"656\" data-original=\"https://pic4.zhimg.com/v2-4d9f2149c9dd9a4e1aa85323d5f09a27_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;656&#39; height=&#39;467&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"656\" data-rawheight=\"467\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"656\" data-original=\"https://pic4.zhimg.com/v2-4d9f2149c9dd9a4e1aa85323d5f09a27_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4d9f2149c9dd9a4e1aa85323d5f09a27_b.jpg\"/></figure><p>训练参数，lr=0.01，分别在10,20,40个epoch时下调学习率，最后采用10个crop，分别为四个角，中心以及水平翻转。</p><p>在试用了多个batchsize之后，最大的能用的batchsize取得最优，resnet152单个模型能到97%。</p><p>在测试的时候有trick，采纳dpn的思想，使用较小的尺度训练，使用较大的尺度测试，最终在略大于224的尺度上，有微小的提升，对于刷榜来说还有很重要的，毕竟0.5%可以干掉10个人。</p><div class=\"highlight\"><pre><code class=\"language-text\">3 怎么做模型融合？</code></pre></div><p>不同网络架构，但能力相当的模型进行融合，结果会稳定提升。</p><p>笔者单模型10个crop，resnet152得到0.971，dpn92得到0.965，两者融合后即到0.978.</p><p>要想得到最优，需采用不同的epoch进行融合，这个需要花时间去测试；所以就会出现两个单模型最优，融合之后缺不是最优的情况。</p><p>这个时候，需要把各自错误样本拿出来分析，我当时没有太多时间和耐心去尝试各种方案。</p><p>这就是提交比赛的最后结果，两个现有的模型在224尺度用4张卡训练，融合之后，在比赛结束前的一个月，能排在15名左右，比赛结束后我回去一看，test_a也在20名以内，test_b也差不多，由于test_b比较难，所有参赛队伍的成绩都下降了4个点左右。</p><div class=\"highlight\"><pre><code class=\"language-text\">4 哪些trick比较关键</code></pre></div><p>虽然提交的结果非常简单，笔者还是实验过很多参数的，稍微有些经验拿出来分享下，有些参数是不能乱调的，有些则不需要调。</p><p>(1) finetune很关键</p><p>从相关大数据集上训练好的模型开始finetune，基本上可以肯定会比从不相关大数据集上训练的模型，或者从头开始训练更好，这个大家应该是通识了。</p><p>(2) 学习率lr和batchsize</p><p>学习率和batch size是成对的参数，batch size增大N倍，相当于将梯度的方差减少N倍，也就是梯度方差更小了，更加准确，更加容易跳出局部最优，带来的后果就是收敛更慢，这时候为了提高训练速度，可以将lr增加sqrt(N)倍。</p><p><b><i>学习率是最关键的参数了</i></b>，没得说，只能自己从大到小开始尝试。</p><p>笔者列举一个例子：dpn92, lr_step_epochs=&#39;10,20,30,40&#39;,w=0,m=0,bs=64,</p><p>lr取0.001，0.005，0.01，0.01，分别看train和val的acc。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-090f58a0052eaec88faf034e01a1bef0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1310\" data-rawheight=\"266\" class=\"origin_image zh-lightbox-thumb\" width=\"1310\" data-original=\"https://pic1.zhimg.com/v2-090f58a0052eaec88faf034e01a1bef0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1310&#39; height=&#39;266&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1310\" data-rawheight=\"266\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1310\" data-original=\"https://pic1.zhimg.com/v2-090f58a0052eaec88faf034e01a1bef0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-090f58a0052eaec88faf034e01a1bef0_b.jpg\"/></figure><p>从小到大，从欠拟合到过拟合，很明显。</p><p><b><i>batch size相对来说没有lr那么敏感，但是对结果也是至关重要的。</i></b></p><p>下面是resnet152的batchsize的实验，mul_val是多个crop</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-39d787a133bab67e4b7f1ab52c039752_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"438\" data-rawheight=\"278\" class=\"origin_image zh-lightbox-thumb\" width=\"438\" data-original=\"https://pic3.zhimg.com/v2-39d787a133bab67e4b7f1ab52c039752_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;438&#39; height=&#39;278&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"438\" data-rawheight=\"278\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"438\" data-original=\"https://pic3.zhimg.com/v2-39d787a133bab67e4b7f1ab52c039752_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-39d787a133bab67e4b7f1ab52c039752_b.jpg\"/></figure><p>下面是dpn92的batchsize的实验，mul_val是多个crop</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-30dc831b2b74db87855bcf171f2deffc_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"530\" data-rawheight=\"288\" class=\"origin_image zh-lightbox-thumb\" width=\"530\" data-original=\"https://pic1.zhimg.com/v2-30dc831b2b74db87855bcf171f2deffc_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;530&#39; height=&#39;288&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"530\" data-rawheight=\"288\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"530\" data-original=\"https://pic1.zhimg.com/v2-30dc831b2b74db87855bcf171f2deffc_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-30dc831b2b74db87855bcf171f2deffc_b.jpg\"/></figure><p>看的出来，指标有所上升。</p><p>当然了，还是那句话，单个最优的模型融合起来并不能保证结果最优。</p><p>(3) weight decay和momentum</p><p>这两个参数，对于小模型的训练是比较关键的，不过越大越不敏感。</p><p>下面是res18的训练结果，从结果看来差异是很大的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6d72fd07f11e8e63d14bc5acd7046bb1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1070\" data-rawheight=\"126\" class=\"origin_image zh-lightbox-thumb\" width=\"1070\" data-original=\"https://pic2.zhimg.com/v2-6d72fd07f11e8e63d14bc5acd7046bb1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1070&#39; height=&#39;126&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1070\" data-rawheight=\"126\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1070\" data-original=\"https://pic2.zhimg.com/v2-6d72fd07f11e8e63d14bc5acd7046bb1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6d72fd07f11e8e63d14bc5acd7046bb1_b.jpg\"/></figure><p>Res50，差距就不明显了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-cc30632e5a9b878468122fb0b68e9d85_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1042\" data-rawheight=\"136\" class=\"origin_image zh-lightbox-thumb\" width=\"1042\" data-original=\"https://pic2.zhimg.com/v2-cc30632e5a9b878468122fb0b68e9d85_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1042&#39; height=&#39;136&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1042\" data-rawheight=\"136\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1042\" data-original=\"https://pic2.zhimg.com/v2-cc30632e5a9b878468122fb0b68e9d85_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-cc30632e5a9b878468122fb0b68e9d85_b.jpg\"/></figure><p>Senet50也是。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-6694c48bcd222424d4d09eb18203a034_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1042\" data-rawheight=\"130\" class=\"origin_image zh-lightbox-thumb\" width=\"1042\" data-original=\"https://pic1.zhimg.com/v2-6694c48bcd222424d4d09eb18203a034_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1042&#39; height=&#39;130&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1042\" data-rawheight=\"130\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1042\" data-original=\"https://pic1.zhimg.com/v2-6694c48bcd222424d4d09eb18203a034_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-6694c48bcd222424d4d09eb18203a034_b.jpg\"/></figure><p>我的结论是这个参数可以去调一调，不过对于大模型可能不是很必要，我都用的是0 </p><p>(4) 测试网络</p><p>下面是单个crop和10个crop的比较</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-191e77feee4c0b501724b0c442c40a30_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1296\" data-rawheight=\"378\" class=\"origin_image zh-lightbox-thumb\" width=\"1296\" data-original=\"https://pic1.zhimg.com/v2-191e77feee4c0b501724b0c442c40a30_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1296&#39; height=&#39;378&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1296\" data-rawheight=\"378\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1296\" data-original=\"https://pic1.zhimg.com/v2-191e77feee4c0b501724b0c442c40a30_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-191e77feee4c0b501724b0c442c40a30_b.jpg\"/></figure><p>很明显，不管是什么网络，多个crop会有很明显的提升，上面稳定提升2%以上，更多的crop笔者没尝试，因为实在是太慢了。</p><p>另一方面，借鉴dpn的思想，用小尺度训练，大尺度测试可能也有微小的点提升。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6cac0a25d686e1b96680403c6145040e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1160\" data-rawheight=\"308\" class=\"origin_image zh-lightbox-thumb\" width=\"1160\" data-original=\"https://pic3.zhimg.com/v2-6cac0a25d686e1b96680403c6145040e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1160&#39; height=&#39;308&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1160\" data-rawheight=\"308\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1160\" data-original=\"https://pic3.zhimg.com/v2-6cac0a25d686e1b96680403c6145040e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-6cac0a25d686e1b96680403c6145040e_b.jpg\"/></figure><p>(5) 数据增强</p><p>本任务中复杂的数据增强没怎么用，使用的是mxnet level=1的数据增强，估计是因为模型已经在大数据库上训练过，au=1就是基本的crop，flip，random<br/>resize，au=2会做图像旋转，au=3会再加上颜色扰动，实际的项目中我们还是会做一点的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-467b7bd30a43916056710d055e9c9e19_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1298\" data-rawheight=\"224\" class=\"origin_image zh-lightbox-thumb\" width=\"1298\" data-original=\"https://pic2.zhimg.com/v2-467b7bd30a43916056710d055e9c9e19_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1298&#39; height=&#39;224&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1298\" data-rawheight=\"224\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1298\" data-original=\"https://pic2.zhimg.com/v2-467b7bd30a43916056710d055e9c9e19_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-467b7bd30a43916056710d055e9c9e19_b.jpg\"/></figure><p>就这么多，不知道你对是否有用，下回搞点机器搞点时间去刷个大榜试试。</p><p><b>更多请移步</b></p><blockquote>1，我的gitchat达人课</blockquote><a href=\"https://link.zhihu.com/?target=http%3A//gitbook.cn/gitchat/column/5a6011fbbd5ff2623773394c\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/v2-778539fd0d72d5e46ebabd371db4df83_180x120.jpg\" data-image-width=\"1920\" data-image-height=\"1080\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">龙鹏的达人课</a><blockquote>2，AI技术公众号,《与有三学AI》</blockquote><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649028759%26idx%3D1%26sn%3D7f7260f530cabb950a6191b0002dfbed%26chksm%3D871346eab064cffc4be460b750ad57270d603a8874c3bed63d9bde463d115cb811297167767d%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/v2-25ebd31d3f8c97e0429d01a94d0d1e2c_ipico.jpg\" data-image-width=\"225\" data-image-height=\"225\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[caffe解读] caffe从数学公式到代码实现1-导论</a><blockquote>3，以及摄影号，《有三工作室》</blockquote><a href=\"https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzczNzY0Mw%3D%3D%26mid%3D2648543628%26idx%3D1%26sn%3D5573c69f7b54acd6e2bfcc123d7a9988%26chksm%3D87234548b054cc5e1aed7177a537fef841768acff589a93d8234fab318bbe682a9da40192134%23rd\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic3.zhimg.com/v2-8a86f4fc840333cf9e0dea9544dc9dde_ipico.jpg\" data-image-width=\"640\" data-image-height=\"640\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">冯小刚说，“他懂我”</a><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-946679151c94cb87962c5a382218d3c4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-946679151c94cb87962c5a382218d3c4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1080&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-946679151c94cb87962c5a382218d3c4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-946679151c94cb87962c5a382218d3c4_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }
            ], 
            "comments": []
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/c_1005865351275573248"
}

{
    "title": "算法工程师", 
    "description": "", 
    "followers": [
        "https://www.zhihu.com/people/lei-xiao-yu-49", 
        "https://www.zhihu.com/people/wu-yue-chen-6", 
        "https://www.zhihu.com/people/chenxiangzhen", 
        "https://www.zhihu.com/people/jia-you-ba-zsw", 
        "https://www.zhihu.com/people/liu-fei-94-95", 
        "https://www.zhihu.com/people/sun-jia-tong-59", 
        "https://www.zhihu.com/people/zhizhu-wang", 
        "https://www.zhihu.com/people/xue-yi-zhi-yong-2", 
        "https://www.zhihu.com/people/crazyvr", 
        "https://www.zhihu.com/people/wanghongze", 
        "https://www.zhihu.com/people/innerpeace-24-25-99", 
        "https://www.zhihu.com/people/mr-lin-82-68", 
        "https://www.zhihu.com/people/yu-huan-92-42", 
        "https://www.zhihu.com/people/yi-dian-yuan-zhi-tong", 
        "https://www.zhihu.com/people/zhang-shao-peng-78-61", 
        "https://www.zhihu.com/people/xiao-xi-11-51-7", 
        "https://www.zhihu.com/people/yun-feng-46-1", 
        "https://www.zhihu.com/people/zhang-shuai-92-1-11", 
        "https://www.zhihu.com/people/sang-jian-shun", 
        "https://www.zhihu.com/people/blueyouth-9", 
        "https://www.zhihu.com/people/tigerking-28", 
        "https://www.zhihu.com/people/dou-you-lu-mian-bao", 
        "https://www.zhihu.com/people/xing-zhe-55-8-2", 
        "https://www.zhihu.com/people/xbl-97", 
        "https://www.zhihu.com/people/nerle", 
        "https://www.zhihu.com/people/wen-de-jin", 
        "https://www.zhihu.com/people/jiang-jun-yan-35", 
        "https://www.zhihu.com/people/zhou-jing-hui-63", 
        "https://www.zhihu.com/people/zhang-xiao-peng-88-4-15", 
        "https://www.zhihu.com/people/zzzzzc-95", 
        "https://www.zhihu.com/people/megatron-58", 
        "https://www.zhihu.com/people/longlyVV", 
        "https://www.zhihu.com/people/Palmer-80", 
        "https://www.zhihu.com/people/zai-lu-shang-12138-26", 
        "https://www.zhihu.com/people/li-jia-54-85-55", 
        "https://www.zhihu.com/people/huang-chun-18", 
        "https://www.zhihu.com/people/yifdu", 
        "https://www.zhihu.com/people/bhltlyr", 
        "https://www.zhihu.com/people/ezail-shen", 
        "https://www.zhihu.com/people/xu-ning-90-74", 
        "https://www.zhihu.com/people/hong-an-10", 
        "https://www.zhihu.com/people/gong-bo-xue-24", 
        "https://www.zhihu.com/people/wang-sheng-66-85", 
        "https://www.zhihu.com/people/long-tao-chen", 
        "https://www.zhihu.com/people/zhe-shan-74-76", 
        "https://www.zhihu.com/people/charles-shen", 
        "https://www.zhihu.com/people/ahahha-99", 
        "https://www.zhihu.com/people/li-zhi-chao-7-63", 
        "https://www.zhihu.com/people/111111-27-97", 
        "https://www.zhihu.com/people/can-er-bu-lan", 
        "https://www.zhihu.com/people/bai-bai-86-98", 
        "https://www.zhihu.com/people/kim-74-51", 
        "https://www.zhihu.com/people/lang-zi-mo-zhe-27", 
        "https://www.zhihu.com/people/wang-ying-39-96-63", 
        "https://www.zhihu.com/people/huang-li-an", 
        "https://www.zhihu.com/people/liu-jian-8-9", 
        "https://www.zhihu.com/people/sunny-98-4-89", 
        "https://www.zhihu.com/people/wu-yu-75-9", 
        "https://www.zhihu.com/people/kong-xiao-fei-14", 
        "https://www.zhihu.com/people/targz", 
        "https://www.zhihu.com/people/ren-xi-niao-tuo", 
        "https://www.zhihu.com/people/wxc7084e962f4c0fb8", 
        "https://www.zhihu.com/people/xiao-yao-10-17", 
        "https://www.zhihu.com/people/xiao-xiao-lao-hu-bu-tou-mi", 
        "https://www.zhihu.com/people/peng-hua-chao-29", 
        "https://www.zhihu.com/people/xuhaohao888", 
        "https://www.zhihu.com/people/111-96-24-49", 
        "https://www.zhihu.com/people/alex-shen-55", 
        "https://www.zhihu.com/people/cancanxinxin", 
        "https://www.zhihu.com/people/fei-cun-37", 
        "https://www.zhihu.com/people/summer-29-35-56", 
        "https://www.zhihu.com/people/auto-man-71", 
        "https://www.zhihu.com/people/lan-mao-mao-44", 
        "https://www.zhihu.com/people/lintao-fan", 
        "https://www.zhihu.com/people/baoziwanzi", 
        "https://www.zhihu.com/people/zmjc-61", 
        "https://www.zhihu.com/people/cong-xin-bu-song-17", 
        "https://www.zhihu.com/people/wu-guo-biao", 
        "https://www.zhihu.com/people/YorkChu", 
        "https://www.zhihu.com/people/xleisure-free", 
        "https://www.zhihu.com/people/wang-peng-49-80", 
        "https://www.zhihu.com/people/cheng-jia-fang-97", 
        "https://www.zhihu.com/people/xingbin.zh", 
        "https://www.zhihu.com/people/jackode", 
        "https://www.zhihu.com/people/786269940", 
        "https://www.zhihu.com/people/lai-xin-38-18", 
        "https://www.zhihu.com/people/chenwuchen", 
        "https://www.zhihu.com/people/lotus-22-47", 
        "https://www.zhihu.com/people/qiao-hai-jun", 
        "https://www.zhihu.com/people/he-he-he-he-77-19-21", 
        "https://www.zhihu.com/people/chen-bo-86-42", 
        "https://www.zhihu.com/people/666233-95-78", 
        "https://www.zhihu.com/people/AI-Investment", 
        "https://www.zhihu.com/people/andy-40-31-48", 
        "https://www.zhihu.com/people/zhang-yan-chi-59", 
        "https://www.zhihu.com/people/xiao-peng-7-36", 
        "https://www.zhihu.com/people/JinLi-81-61-18", 
        "https://www.zhihu.com/people/qihonggang", 
        "https://www.zhihu.com/people/huang-yu-wei-93", 
        "https://www.zhihu.com/people/kang-xi-long", 
        "https://www.zhihu.com/people/ma-ze-feng-56", 
        "https://www.zhihu.com/people/run-tu-6-78", 
        "https://www.zhihu.com/people/tao-tao-56-98-29", 
        "https://www.zhihu.com/people/shi-shou-lang-zhong", 
        "https://www.zhihu.com/people/guo-xiang-40-36", 
        "https://www.zhihu.com/people/zhou-tao-tao-66", 
        "https://www.zhihu.com/people/zhang-xu-50-92-10", 
        "https://www.zhihu.com/people/xiao-xiao-xie-zhu-zhu", 
        "https://www.zhihu.com/people/shi-zhen-bo-11", 
        "https://www.zhihu.com/people/wang-zong-98-28", 
        "https://www.zhihu.com/people/xiao-wei-29-52-18", 
        "https://www.zhihu.com/people/liu-lang-64", 
        "https://www.zhihu.com/people/echo-55-77", 
        "https://www.zhihu.com/people/test-49-43", 
        "https://www.zhihu.com/people/li-de-dong-43", 
        "https://www.zhihu.com/people/wang-tong-78-19", 
        "https://www.zhihu.com/people/dadoudou", 
        "https://www.zhihu.com/people/jiu-san-gong-ren", 
        "https://www.zhihu.com/people/luan-lin-bao", 
        "https://www.zhihu.com/people/huang-yan-3-62", 
        "https://www.zhihu.com/people/ljy-25-2", 
        "https://www.zhihu.com/people/wang-qing-yu-75-53", 
        "https://www.zhihu.com/people/chen-x-16", 
        "https://www.zhihu.com/people/zzx-47-7", 
        "https://www.zhihu.com/people/le-le-42-76-8", 
        "https://www.zhihu.com/people/zhang-hong-bo-89", 
        "https://www.zhihu.com/people/zhui-xun-free", 
        "https://www.zhihu.com/people/amanjb", 
        "https://www.zhihu.com/people/zhang-yang-29-57-14", 
        "https://www.zhihu.com/people/bai-yang-88-85", 
        "https://www.zhihu.com/people/li-yan-77-64", 
        "https://www.zhihu.com/people/sq892246139", 
        "https://www.zhihu.com/people/lu-jie-10-70", 
        "https://www.zhihu.com/people/teawh", 
        "https://www.zhihu.com/people/wang-jing-bo-27-88", 
        "https://www.zhihu.com/people/xdd-2", 
        "https://www.zhihu.com/people/ss-jiligulu", 
        "https://www.zhihu.com/people/wang-hai-jiao-62-28", 
        "https://www.zhihu.com/people/zhang-da-xian-1973", 
        "https://www.zhihu.com/people/lei-yu-sheng-82-4", 
        "https://www.zhihu.com/people/zhen-fan-tian", 
        "https://www.zhihu.com/people/cctv-87", 
        "https://www.zhihu.com/people/xiao-gu-wei-dao-zhu", 
        "https://www.zhihu.com/people/bow-rain-95", 
        "https://www.zhihu.com/people/ma-yu-xiang-4", 
        "https://www.zhihu.com/people/you-zhui-qiu-de-shi-ren", 
        "https://www.zhihu.com/people/mzf-93", 
        "https://www.zhihu.com/people/apollo0801", 
        "https://www.zhihu.com/people/ke-ke-23-12", 
        "https://www.zhihu.com/people/yangscar", 
        "https://www.zhihu.com/people/xiao-hou-72-6", 
        "https://www.zhihu.com/people/xiaoshi-wang", 
        "https://www.zhihu.com/people/kai-xin-yi-ke-2018", 
        "https://www.zhihu.com/people/dang-liu-xing-hua-guo-ni-de-bi-an", 
        "https://www.zhihu.com/people/Micro-Kun", 
        "https://www.zhihu.com/people/lan-ting-90-99", 
        "https://www.zhihu.com/people/michael-wu-25", 
        "https://www.zhihu.com/people/hu-ge-46-83", 
        "https://www.zhihu.com/people/cui-rui-long", 
        "https://www.zhihu.com/people/xiao-wu-gui-80-31", 
        "https://www.zhihu.com/people/cao-yue-54-23", 
        "https://www.zhihu.com/people/hou-feng-yin", 
        "https://www.zhihu.com/people/dong-feng-zao-ji", 
        "https://www.zhihu.com/people/du-li-52", 
        "https://www.zhihu.com/people/mu-xi-luo-chen", 
        "https://www.zhihu.com/people/zecai-liang", 
        "https://www.zhihu.com/people/ou-yang-cai-zi-54", 
        "https://www.zhihu.com/people/cl-ma", 
        "https://www.zhihu.com/people/openqt", 
        "https://www.zhihu.com/people/sheng-huo-bu-shi-shi-65", 
        "https://www.zhihu.com/people/yang-cong-62-7", 
        "https://www.zhihu.com/people/laniakee", 
        "https://www.zhihu.com/people/hong-alex", 
        "https://www.zhihu.com/people/da-shan-li-de-nan-hai-zi", 
        "https://www.zhihu.com/people/zhu-yao-shi-11-84", 
        "https://www.zhihu.com/people/liu-jia-zhu-96-72", 
        "https://www.zhihu.com/people/wu-dou-cai-22", 
        "https://www.zhihu.com/people/hijackjave", 
        "https://www.zhihu.com/people/sun-yan-90-29", 
        "https://www.zhihu.com/people/ryan-74-59", 
        "https://www.zhihu.com/people/zhong-er-cheng-xu-yuan", 
        "https://www.zhihu.com/people/wtzhang95", 
        "https://www.zhihu.com/people/ke-wu-88", 
        "https://www.zhihu.com/people/jiang-a-sheng-85", 
        "https://www.zhihu.com/people/dai-wei-66-30", 
        "https://www.zhihu.com/people/wu-ye-nan-30", 
        "https://www.zhihu.com/people/li-Ameng-30-39", 
        "https://www.zhihu.com/people/cui-zhen-wei-86", 
        "https://www.zhihu.com/people/freedom_forever", 
        "https://www.zhihu.com/people/xiao-jing-50-80-93", 
        "https://www.zhihu.com/people/18040042332", 
        "https://www.zhihu.com/people/maple7sha", 
        "https://www.zhihu.com/people/tigerbaby-71", 
        "https://www.zhihu.com/people/Sing-F", 
        "https://www.zhihu.com/people/superdullwolf", 
        "https://www.zhihu.com/people/deep-learning-66", 
        "https://www.zhihu.com/people/zhrthegreat", 
        "https://www.zhihu.com/people/liu-feng-96-66-33", 
        "https://www.zhihu.com/people/qing-qing-hh", 
        "https://www.zhihu.com/people/xie-zi-13-87", 
        "https://www.zhihu.com/people/fan-de-de-de", 
        "https://www.zhihu.com/people/hui-shou-de-da-zhuang", 
        "https://www.zhihu.com/people/mo-jie-am", 
        "https://www.zhihu.com/people/dong-shui-62", 
        "https://www.zhihu.com/people/zhao-rong-wen", 
        "https://www.zhihu.com/people/huang-xiao-xin-73-98", 
        "https://www.zhihu.com/people/mi-tu-71-36", 
        "https://www.zhihu.com/people/y.i.y.i", 
        "https://www.zhihu.com/people/min-jie-10", 
        "https://www.zhihu.com/people/qie-xing-qie-zhen-xi-60-20", 
        "https://www.zhihu.com/people/li-rui-81-94-44", 
        "https://www.zhihu.com/people/da-zhi-ruo-yu-82-47", 
        "https://www.zhihu.com/people/zheng-jian-yang-56", 
        "https://www.zhihu.com/people/xing-ye-81-89", 
        "https://www.zhihu.com/people/yi-yan-10-16", 
        "https://www.zhihu.com/people/duan-xing-99", 
        "https://www.zhihu.com/people/meng-tuo-9", 
        "https://www.zhihu.com/people/fang-fa-64-69", 
        "https://www.zhihu.com/people/wu-qi-mo-50", 
        "https://www.zhihu.com/people/ge-ge-bu-ru-98-20", 
        "https://www.zhihu.com/people/alice828", 
        "https://www.zhihu.com/people/you-yan-mai", 
        "https://www.zhihu.com/people/zhong-zhi-qing-30", 
        "https://www.zhihu.com/people/xing-yun-liu-lang-33", 
        "https://www.zhihu.com/people/xiao-xiao-mu-yu-68-33", 
        "https://www.zhihu.com/people/bai-ji-97-56", 
        "https://www.zhihu.com/people/lucien-37-79", 
        "https://www.zhihu.com/people/yi-zhi-tu-zi-zhu", 
        "https://www.zhihu.com/people/an-yu-78-48", 
        "https://www.zhihu.com/people/wang-xin-wei-52-94", 
        "https://www.zhihu.com/people/ren-wei-jie-76", 
        "https://www.zhihu.com/people/li-yan-wei-yo", 
        "https://www.zhihu.com/people/xu-xiao-jian-min", 
        "https://www.zhihu.com/people/a-dou-22-23", 
        "https://www.zhihu.com/people/chen-jin-yu-22-81", 
        "https://www.zhihu.com/people/huang-fei-fei-38", 
        "https://www.zhihu.com/people/heliosxh", 
        "https://www.zhihu.com/people/xie-wai-wai-27", 
        "https://www.zhihu.com/people/viskey-23", 
        "https://www.zhihu.com/people/da-tu-30-19", 
        "https://www.zhihu.com/people/wang-zi-yu-6", 
        "https://www.zhihu.com/people/wei-wu-ji-68", 
        "https://www.zhihu.com/people/blueguitar", 
        "https://www.zhihu.com/people/ka-ka-ke-6", 
        "https://www.zhihu.com/people/liu-xiao-yong-80-42", 
        "https://www.zhihu.com/people/chevson", 
        "https://www.zhihu.com/people/huangjiansword", 
        "https://www.zhihu.com/people/chan-1", 
        "https://www.zhihu.com/people/deer-83-9", 
        "https://www.zhihu.com/people/hei-an-zhu-zai-33", 
        "https://www.zhihu.com/people/andy-95-26", 
        "https://www.zhihu.com/people/sticklee", 
        "https://www.zhihu.com/people/li-de-zhi-33-2", 
        "https://www.zhihu.com/people/xiao-ming-57-51", 
        "https://www.zhihu.com/people/feng-xing-long-5", 
        "https://www.zhihu.com/people/sonia.li"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/73380560", 
            "userName": "SLin", 
            "userLink": "https://www.zhihu.com/people/e35507b123bb40364e2d31d606e7dcac", 
            "upvote": 4, 
            "title": "通过理解极大似然估计(MLE)提升对机器学习算法的认知", 
            "content": "<h2>0 引言</h2><p>在机器学习的理论学习理论中往往会遇到“极大似然估计”的概念，极大似然估计的求解过程非常简单致使我们往往会忽律其背后的原理。当我彻底弄懂了极大似然估计的背后的思想后对机器学习算法的理解有了本质上的提高。下面让我们通过通俗并且轻松的方式去学习“极大似然估计”背后的思想以及在机器学习中的应用。当然随着对理论的认识的不断加深还会不断更新此文章。</p><h2>1 通俗理解极大似然估计(Maximum Likelihood Estimate,MLE)</h2><p>如果对全国人身高做一下评估，有一个前提假设是人的身高属于正态分布（如图1所示），在正太分布中我们关心参数为：均值 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 和方差 <img src=\"https://www.zhihu.com/equation?tex=%5Csigma%5E2\" alt=\"\\sigma^2\" eeimg=\"1\"/> ，那如何得到全国人身高的均值和方差呢？如果去挨个测量13亿人的身高其实是不太可能的。我们能做的就是随机的找一些不同年龄段、不同性别的人测量他们的身高，让他们的身高水平代表全国人民的身高水平，然后通过他们对全国人民身高的均值和方差做一下估计，我想这是每个人都能想到的！但是，为什么能让这些人的身高代表全国人的身高呢？这里就蕴含着及其精妙的思想，需要细细斟酌🤔️。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8524501fcf021777bb3d4ecac89d93a2_b.jpg\" data-size=\"normal\" data-rawwidth=\"557\" data-rawheight=\"403\" class=\"origin_image zh-lightbox-thumb\" width=\"557\" data-original=\"https://pic3.zhimg.com/v2-8524501fcf021777bb3d4ecac89d93a2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;557&#39; height=&#39;403&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"557\" data-rawheight=\"403\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"557\" data-original=\"https://pic3.zhimg.com/v2-8524501fcf021777bb3d4ecac89d93a2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8524501fcf021777bb3d4ecac89d93a2_b.jpg\"/><figcaption>图1 正态分布概率密度曲线</figcaption></figure><p>好了请允许我再换一个话题，假如说一个老猎人带着一个小徒弟出去打猎。目前我们知道他们其中一个人打死了一只兔子，假如让你猜这只兔子是谁打死的，大部分人会直接猜测是老猎人打死的，这其实就运用了最大似然的思想。</p><p><b>最大似然原理</b></p><blockquote>假设我们的抽样是理想正确的；<br/>概率大的事件在一次<b>观测</b>中更容易发生（打猎问题）；<br/>在一次<b>观测</b>中发生了的事件其概率应该大（身高问题）。</blockquote><p>现在我们回到身高问题用稍微理论的方法理解一下最大似然估计：</p><p>假设我们从全国人中随机抽取了 <img src=\"https://www.zhihu.com/equation?tex=n\" alt=\"n\" eeimg=\"1\"/> 个人，分别用 <img src=\"https://www.zhihu.com/equation?tex=x_%7B1%7D%2Cx_%7B2%7D%2Cx_%7B3%7D%5Ccdot%5Ccdot%5Ccdot%5Ccdot+x_%7Bn%7D\" alt=\"x_{1},x_{2},x_{3}\\cdot\\cdot\\cdot\\cdot x_{n}\" eeimg=\"1\"/> 代表他们的身高，既然我们<b>观测</b>到了他们的身高。对应上文的最大似然原理我们可以得出我们看到的这些样本出现的概率应该是最大的或者说既然我们抽取到观测到了他们的身高他们发生的可能性就最大。其中这里有一个假设前提是我们对抽取的样本是一个乐观的态度，也就是说假设抽取去的样本是理想的、合理的。然后我们走一遍最大似然估计的流程(不用紧张高中知识)：</p><p>假设我们全国人的身高服从正太分布 <img src=\"https://www.zhihu.com/equation?tex=%5Cxi%5Csim+N%28%5Cmu%2C%5Csigma%5E2%29\" alt=\"\\xi\\sim N(\\mu,\\sigma^2)\" eeimg=\"1\"/> ，但是我们不知到分布具体的参数：均值 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 和方差 <img src=\"https://www.zhihu.com/equation?tex=%5Csigma+%5E2+\" alt=\"\\sigma ^2 \" eeimg=\"1\"/> 。由于我们无法对全国13亿人挨个测量身高，所以我们随机抽取了 <img src=\"https://www.zhihu.com/equation?tex=n\" alt=\"n\" eeimg=\"1\"/> 个人的身高： <img src=\"https://www.zhihu.com/equation?tex=x_%7B1%7D%2Cx_%7B2%7D%2Cx_%7B3%7D%5Ccdot%5Ccdot%5Ccdot%5Ccdot+x_%7Bn%7D\" alt=\"x_{1},x_{2},x_{3}\\cdot\\cdot\\cdot\\cdot x_{n}\" eeimg=\"1\"/>。希望通过最大似然的思想来估计分布的参数 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Csigma%5E2\" alt=\"\\sigma^2\" eeimg=\"1\"/> 。</p><p>已知正态分布的概率密度函数为：</p><p><img src=\"https://www.zhihu.com/equation?tex=+++p%28x%3B%5Cmu%2C%5Csigma%5E2%29%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Cdelta%7De%5E%7B-%5Cfrac%7B%28x-%5Cmu%29%5E2%7D%7B2%5Csigma%5E2%7D+%7D++++\" alt=\"   p(x;\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi}\\delta}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2} }    \" eeimg=\"1\"/> </p><p>step1  计算似然函数：</p><p><img src=\"https://www.zhihu.com/equation?tex=++L%28%5Cmu%2C%5Csigma%5E2%29%3D%5Cprod_%7Bi%3D1%7D%5E%7Bn%7D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Cdelta%7De%5E%7B-%5Cfrac%7B%28x_i-%5Cmu%29%5E2%7D%7B2%5Csigma%5E2+%7D%7D++++\" alt=\"  L(\\mu,\\sigma^2)=\\prod_{i=1}^{n}\\frac{1}{\\sqrt{2\\pi}\\delta}e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2 }}    \" eeimg=\"1\"/> </p><p>step2 似然函数取对数：</p><p><img src=\"https://www.zhihu.com/equation?tex=+lnL%28%5Cmu%2C%5Csigma%5E2%29%3D-%5Cfrac%7Bn%7D%7B2%7Dln%282%5Cpi%29-%5Cfrac%7Bn%7D%7B2%7Dln%5Csigma%5E2-%5Cfrac%7B1%7D%7B2%5Csigma%5E2%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%28x_i-%5Cmu%29%5E+2%7D+\" alt=\" lnL(\\mu,\\sigma^2)=-\\frac{n}{2}ln(2\\pi)-\\frac{n}{2}ln\\sigma^2-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}{(x_i-\\mu)^ 2} \" eeimg=\"1\"/> </p><p>step3 求最值对应的参数：</p><p>                                                                      令： <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%5Cmu%7DlnL%28%5Cmu%2C%5Csigma%5E2%29%3D0+\" alt=\"\\frac{\\partial}{\\partial\\mu}lnL(\\mu,\\sigma^2)=0 \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=++%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%5Csigma%5E2%7DlnL%28%5Cmu%2C%5Csigma%5E2%29+%3D0++\" alt=\"  \\frac{\\partial}{\\partial\\sigma^2}lnL(\\mu,\\sigma^2) =0  \" eeimg=\"1\"/></p><p>step4得到估计参数：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ctilde%7B%5Cmu%7D+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7Bx_i+%7D+++\" alt=\"\\tilde{\\mu} = \\frac{1}{n}\\sum_{i=1}^{n}{x_i }   \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=+%5Ctilde%7B%5Csigma%7D%5E2%3D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%28x_i-%5Cbar%7Bx%7D%29%5E2+%7D++\" alt=\" \\tilde{\\sigma}^2=\\frac{1}{n}\\sum_{i=1}^{n}{(x_i-\\bar{x})^2 }  \" eeimg=\"1\"/> </p><p>更一般的似然函数 <img src=\"https://www.zhihu.com/equation?tex=L%28%5Ctheta%29%3D%5Cprod_%7Bi%3D1%7D%5E%7Bn%7Dp%28x_i%3B%5Ctheta%29\" alt=\"L(\\theta)=\\prod_{i=1}^{n}p(x_i;\\theta)\" eeimg=\"1\"/>， <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 对应上文身高问题 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta%3D%28%5Cmu%2C%5Csigma%5E2%29\" alt=\"\\theta=(\\mu,\\sigma^2)\" eeimg=\"1\"/>,既然我们观察到了 <img src=\"https://www.zhihu.com/equation?tex=n\" alt=\"n\" eeimg=\"1\"/> 个样本，那么他们出现的概率应该是最大的。假设每个人的身高只和自己有关系，人与人之间相互独立，对每个人的概率进行相乘得到的联合概率 <img src=\"https://www.zhihu.com/equation?tex=L%28%5Ctheta%29\" alt=\"L(\\theta)\" eeimg=\"1\"/> 也应该是最大的，根据最大似然的思想满足 <img src=\"https://www.zhihu.com/equation?tex=L%28%5Ctheta%29\" alt=\"L(\\theta)\" eeimg=\"1\"/> 最大的参数 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 是最好的估计值。也就可以说若 <img src=\"https://www.zhihu.com/equation?tex=L%28%5Ctheta_1%29%3EL%28%5Ctheta_2%29\" alt=\"L(\\theta_1)&gt;L(\\theta_2)\" eeimg=\"1\"/> ，那么 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta_1\" alt=\"\\theta_1\" eeimg=\"1\"/> 更接近真实值。</p><p>1.如何体现出我们的估计或者模型在力求最好地拟合抽取的样本？</p><p>   答：求似然函数的最大值。</p><p>2.哪一套参数才是我们要找的最好的参数？</p><p>   答：似然函数最大的时候，对应的参数 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> </p><blockquote>在英语日常生活中，<b>似然（likelihood）</b>和<b>概率（probability）</b>的使用一般不作区分。在统计学上，基于某些模型的参数（粗略地说，我们可以认为参数决定了模型），观测到某数据的概率称为概率；而已经观测到某数据，模型的参数取特定值的概率称为似然。</blockquote><p>好了当我们理解了最大似然估计时，再去重新认识我们的机器学习算法就会有一种豁然开朗的感觉。</p><h2>2机器学习中的极大似然</h2><p>让我们看看最简单的二分类机器学习模型logistic回归吧，其可以表示为如下方式：</p><p><img src=\"https://www.zhihu.com/equation?tex=+P%28Y%3D1%7Cx%29%3D%5Cfrac%7Bexp%28w%5Ccdot+x%29%7D%7B1%2Bexp%28w%5Ccdot+x+%29%7D++\" alt=\" P(Y=1|x)=\\frac{exp(w\\cdot x)}{1+exp(w\\cdot x )}  \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=P%28Y%3D0%7Cx%29%3D%5Cfrac%7B1%7D%7B1%2Bexp%28w%5Ccdot+x+%29%7D++++\" alt=\"P(Y=0|x)=\\frac{1}{1+exp(w\\cdot x )}    \" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=w\" alt=\"w\" eeimg=\"1\"/> 为模型参数， <img src=\"https://www.zhihu.com/equation?tex=x\" alt=\"x\" eeimg=\"1\"/> 为样本，即 <img src=\"https://www.zhihu.com/equation?tex=w%3D%28w%5E%7B%281%29%7D%2Cw%5E%7B%282%29%7D%2Cw%5E%7B%283%29%7D%2C%5Ccdot%5Ccdot%5Ccdot%2Cw%5E%7B%28n%29%7D%2Cb%29%5ET\" alt=\"w=(w^{(1)},w^{(2)},w^{(3)},\\cdot\\cdot\\cdot,w^{(n)},b)^T\" eeimg=\"1\"/> , <img src=\"https://www.zhihu.com/equation?tex=x%3D%28x%5E%7B%281%29%7D%2Cx%5E%7B%282%29%7D%2Cx%5E%7B%283%29%7D%2C%5Ccdot%5Ccdot%5Ccdot%2Cx%5E%7B%28n%29%7D%2C1%29%5ET\" alt=\"x=(x^{(1)},x^{(2)},x^{(3)},\\cdot\\cdot\\cdot,x^{(n)},1)^T\" eeimg=\"1\"/> </p><p>通过什么样的方法学习参数 <img src=\"https://www.zhihu.com/equation?tex=w\" alt=\"w\" eeimg=\"1\"/> 呢？答案就是最大似然估计和梯度下降。</p><p>对于给定的训练数据 <img src=\"https://www.zhihu.com/equation?tex=T%3D%5Cleft%5C%7B+%28x_1%2Cy_1%29%2C%28x_2%2Cy_2%29%2C%5Ccdot%5Ccdot%5Ccdot%2C%28x_n%2Cy_n%29+%5Cright%5C%7D\" alt=\"T=\\left\\{ (x_1,y_1),(x_2,y_2),\\cdot\\cdot\\cdot,(x_n,y_n) \\right\\}\" eeimg=\"1\"/> ,其中 <img src=\"https://www.zhihu.com/equation?tex=x_i%5Cin+R%5En\" alt=\"x_i\\in R^n\" eeimg=\"1\"/> , <img src=\"https://www.zhihu.com/equation?tex=y_i+%5Cin+%5Cleft%5C%7B+0%2C1+%5Cright%5C%7D\" alt=\"y_i \\in \\left\\{ 0,1 \\right\\}\" eeimg=\"1\"/> ,用极大似然估计方法估计模型参数：</p><p>设：                      </p><p><img src=\"https://www.zhihu.com/equation?tex=P%28Y%3D1%7Cx%29%3D%5Cpi%28x%29%2CP%28Y%3D0%7Cx%29%3D1-%5Cpi%28x%29\" alt=\"P(Y=1|x)=\\pi(x),P(Y=0|x)=1-\\pi(x)\" eeimg=\"1\"/> </p><p>似然函数为：</p><p><img src=\"https://www.zhihu.com/equation?tex=+++L%28w%29+%3D+%5Cprod_%7Bi%3D1%7D%5E%7Bn%7D%5B%5Cpi%28x_i%29%5D%5E%7By_i%7D%5B1-%5Cpi%28x_i%29%5D%5E%7B1-y_i+%7D+\" alt=\"   L(w) = \\prod_{i=1}^{n}[\\pi(x_i)]^{y_i}[1-\\pi(x_i)]^{1-y_i } \" eeimg=\"1\"/> </p><p>对数似然为：</p><p><img src=\"https://www.zhihu.com/equation?tex=++logL%28w%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%5By_ilog%5Cpi%28x_i%29%2B%281-y_i%29log%281-%5Cpi%28i%29%29%5D%7D+++\" alt=\"  logL(w)=\\sum_{i=1}^{n}{[y_ilog\\pi(x_i)+(1-y_i)log(1-\\pi(i))]}   \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5By_i%28w%5Ccdot+x%29-log%281%2Bexp%28w%5Ccdot+x%29+%29%5D++\" alt=\"=[y_i(w\\cdot x)-log(1+exp(w\\cdot x) )]  \" eeimg=\"1\"/> </p><p>对 <img src=\"https://www.zhihu.com/equation?tex=logL%28w%29\" alt=\"logL(w)\" eeimg=\"1\"/> 求极大值，得到 <img src=\"https://www.zhihu.com/equation?tex=w\" alt=\"w\" eeimg=\"1\"/> 的参数估计。</p><p>这样就变成了对数似然为目标函数的最优化问题，可以用常见的梯度下降法求最优值。</p><h2>3 深入理解机器学习与极大似然之间的联系</h2><p>在机器学习和深度学学习中由于给定的样本总是有限，所以用样本数据的经验分布 <img src=\"https://www.zhihu.com/equation?tex=%5Cwidehat%7B%5C+p%7D_%7Bdata%7D%28x%29\" alt=\"\\widehat{\\ p}_{data}(x)\" eeimg=\"1\"/> 代替表示所有真实数据的分布 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bdata%7D%28x%29\" alt=\"p_{data}(x)\" eeimg=\"1\"/>。模型的概率分布为  <img src=\"https://www.zhihu.com/equation?tex=p_%7Bmodel%7D%28x%3B%5Ctheta%29\" alt=\"p_{model}(x;\\theta)\" eeimg=\"1\"/> 。考虑一组含有 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> 个样本的数据集 <img src=\"https://www.zhihu.com/equation?tex=X%3D%28x_1%2Cx_2%2C%5Ccdot%5Ccdot%5Ccdot%2Cx_m%29\" alt=\"X=(x_1,x_2,\\cdot\\cdot\\cdot,x_m)\" eeimg=\"1\"/> 独立从未知的真实数据分布 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bdata%7D%28x%29\" alt=\"p_{data}(x)\" eeimg=\"1\"/> 生成。</p><p>令 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bmodel%7D%28x%3B%5Ctheta%29\" alt=\"p_{model}(x;\\theta)\" eeimg=\"1\"/> 是由 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 确定的在相同空间上的概率分布。在理想情况下， <img src=\"https://www.zhihu.com/equation?tex=p_%7Bmodel%7D%28x%3B%5Ctheta%29\" alt=\"p_{model}(x;\\theta)\" eeimg=\"1\"/> 将任意输入 <img src=\"https://www.zhihu.com/equation?tex=x\" alt=\"x\" eeimg=\"1\"/> 映射到真实的概率 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bdata%7D%28x%29\" alt=\"p_{data}(x)\" eeimg=\"1\"/> ，通俗地讲就是我们希望我们的机器学习模型能够对所有数据都预测正确，不仅仅是训练集中的数据，还包括训练集中没有包含的数据，当然这几乎是不可能的。</p><p>对 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 的极大似然估计为：</p><p><img src=\"https://www.zhihu.com/equation?tex=+++++++++++++++++%5Ctheta_%7BML%7D+%3D+%5Cmathop%7B%5Carg%5Cmax%7D%5Climits_%7B%5Ctheta%7D%5Cprod_%7Bi%3D1%7D%5E%7Bm%7Dp_%7Bmodel%7D%28x_i%2C%5Ctheta+%29++\" alt=\"                 \\theta_{ML} = \\mathop{\\arg\\max}\\limits_{\\theta}\\prod_{i=1}^{m}p_{model}(x_i,\\theta )  \" eeimg=\"1\"/></p><p>取对数：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ctheta_%7BML%7D+%3D+%5Cmathop%7B%5Carg%5Cmax%7D%5Climits_%7B%5Ctheta%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7Dlogp_%7Bmodel%7D%28x_i%2C%5Ctheta%29\" alt=\"\\theta_{ML} = \\mathop{\\arg\\max}\\limits_{\\theta}\\sum_{i=1}^{m}logp_{model}(x_i,\\theta)\" eeimg=\"1\"/> </p><p>取关于经验分布的期望:<br/> <img src=\"https://www.zhihu.com/equation?tex=+%5Ctheta_%7BML%7D+%3D+%5Cmathop%7B%5Carg%5Cmax%7D%5Climits_%7B%5Ctheta%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Cwidehat%7B%5C+p%7D_%7Bdata%7D%28x_i%29logp_%7Bmodel%7D%28x_i%2C%5Ctheta%29++++\" alt=\" \\theta_{ML} = \\mathop{\\arg\\max}\\limits_{\\theta}\\sum_{i=1}^{m}\\widehat{\\ p}_{data}(x_i)logp_{model}(x_i,\\theta)    \" eeimg=\"1\"/> </p><p>现在有一种衡量两种概率分布之间差距的方法就做KL散度，假设我们衡量样本数据的概率分布 <img src=\"https://www.zhihu.com/equation?tex=%5Cwidehat%7B%5C+p%7D_%7Bdata%7D%28x%29\" alt=\"\\widehat{\\ p}_{data}(x)\" eeimg=\"1\"/> 与训练出来的模型的概率分布  <img src=\"https://www.zhihu.com/equation?tex=p_%7Bmodel%7D%28x%29\" alt=\"p_{model}(x)\" eeimg=\"1\"/>  之间的差距：</p><p><img src=\"https://www.zhihu.com/equation?tex=+++++++++++++++D_%7BKL%7D%28%5Cwidehat%7B%5C+p%7D_%7Bdata%7D%7C%7Cp_%7Bmodel%7D%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%7B%5Cwidehat%7B%5C+p%7D_%7Bdata%7D%28x_i%29%7D%5Blog%5Cwidehat%7B%5C+p%7D_%7Bdata%7D%28x_i%29-logp_%7Bmodel%7D%28x_+i%29%5D\" alt=\"               D_{KL}(\\widehat{\\ p}_{data}||p_{model})=\\sum_{i=1}^{m}{\\widehat{\\ p}_{data}(x_i)}[log\\widehat{\\ p}_{data}(x_i)-logp_{model}(x_ i)]\" eeimg=\"1\"/> </p><p>理想情况下二者的KL散度越小越好及模型更好地学习了训练集的数据。其中 <img src=\"https://www.zhihu.com/equation?tex=%5Cwidehat%7B%5C+p%7D_%7Bdata%7D%28x_i%29\" alt=\"\\widehat{\\ p}_{data}(x_i)\" eeimg=\"1\"/> 为训练集数据分布，可以认为其固定，所以最小化KL散度就等价于最小化：</p><p><img src=\"https://www.zhihu.com/equation?tex=+-%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%7B%5Cwidehat%7B%5C+p%7D_%7Bdata%7D%28x_i%29%7Dlogp_%7Bmodel%7D%28x+_i%29++\" alt=\" -\\sum_{i=1}^{m}{\\widehat{\\ p}_{data}(x_i)}logp_{model}(x _i)  \" eeimg=\"1\"/> </p><p>上面的式子是不是有一些熟悉，这就是我们在机器学习中最常用到的损失函数---交叉熵。</p><p>本节参考《DeepLearning》(花书)5.5节，为了更容易理解更改了部分符号系统，若有错误欢迎各位大佬指正。</p><p>下面让我对比下信息论中交叉熵公式与机器学习中常见的交叉熵形式对上文更好地理解：</p><p>信息论中交叉熵形式：</p><p><img src=\"https://www.zhihu.com/equation?tex=H%28p%2Cq%29%3D-%5Csum_%7Bi%3D1%7D%5E%7Bm%7Dp%28x_i%29log%28q%28x_i%29%29\" alt=\"H(p,q)=-\\sum_{i=1}^{m}p(x_i)log(q(x_i))\" eeimg=\"1\"/> </p><p>深度学习中交叉熵的形式：</p><p><img src=\"https://www.zhihu.com/equation?tex=Cost+%3D+-%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%7B%5By_%7Bi%7Dlog%5Cwidehat%7By%7D_%7Bi%7D%2B%281-y_i%29log%281-%5Cwidehat%7By%7D_i%29%5D%7D\" alt=\"Cost = -\\frac{1}{n}\\sum_{i=1}^{m}{[y_{i}log\\widehat{y}_{i}+(1-y_i)log(1-\\widehat{y}_i)]}\" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=y_i\" alt=\"y_i\" eeimg=\"1\"/> 对应训练集真实标签可对应 <img src=\"https://www.zhihu.com/equation?tex=%5Cwidehat%7B%5C+p%7D_%7Bdata%7D%28x_i%29+\" alt=\"\\widehat{\\ p}_{data}(x_i) \" eeimg=\"1\"/> , <img src=\"https://www.zhihu.com/equation?tex=%5Cwidehat%7By%7D_%7Bi%7D\" alt=\"\\widehat{y}_{i}\" eeimg=\"1\"/> 为模型的预测值可以对应 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bmodel%7D%28x_i%29\" alt=\"p_{model}(x_i)\" eeimg=\"1\"/> 。</p><h2> References</h2><p>1.李航 (2012) 统计学习方法. 清华大学出版社, 北京.</p><p>2.Deep Learning,Ian Goodfellow and Yoshua Bengio and Aaron Courville,MIT Press,2016</p><p>3.<a href=\"https://www.zhihu.com/question/281311791/answer/498859126\" class=\"internal\"><span class=\"invisible\">https://www.</span><span class=\"visible\">zhihu.com/question/2813</span><span class=\"invisible\">11791/answer/498859126</span><span class=\"ellipsis\"></span></a></p><p>阅读推荐：</p><p><a href=\"https://zhuanlan.zhihu.com/p/56938216\" class=\"internal\">轻松理解pointwise 、 pairwise 、listwise</a></p><p></p>", 
            "topic": [
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "算法工程师", 
                    "tagLink": "https://api.zhihu.com/topics/19656756"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/56938216", 
            "userName": "SLin", 
            "userLink": "https://www.zhihu.com/people/e35507b123bb40364e2d31d606e7dcac", 
            "upvote": 89, 
            "title": "自然语言处理（NLP）面试必备：pointwise 、 pairwise 、listwise", 
            "content": "<h2>0 引言</h2><p>在NLP业务中有这么一种场景：给出一个提问句子从候选句子中选出最佳的答案。就如以下样例所示：</p><blockquote>Who established the Nobel Prize? <br/> 1. The Nobel Prize was established more than 100 years ago.<br/> 2. The Fields Medal, established in 1936, is often described as the Nobel Prize of mathematics.<br/>3. The Nobel Prize was established in the will of Alfred Nobel. </blockquote><p>在上面例子中有一个提问，后面对应了3个候选回答，很明显第3个候选句子为最佳的回答。我们可以把这类问题理解成一个排序问题。假设我们已经有了模型 <img src=\"https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D\" alt=\"h_{\\theta}\" eeimg=\"1\"/> 来对数据集进行学习，那么怎么组织学习学习方式呢？这就涉及了本文的主题：pointwise、pairwise、listwise。</p><h2>1 Pointwise</h2><p>在pointwise中把排序问题当成一个二分类问题，训练的样本被组织成为一个三元组 <img src=\"https://www.zhihu.com/equation?tex=%28q_%7Bi%7D%2Cc_%7Bi%2Cj%7D%2Cy_%7Bi%2Cj%7D%29\" alt=\"(q_{i},c_{i,j},y_{i,j})\" eeimg=\"1\"/> 。其中 <img src=\"https://www.zhihu.com/equation?tex=q_%7Bi%7D\" alt=\"q_{i}\" eeimg=\"1\"/> 为数据集中的一条提问句(如：Who established the Nobel Prize? )；</p><p><img src=\"https://www.zhihu.com/equation?tex=c_%7Bi%2Cj%7D\" alt=\"c_{i,j}\" eeimg=\"1\"/> （ <img src=\"https://www.zhihu.com/equation?tex=c\" alt=\"c\" eeimg=\"1\"/> 取candidate之意）为 <img src=\"https://www.zhihu.com/equation?tex=q_%7Bi%7D\" alt=\"q_{i}\" eeimg=\"1\"/> 对应的一个候选答案，正如样例中的3个候选句子中的一个； <img src=\"https://www.zhihu.com/equation?tex=y_%7Bi%2Cj%7D\" alt=\"y_{i,j}\" eeimg=\"1\"/> 为一个二进制值，表明 <img src=\"https://www.zhihu.com/equation?tex=c_%7Bi%2Cj%7D\" alt=\"c_{i,j}\" eeimg=\"1\"/> 是否为 <img src=\"https://www.zhihu.com/equation?tex=q_%7Bi%7D\" alt=\"q_{i}\" eeimg=\"1\"/> 正确回答。我们就可以训练一个二分类网络： <img src=\"https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D%28q_%7Bi%7D%2Cc_%7Bi%2Cj%7D%29%5Crightarrow+y_%7Bi%2Cj%7D\" alt=\"h_{\\theta}(q_{i},c_{i,j})\\rightarrow y_{i,j}\" eeimg=\"1\"/> ，其中 <img src=\"https://www.zhihu.com/equation?tex=0+%5Cleq+y_%7Bi%2Cj%7D+%5Cleq+1\" alt=\"0 \\leq y_{i,j} \\leq 1\" eeimg=\"1\"/> 。</p><p>结合样例中网络的输入为：Who established the Nobel Prize? 和  1.The Nobel Prize was established more than 100 years ago.</p><p>输出为0，因为第一句回答不正确的候选句子。训练的目标就为最小化数据集中所有问题和候选句子对的交叉熵。</p><p>在预测阶段，二分类模型 <img src=\"https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D\" alt=\"h_{\\theta}\" eeimg=\"1\"/> 被用来排序每一个候选句子，选取最top-ranked的句子作为正确回答，即 <img src=\"https://www.zhihu.com/equation?tex=argmax_%7Bcij%7Dh_%7B%CE%B8%7D%28q_i%2C+c_%7Bij%7D%29\" alt=\"argmax_{cij}h_{θ}(q_i, c_{ij})\" eeimg=\"1\"/> 为 <img src=\"https://www.zhihu.com/equation?tex=q_i\" alt=\"q_i\" eeimg=\"1\"/> 的最佳回答。</p><h2>2 Pairwise</h2><p>在pairwise方法中排序模型 <img src=\"https://www.zhihu.com/equation?tex=h_%5Ctheta\" alt=\"h_\\theta\" eeimg=\"1\"/> 让正确的回答的得分明显高于错误的候选回答。给一个提问，pairwise给定一对候选回答学习并预测哪一个句子才是提问的最佳回答。训练的样例为 <img src=\"https://www.zhihu.com/equation?tex=%28q_i%2C+c%5E%2B_+i%2C+c%5E%E2%88%92_i%29\" alt=\"(q_i, c^+_ i, c^−_i)\" eeimg=\"1\"/> ,其中 <img src=\"https://www.zhihu.com/equation?tex=q_i\" alt=\"q_i\" eeimg=\"1\"/> 为提问,<img src=\"https://www.zhihu.com/equation?tex=c%5E%2B_i\" alt=\"c^+_i\" eeimg=\"1\"/> 为正确的回答， <img src=\"https://www.zhihu.com/equation?tex=c%5E-_i\" alt=\"c^-_i\" eeimg=\"1\"/> 为候选答案中一个错误的回答。</p><p>损失函数为合页损失函数：</p><p><img src=\"https://www.zhihu.com/equation?tex=L%3Dmax%5Cleft%5C%7B+0%EF%BC%8Cm-h_%5Ctheta%28q_i%2Cc%5E%2B_i%29%2Bh_%5Ctheta%28q_i%2Cc%5E-_i%29%5Cright%5C%7D\" alt=\"L=max\\left\\{ 0，m-h_\\theta(q_i,c^+_i)+h_\\theta(q_i,c^-_i)\\right\\}\" eeimg=\"1\"/> </p><p>其中 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> 为边界阀值。如果 <img src=\"https://www.zhihu.com/equation?tex=h_%CE%B8%28q_i%2C+c%5E%2B+_i%29%E2%88%92h_%CE%B8%28q_i%2C+c%5E%E2%88%92_i%29+%3C+m\" alt=\"h_θ(q_i, c^+ _i)−h_θ(q_i, c^−_i) &lt; m\" eeimg=\"1\"/> 损失函数 <img src=\"https://www.zhihu.com/equation?tex=L\" alt=\"L\" eeimg=\"1\"/> 大于0，当满足这个不等式的时候，意味着模型把非正确的回答排在正确答案的上面；如果 <img src=\"https://www.zhihu.com/equation?tex=L\" alt=\"L\" eeimg=\"1\"/> 等于0，模型把正确的回答排在非正确的回答之上。用另一种方式解释就是，如果正确的答案的得分比错误句子的得分之差大于 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> （ <img src=\"https://www.zhihu.com/equation?tex=h_%CE%B8%28q_i%2C+c%5E%2B+_i%29+%E2%88%92+h_%CE%B8%28q_i%2C+c%5E%E2%88%92_i%29+%E2%89%A5+m\" alt=\"h_θ(q_i, c^+ _i) − h_θ(q_i, c^−_i) ≥ m\" eeimg=\"1\"/> ）,总之合页损失函数的目的就是促使正确答案的得分比错误答案的得分大于 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> 。和pairwise类似，在预测阶段得分最高的候选答案被当作正确的答案。</p><h2>3 Listwise</h2><p>pariwise和pointwise忽视了一个事实就是答案选择就是从一系列候选句子中的预测问题。在listwise中单一训练样本就：提问数据和它的所有候选回答句子。在训练过程中给定提问数据 <img src=\"https://www.zhihu.com/equation?tex=q_i\" alt=\"q_i\" eeimg=\"1\"/> 和它的一系列候选句子 <img src=\"https://www.zhihu.com/equation?tex=C+%5Cleft%28+c_%7Bi1%7D%2C+c_%7Bi2%7D%2C+...%2C+c_%7Bim%7D%5Cright%29\" alt=\"C \\left( c_{i1}, c_{i2}, ..., c_{im}\\right)\" eeimg=\"1\"/> 和标签 <img src=\"https://www.zhihu.com/equation?tex=Y%5Cleft%28+y_%7Bi1%7D%2C+y_%7Bi2%7D%2C+...%2C+y_%7Bim%7D+%5Cright%29\" alt=\"Y\\left( y_{i1}, y_{i2}, ..., y_{im} \\right)\" eeimg=\"1\"/> ,归一化的得分向量 <img src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/> 通过如下公式计算：</p><p><img src=\"https://www.zhihu.com/equation?tex=+++++++++++++++++++++++++++++++++++++++++++Score_j%3D+h_%CE%B8%28q_i%2C+c_%7Bij%7D%29++\" alt=\"                                           Score_j= h_θ(q_i, c_{ij})  \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=S+%3D+softmax%28%5BScore_1%2C+Score_2%2C+...%2C+Score_m%5D%29\" alt=\"S = softmax([Score_1, Score_2, ..., Score_m])\" eeimg=\"1\"/>      </p><p>标签的归一化方法为：</p><p><img src=\"https://www.zhihu.com/equation?tex=Y%3D%5Cfrac%7BY%7D%7B%5Csum_%7Bm%7D%5E%7Bj%3D1%7D%7By_%7Bij%7D%7D%7D\" alt=\"Y=\\frac{Y}{\\sum_{m}^{j=1}{y_{ij}}}\" eeimg=\"1\"/> </p><p>训练的目标可以为最小化 <img src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=Y\" alt=\"Y\" eeimg=\"1\"/> 的KL散度(对KL散度、交叉熵等信息论概念不理解的请移步下文参考文献3)。</p><h2>总结</h2><p>虽然pointwise广泛应用但是，但是不接近真实的排序。pairwise和listwise应用了基于候选句子排序的事实。Bian证明在TrecQA 和WikiQA数据集中listwise优于pointwise。下一篇将介绍常用模型 <img src=\"https://www.zhihu.com/equation?tex=h_%5Ctheta\" alt=\"h_\\theta\" eeimg=\"1\"/> 和评价指标。</p><h2>References</h2><ol><li>Lai T M, Bui T, Li S. A review on deep learning techniques applied to answer selection[C]//Proceedings of the 27th International Conference on Computational Linguistics. 2018: 2132-2144.</li><li>Weijie Bian, Si Li, Zhao Yang, Guang Chen, and Zhiqing Lin. 2017. A compare-aggregate model with dynamic- clip attention for answer selection. In CIKM.</li><li><a href=\"https://www.zhihu.com/question/41252833/answer/108777563\" class=\"internal\">如何通俗的解释交叉熵与相对熵?</a></li></ol><p></p>", 
            "topic": [
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "信息检索", 
                    "tagLink": "https://api.zhihu.com/topics/19580199"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": [
                {
                    "userName": "狂热撸狗爱好者", 
                    "userLink": "https://www.zhihu.com/people/066780018dc087f24e6ae31b55bfdf4a", 
                    "content": "您好，作者这个有具体损失函数实例吗。因为我看到一个pointwise损失函数。类似logf(x)的形式。并非交叉墒的形式ylogf(x)。那pointwise损失如何拟合呢", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "AI和投资", 
                    "userLink": "https://www.zhihu.com/people/d2a19f2fbe67a1e54df0f68f454b22cd", 
                    "content": "<p>写的非常好，下一篇文章抓紧啊，谢谢大佬</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/35643721", 
            "userName": "SLin", 
            "userLink": "https://www.zhihu.com/people/e35507b123bb40364e2d31d606e7dcac", 
            "upvote": 20, 
            "title": "01背包、完全背包、多重背包、二维背包之Python实现", 
            "content": "<p>背包问题核心</p><div class=\"highlight\"><pre><code class=\"language-text\">f[j] = max(f[j],f[j-c[i]]+V[i])</code></pre></div><p>01背包：（每种物品就有一个）</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">C</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">7</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">]</span><span class=\"c1\">#cost 单个物品所占容量</span>\n<span class=\"n\">V</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">]</span><span class=\"c1\">#每个物品的价值</span>\n<span class=\"n\">target</span> <span class=\"o\">=</span> <span class=\"mi\">15</span> <span class=\"c1\">#背包容量</span>\n<span class=\"n\">F</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">0</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)]</span> <span class=\"c1\">#初始化 元素个数为背包大小加1（target+1）</span>\n<span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">ZeroOneBackPack</span><span class=\"p\">(</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">reversed</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)):</span> <span class=\"c1\">#逆序遍历</span>\n        <span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"o\">-</span><span class=\"n\">cost</span><span class=\"p\">]</span><span class=\"o\">+</span><span class=\"n\">value</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"n\">n</span><span class=\"p\">):</span>\n    <span class=\"n\">ZeroOneBackPack</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">V</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span>\n<span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">target</span><span class=\"p\">])</span></code></pre></div><p>完全背包：（每种物品有无数多个）</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">C</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">7</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">]</span>\n<span class=\"n\">V</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">]</span>\n<span class=\"n\">target</span> <span class=\"o\">=</span> <span class=\"mi\">15</span>\n<span class=\"n\">F</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">0</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)]</span>\n<span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">CompleteBackPack</span><span class=\"p\">(</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">):</span><span class=\"c1\">#这是和01背包唯一的区别 正序遍历</span>\n        <span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"o\">-</span><span class=\"n\">cost</span><span class=\"p\">]</span><span class=\"o\">+</span><span class=\"n\">value</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"n\">n</span><span class=\"p\">):</span>\n    <span class=\"n\">CompleteBackPack</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">V</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span>\n<span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">target</span><span class=\"p\">])</span>\n</code></pre></div><p>多重背包：（每种物品有有限个，并通过数组给出。）</p><p>时间优化算法对于个数较多的物品进行捆绑，变成多种物品，如果某种物品有9个，可以转化为没1，2，4个进行捆绑产生3种物品一共7个，剩下的2个单独算，三种物品C，V分别乘以捆绑个数如：（C，V），（2C，2V），（4C，4V）</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">C</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">7</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">]</span>\n<span class=\"n\">V</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">]</span>\n<span class=\"n\">Count</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">]</span><span class=\"c1\">#每种物品的实现</span>\n<span class=\"n\">target</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>\n<span class=\"n\">F</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">0</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)]</span>\n<span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">CompleteBackPack</span><span class=\"p\">(</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">):</span>\n        <span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"o\">-</span><span class=\"n\">cost</span><span class=\"p\">]</span><span class=\"o\">+</span><span class=\"n\">value</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">OneZeroBackPack</span><span class=\"p\">(</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">value</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">reversed</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)):</span>\n        <span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"o\">-</span><span class=\"n\">cost</span><span class=\"p\">]</span><span class=\"o\">+</span><span class=\"n\">value</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">MultipleBackPack</span><span class=\"p\">(</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">value</span><span class=\"p\">,</span><span class=\"n\">count</span><span class=\"p\">):</span>\n\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">cost</span> <span class=\"o\">*</span> <span class=\"n\">count</span><span class=\"p\">)</span> <span class=\"o\">&gt;=</span> <span class=\"n\">target</span><span class=\"p\">:</span><span class=\"c1\">#当该种物品的个数乘以体积大于背包容量，视为有无限个即完全背包</span>\n            <span class=\"n\">CompleteBackPack</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">V</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span>\n            <span class=\"k\">return</span>\n        <span class=\"n\">temp_count</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>  <span class=\"c1\">#以上情况不满足，转化为以下情况，具体参考《背包九讲》多重背包的时间优化</span>\n        <span class=\"k\">while</span><span class=\"p\">(</span><span class=\"n\">temp_count</span><span class=\"o\">&lt;</span><span class=\"n\">count</span><span class=\"p\">):</span>\n            <span class=\"n\">OneZeroBackPack</span><span class=\"p\">(</span><span class=\"n\">temp_count</span><span class=\"o\">*</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">temp_count</span><span class=\"o\">*</span><span class=\"n\">value</span><span class=\"p\">)</span>\n            <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"n\">count</span> <span class=\"o\">-</span> <span class=\"n\">temp_count</span>\n            <span class=\"n\">temp_count</span> <span class=\"o\">=</span> <span class=\"n\">temp_count</span> <span class=\"o\">*</span> <span class=\"mi\">2</span>  <span class=\"c1\">#转化为1，2，4</span>\n        <span class=\"n\">OneZeroBackPack</span><span class=\"p\">(</span><span class=\"n\">count</span><span class=\"o\">*</span><span class=\"n\">cost</span><span class=\"p\">,</span><span class=\"n\">count</span><span class=\"o\">*</span><span class=\"n\">value</span><span class=\"p\">)</span><span class=\"c1\">#9个中剩下两个</span>\n\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"n\">n</span><span class=\"p\">):</span>\n    <span class=\"n\">MultipleBackPack</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">V</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">Count</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span>\n<span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">target</span><span class=\"p\">])</span></code></pre></div><p>二维背包：相比前三种，二维背包有两种Cost C1和C2和两个背包容量target1，target2，代码上多了一层内循环，状态上多了一维（F[][])，根据物品的个数选择是01背包（逆序遍历）完全背包（正序遍历）。以下的代码中每种物品只有一个，所以子问题为01背包</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">C1</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">7</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">]</span>\n<span class=\"n\">C2</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">7</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">]</span>\n<span class=\"n\">V</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">9</span><span class=\"p\">]</span>\n\n<span class=\"c1\">#Count = [3,5,1,9,3,5,6,8]</span>\n<span class=\"n\">target1</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>\n<span class=\"n\">target2</span> <span class=\"o\">=</span> <span class=\"mi\">25</span>\n<span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">C1</span><span class=\"p\">)</span>\n<span class=\"n\">F</span> <span class=\"o\">=</span> <span class=\"p\">[[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">target2</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"n\">target1</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)]</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"n\">n</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"nb\">reversed</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">C1</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">target1</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)):</span>\n        <span class=\"k\">for</span> <span class=\"n\">m</span> <span class=\"ow\">in</span> <span class=\"nb\">reversed</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">C2</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">target2</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)):</span><span class=\"c1\">#逆序遍历</span>\n            <span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">],</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"o\">-</span><span class=\"n\">C1</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]][</span><span class=\"n\">m</span><span class=\"o\">-</span><span class=\"n\">C2</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]]</span> <span class=\"o\">+</span> <span class=\"n\">V</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span>\n\n<span class=\"k\">print</span> <span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">[</span><span class=\"n\">target1</span><span class=\"p\">][</span><span class=\"n\">target2</span><span class=\"p\">])</span></code></pre></div><p></p>", 
            "topic": [
                {
                    "tag": "数据结构", 
                    "tagLink": "https://api.zhihu.com/topics/19591797"
                }, 
                {
                    "tag": "动态规划", 
                    "tagLink": "https://api.zhihu.com/topics/19660018"
                }, 
                {
                    "tag": "Python", 
                    "tagLink": "https://api.zhihu.com/topics/19552832"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>终于找到最优雅的实现了。</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "SLin", 
                            "userLink": "https://www.zhihu.com/people/e35507b123bb40364e2d31d606e7dcac", 
                            "content": "谢谢，我也是参考别人整理", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }, 
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>请问您还有原文链接么？建议再加一条关于背包是否需要恰好完全装满的dp数组初始化注意。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "SLin"
                        }
                    ]
                }
            ]
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/zhangshilin"
}

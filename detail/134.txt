{
    "title": "各种数学与其工程应用", 
    "description": "", 
    "followers": [
        "https://www.zhihu.com/people/lsl-3-47", 
        "https://www.zhihu.com/people/fldtt", 
        "https://www.zhihu.com/people/mcsfxy", 
        "https://www.zhihu.com/people/wxb0cf756a5ebe75e9", 
        "https://www.zhihu.com/people/frank-li-90-22", 
        "https://www.zhihu.com/people/wan-sha-28-93", 
        "https://www.zhihu.com/people/zi-fei-yu-76-10", 
        "https://www.zhihu.com/people/jia-jia-81-7-82", 
        "https://www.zhihu.com/people/long-meng-ke", 
        "https://www.zhihu.com/people/zhang-de-ci", 
        "https://www.zhihu.com/people/li-zheng-xian-43", 
        "https://www.zhihu.com/people/liuren-leo", 
        "https://www.zhihu.com/people/luozhongbin", 
        "https://www.zhihu.com/people/a-kun-kun-kun-63", 
        "https://www.zhihu.com/people/mpi-76", 
        "https://www.zhihu.com/people/xtools-26", 
        "https://www.zhihu.com/people/qun-qun-ai-xue-xi", 
        "https://www.zhihu.com/people/gmunu-29", 
        "https://www.zhihu.com/people/lang-ji-40-53", 
        "https://www.zhihu.com/people/wolf-75-45", 
        "https://www.zhihu.com/people/dong-feng-zao-ji", 
        "https://www.zhihu.com/people/da-long-mao-25-70", 
        "https://www.zhihu.com/people/jia-xue-feng", 
        "https://www.zhihu.com/people/eric-3-92", 
        "https://www.zhihu.com/people/yuan-zhong-fei-66", 
        "https://www.zhihu.com/people/yi-liang-23-12", 
        "https://www.zhihu.com/people/dapeng_xu", 
        "https://www.zhihu.com/people/npxrb-48", 
        "https://www.zhihu.com/people/lin-da-ren-26", 
        "https://www.zhihu.com/people/ye-he-zhu-xian-yun", 
        "https://www.zhihu.com/people/zi-cha-52", 
        "https://www.zhihu.com/people/liudacen", 
        "https://www.zhihu.com/people/cjin-31", 
        "https://www.zhihu.com/people/chronaa", 
        "https://www.zhihu.com/people/liu-yu-chen-28-11", 
        "https://www.zhihu.com/people/wo-da-shen-hao", 
        "https://www.zhihu.com/people/phychern", 
        "https://www.zhihu.com/people/wei-wei-1-60", 
        "https://www.zhihu.com/people/yu-hou-36", 
        "https://www.zhihu.com/people/KnowThyself", 
        "https://www.zhihu.com/people/xie-zi-bao-bao-yo", 
        "https://www.zhihu.com/people/oldtownzj", 
        "https://www.zhihu.com/people/goddog", 
        "https://www.zhihu.com/people/xiao-cheng-zi-99-61", 
        "https://www.zhihu.com/people/li-bo-90-26-39", 
        "https://www.zhihu.com/people/shen-xue-yuan-sao-di-seng", 
        "https://www.zhihu.com/people/du-hui-guang", 
        "https://www.zhihu.com/people/lee-87-75", 
        "https://www.zhihu.com/people/shao-shao-98-72", 
        "https://www.zhihu.com/people/wolframai-hao-zhe", 
        "https://www.zhihu.com/people/lala-lala-55-91", 
        "https://www.zhihu.com/people/yang-ze-yu-51-53", 
        "https://www.zhihu.com/people/SrGa", 
        "https://www.zhihu.com/people/wang-wen-jie-72", 
        "https://www.zhihu.com/people/li-gu-shu", 
        "https://www.zhihu.com/people/qi-da-wei-65", 
        "https://www.zhihu.com/people/miao-jian-jian", 
        "https://www.zhihu.com/people/zheng-jian-yang-56", 
        "https://www.zhihu.com/people/li-wei-long-78-50", 
        "https://www.zhihu.com/people/yayameii", 
        "https://www.zhihu.com/people/fei-hong-59-3", 
        "https://www.zhihu.com/people/zehui-qu", 
        "https://www.zhihu.com/people/lao-bing-97-42", 
        "https://www.zhihu.com/people/yu-zhao-yang-87", 
        "https://www.zhihu.com/people/onlygalois", 
        "https://www.zhihu.com/people/yeu-yang", 
        "https://www.zhihu.com/people/wang-jia-cheng-49-38", 
        "https://www.zhihu.com/people/bai-xiao-8", 
        "https://www.zhihu.com/people/logan-71-88", 
        "https://www.zhihu.com/people/ning-sui", 
        "https://www.zhihu.com/people/shu-li-fang-cheng-ai-hao-zhe", 
        "https://www.zhihu.com/people/miao-ni-hui", 
        "https://www.zhihu.com/people/aeroergy", 
        "https://www.zhihu.com/people/kou-jia-qing", 
        "https://www.zhihu.com/people/xun-zhao-xi-hong-shi-de-xiao-tu-dou", 
        "https://www.zhihu.com/people/donal-jiang", 
        "https://www.zhihu.com/people/zzy-64-81", 
        "https://www.zhihu.com/people/ke-li-si-42-21"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/88159622", 
            "userName": "信仰圣光吧", 
            "userLink": "https://www.zhihu.com/people/b06a581781d64d595bbaaefdcf4ac14e", 
            "upvote": 0, 
            "title": "R语言中auto.arima函数计算步骤和参数", 
            "content": "<p>﻿说明：整理自  Forecast：Principe and Practice  <a href=\"https://link.zhihu.com/?target=https%3A//otexts.com/fpp2/arima-r.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">chapter8.7</a>  。python里的pyramid.arima.auto_arima也是在R语言auto.arima的基础上写的。</p><h2>1.计算步骤</h2><p>R语言里的auto.arima是Hyndman-Khandakar算法（<a href=\"https://link.zhihu.com/?target=https%3A//otexts.com/fpp2/arima-r.html%23ref-HK08\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Hyndman &amp; Khandakar, 2008</a>）的一个变种，它结合了单位根检验，最小化AICc和MLE等评价标准来获得一个ARIMA模型。</p><p><b>Hyndman-Khandakar自动ARIMA建模算法</b>步骤如下：</p><p><b>Step1</b>：通过重复地KPSS测试来确定差分阶数d:0≤d≤2。</p><p><b>Step2</b>：对数据差分d次之后，通过最小化AICC来选择最优的p，q。算法通过stepwise search而不是遍历所有可能的p，q组合来寻找最优的p，q组合。</p><p> 　　　（2.a）拟合四个初始模型：</p><p> 　　　　　　ARIMA(0,d,0)，</p><p> 　　　　　　ARIMA(2,d,2)，</p><p> 　　　　　　ARIMA(1,d,0)，</p><p> 　　　　　　ARIMA(0,d,1)，</p><p> 　　　　如果d=2，模型中包含一个常数（constant）；如果d≤1,另外</p><p> 　　　　一个不含常数项的模型也被拟合 ARIMA(0,d,0)；</p><p> 　　　（2.b）步骤（2.a）中拟合出的最好的模型（AICc最小的）称为</p><p> 　　　“current model”；</p><p> 　　　（2.c）考察current model的以下变种模型：</p><p> 　　　　　　——对p 和/或 q的值改变±1，</p><p> 　　　　　　——包含/不包含常数项c，</p><p> 　　　　　　将上述变种和原来的current model中AICc最小的模型即为</p><p> 　　　　　　最新的current model。</p><p> 　　　（2.d）重复（2.c）直到没有更小的AICc的模型。</p><p>【说明】上述的过程其实还有几个疑点没有解释，比如KPSS检验计算步骤和原理，模型中考虑常数项和不考虑常数项的区别，这些都是比较复杂的问题，需要单独去分析，可以参考原资料。</p><h2>2. auto.arima参数简述</h2><p>以python中的pyramid.arima.auto_arima为例简述参数，更详细的请参考原函数。</p><p>auto_arima(y, exogenous=None,  start_p=2, d=None, start_q=2, max_p=5, max_d=2, max_q=5, start_P=1, D=None, start_Q=1, max_P=2, max_D=1, max_Q=2, max_order=10, m=1, seasonal=True, stationary=False, information_criterion=&#39;aic&#39;, alpha=0.05, test=&#39;kpss&#39;, seasonal_test=&#39;ch&#39;, stepwise=True, n_jobs=1, start_params=None, trend=&#39;c&#39;, method=None, transparams=True, solver=&#39;lbfgs&#39;, maxiter=50, disp=0, callback=None, offset_test_args=None, seasonal_test_args=None, suppress_warnings=False, error_action=&#39;warn&#39;, trace=False, random=False, random_state=None, n_fits=10, return_valid_fits=False, out_of_sample_size=0, scoring=&#39;mse&#39;, scoring_args=None, **fit_args)</p><p><b>y</b> : 要拟合的时间序列，需要是一维的浮点型数组。不能包含‘np.nan’ 或者‘np.inf’；</p><p><b>exogenous</b> : 可以在给定时间序列数据之外，给定额外的特征来帮助预测，需要注意的是，对于预测未来的时序数据的时候，也要提供未来的特征数据。</p><p><b>start_p</b> : int, 默认2，算法自动选择p时的下界。</p><p><b>d</b> : int, 默认None,非周期的差分阶数，如果是None，则自动选择，此时，运行时间会显著增加。</p><p><b>start_q</b> : int, 默认2，算法自动选择q时的下界。</p><p><b>max_p</b> : int, 默认5，算法自动选择p时的上界，必须≥start_p。</p><p><b>max_d</b> : int, 默认2，算法自动选择d（非周期差分阶数）时的上界，必须≥d。</p><p><b>max_q</b> : int, 默认5，算法自动选择q时的上界，必须≥start_q。</p><p><b>start_P</b> : int,默认1，周期模型自动选择P时的下界。</p><p><b>D</b> : int,默认None，周期差分的阶数，如果是None，则自动选择。</p><p><b>start_Q</b> : int, 默认1，周期模型自动选择Q时的下界。</p><p><b>max_P</b> : int,默认2，周期模型自动选择P时的上界。</p><p><b>max_D</b> : int, 默认1，周期差分阶数的最大值，必须≥D。</p><p><b>max_Q</b> : int,默认2，周期模型自动选择Q时的上界。</p><p><b>max_order</b> : int,默认10，如果p+q≥max_order，该组合对应的模型将不会被拟合。</p><p><b>m</b> : int, 默认1，周期数，例如季度数据m=4,月度数据m=12；如果m=1,则seasonal会被设置为False。</p><p><b>seasonal</b> : bool, 默认True，是否进行周期ARIMA拟合。需要注意的是，如果seasonal=True同时m=1,seasonal会被设置为False。</p><p><b>stationary</b> : bool, 默认False，标志该序列是否是平稳序列。</p><p><b>information_criterion</b> : str, 默认&#39;aic&#39;，模型评价指标，&#39;aic&#39;, &#39;bic&#39;, &#39;hqic&#39;,&#39;oob&#39;之一。</p><p><b>alpha</b> : float,默认0.05，test的显著性水平。</p><p><b>test</b> : str, 默认&#39;kpss&#39;，单位根检验的类型，当非平稳且d=None才会进行检验。</p><p><b>seasonal_test</b> : str, 默认&#39;ch&#39;，周期单位根检验方法的标志。</p><p><b>stepwise</b> : bool,默认True，如果为True，模型搜寻范围扩大，耗时显著增加。</p><p><b>n_jobs</b> : int,默认1，并行拟合模型的数目，如果为-1，则尽可能多的并行。</p><p><b>start_params</b> : array-like, 默认None，ARMA(p,q)的起始参数。</p><p><b>transparams</b> : bool,默认True，如果为True，则进行变换确保平稳性，如果为False，不检验平稳性和可逆性。</p><p><b>method</b> : str, 似然函数的类型，{&#39;css-mle&#39;,&#39;mle&#39;,&#39;css&#39;}之一。</p><p><b>trend</b> : str or iterable, 多项式趋势的多项式的系数。</p><p><b>solver</b> : str or None, 默认&#39;lbfgs&#39;，模型求解器。其它选项如&#39;bfgs&#39;、&#39;newton&#39; 等等。</p><p><b>maxiter</b> : int, 默认50，The maximum number of function evaluations。</p><p><b>disp</b> : int, 默认0，收敛信息的打印控制。disp&lt;0表示不打印任何信息。</p><p>～～以下这些参数感觉用处不是很大，用的相对也少，就不翻译了～～</p><p><b>callback</b> : callable, optional (default=None)     Called after each iteration as callback(xk) where xk is the current     parameter vector. This is only used in non-seasonal ARIMA models.</p><p><b>offset_test_args</b> : dict, optional (default=None)     The args to pass to the constructor of the offset (d) test. See pyramid.arima.stationarity　 for more details.</p><p><b>seasonal_test_args</b> : dict, optional (default=None)     The args to pass to the constructor of the seasonal offset (D)  test. See pyramid.arima.seasonality for more details.</p><p><b>suppress_warnings</b> : bool, optional (default=False)     Many warnings might be thrown inside of statsmodels. If suppress_warnings is True, all of the warnings coming from     ARIMA will be squelched.</p><p><b>error_action</b> : str, optional (default=&#39;warn&#39;)     If unable to fit an ARIMA due to stationarity issues, whether to     warn (&#39;warn&#39;), raise the ValueError (&#39;raise&#39;) or ignore (&#39;ignore&#39;).Note that the default behavior is to warn, and fits that fail will be returned as None. This is the recommended behavior, as statsmodels ARIMA and SARIMAX models hit bugs periodically that can cause an otherwise healthy parameter combination to fail for reasons not  related to pyramid.</p><p><b>trace</b> : bool, optional (default=False)     Whether to print status on the fits. Note that this can be very verbose...</p><p><b>random</b> : bool, optional (default=False)     Similar to grid searches, auto_arima provides the capability to     perform a &#34;random search&#34; over a hyper-parameter space. If random  is True, rather than perform an exhaustive search or stepwise   search, only n_fits ARIMA models will be fit (stepwise must be False for this option to do anything).</p><p><b>random_state</b> : int, long or numpy RandomState, optional (default=None) The PRNG for when random=True. Ensures replicable testing and results.</p><p><b>n_fits</b> : int, optional (default=10)     If random is True and a &#34;random search&#34; is going to be performed,n_iter is the number of ARIMA models to be fit.</p><p><b>return_valid_fits</b> : bool, optional (default=False)     If True, will return all valid ARIMA fits in a list. If False (by  default), will only return the best fit.</p><p><b>out_of_sample_size</b> : int, optional (default=0)     The ARIMA class can fit only a portion of the data if specified,     in order to retain an &#34;out of bag&#34; sample score. This is the     number of examples from the tail of the time series to hold out     and use as validation examples. The model will not be fit on these     samples, but the observations will be added into the model&#39;s endog and exog arrays so that future forecast values originate from the　end of the endogenous vector.</p><div class=\"highlight\"><pre><code class=\"language-text\">For instance::\n    y = [0, 1, 2, 3, 4, 5, 6]\n    out_of_sample_size = 2\n\n    &gt; Fit on: [0, 1, 2, 3, 4]\n    &gt; Score on: [5, 6]\n    &gt; Append [5, 6] to end of self.arima_res_.data.endog values</code></pre></div><p><b>scoring</b> : str, optional (default=&#39;mse&#39;)     If performing validation (i.e., if out_of_sample_size &gt; 0), the metric to use for scoring the out-of-sample data. One of {&#39;mse&#39;,&#39;mae&#39;}</p><p><b>scoring_args</b> : dict, optional (default=None)     A dictionary of key-word arguments to be passed to the scoring metric.</p><p><b>**fit_args</b> : dict, optional (default=None)     A dictionary of keyword arguments to pass to the :func:‘ARIMA.fit’ method.</p>", 
            "topic": [
                {
                    "tag": "R（编程语言）", 
                    "tagLink": "https://api.zhihu.com/topics/19674181"
                }, 
                {
                    "tag": "Python", 
                    "tagLink": "https://api.zhihu.com/topics/19552832"
                }, 
                {
                    "tag": "时间序列分析", 
                    "tagLink": "https://api.zhihu.com/topics/19712111"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/67446045", 
            "userName": "艾莉特", 
            "userLink": "https://www.zhihu.com/people/2c9161094259447bd78f62ef39d56369", 
            "upvote": 2, 
            "title": "Semantic Image Segmentation: 沙漏形模型（1）", 
            "content": "<p>关于图像分割，它是在实际应用场景中经常出现的一种任务。假如我们把任务空间看作是一个无向的图，那么图像分割可能是一个边更多的任务出口的节点，在它的基础上如图像分类的问题的特征要素其实已经被包括了。在多任务模型的话题中，人们也已经提出了一些思考，现在仍没有一个明确的模型可以形容任务之间的牵连性。接下来的内容，可能需要读者对于现在流行的一些概率图模型有了解，不然可能会读着不是很直观。</p><p>回归到图像分割的话题上来，由于图像的问题最近越来越趋向与独立，确实受到很多的关注。很多的话题因此被系统性的整理了，从流行的角度来说（归功于Justin Johnson），大家喜欢把图像分割这个问题分成语义分割和实例分割两个方向来讨论。包括传统方法在内的一些内容也会在近期的文章中整理。这篇文字主要是讨论语义分割中沙漏状的那些模型，如FCN，U-Net，SegNet这些，他们在这几年（2015-2019）公布的项目中也比较受欢迎。</p><p>其中语义分割（semantic segmentation）指的是做类型层面的分割；实例分割（instance segmentation）做实例层面的处理，将任务分为检测+校准+语义分割。下图比较明白的说明这两者之间的关系，</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-9841f69c7cbf2d948a4c209389e56379_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1227\" data-rawheight=\"347\" class=\"origin_image zh-lightbox-thumb\" width=\"1227\" data-original=\"https://pic2.zhimg.com/v2-9841f69c7cbf2d948a4c209389e56379_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1227&#39; height=&#39;347&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1227\" data-rawheight=\"347\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1227\" data-original=\"https://pic2.zhimg.com/v2-9841f69c7cbf2d948a4c209389e56379_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-9841f69c7cbf2d948a4c209389e56379_b.jpg\"/></figure><p>沙漏模型，其实没有这样一个词，只是有一部分人喜欢用。从个人角度而言，其实这种命名很土味，但是也比较贴切。为了统一印象，先给出一个关于沙漏模型的表述。沙漏的形状就是下图这样的</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d15b56d4f88826072986972d08ce0dcc_b.jpg\" data-size=\"normal\" data-rawwidth=\"319\" data-rawheight=\"500\" class=\"content_image\" width=\"319\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;319&#39; height=&#39;500&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"319\" data-rawheight=\"500\" class=\"content_image lazy\" width=\"319\" data-actualsrc=\"https://pic1.zhimg.com/v2-d15b56d4f88826072986972d08ce0dcc_b.jpg\"/><figcaption>沙漏-hourglass</figcaption></figure><p>一些人说的hourglass model就是使用一个对称的网络结构，它的前段是一个下采样的过程，后段通常是一个对称的上采样过程。其实也并不是一定要对称，或者说可能确实没必要，但是阶段性的尺寸的统一可以方便利用残差的思路优化传递（会在后面解释）。其实对比对称和不对称对于输出的影响也是一个很有趣的事，但那就会牵扯到一个更大的话题了。在整个采样的过程当中，受到时尚的影响，现在流行使用卷积窗口来做区域的映射。</p><p>从直观上来讲，我姑且说最初的沙漏模型是受到了autoencoder的影响，这是一种（可能）在上个世纪很流行的思路。就是通过一些方法把图像加密（encode），再解压（decode），的设计模式。在这个过程中，用有监督学习的手段训练模型只保留像素位置、类别的信息，再在解压还原的过程中生成一个二项图就是一个经典的（图像分割）沙漏模型。</p><p><b>一些具体的方法</b></p><p>那么该怎么做？直觉上来说，由于说到底就是像素的分类，那么就从每个像素的周边提取一个小块，然后训练一个分类模型根据其采样的邻居们来决定该点的标记。但是对于这个想法，想象一下，我们有一幅尺寸只有10x10的小图片，用这种方法，模型需要把它切成100小块，向前传播100次来判断每个点的信息，这样做电费是很贵的，而且也慢。另外一方面，小块可以提的信息很有限，可能不足以在复杂的图像环境中保持较好的支持。于是有了完全卷积网络（Fully Connected Net，FCN）来解决这两个缺陷，这很重要，因为许多最新的方案都将其作为基础架构。从某种角度说，他是第一个沙漏形模型。</p><p>回到动机，关键是补丁之间的重叠，重复计算并耗费最多的消耗。一个完美的解决方案是CNN，其中接收域增长属性正是这些提到的异议所需。此外，它允许输入是整个图像。然而，由于卷积的原生，当网络更深时，输出将变得越来越小，并且在零填充或对称填充的图像分类中使用的方法在这种情况下不能彻底解决问题。因此发明了上采样算子。在普通的卷积网络尾端加入上采样的映射层，可以将下采样特征图投影到其原始比例。这种下采样和上采样过程是FCN中使用的凹形结构。上采样操作也有几种选择。</p><p><br/>1）<b>Nearest Neighbour Unpooling</b>，使用最近邻居的值填充空间。<br/><br/>2）<b>Zero-Unpooling</b>，将值映射到补丁的某个位置，并用零填充剩余的空白位置。<br/><br/>3）<b>Max-Unpooling</b>，类似于零解析，但将输入值放在记录的位置，在下注池进度期间获取值。<br/><br/>4）<b>Linear Interpolation and Bilinear Interpolation</b>，使用线性函数根据相邻条目的值计算插值。<br/><br/>5）<b>Transposed Convolution</b>，在一些文献中也称为fractionally strided convolution。它是可训练的，输出是输入标量和滤波器的乘积。对输出的重叠进行求和。假如先不考虑那些溢美之辞，它实际上是一个填充了0的普通卷积，可训练的位点是受限的。<br/><br/>在FCN之后几个月，就有了U-Net（2015）见下图，（注意：这个图是一篇<i><a href=\"https://link.zhihu.com/?target=https%3A//medium.com/%40sunnerli/simple-introduction-about-hourglass-like-model-11ee7c30138\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">博客</a></i>找来的，但是它原本是有错，下面这是已经修改了的）。它使用对称架构，将较浅的层连接到相应的上采样层。同年，SegNet 问世，这与U-net非常相似，但将提到的Max-Unpooling整合到系统中。不久之后，带有可训练Transposed Convolution的DeconvNet 发表并在一些任务中获得了很好的性能。很快，受到ResNet的影响，RedNet 有意控制了中间层的尺度，并把不同深度的层连接了起来（串联）。它们的结构如下图*所示。此外，对于涉及3D数据的医学图像任务，Fausto Milletari将U-Net架构扩展到3D输入上，称为V-Net，这也很受欢迎。<br/><br/>​</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-66f3ee4e6e85da7b59d133468a6e41ed_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2729\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"2729\" data-original=\"https://pic2.zhimg.com/v2-66f3ee4e6e85da7b59d133468a6e41ed_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2729&#39; height=&#39;1080&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2729\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2729\" data-original=\"https://pic2.zhimg.com/v2-66f3ee4e6e85da7b59d133468a6e41ed_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-66f3ee4e6e85da7b59d133468a6e41ed_b.jpg\"/></figure><p><br/>但是事实上，在不少项目中已经证明了，深层的网络比较难被比较舒服的训练​，会有梯度消失等等的问题，事实上训练已经取代网络架构成为局限模型发展的主要因素，在目前的历史背景下，已经发表的沙漏形模型中上采样和下采样这两个部分的能力其实不是对等的。而且transpose conv说到底还是线性映射，它在局部分析中实际上做的就是等比例放大，亟需被改进，但是新的方法恐怕不只能够是再造图像分割，也会在相当程度上改变当前概率图模型家族的气候，像一个龙卷风。在下采样的过程中的信息损失受限于perceptron的机制，也其实和抽奖一样，在初始化时搜索就被限制在损失函数上的一个有限区域内了，这对于一个需要“发挥想象”的上采样过程来说，确实有点捉衿见肘。这也为什么沙漏模型虽然现在非常流行，但是我觉得它只能是历史过客的原因，流行度是由任务面决定的，因为人们对于精度的要求还比较低，差不多就可以了，但是这些又是另一个故事了——『Semantic Image Segmentation: 沙漏形模型（2）』。</p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "图像处理", 
                    "tagLink": "https://api.zhihu.com/topics/19556376"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "科普", 
                    "tagLink": "https://api.zhihu.com/topics/19551585"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/62776690", 
            "userName": "狼家小土豆", 
            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
            "upvote": 0, 
            "title": "程序实践：MNIST图像分类与重构", 
            "content": "<p>使用pytorch加载数据集：</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"n\">train_data</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">MNIST</span><span class=\"p\">(</span>\n    <span class=\"n\">root</span><span class=\"o\">=</span><span class=\"s1\">&#39;./mnist/&#39;</span><span class=\"p\">,</span>\n    <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>                                     <span class=\"c1\"># this is training data</span>\n    <span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">ToTensor</span><span class=\"p\">(),</span>    <span class=\"c1\"># Converts a PIL.Image or numpy.ndarray to</span>\n                                                    <span class=\"c1\"># torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]</span>\n    <span class=\"n\">download</span><span class=\"o\">=</span><span class=\"n\">DOWNLOAD_MNIST</span><span class=\"p\">,</span>                        <span class=\"c1\"># download it if you don&#39;t have it</span>\n<span class=\"p\">)</span>\n\n\n</code></pre></div><p>MNIST数据集，包含60000个数据，每个数据为28*28灰度像素。</p><p>使用以下自动编码器进行图像重构（莫烦给出的教学程序）：</p><div class=\"highlight\"><pre><code class=\"language-text\">class AutoEncoder(nn.Module):\n    def __init__(self):\n        super(AutoEncoder, self).__init__()\n\n        self.encoder = nn.Sequential(\n            nn.Linear(28*28, 128),\n            nn.Tanh(),\n            nn.Linear(128, 64),\n            nn.Tanh(),\n            nn.Linear(64, 12),\n            nn.Tanh(),\n            nn.Linear(12, 3),   # compress to 3 features which can be visualized in plt\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(3, 12),\n            nn.Tanh(),\n            nn.Linear(12, 64),\n            nn.Tanh(),\n            nn.Linear(64, 128),\n            nn.Tanh(),\n            nn.Linear(128, 28*28),\n            nn.Sigmoid(),       # compress to a range (0, 1)\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return encoded, decoded</code></pre></div><p>在该框架中，直接通过权重矩阵的方式处理图像，而不是卷积。训练误差很大。</p><p>10个迭代之后的重构误差（MSE）：</p><p>0.0357</p><p>若使用卷积的框架，改为卷积自编码器，模型的框架如下：</p><div class=\"highlight\"><pre><code class=\"language-python3\"><span class=\"k\">class</span> <span class=\"nc\">AutoEncoder</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    \n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">AutoEncoder</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span>     <span class=\"c1\"># output shape (16, 28, 28)</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>                      <span class=\"c1\"># activation</span>\n             \n            <span class=\"c1\"># compress to 3 features which can be visualized in plt</span>\n        <span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">pool</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">MaxPool2d</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">return_indices</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n        \n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">line1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">16</span> <span class=\"o\">*</span> <span class=\"mi\">12</span> <span class=\"o\">*</span> <span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Tanh</span><span class=\"p\">(),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Tanh</span><span class=\"p\">(),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">12</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Tanh</span><span class=\"p\">(),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span>    \n        <span class=\"p\">)</span>\n        \n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">line2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">12</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Tanh</span><span class=\"p\">(),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Tanh</span><span class=\"p\">(),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Tanh</span><span class=\"p\">(),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">16</span> <span class=\"o\">*</span> <span class=\"mi\">12</span> <span class=\"o\">*</span> <span class=\"mi\">12</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sigmoid</span><span class=\"p\">(),</span>       <span class=\"c1\"># compress to a range (0, 1)</span>\n            <span class=\"c1\"># output shape (16, 28, 28)         </span>\n        <span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">unpool</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">MaxUnpool2d</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            \n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ConvTranspose2d</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span> \n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">c1</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">c1</span><span class=\"p\">,</span> <span class=\"n\">ind</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">pool</span><span class=\"p\">(</span><span class=\"n\">c1</span><span class=\"p\">)</span>\n        <span class=\"n\">c1</span> <span class=\"o\">=</span> <span class=\"n\">c1</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">c1</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n        <span class=\"n\">encoded</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">line1</span><span class=\"p\">(</span><span class=\"n\">c1</span><span class=\"p\">)</span>\n        <span class=\"n\">c2</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">line2</span><span class=\"p\">(</span><span class=\"n\">encoded</span><span class=\"p\">)</span>\n        <span class=\"n\">c2</span> <span class=\"o\">=</span> <span class=\"n\">c2</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">c2</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"mi\">12</span><span class=\"p\">)</span>\n        <span class=\"n\">c2</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">unpool</span><span class=\"p\">(</span><span class=\"n\">c2</span><span class=\"p\">,</span> <span class=\"n\">ind</span><span class=\"p\">)</span>\n        <span class=\"n\">decoded</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span><span class=\"p\">(</span><span class=\"n\">c2</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">encoded</span><span class=\"p\">,</span> <span class=\"n\">decoded</span></code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><p>本文给出了全连接与自编码器对MNIST图像重构的程序。但是目前得到的结果是粗糙的。下一步还需要优化模型，改进训练方法来提高训练精度。</p><p></p>", 
            "topic": [
                {
                    "tag": "PyTorch", 
                    "tagLink": "https://api.zhihu.com/topics/20075993"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/65009641", 
            "userName": "狼家小土豆", 
            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
            "upvote": 3, 
            "title": "数学学习：EM算法的概念与推导", 
            "content": "<p>在此整理EM算法的推导过程。EM算法，全称Expectation Maximization Algorithm，是一种使用迭代实现极大似然估计的优化算法，作为牛顿迭代法对包含因变量或缺失数据的概率模型进行参数估计。EM算法的基本思想，是预先设定一组参数，然后使用最大似然估计(MLE)更新这一组参数。</p><p>实际应用中，往往会遇到数据缺失的情况。例如，</p><p>比较简单的模型就是硬币模型。两个硬币，A，B，分别服从不同的分布。实验中随机选一个硬币，从多次的投掷结果判断两个硬币的分布的参数。当我们知道选什么硬币时，很容易直接用MLP得到结果。不知道所选硬币时，不能直接求，这里就应用EM算法解决这个问题。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-2f71cb2007650440413357d6a81ca934_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"839\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https://pic1.zhimg.com/v2-2f71cb2007650440413357d6a81ca934_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;720&#39; height=&#39;839&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"839\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"720\" data-original=\"https://pic1.zhimg.com/v2-2f71cb2007650440413357d6a81ca934_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-2f71cb2007650440413357d6a81ca934_b.jpg\"/></figure><p>上图比较清晰地表现了EM 算法的流程。其中，表格显示的过程是按照A，B出现的概率，每次硬币分别出现在A与B的期望。例如，第一组实验，硬币五个正面，先验P(A)=P(B)，知道P(E|A)，P(E|B)，得到后验分布P(A|E) = 0.45，P(B|E) = 0.55。然后在这里相当于A的实验为（5*0.45，5*0.45），以此类推。最后迭代得到0.8， 0.52的参数。</p><p>EM算法的公式推导：</p><p>首先从数学上表述EM算法（来自《统计学习方法》）：</p><p>输入：观测数据Y，隐变量数据Z，联合分布P(Y,Z|θ)，条件分布P(Z|Y，θ)；</p><p>输出：模型参数θ</p><p>迭代：计算 </p><p><img src=\"https://www.zhihu.com/equation?tex=Q%28%5Ctheta%2C+%5Ctheta%5E%7B%28i%29%7D%29+%3D+E_%7Bz%7D+%5Blog%28P%28Y%2CZ%7C%5Ctheta%29%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29%5D+%3D%5CSigma_%7Bz%7D+log%28P%28Y%2CZ%7C%5Ctheta%29+P%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29\" alt=\"Q(\\theta, \\theta^{(i)}) = E_{z} [log(P(Y,Z|\\theta)|Y, \\theta^{(i)})] =\\Sigma_{z} log(P(Y,Z|\\theta) P(Z|Y, \\theta^{(i)})\" eeimg=\"1\"/></p><p>最大化Q函数，得到新的参数估计 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28i%2B1%29%7D\" alt=\"\\theta^{(i+1)}\" eeimg=\"1\"/> ,直到收敛。</p><p>详细解释EM的导出：</p><p><img src=\"https://www.zhihu.com/equation?tex=L%28%5Ctheta%29+%3D+log%28P%28Y%7C%5Ctheta%29%29%3Dlog%28%5CSigma_%7Bz%7D+P%28Y%7CZ%2C+%5Ctheta%29+P%28Z%7C%5Ctheta%29+%29\" alt=\"L(\\theta) = log(P(Y|\\theta))=log(\\Sigma_{z} P(Y|Z, \\theta) P(Z|\\theta) )\" eeimg=\"1\"/> </p><p>新的估计值要使L更大：</p><p><img src=\"https://www.zhihu.com/equation?tex=L%28%5Ctheta%29+-+L%28%5Ctheta%5E%7B%28i%29%7D%29+%3D++log%28%5CSigma_%7Bz%7D+P%28Y%7CZ%2C+%5Ctheta%29+P%28Z%7C%5Ctheta%29+%29+-++log+P%28Y%7C%5Ctheta%5E%7B%28i%29%7D%29\" alt=\"L(\\theta) - L(\\theta^{(i)}) =  log(\\Sigma_{z} P(Y|Z, \\theta) P(Z|\\theta) ) -  log P(Y|\\theta^{(i)})\" eeimg=\"1\"/> </p><p>使用Jensen 不等式，有</p><p><img src=\"https://www.zhihu.com/equation?tex=L%28%5Ctheta%29+-+L%28%5Ctheta%5E%7B%28i%29%7D%29+%3D++log%28%5CSigma_%7Bz%7D+P%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+%5Cfrac%7BP%28Y%7CZ%2C+%5Ctheta%29+P%28Z%7C%5Ctheta%29+%7D%7BP%28P%28Y%7CZ%2C+%5Ctheta%5E%7B%28i%29%7D%29%29+%7D+%29-+log+P%28Y%7C%5Ctheta%5E%7B%28i%29%7D%29\" alt=\"L(\\theta) - L(\\theta^{(i)}) =  log(\\Sigma_{z} P(Z|Y, \\theta^{(i)}) \\frac{P(Y|Z, \\theta) P(Z|\\theta) }{P(P(Y|Z, \\theta^{(i)})) } )- log P(Y|\\theta^{(i)})\" eeimg=\"1\"/></p><p>（补充：《统计学习方法》跳过了一个小步骤）</p><p><img src=\"https://www.zhihu.com/equation?tex=P%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+%3D+P%28Y%7CZ%2C+%5Ctheta%5E%7B%28i%29%7D%29+\" alt=\"P(Z|Y, \\theta^{(i)}) = P(Y|Z, \\theta^{(i)}) \" eeimg=\"1\"/> </p><p>继续，</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cgeq+%5CSigma_%7Bz%7D+P%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+log+%5Cfrac%7BP%28Y%7CZ%2C+%5Ctheta%29+P%28Z%7C%5Ctheta%29+%7D%7BP%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+%7D+-+log+P%28Y%7C%5Ctheta%5E%7B%28i%29%7D%29\" alt=\"\\geq \\Sigma_{z} P(Z|Y, \\theta^{(i)}) log \\frac{P(Y|Z, \\theta) P(Z|\\theta) }{P(Z|Y, \\theta^{(i)}) } - log P(Y|\\theta^{(i)})\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D%5CSigma_%7Bz%7D+P%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+log+%5Cfrac%7BP%28Y%7CZ%2C+%5Ctheta%29+P%28Z%7C%5Ctheta%29+%7D%7BP%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+P%28Y%7C%5Ctheta%5E%7B%28i%29%7D%29%7D+\" alt=\"=\\Sigma_{z} P(Z|Y, \\theta^{(i)}) log \\frac{P(Y|Z, \\theta) P(Z|\\theta) }{P(Z|Y, \\theta^{(i)}) P(Y|\\theta^{(i)})} \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=L%28%5Ctheta%29+%5Cgeq+B%28%5Ctheta%2C+%5Ctheta%5E%7B%28i%29%7D%29+%3D++%5CSigma_%7Bz%7D+P%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+log+%5Cfrac%7BP%28Y%7CZ%2C+%5Ctheta%29+P%28Z%7C%5Ctheta%29+%7D%7BP%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+%7D\" alt=\"L(\\theta) \\geq B(\\theta, \\theta^{(i)}) =  \\Sigma_{z} P(Z|Y, \\theta^{(i)}) log \\frac{P(Y|Z, \\theta) P(Z|\\theta) }{P(Z|Y, \\theta^{(i)}) }\" eeimg=\"1\"/> </p><p class=\"ztext-empty-paragraph\"><br/></p><p>其中， <img src=\"https://www.zhihu.com/equation?tex=B%28%5Ctheta%5E%7B%28i%29%7D%2C+%5Ctheta%5E%7B%28i%29%7D%29+%3D+L%28%5Ctheta%5E%7B%28i%29%7D%29\" alt=\"B(\\theta^{(i)}, \\theta^{(i)}) = L(\\theta^{(i)})\" eeimg=\"1\"/> </p><p>使B达到极大，</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28i%2B1%29%7D+%3D+arg+max_%7B%5Ctheta%7D+%28+%5CSigma_%7Bz%7D+P%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+log+%5Cfrac%7BP%28Y%7CZ%2C+%5Ctheta%29+P%28Z%7C%5Ctheta%29+%7D%7BP%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+%7D+%29\" alt=\"\\theta^{(i+1)} = arg max_{\\theta} ( \\Sigma_{z} P(Z|Y, \\theta^{(i)}) log \\frac{P(Y|Z, \\theta) P(Z|\\theta) }{P(Z|Y, \\theta^{(i)}) } )\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D+arg+max_%7B%5Ctheta%7D+%28+%5CSigma_%7Bz%7D+P%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+log+P%28Y%7CZ%2C+%5Ctheta%29+P%28Z%7C%5Ctheta%29%29+\" alt=\"= arg max_{\\theta} ( \\Sigma_{z} P(Z|Y, \\theta^{(i)}) log P(Y|Z, \\theta) P(Z|\\theta)) \" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D+arg+max_%7B%5Ctheta%7D+%28+%5CSigma_%7Bz%7D+P%28Z%7CY%2C+%5Ctheta%5E%7B%28i%29%7D%29+log+P%28Y%2CZ%7C%5Ctheta%29%29\" alt=\"= arg max_{\\theta} ( \\Sigma_{z} P(Z|Y, \\theta^{(i)}) log P(Y,Z|\\theta))\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%3D+arg+max+_%7B%5Ctheta%7D+Q%28%5Ctheta%2C+%5Ctheta%5E%7B%28i%29%7D%29\" alt=\"= arg max _{\\theta} Q(\\theta, \\theta^{(i)})\" eeimg=\"1\"/> </p><p class=\"ztext-empty-paragraph\"><br/></p><p>应当注意的是，EM算法不能保证收敛到全局最优值。图1说明了这一点，最后迭代收敛的并不是我们预设的0.8, 0.45</p><p>参考文献：</p><p>统计机器学习课程，张志华</p><p>统计学习方法，李航</p><p>What is the expectation maximization algorithm? Chuong B Do &amp; Serafim Batzoglou</p><p></p>", 
            "topic": [
                {
                    "tag": "统计学习方法", 
                    "tagLink": "https://api.zhihu.com/topics/19909949"
                }, 
                {
                    "tag": "随机过程", 
                    "tagLink": "https://api.zhihu.com/topics/19699543"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/63208832", 
            "userName": "狼家小土豆", 
            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
            "upvote": 1, 
            "title": "数学学习：变分推断", 
            "content": "<p>变分推断可以说是生成式模型训练的基础。在变分推断中，使用模型生成的分布去逼近实际的分布。之所以是“变分”，因为一个分布需要用整个函数来描述，训练的误差是这个分布函数的函数。</p><p>我们需要求出的是p(z|x)。 求出p(z|x),最直接的方法是利用贝叶斯公式：</p><p><img src=\"https://www.zhihu.com/equation?tex=p%28z%7Cx%29+%3D+%5Cfrac%7Bp%28x%2Cz%29%7D%7Bp%28x%29%7D\" alt=\"p(z|x) = \\frac{p(x,z)}{p(x)}\" eeimg=\"1\"/> </p><p>其中，p(x,z)好求，但是p(x)不好求，所以难以直接求。</p><p>换一个思路，我们引入另一个分部q(z), 通过生成q(z)来逼近p(z|x)。判断p，q两个分布的逼近程度，用KL散度表示：</p><p><img src=\"https://www.zhihu.com/equation?tex=KL%28q%28z%29%7C%7Cp%28z%7Cx%29%29+%3D+%5Cint_%7Bz%7D+q%28z%29+log%5Cfrac+%7Bq%28z%29%7D%7Bp%28z%7Cx%29%7D+dz+\" alt=\"KL(q(z)||p(z|x)) = \\int_{z} q(z) log\\frac {q(z)}{p(z|x)} dz \" eeimg=\"1\"/> </p><p>KL散度越小，逼近程度越大。但是KL散度难以直接求，因为我们并不知道分布p(z|x)。</p><p>虽然我们不知道p(z|x), 但是再利用贝叶斯公式，我们可以建立下列的联系：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac+%7Bp%28z%2Cx%29%7D%7Bq%28z%29%7D++%5Cfrac%7Bq%28z%29%7D%7Bp%28z%7Cx%29%7D+%3Dp%28x%29\" alt=\"\\frac {p(z,x)}{q(z)}  \\frac{q(z)}{p(z|x)} =p(x)\" eeimg=\"1\"/> </p><p>取对数，并求关于z 的期望，我们有：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cint_z+q%28z%29+log%5Cfrac+%7Bp%28z%2Cx%29%7D%7Bq%28z%29%7D+dz+%2B+%5Cint_z+q%28z%29+log%5Cfrac%7Bq%28z%29%7D%7Bp%28z%7Cx%29%7D+dz%3D%5Cint_z+q%28z%29+log+p%28x%29+dz+%3D+ELBO+%2BKL%28q%28z%29%7C%7Cp%28z%7Cx%29%29\" alt=\"\\int_z q(z) log\\frac {p(z,x)}{q(z)} dz + \\int_z q(z) log\\frac{q(z)}{p(z|x)} dz=\\int_z q(z) log p(x) dz = ELBO +KL(q(z)||p(z|x))\" eeimg=\"1\"/> </p><p>其中，p(x)是客观固定的， <img src=\"https://www.zhihu.com/equation?tex=%5Cint_z+q%28z%29+log+p%28x%29+dz+%3D+log+p%28x%29\" alt=\"\\int_z q(z) log p(x) dz = log p(x)\" eeimg=\"1\"/>  也是固定的。</p><p>所以在这里KL散度完全由ELBO项决定，训练的时候我们只需要增大ELBO便可以减小KL散度。ELBO在这里是可以求的：</p><p><img src=\"https://www.zhihu.com/equation?tex=ELBO+%3D+%5Cint_z+q%28z%29+log%5Cfrac+%7Bp%28z%2Cx%29%7D%7Bq%28z%29%7D+dz+\" alt=\"ELBO = \\int_z q(z) log\\frac {p(z,x)}{q(z)} dz \" eeimg=\"1\"/> </p><p>实际训练的时候，ELBO不像神经网络那样有显式表达式，所以不能用反向传播算法进行训练。所以该算法训练是将其视为黑盒，通过直接求差分的方式得到梯度。</p><p>本文只是自己学习过程中为了理顺思路创作的笔记，讨论的内容并不完备。还需要讨论的内容有：</p><p>1 p(x), p(z,x)的具体概念。</p><p>2 具体如何进行训练。</p><p>3 变分推断的程序实现。考虑使用一个简单的情况，例如投掷硬币的分布。</p>", 
            "topic": [
                {
                    "tag": "数学", 
                    "tagLink": "https://api.zhihu.com/topics/19554091"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "贝叶斯统计", 
                    "tagLink": "https://api.zhihu.com/topics/19632220"
                }
            ], 
            "comments": [
                {
                    "userName": "狼家小土豆", 
                    "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
                    "content": "<p>知乎的公式编辑真好用！比mathtype好多了！</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/56683697", 
            "userName": "Radium", 
            "userLink": "https://www.zhihu.com/people/f46df536867a9cf491de408e8a19839b", 
            "upvote": 12, 
            "title": "天龙八部①天众---人口模型", 
            "content": "<p><b>天龙八部</b>（<a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E6%25A2%25B5%25E8%25AA%259E\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">梵语</a>：Aṣṭasenā；<a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E6%25A8%2599%25E6%25BA%2596%25E8%2597%258F%25E8%25AA%259E\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">标准藏语</a>：lha srin sde brgyad），是<a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E4%25BD%259B%25E6%2595%2599\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">佛教</a>概念，指佛教<a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E8%25AD%25B7%25E6%25B3%2595%25E7%25A5%259E\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">护法神</a>队伍中以天、龙为首的八种神话种族，包含天众、龙众、<a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E5%25A4%259C%25E5%258F%2589\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">夜叉</a>、<a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E4%25B9%25BE%25E9%2597%25BC%25E5%25A9%2586\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">乾闼婆</a>、<a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E9%2598%25BF%25E4%25BF%25AE%25E7%25BD%2597\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">阿修罗</a>、<a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E8%25BF%25A6%25E6%25A5%25BC%25E7%25BD%2597\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">迦楼罗</a>、<a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E7%25B4%25A7%25E9%2582%25A3%25E7%25BD%2597\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">紧那罗</a>、<a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E6%2591%25A9%25E7%259D%25BA%25E7%25BE%2585%25E8%25BF%25A6\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">摩睺罗迦</a>。本系列文章主要分享8个基本模型，因此以天龙八部中的八种神话种族为名。孟子曾谈到一个人性的一个根源，知其性，你就能知天。因此第一个模型-----人口模型为天众。</p><p>人口管理让人口动力作为研究对象创造了条件，但也时常让人头痛，特别是遇到反常的情况。例如，为何一战时在亚得里亚海捕鱼，却导致相对丰富的捕食者也减少？人口动力学是一个复杂的动力学系统，它的复杂来源于任意一种种类的数量与环境以及其他种类数量之间纵横交错的关系。历史上经典的论题有：一个种族或几个种族之间的时间演化、种族之间的相互影响和共处、种群的空间分布，年龄分布等。而最新的论题是用混沌动力学去研究的。</p><h2><b>一，连续时间动力学系统</b></h2><p>用数学处理人口统计学问题的先驱是Thomas Robert Malthus在其著名的《人口原理（An essay on the principle of population as it affects the future improvement of society）》(1798年)一文中提出人口模型，他的模型是基于人口增长率和人口数 <img src=\"https://www.zhihu.com/equation?tex=P\" alt=\"P\" eeimg=\"1\"/> 成比例的自然假设。它由微分方程表示为</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BdN%28t%29%7D%7Bdt%7D%3D%5Cphi+N%28t%29-%5Cmu+N%28t%29%3DrN%28t%29\" alt=\"\\frac{dN(t)}{dt}=\\phi N(t)-\\mu N(t)=rN(t)\" eeimg=\"1\"/> </p><p>其中， <img src=\"https://www.zhihu.com/equation?tex=%5Cphi\" alt=\"\\phi\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> 为常数且为正。我们可以得到 <img src=\"https://www.zhihu.com/equation?tex=N%28t%29%3DN%280%29exp%28rt%29\" alt=\"N(t)=N(0)exp(rt)\" eeimg=\"1\"/> 。所以如果 <img src=\"https://www.zhihu.com/equation?tex=r%3E0\" alt=\"r&gt;0\" eeimg=\"1\"/> ，人口成指数增长。如果 <img src=\"https://www.zhihu.com/equation?tex=r%3C0\" alt=\"r&lt;0\" eeimg=\"1\"/> 人口成指数下降，最后该物种会消失。当 <img src=\"https://www.zhihu.com/equation?tex=r%3D0\" alt=\"r=0\" eeimg=\"1\"/> 时，物种数量不会变化。从数学的角度上来说是对的，但现实情况中却不是。人们考虑进一步修正人口模型，目的是为了寻找更加实际的人口规律。其中之一，就是我们所知道的Logistic人口模型</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BdN%28t%29%7D%7Bdt%7D%3DrN%28t%29%281-%5Cfrac%7BN%28t%29%7D%7BK%7D%29\" alt=\"\\frac{dN(t)}{dt}=rN(t)(1-\\frac{N(t)}{K})\" eeimg=\"1\"/> </p><p>其中r 和K（环境容量）为两个正的常数。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-92437bd63e9edc778f14931b16adb886_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1163\" data-rawheight=\"633\" class=\"origin_image zh-lightbox-thumb\" width=\"1163\" data-original=\"https://pic3.zhimg.com/v2-92437bd63e9edc778f14931b16adb886_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1163&#39; height=&#39;633&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1163\" data-rawheight=\"633\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1163\" data-original=\"https://pic3.zhimg.com/v2-92437bd63e9edc778f14931b16adb886_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-92437bd63e9edc778f14931b16adb886_b.jpg\"/></figure><p>该方程有两个稳定的点， <img src=\"https://www.zhihu.com/equation?tex=N%3D0\" alt=\"N=0\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=N%3DK\" alt=\"N=K\" eeimg=\"1\"/> ，其中 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BdN%28t%29%7D%7Bdt%7D%3D0\" alt=\"\\frac{dN(t)}{dt}=0\" eeimg=\"1\"/> 。解为</p><p><img src=\"https://www.zhihu.com/equation?tex=N%28t%29%3D%5Cfrac%7BN%280%29Kexp%28rt%29%7D%7BK%2BN%280%29%28exp%28rt%29-1%29%7D\" alt=\"N(t)=\\frac{N(0)Kexp(rt)}{K+N(0)(exp(rt)-1)}\" eeimg=\"1\"/> </p><p>我们可以验证上图即为该解的图像，随着 <img src=\"https://www.zhihu.com/equation?tex=N%280%29\" alt=\"N(0)\" eeimg=\"1\"/> 的取值不同，做出的曲线也不一样。特别注意的是，当 <img src=\"https://www.zhihu.com/equation?tex=N%280%29%3C%5Cfrac%7BK%7D%7B2%7D\" alt=\"N(0)&lt;\\frac{K}{2}\" eeimg=\"1\"/> 时，人口会逐渐增长，当达到 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BK%7D%7B2%7D\" alt=\"\\frac{K}{2}\" eeimg=\"1\"/> 时，增长速度最快，之后增长速度会逐渐减缓，随着时间无限延长，人口数量会收敛于K（环境容量）。目前Logistic人口模型是最常用的预测模型，因此网上有很多完整的程序包可以做参考，MATLAB编程可以参考如下：</p><a href=\"https://link.zhihu.com/?target=http%3A//www.voidcn.com/article/p-vwyuiiui-ey.html\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">人口预测模型Matlab实现Logistic曲线模型 - 程序园</a><p>建模都是从实际模型中去获得想法的。而实际模型意味着没有遗漏任何一种情况。在之前的模型中，我们没有考虑年龄分布，也就意味着刚出生的婴儿便可以生育。因此假设在出生与生育之间加入一段时间更加合理。</p><h2>Mc Kendrick-Von Foerster equation</h2><p>设 <img src=\"https://www.zhihu.com/equation?tex=n%28t%2Ca%29\" alt=\"n(t,a)\" eeimg=\"1\"/> 为在时间 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 和年龄段 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 时的人口数量。因此在时间 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 时，总人口为 <img src=\"https://www.zhihu.com/equation?tex=%5Cint_%7B0%7D%5E%7B%5Cinfty%7Dn%28t%2Ca%29da\" alt=\"\\int_{0}^{\\infty}n(t,a)da\" eeimg=\"1\"/> 。设 <img src=\"https://www.zhihu.com/equation?tex=%5Cphi+%28t%2Ca%29\" alt=\"\\phi (t,a)\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu+%28t%2Ca%29\" alt=\"\\mu (t,a)\" eeimg=\"1\"/> 为出生率和死亡率。在无限小的时间 <img src=\"https://www.zhihu.com/equation?tex=dt\" alt=\"dt\" eeimg=\"1\"/> 内， <img src=\"https://www.zhihu.com/equation?tex=%5Cmu+%28t%2Ca%29n%28t%2Ca%29\" alt=\"\\mu (t,a)n(t,a)\" eeimg=\"1\"/> 为在年段 <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 时的死亡人数。出生率只影响 <img src=\"https://www.zhihu.com/equation?tex=n%28t%2C0%29\" alt=\"n(t,0)\" eeimg=\"1\"/> (没人会在年龄为 <img src=\"https://www.zhihu.com/equation?tex=a%3E0\" alt=\"a&gt;0\" eeimg=\"1\"/> 时出生)</p><p>于是我们可以得到Mc Kendrick-Von Foerster equation如下:</p><p><img src=\"https://www.zhihu.com/equation?tex=dn%28t%2Ca%29%3D%5Cfrac%7B%5Cpartial+n%7D%7B%5Cpartial+t%7Ddt%2B%5Cfrac%7B%5Cpartial+n%7D%7B%5Cpartial+a%7Dda%3D-%5Cmu+%28t%2Ca%29n%28t%2Ca%29dt\" alt=\"dn(t,a)=\\frac{\\partial n}{\\partial t}dt+\\frac{\\partial n}{\\partial a}da=-\\mu (t,a)n(t,a)dt\" eeimg=\"1\"/> </p><p>注意， <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7Bda%7D%7Bdt%7D%5Cequiv1\" alt=\"\\frac{da}{dt}\\equiv1\" eeimg=\"1\"/> (每隔一年你就长了一岁！). <img src=\"https://www.zhihu.com/equation?tex=n%28t%2Ca%29\" alt=\"n(t,a)\" eeimg=\"1\"/> 满足下列线性偏微分方程</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+n%7D%7B%5Cpartial+t%7D%2B%5Cfrac%7B%5Cpartial+n%7D%7B%5Cpartial+a%7D%3D-%5Cmu+%28t%2Ca%29n\" alt=\"\\frac{\\partial n}{\\partial t}+\\frac{\\partial n}{\\partial a}=-\\mu (t,a)n\" eeimg=\"1\"/> </p><p>然后我们需要确定边界条件，设 <img src=\"https://www.zhihu.com/equation?tex=n_0+%28a%29\" alt=\"n_0 (a)\" eeimg=\"1\"/> 为初始年龄分布</p><p><img src=\"https://www.zhihu.com/equation?tex=n%280%2Ca%29%3Dn_0+%28a%29\" alt=\"n(0,a)=n_0 (a)\" eeimg=\"1\"/> </p><p>另外一个边界条件是由出生率给出的</p><p><img src=\"https://www.zhihu.com/equation?tex=n%28t%2C0%29%3D%5Cint_%7B0%7D%5E%7B%2B%5Cinfty%7D%5Cphi+%28t%2Ca%29n%28t%2Ca%29da\" alt=\"n(t,0)=\\int_{0}^{+\\infty}\\phi (t,a)n(t,a)da\" eeimg=\"1\"/> </p><p>为了简化模型我们用 <img src=\"https://www.zhihu.com/equation?tex=%2B%5Cinfty\" alt=\"+\\infty\" eeimg=\"1\"/> 作为年龄的上限。最后可用拉普拉斯变化求解，具体求解方法参见参考文献【2】。</p><h2>捕食者与被捕食者：Lotka-Volterra模型</h2><p>由A.J.Lotka（1925年）和V.Volterra(1926年)提出的捕食者与被捕食者模型可以通过非线性一阶常微分方程组</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7Bdx%7D%7Bdt%7D%3D%28a-by%29x%2C%5Cfrac%7Bdy%7D%7Bdt%7D%3D%28kx-l%29y\" alt=\"\\frac{dx}{dt}=(a-by)x,\\frac{dy}{dt}=(kx-l)y\" eeimg=\"1\"/> </p><p>表示，其中 <img src=\"https://www.zhihu.com/equation?tex=a%2Cb%2Ck%2Cl\" alt=\"a,b,k,l\" eeimg=\"1\"/> 是正的常数。这里 <img src=\"https://www.zhihu.com/equation?tex=y\" alt=\"y\" eeimg=\"1\"/> 表示捕食者种类， <img src=\"https://www.zhihu.com/equation?tex=x\" alt=\"x\" eeimg=\"1\"/> 是它的被捕食者。假设被捕食者数量提供了捕食者的总体食物供应。对以上方程组解的定性分析显示，任何一个被Lotka-Volterra方程描述的生物系统最终达到的不是一个常数就是一个周期变化的数量。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-52398358959033f1371fee35eba514ea_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"798\" data-rawheight=\"311\" class=\"origin_image zh-lightbox-thumb\" width=\"798\" data-original=\"https://pic3.zhimg.com/v2-52398358959033f1371fee35eba514ea_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;798&#39; height=&#39;311&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"798\" data-rawheight=\"311\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"798\" data-original=\"https://pic3.zhimg.com/v2-52398358959033f1371fee35eba514ea_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-52398358959033f1371fee35eba514ea_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-eedb5cd042298056bff8144d60069c94_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"721\" data-rawheight=\"523\" class=\"origin_image zh-lightbox-thumb\" width=\"721\" data-original=\"https://pic1.zhimg.com/v2-eedb5cd042298056bff8144d60069c94_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;721&#39; height=&#39;523&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"721\" data-rawheight=\"523\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"721\" data-original=\"https://pic1.zhimg.com/v2-eedb5cd042298056bff8144d60069c94_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-eedb5cd042298056bff8144d60069c94_b.jpg\"/></figure><p>由图可见Lotka-Volterra系统的轨迹不能收敛于一个稳定的点（除了像（0,0）和（1,1）这样微不足道的解）。</p><h2>Super-predator-predator-prey模型</h2><p>现在我们假设有一个处于食物链顶层的Super-捕猎者如人类，共同捕猎捕猎者和被捕猎者。设 <img src=\"https://www.zhihu.com/equation?tex=%5Clambda\" alt=\"\\lambda\" eeimg=\"1\"/> 为Super-捕猎者的数量，以及 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu\" alt=\"\\mu\" eeimg=\"1\"/> （ <img src=\"https://www.zhihu.com/equation?tex=resp.%5Ceta\" alt=\"resp.\\eta\" eeimg=\"1\"/> ）为Super-捕猎者捕猎捕猎者(resp.the preys) 我们可以得到如下模型：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BdN%7D%7Bdt%7D%3D%28%5Calpha_1-%5Cmu+%5Clambda-%5Cbeta_1P%29N\" alt=\"\\frac{dN}{dt}=(\\alpha_1-\\mu \\lambda-\\beta_1P)N\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BdN%7D%7Bdt%7D%3D%28-%5Calpha_2-%5Ceta+%5Clambda%2B%5Cbeta_2N%29P\" alt=\"\\frac{dN}{dt}=(-\\alpha_2-\\eta \\lambda+\\beta_2N)P\" eeimg=\"1\"/> </p><p>这样会有两种情况：</p><ul><li><img src=\"https://www.zhihu.com/equation?tex=%5Calpha_1%3E%5Cmu+%5Clambda\" alt=\"\\alpha_1&gt;\\mu \\lambda\" eeimg=\"1\"/> .被捕猎者（resp.捕猎者）的平均数量为 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Calpha_2%2B%5Ceta+%5Clambda%7D%7B%5Cbeta_2%7D%28resp.%5Cfrac%7B%5Calpha_1-%5Cmu+%5Clambda%7D%7B%5Cbeta_1%7D%29\" alt=\"\\frac{\\alpha_2+\\eta \\lambda}{\\beta_2}(resp.\\frac{\\alpha_1-\\mu \\lambda}{\\beta_1})\" eeimg=\"1\"/> 。随着Super-捕食者的数量增加（也就是说，当 <img src=\"https://www.zhihu.com/equation?tex=%5Clambda\" alt=\"\\lambda\" eeimg=\"1\"/> 从0增加到临界值 <img src=\"https://www.zhihu.com/equation?tex=%5Calpha_1%2F%5Cmu\" alt=\"\\alpha_1/\\mu\" eeimg=\"1\"/> ），捕食者的数量减少，但是被捕食者的数量增加。</li><li><img src=\"https://www.zhihu.com/equation?tex=%5Calpha_1%3E%5Cmu+%5Clambda\" alt=\"\\alpha_1&gt;\\mu \\lambda\" eeimg=\"1\"/> .我们可以简单的check一下，如果 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BdN%7D%7BNdt%7D%3C%5Calpha_1-%5Cmu+%5Clambda\" alt=\"\\frac{dN}{Ndt}&lt;\\alpha_1-\\mu \\lambda\" eeimg=\"1\"/> :被捕食者会成指数型的减少，被捕食者消失后，相应的捕食者也会消失。</li></ul><h2>竞争和生态位</h2><p>我们仍然假设两个物种共同生活在一个生态圈中，但是，没有捕食者也没有被捕食者，这两个物种在竞争同一个资源。那么，这两个物种可以共存吗?于是这样就有了生态位的概念：生态位是指每个个体或种群在种群或群落中的时空位置及功能关系。这种模型和Lotka-Volterra模型很相似，我们可以得到如下等式：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BdN%28t%29%7D%7Bdt%7D%3D%5Calpha+N%28t%29%281-%5Cfrac%7BN%28t%29%2B%5Cbeta_1P%28t%29%7D%7BK_1%7D%29\" alt=\"\\frac{dN(t)}{dt}=\\alpha N(t)(1-\\frac{N(t)+\\beta_1P(t)}{K_1})\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BdP%28t%29%7D%7Bdt%7D%3D%5Calpha+P%28t%29%281-%5Cfrac%7BP%28t%29%2B%5Cbeta_2N%28t%29%7D%7BK_2%7D%29\" alt=\"\\frac{dP(t)}{dt}=\\alpha P(t)(1-\\frac{P(t)+\\beta_2N(t)}{K_2})\" eeimg=\"1\"/> </p><p>我们假设，对于两个物种而言，他们的出生率是相同的；环境容量 <img src=\"https://www.zhihu.com/equation?tex=K_1\" alt=\"K_1\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=K_2\" alt=\"K_2\" eeimg=\"1\"/> 不同；两个物种的环境污染由常数 <img src=\"https://www.zhihu.com/equation?tex=%5Cbeta_1\" alt=\"\\beta_1\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Cbeta_2\" alt=\"\\beta_2\" eeimg=\"1\"/> 来确定，假设 <img src=\"https://www.zhihu.com/equation?tex=0%3C%5Cbeta_1%2C%5Cbeta_2%3C1\" alt=\"0&lt;\\beta_1,\\beta_2&lt;1\" eeimg=\"1\"/> .具体结果分析参见参考文献【2】。</p><h2><b>二、博弈论和进化</b></h2><p>博弈论主要研究公式化了的激励结构间的相互作用，是研究具有斗争或竞争性质现象的数学理论和方法。 博弈论考虑游戏中的个体的预测行为和实际行为，并研究它们的优化策略。生物学家使用博弈理论来理解和预测进化论的某些结果。博弈论研究的假设：</p><p>1、决策主体是理性的，最大化自己的利益；2、完全理性是共同知识/3、每个参与人被假定为对所处环境及其他参与者的行为形成正确信念与预期</p><p>当出现新的食物资源或者为求偶斗争时，物种之间至少会有两种行为：第一种便是斗争，不惜任何代价去获取资源，这种行为便称作“鹰”；第二种便是宁愿牺牲一些资源也不愿去冒险，这样的行为称为“鸽”。两个参与者之间的斗争，便是博弈，其中的问题是：参数为多少时，鹰和鸽的数量可以达到平衡？</p><p>考虑非合作博弈，参与者A和B处于竞争状态。参与者A（resp.B）会以概率选择决策集合中的决策x(resp.y)。因此我们定义 <img src=\"https://www.zhihu.com/equation?tex=R%5E%7B%5C%23A%7D\" alt=\"R^{\\#A}\" eeimg=\"1\"/> 中的子集 <img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BA%7D\" alt=\"\\bar{A}\" eeimg=\"1\"/> ：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BA%7D%3D%5Cleft%5C%7B+x%5Cin%28R%5E%2B%29%5E%7B%5C%23A%7D%2C%5Csum_%7B1%7D%5E%7B%5C%23A%7D%7Bx_i%3D1%7D+%5Cright%5C%7D\" alt=\"\\bar{A}=\\left\\{ x\\in(R^+)^{\\#A},\\sum_{1}^{\\#A}{x_i=1} \\right\\}\" eeimg=\"1\"/> </p><p>集合 <img src=\"https://www.zhihu.com/equation?tex=A\" alt=\"A\" eeimg=\"1\"/> 包含于集合 <img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BA%7D\" alt=\"\\bar{A}\" eeimg=\"1\"/> 中：A中第i个元素被向量（0,...,1,...,0）在第i个位置上用1所替代。这样我们就有了连续的决策集合 <img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BA%7D\" alt=\"\\bar{A}\" eeimg=\"1\"/> 。而混合决策是纯决策的凸组合。凸组合上的权重可以解释为参与者A选择该纯决策的概率，对于玩家B也是一样的，决策集合为 <img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BB%7D\" alt=\"\\bar{B}\" eeimg=\"1\"/> 。 <img src=\"https://www.zhihu.com/equation?tex=R%5E2\" alt=\"R^2\" eeimg=\"1\"/> 中 <img src=\"https://www.zhihu.com/equation?tex=A%5Ctimes+B\" alt=\"A\\times B\" eeimg=\"1\"/> 上的函数 <img src=\"https://www.zhihu.com/equation?tex=f\" alt=\"f\" eeimg=\"1\"/> 称为联合函数。其中 <img src=\"https://www.zhihu.com/equation?tex=f_A%28x%2Cy%29\" alt=\"f_A(x,y)\" eeimg=\"1\"/> 代表着参与者A的“盈利”。函数 <img src=\"https://www.zhihu.com/equation?tex=f\" alt=\"f\" eeimg=\"1\"/>为定义在集合 <img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BA%7D\" alt=\"\\bar{A}\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BB%7D\" alt=\"\\bar{B}\" eeimg=\"1\"/> 上的双线性函数。设 <img src=\"https://www.zhihu.com/equation?tex=x%3D%28x_i%29\" alt=\"x=(x_i)\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=y%3D%28y_i%29\" alt=\"y=(y_i)\" eeimg=\"1\"/> 为 <img src=\"https://www.zhihu.com/equation?tex=%5Cbar%7BA%7D%5Ctimes+%5Cbar%7BB%7D\" alt=\"\\bar{A}\\times \\bar{B}\" eeimg=\"1\"/> 中的混合决策。于是有:</p><p><img src=\"https://www.zhihu.com/equation?tex=f_A%28x%2Cy%29%3D%5Csum_%7Bi%2Cj%3D1%7D%5E%7B%5C%23A%2C%5C%23B%7D%7Bx_iy_jf_A%28A_i%2CB_j%29%7D\" alt=\"f_A(x,y)=\\sum_{i,j=1}^{\\#A,\\#B}{x_iy_jf_A(A_i,B_j)}\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=f_B%28x%2Cy%29%3D%5Csum_%7Bi%2Cj%3D1%7D%5E%7B%5C%23A%2C%5C%23B%7D%7Bx_iy_jf_B%28A_i%2CB_j%29%7D\" alt=\"f_B(x,y)=\\sum_{i,j=1}^{\\#A,\\#B}{x_iy_jf_B(A_i,B_j)}\" eeimg=\"1\"/> </p><p>当然，参与者A和B的行为是联合函数的结果。参与者A选择决策 <img src=\"https://www.zhihu.com/equation?tex=x%5E%5Cstar\" alt=\"x^\\star\" eeimg=\"1\"/> 可以实现他的最大化利润，但这并不一定是B的最佳决策，可以用数学语言表示为</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+x%5E%5Cstar%5Cin%5Cbar%7BA%7D%2Cf_A%28x%5E%5Cstar%2Cy%29%3D%5Cmax_%7Bx+%5Cin+%5Cbar%7BA%7D%7D%7Bf_A%28x%2Cy%29%7D%5Cright%5C%7D\" alt=\"\\left\\{ x^\\star\\in\\bar{A},f_A(x^\\star,y)=\\max_{x \\in \\bar{A}}{f_A(x,y)}\\right\\}\" eeimg=\"1\"/> </p><p>类似的，可以得到</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+y%5E%5Cstar%5Cin%5Cbar%7BB%7D%2Cf_B%28x%2Cy%5E%5Cstar%29%3D%5Cmax_%7Bx+%5Cin+%5Cbar%7BB%7D%7D%7Bf_B%28x%2Cy%29%7D%5Cright%5C%7D\" alt=\"\\left\\{ y^\\star\\in\\bar{B},f_B(x,y^\\star)=\\max_{x \\in \\bar{B}}{f_B(x,y)}\\right\\}\" eeimg=\"1\"/> </p><p>于是问题便是要知道是否存在一对决策 <img src=\"https://www.zhihu.com/equation?tex=%5Cleft%28+x%5E%5Cstar%2Cy%5E%5Cstar+%5Cright%29\" alt=\"\\left( x^\\star,y^\\star \\right)\" eeimg=\"1\"/> 满足之前的条件。这样的一对组合称为纳什均衡。在博弈中，如果一对决策称为纳什均衡当且仅当：</p><p><img src=\"https://www.zhihu.com/equation?tex=f_A%28x%5E%5Cstar%2Cy%5E%5Cstar%29%3D%5Cmax_%7Bx+%5Cin+%5Cbar%7BA%7D%7D%7Bf_A%28x%2Cy%5E%5Cstar%29%7D\" alt=\"f_A(x^\\star,y^\\star)=\\max_{x \\in \\bar{A}}{f_A(x,y^\\star)}\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=f_B%28x%5E%5Cstar%2Cy%5E%5Cstar%29%3D%5Cmax_%7Bx+%5Cin+%5Cbar%7BB%7D%7D%7Bf_B%28x%5E%5Cstar%2Cy%29%7D\" alt=\"f_B(x^\\star,y^\\star)=\\max_{x \\in \\bar{B}}{f_B(x^\\star,y)}\" eeimg=\"1\"/> </p><p>纳什均衡是否存在是一个十分困难的问题，需要考虑Brouwer不动点定理。</p><blockquote>Nash Theorem<br/>假设有凹函数 <img src=\"https://www.zhihu.com/equation?tex=x%5Crightarrow+f_A%28x%2Cy%29\" alt=\"x\\rightarrow f_A(x,y)\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=y%5Crightarrow+f_B%28x%2Cy%29\" alt=\"y\\rightarrow f_B(x,y)\" eeimg=\"1\"/> ,那么该博弈至少有一个纳什均衡点。</blockquote><p>我们考虑有限步中物种人口，这些物种竞争资源或食物。他们有两种决策，记鹰决策为“H”，鸽决策为“D”。当“鹰”和“鸽”相遇后有以下情况：</p><p>1、当两只鸽相遇，它们共同分享资源 <img src=\"https://www.zhihu.com/equation?tex=R\" alt=\"R\" eeimg=\"1\"/> ；</p><p>2、当一只鹰和一只鸽相遇，鹰无需斗争便可占有资源 <img src=\"https://www.zhihu.com/equation?tex=R\" alt=\"R\" eeimg=\"1\"/> ；</p><p>3、当两只鹰相遇，它们会斗争，造成损失 <img src=\"https://www.zhihu.com/equation?tex=P\" alt=\"P\" eeimg=\"1\"/> ，最后两只鹰都将获得资源 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BR-P%7D%7B2%7D\" alt=\"\\frac{R-P}{2}\" eeimg=\"1\"/> </p><p>设 <img src=\"https://www.zhihu.com/equation?tex=G%EF%BC%88.%2C.%EF%BC%89\" alt=\"G（.,.）\" eeimg=\"1\"/> 为“相遇”后的盈利，用数学语言便可以表示为：</p><p><img src=\"https://www.zhihu.com/equation?tex=G%28H%2CH%29%3D%5Cfrac%7BR-P%7D%7B2%7D\" alt=\"G(H,H)=\\frac{R-P}{2}\" eeimg=\"1\"/> , <img src=\"https://www.zhihu.com/equation?tex=G%28H%2CD%29%3DR\" alt=\"G(H,D)=R\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=G%28D%2CH%29%3D0\" alt=\"G(D,H)=0\" eeimg=\"1\"/> , <img src=\"https://www.zhihu.com/equation?tex=G%28D%2CD%29%3D%5Cfrac%7BR%7D%7B2%7D\" alt=\"G(D,D)=\\frac{R}{2}\" eeimg=\"1\"/> </p><p>这便是博弈中的纯决策。设 <img src=\"https://www.zhihu.com/equation?tex=%5Clambda\" alt=\"\\lambda\" eeimg=\"1\"/> 为参与者采取鸽决策的概率，根据之前的记号，联合函数 <img src=\"https://www.zhihu.com/equation?tex=f%3D%28f_A%2Cf_B%29\" alt=\"f=(f_A,f_B)\" eeimg=\"1\"/> 可写为：</p><p><img src=\"https://www.zhihu.com/equation?tex=f_A%28H%2CH%29%3Df_B%28H%2CH%29%3DG%28H%2CH%29\" alt=\"f_A(H,H)=f_B(H,H)=G(H,H)\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=f_A%28H%2CD%29%3Df_B%28D%2CH%29%3DG%28H%2CD%29\" alt=\"f_A(H,D)=f_B(D,H)=G(H,D)\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=f_A%28D%2CH%29%3Df_B%28H%2CD%29%3DG%28D%2CH%29\" alt=\"f_A(D,H)=f_B(H,D)=G(D,H)\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=f_A%28D%2CD%29%3Df_B%28D%2CD%29%3DG%28D%2CD%29\" alt=\"f_A(D,D)=f_B(D,D)=G(D,D)\" eeimg=\"1\"/> </p><p>接下来 ，我们来讨论该博弈的纳什均衡点。首先计算 <img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%7Bx+%5Cin+%5Cbar%7BA%7D%7D%7Bf_A%28x%2Cy%29%7D\" alt=\"\\max_{x \\in \\bar{A}}{f_A(x,y)}\" eeimg=\"1\"/> 。决策 <img src=\"https://www.zhihu.com/equation?tex=x\" alt=\"x\" eeimg=\"1\"/> 为混合决策可以写为 <img src=\"https://www.zhihu.com/equation?tex=x%3D%5Clambda+C%2B%281-%5Clambda%29F\" alt=\"x=\\lambda C+(1-\\lambda)F\" eeimg=\"1\"/> ,于是我们可以求得：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%7Bx%5Cin%5Cbar%7BA%7D%7D%7Bf_A%28x%2Cy%29%7D%3D%5Cmax%7B%28f_A%28D%2Cy%29%2Cf_A%28H%2Cy%29%29%7D\" alt=\"\\max_{x\\in\\bar{A}}{f_A(x,y)}=\\max{(f_A(D,y),f_A(H,y))}\" eeimg=\"1\"/> </p><p>决策y也是混合决策： <img src=\"https://www.zhihu.com/equation?tex=y%3D%5Clambda%27D%2B%281-%5Clambda%27%29H\" alt=\"y=\\lambda&#39;D+(1-\\lambda&#39;)H\" eeimg=\"1\"/> ,于是有：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%7Bx+%5Cin+A%7D%7Bf_A%28x%2Cy%29%3D%5Cmax%28%5Clambda%27%5Cfrac%7BR%7D%7B2%7D%2C%5Clambda%27R%2B%281-%5Clambda%27%29%5Cfrac%7BR-P%7D%7B2%7D%29%7D\" alt=\"\\max_{x \\in A}{f_A(x,y)=\\max(\\lambda&#39;\\frac{R}{2},\\lambda&#39;R+(1-\\lambda&#39;)\\frac{R-P}{2})}\" eeimg=\"1\"/> </p><p>分两种情况讨论：一个是损失 <img src=\"https://www.zhihu.com/equation?tex=P\" alt=\"P\" eeimg=\"1\"/> 大于资源 <img src=\"https://www.zhihu.com/equation?tex=R\" alt=\"R\" eeimg=\"1\"/> ，以及损失 <img src=\"https://www.zhihu.com/equation?tex=P\" alt=\"P\" eeimg=\"1\"/> 小于资源 <img src=\"https://www.zhihu.com/equation?tex=R\" alt=\"R\" eeimg=\"1\"/> 。</p><ul><li>情况一： <img src=\"https://www.zhihu.com/equation?tex=R%3EP\" alt=\"R&gt;P\" eeimg=\"1\"/> </li></ul><p>有 <img src=\"https://www.zhihu.com/equation?tex=f_A%28H%2Cy%29%3Ef_A%28D%2Cy%29\" alt=\"f_A(H,y)&gt;f_A(D,y)\" eeimg=\"1\"/> 于是 <img src=\"https://www.zhihu.com/equation?tex=%5Cmax_%7Bx%5Cin+%5Cbar%7BA%7D%7D%7Bf_A%28x%2Cy%29%7D%3Df_A%28H%2Cy%29\" alt=\"\\max_{x\\in \\bar{A}}{f_A(x,y)}=f_A(H,y)\" eeimg=\"1\"/> .</p><p>因为函数 <img src=\"https://www.zhihu.com/equation?tex=f_A\" alt=\"f_A\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=f_B\" alt=\"f_B\" eeimg=\"1\"/> 之间存在对称关系，均衡 <img src=\"https://www.zhihu.com/equation?tex=%5Cleft%28+x%5E%5Cstar%2Cy%5E%5Cstar+%5Cright%29\" alt=\"\\left( x^\\star,y^\\star \\right)\" eeimg=\"1\"/> 满足 <img src=\"https://www.zhihu.com/equation?tex=x%5E%5Cstar%3Dy%5E%5Cstar\" alt=\"x^\\star=y^\\star\" eeimg=\"1\"/> .我们需要寻找 <img src=\"https://www.zhihu.com/equation?tex=x%5E%5Cstar\" alt=\"x^\\star\" eeimg=\"1\"/> 满足 <img src=\"https://www.zhihu.com/equation?tex=f_A%28x%5E%5Cstar%2Cx%5E%5Cstar%29%3Df_A%28H%2Cx%5E%5Cstar%29\" alt=\"f_A(x^\\star,x^\\star)=f_A(H,x^\\star)\" eeimg=\"1\"/> ,将 <img src=\"https://www.zhihu.com/equation?tex=x%5E%5Cstar%3D%5Clambda%5E%5Cstar+D%2B%281-%5Clambda%5E%5Cstar%29H\" alt=\"x^\\star=\\lambda^\\star D+(1-\\lambda^\\star)H\" eeimg=\"1\"/> 带入得到</p><p><img src=\"https://www.zhihu.com/equation?tex=f_A%28x%5E%5Cstar%2Cx%5E%5Cstar%29%3Df_A%28H%2Cx%5E%5Cstar%29%3D%5Clambda%5E%5Cstar+f_A%28D%2Cx%5E%5Cstar%29%2B%281-%5Clambda%5E%5Cstar%29f_A%28H%2Cx%5E%5Cstar%29\" alt=\"f_A(x^\\star,x^\\star)=f_A(H,x^\\star)=\\lambda^\\star f_A(D,x^\\star)+(1-\\lambda^\\star)f_A(H,x^\\star)\" eeimg=\"1\"/> </p><p>于是可以得到当 <img src=\"https://www.zhihu.com/equation?tex=%5Clambda%5E%5Cstar%3D0\" alt=\"\\lambda^\\star=0\" eeimg=\"1\"/> 时，也就是鹰-鹰决策是纳什均衡。</p><ul><li>情况二： <img src=\"https://www.zhihu.com/equation?tex=R%3CP\" alt=\"R&lt;P\" eeimg=\"1\"/> </li></ul><p>根据情况一我们可以得到当 <img src=\"https://www.zhihu.com/equation?tex=R%3CP\" alt=\"R&lt;P\" eeimg=\"1\"/> 时，我们需要解 <img src=\"https://www.zhihu.com/equation?tex=f_A%28D%2Cx%5E%5Cstar%29%3Df_A%28H%2Cx%5E%5Cstar%29\" alt=\"f_A(D,x^\\star)=f_A(H,x^\\star)\" eeimg=\"1\"/> ,定义<img src=\"https://www.zhihu.com/equation?tex=%5Clambda%5E%5Cstar\" alt=\"\\lambda^\\star\" eeimg=\"1\"/> 为鹰和鸽盈利的平衡点，该点由 <img src=\"https://www.zhihu.com/equation?tex=%5Clambda%5E%5Cstar%3D1-%5Cfrac%7BR%7D%7BP%7D\" alt=\"\\lambda^\\star=1-\\frac{R}{P}\" eeimg=\"1\"/> 给出。纳什均衡需由鸽决策产生的比例 <img src=\"https://www.zhihu.com/equation?tex=1-%5Cfrac%7BR%7D%7BP%7D\" alt=\"1-\\frac{R}{P}\" eeimg=\"1\"/> 以及鹰决策产生的比例 <img src=\"https://www.zhihu.com/equation?tex=%5Cfrac%7BR%7D%7BP%7D\" alt=\"\\frac{R}{P}\" eeimg=\"1\"/> 所确定。</p><blockquote>最后，关于人口模型的讨论还有很多方法，例如利用马尔科夫链和扩散方程等。<br/>如果觉得本文对你有帮助，希望大家点一个赞~~~~你们的支持是我创作的动力！谢谢！</blockquote><p>参考文献：</p><p>【1】《微分方程与数学物理问题》.瑞典.Nail H.Ibragimov</p><p>【2】《Mathematical Modeling for the life Sciences》.Jacques Istas</p>", 
            "topic": [
                {
                    "tag": "数学模型", 
                    "tagLink": "https://api.zhihu.com/topics/19612521"
                }, 
                {
                    "tag": "人口", 
                    "tagLink": "https://api.zhihu.com/topics/19558945"
                }, 
                {
                    "tag": "博弈论", 
                    "tagLink": "https://api.zhihu.com/topics/19567962"
                }
            ], 
            "comments": [
                {
                    "userName": "狼家小土豆", 
                    "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
                    "content": "很详细地介绍了一类微分方程描述的数学模型，比较可贵的是介绍了博弈论，原来纳什均衡是这一回事", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/40578973", 
            "userName": "狼家小土豆", 
            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
            "upvote": 17, 
            "title": "MATLAB中PSO工具箱使用介绍", 
            "content": "<p>这篇也勉强发到自己的专栏中，算是关于“数学的工程应用”的一篇。</p><p>最近在做pso优化rbf的时候，发现自己编的pso优化神经网络很不理想，于是从mathwork上面下载了pso工具箱，发现实在太好用了。下面简单介绍一下pso工具箱的使用方法。</p><p>首先，下载地址为：<a href=\"https://link.zhihu.com/?target=http%3A//www.mathworks.com/matlabcentral/fileexchange/25986-another-particle-swarm-toolbox\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">mathworks.com/matlabcen</span><span class=\"invisible\">tral/fileexchange/25986-another-particle-swarm-toolbox</span><span class=\"ellipsis\"></span></a> 从论坛上看到的。</p><p>pso函数形式如下：</p><p>[xOpt,fval,exitflag,output,population,scores] = ...</p><p>    pso(fitnessfcn,nvars,Aineq,bineq,Aeq,beq,LB,UB,nonlcon,options)</p><p>各种参数的意义：</p><p>输出变量：</p><p>xOpt：最优解</p><p>fval：最优值</p><p>exitflag :  终止算法的原因（达到迭代还是达到误差要求，等等原因）</p><p>output :  输出文本（描述了迭代了多少步，计算结果如何，满足了什么终止条件blabla）</p><p>population ：最终的粒子们的位置</p><p>scores ：最终的粒子对应的适应度</p><p>输入变量</p><p>fitnessfcn ： 优化的目标函数</p><p>nvars ： 参数的个数（函数维度）</p><p>Aineq ：约束</p><p>bineq ：约束</p><p>Aeq ：约束</p><p>beq ：约束</p><p>LB ： 参数取值的下限</p><p>UB： 参数取值的上限</p><p>nonlcon ：非线性约束</p><p>options ：重点！这是一个结构体，迭代步数，种群数量等等都可以通过这个选项设置。</p><p>关于options的设置：</p><p>可以直接按照结构体的定义方法，例如：options.PopulationSize=......</p><p>也可以通过psoptimset设置：</p><p>options=psoptimset（......）,这个的话有MATLAB官方的介绍，所以不详细介绍。</p><p>pso工具箱里面的psoptimset与matlab原来自带的psoptimset函数重复，建议取消自带psoptimset函数，或者，吧pso工具箱里面psoptimset函数里面的默认参数设置弄出来，事先定义options的各个要素：</p><p>% Default options</p><p>options.CognitiveAttraction = 0.5 ;</p><p>options.ConstrBoundary = &#39;penalize&#39; ; </p><p>options.AccelerationFcn = @psoiterate ;</p><p>options.DemoMode = &#39;off&#39; ;</p><p>options.Display = &#39;final&#39; ;</p><p>options.FitnessLimit = -inf ;</p><p>options.Generations = 200 ;</p><p>options.HybridFcn = [] ;</p><p>options.InitialPopulation = [] ;</p><p>options.InitialVelocities = [] ;</p><p>options.KnownMin = [] ;</p><p>options.OutputFcns = {} ;</p><p>options.PlotFcns = {} ;</p><p>options.PlotInterval = 1 ;</p><p>options.PopInitRange = [0;1] ;</p><p>options.PopulationSize = 40 ;</p><p>options.PopulationType = &#39;doubleVector&#39; ;</p><p>options.SocialAttraction = 1.25 ;</p><p>options.StallGenLimit = 50 ;</p><p>options.StallTimeLimit = Inf ;</p><p>options.TimeLimit = Inf ;</p><p>options.TolCon = 1e-6 ;</p><p>options.TolFun = 1e-6 ;</p><p>options.UseParallel = &#39;never&#39; ;</p><p>options.Vectorized = &#39;off&#39; ;</p><p>options.VelocityLimit = [] ;</p><p>以上就是pso工具箱的使用方法。个人感觉比我自己编的运行速度更快，并且收敛的更快。</p><p>最近发现陆陆续续有人收藏这篇文章，还有的就里面的程序问题来私聊我。非常感谢大家的关注，如果觉得有帮助的话，请多点赞，点赞是精神支持，也是帮助文章得到更大的关注度。</p>", 
            "topic": [
                {
                    "tag": "优化", 
                    "tagLink": "https://api.zhihu.com/topics/19570512"
                }, 
                {
                    "tag": "智能算法", 
                    "tagLink": "https://api.zhihu.com/topics/20036563"
                }, 
                {
                    "tag": "遗传算法", 
                    "tagLink": "https://api.zhihu.com/topics/19555677"
                }
            ], 
            "comments": [
                {
                    "userName": "诸屹之", 
                    "userLink": "https://www.zhihu.com/people/39506d436876b00f491eb916f4e919b8", 
                    "content": "您好，想咨询一下这个工具箱里有一个private文件夹为什么无法添加入matlab路径[可怜][可怜][可怜]。", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "狼家小土豆", 
                            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
                            "content": "<p>现在解决了没有？还有问题的话欢迎私信</p>", 
                            "likes": 0, 
                            "replyToAuthor": "诸屹之"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>迭代速度确实比自己写的快很多。在2018b里还有一个demo。</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "狼家小土豆", 
                            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
                            "content": "<p>没记错的话好像这个包用了并行吧</p>", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "「已注销」", 
                    "userLink": "https://www.zhihu.com/people/3811a260a3a5de5811e6176efa1b0b0a", 
                    "content": "<p>看了之后还是不太会用啊</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/44063413", 
            "userName": "狼家小土豆", 
            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
            "upvote": 37, 
            "title": "流形学习的微分几何基础", 
            "content": "<p>微分几何的定义非常严谨，在这里，我借助一些形象的比喻来解释一下。本人非数学专业，所以在下面肯定有很多不严谨的地方，欢迎大家指正。</p><p>比如说，拿一个面包。不妨说面包是一块连续的物质，是由连续的点构成的。这样，我们有了<b>空间</b>的概念。</p><p>从面包的内部，能找出一块连续的区域，包含在面包之内，我们叫它为“面包内的小面包”，这就是<b>子集</b>。如果来拿出一个部分，也就是子集，若这个部分不包含边界，则这个部分称为开集。姑且可以理解为没有“皮”的小面包吧。</p><p>让我们来讨论一下这些面包内的没有“皮”小面包。你可以用非常多的方式搞出不同的小面包，切割挖取，等等。甚至你能写一部非常非常大篇幅的书，来记录属于这个大面包的所有面包。这本神奇的书，可以命名为《面包国志》。《面包国志》有以下的特点：</p><p>1 面包国志里面包含大面包整体，还有胡乱注册的根本不含有任何面包材质的空号。</p><p>2 面包国志内部的任意多小面包合并起来之后生成的新的小面包都被记录在面包国志之中。</p><p>3 面包国之内部有限多个小面包取他们的共同区域生成的新的小面包也都被记录在面包国志之中。</p><p>这本《面包国志》，就是<b>拓扑</b>。有了这本小面包的宏大的记录本，我们就能描述这个空间的一些性质，也就是<b>拓扑性质</b>。</p><p>有了这本《面包国志》，这块面包被人们另眼相看，于是这块面包和它的《面包国志》成为了<b>拓扑空间</b>。</p><p>下面，让我们来揉捏这个面包。面包同志被惨无人道地各种虐待，但是这个坚强的面包相信他还是他自己，因为他手中还紧紧握着那本《面包国志》。只要自己的还在，自己还是自己。这个面包成了一个新的面包，但人们一见到他这本《面包国志》，还会认识到这就是原来的那个面包。新的面包与旧的面包，构成了<b>同胚</b>。</p><p>用同胚的概念，可以从拓扑学的角度解释，为什么球和面包圈在拓扑学上面是不同的。考虑一个从球到面包圈的变换，则会出现下列的情况:本来在球中心的那一块没有皮的部分，在变成面包圈之后成了带有外皮的部分，即不再是开集。所以拓扑上讲球和面包圈是不同的。</p><p>下面，考虑将这个面包的级别再次地升级。考虑到高等数学圈“微分”的概念比较火，为了炒概念，这个面包也强行给自己加了一波“微分”的概念。具体描述如下：</p><p>1 组成面包的每一块，都能同胚于一个欧式空间，这样，即使是一块被揉得很不像样子的空间，都能用欧式空间的坐标系来表达，从而这个面包的每一部分，可以进行编码。</p><p>2 从面包划分出两个小部分，两个部分之间若是有重合，则根据上面的那一条，这个重合能与不同的欧式空间同胚，也就是能用不同的坐标系表达。这两个坐标系之间的坐标变换要求是无限可微的。</p><p>满足上面两个条件，面包从拓扑空间升级为<b>微分流形</b>，简称为<b>流形</b>。微分流形将流形的概念和欧式空间，坐标系的概念联系在一起，比如我们常说的非欧几何，表面上看非欧的空间不能用欧式空间来表达，但是从微分的角度来看，无穷小的局部上仍然具有欧式空间的性质。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e82c48b9f37c9d50f4bfebc20d5e339d_b.jpg\" data-rawwidth=\"720\" data-rawheight=\"569\" data-size=\"normal\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https://pic2.zhimg.com/v2-e82c48b9f37c9d50f4bfebc20d5e339d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;720&#39; height=&#39;569&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"720\" data-rawheight=\"569\" data-size=\"normal\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"720\" data-original=\"https://pic2.zhimg.com/v2-e82c48b9f37c9d50f4bfebc20d5e339d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e82c48b9f37c9d50f4bfebc20d5e339d_b.jpg\"/><figcaption>流形的定义</figcaption></figure><p>这回，面包因为升级了，所以多了一个坐标系来描述面包上面的每一个点。这种新的描述方式自然比之前的描述开集的《面包国志》更加先进，前者描述区域，后者直接描述点。对这个由（面包，坐标）组成的坐标系，就是<b>图</b>。一种同胚的区域总能用多种坐标系来描述，这些坐标系如果有光滑坐标变换关系，则所有（区域，坐标）构成了<b>图册</b>。</p><p>既然有了微分流形，干脆也把同胚进行一个升级，变成<b>微分同胚</b>。还是在考虑一块面包的同胚变换，只不过之前考虑的时面包每个区域上的变换，这回换成是面包上的每个点上的变换。这个变换可以写成是一个映射，如果映射是一对一的，并且映射和逆映射无限可微，这个变换就是微分同胚。</p><p>微分同胚变换，可以说是保留了点与点之间的邻接关系，是一种数学和工程上非常重要的变换。从数学上举例，描述一个半球面，我们可以将这个球投影在一个圆上，从而用两个坐标就能表达半球面的三维信息；从工程上举例，大名鼎鼎的流形学习方法，<b>ISOMAP</b>，就可以看成一种同胚变换：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c5e384a57e34da48e6428d10c8cf8ea8_b.jpg\" data-rawwidth=\"2080\" data-rawheight=\"523\" data-size=\"normal\" class=\"origin_image zh-lightbox-thumb\" width=\"2080\" data-original=\"https://pic1.zhimg.com/v2-c5e384a57e34da48e6428d10c8cf8ea8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2080&#39; height=&#39;523&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"2080\" data-rawheight=\"523\" data-size=\"normal\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2080\" data-original=\"https://pic1.zhimg.com/v2-c5e384a57e34da48e6428d10c8cf8ea8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c5e384a57e34da48e6428d10c8cf8ea8_b.jpg\"/><figcaption>从isomap文献上面抠的图</figcaption></figure><p>关于ISOMAP等流形学习的方法就简单讲到这里。专栏的更多文章将会对ISOMAP等流形学习方法进行细致的介绍。</p><p>参考：</p><p>1 梁灿彬. 《微分几何入门与广义相对论》[J]. 科学通报, 2007(6):625-625.</p><p>2 童哲. 万门大学《微分几何与张量分析两日特训班》</p><p>3 （流形学习论文）Tenenbaum J B, Silva V D, Langford J C. A Global Geometric Framework for Nonlinear Dimensionality Reduction[J]. Science, 2000, 290(5500):2319-2323.</p>", 
            "topic": [
                {
                    "tag": "微分几何", 
                    "tagLink": "https://api.zhihu.com/topics/19571298"
                }, 
                {
                    "tag": "自然科学", 
                    "tagLink": "https://api.zhihu.com/topics/19553298"
                }, 
                {
                    "tag": "数学", 
                    "tagLink": "https://api.zhihu.com/topics/19554091"
                }
            ], 
            "comments": [
                {
                    "userName": "狼家小土豆", 
                    "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
                    "content": "感谢<a class=\"member_mention\" href=\"http://www.zhihu.com/people/4d4491fd37617a1da07e460b0343041e\" data-hash=\"4d4491fd37617a1da07e460b0343041e\" data-hovercard=\"p$b$4d4491fd37617a1da07e460b0343041e\">@克里斯</a>的耐心审稿！", 
                    "likes": 3, 
                    "childComments": []
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "学长厉害👍之前看的都是搬书本，扯高深的东西。", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "狼家小土豆", 
                            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
                            "content": "学妹别盲目崇拜。。。相当不严谨的文章", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "苏君", 
                    "userLink": "https://www.zhihu.com/people/5dda6d6b9b0f4fcf64db71f266cd4ffc", 
                    "content": "讲的挺好的，小伙子，我这几天在想关于流体微团的模型假设（流体力学中的一个概念），以后有空的话，我跟你聊一聊，不过我的想法挺民科的啊，哈哈。", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "苏君", 
                    "userLink": "https://www.zhihu.com/people/5dda6d6b9b0f4fcf64db71f266cd4ffc", 
                    "content": "我靠，你怎么关注我了，我刚想关注你，发现被你关注了竟然，", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "狼家小土豆", 
                            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
                            "content": "你是流体力学专业的？", 
                            "likes": 0, 
                            "replyToAuthor": "苏君"
                        }, 
                        {
                            "userName": "狼家小土豆", 
                            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
                            "content": "没准咱是同行", 
                            "likes": 0, 
                            "replyToAuthor": "苏君"
                        }
                    ]
                }, 
                {
                    "userName": "非平凡的理想", 
                    "userLink": "https://www.zhihu.com/people/a077b1066cc3dc977ffa11bd5c19b6f1", 
                    "content": "建议把流形和微分流形分开，毕竟流形和微分流形还是不同的", 
                    "likes": 2, 
                    "childComments": []
                }, 
                {
                    "userName": "神魔协奏", 
                    "userLink": "https://www.zhihu.com/people/430489707834af3f1ea1794051400a4b", 
                    "content": "我刚看懂一点，就刷到你这个", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "狼家小土豆", 
                            "userLink": "https://www.zhihu.com/people/2c44fa8e4731db77f6cbacf60d3f3607", 
                            "content": "<p>你这个名字太秀了，可以再加三个空格变成“梦 之 泪 伤”</p>", 
                            "likes": 0, 
                            "replyToAuthor": "神魔协奏"
                        }
                    ]
                }
            ]
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/c_1021058460410114048"
}

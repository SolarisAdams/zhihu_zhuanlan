{
    "title": "深度学习模型压缩与计算加速学习", 
    "description": "github链接：\n包含三个专题：\n1. 算法\n2. 硬件平台\n3. 开源框架", 
    "followers": [
        "https://www.zhihu.com/people/max-31-25", 
        "https://www.zhihu.com/people/linuxai", 
        "https://www.zhihu.com/people/wang-hao-3-88-97", 
        "https://www.zhihu.com/people/sirius-caffrey", 
        "https://www.zhihu.com/people/bei-qiu-56-57", 
        "https://www.zhihu.com/people/xian-rou-77", 
        "https://www.zhihu.com/people/cai-cai-14-67", 
        "https://www.zhihu.com/people/tian-hao-5-32", 
        "https://www.zhihu.com/people/yao-chen-55-4", 
        "https://www.zhihu.com/people/jiaqi-yin-36", 
        "https://www.zhihu.com/people/gong-cheng-shu-xue-yong-yong-yong", 
        "https://www.zhihu.com/people/ray-ykc", 
        "https://www.zhihu.com/people/jian-ji-29-97", 
        "https://www.zhihu.com/people/sky-86-76-70", 
        "https://www.zhihu.com/people/eclipse9527", 
        "https://www.zhihu.com/people/dong-feng-66-72", 
        "https://www.zhihu.com/people/nishuo-91", 
        "https://www.zhihu.com/people/peng-you-82", 
        "https://www.zhihu.com/people/guan-wen-long-25", 
        "https://www.zhihu.com/people/yang-meng-zhao", 
        "https://www.zhihu.com/people/xiao-pa-pa-37", 
        "https://www.zhihu.com/people/tan-xiao-96-35", 
        "https://www.zhihu.com/people/zhang-wei-kang-97", 
        "https://www.zhihu.com/people/yu-xin-68-30-42", 
        "https://www.zhihu.com/people/zhang-xiang-96-81", 
        "https://www.zhihu.com/people/feng-yi-bing-zhou", 
        "https://www.zhihu.com/people/wen-nuan-ru-chu-6-77", 
        "https://www.zhihu.com/people/wang-jing-bo-27-88", 
        "https://www.zhihu.com/people/fengjx", 
        "https://www.zhihu.com/people/zhou-gang-77-93", 
        "https://www.zhihu.com/people/shi-ba-zi-86-89", 
        "https://www.zhihu.com/people/hou-jie-96-11", 
        "https://www.zhihu.com/people/jevie", 
        "https://www.zhihu.com/people/henryqin2005", 
        "https://www.zhihu.com/people/liu-fei-94-95", 
        "https://www.zhihu.com/people/Roython14.17.18", 
        "https://www.zhihu.com/people/ming-ri-76-46", 
        "https://www.zhihu.com/people/chevson", 
        "https://www.zhihu.com/people/qiu-feng-87-35", 
        "https://www.zhihu.com/people/xiao-99-51", 
        "https://www.zhihu.com/people/tesla-89-26", 
        "https://www.zhihu.com/people/john-24-8", 
        "https://www.zhihu.com/people/huhuhuhuhuhuhuhu", 
        "https://www.zhihu.com/people/hu-xiao-ming-15-16", 
        "https://www.zhihu.com/people/shu-ru-yong-hu-ming-42-82", 
        "https://www.zhihu.com/people/tian-tian-13-85-14", 
        "https://www.zhihu.com/people/merlin-76-70", 
        "https://www.zhihu.com/people/terry-xiao-37", 
        "https://www.zhihu.com/people/cai-lin-jin", 
        "https://www.zhihu.com/people/xie-meng-qiao", 
        "https://www.zhihu.com/people/juan-juan-ye-bai-he", 
        "https://www.zhihu.com/people/judy-75-76-53", 
        "https://www.zhihu.com/people/sillyfox", 
        "https://www.zhihu.com/people/gao-xiang-8", 
        "https://www.zhihu.com/people/yang-zhu-53-77", 
        "https://www.zhihu.com/people/one-every", 
        "https://www.zhihu.com/people/hp-wang-8-10", 
        "https://www.zhihu.com/people/yang-xun-zheng", 
        "https://www.zhihu.com/people/hewu-16", 
        "https://www.zhihu.com/people/li-yi-xing-29", 
        "https://www.zhihu.com/people/thedoctor-86", 
        "https://www.zhihu.com/people/ly865623", 
        "https://www.zhihu.com/people/ke-xue-10", 
        "https://www.zhihu.com/people/shadow-57-96", 
        "https://www.zhihu.com/people/na-bian-e-hao", 
        "https://www.zhihu.com/people/feng-qian-85-60-28", 
        "https://www.zhihu.com/people/xiao-leng-88-5", 
        "https://www.zhihu.com/people/kgbook", 
        "https://www.zhihu.com/people/yang-guang-can-lan-de-ri-zi-16", 
        "https://www.zhihu.com/people/zhang-zheng-fu", 
        "https://www.zhihu.com/people/degepengcuo", 
        "https://www.zhihu.com/people/-.-Luffy", 
        "https://www.zhihu.com/people/hua-li-de-zhuan-vshen", 
        "https://www.zhihu.com/people/zjazz", 
        "https://www.zhihu.com/people/yue-sun-7-88", 
        "https://www.zhihu.com/people/li-lin-feng-55-54", 
        "https://www.zhihu.com/people/hs7001", 
        "https://www.zhihu.com/people/jeason52", 
        "https://www.zhihu.com/people/frank-pu", 
        "https://www.zhihu.com/people/leo-lee-58-57", 
        "https://www.zhihu.com/people/wa-wa-wa-49-73", 
        "https://www.zhihu.com/people/huang-qian-64-70", 
        "https://www.zhihu.com/people/chisuhua", 
        "https://www.zhihu.com/people/wang-shi-wei-63", 
        "https://www.zhihu.com/people/philoxmyu", 
        "https://www.zhihu.com/people/kuan-tao-12", 
        "https://www.zhihu.com/people/dog-lee-33", 
        "https://www.zhihu.com/people/smilelixuejian", 
        "https://www.zhihu.com/people/finley-zeng", 
        "https://www.zhihu.com/people/007zzw", 
        "https://www.zhihu.com/people/ks-mooi-53", 
        "https://www.zhihu.com/people/xu-jiong-27", 
        "https://www.zhihu.com/people/lu-geng-77", 
        "https://www.zhihu.com/people/xiao-shu-qing-33", 
        "https://www.zhihu.com/people/wang-zi-wen-85-81", 
        "https://www.zhihu.com/people/zjscu-31", 
        "https://www.zhihu.com/people/starsingchow", 
        "https://www.zhihu.com/people/xiao-hong-jun-23", 
        "https://www.zhihu.com/people/guo-xin-tao-3", 
        "https://www.zhihu.com/people/yaozhangchn", 
        "https://www.zhihu.com/people/whjxnyzh", 
        "https://www.zhihu.com/people/chen-mo-56-2", 
        "https://www.zhihu.com/people/xiaojidan", 
        "https://www.zhihu.com/people/qiu-feng-48-18", 
        "https://www.zhihu.com/people/wu-zhi-yang-53", 
        "https://www.zhihu.com/people/caishanli", 
        "https://www.zhihu.com/people/hqwsky", 
        "https://www.zhihu.com/people/123456ddd-42", 
        "https://www.zhihu.com/people/liang-de-peng", 
        "https://www.zhihu.com/people/coder-12", 
        "https://www.zhihu.com/people/feng-zhong-de-yi-han-83", 
        "https://www.zhihu.com/people/tuyamiao", 
        "https://www.zhihu.com/people/ai-na-65", 
        "https://www.zhihu.com/people/chen-peng-fei-5-27", 
        "https://www.zhihu.com/people/superpermutation", 
        "https://www.zhihu.com/people/zhou-yan-zhen-18", 
        "https://www.zhihu.com/people/yu-bo-65-57", 
        "https://www.zhihu.com/people/xhtseu", 
        "https://www.zhihu.com/people/fei-li-13", 
        "https://www.zhihu.com/people/a-wen-13-58", 
        "https://www.zhihu.com/people/xiao-heng-nan", 
        "https://www.zhihu.com/people/guo-wei-47", 
        "https://www.zhihu.com/people/bgn701", 
        "https://www.zhihu.com/people/wen-ke-59-50", 
        "https://www.zhihu.com/people/su-wei-24-1", 
        "https://www.zhihu.com/people/joy586210", 
        "https://www.zhihu.com/people/chi-xian-sheng-25", 
        "https://www.zhihu.com/people/lin-ming-bao-zi", 
        "https://www.zhihu.com/people/wen-hong-chen", 
        "https://www.zhihu.com/people/kh-liang", 
        "https://www.zhihu.com/people/LYJ-viviani", 
        "https://www.zhihu.com/people/ykone-43", 
        "https://www.zhihu.com/people/oxygen-12-77", 
        "https://www.zhihu.com/people/shuai-bu-guo-jin-cheng-xiong", 
        "https://www.zhihu.com/people/cp3xiao-mi-di", 
        "https://www.zhihu.com/people/feng-yu-luo-xue", 
        "https://www.zhihu.com/people/zhu-lei-46-52", 
        "https://www.zhihu.com/people/wen-ya-wei-98", 
        "https://www.zhihu.com/people/rabbit-stirfry", 
        "https://www.zhihu.com/people/yu-chen-37-17", 
        "https://www.zhihu.com/people/chen-fu-duo-98", 
        "https://www.zhihu.com/people/chen-zhi-ze-64", 
        "https://www.zhihu.com/people/storyofwanger", 
        "https://www.zhihu.com/people/mercurytplink", 
        "https://www.zhihu.com/people/tilaba", 
        "https://www.zhihu.com/people/zhake-hu", 
        "https://www.zhihu.com/people/huang-kun-71-34-16", 
        "https://www.zhihu.com/people/limonlin", 
        "https://www.zhihu.com/people/ganwenyao", 
        "https://www.zhihu.com/people/xiao-ai-78-63", 
        "https://www.zhihu.com/people/SuperNoVa-wen", 
        "https://www.zhihu.com/people/yong-cheng-42-49", 
        "https://www.zhihu.com/people/123456abcdef-51", 
        "https://www.zhihu.com/people/xu-zhi-ying-35", 
        "https://www.zhihu.com/people/li-lian-qiang-94-1", 
        "https://www.zhihu.com/people/bluewhale-22", 
        "https://www.zhihu.com/people/robotics7gw", 
        "https://www.zhihu.com/people/zhou-ao-jun", 
        "https://www.zhihu.com/people/kim-74-51", 
        "https://www.zhihu.com/people/0400H", 
        "https://www.zhihu.com/people/sha-feng-82", 
        "https://www.zhihu.com/people/yhcvb", 
        "https://www.zhihu.com/people/cao-ji-49-42", 
        "https://www.zhihu.com/people/fc500110", 
        "https://www.zhihu.com/people/sirs05", 
        "https://www.zhihu.com/people/liu-jn-33", 
        "https://www.zhihu.com/people/hong-lan-99", 
        "https://www.zhihu.com/people/mu-xiao-er-93", 
        "https://www.zhihu.com/people/dai-wei-66-30", 
        "https://www.zhihu.com/people/daysand", 
        "https://www.zhihu.com/people/xiao-tao-qi-yu-guai-bao-bao", 
        "https://www.zhihu.com/people/zhongtian0018", 
        "https://www.zhihu.com/people/li-gui-you-23", 
        "https://www.zhihu.com/people/tao-bo-yang", 
        "https://www.zhihu.com/people/yongjiankuang", 
        "https://www.zhihu.com/people/jon-58", 
        "https://www.zhihu.com/people/wang-wei-49-6", 
        "https://www.zhihu.com/people/tian-ya-lei-14", 
        "https://www.zhihu.com/people/yang-zhi-gang-70-1", 
        "https://www.zhihu.com/people/ke-wu-88", 
        "https://www.zhihu.com/people/chlrandybear", 
        "https://www.zhihu.com/people/yue-zhen-37-7", 
        "https://www.zhihu.com/people/zhang-tao-60-41", 
        "https://www.zhihu.com/people/pu.fuan", 
        "https://www.zhihu.com/people/Paraoia_Dre", 
        "https://www.zhihu.com/people/shi-kong-chuan-suo-64", 
        "https://www.zhihu.com/people/peng-jia-qiao", 
        "https://www.zhihu.com/people/ge-chen-1993", 
        "https://www.zhihu.com/people/xiang-chen-70-27", 
        "https://www.zhihu.com/people/zhou-xian-21-76", 
        "https://www.zhihu.com/people/1234567890-33-16-94", 
        "https://www.zhihu.com/people/zhu-forrest", 
        "https://www.zhihu.com/people/zhang-yl-28", 
        "https://www.zhihu.com/people/liu-yan-37-30-39", 
        "https://www.zhihu.com/people/hu-yu-tao-9", 
        "https://www.zhihu.com/people/liwei46", 
        "https://www.zhihu.com/people/li-zhi-90", 
        "https://www.zhihu.com/people/wang-li-xia-59", 
        "https://www.zhihu.com/people/chi-fei-fan-qun-cong-ao", 
        "https://www.zhihu.com/people/liu-bing-yan-36-28", 
        "https://www.zhihu.com/people/key-90-38", 
        "https://www.zhihu.com/people/liu-dun-qiang-11", 
        "https://www.zhihu.com/people/sun-qiong-zai", 
        "https://www.zhihu.com/people/liu-hao-jie-25", 
        "https://www.zhihu.com/people/zou-da-ben-91", 
        "https://www.zhihu.com/people/lu-jin-ming-58", 
        "https://www.zhihu.com/people/fanghaizhou", 
        "https://www.zhihu.com/people/fishofnorth", 
        "https://www.zhihu.com/people/lumial-engine", 
        "https://www.zhihu.com/people/xiong-xin-lei-15", 
        "https://www.zhihu.com/people/go-ro-87", 
        "https://www.zhihu.com/people/matchlessxiaomao", 
        "https://www.zhihu.com/people/xie-liang-liang-88", 
        "https://www.zhihu.com/people/liu-xiao-jia-09", 
        "https://www.zhihu.com/people/feng-jing-72-66", 
        "https://www.zhihu.com/people/ming-ri-qing-yun-qu", 
        "https://www.zhihu.com/people/chen-hong-bing-25", 
        "https://www.zhihu.com/people/xia-zheng-79", 
        "https://www.zhihu.com/people/han-yi-zeng", 
        "https://www.zhihu.com/people/guang-ming-26-27", 
        "https://www.zhihu.com/people/lu-chi-zou-bu-chu-hu-bu-xiang", 
        "https://www.zhihu.com/people/qiuchuyu", 
        "https://www.zhihu.com/people/hong-chen-bi-luo", 
        "https://www.zhihu.com/people/wang-xin-83", 
        "https://www.zhihu.com/people/ning-ding-17", 
        "https://www.zhihu.com/people/wu-yue-ying-39", 
        "https://www.zhihu.com/people/l_0329", 
        "https://www.zhihu.com/people/tylee-durden", 
        "https://www.zhihu.com/people/du-zi-teng-39-70", 
        "https://www.zhihu.com/people/aaa-79-26", 
        "https://www.zhihu.com/people/sophomore2", 
        "https://www.zhihu.com/people/chen-fei-65-30", 
        "https://www.zhihu.com/people/cuoqian", 
        "https://www.zhihu.com/people/xiao-chao-chao-42", 
        "https://www.zhihu.com/people/tang-mou-ren-13", 
        "https://www.zhihu.com/people/meng-jiao-han-ge", 
        "https://www.zhihu.com/people/qian-xin-chun", 
        "https://www.zhihu.com/people/how2", 
        "https://www.zhihu.com/people/zhe-da-gai-jiu-shi-ren-sheng-ba", 
        "https://www.zhihu.com/people/da-da-la-tou", 
        "https://www.zhihu.com/people/mel-tor", 
        "https://www.zhihu.com/people/hong-ye-97-62", 
        "https://www.zhihu.com/people/DiXinkai", 
        "https://www.zhihu.com/people/wang-xin-76-12", 
        "https://www.zhihu.com/people/muzi2045", 
        "https://www.zhihu.com/people/fu-ai-ru-shan", 
        "https://www.zhihu.com/people/yue-si-26"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/84403478", 
            "userName": "田子宸", 
            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
            "upvote": 8, 
            "title": "RK3399Pro整理", 
            "content": "<h2>0、 背景</h2><p>最近需要用到RK3399Pro，在这里记一些关键的参数</p><p>所有资料来自于toybrick的官网：</p><a href=\"https://link.zhihu.com/?target=http%3A//t.rock-chips.com/portal.php\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Toybrick | 让AI开发更简单</a><h2>1、 概述</h2><p>RK3399Pro是具有CPU、GPU、NPU的SoC</p><ul><li>CPU：有两个A72，四个A53</li><li>GPU：ARM Mali T860 MP4 GPU</li><li>NPU：自研架构</li></ul><p>同时还有一些其他部件，如DSP、ISP等</p><h2>2、 各部件参数</h2><h3>2.0 部件框图</h3><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8f85fd9737d70e1e782d02d477ad265e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"828\" data-rawheight=\"777\" class=\"origin_image zh-lightbox-thumb\" width=\"828\" data-original=\"https://pic3.zhimg.com/v2-8f85fd9737d70e1e782d02d477ad265e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;828&#39; height=&#39;777&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"828\" data-rawheight=\"777\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"828\" data-original=\"https://pic3.zhimg.com/v2-8f85fd9737d70e1e782d02d477ad265e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8f85fd9737d70e1e782d02d477ad265e_b.jpg\"/></figure><h3>2.1 CPU</h3><p>有两个cluster。一个cluster上有双核A72，另一个cluster上有四核A53。</p><p>都支持ARMv8-A指令集，都支持NEON，都支持Cryptography Extensions</p><p>两个cluster之间通过CCI500保证访存一致性</p><p>每一个A72核心有48KB的L1指令cache，32KB的数据cache（4组相联）；每一个A53核心有32KB的L1cache，32KB的L1数据cache（4组相联）</p><p>每一个cluster共享一个L2 cache，大cluster（A72）为1MB，小cluster（A53）为512KB</p><h3>2.2 NPU</h3><p>每个周期可执行：</p><ul><li>INT8：1920 MACs per cycle</li><li>FP16：64 MACs per cycle</li><li>INT16：192 MACs per cycle</li></ul><p>有512KB的internal buffer</p><h3>2.3 Boot</h3><p>可以通过SPI、eMMC、SD/MMC来启动，可以通过USB OTG来烧写代码</p><h3>2.4 Internal Memory</h3><p>32KB BootROM</p><p>200KB Internal SRAM，支持security access 和 non-security access</p><h3>2.5 External Memory or Storage Device</h3><p>双通道内存，支持DDR3-1866/DDR3L-1866/LPDDR3-1866/LPDDR4；每个通道支持2个bank，每个bank最大访存空间为4GB。总共支持4GB访存空间</p><p>NPU的内存是独立的，支持DDR3-1600/DDR3L-1600/LPDDR2-1066/LPDDR3-1600；支持两个bank，每个bank访存空间最大为2G。总共支持2G访存空间</p><p>注意，这些内存只能选一种，不能混用</p><p>一个eMMC接口；两个SD/MMC接口，每一个都可以被配置为SD/MMC或SDIO，数据带宽为4bits</p><h3>2.6 系统组件</h3><ul><li>两个Cortex-M0</li><li>CRU（clock and reset unit）：24MHz clock input</li><li>PMU（power management unit）</li><li>Timer</li><li>PWM</li><li>Watchdog</li><li>Mailbox</li><li>Bus：128bit/64bit/32bit multi-layer AXI/AHB/APB；CCI500</li><li>Interrupt Controller</li><li>DMA：支持memory-to-memory/meory-to-peripheral/peripheral-to-memory；有两个DMA Controller，BUS_DMAC负责bus system，PERI_DMAC负责peripheral system</li><li>Security System：支持TrustZone；双通道加密/解密引擎；支持security boot；支持security debug</li></ul><h3>2.7 Video CODEC</h3><p>支持H.264/H.265/MPEG-4等格式的解码</p><p>支持H.264等格式的编码（只支持I帧和P帧，不支持B帧）</p><h3>2.8 JPEG CODEC</h3><p>支持JPEG解码，支持JPEG ROI decode，最大速率可达76,000,000 pixels per second</p><p>支持JPEG编码，最大速率可达90,000,000 pixels per second</p><h3>2.9 Image Enhancement Processor（IEP）</h3><p>包括如下功能：</p><ul><li>图像增强：GAMMA校正、色调/饱和度/亮度/对比度增强、边缘增强</li><li>图像降噪：Spatial sampling/Temporal sampling noise reduction</li><li>De-interlace</li></ul><h3>2.10 Graphics Engine</h3><p><b>3D Graphics Engine</b></p><p>ARM Mali-T860 MP4 GPU，支持OpenGL ES1.1/2.0/3.0、OpenCL 1.2，DirectX11.1等接口</p><p>Embedded 4 shader cores with shared hierarchical tiler</p><p>有MMU，有256KB的L2 cache</p><p><b>2D Graphics Engine</b></p><p>支持多种数据格式，可以做Scaling、Rotation等操作</p><h3>2.11 Video IN/OUT</h3><p>相机接口：1或2个MIPI-CSI接口</p><p>Image Signal Processer（ISP）：</p><ul><li>DVP或MIPI接口</li><li>可以做Balck level compensation、Lens shade correction、AF/AWB/AE/HIST</li><li>通过MPIP-DSI/eDP/DP/HDMI显示</li><li>支持AFBC function co-operation with GPU</li></ul><p>VOP（Video Output Processor）：有两个，分别是VOP_BIG和VOP_LIT，可以输出HDMI、MIPI等，也可以进行Display Process（如GAMMA、MIRROR）和Layer Process（大概是图层吧）</p><h3>2.12 HDMI</h3><h3>2.13 MIPI PHY</h3><h3>2.14 eDP PHY</h3><h3>2.15 DisplayPort</h3><h3>2.16 Type-C Interface</h3><h3>2.17 Audio Interface</h3><p>有I2S/PCM和SPDIF接口</p><h3>2.18 接口</h3><p>SDIO：SDIO 3.0协议，数据带宽4bits，有两个MMC接口，可以配置为SD/MMC或SDIO</p><p>GMAC 10/100/1000M 以太网控制器：支持IEEE 802.1Q VLAN，支持LAN wake-up</p><p>SPI：5个SPI控制器，支持DMA和中断，作为主机从机均可</p><p>UART：5个串口，DMA+中断，最高可达4Mbps，UART0~UART3支持自动流控</p><p>I2C：9个I2C控制器，可进行multi-master I2C，支持Fast-mode plus（1MHz）</p><p>GPIO：5组GPIO</p><p>USB 2.0/3.0：两个USB 2.0 host interfaces，1个USB3.0 interfaces</p><p>PCIe：1个PCIe port， 2.5Gbps，maximum link width is 4</p><h3>2.19 其他</h3><p>Temperature Sensor（TSADC）</p><p>Successive Approximation Register（SARADC）</p><p>eFuse</p><p>封装：FCBGA1372，尺寸27x27mm，厚度0.35mm</p><h2>3、 NPU</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-403ad7ecef8b4af9e47dd20301c911fa_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"834\" data-rawheight=\"451\" class=\"origin_image zh-lightbox-thumb\" width=\"834\" data-original=\"https://pic3.zhimg.com/v2-403ad7ecef8b4af9e47dd20301c911fa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;834&#39; height=&#39;451&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"834\" data-rawheight=\"451\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"834\" data-original=\"https://pic3.zhimg.com/v2-403ad7ecef8b4af9e47dd20301c911fa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-403ad7ecef8b4af9e47dd20301c911fa_b.jpg\"/></figure><p>NPU由4个部分组成：Host Interface、Power Management、Nerual Network Engine、Vector Processing Unit</p><ul><li>Host Interface：AXI用来从内存中取数据（128bit），AHB用来传递配置信息和debug（32bit）</li><li>Power Management：处理Power、Clock、Reset和同步</li><li>Nerual Network Engine：支持int8、int16、fp16，卷积、pooling、relu等操作在NN Engine上进行</li><li>Vector Processing Unit：一个SIMD器件，一个周期可以执行16个元素的乘法/加法，Elewise操作在VPU上执行</li></ul><p>NPU的运算能力：</p><ul><li>1920个int8 MAD（multiply-add units）</li><li>192个int16 MAD</li><li>64个fp16 MAD</li></ul><p>基本支持常用算子，包括CNN和RNN的</p><p></p><p></p><p></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }, 
                {
                    "tag": "高性能计算", 
                    "tagLink": "https://api.zhihu.com/topics/19608622"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/76719906", 
            "userName": "田子宸", 
            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
            "upvote": 15, 
            "title": "深度学习模型压缩与计算加速知识整理", 
            "content": "<h2>深度学习模型压缩与计算加速知识整理</h2><p>整理一下深度学习模型压缩与计算加速相关的知识，包含三大板块： </p><ul><li>算法：网络压缩算法（剪枝、蒸馏等）和计算加速算法（量化、Winograd等）  </li><li>硬件平台：各个硬件平台（CPU、GPU）及编程接口和运算库介绍 </li><li>开源框架：各大开源框架介绍</li></ul><p>知乎链接：<a href=\"https://zhuanlan.zhihu.com/c_1064124187198705664\" class=\"internal\">专栏：深度学习模型压缩与计算加速学习</a><br/>github链接：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/ZichenTian/DL_accelerate_review\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/ZichenTian/D</span><span class=\"invisible\">L_accelerate_review</span><span class=\"ellipsis\"></span></a></p><p><b>以github为主体，知乎同步可能会晚一些，建议大家直接看github</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4d816212eb376234bb0fbee2adf543b9_b.jpg\" data-size=\"normal\" data-rawwidth=\"909\" data-rawheight=\"655\" class=\"origin_image zh-lightbox-thumb\" width=\"909\" data-original=\"https://pic2.zhimg.com/v2-4d816212eb376234bb0fbee2adf543b9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;909&#39; height=&#39;655&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"909\" data-rawheight=\"655\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"909\" data-original=\"https://pic2.zhimg.com/v2-4d816212eb376234bb0fbee2adf543b9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4d816212eb376234bb0fbee2adf543b9_b.jpg\"/><figcaption>内容结构图</figcaption></figure><p>整体结构如下，慢慢填坑</p><h2>1. 算法</h2><h3>1.1 网络算法</h3><h3>1.2 计算算法</h3><h2>2. 硬件</h2><h3>2.1 CPU</h3><h3>2.2 GPU</h3><h3>2.3 FPGA</h3><h3>2.4 DSP</h3><h3>2.5 其他加速器</h3><h2>3. 开源框架</h2><h3>3.1 训练端</h3><h3>3.2 部署端</h3>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "高性能计算", 
                    "tagLink": "https://api.zhihu.com/topics/19608622"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>期待</p><a class=\"comment_sticker\" href=\"https://pic4.zhimg.com/v2-ba306425d0a7aee2c7260381f1bf7b97.gif\" data-width=\"\" data-height=\"\">[欢呼]</a>", 
                    "likes": 1, 
                    "childComments": []
                }, 
                {
                    "userName": "悦酱", 
                    "userLink": "https://www.zhihu.com/people/d4b708fd63aa0e6ac420a3aa50c9a5e0", 
                    "content": "帮HL顶", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/53772179", 
            "userName": "田子宸", 
            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
            "upvote": 5, 
            "title": "OpenCL练习(一)：使用OpenCL+OpenCV进行RGB转灰度图", 
            "content": "<h2>背景</h2><p>最近在学OpenCL，用的书是《OpenCL异构并行编程实战》。怎么说呢，感觉这本书比较迷，讲的很乱，跟着看完的话可能学不到什么。好在之前学过CUDA，勉强能够理解并行计算的思路。因此这里写了一下用显卡进行RGB2Gray的程序，也算是自己能够使用OpenCL进行一些简单的显卡计算吧。</p><p>平台：Ubuntu18.04 + CUDA10.0 + MX150 + OpenCL 1.2<br/> 目标：从磁盘读取一张图片，送入OpenCL设备进行RGB转灰度图，再拷贝回来显示</p><h2>使用OpenCL进行计算的流程</h2><p>无论是OpenCL，还是CUDA，当利用显卡计算时，都需要经历如下步骤：<br/> 1. 设备初始化 2. 准备主机端数据(分配主机端内存+获取数据) 3. 分配设备端内存 4. 将主机端数据拷贝到设备端 5. 设备启动内核函数，进行运算，将结果写到设备端内存 6. 将设备端结果拷贝回主机端 7. 读取主机端内存，进行后续处理 8. 释放资源</p><p>对于OpenCL，具体的步骤是：<br/> 1. 设备初始化(获取平台和设备id，创建上下文和命令队列) 2. 编写并编译内核 3. 准备主机端数据并传入设备(准备主机端数据，创建设备端缓冲对象，传入数据) 4. 启动内核函数(传递参数，启动内核) 5. 将结果拷贝回主机端 6. 后续处理 7. 释放资源</p><h2>设备初始化</h2><h2>获取平台id</h2><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cl_int</span> <span class=\"n\">error</span><span class=\"p\">;</span>\n    <span class=\"n\">cl_platform_id</span> <span class=\"n\">platform</span><span class=\"p\">;</span>\n\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clGetPlatformIDs</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">platform</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>   <span class=\"c1\">//获取平台id\n</span></code></pre></div><p>这里clGetPlatformIDs的函数原型为：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">clGetPlatformIDs</span><span class=\"p\">(</span><span class=\"n\">cl_uint</span>          <span class=\"cm\">/* num_entries */</span><span class=\"p\">,</span>\n                 <span class=\"n\">cl_platform_id</span> <span class=\"o\">*</span> <span class=\"cm\">/* platforms */</span><span class=\"p\">,</span>\n                 <span class=\"n\">cl_uint</span> <span class=\"o\">*</span>        <span class=\"cm\">/* num_platforms */</span><span class=\"p\">)</span>\n</code></pre></div><p>本例是只读取一个平台。实际上可能有多个平台。因此实际上更为通用的使用方法为：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cl_uint</span> <span class=\"n\">numOfPlatforms</span><span class=\"p\">;</span>\n<span class=\"n\">cl_int</span> <span class=\"n\">error</span><span class=\"p\">;</span>\n\n<span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clGetPlatformIDs</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">numOfPlatforms</span><span class=\"p\">);</span> <span class=\"c1\">//获取平台数量\n</span><span class=\"c1\"></span><span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">error</span> <span class=\"o\">!=</span> <span class=\"n\">CL_SUCCESS</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"n\">perror</span><span class=\"p\">(</span><span class=\"s\">&#34;Cannot get platform ids&#34;</span><span class=\"p\">);</span>\n    <span class=\"n\">exit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n<span class=\"n\">cl_platform_id</span> <span class=\"o\">*</span><span class=\"n\">platforms</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">cl_platform_id</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">alloca</span><span class=\"p\">(</span><span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">cl_platform_id</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"n\">numOfPlatforms</span><span class=\"p\">);</span>\n<span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clGetPlatformIDs</span><span class=\"p\">(</span><span class=\"n\">numOfPlatforms</span><span class=\"p\">,</span> <span class=\"n\">platforms</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>  <span class=\"c1\">//获取cl_platform_id实体\n</span></code></pre></div><p>这里我们看到<code>clGetPlatformIDs()</code>函数被调用了两次，第一次是获取平台的数量<code>numOfPlatforms</code>，第二次是获取<code>cl_platform_id</code>的实体。OpenCL里有很多类似的API。</p><p>本例是为了偷个懒，只使用第一个平台。</p><h2>获取设备id</h2><p>获取完平台id后，要获取设备id。这里一样偷懒，只使用平台上第一个设备。实际上一个平台上可能有多个OpenCL设备(CPU、GPU)。</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cl_device_id</span> <span class=\"n\">device</span><span class=\"p\">;</span>\n\n<span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clGetDeviceIDs</span><span class=\"p\">(</span><span class=\"n\">platform</span><span class=\"p\">,</span> <span class=\"n\">CL_DEVICE_TYPE_GPU</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span> <span class=\"c1\">//获取设备id\n</span></code></pre></div><p>函数原型为：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">clGetDeviceIDs</span><span class=\"p\">(</span><span class=\"n\">cl_platform_id</span>   <span class=\"cm\">/* platform */</span><span class=\"p\">,</span>\n               <span class=\"n\">cl_device_type</span>   <span class=\"cm\">/* device_type */</span><span class=\"p\">,</span> \n               <span class=\"n\">cl_uint</span>          <span class=\"cm\">/* num_entries */</span><span class=\"p\">,</span> \n               <span class=\"n\">cl_device_id</span> <span class=\"o\">*</span>   <span class=\"cm\">/* devices */</span><span class=\"p\">,</span> \n               <span class=\"n\">cl_uint</span> <span class=\"o\">*</span>        <span class=\"cm\">/* num_devices */</span><span class=\"p\">)</span>\n</code></pre></div><h2>创建设备上下文</h2><p>OpenCL使用上下文来管理设备，因此不论进行什么操作，都需要先创建上下文：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">context</span> <span class=\"o\">=</span> <span class=\"n\">clCreateContext</span><span class=\"p\">(</span><span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>    <span class=\"c1\">//创建上下文\n</span></code></pre></div><h2>创建命令队列</h2><p>命令队列和CUDA中的<b>流</b>的概念相对应。主机程序在设备上创建命令队列，并向命令队列中压入操作(数据传输、内核执行)。  一个设备上可以创建多个命令队列。 <br/> 与CUDA略有区别的是，OpenCL除了顺序执行命令队列中的任务之外，还可以不按顺序执行(创建队列时传入<code>CL_QUEUE_OUT_OF_ORDER_EXEC_MODE_ENABLE</code>标志位)。</p><p>创建命令队列时，需要传入设备id和上下文</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cQ</span> <span class=\"o\">=</span> <span class=\"n\">clCreateCommandQueue</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>\n</code></pre></div><p>函数原型：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">clCreateCommandQueue</span><span class=\"p\">(</span><span class=\"n\">cl_context</span>                     <span class=\"cm\">/* context */</span><span class=\"p\">,</span>\n                     <span class=\"n\">cl_device_id</span>                   <span class=\"cm\">/* device */</span><span class=\"p\">,</span>\n                     <span class=\"n\">cl_command_queue_properties</span>    <span class=\"cm\">/* properties */</span><span class=\"p\">,</span>\n                     <span class=\"n\">cl_int</span> <span class=\"o\">*</span>                       <span class=\"cm\">/* errcode_ret */</span><span class=\"p\">)</span>\n</code></pre></div><h2>编译内核</h2><p>与CUDA不同的是，OpenCL需要在程序中显式编译内核。</p><h2>内核函数</h2><p>OpenCL工程一般将内核放在单独的*.cl文件中。本例的内核为：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"cm\">/*rgb2gray.cl*/</span>\n<span class=\"n\">__kernel</span> <span class=\"kt\">void</span> <span class=\"nf\">kernel_rgb2gray</span><span class=\"p\">(</span><span class=\"n\">__global</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"o\">*</span> <span class=\"n\">rgbImage</span><span class=\"p\">,</span> \n                              <span class=\"n\">__global</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"o\">*</span> <span class=\"n\">grayImage</span><span class=\"p\">,</span> \n                              <span class=\"n\">__global</span> <span class=\"kt\">unsigned</span> <span class=\"o\">*</span> <span class=\"k\">const</span> <span class=\"n\">p_height</span><span class=\"p\">,</span> \n                              <span class=\"n\">__global</span> <span class=\"kt\">unsigned</span> <span class=\"o\">*</span> <span class=\"k\">const</span> <span class=\"n\">p_width</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"kt\">int</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">get_global_id</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n    <span class=\"kt\">int</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">get_global_id</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n    <span class=\"kt\">int</span> <span class=\"n\">height</span> <span class=\"o\">=</span> <span class=\"o\">*</span><span class=\"n\">p_height</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">width</span> <span class=\"o\">=</span> <span class=\"o\">*</span><span class=\"n\">p_width</span><span class=\"p\">;</span>\n    <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">&lt;</span> <span class=\"n\">width</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">y</span> <span class=\"o\">&lt;</span> <span class=\"n\">height</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"kt\">int</span> <span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">y</span> <span class=\"o\">*</span> <span class=\"n\">width</span> <span class=\"o\">+</span> <span class=\"n\">x</span><span class=\"p\">;</span>\n        <span class=\"n\">grayImage</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.299f</span><span class=\"o\">*</span><span class=\"n\">rgbImage</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">+</span> \n                            <span class=\"mf\">0.587f</span><span class=\"o\">*</span><span class=\"n\">rgbImage</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> \n                            <span class=\"mf\">0.114f</span><span class=\"o\">*</span><span class=\"n\">rgbImage</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"o\">+</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>程序很简单，每个工作项(对应于CUDA中的线程)读取一个像素，计算灰度值，写回该像素。</p><p>由于图像尺寸不定，因此工作项不可能刚好和图像尺寸相对匹配，因此需要<code>if(x &lt; width &amp;&amp; y &lt; height)</code>来分支。<code>height</code>和<code>width</code>则是由主机程序启动内核时传入的。</p><h2>编译内核</h2><p>OpenCL需要显示编译内核，其流程为：<br/> 读取内核文件-&gt;创建program对象-&gt;编译程序-&gt;创建内核</p><p><b>读取内核文件</b>的代码如下：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"k\">const</span> <span class=\"kt\">char</span> <span class=\"o\">*</span><span class=\"n\">file_names</span><span class=\"p\">[]</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s\">&#34;rgb2gray.cl&#34;</span><span class=\"p\">};</span>     <span class=\"c1\">//待编译的内核文件\n</span><span class=\"c1\"></span>    <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">NUMBER_OF_FILES</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">;</span>\n    <span class=\"kt\">char</span><span class=\"o\">*</span> <span class=\"n\">buffer</span><span class=\"p\">[</span><span class=\"n\">NUMBER_OF_FILES</span><span class=\"p\">];</span>\n    <span class=\"n\">size_t</span> <span class=\"n\">sizes</span><span class=\"p\">[</span><span class=\"n\">NUMBER_OF_FILES</span><span class=\"p\">];</span>\n\n    <span class=\"n\">loadProgramSource</span><span class=\"p\">(</span><span class=\"n\">file_names</span><span class=\"p\">,</span> <span class=\"n\">NUMBER_OF_FILES</span><span class=\"p\">,</span> <span class=\"n\">buffer</span><span class=\"p\">,</span> <span class=\"n\">sizes</span><span class=\"p\">);</span>  <span class=\"c1\">//读取内核文件文本\n</span><span class=\"c1\"></span>    <span class=\"n\">program</span> <span class=\"o\">=</span> <span class=\"n\">clCreateProgramWithSource</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">NUMBER_OF_FILES</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"kt\">char</span><span class=\"o\">**</span><span class=\"p\">)</span><span class=\"n\">buffer</span><span class=\"p\">,</span> <span class=\"n\">sizes</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span> <span class=\"c1\">//创建program对象\n</span><span class=\"c1\"></span>    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clBuildProgram</span><span class=\"p\">(</span><span class=\"n\">program</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>  <span class=\"c1\">//编译程序\n</span><span class=\"c1\"></span>\n    <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">error</span> <span class=\"o\">!=</span> <span class=\"n\">CL_SUCCESS</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// If there&#39;s an error whilst building the program, dump the log\n</span><span class=\"c1\"></span>        <span class=\"n\">size_t</span> <span class=\"n\">log_size</span><span class=\"p\">;</span>\n        <span class=\"n\">clGetProgramBuildInfo</span><span class=\"p\">(</span><span class=\"n\">program</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">CL_PROGRAM_BUILD_LOG</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">log_size</span><span class=\"p\">);</span>\n        <span class=\"kt\">char</span> <span class=\"o\">*</span><span class=\"n\">program_log</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"kt\">char</span><span class=\"o\">*</span><span class=\"p\">)</span> <span class=\"n\">malloc</span><span class=\"p\">(</span><span class=\"n\">log_size</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n        <span class=\"n\">program_log</span><span class=\"p\">[</span><span class=\"n\">log_size</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"sc\">&#39;\\0&#39;</span><span class=\"p\">;</span>\n        <span class=\"n\">clGetProgramBuildInfo</span><span class=\"p\">(</span><span class=\"n\">program</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">CL_PROGRAM_BUILD_LOG</span><span class=\"p\">,</span> \n                            <span class=\"n\">log_size</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">program_log</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>\n        <span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">&#34;</span><span class=\"se\">\\n</span><span class=\"s\">=== ERROR ===</span><span class=\"se\">\\n\\n</span><span class=\"s\">%s</span><span class=\"se\">\\n</span><span class=\"s\">=============</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"n\">program_log</span><span class=\"p\">);</span>\n        <span class=\"n\">free</span><span class=\"p\">(</span><span class=\"n\">program_log</span><span class=\"p\">);</span>\n        <span class=\"n\">exit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clCreateKernelsInProgram</span><span class=\"p\">(</span><span class=\"n\">program</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>    <span class=\"c1\">//创建内核\n</span></code></pre></div><p>其中<code>LoadProgramSource()</code>函数是自己编写的，目的是从file_names定义的文件中将文本读出，放入buffer中：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">void</span> <span class=\"nf\">loadProgramSource</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"kt\">char</span><span class=\"o\">**</span> <span class=\"n\">files</span><span class=\"p\">,</span>\n                       <span class=\"n\">size_t</span> <span class=\"n\">length</span><span class=\"p\">,</span>\n                       <span class=\"kt\">char</span><span class=\"o\">**</span> <span class=\"n\">buffer</span><span class=\"p\">,</span>\n                       <span class=\"n\">size_t</span><span class=\"o\">*</span> <span class=\"n\">sizes</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n       <span class=\"cm\">/* Read each source file (*.cl) and store the contents into a temporary datastore */</span>\n       <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"n\">length</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n          <span class=\"n\">FILE</span><span class=\"o\">*</span> <span class=\"n\">file</span> <span class=\"o\">=</span> <span class=\"n\">fopen</span><span class=\"p\">(</span><span class=\"n\">files</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"s\">&#34;r&#34;</span><span class=\"p\">);</span>\n          <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">file</span> <span class=\"o\">==</span> <span class=\"nb\">NULL</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n             <span class=\"n\">perror</span><span class=\"p\">(</span><span class=\"s\">&#34;Couldn&#39;t read the program file&#34;</span><span class=\"p\">);</span>\n             <span class=\"n\">exit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>   \n          <span class=\"p\">}</span>\n          <span class=\"n\">fseek</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">SEEK_END</span><span class=\"p\">);</span>\n          <span class=\"n\">sizes</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">ftell</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">);</span>\n          <span class=\"n\">rewind</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">);</span> <span class=\"c1\">// reset the file pointer so that &#39;fread&#39; reads from the front\n</span><span class=\"c1\"></span>          <span class=\"n\">buffer</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"kt\">char</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">malloc</span><span class=\"p\">(</span><span class=\"n\">sizes</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n          <span class=\"n\">buffer</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"n\">sizes</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"sc\">&#39;\\0&#39;</span><span class=\"p\">;</span>\n          <span class=\"n\">fread</span><span class=\"p\">(</span><span class=\"n\">buffer</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">char</span><span class=\"p\">),</span> <span class=\"n\">sizes</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">file</span><span class=\"p\">);</span>\n          <span class=\"n\">fclose</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">);</span>\n       <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>这里，除了从源码得到程序外，还可以从二进制文件中获取程序。</p><h2>准备主机端数据并传入设备</h2><h2>准备主机端数据</h2><p>本例准备主机端数据很简单，就是使用OpenCV接口读图片即可：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">Mat</span> <span class=\"n\">srcImage</span> <span class=\"o\">=</span> <span class=\"n\">imread</span><span class=\"p\">(</span><span class=\"s\">&#34;./test.jpg&#34;</span><span class=\"p\">);</span>\n    <span class=\"kt\">int</span> <span class=\"n\">img_h</span> <span class=\"o\">=</span> <span class=\"n\">srcImage</span><span class=\"p\">.</span><span class=\"n\">rows</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">img_w</span> <span class=\"o\">=</span> <span class=\"n\">srcImage</span><span class=\"p\">.</span><span class=\"n\">cols</span><span class=\"p\">;</span>\n    <span class=\"n\">Mat</span> <span class=\"n\">grayImage</span> <span class=\"o\">=</span> <span class=\"n\">Mat</span><span class=\"p\">(</span><span class=\"n\">img_h</span><span class=\"p\">,</span> <span class=\"n\">img_w</span><span class=\"p\">,</span> <span class=\"n\">CV_8UC1</span><span class=\"p\">,</span> <span class=\"n\">Scalar</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">));</span>  <span class=\"c1\">//创建同尺寸灰度图\n</span></code></pre></div><h2>创建缓存对象并传入数据</h2><p>使用如下函数，在设备上创建缓存对象：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">clCreateBuffer</span><span class=\"p\">(</span><span class=\"n\">cl_context</span>   <span class=\"cm\">/* context */</span><span class=\"p\">,</span>\n               <span class=\"n\">cl_mem_flags</span> <span class=\"cm\">/* flags */</span><span class=\"p\">,</span>\n               <span class=\"n\">size_t</span>       <span class=\"cm\">/* size */</span><span class=\"p\">,</span>\n               <span class=\"kt\">void</span> <span class=\"o\">*</span>       <span class=\"cm\">/* host_ptr */</span><span class=\"p\">,</span>\n               <span class=\"n\">cl_int</span> <span class=\"o\">*</span>     <span class=\"cm\">/* errcode_ret */</span><span class=\"p\">)</span>\n</code></pre></div><p>其中，<code>cl_mem_flags</code>可以指定缓存对象的类型：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"cm\">/* cl_mem_flags and cl_svm_mem_flags - bitfield */</span>\n<span class=\"n\">CL_MEM_READ_WRITE</span>\n<span class=\"n\">CL_MEM_WRITE_ONLY</span>\n<span class=\"n\">CL_MEM_READ_ONLY</span>\n<span class=\"n\">CL_MEM_USE_HOST_PTR</span>\n<span class=\"n\">CL_MEM_ALLOC_HOST_PTR</span>\n<span class=\"n\">CL_MEM_COPY_HOST_PTR</span>\n</code></pre></div><p>然后使用如下函数拷贝数据：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">clEnqueueWriteBuffer</span><span class=\"p\">(</span><span class=\"n\">cl_command_queue</span>   <span class=\"cm\">/* command_queue */</span><span class=\"p\">,</span> \n                     <span class=\"n\">cl_mem</span>             <span class=\"cm\">/* buffer */</span><span class=\"p\">,</span> \n                     <span class=\"n\">cl_bool</span>            <span class=\"cm\">/* blocking_write */</span><span class=\"p\">,</span> \n                     <span class=\"n\">size_t</span>             <span class=\"cm\">/* offset */</span><span class=\"p\">,</span> \n                     <span class=\"n\">size_t</span>             <span class=\"cm\">/* size */</span><span class=\"p\">,</span> \n                     <span class=\"k\">const</span> <span class=\"kt\">void</span> <span class=\"o\">*</span>       <span class=\"cm\">/* ptr */</span><span class=\"p\">,</span> \n                     <span class=\"n\">cl_uint</span>            <span class=\"cm\">/* num_events_in_wait_list */</span><span class=\"p\">,</span> \n                     <span class=\"k\">const</span> <span class=\"n\">cl_event</span> <span class=\"o\">*</span>   <span class=\"cm\">/* event_wait_list */</span><span class=\"p\">,</span> \n                     <span class=\"n\">cl_event</span> <span class=\"o\">*</span>         <span class=\"cm\">/* event */</span><span class=\"p\">)</span>\n</code></pre></div><p>该函数实际上是将数据拷贝压入了设备的命令队列执行。当指定blocking_write为CL_TRUE时，写操作会阻塞主机。</p><p>另一种比较简单的拷贝方式是在创建缓存对象时，就拷贝数据：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cl_mem</span> <span class=\"n\">memRgbImage</span> <span class=\"o\">=</span> <span class=\"n\">clCreateBuffer</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">CL_MEM_READ_ONLY</span> <span class=\"o\">|</span> <span class=\"n\">CL_MEM_COPY_HOST_PTR</span><span class=\"p\">,</span> \n                                    <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">uchar</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"o\">*</span><span class=\"n\">img_h</span><span class=\"o\">*</span><span class=\"n\">img_w</span><span class=\"p\">,</span> <span class=\"n\">srcImage</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>    <span class=\"c1\">//CL_MEM_COPY_HOST_PTR指定创建缓存对象后拷贝数据\n</span><span class=\"c1\"></span>    <span class=\"n\">cl_mem</span> <span class=\"n\">memGrayImage</span> <span class=\"o\">=</span> <span class=\"n\">clCreateBuffer</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">CL_MEM_WRITE_ONLY</span><span class=\"p\">,</span> \n                                    <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">uchar</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"n\">img_h</span><span class=\"o\">*</span><span class=\"n\">img_w</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>\n    <span class=\"n\">cl_mem</span> <span class=\"n\">memImageHeight</span> <span class=\"o\">=</span> <span class=\"n\">clCreateBuffer</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">CL_MEM_READ_ONLY</span><span class=\"o\">|</span> <span class=\"n\">CL_MEM_COPY_HOST_PTR</span><span class=\"p\">,</span> \n                                    <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">img_h</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>\n    <span class=\"n\">cl_mem</span> <span class=\"n\">memImageWidth</span> <span class=\"o\">=</span> <span class=\"n\">clCreateBuffer</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">CL_MEM_READ_ONLY</span><span class=\"o\">|</span> <span class=\"n\">CL_MEM_COPY_HOST_PTR</span><span class=\"p\">,</span> \n                                    <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">img_w</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>\n</code></pre></div><p>上例中的<code>CL_MEM_COPY_HOST_PTR</code>就是指定在创建缓存对象后，从主机端的<code>srcImage.data</code>中拷贝数据。</p><h2>启动内核函数</h2><h2>传入内核函数参数</h2><p>如下函数分别向内核传入参数：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clSetKernelArg</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">cl_mem</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">memRgbImage</span><span class=\"p\">);</span>\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clSetKernelArg</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">cl_mem</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">memGrayImage</span><span class=\"p\">);</span>\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clSetKernelArg</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">cl_mem</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">memImageHeight</span><span class=\"p\">);</span>\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clSetKernelArg</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">cl_mem</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">memImageWidth</span><span class=\"p\">);</span>\n</code></pre></div><h2>工作组与工作项排布</h2><p>OpenCL中的工作组和CUDA中的线程块相对应，工作项与CUDA中的线程相对应。</p><p>CUDA在启动内核时，需要指定线程块的大小，以及线程网格中有多少个线程块。<br/> OpenCL与之不同：OpenCL需要指定所有工作项的大小，以及每个工作组中工作项的大小。OpenCL会自动计算工作组的数量与排布。</p><p>本例采用2维排布，需要的工作项数量跟图片大小相关：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">size_t</span> <span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">};</span>   <span class=\"c1\">//工作组中工作项的排布\n</span><span class=\"c1\"></span>    <span class=\"n\">size_t</span> <span class=\"n\">globalThreads</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">{((</span><span class=\"n\">img_w</span><span class=\"o\">+</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">/</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span><span class=\"o\">*</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> \n                                <span class=\"p\">((</span><span class=\"n\">img_h</span><span class=\"o\">+</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">/</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span><span class=\"o\">*</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]};</span>   <span class=\"c1\">//整体排布\n</span></code></pre></div><p>由于使用的是NVIDIA显卡，warpSize=32，因此工作组最好为32的倍数。 注意，全局的工作项数量不能和图片尺寸保持一致。因为图片尺寸不一定能够整除32或者4，会产生错误。</p><h2>启动内核</h2><p>由于命令队列中的内核执行和主机程序是异步的，因此需要事件来进行同步：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cl_event</span> <span class=\"n\">evt</span><span class=\"p\">;</span>\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clEnqueueNDRangeKernel</span><span class=\"p\">(</span><span class=\"n\">cQ</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span>  <span class=\"c1\">//启动内核\n</span><span class=\"c1\"></span>                               <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">globalThreads</span><span class=\"p\">,</span> <span class=\"n\">localThreads</span><span class=\"p\">,</span> \n                               <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">evt</span><span class=\"p\">);</span>  <span class=\"c1\">//内核执行完成后，会将evt置为CL_SUCCESS/CL_COMPLETE\n</span><span class=\"c1\"></span>    <span class=\"n\">clWaitForEvents</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">evt</span><span class=\"p\">);</span>   <span class=\"c1\">//等待命令事件发生\n</span><span class=\"c1\"></span>    <span class=\"n\">clReleaseEvent</span><span class=\"p\">(</span><span class=\"n\">evt</span><span class=\"p\">);</span>\n</code></pre></div><h2>将结果拷贝回主机端</h2><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">error</span> <span class=\"o\">=</span><span class=\"n\">clEnqueueReadBuffer</span><span class=\"p\">(</span><span class=\"n\">cQ</span><span class=\"p\">,</span> <span class=\"n\">memGrayImage</span><span class=\"p\">,</span> \n                            <span class=\"n\">CL_TRUE</span><span class=\"p\">,</span> \n                            <span class=\"mi\">0</span><span class=\"p\">,</span> \n                            <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">uchar</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"n\">img_h</span><span class=\"o\">*</span><span class=\"n\">img_w</span><span class=\"p\">,</span> \n                            <span class=\"n\">grayImage</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>\n</code></pre></div><p>CL_TRUE可以让拷贝操作阻塞主机程序。</p><h2>后续处理</h2><p>比较简单，就是显示图片：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"s\">&#34;srcImage&#34;</span><span class=\"p\">,</span> <span class=\"n\">srcImage</span><span class=\"p\">);</span>\n    <span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"s\">&#34;grayImage&#34;</span><span class=\"p\">,</span> <span class=\"n\">grayImage</span><span class=\"p\">);</span>\n    <span class=\"n\">waitKey</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n</code></pre></div><h2>释放资源</h2><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">clReleaseMemObject</span><span class=\"p\">(</span><span class=\"n\">memRgbImage</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseMemObject</span><span class=\"p\">(</span><span class=\"n\">memGrayImage</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseMemObject</span><span class=\"p\">(</span><span class=\"n\">memImageHeight</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseMemObject</span><span class=\"p\">(</span><span class=\"n\">memImageWidth</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseKernel</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseProgram</span><span class=\"p\">(</span><span class=\"n\">program</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseCommandQueue</span><span class=\"p\">(</span><span class=\"n\">cQ</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseContext</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">);</span>\n\n    <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"n\">NUMBER_OF_FILES</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"n\">free</span><span class=\"p\">(</span><span class=\"n\">buffer</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n    <span class=\"k\">delete</span> <span class=\"o\">&amp;</span><span class=\"n\">srcImage</span><span class=\"p\">;</span>\n    <span class=\"k\">delete</span> <span class=\"o\">&amp;</span><span class=\"n\">grayImage</span><span class=\"p\">;</span>\n</code></pre></div><h2>编译程序</h2><p>没有用Cmake，因此使用如下编译指令： </p><p><code>g++ rgb2gray.cpp `pkg-config --cflags --libs opencv` -lOpenCL -o rgb2gray</code></p><h2>总结</h2><p>总的来说，OpenCL的API比CUDA麻烦一点，但程序大体思路是不变的。一些区别如下：<br/> 1. OpenCL需要在程序中调用API显式地编译内核，而CUDA只需要在.cu文件中写好内核，编译由nvcc编译器进行。 2. OpenCL有很多API像<code>clGetPlatformIDs()</code>一样，可能需要调用两次，需要习惯 3. 启动内核时，对于工作组和工作项(线程块和线程)的定义需求不一样 4. 一些名称不一样：工作项-线程、工作组-线程块、设备缓存对象-设备内存</p><h2>源代码</h2><p>rgb2gray.cpp:</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"cp\">#include</span> <span class=\"cpf\">&lt;iostream&gt;</span><span class=\"cp\">\n</span><span class=\"cp\">#include</span> <span class=\"cpf\">&lt;opencv2/opencv.hpp&gt;</span><span class=\"cp\">\n</span><span class=\"cp\">#include</span> <span class=\"cpf\">&lt;opencv2/highgui.hpp&gt;</span><span class=\"cp\">\n</span><span class=\"cp\"></span><span class=\"k\">using</span> <span class=\"k\">namespace</span> <span class=\"n\">cv</span><span class=\"p\">;</span>\n<span class=\"k\">using</span> <span class=\"k\">namespace</span> <span class=\"n\">std</span><span class=\"p\">;</span>\n\n<span class=\"cp\">#ifdef APPLE        </span><span class=\"c1\">//平台相关代码\n</span><span class=\"c1\"></span><span class=\"cp\">#include</span> <span class=\"cpf\">&lt;OpenCL/cl.h&gt;</span><span class=\"cp\">\n</span><span class=\"cp\">#else\n</span><span class=\"cp\">#include</span> <span class=\"cpf\">&lt;CL/cl.h&gt;</span><span class=\"cp\">\n</span><span class=\"cp\">#endif\n</span><span class=\"cp\"></span>\n<span class=\"c1\">//编译指令：g++ rgb2gray.cpp `pkg-config --cflags --libs opencv` -lOpenCL -o rgb2gray\n</span><span class=\"c1\"></span>\n<span class=\"kt\">void</span> <span class=\"nf\">loadProgramSource</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"kt\">char</span><span class=\"o\">**</span> <span class=\"n\">files</span><span class=\"p\">,</span>\n                       <span class=\"n\">size_t</span> <span class=\"n\">length</span><span class=\"p\">,</span>\n                       <span class=\"kt\">char</span><span class=\"o\">**</span> <span class=\"n\">buffer</span><span class=\"p\">,</span>\n                       <span class=\"n\">size_t</span><span class=\"o\">*</span> <span class=\"n\">sizes</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n       <span class=\"cm\">/* Read each source file (*.cl) and store the contents into a temporary datastore */</span>\n       <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"n\">length</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n          <span class=\"n\">FILE</span><span class=\"o\">*</span> <span class=\"n\">file</span> <span class=\"o\">=</span> <span class=\"n\">fopen</span><span class=\"p\">(</span><span class=\"n\">files</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"s\">&#34;r&#34;</span><span class=\"p\">);</span>\n          <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">file</span> <span class=\"o\">==</span> <span class=\"nb\">NULL</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n             <span class=\"n\">perror</span><span class=\"p\">(</span><span class=\"s\">&#34;Couldn&#39;t read the program file&#34;</span><span class=\"p\">);</span>\n             <span class=\"n\">exit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>   \n          <span class=\"p\">}</span>\n          <span class=\"n\">fseek</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">SEEK_END</span><span class=\"p\">);</span>\n          <span class=\"n\">sizes</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">ftell</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">);</span>\n          <span class=\"n\">rewind</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">);</span> <span class=\"c1\">// reset the file pointer so that &#39;fread&#39; reads from the front\n</span><span class=\"c1\"></span>          <span class=\"n\">buffer</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"kt\">char</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">malloc</span><span class=\"p\">(</span><span class=\"n\">sizes</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n          <span class=\"n\">buffer</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"n\">sizes</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"sc\">&#39;\\0&#39;</span><span class=\"p\">;</span>\n          <span class=\"n\">fread</span><span class=\"p\">(</span><span class=\"n\">buffer</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">char</span><span class=\"p\">),</span> <span class=\"n\">sizes</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">file</span><span class=\"p\">);</span>\n          <span class=\"n\">fclose</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">);</span>\n       <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"kt\">int</span> <span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"kt\">void</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"n\">Mat</span> <span class=\"n\">srcImage</span> <span class=\"o\">=</span> <span class=\"n\">imread</span><span class=\"p\">(</span><span class=\"s\">&#34;./test.jpg&#34;</span><span class=\"p\">);</span>\n    <span class=\"kt\">int</span> <span class=\"n\">img_h</span> <span class=\"o\">=</span> <span class=\"n\">srcImage</span><span class=\"p\">.</span><span class=\"n\">rows</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">img_w</span> <span class=\"o\">=</span> <span class=\"n\">srcImage</span><span class=\"p\">.</span><span class=\"n\">cols</span><span class=\"p\">;</span>\n    <span class=\"n\">Mat</span> <span class=\"n\">grayImage</span> <span class=\"o\">=</span> <span class=\"n\">Mat</span><span class=\"p\">(</span><span class=\"n\">img_h</span><span class=\"p\">,</span> <span class=\"n\">img_w</span><span class=\"p\">,</span> <span class=\"n\">CV_8UC1</span><span class=\"p\">,</span> <span class=\"n\">Scalar</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">));</span>  <span class=\"c1\">//创建同尺寸灰度图\n</span><span class=\"c1\"></span>\n    <span class=\"n\">cl_int</span> <span class=\"n\">error</span><span class=\"p\">;</span>\n    <span class=\"n\">cl_platform_id</span> <span class=\"n\">platform</span><span class=\"p\">;</span>\n    <span class=\"n\">cl_device_id</span> <span class=\"n\">device</span><span class=\"p\">;</span>\n    <span class=\"n\">cl_context</span> <span class=\"n\">context</span><span class=\"p\">;</span>\n    <span class=\"n\">cl_program</span> <span class=\"n\">program</span><span class=\"p\">;</span>\n    <span class=\"n\">cl_kernel</span> <span class=\"n\">kernel</span><span class=\"p\">;</span>\n    <span class=\"n\">cl_command_queue</span> <span class=\"n\">cQ</span><span class=\"p\">;</span>\n\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clGetPlatformIDs</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">platform</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>   <span class=\"c1\">//获取平台id\n</span><span class=\"c1\"></span>    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clGetDeviceIDs</span><span class=\"p\">(</span><span class=\"n\">platform</span><span class=\"p\">,</span> <span class=\"n\">CL_DEVICE_TYPE_GPU</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span> <span class=\"c1\">//获取设备id\n</span><span class=\"c1\"></span>    <span class=\"n\">context</span> <span class=\"o\">=</span> <span class=\"n\">clCreateContext</span><span class=\"p\">(</span><span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>    <span class=\"c1\">//创建上下文\n</span><span class=\"c1\"></span>    <span class=\"n\">cQ</span> <span class=\"o\">=</span> <span class=\"n\">clCreateCommandQueue</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>   <span class=\"c1\">//创建命令队列\n</span><span class=\"c1\"></span>\n    <span class=\"k\">const</span> <span class=\"kt\">char</span> <span class=\"o\">*</span><span class=\"n\">file_names</span><span class=\"p\">[]</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s\">&#34;rgb2gray.cl&#34;</span><span class=\"p\">};</span>     <span class=\"c1\">//待编译的内核文件\n</span><span class=\"c1\"></span>    <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">NUMBER_OF_FILES</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">;</span>\n    <span class=\"kt\">char</span><span class=\"o\">*</span> <span class=\"n\">buffer</span><span class=\"p\">[</span><span class=\"n\">NUMBER_OF_FILES</span><span class=\"p\">];</span>\n    <span class=\"n\">size_t</span> <span class=\"n\">sizes</span><span class=\"p\">[</span><span class=\"n\">NUMBER_OF_FILES</span><span class=\"p\">];</span>\n    <span class=\"n\">loadProgramSource</span><span class=\"p\">(</span><span class=\"n\">file_names</span><span class=\"p\">,</span> <span class=\"n\">NUMBER_OF_FILES</span><span class=\"p\">,</span> <span class=\"n\">buffer</span><span class=\"p\">,</span> <span class=\"n\">sizes</span><span class=\"p\">);</span>  <span class=\"c1\">//读取内核文件文本\n</span><span class=\"c1\"></span>    <span class=\"n\">program</span> <span class=\"o\">=</span> <span class=\"n\">clCreateProgramWithSource</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">NUMBER_OF_FILES</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"kt\">char</span><span class=\"o\">**</span><span class=\"p\">)</span><span class=\"n\">buffer</span><span class=\"p\">,</span> <span class=\"n\">sizes</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span> <span class=\"c1\">//创建program对象\n</span><span class=\"c1\"></span>    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clBuildProgram</span><span class=\"p\">(</span><span class=\"n\">program</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>  <span class=\"c1\">//编译程序\n</span><span class=\"c1\"></span>    <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">error</span> <span class=\"o\">!=</span> <span class=\"n\">CL_SUCCESS</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// If there&#39;s an error whilst building the program, dump the log\n</span><span class=\"c1\"></span>        <span class=\"n\">size_t</span> <span class=\"n\">log_size</span><span class=\"p\">;</span>\n        <span class=\"n\">clGetProgramBuildInfo</span><span class=\"p\">(</span><span class=\"n\">program</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">CL_PROGRAM_BUILD_LOG</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">log_size</span><span class=\"p\">);</span>\n        <span class=\"kt\">char</span> <span class=\"o\">*</span><span class=\"n\">program_log</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"kt\">char</span><span class=\"o\">*</span><span class=\"p\">)</span> <span class=\"n\">malloc</span><span class=\"p\">(</span><span class=\"n\">log_size</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n        <span class=\"n\">program_log</span><span class=\"p\">[</span><span class=\"n\">log_size</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"sc\">&#39;\\0&#39;</span><span class=\"p\">;</span>\n        <span class=\"n\">clGetProgramBuildInfo</span><span class=\"p\">(</span><span class=\"n\">program</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">CL_PROGRAM_BUILD_LOG</span><span class=\"p\">,</span> \n                            <span class=\"n\">log_size</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">program_log</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>\n        <span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">&#34;</span><span class=\"se\">\\n</span><span class=\"s\">=== ERROR ===</span><span class=\"se\">\\n\\n</span><span class=\"s\">%s</span><span class=\"se\">\\n</span><span class=\"s\">=============</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"n\">program_log</span><span class=\"p\">);</span>\n        <span class=\"n\">free</span><span class=\"p\">(</span><span class=\"n\">program_log</span><span class=\"p\">);</span>\n        <span class=\"n\">exit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n    <span class=\"p\">}</span>\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clCreateKernelsInProgram</span><span class=\"p\">(</span><span class=\"n\">program</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>    <span class=\"c1\">//创建内核\n</span><span class=\"c1\"></span>    <span class=\"c1\">//创建缓存对象\n</span><span class=\"c1\"></span>    <span class=\"n\">cl_mem</span> <span class=\"n\">memRgbImage</span> <span class=\"o\">=</span> <span class=\"n\">clCreateBuffer</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">CL_MEM_READ_ONLY</span> <span class=\"o\">|</span> <span class=\"n\">CL_MEM_COPY_HOST_PTR</span><span class=\"p\">,</span> \n                                    <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">uchar</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"o\">*</span><span class=\"n\">img_h</span><span class=\"o\">*</span><span class=\"n\">img_w</span><span class=\"p\">,</span> <span class=\"n\">srcImage</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>    <span class=\"c1\">//CL_MEM_COPY_HOST_PTR指定创建缓存对象后拷贝数据\n</span><span class=\"c1\"></span>    <span class=\"n\">cl_mem</span> <span class=\"n\">memGrayImage</span> <span class=\"o\">=</span> <span class=\"n\">clCreateBuffer</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">CL_MEM_WRITE_ONLY</span><span class=\"p\">,</span> \n                                    <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">uchar</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"n\">img_h</span><span class=\"o\">*</span><span class=\"n\">img_w</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>\n    <span class=\"n\">cl_mem</span> <span class=\"n\">memImageHeight</span> <span class=\"o\">=</span> <span class=\"n\">clCreateBuffer</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">CL_MEM_READ_ONLY</span><span class=\"o\">|</span> <span class=\"n\">CL_MEM_COPY_HOST_PTR</span><span class=\"p\">,</span> \n                                    <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">img_h</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>\n    <span class=\"n\">cl_mem</span> <span class=\"n\">memImageWidth</span> <span class=\"o\">=</span> <span class=\"n\">clCreateBuffer</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">CL_MEM_READ_ONLY</span><span class=\"o\">|</span> <span class=\"n\">CL_MEM_COPY_HOST_PTR</span><span class=\"p\">,</span> \n                                    <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">img_w</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">error</span><span class=\"p\">);</span>\n    <span class=\"c1\">//向内核函数传递参数\n</span><span class=\"c1\"></span>    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clSetKernelArg</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">cl_mem</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">memRgbImage</span><span class=\"p\">);</span>\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clSetKernelArg</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">cl_mem</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">memGrayImage</span><span class=\"p\">);</span>\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clSetKernelArg</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">cl_mem</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">memImageHeight</span><span class=\"p\">);</span>\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clSetKernelArg</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">cl_mem</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">memImageWidth</span><span class=\"p\">);</span>\n\n    <span class=\"n\">size_t</span> <span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">};</span>   <span class=\"c1\">//工作组中工作项的排布\n</span><span class=\"c1\"></span>    <span class=\"n\">size_t</span> <span class=\"n\">globalThreads</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">{((</span><span class=\"n\">img_w</span><span class=\"o\">+</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">/</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span><span class=\"o\">*</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> \n                                <span class=\"p\">((</span><span class=\"n\">img_h</span><span class=\"o\">+</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">/</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span><span class=\"o\">*</span><span class=\"n\">localThreads</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]};</span>   <span class=\"c1\">//整体排布\n</span><span class=\"c1\"></span>\n    <span class=\"n\">cl_event</span> <span class=\"n\">evt</span><span class=\"p\">;</span>\n    <span class=\"n\">error</span> <span class=\"o\">=</span> <span class=\"n\">clEnqueueNDRangeKernel</span><span class=\"p\">(</span><span class=\"n\">cQ</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"p\">,</span>  <span class=\"c1\">//启动内核\n</span><span class=\"c1\"></span>                               <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">globalThreads</span><span class=\"p\">,</span> <span class=\"n\">localThreads</span><span class=\"p\">,</span> \n                               <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">evt</span><span class=\"p\">);</span>  <span class=\"c1\">//内核执行完成后，会将evt置为CL_SUCCESS/CL_COMPLETE\n</span><span class=\"c1\"></span>    <span class=\"n\">clWaitForEvents</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">evt</span><span class=\"p\">);</span>   <span class=\"c1\">//等待命令事件发生\n</span><span class=\"c1\"></span>    <span class=\"n\">clReleaseEvent</span><span class=\"p\">(</span><span class=\"n\">evt</span><span class=\"p\">);</span>\n    <span class=\"c1\">//读回数据\n</span><span class=\"c1\"></span>    <span class=\"n\">error</span> <span class=\"o\">=</span><span class=\"n\">clEnqueueReadBuffer</span><span class=\"p\">(</span><span class=\"n\">cQ</span><span class=\"p\">,</span> <span class=\"n\">memGrayImage</span><span class=\"p\">,</span> \n                            <span class=\"n\">CL_TRUE</span><span class=\"p\">,</span> \n                            <span class=\"mi\">0</span><span class=\"p\">,</span> \n                            <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">uchar</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"n\">img_h</span><span class=\"o\">*</span><span class=\"n\">img_w</span><span class=\"p\">,</span> \n                            <span class=\"n\">grayImage</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>\n\n    <span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"s\">&#34;srcImage&#34;</span><span class=\"p\">,</span> <span class=\"n\">srcImage</span><span class=\"p\">);</span>\n    <span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"s\">&#34;grayImage&#34;</span><span class=\"p\">,</span> <span class=\"n\">grayImage</span><span class=\"p\">);</span>\n    <span class=\"n\">waitKey</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n    <span class=\"c1\">//释放资源\n</span><span class=\"c1\"></span>    <span class=\"n\">clReleaseMemObject</span><span class=\"p\">(</span><span class=\"n\">memRgbImage</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseMemObject</span><span class=\"p\">(</span><span class=\"n\">memGrayImage</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseMemObject</span><span class=\"p\">(</span><span class=\"n\">memImageHeight</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseMemObject</span><span class=\"p\">(</span><span class=\"n\">memImageWidth</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseKernel</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseProgram</span><span class=\"p\">(</span><span class=\"n\">program</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseCommandQueue</span><span class=\"p\">(</span><span class=\"n\">cQ</span><span class=\"p\">);</span>\n    <span class=\"n\">clReleaseContext</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">);</span>\n\n    <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"n\">NUMBER_OF_FILES</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"n\">free</span><span class=\"p\">(</span><span class=\"n\">buffer</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n    <span class=\"k\">delete</span> <span class=\"o\">&amp;</span><span class=\"n\">srcImage</span><span class=\"p\">;</span>\n    <span class=\"k\">delete</span> <span class=\"o\">&amp;</span><span class=\"n\">grayImage</span><span class=\"p\">;</span>\n\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>rgb2gray.cl:</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">__kernel</span> <span class=\"kt\">void</span> <span class=\"nf\">kernel_rgb2gray</span><span class=\"p\">(</span><span class=\"n\">__global</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"o\">*</span> <span class=\"n\">rgbImage</span><span class=\"p\">,</span> \n                              <span class=\"n\">__global</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"o\">*</span> <span class=\"n\">grayImage</span><span class=\"p\">,</span> \n                              <span class=\"n\">__global</span> <span class=\"kt\">unsigned</span> <span class=\"o\">*</span> <span class=\"k\">const</span> <span class=\"n\">p_height</span><span class=\"p\">,</span> \n                              <span class=\"n\">__global</span> <span class=\"kt\">unsigned</span> <span class=\"o\">*</span> <span class=\"k\">const</span> <span class=\"n\">p_width</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"kt\">int</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">get_global_id</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n    <span class=\"kt\">int</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">get_global_id</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n    <span class=\"kt\">int</span> <span class=\"n\">height</span> <span class=\"o\">=</span> <span class=\"o\">*</span><span class=\"n\">p_height</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">width</span> <span class=\"o\">=</span> <span class=\"o\">*</span><span class=\"n\">p_width</span><span class=\"p\">;</span>\n    <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">&lt;</span> <span class=\"n\">width</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">y</span> <span class=\"o\">&lt;</span> <span class=\"n\">height</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"kt\">int</span> <span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">y</span> <span class=\"o\">*</span> <span class=\"n\">width</span> <span class=\"o\">+</span> <span class=\"n\">x</span><span class=\"p\">;</span>\n        <span class=\"n\">grayImage</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.299f</span><span class=\"o\">*</span><span class=\"n\">rgbImage</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">+</span> \n                            <span class=\"mf\">0.587f</span><span class=\"o\">*</span><span class=\"n\">rgbImage</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> \n                            <span class=\"mf\">0.114f</span><span class=\"o\">*</span><span class=\"n\">rgbImage</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"o\">+</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div><p></p>", 
            "topic": [
                {
                    "tag": "OpenCL", 
                    "tagLink": "https://api.zhihu.com/topics/19562757"
                }, 
                {
                    "tag": "GPU 通用计算", 
                    "tagLink": "https://api.zhihu.com/topics/19570902"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "朝歌", 
                    "userLink": "https://www.zhihu.com/people/65742ac72aa0b0e41549cfd25060d0bb", 
                    "content": "<p>写的真挺好，赞一个</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "向前涌", 
                    "userLink": "https://www.zhihu.com/people/5ddc31e67bf34b40ee90368ff39f550d", 
                    "content": "<p>opencl是不是已经死了？</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/71881443", 
            "userName": "田子宸", 
            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
            "upvote": 76, 
            "title": "NCNN Conv量化详解（一）", 
            "content": "<h2>0、前言</h2><p>今天看了一篇量化的好文章：<a href=\"https://zhuanlan.zhihu.com/p/58182172\" class=\"internal\">Int8量化-介绍（一）</a>，用很有趣的语言讲解了量化的原理及讲解了一下NVIDIA和NCNN的实现方式。突然有点手痒痒，正好趁着工作上有空闲，详细看了看NCNN关于Conv量化的实现，特整理在此，内容包括：</p><ul><li>NCNN的conv量化计算流程</li><li>NCNN量化与反量化方法</li><li>NCNN的requantize</li></ul><h2>1、 NCNN的Conv量化计算流程</h2><p>正常的fp32计算中，一个Conv的计算流程如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7a5aa30d1d5e677de9389e8254d69b99_b.jpg\" data-size=\"normal\" data-rawwidth=\"951\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb\" width=\"951\" data-original=\"https://pic2.zhimg.com/v2-7a5aa30d1d5e677de9389e8254d69b99_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;951&#39; height=&#39;369&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"951\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"951\" data-original=\"https://pic2.zhimg.com/v2-7a5aa30d1d5e677de9389e8254d69b99_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7a5aa30d1d5e677de9389e8254d69b99_b.jpg\"/><figcaption>fp32 Conv计算流程，有时可不加bias</figcaption></figure><p>所有的数据类型均为fp32，没有什么特别的</p><p class=\"ztext-empty-paragraph\"><br/></p><p>在NCNN Conv进行Int8计算时，计算流程如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f8def9df29ec378bae3831d9fece2656_b.jpg\" data-size=\"normal\" data-rawwidth=\"1388\" data-rawheight=\"397\" class=\"origin_image zh-lightbox-thumb\" width=\"1388\" data-original=\"https://pic3.zhimg.com/v2-f8def9df29ec378bae3831d9fece2656_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1388&#39; height=&#39;397&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1388\" data-rawheight=\"397\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1388\" data-original=\"https://pic3.zhimg.com/v2-f8def9df29ec378bae3831d9fece2656_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f8def9df29ec378bae3831d9fece2656_b.jpg\"/><figcaption>int8 Conv计算流程，在进行conv前，对input和weight做量化，计算完后反量化到fp32,再加bias</figcaption></figure><p>NCNN首先将输入(bottom_blob)和权重(weight_blob)量化成INT8，在INT8下计算卷积，然后反量化到fp32，再和未量化的bias相加，得到输出(top_blob)</p><p class=\"ztext-empty-paragraph\"><br/></p><p>输入和权重的量化公式：</p><p><img src=\"https://www.zhihu.com/equation?tex=bottom%5C_blob%28int8%29+%3D+bottom%5C_blob%5C_int8%5C_scale+%2A+bottom%5C_blob%28fp32%29\" alt=\"bottom\\_blob(int8) = bottom\\_blob\\_int8\\_scale * bottom\\_blob(fp32)\" eeimg=\"1\"/> <img src=\"https://www.zhihu.com/equation?tex=weight%5C_blob%28int8%29+%3D+weight%5C_data%5C_int8%5C_scale+%2A+weight%5C_blob%28fp32%29\" alt=\"weight\\_blob(int8) = weight\\_data\\_int8\\_scale * weight\\_blob(fp32)\" eeimg=\"1\"/> </p><p>反量化的目的是将int8映射回原来的fp32，范围要保持一致；由于weight_blob(int8)和bottom_blob(int8)是相乘的：</p><p><img src=\"https://www.zhihu.com/equation?tex=inner%5C_blob%28int32%29+%3D+%28bottom%5C_blob%5C_int8%5C_scale%2Aweight%5C_data%5C_int8%5C_scale%29%2A%28bottom%5C_blob%28fp32%29%2Aweight%5C_blob%28fp32%29%29\" alt=\"inner\\_blob(int32) = (bottom\\_blob\\_int8\\_scale*weight\\_data\\_int8\\_scale)*(bottom\\_blob(fp32)*weight\\_blob(fp32))\" eeimg=\"1\"/> </p><p>所以为了实现一个反映射，量化反量化的scale应该为：</p><p><img src=\"https://www.zhihu.com/equation?tex=dequantize%5C_scale%3D1%2F%28bottom%5C_blob%5C_int8%5C_scale%2Aweight%5C_data%5C_int8%5C_scale%29\" alt=\"dequantize\\_scale=1/(bottom\\_blob\\_int8\\_scale*weight\\_data\\_int8\\_scale)\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=inner%5C_blob%28fp32%29%3Ddequantize%5C_scale%2Ainner%5C_blob%28int32%29\" alt=\"inner\\_blob(fp32)=dequantize\\_scale*inner\\_blob(int32)\" eeimg=\"1\"/> </p><p class=\"ztext-empty-paragraph\"><br/></p><p>NCNN并没有对bias做量化。</p><p>另外值得一提的是，由于权重不会变，权重是在网络初始化时量化的；而输入由于会变化，是在线量化的。</p><h3>代码实现</h3><p>下面我们从代码里看一下NCNN的Conv是如何执行这一过程的，这里只分析convolution.cpp，convolution_arm.cpp/convolution_x86.cpp的实现和这里类似。</p><h3>(1) int8开关</h3><p>首先在Convolution::load_param()中，会从.param文件里读是否使用int8：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"n\">Convolution</span><span class=\"o\">::</span><span class=\"n\">load_param</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"n\">ParamDict</span><span class=\"o\">&amp;</span> <span class=\"n\">pd</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n    <span class=\"n\">int8_scale_term</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">);</span>     <span class=\"c1\">// int8开关\n</span><span class=\"c1\"></span>    <span class=\"p\">...</span>\n\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>一旦int8_scale_term = true，则会从.bin文件中读取scale的值：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"n\">Convolution</span><span class=\"o\">::</span><span class=\"n\">load_model</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"n\">ModelBin</span><span class=\"o\">&amp;</span> <span class=\"n\">mb</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">int8_scale_term</span><span class=\"p\">)</span>    <span class=\"c1\">// 一旦从.param文件中读到了int_scale_term，就可以从.bin文件中读到scale值\n</span><span class=\"c1\"></span>    <span class=\"p\">{</span>\n        <span class=\"n\">weight_data_int8_scales</span> <span class=\"o\">=</span> <span class=\"n\">mb</span><span class=\"p\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">num_output</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">);</span>\n        <span class=\"n\">bottom_blob_int8_scale</span> <span class=\"o\">=</span> <span class=\"n\">mb</span><span class=\"p\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">];</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>否则，在create_pipeline函数中，会强制关闭int8模式</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"n\">Convolution</span><span class=\"o\">::</span><span class=\"n\">create_pipeline</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"n\">Option</span><span class=\"o\">&amp;</span> <span class=\"n\">opt</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"n\">Option</span> <span class=\"n\">opt_cpu</span> <span class=\"o\">=</span> <span class=\"n\">opt</span><span class=\"p\">;</span>\n    <span class=\"n\">opt_cpu</span><span class=\"p\">.</span><span class=\"n\">use_vulkan_compute</span> <span class=\"o\">=</span> <span class=\"nb\">false</span><span class=\"p\">;</span>\n\n    <span class=\"n\">use_int8_inference</span> <span class=\"o\">=</span> <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">use_int8_inference</span><span class=\"p\">;</span>    <span class=\"c1\">// opt里面的配置决定是否打开int8\n</span><span class=\"c1\"></span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">int8_scale_term</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">)</span>   <span class=\"c1\">// 但如果.param文件中说这个层不能用int8,则强制关闭\n</span><span class=\"c1\"></span>        <span class=\"n\">use_int8_inference</span> <span class=\"o\">=</span> <span class=\"nb\">false</span><span class=\"p\">;</span>\n    <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>opt则是在创建net对象时指定的：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"cm\">/* 用户自定义文件 */</span>\n<span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Net</span> <span class=\"n\">example_net</span><span class=\"p\">;</span>\n<span class=\"n\">example_net</span><span class=\"p\">.</span><span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">use_int8_inference</span> <span class=\"o\">=</span> <span class=\"nb\">true</span><span class=\"p\">;</span>  <span class=\"c1\">// 该opt会在net.load_model里传给每一个layer\n</span><span class=\"c1\"></span>\n<span class=\"cm\">/* net.cpp */</span>\n<span class=\"kt\">int</span> <span class=\"n\">Net</span><span class=\"o\">::</span><span class=\"n\">load_model</span><span class=\"p\">(</span><span class=\"n\">FILE</span><span class=\"o\">*</span> <span class=\"n\">fp</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n        <span class=\"kt\">int</span> <span class=\"n\">cret</span> <span class=\"o\">=</span> <span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">create_pipeline</span><span class=\"p\">(</span><span class=\"n\">opt</span><span class=\"p\">);</span> <span class=\"c1\">// use_int8_inference是从这里传给每个层的\n</span><span class=\"c1\"></span>        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">cret</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span> <span class=\"s\">&#34;layer create_pipeline %d failed</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"p\">)</span><span class=\"n\">i</span><span class=\"p\">);</span>\n            <span class=\"n\">ret</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">;</span>\n            <span class=\"k\">break</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div><h3>（2） 权重量化</h3><p>上面提到过，权重是离线量化的，在Convolution::create_pipeline()里实现：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"n\">Convolution</span><span class=\"o\">::</span><span class=\"n\">create_pipeline</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"n\">Option</span><span class=\"o\">&amp;</span> <span class=\"n\">opt</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n\n    <span class=\"c1\">// runtime quantize the weight data\n</span><span class=\"c1\"></span>    <span class=\"c1\">// 创建Conv Layer时，一次性将权重量化好\n</span><span class=\"c1\"></span>    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">weight_data_is_float32</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">use_int8_inference</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"c1\">// quantize weight to int8\n</span><span class=\"c1\"></span>        <span class=\"n\">Mat</span> <span class=\"n\">int8_weight_data</span><span class=\"p\">(</span><span class=\"n\">weight_data_size</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">size_t</span><span class=\"p\">)</span><span class=\"mi\">1u</span><span class=\"p\">);</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">int8_weight_data</span><span class=\"p\">.</span><span class=\"n\">empty</span><span class=\"p\">())</span>\n            <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"mi\">100</span><span class=\"p\">;</span>\n\n        <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">weight_data_size_output</span> <span class=\"o\">=</span> <span class=\"n\">weight_data_size</span> <span class=\"o\">/</span> <span class=\"n\">num_output</span><span class=\"p\">;</span>\n\n        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">n</span><span class=\"o\">&lt;</span><span class=\"n\">num_output</span><span class=\"p\">;</span> <span class=\"n\">n</span><span class=\"o\">++</span><span class=\"p\">)</span>    <span class=\"c1\">// 每个kernel单独量化\n</span><span class=\"c1\"></span>        <span class=\"p\">{</span>\n            <span class=\"n\">Layer</span><span class=\"o\">*</span> <span class=\"n\">op</span> <span class=\"o\">=</span> <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">create_layer</span><span class=\"p\">(</span><span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">LayerType</span><span class=\"o\">::</span><span class=\"n\">Quantize</span><span class=\"p\">);</span>\n\n            <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">ParamDict</span> <span class=\"n\">pd</span><span class=\"p\">;</span>\n            <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">set</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">weight_data_int8_scales</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]);</span><span class=\"c1\">// 设置scale参数\n</span><span class=\"c1\"></span>\n            <span class=\"n\">op</span><span class=\"o\">-&gt;</span><span class=\"n\">load_param</span><span class=\"p\">(</span><span class=\"n\">pd</span><span class=\"p\">);</span>\n\n            <span class=\"n\">op</span><span class=\"o\">-&gt;</span><span class=\"n\">create_pipeline</span><span class=\"p\">(</span><span class=\"n\">opt_cpu</span><span class=\"p\">);</span>\n\n            <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Option</span> <span class=\"n\">opt</span><span class=\"p\">;</span>\n            <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">blob_allocator</span> <span class=\"o\">=</span> <span class=\"n\">int8_weight_data</span><span class=\"p\">.</span><span class=\"n\">allocator</span><span class=\"p\">;</span>\n            <span class=\"c1\">// 拆开计算后组合\n</span><span class=\"c1\"></span>            <span class=\"k\">const</span> <span class=\"n\">Mat</span> <span class=\"n\">weight_data_n</span> <span class=\"o\">=</span> <span class=\"n\">weight_data</span><span class=\"p\">.</span><span class=\"n\">range</span><span class=\"p\">(</span><span class=\"n\">weight_data_size_output</span> <span class=\"o\">*</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">weight_data_size_output</span><span class=\"p\">);</span>\n            <span class=\"n\">Mat</span> <span class=\"n\">int8_weight_data_n</span> <span class=\"o\">=</span> <span class=\"n\">int8_weight_data</span><span class=\"p\">.</span><span class=\"n\">range</span><span class=\"p\">(</span><span class=\"n\">weight_data_size_output</span> <span class=\"o\">*</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">weight_data_size_output</span><span class=\"p\">);</span>\n            <span class=\"n\">op</span><span class=\"o\">-&gt;</span><span class=\"n\">forward</span><span class=\"p\">(</span><span class=\"n\">weight_data_n</span><span class=\"p\">,</span> <span class=\"n\">int8_weight_data_n</span><span class=\"p\">,</span> <span class=\"n\">opt</span><span class=\"p\">);</span>    <span class=\"c1\">// 计算量化值\n</span><span class=\"c1\"></span>\n            <span class=\"k\">delete</span> <span class=\"n\">op</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"n\">weight_data</span> <span class=\"o\">=</span> <span class=\"n\">int8_weight_data</span><span class=\"p\">;</span> <span class=\"c1\">// 替代原来的weight_data\n</span><span class=\"c1\"></span>    <span class=\"p\">}</span>\n\n    <span class=\"c1\">// initial the quantize,dequantize op layer\n</span><span class=\"c1\"></span>    <span class=\"c1\">// 初始化输入/输出的量化/反量化Op\n</span><span class=\"c1\"></span>    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">use_int8_inference</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"c1\">// 创建量化Op，不run\n</span><span class=\"c1\"></span>        <span class=\"n\">quantize</span> <span class=\"o\">=</span> <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">create_layer</span><span class=\"p\">(</span><span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">LayerType</span><span class=\"o\">::</span><span class=\"n\">Quantize</span><span class=\"p\">);</span>\n        <span class=\"p\">{</span>\n            <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">ParamDict</span> <span class=\"n\">pd</span><span class=\"p\">;</span>\n            <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">set</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">bottom_blob_int8_scale</span><span class=\"p\">);</span><span class=\"c1\">// 所有输入用同一个scale\n</span><span class=\"c1\"></span>\n            <span class=\"n\">quantize</span><span class=\"o\">-&gt;</span><span class=\"n\">load_param</span><span class=\"p\">(</span><span class=\"n\">pd</span><span class=\"p\">);</span>\n\n            <span class=\"n\">quantize</span><span class=\"o\">-&gt;</span><span class=\"n\">create_pipeline</span><span class=\"p\">(</span><span class=\"n\">opt_cpu</span><span class=\"p\">);</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"c1\">// 创建反量化Op，不Run\n</span><span class=\"c1\"></span>        <span class=\"n\">dequantize_ops</span><span class=\"p\">.</span><span class=\"n\">resize</span><span class=\"p\">(</span><span class=\"n\">num_output</span><span class=\"p\">);</span>  <span class=\"c1\">// 由于不同kernel weight的scale是不同的\n</span><span class=\"c1\"></span>        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">n</span><span class=\"o\">&lt;</span><span class=\"n\">num_output</span><span class=\"p\">;</span> <span class=\"n\">n</span><span class=\"o\">++</span><span class=\"p\">)</span>    <span class=\"c1\">// 因此反量化scale也是不同的\n</span><span class=\"c1\"></span>        <span class=\"p\">{</span>\n            <span class=\"n\">dequantize_ops</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">create_layer</span><span class=\"p\">(</span><span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">LayerType</span><span class=\"o\">::</span><span class=\"n\">Dequantize</span><span class=\"p\">);</span>\n\n            <span class=\"kt\">float</span> <span class=\"n\">top_rescale</span> <span class=\"o\">=</span> <span class=\"mf\">1.f</span><span class=\"p\">;</span>\n\n            <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">weight_data_int8_scales</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n                <span class=\"n\">top_rescale</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n            <span class=\"k\">else</span>    <span class=\"c1\">// 反量化scale=1/(输入scale*权重scale)，即一个反映射\n</span><span class=\"c1\"></span>                <span class=\"n\">top_rescale</span> <span class=\"o\">=</span> <span class=\"mf\">1.f</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">bottom_blob_int8_scale</span> <span class=\"o\">*</span> <span class=\"n\">weight_data_int8_scales</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]);</span>\n\n            <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">ParamDict</span> <span class=\"n\">pd</span><span class=\"p\">;</span>\n            <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">set</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">top_rescale</span><span class=\"p\">);</span><span class=\"c1\">// scale\n</span><span class=\"c1\"></span>            <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">set</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">bias_term</span><span class=\"p\">);</span>  <span class=\"c1\">// bias_term\n</span><span class=\"c1\"></span>            <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">set</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">);</span>          <span class=\"c1\">// bias_data_size\n</span><span class=\"c1\"></span>\n            <span class=\"n\">dequantize_ops</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]</span><span class=\"o\">-&gt;</span><span class=\"n\">load_param</span><span class=\"p\">(</span><span class=\"n\">pd</span><span class=\"p\">);</span>\n\n            <span class=\"n\">dequantize_ops</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]</span><span class=\"o\">-&gt;</span><span class=\"n\">create_pipeline</span><span class=\"p\">(</span><span class=\"n\">opt_cpu</span><span class=\"p\">);</span>\n\n            <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">weights</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">];</span>\n            <span class=\"n\">weights</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">bias_data</span><span class=\"p\">.</span><span class=\"n\">range</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">);</span>\n\n            <span class=\"n\">dequantize_ops</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]</span><span class=\"o\">-&gt;</span><span class=\"n\">load_model</span><span class=\"p\">(</span><span class=\"n\">ModelBinFromMatArray</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"p\">));</span>\n\n            <span class=\"n\">dequantize_scales</span><span class=\"p\">.</span><span class=\"n\">push_back</span><span class=\"p\">(</span><span class=\"n\">top_rescale</span><span class=\"p\">);</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>可以看到，NCNN的实现很简单：创建int8 Mat-&gt;创建量化op-&gt;执行op-&gt;组合替换Mat</p><p>值得注意的是，权重里每个kernel有不同的scale参数</p><h3>（3） 输入/输出 的 量化/反量化</h3><p>上一个代码段的后半部分就是输入输出的量化反量化初始化代码</p><p>input_blob使用同一个scale进行量化；由于权重每个kernel的scale不同，输出反量化的scale也是不同的，每个output_channel有独立的scale参数</p><p>这里只是对quantize/dequantize做了初始化，真正run的代码在Convolution::forward()下：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"n\">Convolution</span><span class=\"o\">::</span><span class=\"n\">forward</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"n\">Mat</span><span class=\"o\">&amp;</span> <span class=\"n\">bottom_blob</span><span class=\"p\">,</span> <span class=\"n\">Mat</span><span class=\"o\">&amp;</span> <span class=\"n\">top_blob</span><span class=\"p\">,</span> <span class=\"k\">const</span> <span class=\"n\">Option</span><span class=\"o\">&amp;</span> <span class=\"n\">opt</span><span class=\"p\">)</span> <span class=\"k\">const</span>\n<span class=\"p\">{</span>\n\n    <span class=\"p\">...</span>\n    <span class=\"c1\">// 量化相关代码\n</span><span class=\"c1\"></span>    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">use_int8_inference</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">elemsize</span> <span class=\"o\">!=</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"n\">Mat</span> <span class=\"n\">bottom_blob_int8</span><span class=\"p\">;</span>\n        <span class=\"n\">bottom_blob_int8</span><span class=\"p\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"n\">h</span><span class=\"p\">,</span> <span class=\"n\">channels</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">size_t</span><span class=\"p\">)</span><span class=\"mi\">1u</span><span class=\"p\">,</span> <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">workspace_allocator</span><span class=\"p\">);</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">bottom_blob_int8</span><span class=\"p\">.</span><span class=\"n\">empty</span><span class=\"p\">())</span>\n            <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"mi\">100</span><span class=\"p\">;</span>\n\n        <span class=\"c1\">// quantize, scale and round to nearest\n</span><span class=\"c1\"></span>        <span class=\"p\">{</span>\n            <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Option</span> <span class=\"n\">opt_g</span> <span class=\"o\">=</span> <span class=\"n\">opt</span><span class=\"p\">;</span>\n            <span class=\"n\">opt_g</span><span class=\"p\">.</span><span class=\"n\">blob_allocator</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob_int8</span><span class=\"p\">.</span><span class=\"n\">allocator</span><span class=\"p\">;</span>  <span class=\"c1\">// 分配内存，int8\n</span><span class=\"c1\"></span>\n            <span class=\"n\">quantize</span><span class=\"o\">-&gt;</span><span class=\"n\">forward</span><span class=\"p\">(</span><span class=\"n\">bottom_blob</span><span class=\"p\">,</span> <span class=\"n\">bottom_blob_int8</span><span class=\"p\">,</span> <span class=\"n\">opt_g</span><span class=\"p\">);</span>    <span class=\"c1\">// 量化计算\n</span><span class=\"c1\"></span>        <span class=\"p\">}</span>\n\n        <span class=\"n\">bottom_blob_unbordered</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob_int8</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">...</span>\n\n    <span class=\"c1\">// int8\n</span><span class=\"c1\"></span>    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">use_int8_inference</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">use_int8_requantize</span> <span class=\"o\">==</span> <span class=\"nb\">true</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n              <span class=\"p\">...</span>   <span class=\"c1\">// 使用了requantize，一会讲\n</span><span class=\"c1\"></span>        <span class=\"p\">}</span>\n        <span class=\"k\">else</span>\n        <span class=\"p\">{</span>\n              <span class=\"n\">top_blob</span><span class=\"p\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"n\">outw</span><span class=\"p\">,</span> <span class=\"n\">outh</span><span class=\"p\">,</span> <span class=\"n\">num_output</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">size_t</span><span class=\"p\">)</span><span class=\"mi\">4u</span><span class=\"p\">,</span> <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">blob_allocator</span><span class=\"p\">);</span>  <span class=\"c1\">// 输出为int32\n</span><span class=\"c1\"></span>              <span class=\"c1\">// 量化卷积计算  \n</span><span class=\"c1\"></span>              <span class=\"p\">...</span>\n              <span class=\"c1\">// dequantize, reverse scale inplace\n</span><span class=\"c1\"></span>              <span class=\"p\">{</span>\n                  <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Option</span> <span class=\"n\">opt_g</span> <span class=\"o\">=</span> <span class=\"n\">opt</span><span class=\"p\">;</span>\n                  <span class=\"n\">opt_g</span><span class=\"p\">.</span><span class=\"n\">num_threads</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">;</span>\n                  <span class=\"n\">opt_g</span><span class=\"p\">.</span><span class=\"n\">blob_allocator</span> <span class=\"o\">=</span> <span class=\"n\">top_blob</span><span class=\"p\">.</span><span class=\"n\">allocator</span><span class=\"p\">;</span>\n\n                  <span class=\"n\">Mat</span> <span class=\"n\">top_blob_g</span> <span class=\"o\">=</span> <span class=\"n\">top_blob</span><span class=\"p\">.</span><span class=\"n\">channel_range</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">);</span>\n                  <span class=\"n\">dequantize_ops</span><span class=\"p\">[</span><span class=\"n\">p</span><span class=\"p\">]</span><span class=\"o\">-&gt;</span><span class=\"n\">forward_inplace</span><span class=\"p\">(</span><span class=\"n\">top_blob_g</span><span class=\"p\">,</span> <span class=\"n\">opt_g</span><span class=\"p\">);</span>  <span class=\"c1\">// 反量化计算，inplace\n</span><span class=\"c1\"></span>              <span class=\"p\">}</span>   \n        <span class=\"p\">}</span>\n        \n        <span class=\"p\">...</span>   \n        <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n\n<span class=\"p\">}</span>\n</code></pre></div><p>在Convolution每次forward时，先调用quantize-&gt;forward对输入进行量化，存在int8的blob中，然后运行量化卷积计算，将结果存在int32的blob里，然后调用dequantize将int32转为float32</p><p>由于int32和float32位数一样，NCNN这里转成float32后，直接覆盖了int32的数据</p><h2>2、 NCNN的量化反量化方法</h2><p>NCNN的量化/反量化是以Op的形式调用的，其实现分别在quantize.cpp/dequantize.cpp中</p><h3>quantize</h3><p>量化的实现非常简单，就是所有数据乘以scale，然后截断成int8：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"n\">Quantize</span><span class=\"o\">::</span><span class=\"n\">forward</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"n\">Mat</span><span class=\"o\">&amp;</span> <span class=\"n\">bottom_blob</span><span class=\"p\">,</span> <span class=\"n\">Mat</span><span class=\"o\">&amp;</span> <span class=\"n\">top_blob</span><span class=\"p\">,</span> <span class=\"k\">const</span> <span class=\"n\">Option</span><span class=\"o\">&amp;</span> <span class=\"n\">opt</span><span class=\"p\">)</span> <span class=\"k\">const</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n    <span class=\"err\">遍历所有数据：</span>\n        <span class=\"n\">outptr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">float2int8</span><span class=\"p\">(</span><span class=\"n\">ptr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">scale</span><span class=\"p\">);</span>\n\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">static</span> <span class=\"kr\">inline</span> <span class=\"kt\">signed</span> <span class=\"kt\">char</span> <span class=\"n\">float2int8</span><span class=\"p\">(</span><span class=\"kt\">float</span> <span class=\"n\">v</span><span class=\"p\">)</span>   <span class=\"c1\">// 截断成int8\n</span><span class=\"c1\"></span><span class=\"p\">{</span>\n    <span class=\"kt\">int</span> <span class=\"n\">int32</span> <span class=\"o\">=</span> <span class=\"n\">round</span><span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">int32</span> <span class=\"o\">&gt;</span> <span class=\"mi\">127</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"mi\">127</span><span class=\"p\">;</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">int32</span> <span class=\"o\">&lt;</span> <span class=\"o\">-</span><span class=\"mi\">128</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"mi\">128</span><span class=\"p\">;</span>\n    <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"kt\">signed</span> <span class=\"kt\">char</span><span class=\"p\">)</span><span class=\"n\">int32</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><h3>dequantize</h3><p>反量化的实现也非常简单，乘scale加bias即可</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"n\">Dequantize</span><span class=\"o\">::</span><span class=\"n\">forward_inplace</span><span class=\"p\">(</span><span class=\"n\">Mat</span><span class=\"o\">&amp;</span> <span class=\"n\">bottom_top_blob</span><span class=\"p\">,</span> <span class=\"k\">const</span> <span class=\"n\">Option</span><span class=\"o\">&amp;</span> <span class=\"n\">opt</span><span class=\"p\">)</span> <span class=\"k\">const</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">bias_term</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n                <span class=\"p\">...</span>\n                <span class=\"err\">遍历所有数据：</span>\n                    <span class=\"n\">ptr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">intptr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">scale</span> <span class=\"o\">+</span> <span class=\"n\">bias</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n        <span class=\"k\">else</span>\n        <span class=\"p\">{</span>\n                <span class=\"p\">...</span>\n                <span class=\"err\">遍历所有数据</span>\n                    <span class=\"n\">ptr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">intptr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">scale</span><span class=\"p\">;</span>      \n        <span class=\"p\">}</span>\n\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><h2>3、 NCNN的requantize</h2><p>当一个Conv1后面紧跟着另一个Conv2时，NCNN会进行requantize的操作。大致意思就是在得到Conv1的INT32输出后，会顺手帮Conv2做量化，得到Conv2的INT8输入。这中间不会输出fp32的blob，节省一次内存读写</p><p>具体流程如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e7336fdc3e9c47e49ef550fe3b86e8f5_b.jpg\" data-size=\"normal\" data-rawwidth=\"1141\" data-rawheight=\"486\" class=\"origin_image zh-lightbox-thumb\" width=\"1141\" data-original=\"https://pic2.zhimg.com/v2-e7336fdc3e9c47e49ef550fe3b86e8f5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1141&#39; height=&#39;486&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1141\" data-rawheight=\"486\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1141\" data-original=\"https://pic2.zhimg.com/v2-e7336fdc3e9c47e49ef550fe3b86e8f5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e7336fdc3e9c47e49ef550fe3b86e8f5_b.jpg\"/><figcaption>requantize相当于替换了原来的dequantize+add_bias+下一层的quantize</figcaption></figure><p>原来的流程中（上图），第一个Conv计算完int32后，会使用scale=1/(s1*s2)进行反量化，然后加上bias，得到fp32的输出。之后再在下一层使用s3进行量化。</p><p>而requantize将反量化、加bias、量化的过程合起来，直接得到下一层Conv的int8输入，可以节省一次fp32数据的读写。</p><p>我们来看一下NCNN requantize的代码实现</p><h3>代码实现</h3><h3>（1）什么时候会进行requantitize？</h3><p>这在net.cpp中写的很明确，我们看一下Net::fuse_network()函数：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">bool</span> <span class=\"n\">net_quantized</span> <span class=\"o\">=</span> <span class=\"nb\">false</span><span class=\"p\">;</span>\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">layers</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"n\">Layer</span><span class=\"o\">*</span> <span class=\"n\">layer</span> <span class=\"o\">=</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;Convolution&#34;</span> <span class=\"o\">||</span> <span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;ConvolutionDepthWise&#34;</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;Convolution&#34;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"p\">(((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">use_int8_inference</span> <span class=\"o\">==</span> <span class=\"nb\">false</span><span class=\"p\">))</span>\n                <span class=\"k\">continue</span><span class=\"p\">;</span>\n            <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;ConvolutionDepthWise&#34;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"p\">(((</span><span class=\"n\">ConvolutionDepthWise</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">use_int8_inference</span> <span class=\"o\">==</span> <span class=\"nb\">false</span><span class=\"p\">))</span>\n                <span class=\"k\">continue</span><span class=\"p\">;</span>    \n            <span class=\"n\">net_quantized</span> <span class=\"o\">=</span> <span class=\"nb\">true</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">net_quantized</span> <span class=\"o\">==</span> <span class=\"nb\">false</span><span class=\"p\">)</span>   <span class=\"c1\">// 如果没有量化相关的层，直接return\n</span><span class=\"c1\"></span>        <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n</code></pre></div><p>第一段代码用来检测网络中是否有量化相关的层，如果没有的话，直接return，没有可fuse的操作</p><p>接下来的代码用来判断Conv是否需要使用requantize，代码比较长，先用伪码阐述逻辑：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"err\">遍历</span><span class=\"n\">layers</span><span class=\"o\">-&gt;</span><span class=\"n\">layer</span><span class=\"err\">：</span>\n  <span class=\"k\">if</span> <span class=\"n\">layer是conv层</span> <span class=\"err\">且</span> <span class=\"err\">使用了</span><span class=\"n\">int8</span><span class=\"err\">：</span>\n     <span class=\"err\">获取</span><span class=\"n\">layer的下一层layer_next</span>\n         <span class=\"k\">if</span> <span class=\"n\">layer_next是ReLU层</span><span class=\"err\">：</span>\n             <span class=\"err\">获取</span><span class=\"n\">layer的下下层layer_next_2</span>\n             <span class=\"k\">if</span> <span class=\"n\">layer_next_2是卷积层</span> <span class=\"err\">且</span> <span class=\"err\">使用了</span><span class=\"n\">int8</span><span class=\"err\">：</span>\n                <span class=\"n\">layer层使用requantize</span>\n             <span class=\"k\">if</span> <span class=\"n\">layer_next_2是split层</span><span class=\"err\">：</span>\n                <span class=\"k\">if</span> <span class=\"n\">layer_next_2</span> <span class=\"n\">split出来的blob后面接的全是conv</span> <span class=\"err\">且</span> <span class=\"err\">这些</span><span class=\"n\">conv都用int8</span><span class=\"err\">：</span>\n                   <span class=\"n\">layer层使用requantize</span>\n</code></pre></div><p>是不是看懵了？我也写懵了</p><p>用另一种方式阐述就会容易很多，目前NCNN只有两种情况会用到requantize：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"n\">Conv1</span> <span class=\"o\">-&gt;</span> <span class=\"n\">ReLU</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Conv2</span><span class=\"err\">，且</span><span class=\"n\">Conv1和Conv2都用int8</span>\n<span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span> <span class=\"n\">Conv1</span> <span class=\"o\">-&gt;</span> <span class=\"n\">ReLU</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Split</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Conv2_1</span>\n                           <span class=\"o\">-&gt;</span> <span class=\"n\">Conv2_2</span>\n                           <span class=\"p\">...</span>\n                           <span class=\"o\">-&gt;</span> <span class=\"n\">Conv2_x</span><span class=\"err\">，且这些</span><span class=\"n\">Conv都用int8</span>\n</code></pre></div><p>这样是不是明白一点？下面给出原始代码：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">layers</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"n\">Layer</span><span class=\"o\">*</span> <span class=\"n\">layer</span> <span class=\"o\">=</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span>\n\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;Convolution&#34;</span> <span class=\"o\">||</span> <span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;ConvolutionDepthWise&#34;</span><span class=\"p\">)</span>  <span class=\"c1\">// 只有Conv支持\n</span><span class=\"c1\"></span>        <span class=\"p\">{</span>\n            <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;Convolution&#34;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"p\">(((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">use_int8_inference</span> <span class=\"o\">==</span> <span class=\"nb\">false</span><span class=\"p\">))</span>\n                <span class=\"k\">continue</span><span class=\"p\">;</span>\n            <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;ConvolutionDepthWise&#34;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"p\">(((</span><span class=\"n\">ConvolutionDepthWise</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">use_int8_inference</span> <span class=\"o\">==</span> <span class=\"nb\">false</span><span class=\"p\">))</span>\n                <span class=\"k\">continue</span><span class=\"p\">;</span>   <span class=\"c1\">// 如果不使用int8,不予理会\n</span><span class=\"c1\"></span>\n            <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">n</span><span class=\"o\">&lt;</span><span class=\"n\">blobs</span><span class=\"p\">[</span><span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">tops</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]].</span><span class=\"n\">consumers</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">n</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"kt\">int</span> <span class=\"n\">layer_next_index</span> <span class=\"o\">=</span> <span class=\"n\">blobs</span><span class=\"p\">[</span><span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">tops</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]].</span><span class=\"n\">consumers</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">];</span>\n                <span class=\"n\">Layer</span><span class=\"o\">*</span> <span class=\"n\">layer_next</span> <span class=\"o\">=</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"n\">layer_next_index</span><span class=\"p\">];</span>   <span class=\"c1\">// conv的下一层\n</span><span class=\"c1\"></span>\n                <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer_next</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;ReLU&#34;</span><span class=\"p\">)</span> <span class=\"c1\">// 如果下一层是ReLU，则去看下下层\n</span><span class=\"c1\"></span>                <span class=\"p\">{</span>\n                    <span class=\"kt\">int</span> <span class=\"n\">layer_next_2_index</span> <span class=\"o\">=</span> <span class=\"n\">blobs</span><span class=\"p\">[</span><span class=\"n\">layer_next</span><span class=\"o\">-&gt;</span><span class=\"n\">tops</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]].</span><span class=\"n\">consumers</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">];</span>\n                    <span class=\"n\">Layer</span><span class=\"o\">*</span> <span class=\"n\">layer_next_2</span> <span class=\"o\">=</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"n\">layer_next_2_index</span><span class=\"p\">];</span>\n\n                    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;Convolution&#34;</span> <span class=\"o\">||</span> <span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;ConvolutionDepthWise&#34;</span><span class=\"p\">)</span>  <span class=\"c1\">// 下下层是卷积的情况，也就是Conv-&gt;ReLU-&gt;Conv的情况，则做requantize\n</span><span class=\"c1\"></span>                    <span class=\"p\">{</span>\n                        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;Convolution&#34;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"p\">((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer_next_2</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">use_int8_inference</span> <span class=\"o\">==</span> <span class=\"nb\">false</span><span class=\"p\">)</span>\n                            <span class=\"k\">continue</span><span class=\"p\">;</span>\n                        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;ConvolutionDepthWise&#34;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"p\">((</span><span class=\"n\">ConvolutionDepthWise</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer_next_2</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">use_int8_inference</span> <span class=\"o\">==</span> <span class=\"nb\">false</span><span class=\"p\">)</span>\n                            <span class=\"k\">continue</span><span class=\"p\">;</span>    \n\n                        <span class=\"c1\">// fprintf(stderr, &#34;%s, %s, %s\\n&#34;, layer-&gt;name.c_str(), layer_next-&gt;name.c_str(), layer_next_2-&gt;name.c_str());\n</span><span class=\"c1\"></span>                        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;Convolution&#34;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;Convolution&#34;</span><span class=\"p\">)</span>\n                        <span class=\"p\">{</span>\n                            <span class=\"c1\">// 打开requantize的开关\n</span><span class=\"c1\"></span>                            <span class=\"p\">((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">use_int8_requantize</span> <span class=\"o\">=</span> <span class=\"nb\">true</span><span class=\"p\">;</span>\n                            <span class=\"c1\">// 存一下下一层输入量化的scale\n</span><span class=\"c1\"></span>                            <span class=\"p\">((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">top_blob_int8_scale</span> <span class=\"o\">=</span> <span class=\"p\">((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer_next_2</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">bottom_blob_int8_scale</span><span class=\"p\">;</span>\n                            <span class=\"c1\">// 创建requantize op\n</span><span class=\"c1\"></span>                            <span class=\"p\">((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">create_requantize_op</span><span class=\"p\">();</span>\n                        <span class=\"p\">}</span>\n                        <span class=\"p\">...</span>\n                    <span class=\"p\">}</span>\n                    <span class=\"k\">else</span> <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;Split&#34;</span><span class=\"p\">)</span>\n                    <span class=\"p\">{</span>\n                        <span class=\"c1\">// 如果Conv后面紧跟着ReLU和Split，但Split出来的Blob紧跟着的都是Conv\n</span><span class=\"c1\"></span>                        <span class=\"c1\">// 即 Conv -&gt; ReLU -&gt; Split -&gt; Conv\n</span><span class=\"c1\"></span>                        <span class=\"c1\">//                          -&gt; Conv\n</span><span class=\"c1\"></span>                        <span class=\"c1\">//                          -&gt; Conv，也会使用requantize，因为输出的scale是每个channel都不同的\n</span><span class=\"c1\"></span>                        <span class=\"c1\">//                                   可以按channel requantize\n</span><span class=\"c1\"></span>                        <span class=\"kt\">bool</span> <span class=\"n\">all_conv</span> <span class=\"o\">=</span> <span class=\"nb\">true</span><span class=\"p\">;</span>\n                        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">tops</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                        <span class=\"p\">{</span>\n                            <span class=\"kt\">int</span> <span class=\"n\">layer_next_3_index</span> <span class=\"o\">=</span> <span class=\"n\">blobs</span><span class=\"p\">[</span><span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">tops</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]].</span><span class=\"n\">consumers</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">];</span>\n                            <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"n\">layer_next_3_index</span><span class=\"p\">]</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">!=</span> <span class=\"s\">&#34;Convolution&#34;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"n\">layer_next_3_index</span><span class=\"p\">]</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">!=</span> <span class=\"s\">&#34;ConvolutionDepthWise&#34;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"n\">layer_next_3_index</span><span class=\"p\">]</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">!=</span> <span class=\"s\">&#34;PriorBox&#34;</span> <span class=\"p\">)</span>\n                            <span class=\"p\">{</span>\n                                <span class=\"c1\">// fprintf(stderr, &#34;%s, %s, %s, %s\\n&#34;, layer-&gt;name.c_str(), layer_next-&gt;name.c_str(), layer_next_2-&gt;name.c_str(), layers[layer_next_3_index]-&gt;name.c_str());\n</span><span class=\"c1\"></span>                                <span class=\"n\">all_conv</span> <span class=\"o\">=</span> <span class=\"nb\">false</span><span class=\"p\">;</span>\n                            <span class=\"p\">}</span>\n                        <span class=\"p\">}</span>\n\n                        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">all_conv</span> <span class=\"o\">==</span> <span class=\"nb\">true</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">tops</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">()</span> <span class=\"o\">&gt;=</span> <span class=\"n\">size_t</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n                        <span class=\"p\">{</span>\n                            <span class=\"c1\">// fprintf(stderr, &#34;%s, %s, %s, &#34;, layer-&gt;name.c_str(), layer_next-&gt;name.c_str(), layer_next_2-&gt;name.c_str());\n</span><span class=\"c1\"></span>                            <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">tops</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                            <span class=\"p\">{</span>\n                                <span class=\"kt\">int</span> <span class=\"n\">layer_next_3_index</span> <span class=\"o\">=</span> <span class=\"n\">blobs</span><span class=\"p\">[</span><span class=\"n\">layer_next_2</span><span class=\"o\">-&gt;</span><span class=\"n\">tops</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]].</span><span class=\"n\">consumers</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">];</span>\n                                <span class=\"n\">Layer</span><span class=\"o\">*</span> <span class=\"n\">layer_next_3</span> <span class=\"o\">=</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"n\">layer_next_3_index</span><span class=\"p\">];</span>\n\n                                <span class=\"c1\">// fprintf(stderr, &#34;%s, &#34;, layer_next_3-&gt;name.c_str());\n</span><span class=\"c1\"></span>                                <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">layer_next_3</span><span class=\"o\">-&gt;</span><span class=\"n\">type</span> <span class=\"o\">==</span> <span class=\"s\">&#34;Convolution&#34;</span><span class=\"p\">)</span>\n                                <span class=\"p\">{</span>\n                                    <span class=\"p\">((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">top_blob_int8_scale</span> <span class=\"o\">=</span> <span class=\"p\">((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer_next_3</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">bottom_blob_int8_scale</span><span class=\"p\">;</span> \n                                <span class=\"p\">}</span>    \n                            <span class=\"p\">}</span>\n\n                            <span class=\"p\">((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">use_int8_requantize</span> <span class=\"o\">=</span> <span class=\"nb\">true</span><span class=\"p\">;</span>\n                            <span class=\"p\">((</span><span class=\"n\">Convolution</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">layer</span><span class=\"p\">)</span><span class=\"o\">-&gt;</span><span class=\"n\">create_requantize_op</span><span class=\"p\">();</span>    \n                            <span class=\"c1\">// fprintf(stderr, &#34;\\n&#34;);\n</span><span class=\"c1\"></span>                        <span class=\"p\">}</span>\n                    <span class=\"p\">}</span>\n                <span class=\"p\">}</span>               \n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n</code></pre></div><h3>(2) requantize如何做？</h3><p>设Conv1的反量化scale=1/(s1*s2)，Conv2的输入量化scale=s3，则requantize的公式为：</p><p><img src=\"https://www.zhihu.com/equation?tex=Conv2%5C_Input%28int8%29+%3D+%28Conv1%5C_Inner%28int32%29%2A%281%2Fs1%2As2%29+%2B+Conv1%5C_Bias%29%2As3\" alt=\"Conv2\\_Input(int8) = (Conv1\\_Inner(int32)*(1/s1*s2) + Conv1\\_Bias)*s3\" eeimg=\"1\"/> </p><p>从公式上来看，跟不使用requantize，独立的两个层计算没有任何区别，但从代码上能看出些不同：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"cm\">/* requantize.cpp */</span>\n\n<span class=\"c1\">// 下面截取了部分代码\n</span><span class=\"c1\"></span><span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">size</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"n\">ptr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">float2int8</span><span class=\"p\">(((</span><span class=\"n\">intptr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">scale_in</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">bias</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">scale_out</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">fusion_relu</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">ptr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">&lt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n        <span class=\"n\">ptr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>可以看到，在requantize的过程中，有两个优化点：</p><ol><li>不再显式的存储Conv1反量化的结果，而是直接算好Conv2的量化再存储，省去了一次写和一次读</li><li>ReLU也被合并进两个Conv中间</li></ol><h3>（3）requantize何时调用？</h3><p>跟dequantize一样，在卷积计算完，得到INT32后调用</p><h3>（4）Conv1做完requantize后，Conv2怎么知道不需要再做量化了呢？</h3><p>在Convlution::Forward()函数里，有这样一段代码：</p><div class=\"highlight\"><pre><code class=\"language-cpp\">    <span class=\"n\">size_t</span> <span class=\"n\">elemsize</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob</span><span class=\"p\">.</span><span class=\"n\">elemsize</span><span class=\"p\">;</span>   <span class=\"c1\">// blob中每个数据所占字节数\n</span><span class=\"c1\"></span>\n    <span class=\"n\">Mat</span> <span class=\"n\">bottom_blob_unbordered</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob</span><span class=\"p\">;</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">use_int8_inference</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">elemsize</span> <span class=\"o\">!=</span> <span class=\"mi\">1</span><span class=\"p\">)</span>    <span class=\"c1\">// elemsize ！= 1 说明若输入已经是int8,则不需要再次量化\n</span><span class=\"c1\"></span>    <span class=\"p\">{</span>\n        <span class=\"n\">Mat</span> <span class=\"n\">bottom_blob_int8</span><span class=\"p\">;</span>\n        <span class=\"n\">bottom_blob_int8</span><span class=\"p\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"n\">h</span><span class=\"p\">,</span> <span class=\"n\">channels</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">size_t</span><span class=\"p\">)</span><span class=\"mi\">1u</span><span class=\"p\">,</span> <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">workspace_allocator</span><span class=\"p\">);</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">bottom_blob_int8</span><span class=\"p\">.</span><span class=\"n\">empty</span><span class=\"p\">())</span>\n            <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"mi\">100</span><span class=\"p\">;</span>\n\n        <span class=\"c1\">// quantize, scale and round to nearest\n</span><span class=\"c1\"></span>        <span class=\"p\">{</span>\n            <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Option</span> <span class=\"n\">opt_g</span> <span class=\"o\">=</span> <span class=\"n\">opt</span><span class=\"p\">;</span>\n            <span class=\"n\">opt_g</span><span class=\"p\">.</span><span class=\"n\">blob_allocator</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob_int8</span><span class=\"p\">.</span><span class=\"n\">allocator</span><span class=\"p\">;</span>\n\n            <span class=\"n\">quantize</span><span class=\"o\">-&gt;</span><span class=\"n\">forward</span><span class=\"p\">(</span><span class=\"n\">bottom_blob</span><span class=\"p\">,</span> <span class=\"n\">bottom_blob_int8</span><span class=\"p\">,</span> <span class=\"n\">opt_g</span><span class=\"p\">);</span>    <span class=\"c1\">// 量化计算\n</span><span class=\"c1\"></span>        <span class=\"p\">}</span>\n\n        <span class=\"n\">bottom_blob_unbordered</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob_int8</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n</code></pre></div><p>其中elemsize是输入数据中每个数据所占字节数，若elemsize=1,则说明输入已经是int8了，不再需要量化了。</p><p>NCNN通过blob向Conv2传递是否进行了requantize的信息</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>4、结语</h2><p>本文介绍了NCNN代码中目前对于量化的处理。至于如何得到量化模型，请参考NCNN github上的wiki：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/Tencent/ncnn/wiki/quantized-int8-inference\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">quantized int8 inference</a>，可以将caffe模型量化成NCNN模型。</p><p>（经评论区提醒，NCNN最近添加了量化工具ncnn2int8.cpp和ncnn2table.cpp，放在了tools/quantize下，不再局限于caffe了）</p><p>关于NCNN量化工具的介绍：</p><a href=\"https://zhuanlan.zhihu.com/p/72375164\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic4.zhimg.com/equation.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"internal\">田子宸：NCNN量化详解（二）</a><p>如有不足，请各位指出</p><p>谢谢！</p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "高性能计算", 
                    "tagLink": "https://api.zhihu.com/topics/19608622"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": [
                {
                    "userName": "王小二", 
                    "userLink": "https://www.zhihu.com/people/f6667623cf045e112fc9a30f995a9742", 
                    "content": "手动呼叫虫叔 <a class=\"member_mention\" href=\"http://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f\" data-hash=\"647087f95394a5f589bf72bf3edcb44f\" data-hovercard=\"p$b$647087f95394a5f589bf72bf3edcb44f\">@圈圈虫 </a>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "圈圈虫", 
                            "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                            "content": "来了来了<a href=\"https://pic2.zhimg.com/v2-2b7e64f732b793ac0c7323e9d71c9499.webp\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"1029328993056542720\">[笔芯]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "王小二"
                        }
                    ]
                }, 
                {
                    "userName": "圈圈虫", 
                    "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                    "content": "最新的代码，不局限于caffe模型了，只要是ncnn的模型都可以通过tools/quantize/目录下的ncnn2table和ncnn2int8来进行模型转换。非常棒的文章！[爱]其实requant本来支持pooling max、concat、eltwise的，会更晕<a href=\"https://pic1.zhimg.com/v2-12562ad40366818a1ea39bcecb2599a0.gif\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"951517104542273536\">[害羞]</a>", 
                    "likes": 3, 
                    "childComments": [
                        {
                            "userName": "田子宸", 
                            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
                            "content": "<p>感谢提醒，我这个代码是半个月前clone下来的，没想到NCNN这么快就出了quantize的tool。<br>requantize其实更亮眼的是NCNN开始关注图优化了，希望后续能做得更好</p>", 
                            "likes": 0, 
                            "replyToAuthor": "圈圈虫"
                        }
                    ]
                }, 
                {
                    "userName": "Young", 
                    "userLink": "https://www.zhihu.com/people/91a079d6e279bb4f0af93f0bfac8d434", 
                    "content": "<p>文中第二个图（int8 Conv计算流程）中 inner blob(int32) -&gt; inner blob(fp32)，这一步应该也是 online 处理的吧，不是 offline</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "syl", 
                    "userLink": "https://www.zhihu.com/people/34cd2ab72fd770fc71aca683ae8f30f5", 
                    "content": "您好，请问，如果权重里每个kernel有不同的scale参数，那么如果量化的网络有concat层，你们scale不同，对concat之后会不会有影响啊？我的理解是，concat层将各个支路结合起来，scale不同，会使得量化之后的误差更大吧！", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/53773183", 
            "userName": "田子宸", 
            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
            "upvote": 158, 
            "title": "《CUDA C Programming Guide》(《CUDA C 编程指南》)导读", 
            "content": "<h2>说明</h2><p>最近在学习CUDA，感觉看完就忘，于是这里写一个导读，整理一下重点</p><p>主要内容来源于NVIDIA的官方文档《CUDA C Programming Guide》，结合了另一本书《CUDA并行程序设计 GPU编程指南》的知识。 因此在翻译总结官方文档的同时，会加一些评注，不一定对，望大家讨论指出。</p><p>另外，我才不会老老实实的翻译文档，因此细节还是需要从文档里看的。</p><p>看完两份文档总的来说，感觉《CUDA C Programming Guide》这本书作为一份官方文档，知识细碎且全面，且是针对最新的Maxwell、Pascal、Volta架构的阐述。但相对来说不够深入，且有关程序设计方面所述甚少。</p><p>而《CUDA并行程序设计 GPU编程指南》这本书，讲解的比较深入，不仅阐述了NVIDIA GPU的特性，并且在程序设计方面有比较深入的见解。美中不足的是该书是针对老旧的Tesla、Fermi架构GPU，没有涉及到新架构的新特性。  </p><hr/><h2>Chapter 1 简介</h2><h2>1.1 从图形处理到通用并行计算</h2><p>GPU是能够高度并行化、具有很多处理器核心的器件，具有很强的计算能力和内存带宽。下图是CPU和GPU在浮点运算上的性能对比发展趋势。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4ab55721bb183975ef93a1d33c56fbee_b.jpg\" data-size=\"normal\" data-rawwidth=\"1216\" data-rawheight=\"645\" class=\"origin_image zh-lightbox-thumb\" width=\"1216\" data-original=\"https://pic3.zhimg.com/v2-4ab55721bb183975ef93a1d33c56fbee_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1216&#39; height=&#39;645&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1216\" data-rawheight=\"645\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1216\" data-original=\"https://pic3.zhimg.com/v2-4ab55721bb183975ef93a1d33c56fbee_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4ab55721bb183975ef93a1d33c56fbee_b.jpg\"/><figcaption>NVIDIA GPU和 Intel CPU 浮点计算能力对比</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>可以看到，NVIDIA的GPU在浮点运算能力上，吊打了Intel的CPU。其原因来自于CPU和GPU结构上的差异。</p><p>如下图所示，CPU仅仅具有有限的核心数量。相比于GPU，CPU的核心属于“少而精”的存在，核心数虽然很少，但是每个核心的性能很强，适合处理具有很多分支的复杂的逻辑。近些年来，CPU中集成了一些并行指令集，如SSE、AVX等，其中AVX可以同时处理256位(32个字节)，可以大大加速并行计算。但是相比于GPU，还是小巫见大巫。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a509cb4eb6863be492b0672ff4bb7b30_b.jpg\" data-size=\"normal\" data-rawwidth=\"969\" data-rawheight=\"363\" class=\"origin_image zh-lightbox-thumb\" width=\"969\" data-original=\"https://pic1.zhimg.com/v2-a509cb4eb6863be492b0672ff4bb7b30_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;969&#39; height=&#39;363&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"969\" data-rawheight=\"363\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"969\" data-original=\"https://pic1.zhimg.com/v2-a509cb4eb6863be492b0672ff4bb7b30_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a509cb4eb6863be492b0672ff4bb7b30_b.jpg\"/><figcaption>CPU 与 GPU 内部结构对比</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>GPU的设计理念与CPU不同，GPU具有庞大的核心数。以TITANX为例，流处理器（等同于CPU的核心）达到3072个之多。这意味着相比于8核的CPU处理器，TITANX可以同时并行处理384倍的任务。但是GPU的单个核心不如CPU的核心强大。因此相对于CPU，GPU更适合处理高度并行化的任务。</p><p>从另一个视角来看上图，在CPU芯片中，运算单元(ALU)所占的比例较小，CPU中更多的硅片被用来制作控制单元和缓存，以完成复杂的逻辑；而GPU的运算单元使用的硅片面积比例要大于CPU，以完成高强度的计算。因此CPU的侧重点在于逻辑控制，而GPU的侧重点在于计算。</p><p>深度学习，尤其是卷积神经网络中，有很多可以高度并行化的向量运算与矩阵运算。因此使用GPU进行深度学习运算，远比CPU快速。</p><p>另外还需注意的是，由于GPU的核心数量太多，即使GPU的内存（也称作显存）优于CPU的内存，其内存仍然是瓶颈。因此，GPU希望程序是 计算密集型 而不是 内存密集型。</p><h2>1.2 CUDA</h2><p>CUDA(Compute Unified Device Architecture)，是NVIDIA推出的通用并行计算平台和编程模型。CUDA是在底层API的基础上，封装了一层，使得程序员可以使用C语言来方便的编程。</p><p>CUDA还支持C++/Python等更高级的语言编程；此外，NVIDIA还提供了CuDNN、TensorRT、NPP等更高级的库函数。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-7f6f84f9f34c5bcbf2f1dd0e8e4d7048_b.jpg\" data-size=\"normal\" data-rawwidth=\"848\" data-rawheight=\"729\" class=\"origin_image zh-lightbox-thumb\" width=\"848\" data-original=\"https://pic1.zhimg.com/v2-7f6f84f9f34c5bcbf2f1dd0e8e4d7048_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;848&#39; height=&#39;729&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"848\" data-rawheight=\"729\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"848\" data-original=\"https://pic1.zhimg.com/v2-7f6f84f9f34c5bcbf2f1dd0e8e4d7048_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-7f6f84f9f34c5bcbf2f1dd0e8e4d7048_b.jpg\"/><figcaption>各代显卡、CUDA、上层库之间的关系</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>从上图中也可以看出各个系列的GPU属于哪些架构、什么定位。例如GeForece 1000系列，就是使用Pascal架构的消费显卡。</p><h2>1.3 可扩展的编程模型</h2><p>CUDA的编程模型，使得同一个CUDA程序，可以在不同的显卡上运行。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d3271f519f1fe9ad2363b5a11b44501d_b.jpg\" data-size=\"normal\" data-rawwidth=\"688\" data-rawheight=\"650\" class=\"origin_image zh-lightbox-thumb\" width=\"688\" data-original=\"https://pic2.zhimg.com/v2-d3271f519f1fe9ad2363b5a11b44501d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;688&#39; height=&#39;650&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"688\" data-rawheight=\"650\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"688\" data-original=\"https://pic2.zhimg.com/v2-d3271f519f1fe9ad2363b5a11b44501d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d3271f519f1fe9ad2363b5a11b44501d_b.jpg\"/><figcaption>CUDA编程模型</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>如上图所示，CUDA程序一般会创建一些线程块(Block)，线程块会被调度到空闲的流处理器簇(SM)上去。当线程块执行完毕后，线程块会退出SM，释放出SM的资源，以供其他待执行线程块调度进去。</p><p>因此，无论是只有2个SM的GPU，还是有4个SM的GPU，这些线程块都会被调度执行，只不过是执行的时间有长有短。因此，同样的程序，可以在具有不同SM数量上的GPU运行。</p><h2>1.4 Document Structure</h2><p>略</p><hr/><h2>Chapter 2 编程模型</h2><h2>2.2 线程层级</h2><p>在讲解内核函数前，先讲解一下线程层级，不然有点难讲。</p><p>CUDA编程是一个多线程编程，数个线程(Thread)组成一个线程块(Block)，所有线程块组成一个线程网格(Grid)，如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-ca7030c0d6e2702b88271e8b0d9c1e38_b.jpg\" data-size=\"normal\" data-rawwidth=\"584\" data-rawheight=\"727\" class=\"origin_image zh-lightbox-thumb\" width=\"584\" data-original=\"https://pic1.zhimg.com/v2-ca7030c0d6e2702b88271e8b0d9c1e38_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;584&#39; height=&#39;727&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"584\" data-rawheight=\"727\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"584\" data-original=\"https://pic1.zhimg.com/v2-ca7030c0d6e2702b88271e8b0d9c1e38_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-ca7030c0d6e2702b88271e8b0d9c1e38_b.jpg\"/><figcaption>CUDA线程层级</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>图中的线程块，以及线程块中的线程，是按照2维的方式排布的。实际上，CUDA编程模型允许使用1维、2维、3维三种方式来排布。另外，即使线程块使用的是1维排布，线程块中的线程也不一定要按照1维排，而是可以任意排布。</p><p>目前的GPU限制一个线程块中，最多可以安排1024个线程。</p><p>一个线程块用多少线程，以及一个线程网格用多少线程块，是程序员可以自由安排的。由于32个相邻的线程会组成一个线程束(Thread Warp)，而一个线程束中的线程会运行同样的指令。因此一般线程块中线程的数量被安排为32的倍数，选用256是比较合适的。</p><p>在线程数定下来之后，一般根据数据的排布情况来确定线程块的个数。</p><p>例如：一个数组的长度为4096，安排每个线程处理一个元素。如果安排一个线程块为256个线程，则需要4096/256=16个线程块。</p><h2>2.1 内核函数(Kernels)</h2><p>内核函数是CUDA <b>每个线程</b> 执行的函数。CUDA使用扩展的C语言编写内核函数，关键字为<b>global</b>。内核函数返回值只能是void。</p><p>下面是一段简单的内核函数，用于求两个数组的和：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"c1\">// Kernel definition\n</span><span class=\"c1\"></span><span class=\"n\">__global__</span> <span class=\"kt\">void</span> <span class=\"nf\">VecAdd</span><span class=\"p\">(</span><span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">A</span><span class=\"p\">,</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">C</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">;</span>\n    <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span>\n<span class=\"p\">}</span>\n\n<span class=\"kt\">int</span> <span class=\"nf\">main</span><span class=\"p\">()</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n    <span class=\"c1\">// Kernel invocation with N threads\n</span><span class=\"c1\"></span>    <span class=\"n\">VecAdd</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">N</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">,</span> <span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"p\">);</span>\n    <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div><p><code>threadIdx.x</code>是线程在所处线程块中的X方向的ID。由于本例中是定义的1维排布，因此X方向ID即为线程的ID。</p><p>由于GPU中的每个线程都会执行相同的VecAdd函数，因此不同的线程需要使用自己独有的ID来区分彼此，来获取不同的数据。这就是SIMT的概念，即“相同指令，不同线程”。</p><p>在main()函数中，我们注意到，VecAdd函数的调用使用了<code>&lt;&lt;&lt;blockPerGrid, threadsPerBlock&gt;&gt;&gt;</code>关键字。这是调用内核函数所独有的。程序员通过该关键字，制定网格中线程块和线程的排布方式。排布方式与数据息息相关。</p><p>下面举一个2维排布的例子，用于做矩阵加法：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"c1\">// Kernel definition\n</span><span class=\"c1\"></span><span class=\"n\">__global__</span> <span class=\"kt\">void</span> <span class=\"nf\">MatAdd</span><span class=\"p\">(</span><span class=\"kt\">float</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">][</span><span class=\"n\">N</span><span class=\"p\">],</span> <span class=\"kt\">float</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">][</span><span class=\"n\">N</span><span class=\"p\">],</span>\n<span class=\"kt\">float</span> <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">][</span><span class=\"n\">N</span><span class=\"p\">])</span>\n<span class=\"p\">{</span>\n    <span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"n\">blockIdx</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">*</span> <span class=\"n\">blockDim</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">j</span> <span class=\"o\">=</span> <span class=\"n\">blockIdx</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">*</span> <span class=\"n\">blockDim</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">+</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">y</span><span class=\"p\">;</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"n\">N</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">j</span> <span class=\"o\">&lt;</span> <span class=\"n\">N</span><span class=\"p\">)</span>\n        <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"n\">i</span><span class=\"p\">];</span>\n<span class=\"p\">}</span>\n\n<span class=\"kt\">int</span> <span class=\"nf\">main</span><span class=\"p\">()</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n    <span class=\"c1\">// Kernel invocation\n</span><span class=\"c1\"></span>    <span class=\"n\">dim3</span> <span class=\"n\">threadsPerBlock</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">);</span>\n    <span class=\"n\">dim3</span> <span class=\"n\">numBlocks</span><span class=\"p\">(</span><span class=\"n\">N</span> <span class=\"o\">/</span> <span class=\"n\">threadsPerBlock</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">N</span> <span class=\"o\">/</span> <span class=\"n\">threadsPerBlock</span><span class=\"p\">.</span><span class=\"n\">y</span><span class=\"p\">);</span>\n    <span class=\"n\">MatAdd</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"n\">numBlocks</span><span class=\"p\">,</span> <span class=\"n\">threadsPerBlock</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">,</span> <span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"p\">);</span>\n<span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>首先看主函数，当排布不使用1维时，需要使用<code>dim3</code>数据类型。该程序每个线程块中线程为16x16排布，而线程块的排布依赖于数据的多少。</p><p>在内核函数中，i代表x方向上的ID，j代表y方向上的ID。<code>blockDim</code>代表当前线程块的尺寸。从程序中可以看到，x方向为行方向，y方向为列方向。（注意，这里官方文档里面写的有些错误）</p><p>每个线程读取自己ID对应的数据A[j][i]和B[j][i]，并将结果写回C[j][i]。其中A、B、C都存储在GPU的全局内存上（后面会提及）</p><h2>2.3 内存层级</h2><p>同CPU一样，GPU也有不同层级的内存。越靠近核心的内存速度越快，但容量越小；反之，越远离核心的内存速度越慢，但容量较大。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-f40c0b301c39da9230f169f3702f1d97_b.jpg\" data-size=\"normal\" data-rawwidth=\"867\" data-rawheight=\"667\" class=\"origin_image zh-lightbox-thumb\" width=\"867\" data-original=\"https://pic4.zhimg.com/v2-f40c0b301c39da9230f169f3702f1d97_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;867&#39; height=&#39;667&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"867\" data-rawheight=\"667\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"867\" data-original=\"https://pic4.zhimg.com/v2-f40c0b301c39da9230f169f3702f1d97_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-f40c0b301c39da9230f169f3702f1d97_b.jpg\"/><figcaption>CUDA内存层级</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>上图是NVIDIA设备的硬件示意图。</p><ul><li>最上方是主机端内存(host memory)，指的就是我们常说的内存。一般主机端内存通过PCI-E总线与设备端内存交换数据。数据交换的速度等于PCI-E总线的速度。</li><li><b>全局内存(global memory)</b> 、常量内存(constant memory)、纹理内存(texture memory)、本地内存(local memory)。都位于GPU板上，但不在片内。因此速度相对片内内存较慢。<br/> 常量内存和纹理内存对于GPU来说是只读的。  </li><li>GPU上有 L2 cache和 L1 cahce。其中L2 cache为所有流处理器簇(SM)共享，而L1 cache为每个SM内部共享。这里的cache和CPU的cache一样，程序员无法对cache显式操纵。</li><li>纹理缓存和常量缓存在SM内部共享，在早期1.x计算能力的时代，这两种缓存是片上唯一的缓存，十分宝贵。而当Fermi架构出现后，普通的全局内存也具有了缓存，因此就不那么突出了。</li><li><b>共享内存(shared memory, SMEM)</b> 具有和L1缓存同样的速度，且可以被程序员显式操纵，因此经常被用作存放一些需要反复使用的数据。共享内存只能在SM内共享，且对于CUDA编程模型来说，即使线程块被调度到了同一个SM内也无法互相访问。</li><li>GPU的<b>寄存器(registers)</b> 和CPU不一样，其空间非常巨大，以至于可以为每一个线程分配一块独立的寄存器空间。因此，不像CPU那样切换进程时需要保存上下文，GPU只需要修改一下寄存器空间的指针即可继续运行。所以巨大的寄存器空间，使得GPU上线程切换成为了一个几乎无消耗的操作。<br/> 不过有一点需要注意，寄存器的空间不是无限大的。如果线程数过多，或一个线程使用的寄存器数量太多，多出来的数据会被保存到缓慢的本地内存上，影响程序速度，需要注意。</li></ul><p>这里想强调一下共享内存。<br/> 共享内存在物理上是一个个存储体组成的。如果在访问时没有出现冲突，则可以实现高速的访问。但如果出现了冲突(如对某一个存储体的原子操作)，则不仅仅当前线程束会发生串行化，<i>而且会导致其他线程束无法被调度(存疑，待考证)</i>。</p><p>以上是从硬件的角度解读了一下GPU的内存层级。从编程角度来看，CUDA的线程网格、线程块、线程与各个内存见的关系如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c716333e7f0716d080c6b24383fb368e_b.jpg\" data-size=\"normal\" data-rawwidth=\"731\" data-rawheight=\"958\" class=\"origin_image zh-lightbox-thumb\" width=\"731\" data-original=\"https://pic3.zhimg.com/v2-c716333e7f0716d080c6b24383fb368e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;731&#39; height=&#39;958&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"731\" data-rawheight=\"958\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"731\" data-original=\"https://pic3.zhimg.com/v2-c716333e7f0716d080c6b24383fb368e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c716333e7f0716d080c6b24383fb368e_b.jpg\"/><figcaption>线程层级与内存层级对应图</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><ul><li>寄存器和本地内存绑定到了每个线程，其他线程无法访问。</li><li>同一个线程块内的线程，可以访问同一块共享内存。注意，即使两个线程块被调度到了同一个SM上，他们的共享内存也是隔离开的，不能互相访问。</li><li>网格中的所有线程都可以自由读写全局内存。</li><li>常量内存和纹理内存只能被CPU端修改，GPU内的线程只能读取数据。</li></ul><h2>2.4 CPU/GPU混合编程</h2><p>一种最简单的CPU/GPU混合编程如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-ccc5ef84d2f569f5fac3f0171d09ed78_b.jpg\" data-size=\"normal\" data-rawwidth=\"578\" data-rawheight=\"948\" class=\"origin_image zh-lightbox-thumb\" width=\"578\" data-original=\"https://pic1.zhimg.com/v2-ccc5ef84d2f569f5fac3f0171d09ed78_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;578&#39; height=&#39;948&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"578\" data-rawheight=\"948\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"578\" data-original=\"https://pic1.zhimg.com/v2-ccc5ef84d2f569f5fac3f0171d09ed78_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-ccc5ef84d2f569f5fac3f0171d09ed78_b.jpg\"/><figcaption>CPU/GPU混合编程</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>主机端(Host，即CPU)执行串行代码，然后调用内核函数，让设备端(Device，即GPU)执行并行代码。如此交错执行。</p><p>CPU和GPU的内存是独立的。因此在运行内核函数前，主机端需要调用内存拷贝函数，将数据通过PCI-E总线拷贝到设备端。内核运行结束后，需要CPU再次调用内存拷贝函数，将数据拷回主机端内存。</p><p>另一种方式是使用统一编址，将设备端的内存和主机端内存编到一起。这样主机就不需要显式的调用函数将数据拷贝到设备端内存了。</p><p>除了CPU/GPU交错执行代码的方式外，还可以通过使用事件(event)和流(stream)等方式，让CPU/GPU并行工作，提升整体的效率。</p><h2>2.5 计算能力(Compute Capability)</h2><p>所谓的计算能力(Compute Capability)，说白了就是GPU的版本号。有时也被称作SM Version。</p><p>不同版本的GPU具有不同的特性，因此程序编写也会有所差异。</p><p>计算能力为X.Y，其中主版本号X代表架构，各个架构如下表：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-31a23645d2ddde3415f0e8abbd059f32_b.png\" data-size=\"normal\" data-rawwidth=\"196\" data-rawheight=\"263\" class=\"content_image\" width=\"196\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;196&#39; height=&#39;263&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"196\" data-rawheight=\"263\" class=\"content_image lazy\" width=\"196\" data-actualsrc=\"https://pic3.zhimg.com/v2-31a23645d2ddde3415f0e8abbd059f32_b.png\"/><figcaption>版本号与架构名称</figcaption></figure><p>在CUDA的书籍文档中，我们经常能看到&#34;1.x&#34;、&#34;5.x&#34;等这样的字眼，代表第1代/第5代架构，也就是Tesla/Maxwell架构。</p><p>次版本号Y，代表在架构的基础上，有一定改进，或者有一些新特性的引入。</p><p>最新的图灵架构(Turing)，实际上计算能力是7.5，也就是说还是属于Volta架构。</p><p>CUDA是软件平台，其版本(CUDA7.5 CUDA8.0 CUDA10.0)与计算能力基本没有关系。不过最新的CUDA一般会支持最新的架构。<br/> 从CUDA7.0起，Tesla架构不再被支持；从CUDA9.0起，Fermi架构不再被支持。</p><h2>2.6 完整的例子</h2><p>初学者的话，上面内容能看明白的都是勇士。这里给一个例子，是我自己写的BGR转灰度图的程序，希望能让大家稍微明白一点CUDA程序如何写。</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"cm\">/* main.cu */</span>\n<span class=\"cp\">#include</span> <span class=\"cpf\">&lt;iostream&gt;</span><span class=\"cp\">\n</span><span class=\"cp\">#include</span> <span class=\"cpf\">&lt;time.h&gt;</span><span class=\"cp\">\n</span><span class=\"cp\">#include</span> <span class=\"cpf\">&#34;opencv2/highgui.hpp&#34;  //实际上在/usr/include下</span><span class=\"cp\">\n</span><span class=\"cp\">#include</span> <span class=\"cpf\">&#34;opencv2/opencv.hpp&#34;</span><span class=\"cp\">\n</span><span class=\"cp\"></span><span class=\"k\">using</span> <span class=\"k\">namespace</span> <span class=\"n\">cv</span><span class=\"p\">;</span>\n<span class=\"k\">using</span> <span class=\"k\">namespace</span> <span class=\"n\">std</span><span class=\"p\">;</span>\n\n<span class=\"c1\">//内核函数\n</span><span class=\"c1\"></span><span class=\"n\">__global__</span> <span class=\"kt\">void</span> <span class=\"nf\">rgb2grayincuda</span><span class=\"p\">(</span><span class=\"n\">uchar3</span> <span class=\"o\">*</span> <span class=\"k\">const</span> <span class=\"n\">d_in</span><span class=\"p\">,</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"o\">*</span> <span class=\"k\">const</span> <span class=\"n\">d_out</span><span class=\"p\">,</span> \n                                <span class=\"n\">uint</span> <span class=\"n\">imgheight</span><span class=\"p\">,</span> <span class=\"n\">uint</span> <span class=\"n\">imgwidth</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"k\">const</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">int</span> <span class=\"n\">idx</span> <span class=\"o\">=</span> <span class=\"n\">blockIdx</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">*</span> <span class=\"n\">blockDim</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">;</span>\n    <span class=\"k\">const</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">int</span> <span class=\"n\">idy</span> <span class=\"o\">=</span> <span class=\"n\">blockIdx</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">*</span> <span class=\"n\">blockDim</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">+</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">y</span><span class=\"p\">;</span>\n\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">idx</span> <span class=\"o\">&lt;</span> <span class=\"n\">imgwidth</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">idy</span> <span class=\"o\">&lt;</span> <span class=\"n\">imgheight</span><span class=\"p\">)</span>  <span class=\"c1\">//有的线程会跑到图像外面去，不执行即可\n</span><span class=\"c1\"></span>    <span class=\"p\">{</span>\n        <span class=\"n\">uchar3</span> <span class=\"n\">rgb</span> <span class=\"o\">=</span> <span class=\"n\">d_in</span><span class=\"p\">[</span><span class=\"n\">idy</span> <span class=\"o\">*</span> <span class=\"n\">imgwidth</span> <span class=\"o\">+</span> <span class=\"n\">idx</span><span class=\"p\">];</span>\n        <span class=\"n\">d_out</span><span class=\"p\">[</span><span class=\"n\">idy</span> <span class=\"o\">*</span> <span class=\"n\">imgwidth</span> <span class=\"o\">+</span> <span class=\"n\">idx</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.299f</span> <span class=\"o\">*</span> <span class=\"n\">rgb</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"mf\">0.587f</span> <span class=\"o\">*</span> <span class=\"n\">rgb</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">+</span> <span class=\"mf\">0.114f</span> <span class=\"o\">*</span> <span class=\"n\">rgb</span><span class=\"p\">.</span><span class=\"n\">z</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">//用于对比的CPU串行代码\n</span><span class=\"c1\"></span><span class=\"kt\">void</span> <span class=\"nf\">rgb2grayincpu</span><span class=\"p\">(</span><span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"o\">*</span> <span class=\"k\">const</span> <span class=\"n\">d_in</span><span class=\"p\">,</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"o\">*</span> <span class=\"k\">const</span> <span class=\"n\">d_out</span><span class=\"p\">,</span>\n                                <span class=\"n\">uint</span> <span class=\"n\">imgheight</span><span class=\"p\">,</span> <span class=\"n\">uint</span> <span class=\"n\">imgwidth</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"n\">imgheight</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">j</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span> <span class=\"o\">&lt;</span> <span class=\"n\">imgwidth</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"n\">d_out</span><span class=\"p\">[</span><span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">imgwidth</span> <span class=\"o\">+</span> <span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.299f</span> <span class=\"o\">*</span> <span class=\"n\">d_in</span><span class=\"p\">[(</span><span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">imgwidth</span> <span class=\"o\">+</span> <span class=\"n\">j</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"p\">]</span>\n                                     <span class=\"o\">+</span> <span class=\"mf\">0.587f</span> <span class=\"o\">*</span> <span class=\"n\">d_in</span><span class=\"p\">[(</span><span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">imgwidth</span> <span class=\"o\">+</span> <span class=\"n\">j</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"mi\">3</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">]</span>\n                                     <span class=\"o\">+</span> <span class=\"mf\">0.114f</span> <span class=\"o\">*</span> <span class=\"n\">d_in</span><span class=\"p\">[(</span><span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">imgwidth</span> <span class=\"o\">+</span> <span class=\"n\">j</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"mi\">3</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">];</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"kt\">int</span> <span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"kt\">void</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"n\">Mat</span> <span class=\"n\">srcImage</span> <span class=\"o\">=</span> <span class=\"n\">imread</span><span class=\"p\">(</span><span class=\"s\">&#34;./test.jpg&#34;</span><span class=\"p\">);</span>\n    <span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"s\">&#34;srcImage&#34;</span><span class=\"p\">,</span> <span class=\"n\">srcImage</span><span class=\"p\">);</span>\n    <span class=\"n\">waitKey</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n\n    <span class=\"k\">const</span> <span class=\"n\">uint</span> <span class=\"n\">imgheight</span> <span class=\"o\">=</span> <span class=\"n\">srcImage</span><span class=\"p\">.</span><span class=\"n\">rows</span><span class=\"p\">;</span>\n    <span class=\"k\">const</span> <span class=\"n\">uint</span> <span class=\"n\">imgwidth</span> <span class=\"o\">=</span> <span class=\"n\">srcImage</span><span class=\"p\">.</span><span class=\"n\">cols</span><span class=\"p\">;</span>\n\n    <span class=\"n\">Mat</span> <span class=\"n\">grayImage</span><span class=\"p\">(</span><span class=\"n\">imgheight</span><span class=\"p\">,</span> <span class=\"n\">imgwidth</span><span class=\"p\">,</span> <span class=\"n\">CV_8UC1</span><span class=\"p\">,</span> <span class=\"n\">Scalar</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">));</span>\n\n    <span class=\"n\">uchar3</span> <span class=\"o\">*</span><span class=\"n\">d_in</span><span class=\"p\">;</span>   <span class=\"c1\">//向量类型，3个uchar\n</span><span class=\"c1\"></span>    <span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"o\">*</span><span class=\"n\">d_out</span><span class=\"p\">;</span>\n\n    <span class=\"c1\">//首先分配GPU上的内存\n</span><span class=\"c1\"></span>    <span class=\"n\">cudaMalloc</span><span class=\"p\">((</span><span class=\"kt\">void</span><span class=\"o\">**</span><span class=\"p\">)</span><span class=\"o\">&amp;</span><span class=\"n\">d_in</span><span class=\"p\">,</span> <span class=\"n\">imgheight</span><span class=\"o\">*</span><span class=\"n\">imgwidth</span><span class=\"o\">*</span><span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">uchar3</span><span class=\"p\">));</span>\n    <span class=\"n\">cudaMalloc</span><span class=\"p\">((</span><span class=\"kt\">void</span><span class=\"o\">**</span><span class=\"p\">)</span><span class=\"o\">&amp;</span><span class=\"n\">d_out</span><span class=\"p\">,</span> <span class=\"n\">imgheight</span><span class=\"o\">*</span><span class=\"n\">imgwidth</span><span class=\"o\">*</span><span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">unsigned</span> <span class=\"kt\">char</span><span class=\"p\">));</span>\n\n    <span class=\"c1\">//将主机端数据拷贝到GPU上\n</span><span class=\"c1\"></span>    <span class=\"n\">cudaMemcpy</span><span class=\"p\">(</span><span class=\"n\">d_in</span><span class=\"p\">,</span> <span class=\"n\">srcImage</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">imgheight</span><span class=\"o\">*</span><span class=\"n\">imgwidth</span><span class=\"o\">*</span><span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">uchar3</span><span class=\"p\">),</span> <span class=\"n\">cudaMemcpyHostToDevice</span><span class=\"p\">);</span>\n\n    <span class=\"c1\">//每个线程处理一个像素\n</span><span class=\"c1\"></span>    <span class=\"n\">dim3</span> <span class=\"n\">threadsPerBlock</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">);</span>\n    <span class=\"n\">dim3</span> <span class=\"n\">blocksPerGrid</span><span class=\"p\">((</span><span class=\"n\">imgwidth</span> <span class=\"o\">+</span> <span class=\"n\">threadsPerBlock</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">threadsPerBlock</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">,</span>\n        <span class=\"p\">(</span><span class=\"n\">imgheight</span> <span class=\"o\">+</span> <span class=\"n\">threadsPerBlock</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">threadsPerBlock</span><span class=\"p\">.</span><span class=\"n\">y</span><span class=\"p\">);</span>\n\n    <span class=\"n\">clock_t</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"p\">;</span>\n    <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"n\">clock</span><span class=\"p\">();</span>\n\n    <span class=\"c1\">//启动内核\n</span><span class=\"c1\"></span>    <span class=\"n\">rgb2grayincuda</span><span class=\"o\">&lt;&lt;</span> <span class=\"o\">&lt;</span><span class=\"n\">blocksPerGrid</span><span class=\"p\">,</span> <span class=\"n\">threadsPerBlock</span><span class=\"o\">&gt;&gt;</span> <span class=\"o\">&gt;</span><span class=\"p\">(</span><span class=\"n\">d_in</span><span class=\"p\">,</span> <span class=\"n\">d_out</span><span class=\"p\">,</span> <span class=\"n\">imgheight</span><span class=\"p\">,</span> <span class=\"n\">imgwidth</span><span class=\"p\">);</span>\n\n    <span class=\"c1\">//执行内核是一个异步操作，因此需要同步以测量准确时间\n</span><span class=\"c1\"></span>    <span class=\"n\">cudaDeviceSynchronize</span><span class=\"p\">();</span>\n    <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"n\">clock</span><span class=\"p\">();</span>\n\n    <span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">&#34;cuda exec time is %.8f</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"kt\">double</span><span class=\"p\">)(</span><span class=\"n\">end</span><span class=\"o\">-</span><span class=\"n\">start</span><span class=\"p\">)</span><span class=\"o\">/</span><span class=\"n\">CLOCKS_PER_SEC</span><span class=\"p\">);</span>\n\n    <span class=\"c1\">//拷贝回来数据\n</span><span class=\"c1\"></span>    <span class=\"n\">cudaMemcpy</span><span class=\"p\">(</span><span class=\"n\">grayImage</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">d_out</span><span class=\"p\">,</span> <span class=\"n\">imgheight</span><span class=\"o\">*</span><span class=\"n\">imgwidth</span><span class=\"o\">*</span><span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">unsigned</span> <span class=\"kt\">char</span><span class=\"p\">),</span> <span class=\"n\">cudaMemcpyDeviceToHost</span><span class=\"p\">);</span>\n\n    <span class=\"c1\">//释放显存\n</span><span class=\"c1\"></span>    <span class=\"n\">cudaFree</span><span class=\"p\">(</span><span class=\"n\">d_in</span><span class=\"p\">);</span>\n    <span class=\"n\">cudaFree</span><span class=\"p\">(</span><span class=\"n\">d_out</span><span class=\"p\">);</span>\n\n    <span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"s\">&#34;grayImage&#34;</span><span class=\"p\">,</span> <span class=\"n\">grayImage</span><span class=\"p\">);</span>\n    <span class=\"n\">waitKey</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n\n<span class=\"p\">}</span>\n</code></pre></div><p>这里我对比了CUDA、CPU、OPENCV三种实现方式的执行时间：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-65b97530b0ddd438d1db022f23acf484_b.jpg\" data-size=\"normal\" data-rawwidth=\"357\" data-rawheight=\"62\" class=\"content_image\" width=\"357\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;357&#39; height=&#39;62&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"357\" data-rawheight=\"62\" class=\"content_image lazy\" width=\"357\" data-actualsrc=\"https://pic1.zhimg.com/v2-65b97530b0ddd438d1db022f23acf484_b.jpg\"/><figcaption>CUDA、CPU、OPENCV执行时间对比</figcaption></figure><p>速度：CUDA&gt;OPENCV&gt;CPU。其中OPENCV快于CPU的主要原因是OPENCV调用了并行运算指令，但慢于CUDA。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>附上CMakeLists.txt：</p><div class=\"highlight\"><pre><code class=\"language-text\">cmake_minimum_required(VERSION 2.8)\nproject(testcuda)\nfind_package(CUDA REQUIRED)\nfind_package(OpenCV REQUIRED)\ncuda_add_executable(testcuda main.cu)\ntarget_link_libraries(testcuda ${OpenCV_LIBS})</code></pre></div><hr/><p><i>水水的介绍到此结束，剩下的我就要放飞自我了，看不懂别怪我</i></p><hr/><h2>Chapter 3 编程接口</h2><p>CUDA的编程接口由一系列C语言的扩展和运行库(runtime library)组成。  </p><p>C语言的扩展在第二章“编程模型”中有所提及，如内核函数、线程网格和线程块等；<br/> 运行库则是在CUDA Driver API的基础上建立的。用户可以直接在应用程序中跳过CUDA，直接调用CUDA Driver API，以便更底层地操作GPU，如操作GPU的上下文。不过对于大多数应用来说，使用CUDA提供的运行库就足够了。</p><p>本章讲首先讲解CUDA程序的编译过程，之后会介绍CUDA运行库，最后会介绍程序兼容性等问题。</p><h2>3.1 使用NVCC编译CUDA程序</h2><p>CUDA程序使用NVCC编译器。<br/> NVCC提供了简单方便的接口，能够很好的同时处理主机端和设备端代码。这里将简要介绍NVCC编译CUDA程序的流程，更多信息请参考nvcc user manual。</p><h2>3.1.1 编译流程</h2><h2>3.1.1.1 离线编译</h2><p>NVCC进行离线编译的操作流程是：<br/> <i> 分离CUDA程序中的主机端代码(host code)和设备端代码(device code) </i> 将设备端代码编译成一种虚拟汇编文件(名为PTX)，再接着编译成二进制代码(名为cubin) <i> 将主机端代码中含有&#34;&lt;&lt;&lt;&gt;&gt;&gt;&#34;的代码(即内核调用)替换为CUDA运行库中的函数调用代码 </i> 之后NVCC会借助其他编译器(如gcc)将主机端代码编译出来 * 主机端代码和设备端代码被编译好后，nvcc会将两段代码链接起来</p><h2>3.1.1.2 在线编译(JIT Compilation)</h2><p>PTX是一个虚拟汇编文件。其形式虽然很像汇编，但里面的每一条指令实际上是一个虚拟的指令，与机器码无法对应。需要编译器或设备驱动程序将其翻译成对应平台的汇编/机器码才能运行。</p><p>如果在编译过程中，NVCC不将设备端代码编译为cubin文件，即二进制代码，而是停在PTX代码上。设备驱动(device driver)会负责在运行时，使用PTX代码生成二进制代码。这个过程被称作在线编译(JIT Compilation, Just-In-Time Compilation)。</p><p>在线编译必然会使得程序启动的时间延长，不过设备驱动程序会自动缓存编译出来的二进制代码(也被称作compute cache)。</p><p>在线编译一方面的优势在于兼容性。另一方面的优势在于，当设备驱动程序有关编译的部分得到优化时，同样的PTX编出来的cubin文件同样会得到优化。也就是说，一段祖传的PTX代码，很有可能因为驱动程序不断的优化，而躺着得到了优化。而如果直接离线编译得到了cubin文件的话，则无法享受到这一优化。</p><h2>3.1.2 二进制代码的兼容性</h2><p>二进制代码cubin是受到GPU计算能力的限制的。在编译时，需要使用<code>-code</code>来指定将代码编译到哪个计算能力平台上，如<code>-code=sm_35</code>代表生成的cubin代码是运行在计算能力为3.5的平台上的。</p><p>二进制代码若要兼容，首先架构得一致。不同架构上的二进制代码不能互相兼容，如在Maxwell架构上编译出来的代码，不能在其他架构上运行。<br/> 其次，若执行平台的次版本号版本比编译时指定的的次版本号高，则可以运行。例如如果在编译时指定<code>-code=sm_35</code>，则在计算能力3.7的平台上也可以运行。反之则不可以。</p><p>另外需要说明的是，上述二进制代码的兼容性原则只限于桌面款显卡。</p><h2>3.1.3 PTX代码的兼容性</h2><p>PTX代码的兼容性远强于二进制代码。只要不涉及到不同架构上的特性差异，PTX可以在任何架构上运行。</p><p>不过PTX代码在两种情况下其兼容性会受限：<br/> 1. 若PTX代码使用了较高级别架构的特有特性，则无法在较低架构上运行。例如若PTX代码用到了计算能力3.0以上才能使用的Warp Shuffle特性，则无法在2.x或1.x平台上运行。 2. 若PTX在较低架构上生成，则虽然能够在所有更高级别的架构上运行，但无法充分利用这些架构的硬件特性，造成性能无法最大化的问题。</p><p>在编译时，可以通过<code>-arch</code>来指定生成的PTX代码的版本，如<code>-arch=compute_30</code>。</p><h2>3.1.4 应用程序兼容性</h2><p>为了保证应用程序的兼容性，最好是将代码编译成PTX代码，然后依靠各个计算能力的驱动程序在线编译成对应平台的二进制代码cubin。</p><p>除了使用<code>-arch</code>和<code>-code</code>来分别指定C-&gt;PTX和PTX-&gt;cubin的计算能力外，还可以用<code>-gencode</code>关键字来操作，如下例：</p><div class=\"highlight\"><pre><code class=\"language-text\">nvcc x.cu\n    -gencode arch=compute_35,code=sm_35\n    -gencode arch=compute_50,code=sm_50\n    -gencode arch=compute_60,code=\\&#39;compute_60,sm_60\\&#39;</code></pre></div><p>使用上述编译指令后，会生成3.5/5.0/6.0的cubin文件，以及6.0的PTX代码。具体内容请参考nvcc user manual。</p><p>对于主机端代码，会自动编译，并在运行时决定调用哪一个版本的执行。对于上例，主机端代码会编译为：3.5/5.0/6.0的二进制文件，以及7.0的PTX文件。</p><p>另外，在程序中可以使用<code>__CUDA_ARCH__</code>宏来指定计算能力(只能用于修饰设备端代码)。计算能力3.5在程序中对应的<code>__CUDA_ARCH__</code>为350。</p><p>有一点需要注意的是，7.0以前，都是以线程束为单位在调度，线程束内指令永远是同步的，被成为<b>锁步</b>。而Volta架构(计算能力7.x)引入了Independent Thread Scheduling，破坏了线程束内的隐式同步。因此，如果老版本的代码里面有默认锁步的代码，在Volta架构下运行时可能会因为锁步的消失而出问题，可以指定<code>-arch=compute_60 -code=sm_70</code>，即将PTX编到Pascal架构下以禁用Independent Thread Scheduling特性。（当然，也可以修改代码来显示同步）</p><p>另外，版本相关编译指令有缩写的情况，具体看手册。</p><h2>3.1.5 C/C++兼容性</h2><p>对于主机端代码，nvcc支持C++的全部特性；而对于设备端代码，只支持C++的部分特性。具体查阅手册。</p><h2>3.1.6 32/64位兼容性</h2><p>当且仅当主机端代码按照64位编译时，设备端代码才能编译为64位。当主机端代码编译为32位时，设备端代码只能编译成32位。即设备端代码的位数和主机端永远保持一致。</p><p>具体编译成32/64位的哪一种，取决于nvcc本身的版本。32位nvcc会自动编出32位的代码，不过可以使用<code>-m64</code>来编出64位代码。对于64位编译器亦然。</p><h2>3.2 CUDA C 运行库</h2><p>运行库实际上在cudart库内，可以使静态链接库<code>cudart.lib/libcudart.a</code>，或者动态链接库<code>cudart.dll/cudart.so</code>。</p><p>所有程序的入口都是<code>cuda</code>。</p><h2>3.2.1 初始化</h2><p>CUDA运行库没有显式的初始化函数，在调用第一个函数时会自动初始化(设备和版本管理函数不行)。初始化时，会产生一个全局可见的设备上下文(device context)。</p><p>当主机端代码调用了<code>cudaDeviceReset()</code>函数，则会销毁掉这个上下文。注意，销毁的上下文是主机端正在操纵的设备。如要更换，需要使用<code>cudaSetDevice()</code>来进行切换。</p><h2>3.2.2 设备内存</h2><p>CUDA运行库提供了函数以分配/释放设备端的内存，以及与主机端内存传输数据。</p><p>这里的设备内存，指的是全局内存+常量内存+纹理内存。</p><p>设备内存有两种分配模式：线性存储(linear memory)、CUDA arrays。 其中CUDA arrays与纹理内存有关，本导读略去不谈。</p><p>线性内存是我们常用的内存方式，在GPU上用40位的地址线寻址。线性内存可以用<code>cudaMalloc()</code>分配，用<code>cudaFree()</code>释放，用<code>cudaMemcpy()</code>复制数据，用<code>cudaMemset()</code>赋值。</p><p>对于2D或3D数组，可以使用<code>cudaMallocPitch()</code>和<code>cudaMalloc3D()</code>来分配内存。这两个函数会自动padding，以满足内存对齐的要求，提高内存读写效率。内存对齐的问题，会在第五章里详细阐述。</p><p>另外，如果要在设备内存中定义全局变量，则需要使用使用<code>__constant__</code>或<code>__device__</code>来修饰，并使用<code>cudaMemcpyToSymbol()</code>和<code>cudaMemcpyFromSymbol()</code>来读写。如下例：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">__constant__</span> <span class=\"kt\">float</span> <span class=\"n\">constData</span><span class=\"p\">[</span><span class=\"mi\">256</span><span class=\"p\">];</span>\n<span class=\"kt\">float</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"mi\">256</span><span class=\"p\">];</span>\n<span class=\"n\">cudaMemcpyToSymbol</span><span class=\"p\">(</span><span class=\"n\">constData</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">));</span>\n<span class=\"n\">cudaMemcpyFromSymbol</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">constData</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">));</span>\n\n<span class=\"n\">__device__</span> <span class=\"kt\">float</span> <span class=\"n\">devData</span><span class=\"p\">;</span>\n<span class=\"kt\">float</span> <span class=\"n\">value</span> <span class=\"o\">=</span> <span class=\"mf\">3.14f</span><span class=\"p\">;</span>\n<span class=\"n\">cudaMemcpyToSymbol</span><span class=\"p\">(</span><span class=\"n\">devData</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">float</span><span class=\"p\">));</span>\n\n<span class=\"n\">__device__</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">devPointer</span><span class=\"p\">;</span>\n<span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">ptr</span><span class=\"p\">;</span>\n<span class=\"n\">cudaMalloc</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">ptr</span><span class=\"p\">,</span> <span class=\"mi\">256</span> <span class=\"o\">*</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">float</span><span class=\"p\">));</span>\n<span class=\"n\">cudaMemcpyToSymbol</span><span class=\"p\">(</span><span class=\"n\">devPointer</span><span class=\"p\">,</span> <span class=\"o\">&amp;</span><span class=\"n\">ptr</span><span class=\"p\">,</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"n\">ptr</span><span class=\"p\">));</span>\n</code></pre></div><p>实际上，当使用<code>__constant__</code>关键字时，是申请了一块常量内存；而使用<code>__device__</code>时，是普通的全局内存。因此<code>__device__</code>申请的内存需要申请，而<code>__constant__</code>不用。不管是全局内存，还是常量内存，需要用带有<code>Symbol</code>的函数拷贝。</p><h2>3.2.3 共享内存</h2><p>不管是全局变量还是局部变量，都需要使用<code>__shared__</code>来修饰。不过需要注意的是，即使定义为全局变量，共享内存依旧只能被同一线程块内的线程可见。</p><p>举个例子，对于如下代码，虽然是定义了一个全局的共享内存hist_shared，但实际上，在每一个线程块被调度到SM上时，都会在SM的共享内存区开一块内存。因此，每一个线程块都有一个hist_shared，且之间无法互相访问。</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">__shared__</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">int</span> <span class=\"n\">hist_shared</span><span class=\"p\">[</span><span class=\"mi\">256</span><span class=\"p\">];</span>   <span class=\"c1\">//共享内存仅在线程块内共享\n</span><span class=\"c1\"></span>\n<span class=\"n\">__global__</span> <span class=\"kt\">void</span> <span class=\"nf\">getGrayHistincuda_usesharemem</span><span class=\"p\">(</span><span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"o\">*</span> <span class=\"k\">const</span> <span class=\"n\">grayData</span><span class=\"p\">,</span> \n                                            <span class=\"kt\">unsigned</span> <span class=\"kt\">int</span> <span class=\"o\">*</span> <span class=\"k\">const</span> <span class=\"n\">hist</span><span class=\"p\">,</span>\n                                            <span class=\"n\">uint</span> <span class=\"n\">imgheight</span><span class=\"p\">,</span>\n                                            <span class=\"n\">uint</span> <span class=\"n\">imgwidth</span><span class=\"p\">)</span>  <span class=\"c1\">//使用共享内存加速\n</span><span class=\"c1\"></span><span class=\"p\">{</span>\n    <span class=\"k\">const</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">int</span> <span class=\"n\">idx</span> <span class=\"o\">=</span> <span class=\"n\">blockDim</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">*</span> <span class=\"n\">blockIdx</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">;</span>\n    <span class=\"k\">const</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">int</span> <span class=\"n\">idy</span> <span class=\"o\">=</span> <span class=\"n\">blockDim</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">*</span> <span class=\"n\">blockIdx</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">+</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">y</span><span class=\"p\">;</span>  \n    <span class=\"k\">const</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"n\">inner_idx</span> <span class=\"o\">=</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">*</span> <span class=\"n\">blockDim</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">;</span>\n\n    <span class=\"n\">hist_shared</span><span class=\"p\">[</span><span class=\"n\">inner_idx</span><span class=\"o\">%</span><span class=\"mi\">256</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>   <span class=\"c1\">//清空数据，由于每个块的inner_idx可以超过256，所以这样可以保证hist_shared被全部清零\n</span><span class=\"c1\"></span>\n    <span class=\"n\">__syncthreads</span><span class=\"p\">();</span>    <span class=\"c1\">//等待其他线程完成\n</span><span class=\"c1\"></span>\n    <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">idx</span> <span class=\"o\">&lt;</span> <span class=\"n\">imgwidth</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">idy</span> <span class=\"o\">&lt;</span> <span class=\"n\">imgheight</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"k\">const</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">long</span> <span class=\"n\">pid</span> <span class=\"o\">=</span> <span class=\"n\">imgwidth</span> <span class=\"o\">*</span> <span class=\"n\">idy</span> <span class=\"o\">+</span> <span class=\"n\">idx</span><span class=\"p\">;</span>\n        <span class=\"k\">const</span> <span class=\"kt\">unsigned</span> <span class=\"kt\">char</span> <span class=\"n\">value</span> <span class=\"o\">=</span> <span class=\"n\">grayData</span><span class=\"p\">[</span><span class=\"n\">pid</span><span class=\"p\">];</span>\n        <span class=\"n\">atomicAdd</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"p\">(</span><span class=\"n\">hist_shared</span><span class=\"p\">[</span><span class=\"n\">value</span><span class=\"p\">]),</span> <span class=\"mi\">1</span><span class=\"p\">);</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">__syncthreads</span><span class=\"p\">();</span>\n\n    <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">&lt;</span> <span class=\"mi\">8</span><span class=\"p\">)</span> <span class=\"c1\">//每个线程块将自己共享内存中的值合并到全局内存中去\n</span><span class=\"c1\"></span>    <span class=\"p\">{</span>\n        <span class=\"n\">atomicAdd</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"p\">(</span><span class=\"n\">hist</span><span class=\"p\">[</span><span class=\"n\">inner_idx</span><span class=\"p\">]),</span> <span class=\"n\">hist_shared</span><span class=\"p\">[</span><span class=\"n\">inner_idx</span><span class=\"p\">]);</span>\n    <span class=\"p\">}</span>\n\n<span class=\"p\">}</span>\n</code></pre></div><p>当然，共享内存的声明放在内核函数里面也是可以的，效果一致。</p><p>使用共享内存，可以获得等同于L1 cache的访存速度，其速度远快于全局内存。</p><p>但是注意，并不是什么时候都可以使用共享内存来获取加速的。例如内核函数计算出来结果后，如果这个结果只需要传输回主机端，而不需要再次被用到时，直接写回全局内存会比较快。如果先写回共享内存，再写回全局内存，反而会比较缓慢。<br/> 一般来讲，当需要频繁读写，或是有原子操作时，使用共享内存替代全局内存，会取得比较大的增益。</p><p>强调一下，共享内存只能为线程块内的线程共享。如果需要整个线程网格中线程都能访问，则需要全局内存或常量内存。</p><p>另外，共享内存是一个稀缺资源。有些架构可以通过配置，分配L1 cache和共享内存的比例。</p><h2>3.2.4 锁页内存(Page-Locked Host Memory/Pinned Memory)</h2><p>锁页内存指的是主机端上不会被换出到虚拟内存(位于硬盘)上的内存。  </p><p>锁页内存的分配与释放：<br/> 在CUDA程序中，使用<code>cudaHostAlloc()</code>，可以分配锁页内存，使用<code>cudaFreeHost()</code>来释放锁页内存<br/> 或者使用<code>cudaHostRegister()</code>来将<code>malloc()</code>分配的内存指定为锁页内存</p><p>NVIDIA官方给出的锁页内存相对于普通的内存的的好处是：<br/> <i> 使用锁页内存后，锁页内存与设备内存之间的数据传输，可以使用流的方式，和内核函数执行并行。 </i> 使用锁页内存后，可以将锁页内存映射到设备内存上。 <i> 对于使用</i>前端总线*的系统，使用锁页内存可以提升主机端到设备端传输的带宽；<br/> 如果将锁页内存指定为合并写(write_combining)，则可以进一步提高带宽。</p><p>另一本书对于锁页内存之所以快的解释是：<br/> <i> 如果主机端将数据放在锁页内存，则可以使用PCI-E的DMA与设备内存进行数据传输，而不需要CPU来搬运数据。 这也是为何使用了锁页内存后，可以使用流和内存映射，来让CPU程序、数据传输和内核执行并行。 </i> 如果主机端将数据放在普通内存，则CUDA会先申请一块锁页内存，然后将数据拷贝到锁页内存，再做后面的操作。 拷贝的过程浪费了一定时间。</p><p>注意，锁页内存在 <i>non I/O coherent Tegra</i> 设备上不支持</p><h2>3.2.4.1 Portable Memory</h2><p>NVIDIA官方文档表示：上述所说的锁页内存的优点，只有在使用<code>cudaHostAlloc()</code>时，传入<code>cudaHostAllocPortable</code> flag，或者在使用<code>cudaHostRegister()</code>时传入<code>cudaHostRegisterPortable</code> flag，才能体现。否则锁页内存并不会有上述优点。</p><p>《GPU编程指南》一书中是这么描述的：如果传入了<code>cudaHostAllocPortable</code> flag，则锁页内存在所有的CUDA上下文中变成锁页的和可见的。如果需要在CUDA上下文之间或者主机处理器的线程之间传递指针，则必须使用这个标志。</p><p><i>(好吧，从编程指南一书中确实没出来用Portable的必要性，不是很明白)</i></p><h2>3.2.4.2 合并写内存(Write-Combining Memory)</h2><p>锁页内存默认是使用缓存的。如果将flag <code>cudaHostAllocWriteCombined</code> 传入到 <code>cudaHostAlloc()</code>，则可以将这块锁页内存指定为合并写内存。</p><p>合并写内存不再使用主机端的L1&amp;L2 cache，使得更多的cache可以供其他任务使用。</p><p>另外，对于通过PCI-E传输数据的情景，使用合并写内存不会被snooped <i>(是不是指的是不会被缓存管？不理解这个snooped什么意思)</i>，可以提升40%的传输性能。</p><p>此外需要注意的是，由于合并写内存不使用缓存，因此读入CPU核的操作会<b>非常的慢</b>。因此合并写内存最好只用作向GPU传数据的内存，而不是传回数据的内存。</p><h2>3.2.4.3 内存映射(Mapped Memory)</h2><p>CUDA中的内存映射，指的是将CPU端的锁页内存，映射到GPU端。</p><p>通过向<code>cudaHostAlloc()</code>传入<code>cudaHostAllocMapped</code> flag，或向<code>cudaHostRegister()</code>传入<code>cudaHostAllocMapped</code> flag，来将一块内存指定为向GPU映射的内存。</p><p>映射的内存有两个地址，一个是CPU端访问的地址，一个是GPU端访问的地址。<br/> CPU端的地址在调用<code>malloc()</code>或<code>cudaHostAlloc()</code>时就已经返回； GPU端的地址使用<code>cudaHostGetDevicePointer()</code>函数来获取。</p><p>使用内存映射有以下好处：<br/> <i> 使用内存映射，可以让CPU/GPU之间的数据传输隐式执行，而不需要显示的分配GPU内存并传输数据。</i><br/><i> 当设备端执行内核函数需要某一块数据时，如果数据实际上在CPU端，会给出一个PCI-E传输请求(比全局内存还慢)，从主机端内存获取数据。此时给出数据请求的线程会被换出，直到数据就位后再被换入。因此如果使用内存映射，需要使用足够多的线程来隐藏PCI-E的传输延迟。 </i> 内存映射可以替代流，实现数据传输和内核执行的并行  有一点不是很确定：内存映射是否会在GPU端缓存数据；据我的记忆是不会缓存的，因此多次请求同一块数据的话，会启动多个PCI-E传输，效率很低  <i>不清楚内存映射在GPU更新后，CPU端数据会何时更新。是在CPU访问这些数据时？还是自动更新？</i></p><p>使用内存映射必须要注意的几点：<br/> <i> 由于映射的内存会被CPU和GPU两方共享，因此程序需要注意数据同步问题 </i> 如果要使用内存映射，必须在其他CUDA函数执行前，执行<code>cudaSetDeviceFlags()</code>并传入<code>cudaDeviceMapHost</code>，来使能设备的内存映射功能。否则<code>cudaHostGetDevicePointer()</code>函数会返回error。 <i> 如果设备本身不支持内存映射，则使用<code>cudaHostGetDevicePointer()</code>一定会返回error。可以通过查看设备的<code>canMapHostMemory</code>信息来确认。 </i> 如果使用原子操作(atomicXXX)，需要注意，主机端和设备端的同时操作是不原子的。</p><h2>3.2.5 异步并行执行</h2><p>CUDA允许以下操作互相并行：<br/> <i> 主机端计算 </i> 设备端计算(内核执行) <i> 主机端to设备端传数据 </i> 设备端to主机端传数据 <i> 设备端内部传数据 </i> 设备间传数据(可通过PCI-E直接传输，不需要先传到主机端再转发，<i>不过这一操作跟使用的操作系统有关</i>)</p><h2>3.2.5.1 主机端/设备端并行</h2><p>设备端的如下操作，可以跟主机端并行：</p><ul><li><i>内核启动与执行(可以通过将<code>CUDA_LAUNCH_BLOCKING</code>设为1，来disable内核执行并行，debug使用) </i> </li><li>设备端内部传输数据 <i> 64KB及以下的 host-to-device数据传输 </i> </li><li>使用流(带有<code>Async</code>前缀的内存传输函数)或内存映射传输数据（不再受64KB的限制）</li><li>设备端memset函数(<code>cudaMemset()</code>)</li></ul><p>其中第3、4条说明，在使用<code>cudaMemcpy()</code>时，如果数据小于等于64KB，其实传输相对于CPU是异步的。 如果数据多于64KB，则CPU会阻塞<i>到数据传输完成</i>。 这时使用带<code>Async</code>的内存传输函数，会释放CPU资源。<br/> 使用<code>Async</code>传输函数，不仅可以和CPU并行，而且可以和内核执行并行。</p><p>需要注意的是，如果没有使用锁页内存，即使使用了<code>Async</code>函数，内存传输也不是并行的(<i>和CPU？还是GPU？</i>)。</p><h2>3.2.5.2 内核并行执行</h2><p>计算能力2.x及以上的设备，支持多个内核函数同时执行。(可以通过检查<code>concurrentKernels</code>来确定)</p><p><b>执行多个内核函数，需要主机端不同的线程启动。如果一个线程依次启动多个内核，则这些内核会串行执行。同一线程的内核函数返回时会触发隐式的同步。</b></p><p>另外，多个内核函数必须位于同一个CUDA上下文(CUDA context)上。不同CUDA上下文上的内核不能并行。这意味着，启动多个内核的多个线程必须使用相同的CUDA上下文。(<i>如何传递CUDA上下文？</i>)</p><h2>3.2.5.3 数据传输和内核执行并行(需要使用锁页内存)</h2><p>一些设备支持数据传输(主机端/设备端、设备端/设备端)和内核执行并行，可通过检查<code>asyncEngineCount</code>来确认。</p><p>一些设备支持设备端内部数据传输和内核执行/数据传输并行，可通过检查<code>concurrentKernels</code>来确认。</p><p>这一特性需要使用锁页内存。</p><h2>3.2.5.4 数据并行传输(需要使用锁页内存)</h2><p>计算能力2.x及以上的设备，支持数据传入和传出并行。</p><p>必须使用锁页内存。</p><h2>3.2.5.5 流(streams)</h2><p>在CUDA中，流(streams)指的是在GPU上一连串执行的命令。</p><p>不同的线程，可以向同一个流填入任务。</p><p>同一个流内的任务会按顺序执行；同一设备上不同的流有可能并行，其执行顺序不会有保证。</p><h2>3.2.5.5.1 流的创建和销毁</h2><p>下述代码是一个流的创建和销毁的例子。该程序创建了两个流，分配了两个锁页内存传输数据，依次启动了两个内核，最后销毁了这两个流。</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cudaStream_t</span> <span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">2</span><span class=\"p\">;</span> <span class=\"o\">++</span><span class=\"n\">i</span><span class=\"p\">)</span>\n    <span class=\"n\">cudaStreamCreate</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n<span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">hostPtr</span><span class=\"p\">;</span>\n<span class=\"n\">cudaMallocHost</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">hostPtr</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">);</span>\n\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">2</span><span class=\"p\">;</span> <span class=\"o\">++</span><span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">cudaMemcpyAsync</span><span class=\"p\">(</span><span class=\"n\">inputDevPtr</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">hostPtr</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span>\n                    <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">cudaMemcpyHostToDevice</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n    <span class=\"n\">MyKernel</span> <span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">&gt;&gt;&gt;</span>\n        <span class=\"p\">(</span><span class=\"n\">outputDevPtr</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">inputDevPtr</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">);</span>\n    <span class=\"n\">cudaMemcpyAsync</span><span class=\"p\">(</span><span class=\"n\">hostPtr</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">outputDevPtr</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span>\n                    <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">cudaMemcpyDeviceToHost</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">2</span><span class=\"p\">;</span> <span class=\"o\">++</span><span class=\"n\">i</span><span class=\"p\">)</span>\n    <span class=\"n\">cudaStreamDestroy</span><span class=\"p\">(</span><span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n</code></pre></div><p>从上例中可以看到，流的创建需要定义<code>cudaStream_t</code>结构，并调用<code>cudaStreamCreate()</code>来初始化。<br/> 流的销毁需要调用<code>cudaStreamDestroy()</code>来实现。</p><p>当向流中添加内核函数任务时，<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>不再是<code>&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;</code>，而是<code>&lt;&lt;&lt;blocksPerGrid, threadsPerBlock, dynamic_shared_memory, stream&gt;&gt;&gt;</code>。<br/> 其中dynamic_shared_memory指的是动态共享内存的大小(<i>回去翻书</i>)； stream就是<code>cudaStream_t</code>结构。</p><p>当设备还在执行流中的任务，而用户调用<code>cudaStreamDestroy()</code>函数时，函数会立刻执行(不会阻塞)。之后，当流中的任务完成后，与流相关的资源会自动释放。</p><p><b>另外需要注意的是，上例中主机端线程、数据拷贝和内核执行完全异步，因此在&#34;拷贝回主机端&#34;这一操作完成之前，主机端的内存数据是不正确的。必须在数据返回的一步做同步操作，方能保证数据是正确的。</b></p><p><i>(需要了解一下流内部是如何实现的，为什么内核执行和内存拷贝能够异步且重叠？什么样的操作又不能重叠？)</i></p><h2>3.2.5.5.2 默认流(Default Stream)</h2><p>在调用内核函数时，不指定流或者将流指定为0，则代表使用了默认流(default stream)。</p><p>如果在编译时使用了<code>--default-stream per-thread</code>，或是在include任何cuda头文件前<code>#define CUDA_API_PER_THREAD_DEFAULT_STREAM</code>，则主机端的每一个线程都有自己专属的默认流。<br/> 而如果在编译时未指定相关flag，或指定<code>--default-stream legacy</code>，则默认流是一个特殊的流，称作NULL stream。主机端的所有线程会共享这个NULL stream。NULL stream是一个同步流，所有命令会产生隐式的同步。</p><h2>3.2.5.5.3 显式同步(Explicit Synchronization)</h2><p>可以使用如下函数进行显式同步：<br/> <i><code>cudaDeviceSynchronize()</code>：直到<b>所有线程</b>向设备端的<b>所有流</b>的<b>所有已送入指令</b>完成，才会退出阻塞。 </i> <code>cudaStreamSynchronize()</code>：直到<b>指定流</b>的<b>之前所有已送入指令</b>完成，才会退出阻塞。此函数可以用作同步指定流，而其他流可以不受干扰地继续运行。  <i><code>cudaStreamWaitEvent()</code>：需要stream和event作为输入参数。在调用该函数之后的命令，需要等待该函数等待的事件(Event)发生后，才能执行。如果stream指定为0，则对于向所有stream加入的命令来说，只要加在了该函数之后，都会阻塞直到等待的时间发生方可执行。 </i>(不知道我理解的对不对：如果是Event-&gt;内核1-&gt;WaitEvent-&gt;内核2，则内核1不用等到Event发生就可以执行，而内核2必须等到Event发生才能执行。还是说内核1其实只有等待Event发生后才会执行？) (如果多个线程向同一个流压入了任务，然后线程0调用了cudaStreamWaitEvent()，则线程1会不会被阻塞？线程1压入的任务会不会被阻塞？)  <code>cudaStreamQuery()</code>：查询流内所有压入的指令(preceding commands)是否全部完成。</p><p>注意，同步函数慎用，因为有可能会产生速度的下降。</p><h2>3.2.5.5.4 隐式同步(Implicit Synchronization)</h2><p>一般来讲，不同流内的命令可以并行。但是当任何一个流执行如下的命令时，情况例外，不能并行：<br/> <i> 锁页内存的分配 </i> 设备端内存分配 <i> 设备端内存设置(memset) </i> 设备内部拷贝 <i> NULL stream内的命令 </i> L1 cache/共享内存空间的重新分配</p><h2>3.2.5.5.5 操作重叠(Overlapping Behavior)</h2><p>操作的重叠程度，一方面取决于各个操作的顺序，另一方面取决于设备支持重叠的程度(是否支持内核执行并行/数据传输与内核执行并行/数据传输并行)</p><h2>3.2.5.5.6 回调函数(Callbacks)</h2><p>可以使用<code>cudaStreamAddCallback()</code>函数，向流中添加callback。该callback会在流中之前所有的任务完成后被调用。如果stream参数设为0，则代表之前的所有stream的任务执行完后就调用该callback。</p><p>回调函数和<code>cudaStreamWaitEvent()</code>一样，对于在加在callback之后的指令，必须等待callback<i>执行完成</i>后，才会继续执行。</p><p>下例是一个使用回调的例子。该例中，两个stream将数据拷回主机端后，会调用回调函数。</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">void</span> <span class=\"n\">CUDART_CB</span> <span class=\"nf\">MyCallback</span><span class=\"p\">(</span><span class=\"n\">cudaStream_t</span> <span class=\"n\">stream</span><span class=\"p\">,</span> <span class=\"n\">cudaError_t</span> <span class=\"n\">status</span><span class=\"p\">,</span> <span class=\"kt\">void</span> <span class=\"o\">*</span><span class=\"n\">data</span><span class=\"p\">){</span>\n    <span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">&#34;Inside callback %d</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">size_t</span><span class=\"p\">)</span><span class=\"n\">data</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n<span class=\"p\">...</span>\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">2</span><span class=\"p\">;</span> <span class=\"o\">++</span><span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">cudaMemcpyAsync</span><span class=\"p\">(</span><span class=\"n\">devPtrIn</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">hostPtr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">cudaMemcpyHostToDevice</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n    <span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">(</span><span class=\"n\">devPtrOut</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">devPtrIn</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">size</span><span class=\"p\">);</span>\n    <span class=\"n\">cudaMemcpyAsync</span><span class=\"p\">(</span><span class=\"n\">hostPtr</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">devPtrOut</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">cudaMemcpyDeviceToHost</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n    <span class=\"n\">cudaStreamAddCallback</span><span class=\"p\">(</span><span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">MyCallback</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"kt\">void</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>回调函数中不能直接或间接的执行CUDA函数，否则会因为等待自己完成而造成死锁。 <i>(原因尚不太明白)</i></p><h2>3.2.5.5.7 流的优先级(Stream Priorities)</h2><p>可以通过<code>cudaStreamCreateWithPriority()</code>来在创建流时指定流的优先级。可以指定的优先级可由<code>cudaDeviceGetStreamPriorityRange()</code>来获得。</p><p>运行时，高优先级stream中的线程块不能打断正在执行的低优先级stream的线程块(即不是抢占式的)。但是当低优先级stream的线程块退出SM时，高优先级stream中的线程块会被优先调度进SM。</p><h2>3.2.5.6 事件(Event)</h2><p>事件(Event)可以被压入流中以监视流的运行情况，或者用于精确计时。</p><p>如果向stream 0压入事件，则当压入事件前向所有流压入的任务完成后，事件才被触发。</p><h2>3.2.5.6.1 事件的创建和销毁</h2><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cudaEvent_t</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">stop</span><span class=\"p\">;</span>    <span class=\"c1\">//创建\n</span><span class=\"c1\"></span><span class=\"n\">cudaEventCreate</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">start</span><span class=\"p\">);</span>\n<span class=\"n\">cudaEventCreate</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">stop</span><span class=\"p\">);</span>\n<span class=\"p\">...</span>\n<span class=\"n\">cudaEventDestroy</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">);</span>    <span class=\"c1\">//销毁\n</span><span class=\"c1\"></span><span class=\"n\">cudaEventDestroy</span><span class=\"p\">(</span><span class=\"n\">stop</span><span class=\"p\">);</span>\n</code></pre></div><h2>3.2.5.6.2 计算时间</h2><p>下例是一个使用Event计算时间的例子：  </p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cudaEventRecord</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">);</span>  <span class=\"c1\">//记录事件(将事件压入流)，流0则代表所有流完成任务后事件才会被触发\n</span><span class=\"c1\"></span><span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">2</span><span class=\"p\">;</span> <span class=\"o\">++</span><span class=\"n\">i</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">cudaMemcpyAsync</span><span class=\"p\">(</span><span class=\"n\">inputDev</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">inputHost</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">cudaMemcpyHostToDevice</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n    <span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">(</span><span class=\"n\">outputDev</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">inputDev</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">);</span>\n    <span class=\"n\">cudaMemcpyAsync</span><span class=\"p\">(</span><span class=\"n\">outputHost</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">outputDev</span> <span class=\"o\">+</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">cudaMemcpyDeviceToHost</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n<span class=\"p\">}</span>\n<span class=\"n\">cudaEventRecord</span><span class=\"p\">(</span><span class=\"n\">stop</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">);</span>\n<span class=\"n\">cudaEventSynchronize</span><span class=\"p\">(</span><span class=\"n\">stop</span><span class=\"p\">);</span>\n<span class=\"kt\">float</span> <span class=\"n\">elapsedTime</span><span class=\"p\">;</span>\n<span class=\"n\">cudaEventElapsedTime</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">elapsedTime</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">stop</span><span class=\"p\">);</span>    <span class=\"c1\">//获取两个事件发生的时间差(ms)\n</span></code></pre></div><h2>3.2.6 多设备系统(Multi-Device System)</h2><h2>3.2.6.1 设备枚举(Device Enumeration)</h2><p>下例是如何枚举设备，并获取设备信息的例子：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"n\">deviceCount</span><span class=\"p\">;</span>\n<span class=\"n\">cudaGetDeviceCount</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">deviceCount</span><span class=\"p\">);</span>   <span class=\"c1\">//获取设备数量\n</span><span class=\"c1\"></span><span class=\"kt\">int</span> <span class=\"n\">device</span><span class=\"p\">;</span>\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">device</span> <span class=\"o\">&lt;</span> <span class=\"n\">deviceCount</span><span class=\"p\">;</span> <span class=\"o\">++</span><span class=\"n\">device</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">cudaDeviceProp</span> <span class=\"n\">deviceProp</span><span class=\"p\">;</span>\n    <span class=\"n\">cudaGetDeviceProperties</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">deviceProp</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">);</span>\n    <span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">&#34;Device %d has compute capability %d.%d.</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">deviceProp</span><span class=\"p\">.</span><span class=\"n\">major</span><span class=\"p\">,</span> <span class=\"n\">deviceProp</span><span class=\"p\">.</span><span class=\"n\">minor</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div><h2>3.2.6.2 设备选择(Device Selection)</h2><p>使用<code>cudaSetDevice()</code>选择设备，当不选择时，默认使用设备0。</p><p>注意，所有的内存分配、内核函数启动、流和事件的创建等，都是针对当前选择的设备的。</p><p>下例是一个设备选择的例子：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">size_t</span> <span class=\"n\">size</span> <span class=\"o\">=</span> <span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">float</span><span class=\"p\">);</span>\n<span class=\"n\">cudaSetDevice</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>   <span class=\"c1\">// Set device 0 as current\n</span><span class=\"c1\"></span><span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">p0</span><span class=\"p\">;</span>\n<span class=\"n\">cudaMalloc</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">p0</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">);</span>  <span class=\"c1\">// Allocate memory on device 0\n</span><span class=\"c1\"></span><span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">(</span><span class=\"n\">p0</span><span class=\"p\">);</span>    <span class=\"c1\">// Launch kernel on device 0\n</span><span class=\"c1\"></span><span class=\"n\">cudaSetDevice</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>   <span class=\"c1\">// Set device 1 as current\n</span><span class=\"c1\"></span><span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">p1</span><span class=\"p\">;</span>\n<span class=\"n\">cudaMalloc</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">p1</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">);</span>  <span class=\"c1\">// Allocate memory on device 1\n</span><span class=\"c1\"></span><span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">(</span><span class=\"n\">p1</span><span class=\"p\">);</span> <span class=\"c1\">// Launch kernel on device 1\n</span></code></pre></div><h2>3.2.6.3 (多设备下)流和事件的执行情况</h2><p>下面将讨论，如果对一个不属于当前设备的流或事件进行操作，哪些操作会成功，哪些操作会失败：</p><ul><li><b>内核启动</b>(will fail)：如果将内核压入不属于当前设备的流中，则内核会启动失败。也就是说，如果要向一个流中压入内核，必须先切换到流所在的设备：</li></ul><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cudaSetDevice</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>   <span class=\"c1\">// Set device 0 as current\n</span><span class=\"c1\"></span><span class=\"n\">cudaStream_t</span> <span class=\"n\">s0</span><span class=\"p\">;</span>\n<span class=\"n\">cudaStreamCreate</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">s0</span><span class=\"p\">);</span>  <span class=\"c1\">// Create stream s0 on device 0\n</span><span class=\"c1\"></span><span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">s0</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">();</span> <span class=\"c1\">// Launch kernel on device 0 in s0\n</span><span class=\"c1\"></span><span class=\"n\">cudaSetDevice</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>   <span class=\"c1\">// Set device 1 as current\n</span><span class=\"c1\"></span><span class=\"n\">cudaStream_t</span> <span class=\"n\">s1</span><span class=\"p\">;</span>\n<span class=\"n\">cudaStreamCreate</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">s1</span><span class=\"p\">);</span>  <span class=\"c1\">// Create stream s1 on device 1\n</span><span class=\"c1\"></span><span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">s1</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">();</span> <span class=\"c1\">// Launch kernel on device 1 in s1\n</span><span class=\"c1\"></span>\n<span class=\"c1\">// This kernel launch will fail:\n</span><span class=\"c1\"></span><span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">s0</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">();</span> <span class=\"c1\">// Launch kernel on device 1 in s0\n</span></code></pre></div><ul><li><b>内存拷贝</b>(will success)：如果对一个不属于当前设备的流进行内存拷贝工作，内存拷贝会成功。</li><li><b>cudaEventRecord()</b>(will fail)：必须现将设备上下文切换过去，再向流压入事件。</li><li><b>cudaEventElapsedTime()</b>(will fail)：计算时间差前，必须先切换设备。</li><li><b>cudaEventSynchronize() and cudaEventQuery()</b>(will success)：即使处于不同的设备，事件同步和事件查询依然有效。</li><li><b>cudaStreamWaitEvent()</b>(will success)：比较特殊，即使函数输入的流和事件不在同一个设备上，也能成功执行。也就是说，可以让流等待另一个设备上(当然当前设备也可以)的事件。这个函数可以用作多个设备间的同步。</li></ul><p>另外需要注意，<b>每个设备都有自己的默认流</b>。因此在没有指定流的情况下，向不同设备分派的任务，实际上是压入了各个设备的默认流，他们之间是并行执行的。</p><h2>3.2.6.4 (设备间)对等内存访问(Peer-to-Peer Memory Access)</h2><p>计算能力2.0及以上的设备支持设备间对等内存访问，这意味着两个GPU之间的传输和访问可以不经过主机端中转，速度会有提升。查询<code>cudaDeviceCanAccessPeer()</code>可以得知设备是否支持这一特性。<i>(官方文档说还需要一个条件：64位程序，存疑)</i></p><p>需要使用<code>cudaDeviceEnablePeerAccess()</code>来使能这一特性。</p><p>对等设备的的地址是统一编址的，可用同一个指针访问，如下例：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cudaSetDevice</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>   <span class=\"c1\">// Set device 0 as current\n</span><span class=\"c1\"></span><span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">p0</span><span class=\"p\">;</span>\n<span class=\"n\">size_t</span> <span class=\"n\">size</span> <span class=\"o\">=</span> <span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">float</span><span class=\"p\">);</span>\n<span class=\"n\">cudaMalloc</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">p0</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">);</span>      <span class=\"c1\">// Allocate memory on device 0\n</span><span class=\"c1\"></span><span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">(</span><span class=\"n\">p0</span><span class=\"p\">);</span>    <span class=\"c1\">// Launch kernel on device 0\n</span><span class=\"c1\"></span><span class=\"n\">cudaSetDevice</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>               <span class=\"c1\">// Set device 1 as current\n</span><span class=\"c1\"></span><span class=\"n\">cudaDeviceEnablePeerAccess</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">);</span>   <span class=\"c1\">// Enable peer-to-peer access with device 0\n</span><span class=\"c1\"></span>\n<span class=\"c1\">// Launch kernel on device 1\n</span><span class=\"c1\">// This kernel launch can access memory on device 0 at address p0\n</span><span class=\"c1\"></span><span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">(</span><span class=\"n\">p0</span><span class=\"p\">);</span>\n</code></pre></div><h2>3.2.6.5 (设备间)对等内存拷贝(Peer-to-Peer Memory Copy)</h2><p>对等设备的地址是统一编址的，可以使用<code>cudaMemcpyPeer()、cudaMemcpyPeerAsync()、cudaMemcpy3DPeer、cudaMemcpy3DPeerAsync()</code>来进行直接拷贝。无需先拷贝会主机端内存，再转到另一块卡上。如下例：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">cudaSetDevice</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>   <span class=\"c1\">// Set device 0 as current\n</span><span class=\"c1\"></span><span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">p0</span><span class=\"p\">;</span>\n<span class=\"n\">size_t</span> <span class=\"n\">size</span> <span class=\"o\">=</span> <span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">float</span><span class=\"p\">);</span>\n<span class=\"n\">cudaMalloc</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">p0</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">);</span>  <span class=\"c1\">// Allocate memory on device 0\n</span><span class=\"c1\"></span><span class=\"n\">cudaSetDevice</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n<span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">p1</span><span class=\"p\">;</span>\n<span class=\"n\">cudaMalloc</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">p1</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">);</span>  <span class=\"c1\">// Allocate memory on device 1\n</span><span class=\"c1\"></span><span class=\"n\">cudaSetDevice</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>       <span class=\"c1\">// Set Device 0 as Current\n</span><span class=\"c1\"></span><span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">(</span><span class=\"n\">p0</span><span class=\"p\">);</span>    <span class=\"c1\">// Launch Kernel on Device 0\n</span><span class=\"c1\"></span><span class=\"n\">cudaSetDevice</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>               <span class=\"c1\">// Set Device 1 as Current\n</span><span class=\"c1\"></span><span class=\"n\">cudaMemcpyPeer</span><span class=\"p\">(</span><span class=\"n\">p1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">p0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">);</span> <span class=\"c1\">// Copy p0 to p1\n</span><span class=\"c1\"></span><span class=\"n\">MyKernel</span><span class=\"o\">&lt;&lt;&lt;</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"o\">&gt;&gt;&gt;</span><span class=\"p\">(</span><span class=\"n\">p1</span><span class=\"p\">);</span>        <span class=\"c1\">// Launch Kernel on Device 1\n</span></code></pre></div><p>关于设备间的对等拷贝，如果使用的是NULL stream，则有如下性质：<br/> <i> 如果拷贝的双方中的任何一方，在设备拷贝前有任务未完成，则拷贝会被阻塞，直至任务完成。 </i> 只有拷贝结束后，两者的后续任务才能继续执行。</p><p><i>(使用的如果不是NULL Stream，又会怎样呢？)</i></p><h2>3.2.7 统一虚拟地址空间(Unified Virtual Address Space)</h2><p>当程序是64位程序时，所有主机端内存，以及计算能力≥2.0的设备的内存是统一编址的。所有通过CUDA API分配的主机内存和设备内存，都在统一编址的范围内，有自己的虚拟地址。因此：</p><ul><li>可以通过<code>cudaPointerGetAttributes()</code>，来确定指针所指的内存处在主机端还是设备端。</li><li>进行拷贝时，可以将<code>cudaMemcpy***()</code>中的<code>cudaMemcpyKind</code>参数设置为<code>cudaMemcpyDefault</code>，去让函数根据指针所处的位置自行判断应该是从哪里拷到哪里。</li><li>使用<code>cudaHostAlloc()</code>分配的锁页内存，自动是<i>Portable</i>的，所有支持统一虚拟编址的设备均可访问。<code>cudaHostAlloc()</code>返回的指针，无需通过<code>cudaHostGetDevicePointer()</code>，就可以直接被设备端使用。</li></ul><p>可以通过查询<code>unifiedAddressing</code>来查看设备是否支持统一虚拟编址。</p><h2>3.2.8 进程间通讯(Interprocess Communication)</h2><p>线程间通讯，可以很方便的通过共享的变量来实现。然而进程间通讯不行。</p><p>为了在进程间共享设备端内存的指针或者事件，必须使用IPC(Inter Process Communication) API。IPC API只支持64位程序，并且要求设备计算能力≥2.0。</p><p>通过IPC中的<code>cudaIpcGetMemHandle()</code>，可以得到设备内存指针的IPC句柄。该句柄可以通过标准的IPC机制(interprocess shared memory or files)传递到另一个进程，再使用<code>cudaIpcOpenMemHandle()</code>解码得到该进程可以使用的设备内存指针。<br/> 事件的共享也是如此。</p><h2>3.2.9 错误检查(Error Checking)</h2><p>所有的runtime function都会返回一个error code，可通过检查error code判断是否出错。</p><p>但是对于异步函数，由于在执行前就会返回，因此返回的error code仅仅代表函数启动时的错误(如参数校验)；异步函数不会返回运行时出现的错误。如果运行时出了错，会被后面的某个函数捕获并返回。</p><p>检查异步函数是否出错的唯一方式，就是在异步函数启动后，进行同步。 如在异步函数后，调用<code>cudaDeviceSynchronize()</code>，则异步函数的错误会被<code>cudaDeviceSynchronize()</code>捕获到。</p><p>事实上，除了runtime function会返回error code之外，每一个主机端线程都会有一个初始化为<code>cudaSuccess</code>的变量，用于指示错误。一旦发生了错误，该变量也会被设置为相应的error code。</p><p>该变量不会被直接调用，但可以被<code>cudaPeekAtLastError()</code>和<code>cudaGetLastError()</code>访问到。不同的是，<code>cudaGetLastError()</code>在返回这一变量的同时，会把它重置为<code>cudaSuccess</code>。</p><p>内核函数不会返回值，因此只能通过<code>cudaPeekAtLastError()</code>或<code>cudaGetLastError()</code>来知悉<b>调用内核</b>是否有错误。<br/> 当然，为了排除错误出现在调用内核之前就有错误，可以先检验之前的错误变量是否为<code>cudaSuccess</code>。</p><p>另外需要注意的是，<code>cudaStreamQuery()</code>和<code>cudaEventQuery()</code>这类函数，有可能会返回<code>cudaErrorNotReady</code>。但这不被认为是错误，因此不会被<code>cudaPeekAtLastError()</code>和<code>cudaGetLastError()</code>捕获到。</p><h2>3.2.10 调用栈(Call Stack)</h2><p>对于计算能力≥2.0的设备，可以通过<code>cudaDeviceGetLimit()</code>/<code>cudaDeviceSetLimit()</code>来查询/设置调用栈的大小。</p><h2>3.2.11 纹理内存</h2><p>略</p><h2>3.2.12 Graphics Interoperability</h2><p>略</p><h2>3.3 版本和兼容性(Versioning and Compatibility)</h2><p>有两个版本需要注意：计算能力，以及CUDA driver API的版本。其中计算能力及其兼容性在前面已有阐述。</p><p>CUDA driver API的版本定义在驱动的头文件中的<code>CUDA_VERSION</code>宏内。可以在程序中将该宏调出，以检查程序是否可以在目标设备上运行。</p><p>CUDA driver API不是向前兼容的。也就是说，针对新版本的CUDA driver API编译的程序、插件、库，并不能在旧版本的驱动上运行。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4df8b897a1c36d1dbc8aa3e93167ba36_b.jpg\" data-size=\"normal\" data-rawwidth=\"522\" data-rawheight=\"490\" class=\"origin_image zh-lightbox-thumb\" width=\"522\" data-original=\"https://pic3.zhimg.com/v2-4df8b897a1c36d1dbc8aa3e93167ba36_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;522&#39; height=&#39;490&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"522\" data-rawheight=\"490\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"522\" data-original=\"https://pic3.zhimg.com/v2-4df8b897a1c36d1dbc8aa3e93167ba36_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4df8b897a1c36d1dbc8aa3e93167ba36_b.jpg\"/><figcaption>CUDA Driver API 兼容性</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>关于CUDA driver API，有几点需要注意：</p><ul><li>由于一个系统只能装一个版本的驱动。因此驱动版本要足够高(至少程序所需的版本)，否则程序跑不起来。</li><li>默认情况下，nvcc编译程序时，库和插件是静态编译的。静态编译不要求库和插件的驱动版本和CUDA运行库保持一致。但是动态链接则要求版本一致。</li></ul><h2>3.4 计算模式(Compute Mode)</h2><p>NVIDIA的设备可以设置三种计算模式：<br/> <i> 默认模式(Default Compute Mode)：多个主机端线程可以同时使用一个设备(通过调用<code>cudaSetDevice()</code>) </i> 专属进程模式(Exclusive-Process Compute Mode)：对于一个设备，只能由一个进程创建设备上下文。一旦创建成功后，该进程的所有线程都可以使用该设备，而其他进程则不行。 * 禁止模式(Prohibited Compute Mode)：无法对设备建立CUDA上下文。</p><p>正常情况下，如果程序没有调用<code>cudaSetDevice()</code>，则会默认使用0号设备。但是如果0号设备被置成禁止模式，亦或是被其他进程所专属，则会在其他设备上创建上下文并使用。 可以向<code>cudaSetValidDevices()</code>函数输入一个设备列表，函数会在第一个可以使用的设备上创建上下文。</p><p>Pascal及以上架构，支持指令级的优先级调度。不再是以线程块为SM的最小调度单位，而是以指令为最小调度单位，且具有优先级。 这意味着具有冗长kernel的线程块不再会占据太多的计算资源，或是发生timeout。但是这也有缺点：当多个进程创建了上下文时，以往基于线程块的调度不会造成太多的上下文切换，但现在的指令级调度则会造成很多的上下文切换，降低效率。(注意跟GPU内线程的上下文切换不同，GPU内线程上下文切换几乎不浪费时间，直接换一个指针就好)。因此最好设置为Exclusive-process，这样只有一个进程会使用设备。<i>(如果线程很多的话，效果不是一样吗？)</i></p><p><i>(讲道理好好看看上下文是什么鬼)</i></p><p><i>(这段需要再看一下Pascal架构的说明，看看指令级的调度是如何实现的，寄存器等又是如何分配的)</i></p><p>设备处于哪种计算模式，可通过检查<code>computeMode</code>来查看。</p><h2>3.5 模式切换(Mode Switches)</h2><p>GPU会将一些内存专门分配给primary surface，用于刷新显示设备。 一旦用户将显示模式切换，如增加分辨率或增加彩色的位数，会造成primary surface所需的内存变多。此时系统会把原来分配给CUDA运算的内存，调拨给primary surface，从而造成CUDA runtime产生错误，并返回invalid context error。</p><p><i>(言外之意是说，跑cuda的时候不要切分辨率？)</i></p><h2>3.6 Tesla Compute Cluster Mode for Windows</h2><p>略</p><h2>Chapter 4 硬件架构</h2><h2>4.0 补充内容</h2><p>这份官方文档讲的硬件内容太少了，从另一本书里补一点过来，可能内容有点老旧，见谅。</p><h2>4.0.0 硬件结构</h2><p>(在一本比较老旧的书上找到的结构图)</p><p>下图是一款比较老旧的显卡(G80/GT200)的硬件结构图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4762cbbf22f55bcb020a3a2f8ee08b41_b.jpg\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1440\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-4762cbbf22f55bcb020a3a2f8ee08b41_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1440&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1440\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic2.zhimg.com/v2-4762cbbf22f55bcb020a3a2f8ee08b41_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4762cbbf22f55bcb020a3a2f8ee08b41_b.jpg\"/><figcaption>NVIDIA显卡硬件结构</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>从图中可以看到，GPU由内存和一系列流处理器簇(Streaming Multiprocessors, SM)组成，不同GPU的具有不同的内存大小和SM数量。<br/> 多个GPU可以挂载在PCI-E总线上，可以跟主机端或其他GPU通信。</p><p>流处理器簇(SM)内部结构如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-b1d2643a753885a3204e95fb22ed0192_b.jpg\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1440\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-b1d2643a753885a3204e95fb22ed0192_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1080&#39; height=&#39;1440&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1440\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https://pic3.zhimg.com/v2-b1d2643a753885a3204e95fb22ed0192_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-b1d2643a753885a3204e95fb22ed0192_b.jpg\"/><figcaption>SM内部结构</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>SM由一系列流处理器(Streaming Processor，SP)、寄存器文件(Register File)、共享内存(Shared Memory, SMem)、SPU(特殊运算单元)，以及纹理/常量/L1缓存组成。L2 cache是由所有SM共享的。</p><ul><li>流处理器(SP)：GPU的ALU单元，每个SP运行调度器分配给它的一个线程。<br/> 在CUDA编程模型里，32个线程(称为一个线程束)同时执行一套指令；但是实际调度时，是以半个线程束(16个线程)调度的。这对应了NVIDIA GPU的每个SM内，SP的数量都是16的整数倍。</li><li>寄存器文件：SM内的寄存器文件很大，大到分配到SM每个线程块内的每个线程，都可以拥有自己的寄存器空间。因此线程的上下文切换，实际上只需要换一下寄存器空间的指针即可，十分迅速。</li><li>共享内存：程序可控制的高速缓存。</li><li>特殊运算单元(SPU)：进行一些特殊运算。</li><li>纹理/常量/L1缓存。</li></ul><h2>4.0.1 调度过程</h2><p><b>线程块调度</b><br/> 当主机端启动内核时，会根据线程网格中的线程块(thread block)所需的寄存器和共享内存，决定将线程块调度到哪个SM上运行，或者等待调度(没有SM有足够的资源运行该线程块)。<br/> 只要资源足够，一个SM上可以同时运行多个线程块。<br/> 当线程块运行完毕时，线程块会退出SM，以供其他线程块被调度上去。  </p><p>另外需要强调一点的是，如果线程块需要的寄存器或共享内存太多，以至于SM连一个线程块都无法满足的时候，内核会启动失败。<br/> CUDA Toolkit提供了 CUDA Occupancy Calculator以供分析。</p><p><b>线程束调度</b><br/> 当线程块被调度到SM上后，具体调度到哪个SP上运行，是由SM内部的调度器执行的。<br/> NVIDIA GPU在逻辑上以32个线程(线程束)，作为最小调度单位。但实际上在硬件方面，是以半个线程束(16个线程)调度的。只不过调度器在调度了前半个线程束后，会立刻调度后半个线程束。调度过程如下图所示(计算能力2.0平台)：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5d6c5458962aa525e2d2b5731d6e3a73_b.jpg\" data-size=\"normal\" data-rawwidth=\"1440\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"1440\" data-original=\"https://pic4.zhimg.com/v2-5d6c5458962aa525e2d2b5731d6e3a73_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1440&#39; height=&#39;1080&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1440\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1440\" data-original=\"https://pic4.zhimg.com/v2-5d6c5458962aa525e2d2b5731d6e3a73_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5d6c5458962aa525e2d2b5731d6e3a73_b.jpg\"/><figcaption>CUDA线程束调度</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>当调度器选择调度线程束0时，第一个时钟周期会将半个线程束调度到第一个16xSP上，然后下一个周期会将另外半个线程束调度到另一个16xSP上。因此，调度一个完整的线程束0的指令，需要2个时钟周期。<br/> 上图所示的计算能力2.0的设备，具有两个调度器，刚好能够保证32个SP核可以连续工作。但前提是SM至少有2个线程束待调度。否则如果只有一个线程束的话，调度器0将会限制。</p><p>线程束有时会处于等待状态(等待内存，或等待特殊计算的结果)。此时调度器会调度其它线程束到SP上运行。当等待的线程束等到了所需的元素后，会再次处于就位状态，等待调度器调度运行。</p><p>不同计算能力的平台，具有不同的调度器数量和SP数量。</p><h2>4.1 SIMT架构</h2><p>NVIDIA GPU是典型的SIMT架构(Single-Instruction, Multiple-Thread Architecture，单指令多线程架构)。(半)线程束在同一时间内执行同样的指令(相同的PC)，但每个线程有自己的数据空间(寄存器)；可以同时做同样的事情，但是处理不同的数据。这样可以有效节省指令带宽(指令由线程束共享)，实现高效并行。</p><p>当线程束中的线程，必须要执行不同的条件分支时，满足分支条件的线程会被激活并执行分支内的内容；不满足分支条件的线程会接收同样的指令，但不会被激活，不会实际执行，但也不能跳过去执行其他指令。换言之，当线程束中的线程遇到分支时，不论线程是否需要执行分支，都会消耗执行该分支的时间，因为线程束中的线程执行同样的指令，是高度同步的。<br/> 举个例子，假如程序是按如下方式编写的：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"p\">...</span>\n<span class=\"k\">if</span><span class=\"p\">(</span><span class=\"err\">条件</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"err\">操作</span><span class=\"mi\">1</span>\n<span class=\"p\">}</span>\n<span class=\"k\">else</span>\n<span class=\"p\">{</span>\n    <span class=\"err\">操作</span><span class=\"mi\">2</span>\n<span class=\"p\">}</span>\n<span class=\"p\">...</span>\n</code></pre></div><p>如果是CPU，如果不满足条件，则会直接跳转去执行操作2，不会执行操作1。 但是对于GPU同一个线程束内的线程，即使不满足条件，依旧会去跟其他线程一起去执行操作1。等到操作1执行完毕后，该线程又会跟其他线程一起执行操作2。这也就意味着，不管线程实际上需不需要执行某一分支，它都要跟其他线程一起跑完这一分支。</p><p>另外，<b>GPU不支持分支预测和推测执行</b>，只会老老实实的一条条执行各个分支里的内容。因此，对于CUDA程序来说，分支实际上是一种低效的行为。</p><p>但是有两种情况是例外：<br/> <i> 线程束中所有线程均只需要执行一个分支，如线程束中的所有线程满足条件，则所有线程执行完操作1后，不会去执行操作2。 </i> 线程束中的半个线程束(线程0~15、线程16~31)同时满足条件，则这半个线程束不会去执行操作2(因为硬件实际上是按照半个线程束调度的)。</p><p>但是从Volta架构开始，Independent Thread Scheduling被引入，线程束内的线程不再完全同步。每个线程都会有自己独立的PC。遇到分支时，不再像之前的架构一样，只有(半)线程束内的线程条件一致时，才会跳过分支；Volta架构的调度优化器会将线程束中的线程，按照分支条件是否满足，重新组合成SIMT单元，从而跳过分支。</p><p>Volta架构的Independent Thread Scheduling无疑是高效的，但是这是一个跟旧架构完全不同的特性。在编写旧架构的CUDA程序时，程序员会默认线程束内的线程一定会同步执行。Volta架构的新特性破坏了这一假设，无疑会给程序带来一些问题，需要注意。</p><h2>4.1.1 线程的激活与原子操作</h2><p>在一个线程束中，参与当前指令的线程称为active threads，不参与的被称为inactive threads。造成线程inactive的原因有：</p><ul><li><i>某个线程比线程束中其他线程先退出(应该只发生在半线程束同时满足分支的情况，或是Volta架构上)。 </i> </li><li>在分支结构中，线程不满足当前分支的条件 </li><li>设置线程块大小时，为了补齐32的倍数而创建的线程(如线程块定义为31个线程，则会补1个线程，这个线程是inactive的)</li></ul><p>当线程束中所有线程，向同一个内存地址写数据时，不能保证哪个线程先写，哪个线程后写，即程序的正确性是无法保证的。 这时需要使用CUDA提供的原子操作(atomic)函数，如<code>atomicAdd()</code>。</p><p>原子操作可以保证程序的正确性，但是会造成线程束中线程的串行化(serialization)，执行时间比并行执行要长。</p><p>另外需要注意的是，即使没使用原子操作，向同一个内存地址写数据，一样也会产生一定程度的串行化，串行化程度依架构而定。不过这样，内存地址的数据时不确定的，可能会引入错误（除非程序刻意为之）。</p><h2>4.2 硬件多线程</h2><p>GPU线程束中的线程的上下文(寄存器&amp;PC等)都存在片内空间庞大的寄存器文件中，直到线程束执行完毕才会被释放(生命周期为整个线程束执行过程)。因此，不像CPU，GPU的线程束上下文切换十分迅速，没有损耗。 线程束调度器(warp scheduler)会选择ready状态的线程束，将其调度到SP上执行。</p><p>（这里跟硬件多线程的概念有点冲突，从另一本书上看到硬件多线程的概念是：一个核可以同时执行两个线程的指令，这是由多发射实现的。NVIDIA的GPU显然不是这个概念。姑且只理解为切换非常迅速吧）</p><h2>Chapter 5 性能优化</h2><h2>5.1 性能优化概述</h2><p>CUDA程序性能优化有三个原则：</p><ul><li><i>最大化并行，以提升资源利用率</i></li><li>优化内存排布，以最大化内存吞吐</li><li>最大化指令吞吐</li></ul><p>在性能优化前，需要先分析程序性能的瓶颈，再针对瓶颈优化，否则收益会很低。<br/> 分析程序瓶颈，可以使用CUDA profiler等工具。</p><h2>5.2 最大化利用率(Maximize Utilization)</h2><p>最大化利用率的方法就是并行。</p><h2>5.2.1 应用级别并行(Application Level)</h2><p>从程序最高层来看，应该尽可能让主机端、设备端、PCI-E总线并行工作。对此可以使用异步CUDA函数，以及流(Stream)来实现。</p><p>同步操作，以及内存的共享会影响程序的并行性。因此需要仔细设计算法流程，尽量减少同步和内存共享。 如果一定需要同步和内存共享，尽量在线程块内完成(线程块同步——使用<code>__syncthreads()</code>涉及到的线程少，且可以通过SM内的共享内存共享数据。如果需要线程网格内同步，则需要两个内核调用，且共享数据只能通过全局内存，速度慢)。</p><h2>5.2.2 设备级别并行(Device Level)</h2><p>可以通过流的方式，尽可能的让多个内核并行，提升利用率。</p><h2>5.2.3 处理器级别并行(Multiprocessor Level)</h2><p>延迟(latency)指的是线程束(从上一个动作开始)到它处于ready状态的时钟数。 例如线程束先提交了一个内存访问请求，然后等了400个时钟周期，内存管理系统才返回数据，线程束可以继续执行。这400个时钟周期称为延迟。</p><p>当一个线程束发生延迟时，线程束调度器(warp scheduler)会将其他处于ready状态的线程束调度到SP上。等到延迟结束后，再将该线程调度回SP继续执行。这样一来，前一个线程束的延迟，就被另一个线程束的执行所隐藏了。 这一过程被称作延迟的隐藏(hidden latency)。  </p><p>隐藏延迟是GPU编程的核心概念。由于GPU具有巨大的寄存器空间，线程的切换不存在损耗。因此，通过向GPU上分配足够多的线程，可以让这些线程延迟互相交错，以起到隐藏延迟的作用，提高硬件利用率。</p><p>造成线程(束)产生延迟的原因有：</p><ul><li><i>指令执行：不同指令有不同的执行延迟 </i> </li><li>内存请求：共享内存、全局内存、PCI-E(Mapped Memory)的读写请求 </li><li>同步操作：如使用<code>__syncthreads()</code>后，先完成的线程(束)，会等待线程块中其他线程(束)达到同步点。</li></ul><p>通过配置线程网格、线程块、寄存器和共享内存用量，让SM可以运行尽可能多的线程束，以隐藏延迟。例如对于计算能力3.x的设备，为了完全隐藏全局内存读取的延迟(200-400时钟)，需要大概40个线程束。</p><p>举个例子，设SM有32KB共享內存空间。程序每个线程需要32B共享內存，即一个线程束需要1KB共享內存，考虑下述两种方案：<br/> <i> 方案1：每个线程块有16个线程束，则每个线程块需要16KB共享內存。可以调度两个线程块到SM上。 </i> 方案2：每个线程块有18个线程束，则每个线程块需要18KB共享內存，则只能调度一个线程块到SM上。</p><p>虽然方案2在一个线程块上，有更多的线程束，但是实际上SM上运行的线程束减少了(32-&gt;18)。因此方案2隐藏延迟的能力弱于方案1，资源利用率较低。</p><p><i>此外，如果寄存器使用过多，超过了SM上的寄存器空间，则会使用本地内存作为寄存器。本地内存是存在在全局内存上的，速度很慢，会严重影响程序速度。因此需要严格考虑寄存器使用数量。</i> <i>(这里官方文档和另一本书里说的有矛盾，难道是新的架构把本地内存给取消掉了？)</i></p><p>最后强调一点，线程块中的线程数量，最好是32的整数倍。这样，就不会有为了补齐线程束，而出现的永远不会激活的线程。这些不激活的线程也会占用SM的资源，降低资源利用率。</p><p>CUDA具有Occupancy Calculator，帮助程序员设计。</p><h2>5.3 最大化内存吞吐(Maximize Memory Throughput)</h2><p>最大化内存吞吐，主要手段就是少用低带宽的内存。这意味着首先要尽可能减少主机端和设备端间的设备传输(PCI-E，特别慢)，其次要尽可能减少全局内存的读写(快于PCI-E，但是相对于片内内存来说，还是挺慢的)；尽可能的使用片内的内存(寄存器、cache、共享内存)。</p><p>这里需要强调一下cache和共享内存的事情。</p><p>共享内存是程序可控的高速缓存。一般情况下，共享内存的使用流程为： </p><ul><li><i>将数据从全局内存拷贝到共享内存，或初始化共享内存 </i> </li><li>进行一个同步操作，确保共享内存全部被赋值 </li><li><i>利用共享内存的数据，运行程序 </i> </li><li>如果出现了共享内存的写操作，一般需要进行一个同步操作，确保写操作全部完成后再进行下面的操作 </li><li>将数据写回全局内存</li></ul><p>这里有一点要强调，只有在数据需要反复读写的时候，共享内存才有意义。如果数据只会被读一次，处理完后又写回并不再处理。则直接从全局内存读出-&gt;寄存器运行-&gt;写回全局内存是最快的。在共享内存中转反而是慢的。</p><p>缓存(L1/L2 cache)是程序员无法显式编程的。但是如果了解缓存的特性的话，可以通过合适的程序设计，增加缓存命中率。<br/> <i>事实上，硬件控制的cache，拥有更好的数据局部性(locality)</i>。</p><h2>5.3.1 主机端和设备端间数据传输</h2><p>由于PCI-E传输并不快，因此要尽量减少主机端和设备端间的数据传输： <i> 一种方式是让中间结果尽可能的在设备端产生，在设备端使用。 </i> 另一种方式是将很多小的数据，打包传输。 <i> 还有可以通过分配锁页内存来加快前端总线</i>系统的带宽。</p><p>当使用内存映射时，需要注意，每次内存访问都会启动一次PCI-E传输。因此，尽量保证数据只被读写一次，且尽可能合并访问以提升有效内存带宽。</p><p>有些GPU设备，主机端和设备端内存，在物理上就是同一块。这种情况下，主机端和设备端传输是不存在的。可通过标志<code>integrated</code>来查看。</p><h2>5.3.2 设备内存访问</h2><h2>5.3.2.1 全局内存(global memory)</h2><p>全局内存支持合并访问，可以一次性传输连续的32、 64、 128字节的数据。因此，在设计内核时，线程束内的线程尽量连续的访问内存。</p><p>考虑如下两个内核：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"c1\">//假设gpuData是一个二维数组，尺寸为32x32\n</span><span class=\"c1\"></span><span class=\"kt\">int</span> <span class=\"n\">gpuData</span><span class=\"p\">[</span><span class=\"mi\">32</span><span class=\"p\">][</span><span class=\"mi\">32</span><span class=\"p\">];</span>  <span class=\"c1\">//这样是不合法的，因为这么定义实际上是在主机端，还需要拷贝到设备端，这里只是为了方便说明问题\n</span><span class=\"c1\"></span>\n<span class=\"n\">__global__</span> <span class=\"kt\">void</span> <span class=\"nf\">Kernel1</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">gpuData</span><span class=\"p\">[][</span><span class=\"mi\">32</span><span class=\"p\">])</span>\n<span class=\"p\">{</span>\n    <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">tid</span> <span class=\"o\">=</span> <span class=\"n\">blockIdx</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">*</span> <span class=\"n\">blockDim</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">sum</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n    <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">32</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"n\">sum</span> <span class=\"o\">+=</span> <span class=\"n\">gpuData</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"n\">tid</span><span class=\"p\">];</span> <span class=\"c1\">//行访问\n</span><span class=\"c1\"></span>    <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">__global__</span> <span class=\"kt\">void</span> <span class=\"nf\">Kernel2</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">gpu</span><span class=\"p\">[][</span><span class=\"mi\">32</span><span class=\"p\">])</span>\n<span class=\"p\">{</span>\n    <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">tid</span> <span class=\"o\">=</span> <span class=\"n\">blockIdx</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">*</span> <span class=\"n\">blockDim</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">sum</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n    <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">32</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"n\">sum</span> <span class=\"o\">+=</span> <span class=\"n\">gpuData</span><span class=\"p\">[</span><span class=\"n\">tid</span><span class=\"p\">][</span><span class=\"n\">i</span><span class=\"p\">];</span> <span class=\"c1\">//列访问\n</span><span class=\"c1\"></span>    <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>上例中，执行Kernel1的线程束中的线程，在一次循环中，32个线程依次访问<code>gpuData[0][0], gpuData[0][1], gpuData[0][2], ..., gpuData[0][31]</code>。在内存中，这32个变量是连续存储的，因此可以被合并访问。这种访问被称为行访问。<br/> 而Kernel2在一次循环中，读取的变量为<code>gpuData[0][0], gpuData[1][0], gpuData[2][0], ..., gpuData[31][0]</code>。这32个变量是不连续的，需要进行32次内存请求。这种访问被称为列访问。</p><p>上例中，列访问之所以效率低，原因有二：<br/> <i> 对于执行一次循环，行访问只需要一个内存请求指令，而列访问需要32个内存请求指令。从指令角度来讲，行访问的内存请求指令带宽是列访问的1/32。 </i> 全局内存的最大带宽为一次取128Byte，但是内核每次只需要4个Byte的数据。这使得列访问的内存带宽为峰值带宽的1/32。事实上，即使内核只需要4Byte，GPU也会取连续的<i>32Byte</i>，然后丢掉后面的28Byte，造成资源的浪费。但是缓存的引入(自计算能力2.x开始)，这一问题得到了缓解，28Byte会先放到缓存中，下次会命中。</p><p>因此，从上例中可以看到，好好安排内存排布，尽量使得内存访问可以合并，可以加速全局内存的读写。</p><h2>5.3.2.2 对齐(Alignment)</h2><p>当变量的尺寸为1/2/4/8/16字节时，变量会对齐。但如果不是的话，变量无法对齐，会产生额外的内存访问。</p><p>C/C++内建的变量(int/float等)，以及CUDA支持的向量(float2/float4等)，是对齐的。</p><p>一些结构体可能会产生不对齐的情况，看下例：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"k\">struct</span> <span class=\"n\">struct1</span><span class=\"p\">{</span>\n    <span class=\"kt\">float</span> <span class=\"n\">x</span><span class=\"p\">;</span>\n    <span class=\"kt\">float</span> <span class=\"n\">y</span><span class=\"p\">;</span>\n<span class=\"p\">};</span>\n\n<span class=\"k\">struct</span> <span class=\"n\">struct2</span><span class=\"p\">{</span>\n    <span class=\"kt\">float</span> <span class=\"n\">x</span><span class=\"p\">;</span>\n    <span class=\"kt\">float</span> <span class=\"n\">y</span><span class=\"p\">;</span>\n    <span class=\"kt\">float</span> <span class=\"n\">z</span><span class=\"p\">;</span>\n<span class=\"p\">};</span>\n\n<span class=\"k\">struct</span> <span class=\"n\">struct3</span> <span class=\"nf\">__align__</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">){</span>\n    <span class=\"kt\">float</span> <span class=\"n\">x</span><span class=\"p\">;</span>\n    <span class=\"kt\">float</span> <span class=\"n\">y</span><span class=\"p\">;</span>\n    <span class=\"kt\">float</span> <span class=\"n\">z</span><span class=\"p\">;</span>\n<span class=\"p\">};</span>\n</code></pre></div><p>上例中，struct1是8字节的结构体，自动会对齐； struct2具有12个字节，无法对齐； struct3使用了<code>__align__(16)</code>关键字，显式指定对齐到16。</p><p>使用各类malloc分配的设备内存，一定是256字节对齐的。</p><h2>5.3.2.3 本地内存(local memory)</h2><p>当使用了<i>自动变量(不明白，再看)</i>时，有可能会将数据放到本地内存上：<br/>  Arrays for which it cannot determine that they are indexed with constant quantities  大的结构体，寄存器放不下 * 寄存器溢出(register spilling)，即内核使用的寄存器多于SM上可用的寄存器</p><p>通过看PTX代码，可以看到标记为<code>.local</code>的变量，就是本地内存。<br/> 即使PTX代码里没有使用本地内存，在编译到cubin代码的过程中，仍然会使用本地内存，编译器会报告<code>lmem</code>的使用情况。</p><p>前面多次强调过了，一旦使用了本地内存，其速度会非常慢。不过本地内存在存储的时候，是按照32个线程连续存储的，因此可以合并访问。<br/> 对于计算能力3.x的设备，本地内存会被缓存在L1/L2 cahce；对于计算能力5.x和6.x设备，本地内存会被缓存到L2 cache。即便如此，其速度还是慢于寄存器。</p><h2>5.3.2.4 共享内存(shared memory)</h2><p>共享内存实际上是被分为多个存储体(memory bank)。多个线程访问同一个存储体会造成串行化。<br/> <i>(存疑：存储体其实是可以广播的，因此多个线程读同一个存储体是不存在冲突的，只是写会存在串行化问题)</i></p><p>因此，编写内核时，需要认真设计，以避免存储体访问的冲突。</p><h2>5.3.2.5 Texture and Surface Memory</h2><p>略</p><h2>5.4 最大化指令吞吐(Maximize Instruction Throughput)</h2><p>可以使用如下方法来最大化指令吞吐：</p><ul><li><i>尽量少使用吞吐率低的算数指令 </i> </li><li>尽量减少线程束内的分支 </li><li>尽量减少指令数，如少用<code>__syncthreads()</code>，或者在合适的时候使用<code>__restrict__</code></li></ul><p>指令吞吐的定义：<b>每个SP</b>在每个时钟周期内执行的操作数。如果一个线程束在一个时钟周期内执行了N个操作，则指令吞吐为N/32。</p><h2>5.4.1 算数指令(Arithmetic Instructions)</h2><p>官方文档这里比较混乱，但主要有如下几点： <i> 不同架构的设备，不同指令有不同的指令吞吐，可以查表 </i> 有一些快速的内联(inline)函数，如使用<code>__fdividef()</code>(快速浮点数除法)来代替普通的除法来加速 <i> 整形的除法和取余会比较慢，可能需要20个机器周期；因此对于n为2的幂次的情况，使用<code>i&gt;&gt;log2(n)</code>代替<code>i/n</code>，使用<code>i&amp;(n-1)</code>来代替<code>i%n</code></i>  半精度(浮点数)运算(Half Precision Arithmetic)：可以使用<code>half2</code>数据类型，并使用对应的运算指令(如<code>__hadd2, __hsub2, __hmul2, __hfma2</code>等)，来让一个周期内执行两次运算，以节省指令带宽。可以通过<code>__halves2half2</code>将两个半精度浮点数合并为<code>half2</code>数据类型。 <i>(半精度又是咋定义的？)</i> * 数据类型转换：当使用char或short，亦或是双精度常量与单精度变量相互操作时，会触发数据类型转换，需要一定执行时间(实际上，char和short，不管是存储在寄存器中，还是在运算时，都是以int型进行的)</p><h2>5.4.2 控制流指令(Control Flow Instructions)</h2><p>尽量避免向线程束中引入分支。</p><p>此外，可以使用<code>#pragma unroll</code>宏，来进行循环展开，减少控制指令。</p><h2>5.4.3 同步指令(Synchronization Instruction)</h2><p>下表为不同计算能力的设备，同步指令<code>__syncthreads()</code>需要消耗的指令周期为：<br/> |计算能力|<code>__syncthreads()消耗的指令周期</code>| |---|---| |3.x|128| |5.x,6.1,6.2|64| |6.0|32| |7.x|16|</p><p>注意，<code>__syncthreads()</code>会造成线程块中的线程等待，影响内核执行效率。</p>", 
            "topic": [
                {
                    "tag": "GPU 通用计算", 
                    "tagLink": "https://api.zhihu.com/topics/19570902"
                }, 
                {
                    "tag": "NVIDIA（英伟达）", 
                    "tagLink": "https://api.zhihu.com/topics/19562754"
                }, 
                {
                    "tag": "CUDA", 
                    "tagLink": "https://api.zhihu.com/topics/19597236"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "非常感谢您的文章。希望了解到更多有关volta构架的实践。谢谢！", 
                    "likes": 2, 
                    "childComments": [
                        {
                            "userName": "田子宸", 
                            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
                            "content": "本人也是菜鸟一枚，以后有机会会写的", 
                            "likes": 1, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "还是老老实实用 openacc[捂脸]", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "openacc不彻底的。隔靴挠痒", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }, 
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "openacc代码写起来至少要简单不少，跨平台性也很好。做科学计算至少是够了。", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "昵称什么的最讨厌的了", 
                    "userLink": "https://www.zhihu.com/people/1ff1b2f722b63c734f9d184a9966f31c", 
                    "content": "请教一下：英文文档看起来太吃力，老要查单词还查不到怎么办？", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "之月", 
                    "userLink": "https://www.zhihu.com/people/4a6d4cdcf26f8b851d2d68062421e24f", 
                    "content": "<p>RTX 现在还不能 Dynamic Parallelism 么？有一年没写 CUDA 了 。。。</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "Pjer", 
                    "userLink": "https://www.zhihu.com/people/3c13de714f625abc1057d2de1aeafbd9", 
                    "content": "您好，斗胆请求您把这篇投到我的专栏里", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "唐俊天", 
                    "userLink": "https://www.zhihu.com/people/0e12dea96428f82e60ef4a15038f6361", 
                    "content": "<p>谢谢你的文章</p>", 
                    "likes": 1, 
                    "childComments": []
                }, 
                {
                    "userName": "坚毅", 
                    "userLink": "https://www.zhihu.com/people/742f9f1294d28bd194fbf4725a0c25c3", 
                    "content": "感谢", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "两仪式", 
                    "userLink": "https://www.zhihu.com/people/d0ffe2ced3db1fbd6c2b002311d3e569", 
                    "content": "<p>非常感谢，一个调包侠莫名其妙就要开始写cuda了</p><a class=\"comment_sticker\" href=\"https://pic2.zhimg.com/v2-f941117b9911dd9af1a6b637fc22ee9d.gif\" data-width=\"\" data-height=\"\">[安慰]</a>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "nishuo", 
                    "userLink": "https://www.zhihu.com/people/32ae24e98a432ed125b75a92a3a9e3fc", 
                    "content": "优秀！", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/72375164", 
            "userName": "田子宸", 
            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
            "upvote": 61, 
            "title": "NCNN量化详解（二）", 
            "content": "<h2>0、 前言</h2><p>上次写了一个量化详解，讲了一下NCNN的量化前传过程。本以为是全部内容了，经评论区提醒NCNN最近刚刚更新了量化表的计算，因此写一篇文章把NCNN的量化表计算的算法与实现写下来。</p><p>上一篇的链接：</p><a href=\"https://zhuanlan.zhihu.com/p/71881443\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/equation.jpg\" data-image-width=\"0\" data-image-height=\"0\" class=\"internal\">田子宸：NCNN Conv量化详解（一）</a><p>本文的内容有：</p><ul><li>NCNN量化算法简介</li><li>NCNN量化表计算代码简析</li></ul><h2>1、 NCNN量化算法简介</h2><p>量化算法介绍的文章的话，下面这篇文章的大佬 <a class=\"member_mention\" href=\"https://www.zhihu.com/people/57e18bb3c0248525c9152cb0134a2641\" data-hash=\"57e18bb3c0248525c9152cb0134a2641\" data-hovercard=\"p$b$57e18bb3c0248525c9152cb0134a2641\">@章小龙</a> 介绍的比我好多啦。虽然介绍的是NVIDIA TensorRT的算法，但是NCNN是参考其算法做出来的，方法几乎一样（经评论区大佬指正，改过来了）。大家可以跳过我这段，看他的介绍就好。我只是想整理一下23333</p><a href=\"https://zhuanlan.zhihu.com/p/58182172\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic2.zhimg.com/v2-7f95901abc4ae49563fca4ee38d4bb65_180x120.jpg\" data-image-width=\"907\" data-image-height=\"138\" class=\"internal\">章小龙：Int8量化-介绍（一）</a><p>大家都跳过去了吗？都跳过去了的话，我就开始写我的笔记了</p><p>首先NVIDIA有一个PPT，很好的阐述了他们的方案，推荐大家也去看一下：</p><a href=\"https://link.zhihu.com/?target=http%3A//on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">on-demand.gputechconf.com</span><span class=\"invisible\">/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf</span><span class=\"ellipsis\"></span></a><h3><b>变换公式</b></h3><p>正常的量化，FP32 Value 和 INT8 Value之间的关系是这样的：</p><p><img src=\"https://www.zhihu.com/equation?tex=Value_%7Bfp32%7D+%3D+Scale_%7Bfp32%7D+%2A+Value_%7Bint8%7D+%2B+Bias_%7Bfp32%7D\" alt=\"Value_{fp32} = Scale_{fp32} * Value_{int8} + Bias_{fp32}\" eeimg=\"1\"/> </p><p>NVIDIA表示，Bias是没用的，因此变成了一个线性公式：</p><p><img src=\"https://www.zhihu.com/equation?tex=Value_%7Bfp32%7D+%3D+Scale_%7Bfp32%7D+%2A+Value_%7Bint8%7D\" alt=\"Value_{fp32} = Scale_{fp32} * Value_{int8}\" eeimg=\"1\"/> </p><h3><b>取值范围</b></h3><p>由于float32的取值范围几乎是无穷的，而int8只有-128~127。因此建立映射关系时，确定float32的取值范围很重要。</p><p>取指范围过大，则int8的精度会下降（想象一下，fp32的取值范围设置为了-1270.0~+1270.0，则0.0~+12.7里面的值，对应到int8都只是+1。若是真实数据就是这么分布的还好，但若是真实数据仅仅分布在-1.0~+1.0下，那么量化后所有的数据只有-1/0/+1三种，是不是精度很差？）</p><p>取指范围过小，则会截断过多的数据，导致分布靠两边的信息损失。</p><p>一个靠谱的想法是：找到fp32数据的最大值，以最大值为取值范围，岂不美哉？</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-847299a570c8bdd7ed778605ab2f520e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"564\" data-rawheight=\"348\" class=\"origin_image zh-lightbox-thumb\" width=\"564\" data-original=\"https://pic3.zhimg.com/v2-847299a570c8bdd7ed778605ab2f520e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;564&#39; height=&#39;348&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"564\" data-rawheight=\"348\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"564\" data-original=\"https://pic3.zhimg.com/v2-847299a570c8bdd7ed778605ab2f520e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-847299a570c8bdd7ed778605ab2f520e_b.jpg\"/></figure><p>但是，如果数据分布有偏差呢？NVIDIA的算法是选择一个阈值T，从而截断一部分的数据，令其饱和。通过合适的T，既可以保证不截断太多的数据，又可以保证分辨率，达到一个Trade-off：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5ba92b8ea620c91866bdd8b7d1b6045b_b.jpg\" data-size=\"normal\" data-rawwidth=\"865\" data-rawheight=\"257\" class=\"origin_image zh-lightbox-thumb\" width=\"865\" data-original=\"https://pic4.zhimg.com/v2-5ba92b8ea620c91866bdd8b7d1b6045b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;865&#39; height=&#39;257&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"865\" data-rawheight=\"257\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"865\" data-original=\"https://pic4.zhimg.com/v2-5ba92b8ea620c91866bdd8b7d1b6045b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5ba92b8ea620c91866bdd8b7d1b6045b_b.jpg\"/><figcaption>数据有偏差的情况，左边的方案是选最大的那个，右边是NVIDIA的算法，选择一个阈值T，达到精度和表示范围的trade-off</figcaption></figure><h3>计算Scale</h3><p>确定了阈值T后，其实也就能确定Scale了，一个简单的线性公式：</p><p><img src=\"https://www.zhihu.com/equation?tex=Scale+%3D+T%2F127\" alt=\"Scale = T/127\" eeimg=\"1\"/> </p><p>所以要计算Scale，只要找到合适的阈值T就可以了。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>那么“合适”要怎么判断呢？这里就引入了一个概念——KL散度。下面这篇文章介绍KL散度介绍得很好，推荐大家去看看：</p><a href=\"https://link.zhihu.com/?target=https%3A//www.cnblogs.com/liaohuiqiang/p/7673681.html\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">信息熵，交叉熵和相对熵 - PilgrimHui - 博客园</a><p>简单来讲，KL散度可以用来描述P、Q两个分布的差异。散度越小，两个分布的差异越小，概率密度函数形状和数值越接近。</p><p>我们假设量化前fp32的数据分布为P，量化后int8的数据分布为Q，那么只要让P和Q之间的KL散度越小，则表明量化前后的分布越接近，量化也就越有效啦</p><p><b>NCNN和NVIDIA TensorRT都以阈值T作为一个搜索的变量，每选择一个T，都去重新计算一下新阈值T下量化后的分布，然后计算一下KL散度。在计算了各个T下的KL散度后，选择令KL散度最小的那个T作为最终的T，从而确定Scale</b></p><h3>计算Scale时的一些小细节</h3><p>这里有一点说明一下，这里的所有分布、计算，都是离散形式的。分布是以统计直方图的方式存在，KL散度公式也是离散公式：</p><p><img src=\"https://www.zhihu.com/equation?tex=D_%7BKL%7D%28p%7C%7Cq%29+%3D+%5Csum_%7Bi%3D0%7D%5E%7BN%7D%7Bp%28i%29%2Alog%5Cfrac%7Bp%28i%29%7D%7Bq%28i%29%7D%7D\" alt=\"D_{KL}(p||q) = \\sum_{i=0}^{N}{p(i)*log\\frac{p(i)}{q(i)}}\" eeimg=\"1\"/> </p><p class=\"ztext-empty-paragraph\"><br/></p><p>从上式中我们还发现一个问题：KL散度计算公式要求P、Q两个统计直方图长度一样（也就是bins的数量一样）。Q还好，一直都是-127～127；可是P的数量会随着T的变化而变化。那这怎么做KL散度呢？</p><p>NCNN的做法是将Q扩展到和P一样的长度，下面举个例子(NVIDIA PPT中的例子)：</p><div class=\"highlight\"><pre><code class=\"language-text\">P=[1 2 2 3 5 3 1 7]     // fp32的统计直方图，T=8\n// 假设只量化到两个bins，即量化后的值只有-1/0/+1三种\nQ=[1+2+2+3, 5+3+1+7] = [8, 16]\n// P 和 Q现在没法做KL散度，所以要将Q扩展到和P一样的长度\nQ_expand = [8/4, 8/4, 8/4, 8/4, 16/4, 16/4, 16/4, 16/4] = [2 2 2 2 4 4 4 4]\nD = KL(P||Q_expand)  // 这样就可以做KL散度计算了</code></pre></div><p>这个扩展的操作，就像图像的上采样一样，将低精度的统计直方图(Q)，上采样的高精度的统计直方图上去(Q_expand)。由于Q中一个bin对应P中的4个bin，因此在Q上采样的Q_expand的过程中，所有的数据要除以4</p><p>但若分布P中有bin值为0时，NCNN是不算在内的：</p><div class=\"highlight\"><pre><code class=\"language-text\">P=[1 0 2 3 5 3 1 7]     // fp32的统计直方图，T=8\n// 假设只量化到两个bins，即量化后的值只有-1/0/+1三种\nQ=[1+0+2+3, 5+3+1+7] = [6, 16]\n// P 和 Q现在没法做KL散度，所以要将Q扩展到和P一样的长度\nQ_expand = [6/3, 0, 6/3, 6/3, 16/4, 16/4, 16/4, 16/4] = [2 0 2 2 4 4 4 4]  // P中有0时，不算在内\nD = KL(P||Q_expand)  // 这样就可以做KL散度计算了</code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><p>另外，在计算fp32的分布P时，被T截断的数据，是要算在最后一个bin里面的</p><h3>NCNN Scale计算流程</h3><p>具体的计算流程如下：</p><div class=\"highlight\"><pre><code class=\"language-text\">1. 计算fp32数据的最大绝对值max_abs_value = (abs(min_value), abs(max_value))\n2. 计算fp32数据的原始分布Po(P original)\n       值得一提的是，NCNN默认Po有2048个bins，即原始统计直方图每一个bin的长度interval = max_abs_value/2048\n3. for num_bins from 128 to 2048：\n   3.1  反推阈值T = interval * num_bins，使用T截断Po，得到分布P，P有num_bins个桶\n   3.2  将P量化到Q中，Q的桶数为128\n   3.3  将Q扩展到和P一样的长度，得到分布Q_expand\n   3.4  计算P和Q_expand的KL散度，并判断是否为最小</code></pre></div><p>这里的num_bins要解释一下。Po被固定分成了2048个bins，而num_bins的意思就是我要从这2048个bins中截断到那个bin，作为我的截断分布P。</p><p>更细的细节会在后面代码部分详解</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>2、 NCNN量化表计算代码简析</h2><p>NCNN的量化相关代码有两处：</p><ul><li>前传相关代码，在src/layer下，我在上一篇文章中已经分析过了</li><li>计算量化表相关代码，在tools/quantitze下，有两个文件，ncnn2table.cpp——计算量化表，ncnn2int8.cpp——通过量化表产生INT8模型</li></ul><h3>量化表的使用</h3><p>稍微解释一下，量化表说白了就是存储scale的一个表，由ncnn2table.cpp生成。在ncnn2int8.cpp中，代码读取量化表，读取模型文件，然后按照量化表中的scale将模型中的参数量化，然后将INT8存下来。代码如下：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"cm\">/* ncnn2int8.cpp */</span>\n<span class=\"kt\">int</span> <span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">argc</span><span class=\"p\">,</span> <span class=\"kt\">char</span><span class=\"o\">**</span> <span class=\"n\">argv</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">int8scale_table_path</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>   <span class=\"c1\">// 读取量化表，量化表由ncnn2table.cpp生成\n</span><span class=\"c1\"></span>        <span class=\"kt\">bool</span> <span class=\"n\">s2</span> <span class=\"o\">=</span> <span class=\"n\">read_int8scale_table</span><span class=\"p\">(</span><span class=\"n\">int8scale_table_path</span><span class=\"p\">,</span> <span class=\"n\">quantizer</span><span class=\"p\">.</span><span class=\"n\">blob_int8scale_table</span><span class=\"p\">,</span> <span class=\"n\">quantizer</span><span class=\"p\">.</span><span class=\"n\">weight_int8scale_table</span><span class=\"p\">);</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">s2</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span> <span class=\"s\">&#34;read_int8scale_table failed</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">);</span>\n            <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">quantizer</span><span class=\"p\">.</span><span class=\"n\">load_param</span><span class=\"p\">(</span><span class=\"n\">inparam</span><span class=\"p\">);</span>   <span class=\"c1\">// 读取模型文件\n</span><span class=\"c1\"></span>    <span class=\"n\">quantizer</span><span class=\"p\">.</span><span class=\"n\">load_model</span><span class=\"p\">(</span><span class=\"n\">inbin</span><span class=\"p\">);</span>\n    \n    <span class=\"n\">quantizer</span><span class=\"p\">.</span><span class=\"n\">quantize_convolution</span><span class=\"p\">();</span>   <span class=\"c1\">// 将conv、convdw、fc层参数量化\n</span><span class=\"c1\"></span>    <span class=\"n\">quantizer</span><span class=\"p\">.</span><span class=\"n\">quantize_convolutiondepthwise</span><span class=\"p\">();</span>\n    <span class=\"n\">quantizer</span><span class=\"p\">.</span><span class=\"n\">quantize_innerproduct</span><span class=\"p\">();</span>\n\n    <span class=\"n\">quantizer</span><span class=\"p\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"n\">outparam</span><span class=\"p\">,</span> <span class=\"n\">outbin</span><span class=\"p\">);</span>   <span class=\"c1\">// 存储模型文件\n</span><span class=\"c1\"></span>\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>其中conv、convdw、fc层量化的核心代码为：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">n</span><span class=\"o\">&lt;</span><span class=\"n\">convolution</span><span class=\"o\">-&gt;</span><span class=\"n\">num_output</span><span class=\"p\">;</span> <span class=\"n\">n</span><span class=\"o\">++</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n     <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Layer</span><span class=\"o\">*</span> <span class=\"n\">op</span> <span class=\"o\">=</span> <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">create_layer</span><span class=\"p\">(</span><span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">LayerType</span><span class=\"o\">::</span><span class=\"n\">Quantize</span><span class=\"p\">);</span>  <span class=\"c1\">// 创建一个quantize op\n</span><span class=\"c1\"></span>\n     <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">ParamDict</span> <span class=\"n\">pd</span><span class=\"p\">;</span>\n     <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">set</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">weight_data_int8_scales</span><span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">]);</span><span class=\"c1\">// 把量化表中的scale设置进op里去\n</span><span class=\"c1\"></span>\n     <span class=\"n\">op</span><span class=\"o\">-&gt;</span><span class=\"n\">load_param</span><span class=\"p\">(</span><span class=\"n\">pd</span><span class=\"p\">);</span>\n\n     <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Option</span> <span class=\"n\">opt</span><span class=\"p\">;</span>\n     <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">blob_allocator</span> <span class=\"o\">=</span> <span class=\"n\">int8_weight_data</span><span class=\"p\">.</span><span class=\"n\">allocator</span><span class=\"p\">;</span>\n\n     <span class=\"k\">const</span> <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">weight_data_n</span> <span class=\"o\">=</span> <span class=\"n\">convolution</span><span class=\"o\">-&gt;</span><span class=\"n\">weight_data</span><span class=\"p\">.</span><span class=\"n\">range</span><span class=\"p\">(</span><span class=\"n\">weight_data_size_output</span> <span class=\"o\">*</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">weight_data_size_output</span><span class=\"p\">);</span>\n     <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">int8_weight_data_n</span> <span class=\"o\">=</span> <span class=\"n\">int8_weight_data</span><span class=\"p\">.</span><span class=\"n\">range</span><span class=\"p\">(</span><span class=\"n\">weight_data_size_output</span> <span class=\"o\">*</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">weight_data_size_output</span><span class=\"p\">);</span>\n     <span class=\"n\">op</span><span class=\"o\">-&gt;</span><span class=\"n\">forward</span><span class=\"p\">(</span><span class=\"n\">weight_data_n</span><span class=\"p\">,</span> <span class=\"n\">int8_weight_data_n</span><span class=\"p\">,</span> <span class=\"n\">opt</span><span class=\"p\">);</span>  <span class=\"c1\">// quantitze op前传，计算量化权值\n</span><span class=\"c1\"></span>     <span class=\"k\">delete</span> <span class=\"n\">op</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">convolution</span><span class=\"o\">-&gt;</span><span class=\"n\">weight_data</span> <span class=\"o\">=</span> <span class=\"n\">int8_weight_data</span><span class=\"p\">;</span>  <span class=\"c1\">// 用量化后的权值替换原来的权值\n</span></code></pre></div><h3>量化表的计算</h3><p>量化表的计算，说白了就是使用我们之前说的算法来计算各个参数的scale，在ncnn2table.cpp下，顶层代码核心就一句话：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"cm\">/* ncnn2table.cpp */</span>\n<span class=\"n\">post_training_quantize</span><span class=\"p\">(</span><span class=\"n\">filenames</span><span class=\"p\">,</span> <span class=\"n\">parampath</span><span class=\"p\">,</span> <span class=\"n\">binpath</span><span class=\"p\">,</span> <span class=\"n\">tablepath</span><span class=\"p\">,</span> <span class=\"n\">pre_param</span><span class=\"p\">);</span>   <span class=\"c1\">// filenames是用来calibration的图片list\n</span><span class=\"c1\"></span>                                                                               <span class=\"c1\">// pre_param就是图片的mean、norm、height、width信息\n</span></code></pre></div><p>我们接下来重点看post_training_quantize这个函数，该函数做了如下几件事：</p><ol><li>初始化quantitize_datas</li><li>计算最大值</li><li>初始化直方图的间隔</li><li>计算直方图</li><li><b>计算Scale</b></li></ol><p>重点在于计算Scale</p><p><b>(1) 初始化</b></p><p>没什么好说的，每一个层有一个QuantizeData对象，初始化num_bins=2048，也就是原始的fp32分布Po，其统计直方图一共有2048个bins</p><div class=\"highlight\"><pre><code class=\"language-cpp\">    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_names</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">string</span> <span class=\"n\">layer_name</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_names</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span>\n\n        <span class=\"n\">QuantizeData</span> <span class=\"nf\">quantize_data</span><span class=\"p\">(</span><span class=\"n\">layer_name</span><span class=\"p\">,</span> <span class=\"mi\">2048</span><span class=\"p\">);</span>  <span class=\"c1\">// 初始化num_bins=2048\n</span><span class=\"c1\"></span>        <span class=\"n\">quantize_datas</span><span class=\"p\">.</span><span class=\"n\">push_back</span><span class=\"p\">(</span><span class=\"n\">quantize_data</span><span class=\"p\">);</span>\n    <span class=\"p\">}</span>  \n</code></pre></div><p><b>(2) 计算最大值</b></p><p>遍历所有图片，计算每个blob的最大激活值，这里找的是绝对值最大的那个。</p><div class=\"highlight\"><pre><code class=\"language-cpp\">    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">filenames</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>   <span class=\"c1\">// 遍历calibration数据\n</span><span class=\"c1\"></span>    <span class=\"p\">{</span>\n        <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">string</span> <span class=\"n\">img_name</span> <span class=\"o\">=</span> <span class=\"n\">filenames</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span>\n\n        <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">i</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">%</span><span class=\"mi\">100</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n            <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span> <span class=\"s\">&#34;          %d/%d</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"p\">)(</span><span class=\"n\">i</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"p\">)</span><span class=\"n\">size</span><span class=\"p\">);</span>\n\n        <span class=\"n\">cv</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">bgr</span> <span class=\"o\">=</span> <span class=\"n\">cv</span><span class=\"o\">::</span><span class=\"n\">imread</span><span class=\"p\">(</span><span class=\"n\">img_name</span><span class=\"p\">,</span> <span class=\"n\">CV_LOAD_IMAGE_COLOR</span><span class=\"p\">);</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">bgr</span><span class=\"p\">.</span><span class=\"n\">empty</span><span class=\"p\">())</span>\n        <span class=\"p\">{</span>\n            <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span> <span class=\"s\">&#34;cv::imread %s failed</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"n\">img_name</span><span class=\"p\">.</span><span class=\"n\">c_str</span><span class=\"p\">());</span>\n            <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">in</span> <span class=\"o\">=</span> <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span><span class=\"o\">::</span><span class=\"n\">from_pixels_resize</span><span class=\"p\">(</span><span class=\"n\">bgr</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span><span class=\"o\">::</span><span class=\"n\">PIXEL_BGR</span><span class=\"p\">,</span> <span class=\"n\">bgr</span><span class=\"p\">.</span><span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">bgr</span><span class=\"p\">.</span><span class=\"n\">rows</span><span class=\"p\">,</span> <span class=\"n\">weith</span><span class=\"p\">,</span> <span class=\"n\">height</span><span class=\"p\">);</span>\n        <span class=\"n\">in</span><span class=\"p\">.</span><span class=\"n\">substract_mean_normalize</span><span class=\"p\">(</span><span class=\"n\">mean_vals</span><span class=\"p\">,</span> <span class=\"n\">norm_vals</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Extractor</span> <span class=\"n\">ex</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">create_extractor</span><span class=\"p\">();</span>\n        <span class=\"n\">ex</span><span class=\"p\">.</span><span class=\"n\">input</span><span class=\"p\">(</span><span class=\"s\">&#34;data&#34;</span><span class=\"p\">,</span> <span class=\"n\">in</span><span class=\"p\">);</span>\n\n        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_names</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>  \n        <span class=\"p\">{</span>\n            <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">string</span> <span class=\"n\">layer_name</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_names</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span>\n            <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">string</span> <span class=\"n\">blob_name</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_bottom_blob_names</span><span class=\"p\">[</span><span class=\"n\">layer_name</span><span class=\"p\">];</span>\n\n            <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">out</span><span class=\"p\">;</span>\n            <span class=\"n\">ex</span><span class=\"p\">.</span><span class=\"n\">extract</span><span class=\"p\">(</span><span class=\"n\">blob_name</span><span class=\"p\">.</span><span class=\"n\">c_str</span><span class=\"p\">(),</span> <span class=\"n\">out</span><span class=\"p\">);</span>   <span class=\"c1\">// 前传网络，相当于caffe的forwardTo，拿到blob数据\n</span><span class=\"c1\"></span>\n            <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">j</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"n\">quantize_datas</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"n\">layer_name</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n                    <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">initial_blob_max</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">);</span>  <span class=\"c1\">// 统计最大值\n</span><span class=\"c1\"></span>                    <span class=\"k\">break</span><span class=\"p\">;</span>\n                <span class=\"p\">}</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>         \n    <span class=\"p\">}</span>\n\n<span class=\"kt\">int</span> <span class=\"n\">QuantizeData</span><span class=\"o\">::</span><span class=\"n\">initial_blob_max</span><span class=\"p\">(</span><span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">data</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"kt\">int</span> <span class=\"n\">channel_num</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">c</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">size</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">w</span> <span class=\"o\">*</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">h</span><span class=\"p\">;</span>\n\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">q</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">&lt;</span><span class=\"n\">channel_num</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"o\">*</span><span class=\"n\">data_n</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n        <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">size</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"n\">max_value</span> <span class=\"o\">=</span> <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">max_value</span><span class=\"p\">,</span> <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">fabs</span><span class=\"p\">(</span><span class=\"n\">data_n</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]));</span>  <span class=\"c1\">// 绝对值\n</span><span class=\"c1\"></span>        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p><b>(3) 初始化直方图间隔</b></p><p>也很简单，遍历每个层，初始化直方图间隔=最大激活值/2048</p><div class=\"highlight\"><pre><code class=\"language-cpp\">    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_names</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">string</span> <span class=\"n\">layer_name</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_names</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span>\n\n        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">j</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"n\">quantize_datas</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"n\">layer_name</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">initial_histogram_interval</span><span class=\"p\">();</span>\n\n                <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span> <span class=\"s\">&#34;%-20s : max = %-15f interval = %-10f</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">name</span><span class=\"p\">.</span><span class=\"n\">c_str</span><span class=\"p\">(),</span> <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">max_value</span><span class=\"p\">,</span> \n                                                                          <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">histogram_interval</span><span class=\"p\">);</span>\n                <span class=\"k\">break</span><span class=\"p\">;</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>    \n\n<span class=\"kt\">int</span> <span class=\"n\">QuantizeData</span><span class=\"o\">::</span><span class=\"n\">initial_histogram_interval</span><span class=\"p\">()</span>\n<span class=\"p\">{</span>\n    <span class=\"n\">histogram_interval</span> <span class=\"o\">=</span> <span class=\"n\">max_value</span> <span class=\"o\">/</span> <span class=\"n\">num_bins</span><span class=\"p\">;</span>\n\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p><b>(4) 计算直方图</b></p><p>再前传一次，遍历每个blob，向每个bin中投票，计算出直方图，得到原始fp32分布Po</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">&#34;    ====&gt; step 3 : generatue the histogram.</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">);</span>\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">filenames</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">string</span> <span class=\"n\">img_name</span> <span class=\"o\">=</span> <span class=\"n\">filenames</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span>\n\n    <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">i</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">%</span><span class=\"mi\">100</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n        <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span> <span class=\"s\">&#34;          %d/%d</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"p\">)(</span><span class=\"n\">i</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"p\">)</span><span class=\"n\">size</span><span class=\"p\">);</span>\n\n    <span class=\"n\">cv</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">bgr</span> <span class=\"o\">=</span> <span class=\"n\">cv</span><span class=\"o\">::</span><span class=\"n\">imread</span><span class=\"p\">(</span><span class=\"n\">img_name</span><span class=\"p\">,</span> <span class=\"n\">CV_LOAD_IMAGE_COLOR</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">bgr</span><span class=\"p\">.</span><span class=\"n\">empty</span><span class=\"p\">())</span>\n    <span class=\"p\">{</span>\n        <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span> <span class=\"s\">&#34;cv::imread %s failed</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"n\">img_name</span><span class=\"p\">.</span><span class=\"n\">c_str</span><span class=\"p\">());</span>\n        <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>  \n\n    <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">in</span> <span class=\"o\">=</span> <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span><span class=\"o\">::</span><span class=\"n\">from_pixels_resize</span><span class=\"p\">(</span><span class=\"n\">bgr</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span><span class=\"o\">::</span><span class=\"n\">PIXEL_BGR</span><span class=\"p\">,</span> <span class=\"n\">bgr</span><span class=\"p\">.</span><span class=\"n\">cols</span><span class=\"p\">,</span> <span class=\"n\">bgr</span><span class=\"p\">.</span><span class=\"n\">rows</span><span class=\"p\">,</span> <span class=\"n\">weith</span><span class=\"p\">,</span> <span class=\"n\">height</span><span class=\"p\">);</span>\n    <span class=\"n\">in</span><span class=\"p\">.</span><span class=\"n\">substract_mean_normalize</span><span class=\"p\">(</span><span class=\"n\">mean_vals</span><span class=\"p\">,</span> <span class=\"n\">norm_vals</span><span class=\"p\">);</span>\n    \n    <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Extractor</span> <span class=\"n\">ex</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">create_extractor</span><span class=\"p\">();</span>\n    <span class=\"n\">ex</span><span class=\"p\">.</span><span class=\"n\">input</span><span class=\"p\">(</span><span class=\"s\">&#34;data&#34;</span><span class=\"p\">,</span> <span class=\"n\">in</span><span class=\"p\">);</span>\n\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_names</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">string</span> <span class=\"n\">layer_name</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_names</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span>\n        <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">string</span> <span class=\"n\">blob_name</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_bottom_blob_names</span><span class=\"p\">[</span><span class=\"n\">layer_name</span><span class=\"p\">];</span>\n\n        <span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">out</span><span class=\"p\">;</span>\n        <span class=\"n\">ex</span><span class=\"p\">.</span><span class=\"n\">extract</span><span class=\"p\">(</span><span class=\"n\">blob_name</span><span class=\"p\">.</span><span class=\"n\">c_str</span><span class=\"p\">(),</span> <span class=\"n\">out</span><span class=\"p\">);</span>    <span class=\"c1\">// 再次前传\n</span><span class=\"c1\"></span>\n        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">j</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"n\">quantize_datas</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"n\">layer_name</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">update_histogram</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">);</span>\n                <span class=\"k\">break</span><span class=\"p\">;</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>     \n<span class=\"p\">}</span>\n\n<span class=\"kt\">int</span> <span class=\"n\">QuantizeData</span><span class=\"o\">::</span><span class=\"n\">update_histogram</span><span class=\"p\">(</span><span class=\"n\">ncnn</span><span class=\"o\">::</span><span class=\"n\">Mat</span> <span class=\"n\">data</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"kt\">int</span> <span class=\"n\">channel_num</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">c</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">size</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">w</span> <span class=\"o\">*</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">h</span><span class=\"p\">;</span>\n\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">q</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">&lt;</span><span class=\"n\">channel_num</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"o\">*</span><span class=\"n\">data_n</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n        <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">size</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">data_n</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n                <span class=\"k\">continue</span><span class=\"p\">;</span>\n\n            <span class=\"kt\">int</span> <span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">min</span><span class=\"p\">(</span><span class=\"k\">static_cast</span><span class=\"o\">&lt;</span><span class=\"kt\">int</span><span class=\"o\">&gt;</span><span class=\"p\">(</span><span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">abs</span><span class=\"p\">(</span><span class=\"n\">data_n</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span> <span class=\"o\">/</span> <span class=\"n\">histogram_interval</span><span class=\"p\">),</span> <span class=\"mi\">2047</span><span class=\"p\">);</span>   <span class=\"c1\">// 向bin中投票\n</span><span class=\"c1\"></span>\n            <span class=\"n\">histogram</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"p\">]</span><span class=\"o\">++</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>        \n\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p><b>(5) 计算Scale</b></p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">&#34;    ====&gt; step 4 : using kld to find the best threshold value.</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">);</span>\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_names</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">string</span> <span class=\"n\">layer_name</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_names</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">];</span>\n    <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">string</span> <span class=\"n\">blob_name</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">.</span><span class=\"n\">conv_bottom_blob_names</span><span class=\"p\">[</span><span class=\"n\">layer_name</span><span class=\"p\">];</span>\n    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span> <span class=\"s\">&#34;%-20s &#34;</span><span class=\"p\">,</span> <span class=\"n\">layer_name</span><span class=\"p\">.</span><span class=\"n\">c_str</span><span class=\"p\">());</span>\n\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">size_t</span> <span class=\"n\">j</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"n\">quantize_datas</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"n\">layer_name</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">get_data_blob_scale</span><span class=\"p\">();</span>    <span class=\"c1\">// 就这一句\n</span><span class=\"c1\"></span>            <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span> <span class=\"s\">&#34;bin : %-8d threshold : %-15f interval : %-10f scale : %-10f</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> \\\n                                                            <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">threshold_bin</span><span class=\"p\">,</span> \\\n                                                            <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">threshold</span><span class=\"p\">,</span> \\\n                                                            <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">histogram_interval</span><span class=\"p\">,</span> \\\n                                                            <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">scale</span><span class=\"p\">);</span>\n\n            <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">fp</span><span class=\"p\">,</span> <span class=\"s\">&#34;%s %f</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span> <span class=\"n\">layer_name</span><span class=\"p\">.</span><span class=\"n\">c_str</span><span class=\"p\">(),</span> <span class=\"n\">quantize_datas</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">].</span><span class=\"n\">scale</span><span class=\"p\">);</span>\n\n            <span class=\"k\">break</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"kt\">float</span> <span class=\"n\">QuantizeData</span><span class=\"o\">::</span><span class=\"n\">get_data_blob_scale</span><span class=\"p\">()</span>\n<span class=\"p\">{</span>   \n    <span class=\"n\">normalize_histogram</span><span class=\"p\">();</span>   <span class=\"c1\">// 直方图归一化\n</span><span class=\"c1\"></span>    <span class=\"n\">threshold_bin</span> <span class=\"o\">=</span> <span class=\"n\">threshold_distribution</span><span class=\"p\">(</span><span class=\"n\">histogram</span><span class=\"p\">);</span>   <span class=\"c1\">// 计算最后有多少个bins\n</span><span class=\"c1\"></span>    <span class=\"n\">threshold</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">threshold_bin</span> <span class=\"o\">+</span> <span class=\"mf\">0.5</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"n\">histogram_interval</span><span class=\"p\">;</span>   <span class=\"c1\">// 之后很容易就能找到Threshold\n</span><span class=\"c1\"></span>    <span class=\"n\">scale</span> <span class=\"o\">=</span> <span class=\"mi\">127</span> <span class=\"o\">/</span> <span class=\"n\">threshold</span><span class=\"p\">;</span>   <span class=\"c1\">// Scale也很简单就能z好到\n</span><span class=\"c1\"></span>    <span class=\"k\">return</span> <span class=\"n\">scale</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>其实说了半天，最核心的就在get_data_blob_scale这个函数里，函数分为3步：</p><ol><li>直方图归一化</li></ol><p>2. 使用KL散度计算最后用多少个bins比较合适</p><p>3. 计算Threshold和bins</p><p class=\"ztext-empty-paragraph\"><br/></p><p>归一化没什么好说的，我们来看一下threshold_distribution这个函数。这里length就是原始分布Po的长度，NCNN默认2048。这里的threshold实际上是num_bins，可以换算成T。</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"n\">QuantizeData</span><span class=\"o\">::</span><span class=\"n\">threshold_distribution</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">vector</span><span class=\"o\">&lt;</span><span class=\"kt\">float</span><span class=\"o\">&gt;</span> <span class=\"o\">&amp;</span><span class=\"n\">distribution</span><span class=\"p\">,</span> <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">target_bin</span> <span class=\"o\">=</span> <span class=\"mi\">128</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n    <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">threshold</span> <span class=\"o\">=</span> <span class=\"n\">target_bin</span><span class=\"p\">;</span> <span class=\"n\">threshold</span> <span class=\"o\">&lt;</span> <span class=\"n\">length</span><span class=\"p\">;</span> <span class=\"n\">threshold</span><span class=\"o\">++</span><span class=\"p\">)</span>   <span class=\"c1\">// target_bin=128，length = 2048\n</span><span class=\"c1\"></span>    <span class=\"p\">{</span>\n        <span class=\"c1\">// 1. 计算截断的fp32分布P\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 2. 计算int8分布Q\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 3. 计算扩展分布Q_expand\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 4. 计算KL散度\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 5. 比大小\n</span><span class=\"c1\"></span>    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div><ol><li>计算截断的fp32分布P也很简单：</li></ol><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">float</span> <span class=\"n\">threshold_sum</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">threshold</span><span class=\"o\">=</span><span class=\"n\">target_bin</span><span class=\"p\">;</span> <span class=\"n\">threshold</span><span class=\"o\">&lt;</span><span class=\"n\">length</span><span class=\"p\">;</span> <span class=\"n\">threshold</span><span class=\"o\">++</span><span class=\"p\">)</span> \n<span class=\"p\">{</span>\n    <span class=\"n\">threshold_sum</span> <span class=\"o\">+=</span> <span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">threshold</span><span class=\"p\">];</span>   <span class=\"c1\">// 128以上的所有数据和\n</span><span class=\"c1\"></span><span class=\"p\">}</span>\n\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">threshold</span><span class=\"o\">=</span><span class=\"n\">target_bin</span><span class=\"p\">;</span> <span class=\"n\">threshold</span><span class=\"o\">&lt;</span><span class=\"n\">length</span><span class=\"p\">;</span> <span class=\"n\">threshold</span><span class=\"o\">++</span><span class=\"p\">)</span> \n<span class=\"p\">{</span>\n\n    <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">vector</span><span class=\"o\">&lt;</span><span class=\"kt\">float</span><span class=\"o\">&gt;</span> <span class=\"n\">t_distribution</span><span class=\"p\">(</span><span class=\"n\">distribution</span><span class=\"p\">.</span><span class=\"n\">begin</span><span class=\"p\">(),</span> <span class=\"n\">distribution</span><span class=\"p\">.</span><span class=\"n\">begin</span><span class=\"p\">()</span><span class=\"o\">+</span><span class=\"n\">threshold</span><span class=\"p\">);</span>\n    \n    <span class=\"n\">t_distribution</span><span class=\"p\">[</span><span class=\"n\">threshold</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">threshold_sum</span><span class=\"p\">;</span>   <span class=\"c1\">// P的最后一个bin加上被截断的所有概率，得到截断的fp32分布P\n</span><span class=\"c1\"></span>    <span class=\"n\">threshold_sum</span> <span class=\"o\">-=</span> <span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">threshold</span><span class=\"p\">];</span>       <span class=\"c1\">// 是通过减法来保证数值正确性的，很巧秒\n</span><span class=\"c1\"></span>    <span class=\"p\">...</span>\n</code></pre></div><p>2. 计算int8分布Q，注意Q是从Po得来的，而不是从P得来的，大于T的部分并不会加进最后一个bin内（存疑，不理解）；另外，当发生了4舍5入时，会有特殊处理</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">vector</span><span class=\"o\">&lt;</span><span class=\"kt\">float</span><span class=\"o\">&gt;</span> <span class=\"n\">quantize_distribution</span><span class=\"p\">(</span><span class=\"n\">target_bin</span><span class=\"p\">);</span>  <span class=\"c1\">// 量化后分布Q，长度是128\n</span><span class=\"c1\"></span> \n<span class=\"n\">fill</span><span class=\"p\">(</span><span class=\"n\">quantize_distribution</span><span class=\"p\">.</span><span class=\"n\">begin</span><span class=\"p\">(),</span> <span class=\"n\">quantize_distribution</span><span class=\"p\">.</span><span class=\"n\">end</span><span class=\"p\">(),</span> <span class=\"mi\">0</span><span class=\"p\">);</span>\n\n<span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"n\">num_per_bin</span> <span class=\"o\">=</span> <span class=\"k\">static_cast</span><span class=\"o\">&lt;</span><span class=\"kt\">float</span><span class=\"o\">&gt;</span><span class=\"p\">(</span><span class=\"n\">threshold</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">target_bin</span><span class=\"p\">;</span>  <span class=\"c1\">// 其实就是当前T下的Scale \n</span><span class=\"c1\"></span><span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">target_bin</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span> \n<span class=\"p\">{</span>\n    <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">num_per_bin</span><span class=\"p\">;</span>\n    <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"n\">start</span> <span class=\"o\">+</span> <span class=\"n\">num_per_bin</span><span class=\"p\">;</span>\n\n    <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">left_upper</span> <span class=\"o\">=</span> <span class=\"n\">ceil</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">left_upper</span> <span class=\"o\">&gt;</span> <span class=\"n\">start</span><span class=\"p\">)</span> \n    <span class=\"p\">{</span>   <span class=\"c1\">// 这里的意思是，如果发生了5入，则需要将舍掉的那个bin按比例加进来\n</span><span class=\"c1\"></span>        <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"n\">left_scale</span> <span class=\"o\">=</span> <span class=\"n\">left_upper</span> <span class=\"o\">-</span> <span class=\"n\">start</span><span class=\"p\">;</span>\n        <span class=\"n\">quantize_distribution</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">left_scale</span> <span class=\"o\">*</span> <span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">left_upper</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">];</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">right_lower</span> <span class=\"o\">=</span> <span class=\"n\">floor</span><span class=\"p\">(</span><span class=\"n\">end</span><span class=\"p\">);</span>\n\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">right_lower</span> <span class=\"o\">&lt;</span> <span class=\"n\">end</span><span class=\"p\">)</span> \n    <span class=\"p\">{</span>\n\n        <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"n\">right_scale</span> <span class=\"o\">=</span> <span class=\"n\">end</span> <span class=\"o\">-</span> <span class=\"n\">right_lower</span><span class=\"p\">;</span>\n        <span class=\"n\">quantize_distribution</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">right_scale</span> <span class=\"o\">*</span> <span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">right_lower</span><span class=\"p\">];</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">j</span><span class=\"o\">=</span><span class=\"n\">left_upper</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"n\">right_lower</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span> \n    <span class=\"p\">{</span>\n        <span class=\"n\">quantize_distribution</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">];</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>3. 计算Q_expand，统计count时0不算在内，注意不管是统计数量还是上采样的过程中，都有4舍5入相关的问题</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"c1\">// get Q\n</span><span class=\"c1\"></span><span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">vector</span><span class=\"o\">&lt;</span><span class=\"kt\">float</span><span class=\"o\">&gt;</span> <span class=\"n\">expand_distribution</span><span class=\"p\">(</span><span class=\"n\">threshold</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">);</span>\n\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">target_bin</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span> \n<span class=\"p\">{</span>\n    <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">num_per_bin</span><span class=\"p\">;</span>\n    <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"n\">start</span> <span class=\"o\">+</span> <span class=\"n\">num_per_bin</span><span class=\"p\">;</span>\n\n    <span class=\"kt\">float</span> <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n\n    <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">left_upper</span> <span class=\"o\">=</span> <span class=\"n\">ceil</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">);</span>\n    <span class=\"kt\">float</span> <span class=\"n\">left_scale</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">left_upper</span> <span class=\"o\">&gt;</span> <span class=\"n\">start</span><span class=\"p\">)</span> \n    <span class=\"p\">{</span>\n        <span class=\"n\">left_scale</span> <span class=\"o\">=</span> <span class=\"n\">left_upper</span> <span class=\"o\">-</span> <span class=\"n\">start</span><span class=\"p\">;</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">left_upper</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">)</span> \n        <span class=\"p\">{</span>\n            <span class=\"n\">count</span> <span class=\"o\">+=</span> <span class=\"n\">left_scale</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">right_lower</span> <span class=\"o\">=</span> <span class=\"n\">floor</span><span class=\"p\">(</span><span class=\"n\">end</span><span class=\"p\">);</span>\n    <span class=\"kt\">float</span> <span class=\"n\">right_scale</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">right_lower</span> <span class=\"o\">&lt;</span> <span class=\"n\">end</span><span class=\"p\">)</span> \n    <span class=\"p\">{</span>\n        <span class=\"n\">right_scale</span> <span class=\"o\">=</span> <span class=\"n\">end</span> <span class=\"o\">-</span> <span class=\"n\">right_lower</span><span class=\"p\">;</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">right_lower</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">)</span> \n        <span class=\"p\">{</span>\n            <span class=\"n\">count</span> <span class=\"o\">+=</span> <span class=\"n\">right_scale</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">j</span><span class=\"o\">=</span><span class=\"n\">left_upper</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"n\">right_lower</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span> \n    <span class=\"p\">{</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">)</span> \n        <span class=\"p\">{</span>\n            <span class=\"n\">count</span><span class=\"o\">++</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"n\">expand_value</span> <span class=\"o\">=</span> <span class=\"n\">quantize_distribution</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">/</span> <span class=\"n\">count</span><span class=\"p\">;</span>\n\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">left_upper</span> <span class=\"o\">&gt;</span> <span class=\"n\">start</span><span class=\"p\">)</span> \n    <span class=\"p\">{</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">left_upper</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">)</span> \n        <span class=\"p\">{</span>\n            <span class=\"n\">expand_distribution</span><span class=\"p\">[</span><span class=\"n\">left_upper</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">expand_value</span> <span class=\"o\">*</span> <span class=\"n\">left_scale</span><span class=\"p\">;</span>  <span class=\"c1\">// 上采样过程中一样有四舍五入的问题\n</span><span class=\"c1\"></span>        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">right_lower</span> <span class=\"o\">&lt;</span> <span class=\"n\">end</span><span class=\"p\">)</span> \n    <span class=\"p\">{</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">right_lower</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">)</span> \n        <span class=\"p\">{</span>\n            <span class=\"n\">expand_distribution</span><span class=\"p\">[</span><span class=\"n\">right_lower</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">expand_value</span> <span class=\"o\">*</span> <span class=\"n\">right_scale</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">j</span><span class=\"o\">=</span><span class=\"n\">left_upper</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"n\">right_lower</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span> \n    <span class=\"p\">{</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">distribution</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">)</span> \n        <span class=\"p\">{</span>\n            <span class=\"n\">expand_distribution</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">expand_value</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>4. 计算KL散度，注意当Q为0时，KL散度只加一（存疑，不理解）</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">float</span> <span class=\"n\">kl_divergence</span> <span class=\"o\">=</span> <span class=\"n\">compute_kl_divergence</span><span class=\"p\">(</span><span class=\"n\">t_distribution</span><span class=\"p\">,</span> <span class=\"n\">expand_distribution</span><span class=\"p\">);</span>\n\n<span class=\"kt\">float</span> <span class=\"n\">QuantizeData</span><span class=\"o\">::</span><span class=\"n\">compute_kl_divergence</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">vector</span><span class=\"o\">&lt;</span><span class=\"kt\">float</span><span class=\"o\">&gt;</span> <span class=\"o\">&amp;</span><span class=\"n\">dist_a</span><span class=\"p\">,</span> <span class=\"k\">const</span> <span class=\"n\">std</span><span class=\"o\">::</span><span class=\"n\">vector</span><span class=\"o\">&lt;</span><span class=\"kt\">float</span><span class=\"o\">&gt;</span> <span class=\"o\">&amp;</span><span class=\"n\">dist_b</span><span class=\"p\">)</span> \n<span class=\"p\">{</span>\n    <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">length</span> <span class=\"o\">=</span> <span class=\"n\">dist_a</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">();</span>\n    <span class=\"n\">assert</span><span class=\"p\">(</span><span class=\"n\">dist_b</span><span class=\"p\">.</span><span class=\"n\">size</span><span class=\"p\">()</span> <span class=\"o\">==</span> <span class=\"n\">length</span><span class=\"p\">);</span>\n    <span class=\"kt\">float</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">length</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span> \n    <span class=\"p\">{</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">dist_a</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">)</span> \n        <span class=\"p\">{</span>\n            <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">dist_b</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">)</span> \n            <span class=\"p\">{</span>\n                <span class=\"n\">result</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span><span class=\"p\">;</span>   <span class=\"c1\">// Q为0时，KL散度只加一\n</span><span class=\"c1\"></span>            <span class=\"p\">}</span> \n            <span class=\"k\">else</span> \n            <span class=\"p\">{</span>\n                <span class=\"n\">result</span> <span class=\"o\">+=</span> <span class=\"n\">dist_a</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">dist_a</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">/</span> <span class=\"n\">dist_b</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]);</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">result</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div><p>5. 轻松愉悦的找最大值</p><div class=\"highlight\"><pre><code class=\"language-text\">if (kl_divergence &lt; min_kl_divergence) \n{\n    min_kl_divergence = kl_divergence;   \n    target_threshold = threshold;   // 实际上是num_bins\n}</code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><p>至此，我们得到了KL散度最小的桶数num_bins，可以通过下述公式得到T和Scale，源代码就不放了，就三行：</p><p><img src=\"https://www.zhihu.com/equation?tex=interval+%3D+max%5C_abs%5C_value%2F2048\" alt=\"interval = max\\_abs\\_value/2048\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=T+%3D+%28num%5C_bins%2B0.5%29+%5Ctimes+interval\" alt=\"T = (num\\_bins+0.5) \\times interval\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=Scale+%3D+T%2F127\" alt=\"Scale = T/127\" eeimg=\"1\"/> </p><p class=\"ztext-empty-paragraph\"><br/></p><p>最后就是将Scale数据存下来，得到量化表了</p><h2>3、 小结</h2><p>呼，总算是写完了。建议大家先去看一下NVIDIA的PPT，把整个过程搞清楚，再看代码就会容易很多</p><p>如有问题，欢迎讨论指正</p><p>谢谢！</p><p></p><p></p><p></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "高性能计算", 
                    "tagLink": "https://api.zhihu.com/topics/19608622"
                }, 
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }
            ], 
            "comments": [
                {
                    "userName": "nihui", 
                    "userLink": "https://www.zhihu.com/people/fb1221929503e7fbec20a21626d297a7", 
                    "content": "<p>写的真好呀 ~</p>", 
                    "likes": 3, 
                    "childComments": [
                        {
                            "userName": "田子宸", 
                            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
                            "content": "被大佬称赞好开心鸭<a href=\"https://pic3.zhimg.com/v2-6eeb544aa5ce6be1e6a6add75e436746.gif\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"951517104676491264\">[哈哈]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "nihui"
                        }
                    ]
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>写的真好呀 ~</p>", 
                    "likes": 2, 
                    "childComments": [
                        {
                            "userName": "田子宸", 
                            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
                            "content": "谢谢夸奖<a href=\"https://pic3.zhimg.com/v2-6eeb544aa5ce6be1e6a6add75e436746.gif\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"951517104676491264\">[哈哈]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }, 
                {
                    "userName": "圈圈虫", 
                    "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                    "content": "<p>\"但是和NCNN用的算法是一样的\"，这样说不太对哟。其实是ncnn参考的TensorRT的PPT才做出来的</p><a class=\"comment_sticker\" href=\"https://pic1.zhimg.com/v2-12562ad40366818a1ea39bcecb2599a0.gif\" data-width=\"\" data-height=\"\">[害羞]</a>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "田子宸", 
                            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
                            "content": "我明天改掉它[飙泪笑]<a href=\"https://pic2.zhimg.com/v2-90359a720808ff45062287127cfa1039.gif\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"971780885277016064\">[爱心]</a>", 
                            "likes": 1, 
                            "replyToAuthor": "圈圈虫"
                        }
                    ]
                }, 
                {
                    "userName": "圈圈虫", 
                    "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                    "content": "<p>写的真好呀 ~</p>", 
                    "likes": 1, 
                    "childComments": []
                }, 
                {
                    "userName": "圈圈虫", 
                    "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                    "content": "<p>RoadMap : int8 winograd -&gt; ncnn vulkan </p><a class=\"comment_sticker\" href=\"https://pic3.zhimg.com/v2-cfc14c7293afd962ecbd1dc31dafd002.gif\" data-width=\"\" data-height=\"\">[赞同]</a>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "田子宸", 
                            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
                            "content": "vulkan恐怕暂时没时间写了，实习这边来活了，不能愉悦的写文章了<a href=\"https://pic1.zhimg.com/v2-bb77994ce7b621dd0d204f5454fea42c.webp\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"1029330334621552640\">[委屈]</a>", 
                            "likes": 1, 
                            "replyToAuthor": "圈圈虫"
                        }, 
                        {
                            "userName": "圈圈虫", 
                            "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                            "content": "在哪里实习哇", 
                            "likes": 0, 
                            "replyToAuthor": "田子宸"
                        }
                    ]
                }, 
                {
                    "userName": "白牛", 
                    "userLink": "https://www.zhihu.com/people/ed709a31c73e487f73068fa553ab15f8", 
                    "content": "写得真好啊～", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "田子宸", 
                            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
                            "content": "<p>谢谢！</p><a class=\"comment_sticker\" href=\"https://pic2.zhimg.com/v2-90359a720808ff45062287127cfa1039.gif\" data-width=\"\" data-height=\"\">[爱心]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "白牛"
                        }
                    ]
                }, 
                {
                    "userName": "Mirror Yu", 
                    "userLink": "https://www.zhihu.com/people/8506f8bb8031b6d93cb360d05f7f6087", 
                    "content": "<p>写的真好，感谢感谢~</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "郭嘉", 
                    "userLink": "https://www.zhihu.com/people/0cb90225a1f61ad4645cf5400b4cebe6", 
                    "content": "<p>想问一下，weights是已知的，可以提前利用KL求取最佳scale，输入的数据是未知的，scale是怎么算的呢？而且NV中是搜集激活值，NCNN量化求取的scale是输入数据和weights本身吗？</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/72149270", 
            "userName": "田子宸", 
            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
            "upvote": 66, 
            "title": "NCNN winograd详解（一）", 
            "content": "<h2>0、前言</h2><p>一样，最近工作有空闲，正好趁这个机会把之前想看的看一看，并分享出来</p><p>本文重点讲解一下NCNN里面winograd的计算流程。其中内存排布懒得用软件画了，有很多灵魂手绘，不要吐槽我画得丑就好</p><h2>1、 winograd原理</h2><p>先放上winograd的论文原文：</p><a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1509.09308\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Fast Algorithms for Convolutional Neural Networks</a><h3>winograd的目的</h3><p>在CNN中，Conv占了绝大部分的运算量，这点在ShuffleNetV2这篇文章中有详细的测试：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f370f7b1305cf02db71a8df44c30e05e_b.jpg\" data-size=\"normal\" data-rawwidth=\"919\" data-rawheight=\"272\" class=\"origin_image zh-lightbox-thumb\" width=\"919\" data-original=\"https://pic3.zhimg.com/v2-f370f7b1305cf02db71a8df44c30e05e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;919&#39; height=&#39;272&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"919\" data-rawheight=\"272\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"919\" data-original=\"https://pic3.zhimg.com/v2-f370f7b1305cf02db71a8df44c30e05e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-f370f7b1305cf02db71a8df44c30e05e_b.jpg\"/><figcaption>不同算子所占时间，图来自ShuffleNetV2论文</figcaption></figure><p>我们看到，在GPU上，Conv占的时间达到了50%；而在ARM上，Conv几乎占到了网络90%左右的耗时。所以要加速CNN，加速Conv是很有收益的一件事。所谓“加速大比例事件”嘛</p><p>Conv有几种计算方法：</p><ul><li>直接卷积：按照定义直接计算，一般来说访存很差，很慢，但在特定情况下可能是最优计算方案</li><li>im2col+gemm：先将特征图换成矩阵，然后用kernel矩阵乘以特征图转换的矩阵，得到输出，访存性能能好一些</li><li>Strassen：减少卷积层的卷积操作数量</li><li>FFT：通过FFT减少Conv的计算量，在大卷积核下收益明显</li></ul><p>可以看到，im2col改善了访存，但是没有减少计算量；FFT减少了Conv的计算量，适用于大卷积核，但目前深度学习模型用的都是小卷积核（3x3、1x1），貌似也加速不了多少</p><p>Winograd就应运而生了，主要专注在3x3卷积核的加速</p><h3>winograd算法简介</h3><p>现今的Winograd主要来源于1980年，由Shmuel Winograd提出减少FIR滤波器计算量的方法</p><p>Shmuel Winograd指出，对于输出个数为m，有r个参数的FIR滤波器，不需要m*r次乘法计算，而仅仅需要：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-9c838dabb0921180665941e137452419_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"283\" data-rawheight=\"32\" class=\"content_image\" width=\"283\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;283&#39; height=&#39;32&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"283\" data-rawheight=\"32\" class=\"content_image lazy\" width=\"283\" data-actualsrc=\"https://pic2.zhimg.com/v2-9c838dabb0921180665941e137452419_b.png\"/></figure><p>次乘法计算即可。</p><p>下面是一个F(2,3)的例子，即输出m=2个结果，参数r=3个：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-773c332ae31b0d8e550b9cbcf0937094_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"611\" data-rawheight=\"96\" class=\"origin_image zh-lightbox-thumb\" width=\"611\" data-original=\"https://pic1.zhimg.com/v2-773c332ae31b0d8e550b9cbcf0937094_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;611&#39; height=&#39;96&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"611\" data-rawheight=\"96\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"611\" data-original=\"https://pic1.zhimg.com/v2-773c332ae31b0d8e550b9cbcf0937094_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-773c332ae31b0d8e550b9cbcf0937094_b.png\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-365ad60c9c0b32385870809a98f79c2d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"554\" data-rawheight=\"111\" class=\"origin_image zh-lightbox-thumb\" width=\"554\" data-original=\"https://pic2.zhimg.com/v2-365ad60c9c0b32385870809a98f79c2d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;554&#39; height=&#39;111&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"554\" data-rawheight=\"111\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"554\" data-original=\"https://pic2.zhimg.com/v2-365ad60c9c0b32385870809a98f79c2d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-365ad60c9c0b32385870809a98f79c2d_b.jpg\"/></figure><p>可以看到，只需要4次乘法计算结果，发生在m1/m2/m3/m4的计算过程中，外加8次加法。注意，跟g相关的加减乘除可以在初始化时一口气算好，不占计算量。</p><p>扩展到二维：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-ed899075ab93e2c31d9235e5499026f0_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"516\" data-rawheight=\"74\" class=\"origin_image zh-lightbox-thumb\" width=\"516\" data-original=\"https://pic1.zhimg.com/v2-ed899075ab93e2c31d9235e5499026f0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;516&#39; height=&#39;74&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"516\" data-rawheight=\"74\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"516\" data-original=\"https://pic1.zhimg.com/v2-ed899075ab93e2c31d9235e5499026f0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-ed899075ab93e2c31d9235e5499026f0_b.png\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-023f7d76a90f6572757417c266423219_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"348\" data-rawheight=\"76\" class=\"content_image\" width=\"348\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;348&#39; height=&#39;76&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"348\" data-rawheight=\"76\" class=\"content_image lazy\" width=\"348\" data-actualsrc=\"https://pic2.zhimg.com/v2-023f7d76a90f6572757417c266423219_b.jpg\"/></figure><p>上式中，g为参数，d为数据，G/B/A都是转换矩阵，Y是输出</p><p>具体的公式推荐大家直接看论文</p><p>对于不同的卷积核和输出大小，winograd的转换矩阵各自不同。本文专注于conv3x3_s1的介绍。</p><h2>2、 NCNN的Winograd原理实现</h2><h3>顶层逻辑</h3><p>NCNN对arm和x86平台都做了winograd优化，我们以arm为例，其顶层逻辑在convolution_arm.cpp下：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"n\">Convolution_arm</span><span class=\"o\">::</span><span class=\"n\">create_pipeline</span><span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"n\">Option</span><span class=\"o\">&amp;</span> <span class=\"n\">opt</span><span class=\"p\">)</span>    <span class=\"c1\">// 卷积的准备工作\n</span><span class=\"c1\"></span><span class=\"p\">{</span>\n    <span class=\"p\">...</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">use_winograd_convolution</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">kernel_w</span> <span class=\"o\">==</span> <span class=\"mi\">3</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">kernel_h</span> <span class=\"o\">==</span> <span class=\"mi\">3</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">dilation_w</span> <span class=\"o\">==</span> <span class=\"mi\">1</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">dilation_h</span> <span class=\"o\">==</span> <span class=\"mi\">1</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">stride_w</span> <span class=\"o\">==</span> <span class=\"mi\">1</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">stride_h</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"kt\">int</span> <span class=\"n\">num_input</span> <span class=\"o\">=</span> <span class=\"n\">weight_data_size</span> <span class=\"o\">/</span> <span class=\"mi\">9</span> <span class=\"o\">/</span> <span class=\"n\">num_output</span><span class=\"p\">;</span>\n        <span class=\"c1\">// winograd is slow on small channel count\n</span><span class=\"c1\"></span>        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">num_input</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">16</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">num_output</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">16</span><span class=\"p\">)</span>\n            <span class=\"n\">use_winograd3x3</span> <span class=\"o\">=</span> <span class=\"nb\">true</span><span class=\"p\">;</span>\n\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">use_int8_inference</span><span class=\"p\">)</span>\n            <span class=\"n\">use_winograd3x3</span> <span class=\"o\">=</span> <span class=\"nb\">true</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">...</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">use_winograd3x3</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"kt\">int</span> <span class=\"n\">num_input</span> <span class=\"o\">=</span> <span class=\"n\">weight_data_size</span> <span class=\"o\">/</span> <span class=\"mi\">9</span> <span class=\"o\">/</span> <span class=\"n\">num_output</span><span class=\"p\">;</span>    <span class=\"c1\">// 准备变换矩阵\n</span><span class=\"c1\">//         conv3x3s1_winograd64_transform_kernel_neon(weight_data, weight_3x3_winograd64_data, num_input, num_output);\n</span><span class=\"c1\"></span>        <span class=\"n\">conv3x3s1_winograd64_transform_kernel_neon5</span><span class=\"p\">(</span><span class=\"n\">weight_data</span><span class=\"p\">,</span> <span class=\"n\">weight_3x3_winograd64_data</span><span class=\"p\">,</span> <span class=\"n\">num_input</span><span class=\"p\">,</span> <span class=\"n\">num_output</span><span class=\"p\">);</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">...</span>\n  \n<span class=\"p\">}</span>\n</code></pre></div><p>上面的第一段代码里，只有input_c 和 output_c都大于16时，才会使用winograd，这是因为小channel下winograd没有im2col快；另外，int8只能用winograd计算。</p><p>第二段代码中，我们看到，NCNN调用了函数conv3x3s1_winograd64_transform_kernel_neonX，这个X我理解应该是函数的版本号。</p><p>这个函数干了什么呢？其实就是使用矩阵G，对权重g预先做好转换，并将结果U存下来，这样计算时就不用再转了，就是下面这个公式：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a238cf2d8847d010edd0d59e10a7d29b_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"134\" data-rawheight=\"30\" class=\"content_image\" width=\"134\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;134&#39; height=&#39;30&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"134\" data-rawheight=\"30\" class=\"content_image lazy\" width=\"134\" data-actualsrc=\"https://pic4.zhimg.com/v2-a238cf2d8847d010edd0d59e10a7d29b_b.png\"/></figure><p>可以看到，上述代码是一些转换工作，真正的计算在forward函数下：</p><div class=\"highlight\"><pre><code class=\"language-text\">int Convolution_arm::forward(const Mat&amp; bottom_blob, Mat&amp; top_blob, const Option&amp; opt) const\n{\n    ...\n    if (use_winograd3x3 &amp;&amp; w &lt;= 120 &amp;&amp; h &lt;= 120)   // 只在特定条件下才使用winograd\n    {\n//        conv3x3s1_winograd64_neon4(bottom_blob_bordered, top_blob, weight_3x3_winograd64_data, bias_data, opt);\n        conv3x3s1_winograd64_neon5(bottom_blob_bordered, top_blob, weight_3x3_winograd64_data, bias_data, opt);\n    }\n    else if (use_sgemm1x1)\n    {\n        conv1x1s1_sgemm_neon(bottom_blob_bordered, top_blob, weight_1x1_sgemm_data, bias_data, opt);\n    }\n    else if (kernel_w == 1 &amp;&amp; kernel_h == 1 &amp;&amp; dilation_w == 1 &amp;&amp; dilation_h == 1 &amp;&amp; stride_w == 2 &amp;&amp; stride_h == 2)\n    {\n        conv_im2col_sgemm_neon(bottom_blob_bordered, top_blob, weight_sgemm_data, bias_data, kernel_w, kernel_h, stride_w, stride_h, opt);\n    }\n    else if (kernel_w == 3 &amp;&amp; kernel_h == 3 &amp;&amp; dilation_w == 1 &amp;&amp; dilation_h == 1 &amp;&amp; stride_w == 2 &amp;&amp; stride_h == 2)\n    {\n        if (outw &gt;=8 &amp;&amp; outh &gt;=8)\n            conv3x3s2_packed_neon(bottom_blob_bordered, top_blob, weight_3x3s2_data, bias_data, opt);\n        else  \n            conv_im2col_sgemm_neon(bottom_blob_bordered, top_blob, weight_sgemm_data, bias_data, kernel_w, kernel_h, stride_w, stride_h, opt);\n    }     \n    else\n        conv(bottom_blob_bordered, top_blob, weight_data, bias_data, opt);   // convhxw_s_neon，查表得到的\n}</code></pre></div><p>可以看到，只有在特定条件下（w &lt;= 120 &amp;&amp; h &lt;= 120）的条件下，NCNN才会用Winograd。其他条件下还是用了别的方法计算Conv。这说明了两点：</p><ul><li>Winograd并不是在什么情况下都是最快的</li><li>目前想要优化到极致，需要不同情况不同对待——上面那段代码中我们就看到了很多策略：sgemm1x1、im2col、packed_neon、no_packed_neon等等</li></ul><p>也可以看到，NCNN的底层还是蛮良心的</p><p>winograd在计算部分做了两个主要运算，其中V是对输入数据的转换，而Y是最终的结果：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1ba9338994652d420e93790719ce8550_b.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"134\" data-rawheight=\"38\" class=\"content_image\" width=\"134\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;134&#39; height=&#39;38&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"134\" data-rawheight=\"38\" class=\"content_image lazy\" width=\"134\" data-actualsrc=\"https://pic1.zhimg.com/v2-1ba9338994652d420e93790719ce8550_b.png\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-6133ba8bdfc71441197d78ce9503086f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"223\" data-rawheight=\"44\" class=\"content_image\" width=\"223\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;223&#39; height=&#39;44&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"223\" data-rawheight=\"44\" class=\"content_image lazy\" width=\"223\" data-actualsrc=\"https://pic4.zhimg.com/v2-6133ba8bdfc71441197d78ce9503086f_b.jpg\"/></figure><p>看了这么多，其实winograd卷积只分为两步：一、在创建卷积时，调用conv3x3s1_winograd64_transform_kernel_neonX计算U；二、计算时调用conv3x3s1_winograd64_neonX运行winograd计算，包括V和Y</p><p>本文将对conv3x3s1_winograd64_transform_kernel_neon4、conv3x3s1_winograd64_neon4这两个函数进行分析</p><h3>conv3x3s1_winograd64_transform_kernel_neon4</h3><p><b>(1) U矩阵计算</b></p><p><img src=\"https://www.zhihu.com/equation?tex=U_%7Bk%2Cc%7D%3DGg_%7Bk%2Cc%7DG%5E%7BT%7D\" alt=\"U_{k,c}=Gg_{k,c}G^{T}\" eeimg=\"1\"/> </p><div class=\"highlight\"><pre><code class=\"language-cpp\"> <span class=\"n\">kernel_tm</span><span class=\"p\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"o\">*</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">inch</span><span class=\"p\">,</span> <span class=\"n\">outch</span><span class=\"p\">);</span>\n\n    <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">][</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">{</span>       <span class=\"c1\">// Acutually Matrix G\n</span><span class=\"c1\"></span>        <span class=\"p\">{</span>   <span class=\"mf\">1.0f</span><span class=\"p\">,</span>     <span class=\"mf\">0.0f</span><span class=\"p\">,</span>     <span class=\"mf\">0.0f</span><span class=\"p\">},</span>    <span class=\"c1\">// G矩阵\n</span><span class=\"c1\"></span>        <span class=\"p\">{</span><span class=\"o\">-</span><span class=\"mf\">2.0f</span><span class=\"o\">/</span><span class=\"mi\">9</span><span class=\"p\">,</span>  <span class=\"o\">-</span><span class=\"mf\">2.0f</span><span class=\"o\">/</span><span class=\"mi\">9</span><span class=\"p\">,</span>  <span class=\"o\">-</span><span class=\"mf\">2.0f</span><span class=\"o\">/</span><span class=\"mi\">9</span><span class=\"p\">},</span>\n        <span class=\"p\">{</span><span class=\"o\">-</span><span class=\"mf\">2.0f</span><span class=\"o\">/</span><span class=\"mi\">9</span><span class=\"p\">,</span>   <span class=\"mf\">2.0f</span><span class=\"o\">/</span><span class=\"mi\">9</span><span class=\"p\">,</span>  <span class=\"o\">-</span><span class=\"mf\">2.0f</span><span class=\"o\">/</span><span class=\"mi\">9</span><span class=\"p\">},</span>\n        <span class=\"p\">{</span><span class=\"mf\">1.0f</span><span class=\"o\">/</span><span class=\"mi\">90</span><span class=\"p\">,</span>  <span class=\"mf\">1.0f</span><span class=\"o\">/</span><span class=\"mi\">45</span><span class=\"p\">,</span>  <span class=\"mf\">2.0f</span><span class=\"o\">/</span><span class=\"mi\">45</span><span class=\"p\">},</span>\n        <span class=\"p\">{</span><span class=\"mf\">1.0f</span><span class=\"o\">/</span><span class=\"mi\">90</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">1.0f</span><span class=\"o\">/</span><span class=\"mi\">45</span><span class=\"p\">,</span>  <span class=\"mf\">2.0f</span><span class=\"o\">/</span><span class=\"mi\">45</span><span class=\"p\">},</span>\n        <span class=\"p\">{</span><span class=\"mf\">1.0f</span><span class=\"o\">/</span><span class=\"mi\">45</span><span class=\"p\">,</span>  <span class=\"mf\">1.0f</span><span class=\"o\">/</span><span class=\"mi\">90</span><span class=\"p\">,</span> <span class=\"mf\">1.0f</span><span class=\"o\">/</span><span class=\"mi\">180</span><span class=\"p\">},</span>\n        <span class=\"p\">{</span><span class=\"mf\">1.0f</span><span class=\"o\">/</span><span class=\"mi\">45</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">1.0f</span><span class=\"o\">/</span><span class=\"mi\">90</span><span class=\"p\">,</span> <span class=\"mf\">1.0f</span><span class=\"o\">/</span><span class=\"mi\">180</span><span class=\"p\">},</span>\n        <span class=\"p\">{</span>   <span class=\"mf\">0.0f</span><span class=\"p\">,</span>     <span class=\"mf\">0.0f</span><span class=\"p\">,</span>     <span class=\"mf\">1.0f</span><span class=\"p\">}</span>\n    <span class=\"p\">};</span>\n\n    <span class=\"cp\">#pragma omp parallel for\n</span><span class=\"cp\"></span>    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">&lt;</span><span class=\"n\">outch</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">&lt;</span><span class=\"n\">inch</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">kernel0</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">kernel</span> <span class=\"o\">+</span> <span class=\"n\">p</span><span class=\"o\">*</span><span class=\"n\">inch</span> <span class=\"o\">*</span> <span class=\"mi\">9</span> <span class=\"o\">+</span> <span class=\"n\">q</span> <span class=\"o\">*</span> <span class=\"mi\">9</span><span class=\"p\">;</span>\n            <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">kernel_tm0</span> <span class=\"o\">=</span> <span class=\"n\">kernel_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">).</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n\n            <span class=\"c1\">// transform kernel, transposed\n</span><span class=\"c1\"></span>            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k0</span> <span class=\"o\">=</span> <span class=\"n\">kernel0</span><span class=\"p\">;</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k1</span> <span class=\"o\">=</span> <span class=\"n\">kernel0</span> <span class=\"o\">+</span> <span class=\"mi\">3</span><span class=\"p\">;</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k2</span> <span class=\"o\">=</span> <span class=\"n\">kernel0</span> <span class=\"o\">+</span> <span class=\"mi\">6</span><span class=\"p\">;</span>\n\n            <span class=\"c1\">// h\n</span><span class=\"c1\"></span>            <span class=\"kt\">float</span> <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">][</span><span class=\"mi\">3</span><span class=\"p\">];</span>    <span class=\"c1\">// tmp = G*gT\n</span><span class=\"c1\"></span>            <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"mi\">8</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k0</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">k0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">k0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n                <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k1</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">k1</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">k1</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n                <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k2</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">k2</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">k2</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n            <span class=\"p\">}</span>\n\n            <span class=\"c1\">// v        // kernel_tm0 = G*g*GT = U\n</span><span class=\"c1\"></span>            <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">j</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"mi\">8</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">tmpp</span> <span class=\"o\">=</span> <span class=\"o\">&amp;</span><span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">];</span>\n\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"mi\">8</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n                    <span class=\"n\">kernel_tm0</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"o\">*</span><span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmpp</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmpp</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmpp</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">][</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n                <span class=\"p\">}</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n</code></pre></div><p>NCNN的winograd实现是F(6x6, 3x3)，所以G矩阵是一个8x3的矩阵，上面这段代码实际上就是U的计算，kernel_tm就是计算结果，其内存排布如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-04b9adbc2d1716a2a312c7e7f23180d3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"762\" data-rawheight=\"308\" class=\"origin_image zh-lightbox-thumb\" width=\"762\" data-original=\"https://pic4.zhimg.com/v2-04b9adbc2d1716a2a312c7e7f23180d3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;762&#39; height=&#39;308&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"762\" data-rawheight=\"308\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"762\" data-original=\"https://pic4.zhimg.com/v2-04b9adbc2d1716a2a312c7e7f23180d3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-04b9adbc2d1716a2a312c7e7f23180d3_b.jpg\"/></figure><p>至此，所有的kernel g都被转换成了U，存放在kernel_tm上了，一行代表一个U(k,c)</p><p>这里有两点强调一下：</p><ol><li>W=64的原因是F(6x6, 3x3)需要每一个输入块(tile)大小为8x8，权重块对应也是8x8，这样才能做eltwise_mult操作。也就是说，一个U(k,c)被存在了一行上</li><li>k代表output_channel号，c代表input_channel号，一个U(k,c)对应卷积核的一个g(k,c)</li></ol><p><b>(2) U矩阵重排</b></p><p>NCNN为了访存的效率，紧接着对kernel_tm做了一个重排，将每个U(k,c)以4个数据为单位，拆开来存放，代码如下：</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"c1\">// optimized layout for winograd4\n</span><span class=\"c1\"></span>    <span class=\"c1\">// interleave weights\n</span><span class=\"c1\"></span>    <span class=\"kt\">int</span> <span class=\"n\">nn_outch</span> <span class=\"o\">=</span> <span class=\"n\">outch</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">remain_outch_start</span> <span class=\"o\">=</span> <span class=\"n\">nn_outch</span> <span class=\"o\">&lt;&lt;</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n\n    <span class=\"n\">Mat</span> <span class=\"nf\">kernel_tm2</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"o\">*</span><span class=\"mi\">8</span> <span class=\"o\">*</span> <span class=\"n\">inch</span> <span class=\"o\">*</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">nn_outch</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">outch</span> <span class=\"o\">%</span> <span class=\"mi\">4</span> <span class=\"o\">+</span> <span class=\"mi\">3</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"mi\">4</span><span class=\"p\">);</span>\n\n    <span class=\"cp\">#pragma omp parallel for\n</span><span class=\"cp\"></span>    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">pp</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">pp</span><span class=\"o\">&lt;</span><span class=\"n\">nn_outch</span><span class=\"p\">;</span> <span class=\"n\">pp</span><span class=\"o\">++</span><span class=\"p\">)</span>   <span class=\"c1\">// 只是做一个reorder\n</span><span class=\"c1\"></span>    <span class=\"p\">{</span>\n        <span class=\"kt\">int</span> <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">pp</span> <span class=\"o\">*</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n\n        <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">ktm2</span> <span class=\"o\">=</span> <span class=\"n\">kernel_tm2</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">pp</span><span class=\"p\">);</span>\n\n        <span class=\"k\">const</span> <span class=\"n\">Mat</span> <span class=\"n\">kernel0_tm</span> <span class=\"o\">=</span> <span class=\"n\">kernel_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">);</span>\n        <span class=\"k\">const</span> <span class=\"n\">Mat</span> <span class=\"n\">kernel1_tm</span> <span class=\"o\">=</span> <span class=\"n\">kernel_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n        <span class=\"k\">const</span> <span class=\"n\">Mat</span> <span class=\"n\">kernel2_tm</span> <span class=\"o\">=</span> <span class=\"n\">kernel_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">+</span><span class=\"mi\">2</span><span class=\"p\">);</span>\n        <span class=\"k\">const</span> <span class=\"n\">Mat</span> <span class=\"n\">kernel3_tm</span> <span class=\"o\">=</span> <span class=\"n\">kernel_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">+</span><span class=\"mi\">3</span><span class=\"p\">);</span>\n\n        <span class=\"kt\">int</span> <span class=\"n\">q</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span>\n\n        <span class=\"k\">for</span> <span class=\"p\">(;</span> <span class=\"n\">q</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"o\">&lt;</span><span class=\"n\">inch</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">+=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k00</span> <span class=\"o\">=</span> <span class=\"n\">kernel0_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>   <span class=\"c1\">// one U(k,c) 8x8\n</span><span class=\"c1\"></span>            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k01</span> <span class=\"o\">=</span> <span class=\"n\">kernel0_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k10</span> <span class=\"o\">=</span> <span class=\"n\">kernel1_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k11</span> <span class=\"o\">=</span> <span class=\"n\">kernel1_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k20</span> <span class=\"o\">=</span> <span class=\"n\">kernel2_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k21</span> <span class=\"o\">=</span> <span class=\"n\">kernel2_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k30</span> <span class=\"o\">=</span> <span class=\"n\">kernel3_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k31</span> <span class=\"o\">=</span> <span class=\"n\">kernel3_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n\n            <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">r</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">&lt;</span><span class=\"mi\">16</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">&lt;</span><span class=\"mi\">4</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">0</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k00</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">4</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k01</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">8</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k10</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">12</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k11</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">16</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k20</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">20</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k21</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">24</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k30</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">28</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k31</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                <span class=\"p\">}</span>\n\n                <span class=\"n\">k00</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">k01</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">k10</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">k11</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">k20</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">k21</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">k30</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">k31</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">ktm2</span> <span class=\"o\">+=</span> <span class=\"mi\">32</span><span class=\"p\">;</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"k\">for</span> <span class=\"p\">(;</span> <span class=\"n\">q</span><span class=\"o\">&lt;</span><span class=\"n\">inch</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"c1\">// inch方向甩尾\n</span><span class=\"c1\"></span>        <span class=\"p\">{</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k00</span> <span class=\"o\">=</span> <span class=\"n\">kernel0_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k10</span> <span class=\"o\">=</span> <span class=\"n\">kernel1_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k20</span> <span class=\"o\">=</span> <span class=\"n\">kernel2_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k30</span> <span class=\"o\">=</span> <span class=\"n\">kernel3_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n\n            <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">r</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">&lt;</span><span class=\"mi\">16</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">&lt;</span><span class=\"mi\">4</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">0</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k00</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">4</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k10</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">8</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k20</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"mi\">12</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k30</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                <span class=\"p\">}</span>\n\n                <span class=\"n\">k00</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">k10</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">k20</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">k30</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">ktm2</span> <span class=\"o\">+=</span> <span class=\"mi\">16</span><span class=\"p\">;</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"cp\">#pragma omp parallel for\n</span><span class=\"cp\"></span>    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">remain_outch_start</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">&lt;</span><span class=\"n\">outch</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">++</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n        <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">ktm2</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">kernel_tm2</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">nn_outch</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">8</span><span class=\"o\">*</span><span class=\"mi\">8</span> <span class=\"o\">*</span> <span class=\"n\">inch</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">-</span><span class=\"n\">remain_outch_start</span><span class=\"p\">);</span>\n\n        <span class=\"k\">const</span> <span class=\"n\">Mat</span> <span class=\"n\">kernel0_tm</span> <span class=\"o\">=</span> <span class=\"n\">kernel_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">);</span>\n\n        <span class=\"kt\">int</span> <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n\n        <span class=\"k\">for</span> <span class=\"p\">(;</span> <span class=\"n\">q</span><span class=\"o\">&lt;</span><span class=\"n\">inch</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">k00</span> <span class=\"o\">=</span> <span class=\"n\">kernel0_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n\n            <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">r</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">&lt;</span><span class=\"mi\">16</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">&lt;</span><span class=\"mi\">4</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n                    <span class=\"n\">ktm2</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">k00</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                <span class=\"p\">}</span>\n\n                <span class=\"n\">k00</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"n\">ktm2</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">kernel_tm</span> <span class=\"o\">=</span> <span class=\"n\">kernel_tm2</span><span class=\"p\">;</span>\n</code></pre></div><p>说白了就是做如下的内存重排：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6982a1ec049bf3aec81b18467355f5ae_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"769\" data-rawheight=\"231\" class=\"origin_image zh-lightbox-thumb\" width=\"769\" data-original=\"https://pic3.zhimg.com/v2-6982a1ec049bf3aec81b18467355f5ae_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;769&#39; height=&#39;231&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"769\" data-rawheight=\"231\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"769\" data-original=\"https://pic3.zhimg.com/v2-6982a1ec049bf3aec81b18467355f5ae_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-6982a1ec049bf3aec81b18467355f5ae_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b90fc77503c3d2ee549a3307afb93e70_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"756\" data-rawheight=\"464\" class=\"origin_image zh-lightbox-thumb\" width=\"756\" data-original=\"https://pic1.zhimg.com/v2-b90fc77503c3d2ee549a3307afb93e70_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;756&#39; height=&#39;464&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"756\" data-rawheight=\"464\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"756\" data-original=\"https://pic1.zhimg.com/v2-b90fc77503c3d2ee549a3307afb93e70_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b90fc77503c3d2ee549a3307afb93e70_b.jpg\"/></figure><p>说白了就是一口气拿出8个U矩阵，然后4个4个交错排布。图中有标号，表示了交错排布的顺序。原数据每4个channel能凑出一行来</p><p>这里关注一下W的维度，W=8x8xinput_channelx4，其中8x8代表一个tile有64个元素，input_channelx4主要是对output_channel做了一个压缩，原因不明</p><p class=\"ztext-empty-paragraph\"><br/></p><p>至此，U矩阵就计算完成并重排，等待输入数据啦</p><h3>conv3x3s1_winograd64_neon4</h3><p><b>(1) V矩阵计算</b></p><p><img src=\"https://www.zhihu.com/equation?tex=V_%7Bc%2Cb%7D%3DB%5E%7BT%7Dd_%7Bc%2Cb%7DB\" alt=\"V_{c,b}=B^{T}d_{c,b}B\" eeimg=\"1\"/> </p><div class=\"highlight\"><pre><code class=\"language-cpp\">    <span class=\"kt\">int</span> <span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob</span><span class=\"p\">.</span><span class=\"n\">w</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob</span><span class=\"p\">.</span><span class=\"n\">h</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">inch</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob</span><span class=\"p\">.</span><span class=\"n\">c</span><span class=\"p\">;</span>\n\n    <span class=\"kt\">int</span> <span class=\"n\">outw</span> <span class=\"o\">=</span> <span class=\"n\">top_blob</span><span class=\"p\">.</span><span class=\"n\">w</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">outh</span> <span class=\"o\">=</span> <span class=\"n\">top_blob</span><span class=\"p\">.</span><span class=\"n\">h</span><span class=\"p\">;</span>\n    <span class=\"kt\">int</span> <span class=\"n\">outch</span> <span class=\"o\">=</span> <span class=\"n\">top_blob</span><span class=\"p\">.</span><span class=\"n\">c</span><span class=\"p\">;</span>\n\n    <span class=\"c1\">// pad to 6n+2\n</span><span class=\"c1\"></span>    <span class=\"n\">Mat</span> <span class=\"n\">bottom_blob_bordered</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob</span><span class=\"p\">;</span>\n\n    <span class=\"n\">outw</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">outw</span> <span class=\"o\">+</span> <span class=\"mi\">5</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"mi\">6</span> <span class=\"o\">*</span> <span class=\"mi\">6</span><span class=\"p\">;</span>\n    <span class=\"n\">outh</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">outh</span> <span class=\"o\">+</span> <span class=\"mi\">5</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"mi\">6</span> <span class=\"o\">*</span> <span class=\"mi\">6</span><span class=\"p\">;</span>\n\n    <span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"n\">outw</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n    <span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">outh</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n    <span class=\"n\">copy_make_border</span><span class=\"p\">(</span><span class=\"n\">bottom_blob</span><span class=\"p\">,</span> <span class=\"n\">bottom_blob_bordered</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">h</span> <span class=\"o\">-</span> <span class=\"n\">bottom_blob</span><span class=\"p\">.</span><span class=\"n\">h</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">w</span> <span class=\"o\">-</span> <span class=\"n\">bottom_blob</span><span class=\"p\">.</span><span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mf\">0.f</span><span class=\"p\">,</span> <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">workspace_allocator</span><span class=\"p\">,</span> <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">num_threads</span><span class=\"p\">);</span>\n\n    <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">bias</span> <span class=\"o\">=</span> <span class=\"n\">_bias</span><span class=\"p\">;</span>\n\n    <span class=\"c1\">// BEGIN transform input\n</span><span class=\"c1\"></span>    <span class=\"n\">Mat</span> <span class=\"n\">bottom_blob_tm</span><span class=\"p\">;</span>\n    <span class=\"p\">{</span>\n        <span class=\"kt\">int</span> <span class=\"n\">w_tm</span> <span class=\"o\">=</span> <span class=\"n\">outw</span> <span class=\"o\">/</span> <span class=\"mi\">6</span> <span class=\"o\">*</span> <span class=\"mi\">8</span><span class=\"p\">;</span>\n        <span class=\"kt\">int</span> <span class=\"n\">h_tm</span> <span class=\"o\">=</span> <span class=\"n\">outh</span> <span class=\"o\">/</span> <span class=\"mi\">6</span> <span class=\"o\">*</span> <span class=\"mi\">8</span><span class=\"p\">;</span>\n        <span class=\"n\">bottom_blob_tm</span><span class=\"p\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">16</span> <span class=\"o\">*</span> <span class=\"n\">w_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span> <span class=\"o\">*</span> <span class=\"n\">h_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">inch</span><span class=\"p\">,</span> <span class=\"mi\">4u</span><span class=\"p\">,</span> <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">workspace_allocator</span><span class=\"p\">);</span>\n        <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">tiles</span> <span class=\"o\">=</span> <span class=\"n\">w_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span> <span class=\"o\">*</span> <span class=\"n\">h_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span><span class=\"p\">;</span>\n\n<span class=\"c1\">//         const float itm[8][8] = {\n</span><span class=\"c1\">//             {1.0f,  0.0f, -5.25f,  0.00f,  5.25f,  0.00f, -1.0f, 0.0f},\n</span><span class=\"c1\">//\n</span><span class=\"c1\">//             {0.0f,  1.0f,  1.00f, -4.25f, -4.25f,  1.00f,  1.0f, 0.0f},\n</span><span class=\"c1\">//             {0.0f, -1.0f,  1.00f,  4.25f, -4.25f, -1.00f,  1.0f, 0.0f},\n</span><span class=\"c1\">//\n</span><span class=\"c1\">//             {0.0f,  0.5f,  0.25f, -2.50f, -1.25f,  2.00f,  1.0f, 0.0f},\n</span><span class=\"c1\">//             {0.0f, -0.5f,  0.25f,  2.50f, -1.25f, -2.00f,  1.0f, 0.0f},\n</span><span class=\"c1\">//\n</span><span class=\"c1\">//             {0.0f,  2.0f,  4.00f, -2.50f, -5.00f,  0.50f,  1.0f, 0.0f},\n</span><span class=\"c1\">//             {0.0f, -2.0f,  4.00f,  2.50f, -5.00f, -0.50f,  1.0f, 0.0f},\n</span><span class=\"c1\">//\n</span><span class=\"c1\">//             {0.0f, -1.0f,  0.00f,  5.25f,  0.00f, -5.25f,  0.0f, 1.0f}\n</span><span class=\"c1\">//         };\n</span><span class=\"c1\"></span>\n        <span class=\"c1\">// 0 = r00 - r06 + (r04 - r02) * 5.25\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 7 = r07 - r01 + (r03 - r05) * 5.25\n</span><span class=\"c1\"></span>\n        <span class=\"c1\">// 1 = (r02 + r06 - r04 * 4.25) + (r01 - r03 * 4.25 + r05)\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 2 = (r02 + r06 - r04 * 4.25) - (r01 - r03 * 4.25 + r05)\n</span><span class=\"c1\"></span>\n        <span class=\"c1\">// 3 = (r06 + r02 * 0.25 - r04 * 1.25) + (r01 * 0.5 - r03 * 2.5 + r05 * 2)\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 4 = (r06 + r02 * 0.25 - r04 * 1.25) - (r01 * 0.5 - r03 * 2.5 + r05 * 2)\n</span><span class=\"c1\"></span>\n        <span class=\"c1\">// reuse r04 * 1.25\n</span><span class=\"c1\"></span>        <span class=\"c1\">// reuse r03 * 2.5\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 5 = (r06 + (r02 - r04 * 1.25) * 4) + (r01 * 2 - r03 * 2.5 + r05 * 0.5)\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 6 = (r06 + (r02 - r04 * 1.25) * 4) - (r01 * 2 - r03 * 2.5 + r05 * 0.5)\n</span><span class=\"c1\"></span>\n        <span class=\"cp\">#pragma omp parallel for num_threads(opt.num_threads)\n</span><span class=\"cp\"></span>        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">&lt;</span><span class=\"n\">inch</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"k\">const</span> <span class=\"n\">Mat</span> <span class=\"n\">img0</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob_bordered</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n            <span class=\"n\">Mat</span> <span class=\"n\">img0_tm</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n\n            <span class=\"kt\">float</span> <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">][</span><span class=\"mi\">8</span><span class=\"p\">];</span>\n\n            <span class=\"c1\">// tile\n</span><span class=\"c1\"></span>            <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">h_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">j</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"n\">w_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n                    <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">r0</span> <span class=\"o\">=</span> <span class=\"n\">img0</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"mi\">6</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">j</span> <span class=\"o\">*</span> <span class=\"mi\">6</span><span class=\"p\">;</span>\n\n                    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">&lt;</span><span class=\"mi\">8</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                    <span class=\"p\">{</span>\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">])</span> <span class=\"o\">*</span> <span class=\"mf\">5.25f</span><span class=\"p\">;</span>\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">])</span> <span class=\"o\">*</span> <span class=\"mf\">5.25f</span><span class=\"p\">;</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp12a</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">4.25f</span><span class=\"p\">);</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp12b</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">4.25f</span><span class=\"p\">);</span>\n\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp12a</span> <span class=\"o\">+</span> <span class=\"n\">tmp12b</span><span class=\"p\">;</span>\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp12a</span> <span class=\"o\">-</span> <span class=\"n\">tmp12b</span><span class=\"p\">;</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp34a</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">0.25f</span> <span class=\"o\">-</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">1.25f</span><span class=\"p\">);</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp34b</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">0.5f</span> <span class=\"o\">-</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">2.5f</span> <span class=\"o\">+</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">2.f</span><span class=\"p\">);</span>\n\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp34a</span> <span class=\"o\">+</span> <span class=\"n\">tmp34b</span><span class=\"p\">;</span>\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp34a</span> <span class=\"o\">-</span> <span class=\"n\">tmp34b</span><span class=\"p\">;</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp56a</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">1.25f</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"mf\">4.f</span><span class=\"p\">);</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp56b</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">2.f</span> <span class=\"o\">-</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">2.5f</span> <span class=\"o\">+</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">0.5f</span><span class=\"p\">);</span>\n\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp56a</span> <span class=\"o\">+</span> <span class=\"n\">tmp56b</span><span class=\"p\">;</span>\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp56a</span> <span class=\"o\">-</span> <span class=\"n\">tmp56b</span><span class=\"p\">;</span>\n\n                        <span class=\"n\">r0</span> <span class=\"o\">+=</span> <span class=\"n\">w</span><span class=\"p\">;</span>\n                    <span class=\"p\">}</span>\n\n                    <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">r0_tm_0</span> <span class=\"o\">=</span> <span class=\"n\">img0_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">w_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j</span><span class=\"p\">);</span>\n                    <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">r0_tm_4</span> <span class=\"o\">=</span> <span class=\"n\">img0_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">w_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j</span> <span class=\"o\">+</span> <span class=\"n\">tiles</span><span class=\"p\">);</span>\n\n                    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">&lt;</span><span class=\"mi\">8</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                    <span class=\"p\">{</span>\n                        <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">tmp0</span> <span class=\"o\">=</span> <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n\n                        <span class=\"n\">r0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">])</span> <span class=\"o\">*</span> <span class=\"mf\">5.25f</span><span class=\"p\">;</span>\n                        <span class=\"n\">r0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">])</span> <span class=\"o\">*</span> <span class=\"mf\">5.25f</span><span class=\"p\">;</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp12a</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">4.25f</span><span class=\"p\">);</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp12b</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">4.25f</span> <span class=\"o\">+</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]);</span>\n\n                        <span class=\"n\">r0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp12a</span> <span class=\"o\">+</span> <span class=\"n\">tmp12b</span><span class=\"p\">;</span>\n                        <span class=\"n\">r0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp12a</span> <span class=\"o\">-</span> <span class=\"n\">tmp12b</span><span class=\"p\">;</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp34a</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">0.25f</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">1.25f</span><span class=\"p\">);</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp34b</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">0.5f</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">2.5f</span> <span class=\"o\">+</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">2.f</span><span class=\"p\">);</span>\n\n                        <span class=\"n\">r0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp34a</span> <span class=\"o\">+</span> <span class=\"n\">tmp34b</span><span class=\"p\">;</span>\n                        <span class=\"n\">r0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp34a</span> <span class=\"o\">-</span> <span class=\"n\">tmp34b</span><span class=\"p\">;</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp56a</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">1.25f</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"mf\">4.f</span><span class=\"p\">);</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp56b</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">2.f</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">2.5f</span> <span class=\"o\">+</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mf\">0.5f</span><span class=\"p\">);</span>\n\n                        <span class=\"n\">r0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp56a</span> <span class=\"o\">+</span> <span class=\"n\">tmp56b</span><span class=\"p\">;</span>\n                        <span class=\"n\">r0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp56a</span> <span class=\"o\">-</span> <span class=\"n\">tmp56b</span><span class=\"p\">;</span>\n\n                        <span class=\"n\">r0_tm_0</span> <span class=\"o\">+=</span> <span class=\"n\">img0_tm</span><span class=\"p\">.</span><span class=\"n\">w</span> <span class=\"o\">*</span> <span class=\"n\">tiles</span> <span class=\"o\">*</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n                        <span class=\"n\">r0_tm_4</span> <span class=\"o\">+=</span> <span class=\"n\">img0_tm</span><span class=\"p\">.</span><span class=\"n\">w</span> <span class=\"o\">*</span> <span class=\"n\">tiles</span> <span class=\"o\">*</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n                    <span class=\"p\">}</span>\n                <span class=\"p\">}</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"n\">bottom_blob_bordered</span> <span class=\"o\">=</span> <span class=\"n\">Mat</span><span class=\"p\">();</span>\n</code></pre></div><p>这里是计算V矩阵，并直接在存储时就对内存进行了重排，过程示意图如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-83a103454c5d37655d6c55704ea1aabb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"761\" data-rawheight=\"502\" class=\"origin_image zh-lightbox-thumb\" width=\"761\" data-original=\"https://pic4.zhimg.com/v2-83a103454c5d37655d6c55704ea1aabb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;761&#39; height=&#39;502&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"761\" data-rawheight=\"502\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"761\" data-original=\"https://pic4.zhimg.com/v2-83a103454c5d37655d6c55704ea1aabb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-83a103454c5d37655d6c55704ea1aabb_b.jpg\"/></figure><p>这里tiles表示一个channel能拆成多少个tile，B是转换矩阵，b表示tile的序号，c代表input_channel</p><p>计算出来的V矩阵理应是8x8连续矩阵，但存的时候被4个4个岔开来存，间隔tiles行。这里没有对channel做压缩，输入blob的一个channel对应输出blob的一个channel</p><p><b>(2) M矩阵计算</b></p><p>M矩阵是啥？公式如下：</p><p><img src=\"https://www.zhihu.com/equation?tex=M_%7Bk%2Cb%7D+%3D+%5Csum_%7Bc%7D%5E%7B+%7D%7BU_%7Bk%2Cc%7D%5Codot+V_%7Bc%2Cb%7D%7D\" alt=\"M_{k,b} = \\sum_{c}^{ }{U_{k,c}\\odot V_{c,b}}\" eeimg=\"1\"/> </p><p>换句话说，M由U、V矩阵对应元素相乘得到。计算了M后，通过如下公式即可计算出最终结果：</p><p><img src=\"https://www.zhihu.com/equation?tex=Y_%7Bk%2Cb%7D+%3D+A%5E%7BT%7D+M_%7Bk%2Cb%7D+A\" alt=\"Y_{k,b} = A^{T} M_{k,b} A\" eeimg=\"1\"/> </p><p>k代表output_channel，b同上代表tile序号</p><div class=\"highlight\"><pre><code class=\"language-cpp\">    <span class=\"n\">Mat</span> <span class=\"n\">top_blob_tm</span><span class=\"p\">;</span>\n    <span class=\"p\">{</span>\n        <span class=\"kt\">int</span> <span class=\"n\">w_tm</span> <span class=\"o\">=</span> <span class=\"n\">outw</span> <span class=\"o\">/</span> <span class=\"mi\">6</span> <span class=\"o\">*</span> <span class=\"mi\">8</span><span class=\"p\">;</span>\n        <span class=\"kt\">int</span> <span class=\"n\">h_tm</span> <span class=\"o\">=</span> <span class=\"n\">outh</span> <span class=\"o\">/</span> <span class=\"mi\">6</span> <span class=\"o\">*</span> <span class=\"mi\">8</span><span class=\"p\">;</span>\n        <span class=\"n\">top_blob_tm</span><span class=\"p\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">16</span> <span class=\"o\">*</span> <span class=\"n\">w_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span> <span class=\"o\">*</span> <span class=\"n\">h_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">outch</span><span class=\"p\">,</span> <span class=\"mi\">4u</span><span class=\"p\">,</span> <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">workspace_allocator</span><span class=\"p\">);</span>\n\n        <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">tiles</span> <span class=\"o\">=</span> <span class=\"n\">h_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span> <span class=\"o\">*</span> <span class=\"n\">w_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span><span class=\"p\">;</span>\n\n        <span class=\"kt\">int</span> <span class=\"n\">nn_outch</span> <span class=\"o\">=</span> <span class=\"n\">outch</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n        <span class=\"kt\">int</span> <span class=\"n\">remain_outch_start</span> <span class=\"o\">=</span> <span class=\"n\">nn_outch</span> <span class=\"o\">&lt;&lt;</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n\n        <span class=\"cp\">#pragma omp parallel for num_threads(opt.num_threads)\n</span><span class=\"cp\"></span>        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">pp</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">pp</span><span class=\"o\">&lt;</span><span class=\"n\">nn_outch</span><span class=\"p\">;</span> <span class=\"n\">pp</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"kt\">int</span> <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">pp</span> <span class=\"o\">*</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n\n            <span class=\"n\">Mat</span> <span class=\"n\">out0_tm</span> <span class=\"o\">=</span> <span class=\"n\">top_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">);</span>\n            <span class=\"n\">Mat</span> <span class=\"n\">out1_tm</span> <span class=\"o\">=</span> <span class=\"n\">top_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n            <span class=\"n\">Mat</span> <span class=\"n\">out2_tm</span> <span class=\"o\">=</span> <span class=\"n\">top_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">+</span><span class=\"mi\">2</span><span class=\"p\">);</span>\n            <span class=\"n\">Mat</span> <span class=\"n\">out3_tm</span> <span class=\"o\">=</span> <span class=\"n\">top_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">+</span><span class=\"mi\">3</span><span class=\"p\">);</span>\n\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">ktm</span> <span class=\"o\">=</span> <span class=\"n\">kernel_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">pp</span><span class=\"p\">);</span>\n\n            <span class=\"n\">out0_tm</span><span class=\"p\">.</span><span class=\"n\">fill</span><span class=\"p\">(</span><span class=\"mf\">0.f</span><span class=\"p\">);</span>\n            <span class=\"n\">out1_tm</span><span class=\"p\">.</span><span class=\"n\">fill</span><span class=\"p\">(</span><span class=\"mf\">0.f</span><span class=\"p\">);</span>\n            <span class=\"n\">out2_tm</span><span class=\"p\">.</span><span class=\"n\">fill</span><span class=\"p\">(</span><span class=\"mf\">0.f</span><span class=\"p\">);</span>\n            <span class=\"n\">out3_tm</span><span class=\"p\">.</span><span class=\"n\">fill</span><span class=\"p\">(</span><span class=\"mf\">0.f</span><span class=\"p\">);</span>\n\n            <span class=\"kt\">int</span> <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n\n            <span class=\"k\">for</span> <span class=\"p\">(;</span> <span class=\"n\">q</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"o\">&lt;</span><span class=\"n\">inch</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">+=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">r0</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n                <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">r1</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n\n                <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output0_tm</span> <span class=\"o\">=</span> <span class=\"n\">out0_tm</span><span class=\"p\">;</span>\n                <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output1_tm</span> <span class=\"o\">=</span> <span class=\"n\">out1_tm</span><span class=\"p\">;</span>\n                <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output2_tm</span> <span class=\"o\">=</span> <span class=\"n\">out2_tm</span><span class=\"p\">;</span>\n                <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output3_tm</span> <span class=\"o\">=</span> <span class=\"n\">out3_tm</span><span class=\"p\">;</span>\n\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">r</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">&lt;</span><span class=\"mi\">16</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n                    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">t</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">t</span><span class=\"o\">&lt;</span><span class=\"n\">tiles</span><span class=\"p\">;</span> <span class=\"n\">t</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                    <span class=\"p\">{</span>\n                        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">&lt;</span><span class=\"mi\">4</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                        <span class=\"p\">{</span>\n                            <span class=\"n\">output0_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">0</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                            <span class=\"n\">output0_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r1</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">4</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                            <span class=\"n\">output1_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">8</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                            <span class=\"n\">output1_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r1</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">12</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                            <span class=\"n\">output2_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">16</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                            <span class=\"n\">output2_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r1</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">20</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                            <span class=\"n\">output3_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">24</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                            <span class=\"n\">output3_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r1</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">28</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                        <span class=\"p\">}</span>\n\n                        <span class=\"n\">r0</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">r1</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">output0_tm</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">output1_tm</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">output2_tm</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">output3_tm</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                    <span class=\"p\">}</span>\n\n                    <span class=\"n\">ktm</span> <span class=\"o\">+=</span> <span class=\"mi\">32</span><span class=\"p\">;</span>\n                <span class=\"p\">}</span>\n            <span class=\"p\">}</span>\n\n            <span class=\"k\">for</span> <span class=\"p\">(;</span> <span class=\"n\">q</span><span class=\"o\">&lt;</span><span class=\"n\">inch</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">r0</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n\n                <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output0_tm</span> <span class=\"o\">=</span> <span class=\"n\">out0_tm</span><span class=\"p\">;</span>\n                <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output1_tm</span> <span class=\"o\">=</span> <span class=\"n\">out1_tm</span><span class=\"p\">;</span>\n                <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output2_tm</span> <span class=\"o\">=</span> <span class=\"n\">out2_tm</span><span class=\"p\">;</span>\n                <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output3_tm</span> <span class=\"o\">=</span> <span class=\"n\">out3_tm</span><span class=\"p\">;</span>\n\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">r</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">&lt;</span><span class=\"mi\">16</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n                    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">t</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">t</span><span class=\"o\">&lt;</span><span class=\"n\">tiles</span><span class=\"p\">;</span> <span class=\"n\">t</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                    <span class=\"p\">{</span>\n                        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">&lt;</span><span class=\"mi\">4</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                        <span class=\"p\">{</span>\n                            <span class=\"n\">output0_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">0</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                            <span class=\"n\">output1_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">4</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                            <span class=\"n\">output2_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">8</span> <span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                            <span class=\"n\">output3_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"mi\">12</span><span class=\"o\">+</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                        <span class=\"p\">}</span>\n\n                        <span class=\"n\">r0</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">output0_tm</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">output1_tm</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">output2_tm</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">output3_tm</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                    <span class=\"p\">}</span>\n\n                    <span class=\"n\">ktm</span> <span class=\"o\">+=</span> <span class=\"mi\">16</span><span class=\"p\">;</span>\n                <span class=\"p\">}</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"cp\">#pragma omp parallel for num_threads(opt.num_threads)\n</span><span class=\"cp\"></span>        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">remain_outch_start</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">&lt;</span><span class=\"n\">outch</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"n\">Mat</span> <span class=\"n\">out0_tm</span> <span class=\"o\">=</span> <span class=\"n\">top_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">);</span>\n\n            <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">ktm</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">kernel_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">nn_outch</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">8</span><span class=\"o\">*</span><span class=\"mi\">8</span> <span class=\"o\">*</span> <span class=\"n\">inch</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">-</span><span class=\"n\">remain_outch_start</span><span class=\"p\">);</span>\n\n            <span class=\"n\">out0_tm</span><span class=\"p\">.</span><span class=\"n\">fill</span><span class=\"p\">(</span><span class=\"mf\">0.f</span><span class=\"p\">);</span>\n\n            <span class=\"kt\">int</span> <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n\n            <span class=\"k\">for</span> <span class=\"p\">(;</span> <span class=\"n\">q</span><span class=\"o\">&lt;</span><span class=\"n\">inch</span><span class=\"p\">;</span> <span class=\"n\">q</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">r0</span> <span class=\"o\">=</span> <span class=\"n\">bottom_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">);</span>\n\n                <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output0_tm</span> <span class=\"o\">=</span> <span class=\"n\">out0_tm</span><span class=\"p\">;</span>\n\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">r</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">&lt;</span><span class=\"mi\">16</span><span class=\"p\">;</span> <span class=\"n\">r</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n\n                <span class=\"c1\">// tile\n</span><span class=\"c1\"></span>                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">tiles</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n                    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">&lt;</span><span class=\"mi\">4</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                    <span class=\"p\">{</span>\n                        <span class=\"n\">output0_tm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">r0</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">ktm</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n                    <span class=\"p\">}</span>\n\n                    <span class=\"n\">r0</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                    <span class=\"n\">output0_tm</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"p\">}</span>\n\n                <span class=\"n\">ktm</span> <span class=\"o\">+=</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                <span class=\"p\">}</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"n\">bottom_blob_tm</span> <span class=\"o\">=</span> <span class=\"n\">Mat</span><span class=\"p\">();</span>\n</code></pre></div><p>这段计算比较复杂，说实话懒得写具体的计算流程了，因为需要对着上面的内容看。总而言之，经过上面的流程，可以得到各个M矩阵，其排布如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-71c2fdf127188ceb3cbf88a00fe3c0b5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"601\" data-rawheight=\"718\" class=\"origin_image zh-lightbox-thumb\" width=\"601\" data-original=\"https://pic2.zhimg.com/v2-71c2fdf127188ceb3cbf88a00fe3c0b5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;601&#39; height=&#39;718&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"601\" data-rawheight=\"718\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"601\" data-original=\"https://pic2.zhimg.com/v2-71c2fdf127188ceb3cbf88a00fe3c0b5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-71c2fdf127188ceb3cbf88a00fe3c0b5_b.jpg\"/></figure><p>可以看到，还是交错排布的</p><p><b>(3) 结果Y计算</b></p><p><img src=\"https://www.zhihu.com/equation?tex=Y_%7Bk%2Cb%7D+%3D+A%5E%7BT%7D+M_%7Bk%2Cb%7D+A\" alt=\"Y_{k,b} = A^{T} M_{k,b} A\" eeimg=\"1\"/> </p><div class=\"highlight\"><pre><code class=\"language-cpp\">    <span class=\"n\">Mat</span> <span class=\"n\">top_blob_bordered</span><span class=\"p\">;</span>\n    <span class=\"n\">top_blob_bordered</span><span class=\"p\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"n\">outw</span><span class=\"p\">,</span> <span class=\"n\">outh</span><span class=\"p\">,</span> <span class=\"n\">outch</span><span class=\"p\">,</span> <span class=\"mi\">4u</span><span class=\"p\">,</span> <span class=\"n\">opt</span><span class=\"p\">.</span><span class=\"n\">workspace_allocator</span><span class=\"p\">);</span>\n    <span class=\"p\">{</span>\n<span class=\"c1\">//         const float otm[6][8] = {\n</span><span class=\"c1\">//             {1.0f,  1.0f,   1.0f,   1.0f,   1.0f,  32.0f, 32.0f, 0.0f},\n</span><span class=\"c1\">//             {0.0f,  1.0f,  -1.0f,   2.0f,  -2.0f,  16.0f,-16.0f, 0.0f},\n</span><span class=\"c1\">//             {0.0f,  1.0f,   1.0f,   4.0f,   4.0f,   8.0f,  8.0f, 0.0f},\n</span><span class=\"c1\">//             {0.0f,  1.0f,  -1.0f,   8.0f,  -8.0f,   4.0f, -4.0f, 0.0f},\n</span><span class=\"c1\">//             {0.0f,  1.0f,   1.0f,  16.0f,  16.0f,   2.0f,  2.0f, 0.0f},\n</span><span class=\"c1\">//             {0.0f,  1.0f,  -1.0f,  32.0f, -32.0f,   1.0f, -1.0f, 1.0f}\n</span><span class=\"c1\">//         };\n</span><span class=\"c1\"></span>\n        <span class=\"c1\">// 0 = r0 + (r1 + r2) + (r3 + r4)     + (r5 + r6) * 32\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 1 =      (r1 - r2) + (r3 - r4) * 2 + (r5 - r6) * 16\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 2 =      (r1 + r2) + (r3 + r4) * 4 + (r5 + r6) * 8\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 3 =      (r1 - r2) + (r3 - r4) * 8 + (r5 - r6) * 4\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 4 =      (r1 + r2) + (r3 + r4) * 16+ (r5 + r6) * 2\n</span><span class=\"c1\"></span>        <span class=\"c1\">// 5 = r7 + (r1 - r2) + (r3 - r4) * 32+ (r5 - r6)\n</span><span class=\"c1\"></span>\n        <span class=\"kt\">int</span> <span class=\"n\">w_tm</span> <span class=\"o\">=</span> <span class=\"n\">outw</span> <span class=\"o\">/</span> <span class=\"mi\">6</span> <span class=\"o\">*</span> <span class=\"mi\">8</span><span class=\"p\">;</span>\n        <span class=\"kt\">int</span> <span class=\"n\">h_tm</span> <span class=\"o\">=</span> <span class=\"n\">outh</span> <span class=\"o\">/</span> <span class=\"mi\">6</span> <span class=\"o\">*</span> <span class=\"mi\">8</span><span class=\"p\">;</span>\n        <span class=\"k\">const</span> <span class=\"kt\">int</span> <span class=\"n\">tiles</span> <span class=\"o\">=</span> <span class=\"n\">w_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span> <span class=\"o\">*</span> <span class=\"n\">h_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span><span class=\"p\">;</span>\n\n        <span class=\"cp\">#pragma omp parallel for num_threads(opt.num_threads)\n</span><span class=\"cp\"></span>        <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">&lt;</span><span class=\"n\">outch</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">++</span><span class=\"p\">)</span>\n        <span class=\"p\">{</span>\n            <span class=\"k\">const</span> <span class=\"n\">Mat</span> <span class=\"n\">out0_tm</span> <span class=\"o\">=</span> <span class=\"n\">top_blob_tm</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">);</span>\n            <span class=\"n\">Mat</span> <span class=\"n\">out0</span> <span class=\"o\">=</span> <span class=\"n\">top_blob_bordered</span><span class=\"p\">.</span><span class=\"n\">channel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">);</span>\n\n            <span class=\"k\">const</span> <span class=\"kt\">float</span> <span class=\"n\">bias0</span> <span class=\"o\">=</span> <span class=\"n\">bias</span> <span class=\"o\">?</span> <span class=\"n\">bias</span><span class=\"p\">[</span><span class=\"n\">p</span><span class=\"p\">]</span> <span class=\"o\">:</span> <span class=\"mf\">0.f</span><span class=\"p\">;</span>\n\n            <span class=\"kt\">float</span> <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">][</span><span class=\"mi\">8</span><span class=\"p\">];</span>\n\n            <span class=\"c1\">// tile\n</span><span class=\"c1\"></span>            <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">outh</span><span class=\"o\">/</span><span class=\"mi\">6</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span>\n            <span class=\"p\">{</span>\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">j</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"n\">outw</span><span class=\"o\">/</span><span class=\"mi\">6</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                <span class=\"p\">{</span>\n                    <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output0_tm_0</span> <span class=\"o\">=</span> <span class=\"n\">out0_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">w_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j</span><span class=\"p\">);</span>\n                    <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output0_tm_4</span> <span class=\"o\">=</span> <span class=\"n\">out0_tm</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"n\">w_tm</span><span class=\"o\">/</span><span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j</span> <span class=\"o\">+</span> <span class=\"n\">tiles</span><span class=\"p\">);</span>\n\n                    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">&lt;</span><span class=\"mi\">8</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                    <span class=\"p\">{</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp024a</span> <span class=\"o\">=</span> <span class=\"n\">output0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">output0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp135a</span> <span class=\"o\">=</span> <span class=\"n\">output0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">output0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp024b</span> <span class=\"o\">=</span> <span class=\"n\">output0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">output0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">];</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp135b</span> <span class=\"o\">=</span> <span class=\"n\">output0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">output0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">];</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp024c</span> <span class=\"o\">=</span> <span class=\"n\">output0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">output0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp135c</span> <span class=\"o\">=</span> <span class=\"n\">output0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">output0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">output0_tm_0</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmp024a</span> <span class=\"o\">+</span> <span class=\"n\">tmp024b</span> <span class=\"o\">+</span> <span class=\"n\">tmp024c</span> <span class=\"o\">*</span> <span class=\"mi\">32</span><span class=\"p\">;</span>\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp024a</span> <span class=\"o\">+</span> <span class=\"n\">tmp024b</span> <span class=\"o\">*</span> <span class=\"mi\">4</span> <span class=\"o\">+</span> <span class=\"n\">tmp024c</span> <span class=\"o\">*</span> <span class=\"mi\">8</span><span class=\"p\">;</span>\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp024a</span> <span class=\"o\">+</span> <span class=\"n\">tmp024b</span> <span class=\"o\">*</span> <span class=\"mi\">16</span> <span class=\"o\">+</span> <span class=\"n\">tmp024c</span> <span class=\"o\">+</span> <span class=\"n\">tmp024c</span><span class=\"p\">;</span>\n\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp135a</span> <span class=\"o\">+</span> <span class=\"n\">tmp135b</span> <span class=\"o\">+</span> <span class=\"n\">tmp135b</span> <span class=\"o\">+</span> <span class=\"n\">tmp135c</span> <span class=\"o\">*</span> <span class=\"mi\">16</span><span class=\"p\">;</span>\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tmp135a</span> <span class=\"o\">+</span> <span class=\"n\">tmp135b</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">tmp135c</span> <span class=\"o\">*</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">][</span><span class=\"n\">m</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">output0_tm_4</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmp135a</span> <span class=\"o\">+</span> <span class=\"n\">tmp135b</span> <span class=\"o\">*</span> <span class=\"mi\">32</span> <span class=\"o\">+</span> <span class=\"n\">tmp135c</span><span class=\"p\">;</span>\n\n                        <span class=\"n\">output0_tm_0</span> <span class=\"o\">+=</span> <span class=\"n\">out0_tm</span><span class=\"p\">.</span><span class=\"n\">w</span> <span class=\"o\">*</span> <span class=\"n\">tiles</span> <span class=\"o\">*</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n                        <span class=\"n\">output0_tm_4</span> <span class=\"o\">+=</span> <span class=\"n\">out0_tm</span><span class=\"p\">.</span><span class=\"n\">w</span> <span class=\"o\">*</span> <span class=\"n\">tiles</span> <span class=\"o\">*</span> <span class=\"mi\">2</span><span class=\"p\">;</span>\n                    <span class=\"p\">}</span>\n\n                    <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output0</span> <span class=\"o\">=</span> <span class=\"n\">out0</span><span class=\"p\">.</span><span class=\"n\">row</span><span class=\"p\">(</span><span class=\"n\">i</span> <span class=\"o\">*</span> <span class=\"mi\">6</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">j</span> <span class=\"o\">*</span> <span class=\"mi\">6</span><span class=\"p\">;</span>\n\n                    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">&lt;</span><span class=\"mi\">6</span><span class=\"p\">;</span> <span class=\"n\">m</span><span class=\"o\">++</span><span class=\"p\">)</span>\n                    <span class=\"p\">{</span>\n                        <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">tmp0</span> <span class=\"o\">=</span> <span class=\"n\">tmp</span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"p\">];</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp024a</span> <span class=\"o\">=</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp135a</span> <span class=\"o\">=</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">];</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp024b</span> <span class=\"o\">=</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">];</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp135b</span> <span class=\"o\">=</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">];</span>\n\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp024c</span> <span class=\"o\">=</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">];</span>\n                        <span class=\"kt\">float</span> <span class=\"n\">tmp135c</span> <span class=\"o\">=</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">];</span>\n\n                        <span class=\"n\">output0</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">bias0</span> <span class=\"o\">+</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmp024a</span> <span class=\"o\">+</span> <span class=\"n\">tmp024b</span> <span class=\"o\">+</span> <span class=\"n\">tmp024c</span> <span class=\"o\">*</span> <span class=\"mi\">32</span><span class=\"p\">;</span>\n                        <span class=\"n\">output0</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">bias0</span> <span class=\"o\">+</span> <span class=\"n\">tmp024a</span> <span class=\"o\">+</span> <span class=\"n\">tmp024b</span> <span class=\"o\">*</span> <span class=\"mi\">4</span> <span class=\"o\">+</span> <span class=\"n\">tmp024c</span> <span class=\"o\">*</span> <span class=\"mi\">8</span><span class=\"p\">;</span>\n                        <span class=\"n\">output0</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">bias0</span> <span class=\"o\">+</span> <span class=\"n\">tmp024a</span> <span class=\"o\">+</span> <span class=\"n\">tmp024b</span> <span class=\"o\">*</span> <span class=\"mi\">16</span> <span class=\"o\">+</span> <span class=\"n\">tmp024c</span> <span class=\"o\">+</span> <span class=\"n\">tmp024c</span><span class=\"p\">;</span>\n\n                        <span class=\"n\">output0</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">bias0</span> <span class=\"o\">+</span> <span class=\"n\">tmp135a</span> <span class=\"o\">+</span> <span class=\"n\">tmp135b</span> <span class=\"o\">+</span> <span class=\"n\">tmp135b</span> <span class=\"o\">+</span> <span class=\"n\">tmp135c</span> <span class=\"o\">*</span> <span class=\"mi\">16</span><span class=\"p\">;</span>\n                        <span class=\"n\">output0</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">bias0</span> <span class=\"o\">+</span> <span class=\"n\">tmp135a</span> <span class=\"o\">+</span> <span class=\"n\">tmp135b</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">tmp135c</span> <span class=\"o\">*</span> <span class=\"mi\">4</span><span class=\"p\">;</span>\n                        <span class=\"n\">output0</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">bias0</span> <span class=\"o\">+</span> <span class=\"n\">tmp0</span><span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tmp135a</span> <span class=\"o\">+</span> <span class=\"n\">tmp135b</span> <span class=\"o\">*</span> <span class=\"mi\">32</span> <span class=\"o\">+</span> <span class=\"n\">tmp135c</span><span class=\"p\">;</span>\n\n                        <span class=\"n\">output0</span> <span class=\"o\">+=</span> <span class=\"n\">outw</span><span class=\"p\">;</span>\n                    <span class=\"p\">}</span>\n                <span class=\"p\">}</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n</code></pre></div><p>这里就是要将M矩阵的结果汇聚并用A矩阵得到最终的结果Y，示意图如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5f6b6f7d60ae217745b333261f61857d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"510\" class=\"origin_image zh-lightbox-thumb\" width=\"690\" data-original=\"https://pic2.zhimg.com/v2-5f6b6f7d60ae217745b333261f61857d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;690&#39; height=&#39;510&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"690\" data-rawheight=\"510\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"690\" data-original=\"https://pic2.zhimg.com/v2-5f6b6f7d60ae217745b333261f61857d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5f6b6f7d60ae217745b333261f61857d_b.jpg\"/></figure><p>至此，计算结束</p><h2>3、 小结</h2><p>本文简要介绍了Winograd的原理，大家还是最好去读一下原文，比我讲的好多了</p><p>之后我们分析了NCNN Winograd的顶层源码，可以看到Winograd并不是什么时候都快的，只有在特定情况下才会选用</p><p>之后我们详细分析了NCNN Winograd 3x3 s1的代码逻辑，分为如下几步：</p><ul><li>初始化时决定是否使用winograd</li><li>初始化时计算U矩阵并重排</li><li>运行时计算V矩阵并重排</li><li>计算M矩阵</li><li>计算结果Y并重排回来</li></ul><p>这里U矩阵是计算好了再单独重排，是整个过程中唯一一个不计算单纯重排的操作。其他过程都是一边计算一边重排。这点其实是可以优化的（可能后续版本已经优化了我还没看到23333）</p><p>另外，本文把汇编代码都去掉了，只分析了C代码，目的是方便分析。后面会补上汇编部分的讲解</p><p>如有不足请各位指正</p><p>谢谢！</p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "高性能计算", 
                    "tagLink": "https://api.zhihu.com/topics/19608622"
                }, 
                {
                    "tag": "计算机视觉", 
                    "tagLink": "https://api.zhihu.com/topics/19590195"
                }
            ], 
            "comments": [
                {
                    "userName": "王小二", 
                    "userLink": "https://www.zhihu.com/people/f6667623cf045e112fc9a30f995a9742", 
                    "content": "这次需要 <a class=\"member_mention\" href=\"http://www.zhihu.com/people/fb1221929503e7fbec20a21626d297a7\" data-hash=\"fb1221929503e7fbec20a21626d297a7\" data-hovercard=\"p$b$fb1221929503e7fbec20a21626d297a7\">@nihui </a>来主持了", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "圈圈虫", 
                            "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                            "content": "然而虫叔来啦[爱]", 
                            "likes": 0, 
                            "replyToAuthor": "王小二"
                        }
                    ]
                }, 
                {
                    "userName": "圈圈虫", 
                    "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                    "content": "<a href=\"https://pic4.zhimg.com/v2-fa3cb6bc9ec57da84ab53a60f48d0c6f.gif\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"951517103955070976\">[棒]</a>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "文亚伟", 
                            "userLink": "https://www.zhihu.com/people/044d80f1ca18f59410287123305e2140", 
                            "content": "<p>虫叔，这个作者是你带的实习生吗？</p>", 
                            "likes": 0, 
                            "replyToAuthor": "圈圈虫"
                        }, 
                        {
                            "userName": "圈圈虫", 
                            "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                            "content": "并不是哇，认真学习的小朋友<a href=\"https://pic4.zhimg.com/v2-fa3cb6bc9ec57da84ab53a60f48d0c6f.gif\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"951517103955070976\">[棒]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "文亚伟"
                        }
                    ]
                }, 
                {
                    "userName": "圈圈虫", 
                    "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                    "content": "为啥把业界最慢的sgemm标红突出显示，伤心<a href=\"https://pic2.zhimg.com/v2-f941117b9911dd9af1a6b637fc22ee9d.gif\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"951517103774715904\">[安慰]</a>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "田子宸", 
                            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
                            "content": "<p>有点摸不清楚知乎的代码片是怎么标格式的，绝不是故意标红sgemm的</p><a class=\"comment_sticker\" href=\"https://pic2.zhimg.com/v2-f4bcc55c40efedc78401a3b6c59e50e5.gif\" data-width=\"\" data-height=\"\">[吃惊]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "圈圈虫"
                        }, 
                        {
                            "userName": "圈圈虫", 
                            "userLink": "https://www.zhihu.com/people/647087f95394a5f589bf72bf3edcb44f", 
                            "content": "<a href=\"https://pic2.zhimg.com/v2-2b7e64f732b793ac0c7323e9d71c9499.webp\" class=\"comment_sticker\" data-width=\"0\" data-height=\"0\" data-sticker-id=\"1029328993056542720\">[笔芯]</a>", 
                            "likes": 0, 
                            "replyToAuthor": "田子宸"
                        }
                    ]
                }, 
                {
                    "userName": "土豆丝", 
                    "userLink": "https://www.zhihu.com/people/62a0d60cdfa5e7ac193327797017a249", 
                    "content": "厉害[赞]毕设的方向也是部署加速，希望能推出更多相关的文章[大笑]", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "田子宸", 
                            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
                            "content": "<p>正好最近实习不是很忙，有空多写写，互相学习哈</p>", 
                            "likes": 0, 
                            "replyToAuthor": "土豆丝"
                        }, 
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "实习不忙 2333", 
                            "likes": 0, 
                            "replyToAuthor": "田子宸"
                        }
                    ]
                }, 
                {
                    "userName": "喵皇", 
                    "userLink": "https://www.zhihu.com/people/4593ea8904d87fa34fc23fbdb50d2d5a", 
                    "content": "顺朋友圈来，膜拜一下就走，反正我也看不懂", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "Aqua", 
                    "userLink": "https://www.zhihu.com/people/620986c82932e495b29eb61d1b9f5371", 
                    "content": "<p>有个疑问：最后计算出了Y_(k,b)，所以还是分一个个tile的，那么要怎么合并这些tile的卷积结果为整体的卷积结果呢？感觉不想是简单重排就可以的。</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "xhtseu", 
                    "userLink": "https://www.zhihu.com/people/f81211e066c438a6a9dbf4998f56c19d", 
                    "content": "<p>你好，开始计算的是U的转置吧 U=G.gT.GT</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/69132476", 
            "userName": "田子宸", 
            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
            "upvote": 195, 
            "title": "CUDA一些小知识整理", 
            "content": "<p>之前写过一篇<a href=\"https://zhuanlan.zhihu.com/p/53773183\" class=\"internal\">《CUDA C Programming Guide》(《CUDA C 编程指南》)导读</a>，整理了一下基础的知识，但没有真正实践过</p><p>最近由于工作需要使用到CUDA，因此需要再看一些书和博文，补一些知识。现将这些知识陈列在这里。</p><p>参考内容：</p><p><a href=\"https://zhuanlan.zhihu.com/p/38507817\" class=\"internal\">CUDA 基础知识博客整理</a></p><hr/><h2>CUDA错误码打印</h2><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">char</span><span class=\"o\">*</span> <span class=\"nf\">cudaGetErrorString</span><span class=\"p\">(</span><span class=\"n\">cudaError_t</span> <span class=\"n\">error</span><span class=\"p\">)</span>   <span class=\"c1\">// 将错误码转换成字符串\n</span><span class=\"c1\"></span>\n<span class=\"c1\">// 可以使用如下宏\n</span><span class=\"c1\"></span><span class=\"cp\">#define CHECK(call)\\\n</span><span class=\"cp\"></span><span class=\"p\">{</span>\\\n  <span class=\"k\">const</span> <span class=\"n\">cudaError_t</span> <span class=\"n\">error</span><span class=\"o\">=</span><span class=\"n\">call</span><span class=\"p\">;</span>\\\n  <span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">error</span><span class=\"o\">!=</span><span class=\"n\">cudaSuccess</span><span class=\"p\">)</span>\\\n  <span class=\"p\">{</span>\\\n      <span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">&#34;ERROR: %s:%d,&#34;</span><span class=\"p\">,</span><span class=\"n\">__FILE__</span><span class=\"p\">,</span><span class=\"n\">__LINE__</span><span class=\"p\">);</span>\\\n      <span class=\"n\">printf</span><span class=\"p\">(</span><span class=\"s\">&#34;code:%d,reason:%s</span><span class=\"se\">\\n</span><span class=\"s\">&#34;</span><span class=\"p\">,</span><span class=\"n\">error</span><span class=\"p\">,</span><span class=\"n\">cudaGetErrorString</span><span class=\"p\">(</span><span class=\"n\">error</span><span class=\"p\">));</span>\\\n      <span class=\"n\">exit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\\\n  <span class=\"p\">}</span>\\\n<span class=\"p\">}</span>\n</code></pre></div><h2>cuda所有kernel启动都是异步的</h2><h2>cudaMemcpy从设备端拷贝回主机端时，会触发一个隐式同步</h2><h2>cuda函数修饰符：</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-408a2d16d27da5e0a6a02f5dafd66273_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"249\" class=\"origin_image zh-lightbox-thumb\" width=\"624\" data-original=\"https://pic4.zhimg.com/v2-408a2d16d27da5e0a6a02f5dafd66273_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;624&#39; height=&#39;249&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"249\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"624\" data-original=\"https://pic4.zhimg.com/v2-408a2d16d27da5e0a6a02f5dafd66273_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-408a2d16d27da5e0a6a02f5dafd66273_b.jpg\"/></figure><p>如果被定义为__global<i>_</i>_，则会生成主机端和设备端两段代码</p><h2>Kernel核函数编写有以下限制</h2><ul><li>只能访问设备内存</li><li>必须有void返回类型</li><li>不支持可变数量的参数</li><li>不支持静态变量</li><li>显示异步行为</li></ul><h2>调试时，可以先把kernel配置成单线程执行</h2><div class=\"highlight\"><pre><code class=\"language-text\">MyKernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(参数)</code></pre></div><h2>使用nvprof可进行计时</h2><p>需要sudo权限（当然注意sudo和普通用户路径差异的问题）</p><p>cudaMalloc占用的时间很长，显存分配好后尽量重复应用</p><h2>查询设备信息</h2><div class=\"highlight\"><pre><code class=\"language-text\">nvidia-smi -q    // 可以查询所有信息</code></pre></div><p>当然也可以用API函数查</p><h2>一篇绝赞好文章：<a href=\"https://link.zhihu.com/?target=http%3A//face2ai.com/CUDA-F-3-1-CUDA%25E6%2589%25A7%25E8%25A1%258C%25E6%25A8%25A1%25E5%259E%258B%25E6%25A6%2582%25E8%25BF%25B0/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【CUDA 基础】3.1 CUDA执行模型概述</a></h2><p>讲了各个架构的硬件模型，有很多好内容、好图，对理解NVIDIA硬件很有帮助</p><h2>线程束的一种分类方式</h2><p>线程束</p><ul><li>被调度到SM上</li><ul><li>选定的线程束</li><ul><li>active的线程束（满足分支条件）</li><li>不active的线程束</li></ul><li>阻塞的线程束</li><li>ready的线程束（所有资源均已就绪）</li></ul><li>未被调度到SM上（寄存器、共享内存、程序计数器不够了）</li></ul><h2>延迟有两种：算数延迟和内存延迟，后者远长于前者；两者均应想办法隐藏</h2><h2>nvprof检测活跃的线程束</h2><div class=\"highlight\"><pre><code class=\"language-text\">nvprof --metrics achieved_occupancy ./program</code></pre></div><p>检测出来的是活跃线程束的比例，即每个周期活跃的线程束的平均值与一个sm支持的线程束最大值的比</p><h2>nvprof检测内存性能</h2><div class=\"highlight\"><pre><code class=\"language-text\">nvprof --metrics gld_throughput ./simple_sum_matrix\nnvprof --metrics gld_efficiency ./simple_sum_matrix</code></pre></div><h2>动态并行与嵌套执行</h2><p>等到执行的时候再配置创建多少个网格，多少个块，这样就可以动态的利用GPU硬件调度器和加载平衡器了，通过动态调整，来适应负载。</p><p>嵌套执行是内核调内核，涉及到一些隐式同步的问题，比较麻烦</p><p>父网格（父内核）调用子网格（子内核）的一种比较好的方式是：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-805a113cdb17e65550fbb58f924145ef_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"646\" data-rawheight=\"470\" class=\"origin_image zh-lightbox-thumb\" width=\"646\" data-original=\"https://pic4.zhimg.com/v2-805a113cdb17e65550fbb58f924145ef_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;646&#39; height=&#39;470&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"646\" data-rawheight=\"470\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"646\" data-original=\"https://pic4.zhimg.com/v2-805a113cdb17e65550fbb58f924145ef_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-805a113cdb17e65550fbb58f924145ef_b.jpg\"/></figure><h2>CUDA Kernel中定长数组也是放在寄存器里的</h2><h2>本地内存(Local Memory)</h2><p>编译器可能将如下三种数据放在本地内存：</p><ul><li>使用未知索引引用的本地数组</li><li>可能会占用大量寄存器空间的较大本地数组或者结构体</li><li>任何不满足核函数寄存器限定条件的变量</li></ul><p>对于2.0以上的设备，本地内存存储在每个SM的一级缓存，或者设备的二级缓存上。而不再是全局内存上。</p><h2>设置共享内存和L1 Cache的比例</h2><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaFuncSetCacheConfig(const void * func,enum cudaFuncCache);\n\ncudaFuncCachePreferNone//无参考值，默认设置\ncudaFuncCachePreferShared//48k共享内存，16k一级缓存\ncudaFuncCachePreferL1// 48k一级缓存，16k共享内存\ncudaFuncCachePreferEqual// 32k一级缓存，32k共享内存</code></pre></div><h2>常量内存</h2><p>每个SM都有自己专属的常量内存cache，大小为64KB</p><p>常量内存有广播的特性，即可以将一块内存的数据一次性给一个线程束；因此类似于多项式系数等变量最好放到常量内存里</p><p>常量内存的最优访问方式是所有线程访问同一个数据</p><div class=\"highlight\"><pre><code class=\"language-text\">__constant__    // 全局可见，生命周期为整个程序运行期间，所有线程网格的所有线程均可见\n\ncudaError_t cudaMemcpyToSymbol(const void* symbol,const void *src,size_t count);  // 只有主机端可以修改，同步</code></pre></div><h2>全局内存</h2><p>动态声明：cudaMalloc，用cudaMemcpy拷贝</p><p>静态声明：__device__，可以放到kernel内部，也可以放到外部声明为全局的</p><p>                    可以在设备端直接赋值；但由于主机端不能直接访问全局内存，需要使用cudaMemcpyToSymbol/cudaMemcpyFromSymbol来操作，这点和动态声明不同</p><h2>与CPU不同的是，CPU读写过程都有可能被缓存，但是GPU写的过程不被缓存，只有加载会被缓存！</h2><h2>CUDA变量总结</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7d962f9c730c8a6afb828c29cf7369fe_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"642\" data-rawheight=\"650\" class=\"origin_image zh-lightbox-thumb\" width=\"642\" data-original=\"https://pic3.zhimg.com/v2-7d962f9c730c8a6afb828c29cf7369fe_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;642&#39; height=&#39;650&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"642\" data-rawheight=\"650\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"642\" data-original=\"https://pic3.zhimg.com/v2-7d962f9c730c8a6afb828c29cf7369fe_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-7d962f9c730c8a6afb828c29cf7369fe_b.jpg\"/></figure><h2>固定内存（锁页内存）</h2><p>为了防止拷贝时系统换页，CUDA会保证所有数据都放在锁页内存上：</p><ul><li>将已分配内存锁定</li><li>直接分配锁页内存：cudaMallocHost/cudaFreeHost</li><li>自动分配一块锁页内存，将数据源拷贝至该锁页内存，再启动拷贝，如下图：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-41edaaf670207bbffff289f1d58eb10b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"577\" data-rawheight=\"308\" class=\"origin_image zh-lightbox-thumb\" width=\"577\" data-original=\"https://pic4.zhimg.com/v2-41edaaf670207bbffff289f1d58eb10b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;577&#39; height=&#39;308&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"577\" data-rawheight=\"308\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"577\" data-original=\"https://pic4.zhimg.com/v2-41edaaf670207bbffff289f1d58eb10b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-41edaaf670207bbffff289f1d58eb10b_b.jpg\"/></figure><p>但是注意：cudaMallocHost会比cudaMalloc慢，只是传输会比较快（不是应该包含的吗）</p><h2>零拷贝内存</h2><p>零拷贝内存在频繁读写的情况下效率极低，但是对于一些CPU和GPU使用同一块物理内存的情况下，效率极高</p><h2>同一虚拟寻址(UVA)</h2><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaHostAlloc(void ** pHost,size_t count,unsigned int flags)</code></pre></div><p>64位系统自动激活UVA，自动实现上述的零拷贝内存</p><p>使用cudaHostAlloc分配的内存，其指针可以被主机端核设备端共用</p><p>UVA可以简化开发，不过不如手动控制数据位置效率高</p><h2>对齐和合并访问</h2><p>Kernel读取全局内存只有两种粒度：32Bytes和128Bytes</p><p>哪怕只要一个字节，也必须从全局内存读出来32Bytes</p><p>具体是多少Bytes取决与是否使用L1 Cache</p><blockquote>对于CPU来说，一级缓存或者二级缓存是不能被编程的，但是CUDA是支持通过编译指令停用一级缓存的。如果启用一级缓存，那么每次从DRAM上加载数据的粒度是128字节，如果不使用一级缓存，只是用二级缓存，那么粒度是32字节。<br/>我们把一次内存请求——也就是从内核函数发起请求，到硬件响应返回数据这个过程称为一个内存事务（加载和存储都行）。<br/>当一个内存事务的首个访问地址是缓存粒度（32或128字节）的偶数倍的时候：比如二级缓存32字节的偶数倍64，128字节的偶数倍256的时候，这个时候被称为对齐内存访问，非对齐访问就是除上述的其他情况，非对齐的内存访问会造成带宽浪费。<br/>当一个线程束内的线程访问的内存都在一个内存块里的时候，就会出现合并访问。<br/>对齐合并访问的状态是理想化的，也是最高速的访问方式，当线程束内的所有线程访问的数据在一个内存块，并且数据是从内存块的首地址开始被需要的，那么对齐合并访问出现了。为了最大化全局内存访问的理想状态，尽量将线程束访问内存组织成对齐合并的方式，这样的效率是最高的。</blockquote><p>下面是有关合并访问和对齐访问的一个例子：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d17b2bb15057cac81bcf10b03f35f23a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"630\" data-rawheight=\"839\" class=\"origin_image zh-lightbox-thumb\" width=\"630\" data-original=\"https://pic3.zhimg.com/v2-d17b2bb15057cac81bcf10b03f35f23a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;630&#39; height=&#39;839&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"630\" data-rawheight=\"839\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"630\" data-original=\"https://pic3.zhimg.com/v2-d17b2bb15057cac81bcf10b03f35f23a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d17b2bb15057cac81bcf10b03f35f23a_b.jpg\"/></figure><p>（终于把这个问题搞明白了...）</p><h2>一篇绝赞好文章<a href=\"https://link.zhihu.com/?target=http%3A//face2ai.com/CUDA-F-4-3-%25E5%2586%2585%25E5%25AD%2598%25E8%25AE%25BF%25E9%2597%25AE%25E6%25A8%25A1%25E5%25BC%258F/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">【CUDA 基础】4.3 内存访问模式</a>，把NVIDIA GPU的内存特性描述的很清楚，解决了我以前很多疑点</h2><h2>只读缓存</h2><p>计算能力在3.5以上的设备，可以将全局内存中的数据缓存到只读缓存中。</p><p>这两块内存粒度为32Bytes，速度和L1 Cache差不多，粒度更细，利用率更高</p><p>只读缓存有从全局内存的专用带宽</p><p>每个SM上只读缓存48KB</p><blockquote>只读缓存独立存在，区别于常量缓存，常量缓存喜欢小数据，而只读内存加载的数据比较大，可以在非统一模式下访问<br/>统一访问（读取同一地址）</blockquote><p>有两种方法指导内存从只读缓存读取：</p><ul><li>使用函数 _ldg</li><li>在间接引用的指针上使用__restrict<i>__</i>限定修饰符</li></ul><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"n\">__global__</span> <span class=\"kt\">void</span> <span class=\"nf\">copyKernel</span><span class=\"p\">(</span><span class=\"kt\">float</span> <span class=\"o\">*</span> <span class=\"n\">in</span><span class=\"p\">,</span><span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">out</span><span class=\"p\">)</span>\n<span class=\"p\">{</span>\n    <span class=\"kt\">int</span> <span class=\"n\">idx</span><span class=\"o\">=</span><span class=\"n\">blockDim</span><span class=\"o\">*</span><span class=\"n\">blockIdx</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"o\">+</span><span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">x</span><span class=\"p\">;</span>\n    <span class=\"n\">out</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"n\">__ldg</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">amp</span><span class=\"p\">;</span><span class=\"n\">in</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">]);</span>\n \n<span class=\"p\">}</span>\n\n<span class=\"kt\">void</span> <span class=\"nf\">kernel</span><span class=\"p\">(</span><span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"k\">const</span> <span class=\"kt\">float</span><span class=\"o\">*</span> <span class=\"n\">__restrict__</span> <span class=\"n\">input</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n<span class=\"p\">...</span>\n<span class=\"n\">output</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">input</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">];</span>\n<span class=\"p\">}</span>\n</code></pre></div><h2>全局内存写入时，Fermi架构核Kepler架构不经过L1 Cache，只经过L2 Cache，粒度为32Bytes</h2><h2>AoS 和 SoA</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-deddf19c1dc7bde0bbd311cdb651f80f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"601\" data-rawheight=\"122\" class=\"origin_image zh-lightbox-thumb\" width=\"601\" data-original=\"https://pic4.zhimg.com/v2-deddf19c1dc7bde0bbd311cdb651f80f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;601&#39; height=&#39;122&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"601\" data-rawheight=\"122\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"601\" data-original=\"https://pic4.zhimg.com/v2-deddf19c1dc7bde0bbd311cdb651f80f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-deddf19c1dc7bde0bbd311cdb651f80f_b.jpg\"/></figure><p>SoA布局访存特性更好，性能更优</p><h2>共享内存分配</h2><ul><li>静态分配：可以分配1、2、3维</li></ul><div class=\"highlight\"><pre><code class=\"language-text\">__shared__ float a[size_x][size_y];    // 静态分配，size_x、size_y必须编译时可确定</code></pre></div><ul><li>动态分配：只能分配1维，不需要手动回收</li></ul><div class=\"highlight\"><pre><code class=\"language-text\">extern __shared__ int tile[];          // 必须添加extern关键字，表明运行时才知道\n\nMyKernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock, isize*sizeof(int)&gt;&gt;&gt;(...);    // 启动Kernel时传入动态共享内存大小</code></pre></div><h2>共享内存存储体的冲突问题</h2><p>共分为32个大小相同的存储体</p><p>有三种经典的访问方式：</p><ol><li>并行访问，多地址访问多存储体</li></ol><p>完全无冲突的话，一个内存事务即可访问完毕</p><p>有小部分冲突时，不冲突的部分一个内存事务可访问完毕，冲突的要多次内存事务才可访问完毕</p><p>2. 串行访问</p><p>完全冲突就是串行访问了，发生在读写同一个存储体的不同地址，或写同一个地址时</p><p>3. 广播访问</p><p>读同一个地址时会触发广播访问：一个内存事务执行完后，一个线程会获取到数据，他会以广播的方式告诉其他线程</p><p>虽然延迟低，但实际上内存带宽利用率差</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-38edba9b8fed4a0945d4e045663bfd1b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"638\" data-rawheight=\"764\" class=\"origin_image zh-lightbox-thumb\" width=\"638\" data-original=\"https://pic4.zhimg.com/v2-38edba9b8fed4a0945d4e045663bfd1b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;638&#39; height=&#39;764&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"638\" data-rawheight=\"764\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"638\" data-original=\"https://pic4.zhimg.com/v2-38edba9b8fed4a0945d4e045663bfd1b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-38edba9b8fed4a0945d4e045663bfd1b_b.jpg\"/></figure><h2>共享内存的访问模式（其实指的是带宽）</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-209f106f5346c6fa2005159c1b1c9127_b.jpg\" data-size=\"normal\" data-rawwidth=\"637\" data-rawheight=\"547\" class=\"origin_image zh-lightbox-thumb\" width=\"637\" data-original=\"https://pic4.zhimg.com/v2-209f106f5346c6fa2005159c1b1c9127_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;637&#39; height=&#39;547&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"637\" data-rawheight=\"547\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"637\" data-original=\"https://pic4.zhimg.com/v2-209f106f5346c6fa2005159c1b1c9127_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-209f106f5346c6fa2005159c1b1c9127_b.jpg\"/><figcaption>存储体宽度为4(Bytes)的存储体数据排布情况</figcaption></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6a36eb084ec95dd55f4a5270690403c5_b.jpg\" data-size=\"normal\" data-rawwidth=\"604\" data-rawheight=\"248\" class=\"origin_image zh-lightbox-thumb\" width=\"604\" data-original=\"https://pic2.zhimg.com/v2-6a36eb084ec95dd55f4a5270690403c5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;604&#39; height=&#39;248&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"604\" data-rawheight=\"248\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"604\" data-original=\"https://pic2.zhimg.com/v2-6a36eb084ec95dd55f4a5270690403c5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6a36eb084ec95dd55f4a5270690403c5_b.jpg\"/><figcaption>存储体宽度为8的存储体数据排布情况，此时访问0和访问32虽然在同一个存储体内，但是不会引发冲突</figcaption></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4317f9cbf73f433906516d4d59f4ad8b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"732\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-4317f9cbf73f433906516d4d59f4ad8b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;640&#39; height=&#39;732&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"732\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"640\" data-original=\"https://pic4.zhimg.com/v2-4317f9cbf73f433906516d4d59f4ad8b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4317f9cbf73f433906516d4d59f4ad8b_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7f354fe87ed3355b5a40042a725d5311_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"639\" data-rawheight=\"733\" class=\"origin_image zh-lightbox-thumb\" width=\"639\" data-original=\"https://pic2.zhimg.com/v2-7f354fe87ed3355b5a40042a725d5311_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;639&#39; height=&#39;733&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"639\" data-rawheight=\"733\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"639\" data-original=\"https://pic2.zhimg.com/v2-7f354fe87ed3355b5a40042a725d5311_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-7f354fe87ed3355b5a40042a725d5311_b.jpg\"/></figure><p>访问模式（带宽）是可查询和可配置的</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaDeviceGetSharedMemConfig(cudaSharedMemConfig * pConfig);\ncudaError_t cudaDeviceSetShareMemConfig(cudaSharedMemConfig config);</code></pre></div><h2>使用Padding避免存储体冲突</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5873b5855960d3599ba162d00c291195_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"373\" data-rawheight=\"428\" class=\"content_image\" width=\"373\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;373&#39; height=&#39;428&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"373\" data-rawheight=\"428\" class=\"content_image lazy\" width=\"373\" data-actualsrc=\"https://pic2.zhimg.com/v2-5873b5855960d3599ba162d00c291195_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-07cd210791e502dd7c4c85aec5286f28_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"386\" data-rawheight=\"509\" class=\"content_image\" width=\"386\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;386&#39; height=&#39;509&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"386\" data-rawheight=\"509\" class=\"content_image lazy\" width=\"386\" data-actualsrc=\"https://pic1.zhimg.com/v2-07cd210791e502dd7c4c85aec5286f28_b.jpg\"/></figure><p>添加padding的两种方式：</p><ul><li>静态padding：静态声明时列方向加一个常量</li></ul><div class=\"highlight\"><pre><code class=\"language-text\">__shared__ int tile[BDIMY][BDIMX+IPAD];</code></pre></div><ul><li>动态padding</li></ul><div class=\"highlight\"><pre><code class=\"language-text\">unsigned int row_idx=threadIdx.y*(blockDim.x+1)+threadIdx.x;\nunsigned int col_idx=threadIdx.x*(blockDim.x+1)+threadIdx.y;</code></pre></div><h2>弱排序内存模型</h2><p>CUDA的内存访问并不严格按照程序里写的顺序执行，例如连续的两个访存指令，谁先谁后执行是不确定的</p><p>在另一本书里也有写过，CUDA是懒惰内存，只有需要数据但还没到的时候才会开始阻塞</p><h2>显式同步</h2><div class=\"highlight\"><pre><code class=\"language-text\">void __syncthreads();</code></pre></div><p>同一线程块内的线程都到达此后，才会继续执行；所有这之前的内存访问也会全部完成</p><blockquote>同一线程块内此障碍点之前的所有全局内存，共享内存操作，对后面的线程都是可见的。</blockquote><p>有可能会造成死锁：</p><div class=\"highlight\"><pre><code class=\"language-text\">if (threadID % 2 == 0) {\n    __syncthreads();\n} else {\n    __syncthreads();\n}</code></pre></div><h2>内存栅栏</h2><blockquote>内存栅栏能保证栅栏前的内核内存写操作对栅栏后的其他线程都是可见的，有以下三种栅栏：块，网格，系统。</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-cb1a2db105c49a106b03a096c9dd81df_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"637\" data-rawheight=\"474\" class=\"origin_image zh-lightbox-thumb\" width=\"637\" data-original=\"https://pic4.zhimg.com/v2-cb1a2db105c49a106b03a096c9dd81df_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;637&#39; height=&#39;474&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"637\" data-rawheight=\"474\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"637\" data-original=\"https://pic4.zhimg.com/v2-cb1a2db105c49a106b03a096c9dd81df_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-cb1a2db105c49a106b03a096c9dd81df_b.jpg\"/></figure><h2>Volatile</h2><p>防止编译器优化，变量修改后立马写回显存，不暂存在寄存器里；Volatile修饰的变量始终在显存中</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-baabc281569f330c6480b6fa56d54219_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"636\" data-rawheight=\"371\" class=\"origin_image zh-lightbox-thumb\" width=\"636\" data-original=\"https://pic2.zhimg.com/v2-baabc281569f330c6480b6fa56d54219_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;636&#39; height=&#39;371&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"636\" data-rawheight=\"371\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"636\" data-original=\"https://pic2.zhimg.com/v2-baabc281569f330c6480b6fa56d54219_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-baabc281569f330c6480b6fa56d54219_b.jpg\"/></figure><h2>nvprof看共享内存的内存事务</h2><div class=\"highlight\"><pre><code class=\"language-text\">nvprof  --metrics shared_load_transactions_per_request ./shared_memory_read\nnvprof  --metrics shared_store_transactions_per_request ./shared_memory_read</code></pre></div><h2>#pragma unroll自动循环展开</h2><h2>warp shuffle指令</h2><p>允许线程束内的线程直接互相访问各自的寄存器，不需要利用共享内存、全局内存交换数据</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"nf\">__shfl</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">var</span><span class=\"p\">,</span><span class=\"kt\">int</span> <span class=\"n\">srcLane</span><span class=\"p\">,</span><span class=\"kt\">int</span> <span class=\"n\">width</span><span class=\"o\">=</span><span class=\"n\">warpSize</span><span class=\"p\">);</span>\n</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-dd1b2670780fa7e14a58065cbb9fca53_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"474\" class=\"origin_image zh-lightbox-thumb\" width=\"624\" data-original=\"https://pic4.zhimg.com/v2-dd1b2670780fa7e14a58065cbb9fca53_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;624&#39; height=&#39;474&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"474\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"624\" data-original=\"https://pic4.zhimg.com/v2-dd1b2670780fa7e14a58065cbb9fca53_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-dd1b2670780fa7e14a58065cbb9fca53_b.jpg\"/></figure><p>srcLane会对width进行取余</p><div class=\"highlight\"><pre><code class=\"language-cpp\"><span class=\"kt\">int</span> <span class=\"nf\">__shfl_up</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">var</span><span class=\"p\">,</span><span class=\"kt\">unsigned</span> <span class=\"kt\">int</span> <span class=\"n\">delta</span><span class=\"p\">,</span><span class=\"kt\">int</span> <span class=\"n\">with</span><span class=\"o\">=</span><span class=\"n\">warpSize</span><span class=\"p\">);</span>\n<span class=\"kt\">int</span> <span class=\"nf\">__shfl_down</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">var</span><span class=\"p\">,</span><span class=\"kt\">unsigned</span> <span class=\"kt\">int</span> <span class=\"n\">delta</span><span class=\"p\">,</span><span class=\"kt\">int</span> <span class=\"n\">with</span><span class=\"o\">=</span><span class=\"n\">warpSize</span><span class=\"p\">);</span>\n</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-679b8e37ec2a49e4f265fcb6c225f508_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"634\" data-rawheight=\"729\" class=\"origin_image zh-lightbox-thumb\" width=\"634\" data-original=\"https://pic1.zhimg.com/v2-679b8e37ec2a49e4f265fcb6c225f508_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;634&#39; height=&#39;729&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"634\" data-rawheight=\"729\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"634\" data-original=\"https://pic1.zhimg.com/v2-679b8e37ec2a49e4f265fcb6c225f508_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-679b8e37ec2a49e4f265fcb6c225f508_b.jpg\"/></figure><div class=\"highlight\"><pre><code class=\"language-text\">int __shfl_xor(int var,int laneMask,int with=warpSize);    // 按位亦或</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-cde14eb5fd316f55408c625753befb67_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"633\" data-rawheight=\"695\" class=\"origin_image zh-lightbox-thumb\" width=\"633\" data-original=\"https://pic4.zhimg.com/v2-cde14eb5fd316f55408c625753befb67_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;633&#39; height=&#39;695&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"633\" data-rawheight=\"695\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"633\" data-original=\"https://pic4.zhimg.com/v2-cde14eb5fd316f55408c625753befb67_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-cde14eb5fd316f55408c625753befb67_b.jpg\"/></figure><p>洗牌指令可以用于下面三种整数变量类型中：</p><ul><li>标量变量</li><li>数组</li><li>向量型变量</li></ul><h2>CUDA流</h2><ul><li>空流：隐式声明的流，无法管理</li><li>非空流：显式声明的流</li></ul><p>基于流的异步内核启动和数据传输支持以下类型的粗粒度并发</p><ul><li>重叠主机和设备计算</li><li>重叠主机计算和主机设备数据传输</li><li>重叠主机设备数据传输和设备计算</li><li>并发设备计算（多个设备）</li></ul><p>cudaMemcpy是同步操作，异步操作版本：</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaMemcpyAsync(void* dst, const void* src, size_t count,cudaMemcpyKind kind, cudaStream_t stream = 0);</code></pre></div><p>stream=0代表默认的空流</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaStream_t a;\ncudaError_t cudaStreamCreate(cudaStream_t* pStream);    // 给流分配资源</code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9910a6548e70e22f19c1390d2248aefe_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"626\" data-rawheight=\"341\" class=\"origin_image zh-lightbox-thumb\" width=\"626\" data-original=\"https://pic3.zhimg.com/v2-9910a6548e70e22f19c1390d2248aefe_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;626&#39; height=&#39;341&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"626\" data-rawheight=\"341\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"626\" data-original=\"https://pic3.zhimg.com/v2-9910a6548e70e22f19c1390d2248aefe_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9910a6548e70e22f19c1390d2248aefe_b.jpg\"/></figure><p>在非空流中启动内核需要加额外的启动参数：</p><div class=\"highlight\"><pre><code class=\"language-text\">MyKernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock, sharedMemSize, pStream&gt;&gt;&gt;(...);</code></pre></div><p>回收流的资源：</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaStreamDestroy(cudaStream_t stream);</code></pre></div><blockquote>由于流和主机端是异步的，你在使用上面指令回收流的资源的时候，很有可能流还在执行，这时候，这条指令会正常执行，但是不会立刻停止流，而是等待流执行完成后，立刻回收该流中的资源。这样做是合理的也是安全的</blockquote><p>查询流执行状态：</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaStreamSynchronize(cudaStream_t stream);    // 阻塞主机，直到流完成\ncudaError_t cudaStreamQuery(cudaStream_t stream);    // 立即返回，执行完了返回cudaSuccess，否则返回cudaErrorNotReady</code></pre></div><p>使用流可以重叠数据移动和运算，利用并发加速：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-24494bd8c739869b6854db8b58a1df66_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"197\" class=\"origin_image zh-lightbox-thumb\" width=\"619\" data-original=\"https://pic3.zhimg.com/v2-24494bd8c739869b6854db8b58a1df66_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;619&#39; height=&#39;197&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"619\" data-rawheight=\"197\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"619\" data-original=\"https://pic3.zhimg.com/v2-24494bd8c739869b6854db8b58a1df66_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-24494bd8c739869b6854db8b58a1df66_b.jpg\"/></figure><blockquote>内核并发最大数量也是有极限的，不同计算能力的设备不同，Fermi设备支持16路并发，Kepler支持32路并发。设备上的所有资源都是限制并发数量的原因，比如共享内存，寄存器，本地内存，这些资源都会限制最大并发数。</blockquote><h2>流调度</h2><p>Fermi架构会有虚假依赖问题：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-258ff78af9947174a2f49d0c398dab86_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"589\" data-rawheight=\"203\" class=\"origin_image zh-lightbox-thumb\" width=\"589\" data-original=\"https://pic3.zhimg.com/v2-258ff78af9947174a2f49d0c398dab86_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;589&#39; height=&#39;203&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"589\" data-rawheight=\"203\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"589\" data-original=\"https://pic3.zhimg.com/v2-258ff78af9947174a2f49d0c398dab86_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-258ff78af9947174a2f49d0c398dab86_b.jpg\"/></figure><p>Hyper-Q技术解决了虚假依赖问题，使用多个工作队列，尽可能的并发：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2d27416c2963a46c0d5f110df9eb93ad_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"604\" data-rawheight=\"200\" class=\"origin_image zh-lightbox-thumb\" width=\"604\" data-original=\"https://pic2.zhimg.com/v2-2d27416c2963a46c0d5f110df9eb93ad_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;604&#39; height=&#39;200&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"604\" data-rawheight=\"200\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"604\" data-original=\"https://pic2.zhimg.com/v2-2d27416c2963a46c0d5f110df9eb93ad_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2d27416c2963a46c0d5f110df9eb93ad_b.jpg\"/></figure><h2>流的优先级</h2><p>3.5以上的设备可以给流优先级，也就是优先级高的（数字上更小的，类似于cpp运算符优先级）</p><p>优先级只影响核函数，不影响数据传输，高优先级的流可以占用低优先级的工作。</p><p>下面函数创建一个有指定优先级的流：</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaStreamCreateWithPriority(cudaStream_t* pStream, unsigned int flags,int priority);</code></pre></div><p>下面函数可以查询当前设备的优先级分布情况：</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaDeviceGetStreamPriorityRange(int *leastPriority, int *greatestPriority);</code></pre></div><h2>CUDA事件</h2><p>CUDA事件可用来：</p><ul><li>同步流执行</li><li>监控设备的进展</li></ul><p>流中的任意点都可以通过API插入事件以及查询事件完成的函数，只有事件所在流中其之前的操作都完成后才能触发事件完成。默认流中设置事件，那么其前面的所有操作都完成时，事件才触发完成。</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaEvent_t event;\ncudaError_t cudaEventCreate(cudaEvent_t* event);\ncudaError_t cudaEventDestroy(cudaEvent_t event);    // 如果回收指令执行的时候事件还没有完成，那么回收指令立即完成，\n                                                       当事件完成后，资源马上被回收。</code></pre></div><h2>通过CUDA事件计时</h2><p>事件通过如下函数添加到流中：</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaEventRecord(cudaEvent_t event, cudaStream_t stream = 0);</code></pre></div><p>查询事件状态：</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaEventSynchronize(cudaEvent_t event);    // 会阻塞主机线程知道事件被完成\ncudaError_t cudaEventQuery(cudaEvent_t event);    // 异步查询</code></pre></div><p>记录两个事件的时间间隔：</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaEventElapsedTime(float* ms, cudaEvent_t start, cudaEvent_t stop);</code></pre></div><blockquote>这个函数记录两个事件start和stop之间的时间间隔，单位毫秒，两个事件不一定是同一个流中。这个时间间隔可能会比实际大一些，因为cudaEventRecord这个函数是异步的，所以加入时间完全不可控，不能保证两个事件之间的间隔刚好是两个事件之间的。</blockquote><h3>CUDA事件可配置参数</h3><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaEventCreateWithFlags(cudaEvent_t* event, unsigned int flags);\n\ncudaEventDefault\ncudaEventBlockingSync\ncudaEventDisableTiming\ncudaEventInterprocess</code></pre></div><blockquote>其中cudaEventBlockingSync指定使用cudaEventSynchronize同步会造成阻塞调用线程。cudaEventSynchronize默认是使用cpu周期不断重复查询事件状态，而当指定了事件是cudaEventBlockingSync的时候，会将查询放在另一个线程中，而原始线程继续执行，直到事件满足条件，才会通知原始线程，这样可以减少CPU的浪费，但是由于通讯的时间，会造成一定的延迟。<br/>cudaEventDisableTiming表示事件不用于计时，可以减少系统不必要的开支也能提升cudaStreamWaitEvent和cudaEventQuery的效率<br/>cudaEventInterprocess表明可能被用于进程之间的事件</blockquote><h2>流同步</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-f5c65df63ee4899a0bd925138084b21d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"642\" class=\"origin_image zh-lightbox-thumb\" width=\"624\" data-original=\"https://pic2.zhimg.com/v2-f5c65df63ee4899a0bd925138084b21d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;624&#39; height=&#39;642&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"624\" data-rawheight=\"642\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"624\" data-original=\"https://pic2.zhimg.com/v2-f5c65df63ee4899a0bd925138084b21d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-f5c65df63ee4899a0bd925138084b21d_b.jpg\"/></figure><h2>阻塞流和非阻塞流</h2><p>cudaStreamCreate创建的是阻塞流，里面有些操作会阻塞，直到空流中某些操作完成</p><p>空流时阻塞流，且与所有阻塞流同步</p><p>不同阻塞流的kernel不会并发执行，只会一个一个执行</p><p>创建非阻塞流的方法：</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaStreamCreateWithFlags(cudaStream_t* pStream, unsigned int flags);\n\ncudaStreamDefault;// 默认阻塞流\ncudaStreamNonBlocking: //非阻塞流，对空流的阻塞行为失效。</code></pre></div><p>非阻塞流可以同时并发执行</p><h2>隐式同步</h2><p>隐式操作常出现在内存操作上，比如：</p><ul><li>锁页主机内存分布</li><li>设备内存分配</li><li>设备内存初始化</li><li>同一设备两地址之间的内存复制</li><li>一级缓存，共享内存配置修改</li></ul><h2>显式同步</h2><p>常见的同步有：</p><ul><li>同步设备</li><li>同步流</li><li>同步流中的事件</li><li>使用事件跨流同步</li></ul><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaDeviceSynchronize(void);    // 阻塞主机线程，直到设备完成所有操作\n\ncudaError_t cudaStreamSynchronize(cudaStream_t stream);    // 阻塞主机直到流完成，用来同步流的\ncudaError_t cudaStreamQuery(cudaStream_t stream);    // 非阻塞流测试，查询流是否完成\n\ncudaError_t cudaEventSynchronize(cudaEvent_t event);\ncudaError_t cudaEventQuery(cudaEvent_t event);\n\ncudaError_t cudaStreamWaitEvent(cudaStream_t stream, cudaEvent_t event);\n// 指定的流要等待指定的事件，事件完成后流才能继续，这个事件可以在这个流中，也可以不在\n// 当在不同的流的时候，这个就是实现了跨流同步\n</code></pre></div><h2>当一个内核数据量大时，可以将自身任务分块，在多个流里执行，重叠数据传输和内核执行</h2><h2>流回调</h2><p>使用如下函数将回调函数加入流中：</p><div class=\"highlight\"><pre><code class=\"language-text\">cudaError_t cudaStreamAddCallback(cudaStream_t stream,cudaStreamCallback_t callback, \n                                  void *userData, unsigned int flags);</code></pre></div><p>回调函数应按如下方式定义：</p><div class=\"highlight\"><pre><code class=\"language-text\">void CUDART_CB my_callback(cudaStream_t stream, cudaError_t status, void *data) {\n    printf(&#34;callback from stream %d\\n&#34;, *((int *)data));\n}</code></pre></div><p>回调函数需要遵循如下规则：</p><ul><li>回调函数里不能调用CUDA的API</li><li>不可以执行同步操作</li></ul><p></p><p></p><p></p>", 
            "topic": [
                {
                    "tag": "GPU 通用计算", 
                    "tagLink": "https://api.zhihu.com/topics/19570902"
                }, 
                {
                    "tag": "CUDA", 
                    "tagLink": "https://api.zhihu.com/topics/19597236"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "伊凡", 
                    "userLink": "https://www.zhihu.com/people/ad8bc220d7191871fbd8129e96d78846", 
                    "content": "整理得好全！", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "魏智勇", 
                    "userLink": "https://www.zhihu.com/people/0ecfdc9ec8ec4a89c6b53a8ad4c17aeb", 
                    "content": "很全面 很详细", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/71984335", 
            "userName": "田子宸", 
            "userLink": "https://www.zhihu.com/people/d14a9ca3ff45a4076924d5ec7ce26b17", 
            "upvote": 6, 
            "title": "NVIDIA Xavier 整理", 
            "content": "<h2>0、前言</h2><p>参考：</p><a href=\"https://link.zhihu.com/?target=https%3A//devblogs.nvidia.com/nvidia-jetson-agx-xavier-32-teraops-ai-robotics/%3Fncid%3Dso-fac-mdjngxxrmllhml-69163\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https://pic1.zhimg.com/v2-c99c8462a3d6c49b8d11a3db59890d84_180x120.jpg\" data-image-width=\"362\" data-image-height=\"290\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">NVIDIA Jetson AGX Xavier Delivers 32 TeraOps for New Era of AI in Robotics | NVIDIA Developer Blog</a><a href=\"https://link.zhihu.com/?target=http%3A//nvdla.org/primer.html\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">NVDLA Primer - NVDLA Documentation</a><h2>1、 Jetson Xavier概述</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-502db65ae2f9e1368c8d2bd8d59930b5_b.jpg\" data-size=\"normal\" data-rawwidth=\"530\" data-rawheight=\"575\" class=\"origin_image zh-lightbox-thumb\" width=\"530\" data-original=\"https://pic2.zhimg.com/v2-502db65ae2f9e1368c8d2bd8d59930b5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;530&#39; height=&#39;575&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"530\" data-rawheight=\"575\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"530\" data-original=\"https://pic2.zhimg.com/v2-502db65ae2f9e1368c8d2bd8d59930b5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-502db65ae2f9e1368c8d2bd8d59930b5_b.jpg\"/><figcaption>NVIDIA Jetson Xavier实物图</figcaption></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4814ce116d8e0259f64e0ddd2ead9aa1_b.jpg\" data-size=\"normal\" data-rawwidth=\"855\" data-rawheight=\"491\" class=\"origin_image zh-lightbox-thumb\" width=\"855\" data-original=\"https://pic2.zhimg.com/v2-4814ce116d8e0259f64e0ddd2ead9aa1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;855&#39; height=&#39;491&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"855\" data-rawheight=\"491\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"855\" data-original=\"https://pic2.zhimg.com/v2-4814ce116d8e0259f64e0ddd2ead9aa1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4814ce116d8e0259f64e0ddd2ead9aa1_b.jpg\"/><figcaption>Jetson Xavier 架构</figcaption></figure><p>Jetson Xavier上的Xavier Soc有如下资源：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c4352d1ff355010b730ee8836b0876d8_b.jpg\" data-size=\"normal\" data-rawwidth=\"650\" data-rawheight=\"440\" class=\"origin_image zh-lightbox-thumb\" width=\"650\" data-original=\"https://pic1.zhimg.com/v2-c4352d1ff355010b730ee8836b0876d8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;650&#39; height=&#39;440&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"650\" data-rawheight=\"440\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"650\" data-original=\"https://pic1.zhimg.com/v2-c4352d1ff355010b730ee8836b0876d8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c4352d1ff355010b730ee8836b0876d8_b.jpg\"/><figcaption>Xavier Soc上的硬件资源</figcaption></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-f12136fedc8baddaf436b8f8753f2b49_b.jpg\" data-size=\"normal\" data-rawwidth=\"530\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb\" width=\"530\" data-original=\"https://pic2.zhimg.com/v2-f12136fedc8baddaf436b8f8753f2b49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;530&#39; height=&#39;420&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"530\" data-rawheight=\"420\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"530\" data-original=\"https://pic2.zhimg.com/v2-f12136fedc8baddaf436b8f8753f2b49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-f12136fedc8baddaf436b8f8753f2b49_b.jpg\"/><figcaption>Jetson Xavier AGX的软件资源，其中L4T那个是BSP</figcaption></figure><h2>2、 Volta GPU</h2><p>Xavier有一块Volta GPU，参数如下：</p><blockquote>provides 512 CUDA cores and 64 Tensor Cores for up to 11 TFLOPS FP16 or 22 TOPS of INT8 compute, with a maximum clock frequency of 1.37GHz. It supports CUDA 10 with a compute capability of sm_72. The GPU includes eight Volta Streaming Multiprocessors (SMs) with 64 CUDA cores and 8 Tensor Cores per Volta SM. Each Volta SM includes a 128KB L1 cache, 8x larger than previous generations. The SMs share a 512KB L2 cache and offers 4x faster access than previous generations.</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-0256ec596eee142dc432c5722acf2b3a_b.jpg\" data-size=\"normal\" data-rawwidth=\"639\" data-rawheight=\"421\" class=\"origin_image zh-lightbox-thumb\" width=\"639\" data-original=\"https://pic3.zhimg.com/v2-0256ec596eee142dc432c5722acf2b3a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;639&#39; height=&#39;421&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"639\" data-rawheight=\"421\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"639\" data-original=\"https://pic3.zhimg.com/v2-0256ec596eee142dc432c5722acf2b3a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-0256ec596eee142dc432c5722acf2b3a_b.jpg\"/><figcaption>每个SM被分为4个SMP，每个SMP有独立的L0 instruction cache、warp scheduler、dispatch unit、and register file、CUDA cores、Tensor Cores</figcaption></figure><h3>Tensor Cores</h3><blockquote>NVIDIA Tensor Cores are programmable fused matrix-multiply-and-accumulate units that execute concurrently alongside CUDA cores. Tensor Cores implement new floating-point HMMA (Half-Precision Matrix Multiply and Accumulate) and IMMA (Integer Matrix Multiply and Accumulate) instructions for accelerating dense linear algebra computations, signal processing, and deep learning inference.</blockquote><p>其实就是一个GEMM部件，目前不支持fp32</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fc5bf2d967a6b3b6c530be328d6a5c1a_b.jpg\" data-size=\"normal\" data-rawwidth=\"958\" data-rawheight=\"240\" class=\"origin_image zh-lightbox-thumb\" width=\"958\" data-original=\"https://pic3.zhimg.com/v2-fc5bf2d967a6b3b6c530be328d6a5c1a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;958&#39; height=&#39;240&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"958\" data-rawheight=\"240\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"958\" data-original=\"https://pic3.zhimg.com/v2-fc5bf2d967a6b3b6c530be328d6a5c1a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fc5bf2d967a6b3b6c530be328d6a5c1a_b.jpg\"/><figcaption>Tensor Core支持的计算数据类型</figcaption></figure><blockquote>NVIDIA libraries including cuBLAS, cuDNN, and TensorRT have been updated to utilize HMMA and IMMA internally, allowing programmers to easily take advantage of the performance gains inherent in Tensor Cores. Users can also directly access Tensor Core operations at the warp level via a new API exposed in the wmma namespace and mma.h header included in CUDA 10.  The warp-level interface maps 16×16, 32×8, and 8×32 size matrices across all 32 threads per warp.</blockquote><p>NVIDIA的那些库，像cuBLAS、cuDNN、TensorRT都会自动使用TensorCore。用户也可以手动编程TensorCore</p><h2>3、 NVDLA（NVIDA Deep Learning Accelerator）</h2><p>DLA是NVIDIA推出的用于专做视觉的部件，Xavier上有两个DLA</p><p>DLA的定位是专做常用计算(Conv+激活函数+Pooling+Normalization+Reshape)，然后复杂的计算交给Volta GPU做</p><p>DLA功耗很低，性能很好</p><blockquote>DLA has up to 5 TOPS INT8 or 2.5 TFLOPS FP16 performance with a power consumption of only 0.5-1.5W. The DLAs support accelerating CNN layers such as convolution, deconvolution, activation functions, min/max/mean pooling, local response normalization, and fully-connected layers.</blockquote><h3>硬件</h3><p>DLA有如下主要部件：</p><ul><li>Convolution Core – optimized high-performance convolution engine.</li><li>Single Data Processor – single-point lookup engine for activation functions.</li><li>Planar Data Processor – planar averaging engine for pooling.</li><li>Channel Data Processor – multi-channel averaging engine for advanced normalization functions.</li><li>Dedicated Memory and Data Reshape Engines – memory-to-memory transformation acceleration for tensor reshape and copy operations.</li></ul><p>每个部件间是独立的，可以单独开启或关闭以节省能耗</p><p>通过部件间的FIFO(例如途中Conv Core到SDP的小连线)，可以让数据直接在各个部件间流动，形成流水线，减少内存无用的搬运，隐藏内存延迟</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-41f2cc782f06071564fc080b3d9f33ea_b.jpg\" data-size=\"normal\" data-rawwidth=\"687\" data-rawheight=\"563\" class=\"origin_image zh-lightbox-thumb\" width=\"687\" data-original=\"https://pic3.zhimg.com/v2-41f2cc782f06071564fc080b3d9f33ea_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;687&#39; height=&#39;563&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"687\" data-rawheight=\"563\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"687\" data-original=\"https://pic3.zhimg.com/v2-41f2cc782f06071564fc080b3d9f33ea_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-41f2cc782f06071564fc080b3d9f33ea_b.jpg\"/><figcaption>DLA架构图</figcaption></figure><h3>Conv部件</h3><p>硬件支持Winograd</p><p>有&#34;Convolution Buffer&#34;，可以将input和weight暂存起来（也不知道能存多少），加速计算</p><h3>Single Data Point Processor</h3><p>可以使用Scale和bias做线性计算，也可以查表做非线性计算，用来实施激活函数</p><h3>Planar Data Processor</h3><p>做Max/Min/Ave Pooling</p><h3>Cross-channel Data Processor</h3><p>专做LRN的（专门搞了一个core来搞这一个算子...）</p><h3>Data Reshape Engine</h3><p>做reshape类操作：splitting or slicing, merging, contraction, reshape-transpose</p><h3>Bridge DMA</h3><p>专做内存拷贝工作</p><p class=\"ztext-empty-paragraph\"><br/></p><h3>软件</h3><p>使用NVDLA的软件架构如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-27759323270409b29f63c3d0482982e8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1113\" data-rawheight=\"190\" class=\"origin_image zh-lightbox-thumb\" width=\"1113\" data-original=\"https://pic1.zhimg.com/v2-27759323270409b29f63c3d0482982e8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1113&#39; height=&#39;190&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1113\" data-rawheight=\"190\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1113\" data-original=\"https://pic1.zhimg.com/v2-27759323270409b29f63c3d0482982e8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-27759323270409b29f63c3d0482982e8_b.jpg\"/></figure><p>build：NVDLA有工具可以解析深度学习模型，编译优化成Loadable文件，量化也在这一步完成</p><p>user mode driver：读取网络并送入kmd，从内存中绑定输入输出地址，启动前传</p><p>kernel mode driver：分析依赖，调度各个Op，设置NVDLA寄存器控制其运行，相应NVDLA中断</p><h2>执行流程</h2><blockquote>The typical flow for inferencing begins with the NVDLA management processor (either a microcontroller in a “headed” implementation, or the main CPU in a “headless” implementation) sending down the configuration of one hardware layer, along with an “activate” command. If data dependencies do not preclude this, multiple hardware layers can be sent down to different engines and activated at the same time (i.e., if there exists another layer whose inputs do not depend on the output from the previous layer). Because every engine has a double-buffer for its configuration registers, it can also capture a second layer’s configuration to begin immediately processing when the active layer has completed. Once a hardware engine finishes its active task, it will issue an interrupt to the management processor to report the completion, and the management processor will then begin the process again. This kind of command-execute-interrupt flow repeats until inference on the entire network is complete.</blockquote><p class=\"ztext-empty-paragraph\"><br/></p><h2>4、 Carmel CPU</h2><blockquote>Jetson AGX Xavier’s CPU complex shown in figure 10  consists of four heterogeneous dual-core NVIDIA Carmel CPU clusters based on ARMv8.2 with a maximum clock frequency of 2.26GHz. Each core includes 128KB instruction and 64KB data L1 caches plus a 2MB L2 cache shared between the two cores. The CPU clusters share a 4MB L3 cache.</blockquote><p>有八个ARMv8.2核，NVIDIA自研Carmel</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4352b4ff8745c8c240b51b470c2921d9_b.jpg\" data-size=\"normal\" data-rawwidth=\"575\" data-rawheight=\"392\" class=\"origin_image zh-lightbox-thumb\" width=\"575\" data-original=\"https://pic2.zhimg.com/v2-4352b4ff8745c8c240b51b470c2921d9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;575&#39; height=&#39;392&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"575\" data-rawheight=\"392\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"575\" data-original=\"https://pic2.zhimg.com/v2-4352b4ff8745c8c240b51b470c2921d9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-4352b4ff8745c8c240b51b470c2921d9_b.jpg\"/><figcaption>Xavier 8核CPU分布，一共分为4个Cluster</figcaption></figure><h2>5、 Vision Accelerator</h2><blockquote>Each includes a dual 7-way VLIW (Very Long Instruction Word) vector processor that offloads computer vision algorithms such as feature detection &amp; matching, optical flow, stereo disparity block matching, and point cloud processing with low latency and low power. Imaging filters such as convolutions, morphological operators, histogramming, colorspace conversion, and warping are also ideal for acceleration.</blockquote><p>说白了是一个SIMD部件，目前还没法用，软件未支持</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-e5e9c4189611d061a3e2b36b7d2380e6_b.jpg\" data-size=\"normal\" data-rawwidth=\"1140\" data-rawheight=\"834\" class=\"origin_image zh-lightbox-thumb\" width=\"1140\" data-original=\"https://pic3.zhimg.com/v2-e5e9c4189611d061a3e2b36b7d2380e6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1140&#39; height=&#39;834&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1140\" data-rawheight=\"834\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1140\" data-original=\"https://pic3.zhimg.com/v2-e5e9c4189611d061a3e2b36b7d2380e6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-e5e9c4189611d061a3e2b36b7d2380e6_b.jpg\"/><figcaption>SIMD部件，目前软件未支持</figcaption></figure><h2>6、 性能</h2><p>比TX2性能高13倍</p><p>功耗上，Xavier可以设置为10/15/30W模式，功耗比较低</p>", 
            "topic": [
                {
                    "tag": "NVIDIA（英伟达）", 
                    "tagLink": "https://api.zhihu.com/topics/19562754"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "张杰", 
                    "userLink": "https://www.zhihu.com/people/0e049e34b320bc19f12a64cd95a76a80", 
                    "content": "<p>感谢整理，很有用</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/c_1064124187198705664"
}

{
    "title": "网络协议基础", 
    "description": "网络协议为计算机网络中进行数据交换而建立的规则、标准或约定的集合。", 
    "followers": [
        "https://www.zhihu.com/people/forever-97-7-21", 
        "https://www.zhihu.com/people/tieren14", 
        "https://www.zhihu.com/people/da-feng-34-56", 
        "https://www.zhihu.com/people/gao-jie-13-68", 
        "https://www.zhihu.com/people/mountain-summer", 
        "https://www.zhihu.com/people/michale-76-26", 
        "https://www.zhihu.com/people/kevin_ok", 
        "https://www.zhihu.com/people/mr-lin-82-68", 
        "https://www.zhihu.com/people/xerath-5", 
        "https://www.zhihu.com/people/xue-li-la-34", 
        "https://www.zhihu.com/people/zhang-zheng-xu", 
        "https://www.zhihu.com/people/wu-xin-zhou", 
        "https://www.zhihu.com/people/wang-ming-66-71", 
        "https://www.zhihu.com/people/studyer-19", 
        "https://www.zhihu.com/people/lei-zi-hai", 
        "https://www.zhihu.com/people/123456abcdef-51", 
        "https://www.zhihu.com/people/steel-13-83", 
        "https://www.zhihu.com/people/faihung", 
        "https://www.zhihu.com/people/jiu-mo-zhi-5", 
        "https://www.zhihu.com/people/james732", 
        "https://www.zhihu.com/people/alan-5171", 
        "https://www.zhihu.com/people/ji-xu-wen-5", 
        "https://www.zhihu.com/people/dan-ding-10-87", 
        "https://www.zhihu.com/people/xie-ming-zhu-53", 
        "https://www.zhihu.com/people/wan-duan-duan", 
        "https://www.zhihu.com/people/tanxun", 
        "https://www.zhihu.com/people/liii-12-83", 
        "https://www.zhihu.com/people/chen-si-peng-97", 
        "https://www.zhihu.com/people/yang-xun-2-85", 
        "https://www.zhihu.com/people/xu-bo-11-5", 
        "https://www.zhihu.com/people/yi-ge-bei-ren", 
        "https://www.zhihu.com/people/huang-wei-zhen-73", 
        "https://www.zhihu.com/people/wang-wei-wei-70", 
        "https://www.zhihu.com/people/an-xiang-you-fu", 
        "https://www.zhihu.com/people/shen-jun-wei-9", 
        "https://www.zhihu.com/people/xu-xian-min-90", 
        "https://www.zhihu.com/people/jian-zhi-jiu-tian-22", 
        "https://www.zhihu.com/people/huang-zhi-tao-97", 
        "https://www.zhihu.com/people/fu-qi-53", 
        "https://www.zhihu.com/people/wo-bu-pei-8", 
        "https://www.zhihu.com/people/jerryhe-30", 
        "https://www.zhihu.com/people/linuxcpp", 
        "https://www.zhihu.com/people/ye-xiao-1-61", 
        "https://www.zhihu.com/people/Geo_cyx", 
        "https://www.zhihu.com/people/honghan-li", 
        "https://www.zhihu.com/people/zhang-xu-dong-22-32", 
        "https://www.zhihu.com/people/kiritou2", 
        "https://www.zhihu.com/people/ning-rain", 
        "https://www.zhihu.com/people/viggo-97", 
        "https://www.zhihu.com/people/chen-xiao-dong-72-56", 
        "https://www.zhihu.com/people/echo-79-1", 
        "https://www.zhihu.com/people/peng-jin-yi", 
        "https://www.zhihu.com/people/chi-yin-54-98", 
        "https://www.zhihu.com/people/Gentle_Mei", 
        "https://www.zhihu.com/people/chang-zheng-62", 
        "https://www.zhihu.com/people/vuliys", 
        "https://www.zhihu.com/people/wanglar-47"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/87467082", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 0, 
            "title": "网络协议 19 - RPC协议综述", 
            "content": "<p>这几年微服务很火，想必各位博友或多或少的都接触过。微服务概念中，<br/>各服务间的相互调用是不可或缺的一环。你知道微服务之间是通过什么方式相互调用的吗？</p><p>    你可能说，这还不简单，用 socket 呗。服务之间分调用方和被调用方，我们就建立一个 TCP 或者 UDP 连接进行通信就好了。</p><p>    说着说着，你可能就会发现，这事儿没那么简单。</p><p>    我们就拿最简单的场景：</p><blockquote> 客户端调用一个加法函数，将两个整数加起来，返回它们的和。<br/> </blockquote><p>    如果放在本地调用，那是简单的不能再简单，但是一旦变成了远程调用，门槛一下子就上去了。</p><p>    首先，你要会 socket 编程，至少要先了解咱们这个系列的所有协议 ，然后再看 N 本砖头厚的 socket 程序设计的书，学会咱们了解过的几种 socket 程序设计的模型。</p><p>    这就使得本来大学毕业就能干的一项工作，变成了一件五年工作经验都不一定干好的工作，而且，搞定了 socket 程序设计，才是万里长征的第一步，后面还有很多问题呢。</p><h3>存在问题</h3><p><b>问题一：如何规定远程调用的语法？</b><br/>    客户端如何告诉服务端，我是一个加法，而另一个是减法。是用字符串 “add” 传给你，还是传给你一个整数，比如 1 表示加法，2 表示减法？</p><p>    服务端又该如果告诉客户端，我这个是加法，目前只能加整数，不能加小数和字符串。而另一个加法 “add1”，它能实现小数和整数的混合加法，那返回值是什么？正确的时候返回什么，错误的时候又返回什么？</p><p><b>问题二：如何传递参数？</b><br/>    是先传两个整数，后传一个操作数 “add”，还是先传操作符，再传两个整数？</p><p>    另外，如果我们是用 UDP 传输，把参数放在一个报文里还好，但如果是 TCP，是一个流，在这个流里面如何区分前后两次调用？</p><p><b>问题三：如何表示数据？</b><br/>    在我们的加法例子中，传递的就是一个固定长度的 int 值，这种情况还好，如果是变长的类型，是一个结构体，甚至是一个类，应该怎么办呢？即使是 int，在不同的平台上长度也不同，该怎么办呢？</p><p><b>问题四：如何知道一个服务端都实现了哪些远程调用？从哪个端口可以访问这个远程调用？</b><br/>    假设服务端实现了多个远程调用，每个实现可能都不在一个进程中，监听的端口也不一样，而且由于服务端都是自己实现的，不可能使用一个大家都公认的端口，而且有可能多个进程部署在一台机器上，大家需要抢占端口，为了防止冲突，往往使用随机端口，那客户端如何找到这些监听的端口呢？</p><p><b>问题五：发生了错误、重传、丢包、性能等问题怎么办？</b><br/>    本地调用没有这个问题，但是一旦到网络上，这些问题都需要处理，因为网络是不可靠的，虽然在同一个连接中，我们还可以通过 TCP 协议保证丢包、重传的问题，但是如果服务器崩溃了又重启，当前连接断开了，TCP 就保证不了了，需要应用自己进行重新调用，重新传输会不会同样的操作做两遍，远程调用性能会不会受影响呢？</p><h3>解决问题</h3><p>    看到这么多问题，是不是很头疼？还记得咱们了解 http 的时候，认识的<b>协议三要素</b>吗？</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-87344b3c23eb41849e9309fe6601ac84_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-87344b3c23eb41849e9309fe6601ac84_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    本地调用函数里很多问题，比如词法分析、语法分析、语义分析等待，这些问题编译器基本上都帮我们解决了，但是在远程调用中，这些问题我们都要自己考虑。</p><h3>协议约定问题</h3><p>    很多公司对于这个问题，是弄一个核心通信组，里面都是 socket 编程的大牛，实现一个统一的库，让其他业务组的人来调用，业务的人不需要知道中间传输的细节。</p><p>    通信双方的语法、语义、格式、端口、错误处理等，都需要调用方和被调用方开会商量，双方达成一致。一旦有一方改变，要及时通知对方，否则就会出现问题。</p><p>    但是，不是每个公司都能通过这种大牛团队解决问题的，而是使用已经实现好的框架。</p><p>    有一个大牛（Bruce Jay Nelson）通过一篇论文，定义了 RPC 的调用标准。后面所有 RPC 框架都是按照这个标准模式来的。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6d8e9351e4557183cfac4b4e6fa3fbee_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-6d8e9351e4557183cfac4b4e6fa3fbee_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>整个过程如下：</p><ol><li>客户端的应用想发起一个远程调用时，它实际上是通过本地调用方的 Stub。它负责将调用的接口、方法和参数，通过约定的协议规范进行编码，并通过本地 RPCRuntime 进行传输，将调用网络包发送到服务器；</li><li>服务端的 RPCRuntime 收到请求后，交给提供方 Stub 进行编码，然后调用服务端的方法，获取结果，并将结果编码后，发送给客户端；</li><li>客户端的 RPCRuntime 收到结果，发给调用方 Stub 解码得到结果，返回给客户端。</li></ol><p>    上面过程中分了三个层次：客户端、Stub 层、服务端。</p><p>    对于客户端和服务端，都像是本地调用一样，专注于业务逻辑的处理就可以了。对于 Stub 层，处理双方约定好的语法、语义、封装、解封装。对于 RPCRuntime，主要处理高性能的传输，以及网络的错误和异常。</p><p>    最早的 RPC 的一种实现方式称为 <b>Sun RPC</b> 或 <b>ONC RPC</b>。Sun 公司是第一个提供商业化 RPC 库和 RPC 编译器的公司。这个 RPC 框架是在 NFS 协议中使用的。</p><p>    NFS（Network File System）就是网络文件系统。要使 NFS 成功运行，就要启动两个服务端，一个 mountd，用来挂载文件路径。另一个是 nfsd，用来读写文件。NFS 可以在本地 mount 一个远程的目录到本地目录，从而实现让本地用户在本地目录里面读写文件时，操作是是远程另一台机器上的文件。</p><p>    远程操作和远程调用的思路是一样的，就像本地操作一样，所以 NFS 协议就是基于 RPC 实现的。当然，无论是什么 RPC，底层都是 socket 编程。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f8b79bf5e5629aeab11576b3b62a0a8a_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-f8b79bf5e5629aeab11576b3b62a0a8a_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    XDR（External Data Representation，外部数据表示法）是有一个标准的数据压缩格式，可以表示基本的数据类型，也可以表示结构体。</p><p>    这里有几种基本的数据类型。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3f8b6bc63a7b9f962804af3be3a71952_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-3f8b6bc63a7b9f962804af3be3a71952_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    在 RPC 的调用过程中，所有的数据类型都要封装成类似的格式，而且 RPC 的调用和结果返回也有严格的格式。</p><ul><li>XID 唯一标识请求和回复。请求是 0，回复是 1；</li><li>RPC 有版本号，两端要匹配 RPC 协议的版本号。如果不匹配，就会返回 Deny，原因是 RPC_MISMATCH；</li><li>程序有编号。如果服务端找不到这个程序，就会返回 PROG_UNAVAIL；</li><li>程序有版本号。如果程序的版本号不匹配，就会返回 PROG_MISMATCH；</li><li>一个程序可以有多个方法，方法也有编号，如果找不到方法，就会返回 PROG_UNAVAIL；</li><li>调用需要认证鉴权，如果不通过，返回 Deny；</li><li>最后是参数列表，如果参数无法解析，返回 GABAGE_ARGS；</li></ul><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-85df327274cb176930d081308a5cbbeb_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-85df327274cb176930d081308a5cbbeb_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    为了可以成功调用 RPC，在客户端和服务端实现 RPC 的时候，首先要定义一个双方都认可的程序、版本、方法、参数等。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e5a89899859422788e26271044154451_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-e5a89899859422788e26271044154451_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    对于上面的加法而言，双方约定为一个协议定义文件，同理，如果是 NFS、mount 和读写，也会有类似的定义。</p><p>    有了协议定义文件，ONC RPC 会提供一个工具，根据这个文件生成客户端和服务器端的 Stub 程序。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a0d9a77b1c2fd48620c92e3664a084e5_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-a0d9a77b1c2fd48620c92e3664a084e5_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    最下层的是 XDR 文件，用于编码和解码参数。这个文件是客户端和服务端共享的，因为只有双方一致才能成功通信。</p><p>    在客户端，会调用 clnt_create 创建一个连接，然后调用 add_1，这是一个 Stub 函数，感觉是在调用本地函数一样。其实是这个函数发起了一个 RPC 调用，通过调用 clnt_call 来调用 ONC RPC 的类库，来真正发送请求。调用的过程较为复杂，后续再进行专门的说明。</p><p>    当然，服务端也有一个 Stub 程序，监听客户端的请求，当调用到达的时候，判断如果是 add，则调用真正的服务端逻辑，也就是将两个数加起来。</p><p>    服务端将结果返回服务端的 Stub，Stub 程序发送结果给客户端 Stub，客户端 Stub 收到结果后就返回给客户端的应用程序，从而完成这个调用过。</p><p>    有了这个 RPC 框架，前面五个问题中的 “如何规定远程调用的语法？”、“如何传递参数？” 以及 “如何表示数据？” 基本解决了，这三个问题我们统称为<b>协议约定问题</b>。</p><h3>传输问题</h3><p>    前三个问题解决了，但是错误、重传、丢包以及性能问题还没有解决，这些问题我们统称为<b>传输问题</b>。这个 Stub 层就无能为力了，而是由 ONC RPC 的类库来实现。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-141e6ba211eabf024638de9e473838b1_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-141e6ba211eabf024638de9e473838b1_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    在这个类库中，为了解决传输问题，对于每一个客户端，都会创建一个传输管理层，而每一次 RPC 调用，都会是一个任务，在传输管理层，你可以看到熟悉的队列机制、拥塞窗口机制等。</p><p>    由于在网络传输的时候，经常需要等待，而同步的方式往往效率比较低，因而也就有 socket 的异步模型。</p><p>    为了能够异步处理，对于远程调用的处理，往往是通过状态机来实现的。只有当满足某个状态的时候，才进行下一步，如果不满足状态，不是在那里等待，而是将资源留出来，用来处理其他的 RPC 调用。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-cd7ec62ae56675d7217628706a9e14e4_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-cd7ec62ae56675d7217628706a9e14e4_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    如上图，从图也可以看出，这个状态转换图还是很复杂的。</p><p>    首先，进入起始状态，查看 RPC 的传输层队列中有没有空闲的位置，可以处理新的 RPC 任务，如果没有，说明太忙了，直接结束或重试。如果申请成功，就可以分配内存，获取服务端的端口号，然后连接服务器。</p><p>    连接的过程要有一段时间，因而要等待连接结果，如果连接失败，直接结束或重试。如果连接成功，则开始发送 RPC 请，然后等待获取 RPC 结果。同样的，这个过程也需要时间，如果发送出错，就重新发送，如果连接断开，要重新连接，如果超时，要重新传输。如果获取到结果，就可以解码，正常结束。</p><p>    这里处理了连接失败、重试、发送失败、超时、重试等场景，因而实现一个 RPC 框架，其实很有难度。</p><h3>服务发现问题</h3><p>    传输问题解决了，我们还遗留了一个 “如何找到 RPC 服务端的那个随机端口”，这个问题我们称为服务发现问题，在 ONC RPC 中，服务发现是通过 portmapper 实现的。</p><p>    portmapper 会启动在一个众所周知的端口上，RPC 程序由于是用户自己写的，会监听在一个随机端口上，但是 RPC 程序启动的时候，会向 portmapper 注册。</p><p>    客户端要访问 RPC 服务端这个程序的时候，首先查询 portmapper，获取 RPC 服务端程序的随机端口，然后向这个随机端口建立连接，开始 RPC 调用。</p><p>从下图中可以看出，mount 命令的 RPC 调用就是这样实现的。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a48b9298a2875b180a8d92a795bf75e8_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-a48b9298a2875b180a8d92a795bf75e8_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>小结</h3><ul><li>远程调用看起来用 socket 编程就可以了，其实是很复杂的，要解决协议约定问题、传输问题和服务发现问题；</li><li>ONC RPC 框架以及 NFS 的实现，给出了解决上述三大问题的示范性实现，也就是公用协议描述文件，并通过这个文件生成 Stub 程序。RPC 的传输一般需要一个状态机，需要另外一个进程专门做服务发现。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "微服务架构", 
                    "tagLink": "https://api.zhihu.com/topics/20023491"
                }, 
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }, 
                {
                    "tag": "rpc协议", 
                    "tagLink": "https://api.zhihu.com/topics/20665895"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/87440468", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 1, 
            "title": "网络协议 18 - CDN", 
            "content": "<p>到现在为止，我们基本上已经了解了网络协议中的大部分常用协议，对于整个 HTTP 请求流程也较为熟悉了。从无到有后，我们就要考虑如何优化“有”这个过程，也就是我们常见的<b>请求优化</b>。而现在的技术栈中，CDN 是最常用的一种方式。</p><p>    在了解 CDN 前，我们可以先了解下现代社会的物流配置。</p><p>    例如我们去电商网站下单买东西，这个东西一定要从电商总部的中心仓库送过来吗？在电商刚兴起的时候，所有的配送都是从中心仓库发货，所以买家可能要很久才能收到货。但是后来电商网站的物流系统学聪明了，他们在全国各地建立了很多仓库，而不是只有总部的中心仓库才可以发货。</p><p>    电商网站根据统计大概知道，北京、上海、广州、深圳、杭州等地，每天能够卖出去多少书籍、纸巾、包、电器等存放期较长的商品，就将这些商品分布存放在各地仓库中，客户一下单，就从临近的仓库发货，大大减少了运输时间，提高了用户体验。</p><p>    同样的，互联网也借鉴了<b>“就近配送”</b>这个思路。</p><h3>CDN 就近配送</h3><p>    全球有那么多的数据中心，无论在哪里上网，临近不远的地方基本上都有数据中心。可以在每个数据中心里部署几台机器，形成一个缓存集群来缓存部分热数据，这样用户访问数据的是，就可以就近访问了。</p><p>    这些分布在各个地方的各个数据中心的节点，我们一般称为<b>边缘节点</b>。</p><p>    由于边缘节点数目比较多，但是每个集群规模比较小，不可能缓存下来所有东西，因而可能无法命中，这样就会在边缘节点之上，形成了<b>区域节点</b>。</p><p>    区域节点规模较大，缓存的数据也较多，命中的概率也就更大。而在区域节点之上是中心节点，规模更大，缓存数据更多。</p><p>    就这样，在这样一层层的节点中缓存数据，提高响应速度。但是所有的节点都没有缓存数据，就只有进行回源网站访问了。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d003bc04556e1a1387135eb40abdc5d0_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-d003bc04556e1a1387135eb40abdc5d0_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    如上图，就是 <b>CDN 的分发系统的架构</b>。CDN 系统的缓存，是一层层的，能不访问源数据，就不访问。这也是电商网站物流系统的思路，广州找不到，找华南局，华南局找不到，再找南方局。</p><p>    有了这个分发系统之后，<b>客户端如何找到相应的边缘节点进行访问呢？</b></p><p>    还记得咱们之前了解的<b>基于 DNS 的全局负载均衡</b>吗？这个负载均衡主要用来选择一个就近的相同运营商的服务器进行访问。</p><p>    同样的，CDN 分发网络也可以用相同的思路选择最合适的边缘节点。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-239c22054520f2aeddd39e586901a594_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-239c22054520f2aeddd39e586901a594_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    如上图，CDN 的负载均衡流程图。<br/><b>1）没有 CDN 的情况</b>（图中虚线部分）。用户向浏览器输入 <a href=\"https://link.zhihu.com/?target=http%3A//www.web.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">web.com</span><span class=\"invisible\"></span></a> 这个域名，客户端访问本地 DNS 服务器的时候，如果本地 DNS 服务器有缓存，则返回网站的地址。如果没有，递归查询到网站的权威 DNS 服务器，这个权威 DNS 服务器是负责 <a href=\"https://link.zhihu.com/?target=http%3A//web.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">web.com</span><span class=\"invisible\"></span></a> 的，它会返回网站的 IP 地址。本地 DNS 服务器缓存下 IP 地址，将 IP 地址返回，然后客户端直接访问这个 IP 地址，就访问到了网站。</p><p><b>2）有 CDN 的情况</b>（图中实线部分）。此时，在 <a href=\"https://link.zhihu.com/?target=http%3A//web.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">web.com</span><span class=\"invisible\"></span></a> 这个权威 DNS 服务器上，会设置一个 CNAME 别名，指向另外一个域名 <a href=\"https://link.zhihu.com/?target=http%3A//www.web.cdn.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">web.cdn.com</span><span class=\"invisible\"></span></a>，返回给本地 DNS 服务器。</p><p>    当本地 DNS 服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的就不是 <a href=\"https://link.zhihu.com/?target=http%3A//web.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">web.com</span><span class=\"invisible\"></span></a> 这个权威 DNS 服务器了，而是 <a href=\"https://link.zhihu.com/?target=http%3A//web.cdn.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">web.cdn.com</span><span class=\"invisible\"></span></a> 的权威 DNS 服务器，这是 CDN 自己的权威 DNS 服务器，在这个服务器上，还是会设置一个 CNAME，指向另外一个域名，也就是 CDN 网络的全局负载均衡器。</p><p>    接下来，本地 DNS 服务器去请求 CDN 的全局负载均衡器解析域名。全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：</p><ul><li>根据用户 IP 地址，判断哪一台服务器距用户最近；</li><li>用户所处的运营商；</li><li>根据用户所请求的 URL 中携带的内容名词，判断哪一台服务器上有用户所需的内容；</li><li>查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。</li></ul><p>    基于以上这些条件，进行综合分析之后，全局负载均衡器会返回一台缓存服务器的 IP 地址。</p><p>    本地 DNS 服务器缓存这个 IP 地址，然后将 IP 返回给客户端，客户端去访问这个边缘节点，下载资源。</p><p>    缓存服务器响应用户请求，将用户所需内容传送给用户。如果这台缓存服务器上没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器，将内容拉到本地。</p><h3>CDN 缓存内容</h3><p>    保质期长的日用品因为不容易过期，因此比较容易缓存。同样的，互联网中的静态页面、图片等，几乎不怎么改变，所以也适合缓存。而像生鲜之类的保存时间较短的，对应互联网中的动态资源，就需要用到<b>动态 CDN </b>。</p><h3>静态资源缓存</h3><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a22d86f2b88dd10a53a840173e757c77_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-a22d86f2b88dd10a53a840173e757c77_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    还记得上图这个<b>接入层缓存的架构</b>吗？在进入数据中心的时候，我们希望通过最外层接入层的缓存，将大部分静态资源的访问拦在边缘。而 CDN 则更进一步，将这些静态资源缓存到离用户更近的数据中心外。总体来说，就是缩短用户的“访问距离”。<b>离客户越近，客户访问性能越好，时延越低</b>。</p><h3>流媒体 CDN</h3><p>    在静态内容中，流媒体也大量使用了 CDN。</p><p>    CDN 支持流媒体协议。例如前面讲过的 RTMP 协议。在很多情况下，这相当于一个代理，从上一级缓存读取内容，转发给用户。由于流媒体往往是连续的，因而可以进行<b>预先缓存</b>的策略，也可以<b>预先推送到用户的客户端</b>。</p><p>    对于静态页面来讲，内容的分发往往采取<b>拉取</b>的方式。也即，当发现缓存未命中的是，再去上一级进行拉取。</p><p>    这个方式对于流媒体就不合适了。流媒体数据量大，如果出现回源，压力会比较大，所以往往采取<b>主动推送</b>的模式，将热点数据主动推送到边缘节点。</p><p>    对于流媒体来讲，很多 CDN 还提供<b>预处理服务</b>。也就是在文件分发之前，进行一定的处理。例如将视频转换成不同的码流，以适应不同的网络带宽的用户需求。再如对视频进行分片，降低存储压力，也使得客户端可以选择使用不同的码率加载不同的分片。这就是我们常见的，超清、标清、流畅等。</p><p>    除此之外，流媒体 CDN 还有个关键的<b>防盗链</b>问题。因为视频要花大价钱买版权，如果流媒体被其他网站盗走，在其他网站的播放，那损失就大了。</p><p>    对于防盗链问题，最常用也最简单的方法就是<b>利用 HTTP 头的 refer 字段</b>。当浏览器发送请求的时候，一般会带上 refer。告诉服务器是从哪个页面链接过来的，服务器基于此可以获得一些信息用于处理。如果 refer 信息不是来自本站，就阻止访问或者跳到其它链接。</p><p>    refer 的机制相对比较容易破解，所以还需要其它的机制配合。</p><p>    一种常用的机制是<b>时间戳防盗链</b>。使用 CDN 的管理员可以在配置界面上，和 CDN 厂商约定一个加密字符串。</p><p>    客户端访问时，取出当前的时间戳、要访问的资源极其路径，联通加密字符串进行前面算法得到一个字符串，然后生成一个下载链接，带上这个前面字符串和截止时间戳去访问 CDN。</p><p>    在服务端，取出过期时间，和当前 CDN 节点时间进行比较，确认请求是否过期。然后 CDN 服务端根据请求的资源及路径、时间戳、和约定的加密字符串进行签名。只有签名和客户端发送的一致，才会将资源返回给客户。</p><h3>动态资源缓存</h3><p>    对于动态资源，用到动态 CDN。动态 CDN 主要有两种模式：<br/><b>1）“生鲜超市模式”，也就是边缘计算模式</b>。</p><p>    既然数据是动态生成的，所以数据的逻辑计算和存储，也相应的放在边缘的节点。其中定时从源数据那里同步存储的数据，然后在边缘节点进行计算得到结果。</p><p>    这种方式很像现在的生鲜超市。新鲜的海鲜大餐是动态的，很难事先做好缓存，因而将生鲜超市放在你家旁边，既能够送货上门，也能够现场烹饪。这就是边缘计算的一种体现。</p><p><b>2）“冷链运输模式”，也就是路径优化模式</b>。数据不是在边缘计算生成的，而是在源站生成的，但是数据的下发则可以通过 CDN 的网络，对路径进行优化。</p><p>    因为 CDN 节点较多，能够找到离源站很近的边缘节点，也能找到离用户很近的边缘节点。中间的链路完全由 CDN 来规划，选择一个更加可靠的路径，使用类似专线的方式进行访问。</p><p>    除此之外，这些资源进行传输的时候，由于 TCP 的流量控制和拥塞控制，可以在 CDN 加速网络中调整 TCP 的参数，使得 TC 可以更加激进的传输数据。</p><p>    所有这些手段就像冷链传输，优化整个物流运输，全程冷冻高速运输。不管是生鲜从你家旁边超市送过去，还是从产地运送，保证到你家是新鲜的。</p><h3>小结</h3><ul><li>CDN 和电商系统的分布式仓储系统一样，分为中心节点、区域节点、边缘节点，从而将数据缓存在离用户最近的位置。</li><li>CDN 最擅长的缓存是缓存静态数据。除此之外还可以缓存流媒体数据。这时候要注意防盗链问题。它也支持动态数据的缓存，一种是边缘计算，另一种是链路优化。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }, 
                {
                    "tag": "CDN", 
                    "tagLink": "https://api.zhihu.com/topics/19566617"
                }, 
                {
                    "tag": "协议", 
                    "tagLink": "https://api.zhihu.com/topics/19563217"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/87360962", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 0, 
            "title": "网络协议 17 - HTTPDNS", 
            "content": "<p>全球统一的 DNS 是很权威，但是我们都知道“适合自己的，才是最好的”。很多时候，标准统一化的 DNS 并不能满足我们定制的需求，这个时候就需要 HTTPDNS 了。</p><p>    上一节我们知道了 DNS 可以根据名称查地址，也可以针对多个地址做负载均衡。然而，我们信任的地址簿也会存在指错路的情况。明明离你 500 米就有个吃饭的地方，非要把你推荐到 5 公里外。为什么会出现这样的情况呢？</p><p>    还记得吗？由我们发出请求解析 DNS 的时候，首先会连接到运营商本地的 DNS 服务器，由这个服务器帮我们去整棵 “DNS 树” 上进行解析，然后将解析的结果返回给客户端。但是本地的 DNS 服务器，作为一个本地导游，往往会有自己的“小心思”。</p><h3>传统 DNS 存在的问题</h3><p><b>1）域名缓存问题</b><br/>    它可以在本地做一个缓存。也就是说，不是每一个请求，它都会去访问权威 DNS 服务器，而是把访问过一次的结果缓存到本地，当其他人来问的时候，直接返回缓存的内容。</p><p>    这就相当于导游去过一个饭店，自己记住了地址，当有一个游客问的时候，他就凭记忆回答了，不用再去查地址簿。这样会存在一个问题，游客问的那个饭店如果已经搬走了，然而因为导游没有刷新“记忆缓存”，导致游客白跑一趟。</p><p>    另外，有的运营商会把一些静态页面，缓存到本运营商的服务器内，<b>这样用户请求的时候，就不用跨运营商进行访问，既加快了速度，也减少了运营商直接流量计算的成本</b>。也就是说，在域名解析的时候，不会将用户导向真正的网站，而是指向这个缓存的服务器。</p><p>    缓存的问题，很多情况下是看不出问题的，但是当页面更新，用户访问到老的页面，问题就出来了。</p><p>    再就是<b>本地的缓存，往往使得全局负载均衡失败</b>。上次进行缓存的时候，缓存中的地址不一定是客户此次访问离客户最近的地方，如果把这个地址返回给客户，就会让客户绕远路了。<br/><b>2）域名转发问题</b><br/>    还记得我们域名解析的过程吗？捂脸是本地域名解析，还是去权威 DNS 服务器中查找，都可以认为是一种<b>外包形式</b>。有了请求，直接转发给其他服务去解析。如果转发的是权威 DNS 服务器还好说，但是如果因为“偷懒”转发给了邻居服务器去解析，就容易产生跨运营商访问的问题。</p><p>    这就好像，如果 A 运营商的客户，访问自己运营商的 DNS 服务器，A 运营商去权威 DNS 服务器查询的话，会查到客户的 A 运营商的，返回一个部署在 A 运营商的网站地址，这样针对相同运营商的访问，速度就会快很多。</p><p>    但是如果 A 运营商偷懒，没有转发给权威 DNS ，而是转发给了 B 运营商，让 B 运营商再去权威 DNS 服务器查询，这样就会让权威服务器误认为客户是 B 运营商的，返回一个 B 运营商的服务器地址，导致客户每次都要跨运营商访问，访问速度就会慢下来。</p><p><b>3）出口 NAT 问题</b><br/>    前面了解网关的时候，我们知道，出口的时候，很多机房都会配置 NAT，也就是<b>网络地址转换</b>，使得从这个网关出去的包，都换成新的 IP 地址。</p><p>    这种情况下，权威 DNS 服务器就没办法通过请求 IP 来判断客户到底是哪个运营商的，很有可能误判运营商，导致跨运营商访问。</p><p><b>4）域名更新问题</b><br/>    本地 DNS 服务器是由不同地区、不同运营商独立部署的。对域名解析缓存的处理上，实现策略也有区别。有的会偷懒，忽略域名解析结构的 TTL 时间限制，在权威 DNS 服务器解析变更的时候，解析结果在全网生效的周期非常漫长。但是有的场景，在 DNS 的切换中，对生效时间要求比较高。</p><p>    例如双机房部署的是，跨机房的负载均衡和容灾多使用 DNS 来做。当一个机房出问题之后，需要修改权威 DNS，将域名指向新的 IP 地址。但是如果更新太慢，很多用户都会访问一次。</p><p><b>5）解析延迟问题</b><br/>    从 DNS 的查询过程来看，DNS 的查询过程需要递归遍历多个 DNS 服务器，才能获得最终的解析结果，这带来一定的延时，甚至会解析超时。</p><p>    上面总结了 DNS 的五个问题。问题有了，总得有解决办法，就像因为 HTTP 的安全问题，才火了 HTTPS 协议一样，对应的，也有 HTTPDNS 来解决上述 DNS 出现的问题。</p><h3>HTTPDNS</h3><p>    什么是 HTTPDNS ？其实很简单：</p><blockquote> HTTPDNS 是基于 HTTP 协议和域名解析的流量调度解决方案。它不走传统的 DNS 解析，而是自己搭建基于 HTTP 协议的 DNS 服务器集群，分布在多个地点和多个运营商。当客户端需要 DNS 解析的时候，直接通过 HTTP 请求这个服务器集群，得到就近的地址。<br/> </blockquote><p>    这就相当于每家基于 HTTP 协议，自己实现自己的域名解析，做一个自己的地址簿，而不使用统一的地址簿。但是我们知道，域名解析默认都是走 DNS 的，因而使用 HTTPDNS 需要绕过默认的 DNS 路径，也就不能使用默认的客户端。**使用 HTTPDNS 的，往往是手机应用，需要在手机端嵌入支持 HTTPDNS 的客户端 SDK。</p><h3>HTTPDNS 的工作流程</h3><p>    接下来，我们一起来认识下 HTTPDNS 的工作流程。</p><p>    HTTPDNS 会在客户端的 SDK 里动态请求服务端，获取 HTTPDNS 服务器的 IP 列表，缓存在本地。随着不断地解析域名，SDK 也会在本地缓存 DNS 域名解析的结果。</p><p>    当手机应用要访问一个地址的时候，首先看是否有本地的缓存，如果有直接返回。这个缓存和本地 DNS 的缓存不一样的是，这个是手机应用自己做的，而非整个运营商统一做。如何更新以及何时更新缓存，手机应用的客户端可以和服务器协调来做这件事情。</p><p>    如果本地没有，就需要请求 HTTPDNS 的服务器，在本地 HTTPDNS 服务器的 IP 列表中，选择一个发出 HTTP 请求，获取一个要访问的网站的 IP 列表。</p><p>请求的方式是这样的：</p><blockquote> curl <a href=\"https://link.zhihu.com/?target=http%3A//123.4.5.6/d%3Fdn%3Dc.m.cnb.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">123.4.5.6/d?</span><span class=\"invisible\">dn=c.m.cnb.com</span><span class=\"ellipsis\"></span></a><br/> </blockquote><p>    手机客户端之道手机在哪个运营商、哪个地址。由于是直接的 HTTP 通信，HTTPDNS 服务器能够准确知道这些信息，因而可以做精准的全局负载均衡。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-7e0a4bea56dd954f0e6f369e29c76779_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-7e0a4bea56dd954f0e6f369e29c76779_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    上面五个问题，归结起来就两大问题。一是<b>解析速度和更新速度的平衡问题</b>，二是<b>智能调度的问题</b>。HTTPDNS 对应的解决方案是 HTTPDNS 的缓存设计和调度设计。</p><h3>HTTPDNS 的缓存设计</h3><p>    解析 DNS 过程复杂，通信此时多，对解析速度造成很大影响。为了加快解析，因而有了缓存，但是这又会产生缓存更新速度不及时的问题。最要命的是，这两个方面都掌握在别人手中，也就是本地 DNS 服务器手中，它不会为你定制，作为客户端干着急也没办法。</p><p>    而 HTTPDNS 就是将解析速度和更新速度全部掌控在自己手中。</p><p>    一方面，解析的过程，不需要本地 DNS 服务递归的调用一大圈，一个 HTTP 的请求直接搞定。要实时更新的时候，马上就能起作用。</p><p>    另一方面，为了提高解析速度，本地也有缓存，缓存是在客户端 SDK 维护的，过期时间、更新时间，都可以自己控制。</p><p>HTTPDNS 的缓存设计策略也是咱们做应用架构中常用的缓存设计模式，也即分为客户端、缓存、数据源三层。</p><ul><li>对于应用架构来讲，就是应用、缓存、数据库。常见的是 Tomcat、Redis、Mysql；</li><li>对于 HTTPDNS 来讲，就是手机客户端、DNS 缓存、HTTPDNS 服务器。</li></ul><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-46ef964c1741315f829f0b71ed1286a7_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-46ef964c1741315f829f0b71ed1286a7_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    只要是缓存模式，就存在缓存的过期、更新、不一致的问题，解决思路也是相似的。</p><p>    例如，DNS 缓存在内存中，也可以持久化到存储上，从而 APP 重启之后，能够尽快从存储中加载上次累积的经常访问的网站的解析结果，就不需要每次都全部解析一遍，再变成缓存。这有点像 Redis 是基于内存的缓存，但是同样提供持久化的能力，使得重启或者主备切换的时候，数据不会完全丢失。</p><p>    SDK 中的缓存会严格按照缓存过期时间，如果缓存没有命中，或者已经过期，而且客户端不允许使用过期的几率，则会发起一次解析，保证缓存记录是更新的。</p><p>    解析可以<b>同步进行</b>，也就是直接调用 HTTPDNS 的接口，返回最新的记录，更新缓存。也可以<b>异步进行</b>，添加一个解析任务到后台，由后台任务调用 HTTPDNS 的接口。</p><p>    同步更新的优点是实时性好，缺点是如果有多个请求都发现过期的时候，会同时请求 HTTPDNS 多次，造成资源浪费。</p><p>    同步更新的方式对应到应用架构缓存的 <b>Cache-Aside</b> 机制，也就是先读缓存，不命中读数据库，同时将结果写入缓存。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-63c2dea49303d29d0cbf65893cb80e12_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-63c2dea49303d29d0cbf65893cb80e12_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    异步更新的优点是，可以将多个请求都发现过期的情况，合并为一个对于 HTTPDNS 的请求任务，只执行一次，减少 HTTPDNS 的压力。同时，可以在即将过期的时候，就创建一个任务进行预加载，防止过期之后再刷新，称为<b>预加载</b>。</p><p>    它的缺点是，当前请求拿到过期数据的时候，如果客户端允许使用过期时间，需要冒一次风险。这次风险是指，如果过期的请求还能请求，就没问题，如果不能请求，就会失败一次，等下次缓存更新后，才能请求成功。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f675e8c1c4051191602f197375de8464_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-f675e8c1c4051191602f197375de8464_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    异步更新的机制，对应到应用架构缓存的 <b>Refresh-Ahead</b> 机制，即业务仅仅访问缓存，当过期的时候定期刷新。在著名的应用缓存 Guava Cache 中，有个 RefreshAfterWrite 机制，对于并发情况下，多个缓存访问不命中从而引发并发回源的请求，可以采取只有一个请求回源的模式。在应用架构的缓存中，也常常用<b>数据预热</b>或者<b>预加载</b>的机制。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-480d253e09af368fc4a1eb7aa526de88_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-480d253e09af368fc4a1eb7aa526de88_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>HTTPDNS 的调度设计</h3><p>    由于客户端嵌入了 SDK，因而就不会因为本地 DNS 的各种缓存、转发、NAT，让权威 DNS 服务器误会客户端所在的位置和运营商，从而可以拿到第一手资料。</p><p>    在客户端，可以知道手机是哪个国家、哪个运营商、哪个省、甚至是哪个市，HTTPDNS 服务端可以根据这些信息，选择最佳的服务节点返回。</p><p>    如果有多个节点，还会考虑错误率、请求时间、服务器压力、网络状态等，进行综合选择，而非仅仅考虑地理位置。当有一个节点宕机或者性能下降的时候，可以尽快进行切换。</p><p>    要做到这一点，需要客户端使用 HTTPDNS 返回的 IP 访问业务应用。客户端的 SDK 会收集网络请求数据，如错误率、请求时间等网络请求质量数据，并发送到统计后台，进行分析、聚合，以此查看不同 IP 的服务质量。</p><p>    在服务端，应用可以通过调用 HTTPDNS 的管理接口，配置不同服务质量的优先级、权重。HTTPDNS 会根据这些策略综合地理位置和线路状况算出一个排序，优先访问当前那些优质的、时延低的 IP 地址。</p><p>    HTTPDNS 通过智能调度之后返回的结果，也会缓存在客户端。为了不让缓存使得调度失真，客户端可以根据不同的移动网络运营商的 SSID 来分维度缓存。不同的运营商解析出来的结果会不同。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-adfb42f05cba673c68692a9c6810dade_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-adfb42f05cba673c68692a9c6810dade_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>小结</h3><ul><li>传统 DNS 会因为<b>缓存、转发、NAT 等问题</b>导致客户端误会自己所在的位置和运营商，从而影响流量的调度；</li><li>HTTPDNS 通过客户端 SDK 和服务端，通过 HTTP 直接调用解析 DNS 的方式，绕过了传统 DNS 的缺点，实现了智能的调度。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }, 
                {
                    "tag": "DNS", 
                    "tagLink": "https://api.zhihu.com/topics/19581904"
                }, 
                {
                    "tag": "计算机网络", 
                    "tagLink": "https://api.zhihu.com/topics/19572894"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/87336344", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 0, 
            "title": "网络协议 16 - DNS 协议", 
            "content": "<p>       为什么在地址栏输入域名，就能直接访问到对应服务器？全局负载均衡和内部负载均衡又是什么？这些都和 DNS 解析息息相关，让我们一起来解密 DNS 解析。</p><p>    其实说起 DNS 解析，应该都知道它很像地址簿。就像我们去一家新开的沃尔玛超市，通过地址簿查出来沃尔玛在哪条路多少号，然后再去找。</p><p>    在网络世界中，也是这样的。我们可以记住网站的名称，但是很难记住网站的 IP 地址，因此需要一个“地址簿”，帮我们将网站名称转换成 IP。这个“地址簿”就是 <b>DNS 服务器</b>。</p><h3>DNS 服务器</h3><p>    对于 DNS 服务器而言，全球每个人上网，都需要访问它。<br/>    而全球的网民数，据最新统计，已经有 40 亿，每个人都访问它，可想而知 DNS 服务器会有很大的访问流量压力（<b>高并发</b>）。<br/>    而且，它还非常重要，一旦出了故障，整个互联网都将瘫痪（<b>高可用</b>）。<br/>    此外，上网的人分布在全世界各地，如果大家都去同一个地方的某一台服务器，时延将会非常的（<b>分布式</b>）。</p><p>    因此，DNS 服务器一定要具备<b>高可用、高并发、分布式</b>的特点。</p><p>    基于此，DNS 服务器设计成<b>树状的层次结构</b>。如下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d851f9242ba4a1acc02d286403bc271c_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-d851f9242ba4a1acc02d286403bc271c_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><ul><li>根 DNS 服务器：返回顶级域 DNS 服务器的 IP 地址；</li><li>顶级域 DNS 服务器：返回权威 DNS 服务器的 IP 地址；</li><li>权威 DNS 服务器：返回相应主机的 IP 地址。</li></ul><h3>DNS 解析流程</h3><p>    上面说了 DNS 服务器面临大流量访问的压力，因此，为了提高 DNS 的解析性能，很多网站都会就近部署 DNS 缓存服务器。所以，我们常见的 DNS 解析流程就变成了：</p><ol><li><b>客户端发出 DNS 请求给本地域名服务器</b>。我们访问博客园，客户端会问本地域名服务器， <a href=\"https://link.zhihu.com/?target=http%3A//www.cnblogs.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">cnblogs.com</span><span class=\"invisible\"></span></a> 的 IP 是什么？（本地域名服务器，如果网络是通过 DHCP 配置，本地 DNS 是由你的网络服务商，如电信、联通等自动分配，它通常就在网络服务商的机房里）；</li><li><b>本地 DNS 收到来自客户端的请求，查找“地址簿”，返回 IP 或请求根域名服务器</b>。我们可以理解为服务器上缓存了一张域名与 IP 对应的大表，如果能找到 <a href=\"https://link.zhihu.com/?target=http%3A//www.cnblogs.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">cnblogs.com</span><span class=\"invisible\"></span></a>，就直接返回对应的 IP 地址。如果没有找到，本地 DNS 会去问它的根域名服务器；</li><li><b>根 DNS 收到来自本地 DNS 的请求，返回 .com 对应的顶级域名服务器的地址</b>。根域名服务器是最高层次的，全球共有 13 套，它不直接用于域名解析，而是指明怎样去查找对应 IP。它发现请求的域名后缀是 .com，就会返回 .com 对应的顶级域名服务器的地址；</li><li><b>本地 DNS 服务器收到顶级 DNS 服务器地址，请求顶级 DNS 服务器查询域名 IP</b>；</li><li><b>顶级 DNS 服务器返回权威 DNS 服务器地址</b>。顶级域名服务器就是大名鼎鼎的，负责 .com、.net、.org 这些二级域名，比如 <a href=\"https://link.zhihu.com/?target=http%3A//cnblogs.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">cnblogs.com</span><span class=\"invisible\"></span></a>，它会返回对应的权威 DNS 服务器地址；</li><li><b>本地 DNS 服务器收到权威 DNS 服务器地址，请求权威 DNS 服务器查询域名 IP</b>。而 <a href=\"https://link.zhihu.com/?target=http%3A//cnblogs.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">cnblogs.com</span><span class=\"invisible\"></span></a> 的权威 DNS 服务器就是域名解析结果的原出处；</li><li><b>权威 DNS 服务器返回对应 IP</b>。权威 DNS 服务器查询“地址簿”，获取到域名对应 IP 地址，返回给本地 DNS 服务器；</li><li><b>本地 DNS 服务器收到 IP，返回给客户端</b>；</li><li><b>客户端与目标建立连接</b>。</li></ol><p>    至此，我们完成了 DNS 的解析过程，整个过程如下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-1bbeadb9af6355eb1febb6e869cd2691_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-1bbeadb9af6355eb1febb6e869cd2691_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>负载均衡</h3><p>    站在客户端角度，上述过程是一次 <b>DNS 递归查询过程</b>。因为本地 DNS 全权为它代劳，它只要坐等结果就好了。在这个过程中，DNS 除了可以通过名称映射为 IP 地址外，它还可以做另外一件很重要的事 - <b>负载均衡</b>。</p><p>    还是拿我们逛沃尔玛超市为例。它可能在一个城市里会有多家店，我们要逛沃尔玛，可以<b>就近找一家，而不用都去同一家</b>，这就是负载均衡。</p><p>DNS 做负载均衡也有花样可以玩。<br/><b>1）DNS 做内部负载均衡</b><br/>    所谓的内部负载均衡，其实很好理解。就像我们的应用访问数据库，在应用里配置的数据库地址。如果配置成 IP 地址，一旦数据库换到了另外一台机器，我们就要修改配置。如果我们有很多台应用同时连一个数据库，一换 IP，就需要将这些应用的配置全部修改一遍，是不是很麻烦？所以，我们可以将数据地址配置成<b>域名</b>。在更换数据库位置时，只要在 DNS 服务器里，将域名映射为新的 IP 地址就可以了。</p><p>    在这个基础上，我们可以更进一步 。例如，某个应用要访问另外一个应用，如果配置另外一个应用的 IP 地址，那么这个访问就是一对一的。但是当被访问的应用因流量过大撑不住的时候，我们就需要部署多个应用。这时候，我们就不能直接配置成 IP，而是要配置域名了。只要在域名解析的时候，配置好策略，这次返回一个 IP，下次返回第二个 IP，就实现了负载均衡。</p><p><b>2）DNS 做全局负载均衡</b><br/>    为了保证我们应用的高可用性，往往会将应用部署在多个机房，每个地方都会有自己的 IP 地址。当用户访问某个域名的时候，这个 IP 地址可以轮询访问多个数据中心。如果一个数据中心因为某种原因挂了，只要将这个 IP 地址从 DNS 服务器中删掉就可以了，用户不会访问到宕机的服务器，保证了应用的可用性。</p><p>    另外，我们肯定希望用户能访问就近的数据中心。这样客户访问速度就会快很多，体验也会好很多，也就实现了全局负载均衡的概念。</p><h3>负载均衡示例</h3><p>    我们通过 NDS 访问数据中心对象存储上的静态资源为例，来看一看整个过程。</p><p>    假设全国有多个数据中心，托管在多个运营商，每个数据中心有三个可用区。对象存储可以通过跨可用区部署，实现高可用性。在每个数据中心中，都至少部署两个内部负载均衡器，内部负载均衡器后面对接多个对象存储的前置服务器（Proxy-server）。那么，请求过程如下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-19ab444e01249ba56be80d74b5bc6e49_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-19ab444e01249ba56be80d74b5bc6e49_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><ol><li>当一个客户端要访问 <a href=\"https://link.zhihu.com/?target=http%3A//object.yourcompany.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">object.yourcompany.com</span><span class=\"invisible\"></span></a> 的时候，需要将域名转换为 IP 地址进行访问，所以它要请求本地 DNS 解析器；</li><li>本地 DNS 解析器先查看本地的缓存是否有这个记录。如果有，就直接用，省略后续查询步骤，提高相应时间；</li><li>如果本地无缓存，就需要请求本地的 DNS 服务器；</li><li>本地 DNS 服务器一般部署在数据中心或者你所在的运营商网络中。本地 DNS 服务器也需要看本地是否有缓存，如果有，就直接返回；</li><li>本地没有，通过第 5、6、7 步骤获取到 IP 地址，缓存到本地 DNS 解析器中，然后在返回给客户端。</li></ol><p>    对于不需要做全局负载均衡的简单应用来讲，<a href=\"https://link.zhihu.com/?target=http%3A//yourcompany.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">yourcompany.com</span><span class=\"invisible\"></span></a> 的权威 DNS 服务器可以直接将 <a href=\"https://link.zhihu.com/?target=http%3A//object.yourcompa.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">object.yourcompa.com</span><span class=\"invisible\"></span></a> 这个域名解析为一个或者多个 IP 地址，然后客户端可以通过多个 IP 地址，进行简单的轮询，实现简单的负载均衡。</p><p>    但是对于复制的应用，尤其是跨地域跨运营商的大型应用，就需要更加复杂的全局负载均衡机制，因而需要专门的设备或者服务器来做这件事情，这就是<b>全局负载均衡器（GSLB，Global Server Load Balance）</b>。</p><p>    在 <a href=\"https://link.zhihu.com/?target=http%3A//yourcompany.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">yourcompany.com</span><span class=\"invisible\"></span></a> 的 DNS 服务器中，一般是通过配置 CNAME 的方式，给 <a href=\"https://link.zhihu.com/?target=http%3A//object.yourcompany.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">object.yourcompany.com</span><span class=\"invisible\"></span></a> 起一个别名。例如 <a href=\"https://link.zhihu.com/?target=http%3A//object.vip.yourcompany.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">object.vip.yourcompany.com</span><span class=\"invisible\"></span></a>，然后告诉本地 DNS 服务器，让它请求 GSLB 解析这个域名，GSLB 就可以在解析这个域名的过程中，通过自己的策略实现负载均衡。</p><p>上图中画了两层的 GSLB，是因为分运营商和地域。我们希望不同运营商的客户，可以访问对应运营商机房中的资源，这样不跨运营商访问，有利于提高吞吐量，减少时延。两层 GSLB 的过程如下：</p><ol><li>第一层 GSLB，通过查看请求它的本地 DNS 服务器所在的运营商，就知道用户所在的运营商。假设是移动，通过 CNAME 的方式，通过另一个别名 <a href=\"https://link.zhihu.com/?target=http%3A//object.yd.yourcompany.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">object.yd.yourcompany.com</span><span class=\"invisible\"></span></a>，告诉本地 DNS 服务器去请求第二层的 GSLB；</li><li>第二层 GSLB，通过查看请求它的本地 DNS 服务器的地址，知道用户所在的地理位置，然后将距离用户位置比较近的一个 Region 的六个内部负载均衡的地址，返回给本地 DNS 服务器；</li><li>本地 DNS 服务器将结果返回给本地 DNS 解析器；</li><li>本地 DNS 解析器将结果缓存后，返回给客户端；</li><li>客户端开始访问属于相同运营商的，且距离比较近的 Region1 中的对象存储。当然，客户端得到了六个 IP 地址，它可以通过负载均衡的方式，随机或者轮询选择一个可用区进行访问。对象存储一般会有三个备份，从而实现对存储读写的负载均衡。</li></ol><h3>小结</h3><ul><li>DNS 是网络世界的地址簿。可以通过域名查地址，因为域名服务器是按照树状结构组织的，因而域名查找是使用递归查询的方式，并通过缓存的方式加快效率；</li><li>在域名和 IP 的映射中，给了应用基于域名做负载均衡的机会，可以是简单的负载均衡，也可以是根据地址和运营商做的全局负载均衡。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "DNS", 
                    "tagLink": "https://api.zhihu.com/topics/19581904"
                }, 
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }, 
                {
                    "tag": "域名解析", 
                    "tagLink": "https://api.zhihu.com/topics/19587249"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/87327257", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 2, 
            "title": "网络协议 15 - P2P 协议", 
            "content": "<p>大家说起种子，应该都知道是用来下载资源的。那么资源下载都有哪些方式？种子下载又有什么优势呢？</p><h3>下载电影的两种方式</h3><p>    第一种是通过 HTTP 进行下载。这种方式，有过经历的人应该体会到，当下载文件稍大点，下载速度简直能把人急死。</p><p>    第二种方式就是是<b>通过 FTP（文件传输协议）</b>。FTP 采用两个 TCP 连接来传输一个文件。</p><ol><li><b>控制连接</b>。服务器以被动的方式，打开众所周知用于 FTP 的端口 21，客户端则主动发起连接。该连接将<b>命令</b>从客户端传给服务器，并传回服务器的<b>应答</b>。常用的命令有：lsit - 获取文件目录，reter - 取一个文件，store - 存一个文件；</li><li><b>数据连接</b>。每当一个文件在客户端与服务器之间传输时，就创建一个数据连接。</li></ol><h3>FTP 的工作模式</h3><p>    在 FTP 的两个 TCP 连接中，每传输一个文件，都要新建立一个数据连接。基于这个数据连接，FTP 又有两种工作模式：<b>主动模式（PORT）</b>和<b>被动模式（PASV）</b>，要注意的是，这里的主动和被动都是站在服务器角度来说的。工作模式过程如下：</p><p><b>主动模式工作流程</b></p><ol><li>客户端随机打开一个大于 1024 的端口 N，向服务器的<b>命令端口 21</b> 发起连接，同时开放 N+1 端口监听，并向服务器发出“port N+1” 命令；</li><li>由服务器从自己的数据端口 20，<b>主动连接到客户端指定的数据端口 N+1</b>。</li></ol><p><b>被动模式工作流程</b></p><ol><li>客户端在开启一个 FTP 连接时，打开两个任意的本地端口 N（大于1024）和 N+1。然后用 N 端口连接服务器的 21 端口，提交 PASV 命令；</li><li>服务器收到命令，开启一个任意的端口 P（大于 1024），返回“227 entering passive mode”消息，消息里有服务器开放的用来进行数据传输的端口号 P。</li><li>客户端收到消息，取得端口号 P，通过 N+1 端口连接服务器的 P 端口，进行数据传输。</li></ol><p>    上面说了 HTTP 下载和 FTP 下载，这两种方式都有一个大缺点-<b>难以解决单一服务器的带宽压力</b>。因为它们使用的都是传统 C/S 结构，这种结构会随着客户端的增多，下载速度越来越慢。这在当今互联网世界显然是不合理的，我们期望能实现“下载人数越多，下载速度不变甚至更快”的愿望。</p><p>    后来，一种创新的，称为 P2P 的方式实现了我们的愿望。</p><h3>P2P</h3><p>    P2P 就是 peer-to-peer。这种方式的特点是，资源一开始并不集中存储在某些设备上，而是分散地存储在多台设备上，这些设备我们称为 peer。</p><p>    在下载一个文件时，只要得到那些已经存在了文件的 peer 地址，并和这些 peer 建立点对点的连接，就可以就近下载文件，而不需要到中心服务器上。一旦下载了文件，你的设备也就称为这个网络的一个 peer，你旁边的那些机器也可能会选择从你这里下载文件。</p><p>    通过这种方式解决上面 C/S 结构单一服务器带宽压力问题。如果使用过 P2P2 软件，例如 BitTorrent，你就会看到自己网络不仅有下载流量，还有上传流量，也就是说你加入了这个 P2P 网络，自己可以从这个网络里下载，同时别人也可以从你这里下载。这样就实现了，<b>下载人数越多，下载速度越快的愿望</b>。</p><h3>种子文件（.torent）</h3><p>    上面整个过程是不是很完美？是的，结果很美好，但为了实现这个美好，我们还是有很多准备工作要做的。比如，我们怎么知道哪些 peer 有某个文件呢？</p><p>    这就用到我们常说的<b>种子（.torrent）</b>。 .torrent 文件由<b>Announce（Tracker URL）</b>和<b>文件信息</b>两部分组成。</p><p>    其中，文件信息里有以下内容：</p><ul><li><b>Info 区</b>：指定该种子包含的文件数量、文件大小及目录结构，包括目录名和文件名；</li><li><b>Name 字段</b>：指定顶层目录名字；</li><li><b>每个段的大小</b>：BitTorrent（BT）协议把一个文件分成很多个小段，然后分段下载；</li><li><b>段哈希值</b>：将整个种子种，每个段的 SHA-1 哈希值拼在一起。</li></ul><p>    下载时，BT 客户端首先解析 .torrent 文件，得到 Tracker 地址，然后连接 Tracker 服务器。Tracker 服务器回应下载者的请求，将其他下载者（包括发布者）的 IP 提供给下载者。</p><p>    下载者再连接其他下载者，根据 .torrent 文件，两者分别对方自己已经有的块，然后交换对方没有的数据。</p><p>    可以看到，下载的过程不需要其他服务器参与，并分散了单个线路上的数据流量，减轻了服务器的压力。</p><p>    下载者每得到一个块，需要算出下载块的 Hash 验证码，并与 .torrent 文件中的进行对比。如果一样，说明块正确，不一样就需要重新下载这个块。这种规定是为了解决下载内容的准确性问题。</p><p>    从这个过程也可以看出，这种方式特别依赖 Tracker。Tracker 需要收集所有 peer 的信息，并将从信息提供给下载者，使下载者相互连接，传输数据。虽然下载的过程是非中心化的，但是加入这个 P2P 网络时，需要借助 Tracker 中心服务器，这个服务器用来登记有哪些用户在请求哪些资源。</p><p>    所以，这种工作方式有一个弊端，一旦 Tracker 服务器出现故障或者线路被屏蔽，BT 工具就无法正常工作了。那能不能彻底去中心化呢？答案是可以的。</p><h3>去中心化网络（DHT）</h3><p><b>DHT（Distributed Hash Table）</b>，这个网络中，每个加入 DHT 网络的人，都要负责存储这个网络里的资源信息和其他成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。</p><p>    而 <b>Kedemlia 协议</b> 就是一种著名的 DHT 协议。我们来基于这个协议来认识下这个神奇的 DHT 网络。</p><p>    当一个客户端启动 BitTorrent 准备下载资源时，这个客户端就充当了两个角色：</p><ol><li>peer 角色：监听一个 TCP 端口，用来上传和下载文件。对外表明我这里有某个文件；</li><li>DHT Node 角色：监听一个 UDP 端口，通过这个角色，表明这个节点加入了一个 DHT 网络。</li></ol><p>    在 DHT 网络里面，每一个 DHT Node 都有一个 ID。这个 ID 是一个长字符串。每个 DHT Node 都有责任掌握一些“知识”，也就是<b>文件索引</b>。也就是说，每个节点要知道哪些文件是保存哪些节点上的。注意，这里它只需要有这些“知识”就可以了，而它本身不一定就是保存这个文件的节点。</p><p>    当然，每个 DHT Node 不会有全局的“知识”，也就是说它不知道所有的文件保存位置，只需要知道一部分。这里的一部分，就是通过哈希算法计算出来的。</p><h3>Node ID 和文件哈希值</h3><p>    每个文件可以计算出一个哈希值，而 <b>DHT Node 的 ID 是和哈希值相同长度的串</b>。</p><p>    对于文件下载，DHT 算法是这样规定的：</p><blockquote> 如果一个文件计算出一个哈希值，则和这个哈希值一样的那个 DHT Node，就有责任知道从哪里下载这个文件，即便它自己没保存这个文件。<br/> </blockquote><p>    当然不一定总这么巧，都能找到和哈希值一模一样的，有可能文件对应的 DHT Node 下线了，所以 DHT 算法还规定：</p><blockquote> 除了一模一样的那个 DHT Node 应该知道文件的保存位置，ID 和这个哈希值非常接近的 N 个 DHT Node 也应该知道。<br/> </blockquote><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9cde0cd2676d3587dc10b1566751fcb6_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-9cde0cd2676d3587dc10b1566751fcb6_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    以上图为例。文件 1 通过哈希运算，得到匹配 ID 的 DHT Node 为 Node C（当然还会有其他的，为了便于理解，咱们就先关注 Node C），所以，Node C 就有责任知道文件 1 的存放地址，虽然 Node C 本身没有存放文件 1。</p><p>    同理，文件 2 通过哈希计算，得到匹配 ID 的 DHT Node 为 Node E，但是 Node D 和 E 的值很近，所以 Node D 也知道。当然，文件 2 本身不一定在 Node D 和 E 这里，但是我们假设 E 就有一份。</p><p>    接下来，一个新节点 Node new 上线了，如果要下载文件 1，它首先要加入 DHT 网络。如何加入呢？</p><p>    在这种模式下，种子 .torrent 文件里面就不再是 Tracker 的地址了，而是一个 list 的 Node 地址，所有这些 Node 都是已经在 DHT 网络里面的。当然，随着时间的推移，很有可能有退出的，有下线的，这里我们假设，不会所有的都联系不上，总有一个能联系上。</p><p>    那么，Node new 只要在种子里面找到一个 DHT Node，就加入了网络。</p><p>    Node new 不知道怎么联系上 Node C，因为种子里面的 Node 列表里面很可能没有 Node C，但是没关系，它可以问。DHT 网络特别像一个社交网络，Node new 会去它能联系上的 Node 问，你们知道 Node C 的联系方式吗？</p><p>    在 DHT 网络中，<b>每个 Node 都保存了一定的联系方式，但是肯定没有所有 Node 的联系方式</b>。节点之间通过相互通信，会交流联系方式，也会删除联系方式。这和人们的沟通方式一样，你有你的朋友圈，他有他的朋友圈，你们互相加微信，就互相认识了，但是过一段时间不联系，就可能会删除朋友关系一样。</p><p>    在社交网络中，还有个著名的<b>六度理论</b>，就是说社交网络中的<b>任何两个人的直接距离不超过六度</b>，也就是即使你想联系比尔盖茨，最多通过六个人就能够联系上。</p><p>    所以，Node New 想联系 Node C，就去万能的朋友圈去问，并且求转发，朋友再问朋友，直到找到 C。如果最后找不到 C，但是能找到离 C 很近的节点，也可以通过 C 的相邻节点下载文件 1。</p><p>    在 Node C上，告诉 Node new，要下载文件 1，可以去 B、D、F，这里我们假设 Node new 选择了 Node B，那么新节点就和 B 进行 peer 连接，开始下载。它一旦开始下载，自己本地也有文件 1 了，于是，Node new 就告诉 C 以及 C 的相邻节点，我也有文件 1 了，可以将我加入文件 1 的拥有者列表了。</p><p>    你可能会发现，上面的过程中漏掉了 Node new 的文件索引，但是根据哈希算法，一定会有某些文件的哈希值是和 Node new 的 ID 匹配的。在 DHT 网络中，会有节点告诉它，你既然加入了咱们这个网络，也就有责任知道某些文件的下载地址了。</p><p>    好了，完成分布式下载了。但是我们上面的过程中遗留了两个细节性的问题。</p><p><b>1）DHT Node ID 以及文件哈希值是什么？</b><br/>    其实，我们可以将节点 ID 理解为一个 160bits（20字节）的字符串，文件的哈希也使用这样的字符串。</p><p><b>2）所谓 ID 相似，具体到什么程度算相似？</b><br/>    这里就要说到两个节点距离的定义和计算了。</p><p>    在 Kademlia 网络中，两个节点的距离采用的是逻辑上的距离，假设节点 A 和 节点 B 的距离为 d，则：</p><blockquote> d = A XOR B<br/> </blockquote><p>    上面说过，每个节点都有一个哈希 ID，这个 ID 由 20 个字符，160 bits 位组成。这里，我们就用一个 5 bits ID 来举例。<br/>    我们假设，节点 A 的 ID 是 01010，节点 B 的 ID 是 01001，则：</p><blockquote> 距离 d = A XOR B = 01010 XOR 00011 = 01001 = 9<br/> </blockquote><p>    所以，我们说节点 A 和节点 B 的逻辑距离为 9。</p><p>    回到我们上面的问题，哈希值接近，可以理解为距离接近，也即，<b>和这个节点距离近的 N 个节点要知道文件的保存位置</b>。</p><p>    要注意的是，这个距离不是地理位置，因为在 Kademlia 网络中，位置近不算近，ID 近才算近。我们可以将这个距离理解为<b>社交距离</b>，也就是在朋友圈中的距离，或者社交网络中的距离。这个和你的空间位置没有多少关系，和人的经历关系比较大。</p><h3>DHT 网络节点关系的维护</h3><p>    就像人一样，虽然我们常联系的只有少数，但是朋友圈肯定是远近都有。DHT 网络的朋友圈也一样，远近都有，并且<b>按距离分层</b>。</p><p>    假设某个节点的 ID 为 01010，如果一个节点的 ID，前面所有位数都与它相同，只有最后 1 位不停，这样的节点只有 1 个，为 01011。与基础节点的异或值为 00001，也就是距离为 1。那么对于 01010 而言，这样的节点归为第一层节点，也就是<b>k-buket 1</b>。</p><p>    类似的，如果一个节点的 ID，前面所有位数和基础节点都相同，从倒数第 2 位开始不同，这样的节点只有 2 个，即 01000 和 01001，与基础节点的亦或值为 00010 和 00011，也就是距离为 2 和 3。这样的节点归为第二层节点，也就是<b>k-bucket 2</b>。</p><p>    所以，我们可以总结出以下规律：</p><blockquote> 如果一个节点的 ID，前面所有位数相同，从倒数第 i 位开始不同，这样的节点只有 2^(i-1) 个，与基础节点的距离范围为 [2^(i-1), 2^i]，对于原始节点而言，这样的节点归为<b>k-bucket i</b>。<br/> </blockquote><p>    你会发现，差距越大，陌生人就越多。但是朋友圈不能把所有的都放下，所以每一层都只放 K 个，这个 K 是可以通过参数配置的。</p><h3>DHT 网络中查找好友</h3><p>    假设，Node A 的 ID 为 00110，要找 B（10000），异或距离为 10110，距离范围在 [2^4, 2^5)，这就说明 B 的 ID 和 A 的从第 5 位开始不同，所以 B 可能在 k-bucket 5 中。</p><p>    然后，A 看看自己的 k-bucket 5 有没有 B，如果有，结束查找。如果没有，就在 k-bucket 5 里随便找一个 C。因为是二进制，C、B 都和 A 的第 5 位不停，那么 C 的 ID 第5 位肯定与 B 相同，即它与 B 的距离小于 2^4，相当于 A、B 之间的距离缩短了一半以上。</p><p>    接着，再请求 C，在 C 的通讯里里，按同样的查找方式找 B，如果 C 找到了 B，就告诉 A。如果 C 也没有找到 B，就按同样的搜索方法，在自己的通讯里里找到一个离 B 更近一步的 D（D、B 之间距离小于 2^3），把 D 推荐给 A，A 请求 D 进行下一步查找。</p><p>    你可能已经发现了，Kademlia 这种查询机制，是通过<b>折半查找</b>的方式来收缩范围，对于总的节点数目为 N 的网络，最多只需要 log2(N) 次查询，就能够找到目标。</p><p>    如下图，A 节点找 B 节点，最坏查找情况：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-971019b8a91da7844e134385280447a5_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-971019b8a91da7844e134385280447a5_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    图中过程如下：</p><ol><li>A 和 B 的每一位都不一样，所以相差 31，A 找到的朋友 C，不巧正好在中间，和 A 的距离是 16，和 B 的距离是 15；</li><li>C 去自己朋友圈找，碰巧找到了 D，距离 C 为 8，距离 B 为 7；</li><li>D 去自己朋友圈找，碰巧找到了 E，距离 D 为 4，距离 B 为 3；</li><li>E 在自己朋友圈找，找到了 F，距离 E 为 2，距离 B 为 1；</li><li>F 在距离为 1 的地方找到了 B。</li></ol><h3>节点的沟通</h3><p>    在 Kademlia 算法中，每个节点下面 4 个指令：</p><ul><li>PING：测试一个节点是否在线。相当于打个电话，看还能打通不；</li><li>STORE：要钱一个节点存储一份数据；</li><li>FIND_NODE：根据节点 ID 查找一个节点；</li><li>FIND_VALUE：根据 KEY 查找一个数据，实则上和 FIND_NODE 非常类似。KEY 就是文件对应的哈希值，找到保存文件的节点。</li></ul><h3>节点的更新</h3><p>    整个 DHT 网络，会通过相互通信，维护自己朋友圈好友的状态。</p><ul><li>每个 bucket 里的节点，都按最后一次接触时间<b>倒序排列</b>。相当于，朋友圈里最近联系的人往往是最熟的；</li><li>每次执行四个指令中的任意一个都会触发更新；</li><li>当一个节点与自己接触时，检查它是否已经在 k-bucket 中。就是说是否已经在朋友圈。如果在，那么就将它移到 k-bucket 列表的最底，也就是最新的位置（刚联系过，就置顶下，方便以后多联系）。如果不在，就要考虑新的联系人要不要加到通讯录里面。假设通讯录已满，就 PING 一下列表最上面的节点（最旧的），如果 PING 通了，将旧节点移动到列表最底，并丢弃新节点（老朋友还是要留点情面的）。如 PING 不同，就删除旧节点，并将新节点加入列表（联系不上的老朋友还是删掉吧）。</li></ul><p>    通过上面这个机制，保证了任意节点的加入和离开都不影响整体网络。</p><h3>小结</h3><ul><li>下载一个文件可以通过 HTTP 或 FTP。这两种都是<b>集中下载</b>的方式，而 P2P 则换了一种思路，采用非中心化下载的方式；</li><li>P2P 有两种。一种是依赖于 Tracker 的，也就是元数据集中，文件数据分散。另一种是基于分布式的哈希算法，元数据和文件数据全部分散。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "P2P", 
                    "tagLink": "https://api.zhihu.com/topics/19557216"
                }, 
                {
                    "tag": "下载", 
                    "tagLink": "https://api.zhihu.com/topics/19553375"
                }, 
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/87325957", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 0, 
            "title": "网络协议 14 - 流媒体协议", 
            "content": "<p>大家都会关注“在浏览器输入一个地址，然后回车，会发生什么”这样一个问题，但是有没有想过这样一个问题：主播开始直播，用户打开客户端观看，这个过程发生了什么？</p><p>    随着技术的发展，直播技术对人们生活的渗透日益加深。从最开始的游戏直播，到前几天爆出来的教育直播，甚至现在都有直播招聘。</p><p>    而我们喜欢的这些直播，他们用到的传输协议有一个通用名-<b>流媒体传输协议</b>。</p><p>    要认识流媒体协议，就离不开下面的三大系列名词。</p><h3>三大系列名词</h3><ul><li>系列一：AVI、MPEG、RMVB、MP4、MOV、FLV、WebM、WMV、ASF、MKV。是不是就 MP4 看着熟悉？</li><li>系列二：H.261、H.262、H.263、H.264、H.265。能认出来几个？别着急，重点关注 H.264。</li><li>系列三：MPEG-1、MPEG-2、MPEG-4、MPEG-7。是不是更懵逼了？</li></ul><p>    在解释上面的三大系列名词之前，咱们先来了解下，视频究竟是什么？</p><p>    博主记得小时候，经常会玩一种叫动感画册的东西。一本很小的画册上，每一页都画了一幅图，用手快速的翻过每一页，就能看到一个很短的“动画片”。</p><p>    没错，咱们看到的视频，本质上就是<b>一连串快速播放的图片</b>。</p><p>    每一张图片，我们称为<b>一帧</b>。只要每秒钟的数据足够多，也就是播放速度足够快，人眼就看不出是一张张独立的图片。对于人眼而言，这个播放临界速度是<b>每秒 30 帧</b>，而这里的 30 也就是我们常说的<b>帧率（FPS)</b>。</p><p>    每一张图片，都是由<b>像素</b>组成，而每个像素又是由 RGB 组成，每个 8 位，共 24 位。</p><p>    我们假设一个视频中的所有图片的像素都是 1024*768，可以大概估算下视频的大小：</p><blockquote> 每秒钟大小 = 30 帧 x 1024 x 768 x 24 = 566,231,010 Bits = 70,778,880 Bytes<br/> </blockquote><p>    按我们上面的估算，一分钟的视频大小就是 4,,246,732,800 Bytes，这里已经有 4 个 G 了。</p><p>    是不是和我们日常接触到的视频大小明显不符？这是因为我们在传输的过程中，<b>将视频压缩了</b>。</p><p>    为什么要压缩视频？按我们上面的估算，一个一小时的视频，就有 240G，这个数据量根本没办法存储和传输。因此，人们利用<b>编码技术</b>，给视频“瘦身”，用尽量少的 Bit 数保持视频，同时要保证播放的时候，画面仍然很清晰。实际上，<b>编码就是压缩的过程</b>。</p><h3>视频和图片的压缩特点</h3><p>我们之所以能够对视频流中的图片进行压缩，因为视频和图片有下列这些特点：</p><ol><li><b>空间冗余</b>：图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，而不是突变的，没必要每个像素都完整的保存，可以隔几个保存一个，中间的用算法计算出来。</li><li><b>时间冗余</b>：视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根据已有的图片进行预测和推断。</li><li><b>视觉冗余</b>：人的视觉系统对某些细节不敏感，因此不会注意到每一个细节，可以允许丢失一些数据。</li><li><b>编码冗余</b>：不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多，类似<b>霍夫曼编码</b>的思路。</li></ol><p>    从上面这些特点中可以看出，用于编码的算法非常复杂，而且多种多样。虽然算法多种，但编码过程实际上是类似的，如下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0b6ede161e6eb5130dca3d80bf21002f_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-0b6ede161e6eb5130dca3d80bf21002f_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>视频编码的两大流派</h3><p>    视频编码的算法这么多，能不能形成一定的标准呢？当然能，这里咱们就来认识下视频编码的两大流派。</p><ul><li>流派一：ITU（International tELECOMMUNICATIONS Union）的 VCEG（Video Coding Experts Group），这个称为<b>国际电联下的 VCEG</b>。既然是电信，可想而知，他们最初是做视频编码，主要侧重<b>传输</b>。我们上面的系列名词二，就是这个组织制定的标准。</li><li>流派二：ISO（International Standards Organization）的 MPEG（Moving Picture Experts Group），这个是 <b>ISO 旗下的 MPEG</b>。本来是做视频存储的，就像咱们场面常说的 VCD 和 DVD。后来也慢慢侧重视频传输了。系列名词三就是这个组织制定的标准。</li><li>后来，ITU-T（国际电信联盟电信标准化部门）与 MPEG 联合制定了 H.264/MPEG-4 AVC，这也是我们重点关注的。</li></ul><h3>直播数据传输</h3><p>    视频经过编码之后，生动活泼的一帧帧图像就变成了一串串让人看不懂的二进制。这个二进制可以放在一个文件里，然后按照一定的格式保存起来，这里的<b>保存格式</b>，就是系列名词一。</p><p>    编码后的二进制文件就可以通过某种网络协议进行封装，放在互联网上传输，这个时候就可以进行网络直播了。</p><p>    网络协议将编码好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的服务端来接收这些网络数据包，从而得到里面的视频流，这个过程称为<b>接流</b>。</p><p>    服务端接到视频流之后，可以滴视频流进行一定的处理，比如<b>转码</b>，也就是从一个编码格式转成另一种格式，这样才能适应各个观众使用的客户端，保证他们都能看到直播。</p><p><b>流处理</b>完毕后，就可以等待观众的客户端来请求这些视频流。观众的客户端请求视频流的过程称为<b>拉流</b>。</p><p>    如果有非常多的观众同时看一个视频直播，都从一个服务器上<b>拉流</b>，压力就非常大，因此需要一个视频的<b>分发网络</b>，将视频预先加载到就近的边缘节点，这样大部分观众就能通过边缘节点拉取视频，降低服务器的压力。</p><p>    当观众将视频流拉下来后，就需要进行<b>解码</b>，也就是通过上述过程的逆过程，将一串串看不懂的二进制转变成一帧帧生动的图片，在客户端播放出来。</p><p>    整个直播过程，可以用下图来描述：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-b8835826c3b91eb39afe8ad7b7d69d9b_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-b8835826c3b91eb39afe8ad7b7d69d9b_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    接下来，我们依次来看一下每个过程：</p><h3>编码：将丰富多彩的图片变成二进制流</h3><p>    虽然我们说视频是一张张图片的序列，但如果每张图片都完整，就太大了，因而会将视频序列分成三种帧：</p><ul><li><b>I帧</b>，也称<b>关键帧</b>。里面是完整的图片，只需要本帧数据，就可以完成解码。</li><li><b>P帧</b>，前向预测编码帧。P 帧表示的是这一帧跟之前一个关键帧（或 P 帧）的差别，解码时需要用之前缓存的画面，叠加上和本帧定义的差别，生成最终画面。</li><li><b>B帧</b>，双向预测内插编码帧。B 帧记录的是本帧与前后帧的差别。要解码 B 帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的数据与本帧数据的叠加，取得最终的画面。</li></ul><p>    可以看出，I 帧最完整，B 帧压缩率最高，而压缩后帧的序列，应该是 IBBP 间隔出现。这就是<b>通过时序进行编码</b>。</p><p>    在一帧中，分成多个片，每个片中分成多个宏块，每个宏块分成多个子块，这样将一张大图分解成一个个小块，可以方便进行<b>空间上的编码</b>。如下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-712dbd843071902224e1869dcb4d6382_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-712dbd843071902224e1869dcb4d6382_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    尽管时空非常立体的组成了一个序列，但总归还是要压缩成一个二进制流。这个流是有结构的，是一个个的<b>网络提取层单元（NALU，Network Abstraction Layer Unit）</b>。变成这种格式就是为了传输，因为网络上的传输，默认的是一个个的包，因而这里也就分成了一个个的单元。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-88e1b4b2fe36ec1187d4b60c4e8227e5_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-88e1b4b2fe36ec1187d4b60c4e8227e5_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    如上图，每个 NALU 首先是一个起始标识符，用于标识 NALU 之间的间隔。然后是 NALU 的头，里面主要配置了 NALU 的类型。最后的 Payload 里面是 NALU 承载的数据。</p><p>    在 NALU 头里面，主要的内容是类型 NAL Type，其中：</p><ul><li>0x07 表示 SPS，是序列参数集，包括一个图像序列的所有信息，如图像尺寸、视频格式等。</li><li>0x08 表示 PPS，是图像参数集，包括一个图像的所有分片的所有相关信息，包括图像类型、序列号等。</li></ul><p>    在传输视频流之前，剥削要传输者两类参数，不然就无法解码。为了保证容错性，每一个 I 帧之前，都会传一遍这两个参数集合。</p><p>    如果 NALU Header 里面的表示类型是 SPS 或 PPS，则 Payload 中就是真正的参数集的内容。</p><p>    如果类型是帧，则 Payload 中是真正的视频数据。当然也是一帧帧保存的。前面说了，一帧的内容还是挺多的，因而每一个 NALU 里面保存的是一片。对于每一片，到底是 I 帧，还是 P 帧，亦或是 B 帧，在片结构里面也有 Header，这里面有个类型用来标识帧的类型，然后是片的内容。</p><p>    这样，整个格式就出来了。<b>一个视频，可以拆分成一系列的帧，每一帧拆分成一系列的片，每一片都放在一个 NALU 里面，NALU 之间都是通过特殊的起始标识符分隔，在每一个 I 帧的第一片前面，要插入单独保存 SPS 和 PPS 的 NALU，最终形成一个长长的 NALU 序列</b>。</p><h3>推流：将数据流打包传输到对端</h3><p>    形成 NALU 序列后，还需要将这个二进制的流打包成网络包进行发送。这里我们以 RTMP 协议为例，进入第二个过程，<b>推流</b>。</p><p>    RTMP 是基于 TCP 的，因而也需要双方建立一个 TCP 连接。在有 TCP 的连接的基础上，还需要建立一个 RTMP 连接，也就是在程序里面，我们调用 RTMP 类库的 Connet 函数，显式创建一个连接。</p><p>    RTMP 为什么需要建立一个单独的连接呢？</p><p>    因为通信双方需要商量一些事情，保证后续的传输能正常进行。其实主要就是两个事情：</p><ol><li>确定版本号。如果客户端、服务端的版本号不一致，就不能正常工作；</li><li>确定时间戳。视频播放中，时间是很重要的一个元素，后面的数据流互通的时候，经常要带上时间戳的差值，因而一开始双方就要知道对方的时间戳。</li></ol><p>    沟通这些事情，需要发送 6 条消息：</p><ul><li>客户端发送 C0、C1、C2</li><li>服务端发送 S0、S1、S2</li></ul><p>    首先，客户端发送 C0 表示自己的版本号，不必等对方回复，然后发送 C1 表示自己的时间戳。</p><p>    服务器只有在收到 C0 的时候，才会返回 S0，表明自己的版本号，如果版本不匹配，可以断开连接。</p><p>    服务器发送完 S0 后，也不用等待，就直接发送自己的时间戳 S1。</p><p>    客户端收到 S1 时，发一个知道了最烦时间戳的 ACK C2。同理，服务器收到 C1 的时候，发一个知道了对方时间戳的 ACK S2。</p><p>    于是，握手完成。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-8c52130ebe3f491fe76ec5765c714c54_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-8c52130ebe3f491fe76ec5765c714c54_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    握手之后，双方需要互相传递一些控制信息，例如 Chunk 块的大小、窗口大小等。</p><p>    真正传输数据的时候，还是需要创建一个流 Stream，然后通过这个 Stream 来推流。</p><p>    推流的过程，就是讲 NALU 放在 Message 里面发送，这个也称为 <b>RTMP Packet 包</b>。其中，Message 的格式就像下图所示：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c20a3b6d2db2ccade6719178cc27843a_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-c20a3b6d2db2ccade6719178cc27843a_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    发送的时候，去掉 NALU 的起始标识符。因为这部分对于 RTMP 协议来讲没有用。接下来，将 SPS 和 PPS 参数集封装成一个 RTMP 包发送，然后发送一个个片的 NALU。</p><p>    RTMP 在收发数据的时候并不是以 Message 为单位的，而是把 Message 拆分成 Chunk 发送，而且必须在一个 Chunk 发送完成之后，才能开始发送下一个 Chunk。每个 Chunk 中都带有 Message ID，表示属于哪个 Message，接收端也会按照这个 ID 将 Chunk 组装成 Message。</p><p>    前面连接的时候，设置 Chunk 块大小就是指这个 Chunk。将大的消息变为小的块再发送，可以在低带宽的情况下，减少网络拥塞。</p><p>    下面用一个分块的示例，来了解下 RTMP 是如何分块的。</p><p>    假设一个视频的消息长度是 307，而 Chunk 大小约定为 128，那么消息就会被拆分为 3 个 Chunk。</p><p>    第一个 Chunk 的 Type = 0，表示 Chunk 头是完整的。头里面 Timestamp 为 1000，总长度 Length 为 307，类型为 9，是个视频，Stream ID 为 12346，正文部分承担 128 个字节的 Data。</p><p>    第二个 Chunk 也要发送 128 个字节，但是由于 Chunk 头和第一个一样，因此它的 Chunk Type = 3，表示头和第一个 Chunk 一样。</p><p>    第三个 Chunk 要发送的 Data 的长度为 51 个字节，Chunk Type 还是用的 3。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d76876ea76c02ab3dcfbbda7e3136441_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-d76876ea76c02ab3dcfbbda7e3136441_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    就这样，数据源源不断的到达流媒体服务器，整个过程就像下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-7f2d36eb96fb709e696d5d52e15b8642_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-7f2d36eb96fb709e696d5d52e15b8642_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    这个时候，大量观看直播的观众就可以通过 RTMP 协议从流媒体服务器上拉取。为了减轻服务器压力，我们会使用<b>分发网络</b>。</p><p>    分发网络分为<b>中心</b>和<b>边缘</b>两层。边缘层服务器部署在全国各地及横跨各大运营商里，和用户距离很近。而中心层是流媒体服务集群，负责内容的转发。</p><p>    智能负载均衡系统，根据用户的地理位置信息，就近选择边缘服务器，为用户提供推/拉流服务。中心层也负责转码服务。例如，将 RTMP 协议的码流转换成 HLS 码流。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-bad4c59b81593f569db680c36bf96d1b_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-bad4c59b81593f569db680c36bf96d1b_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>拉流：观众的客户端看到直播视频</h3><p>    接下来，我们再来看看观众通过 RTMP 拉流的过程。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a3fde75f6a7d36521de6b740c34713d6_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-a3fde75f6a7d36521de6b740c34713d6_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    先读到的是 H.264 的解码参数，例如 SPS 和 PPS，然后对收到的 NALU 组成一个个帧，进行解码，交给播放器播放，这样客户端就能看到直播视频了。</p><h3>小结</h3><ul><li>视频名词比较多，编码两大流派达成了一致，都是通过时间、空间的各种算法来压缩数据；</li><li>压缩好的数据，为了传输而组成一系列的 NALU，按照帧和片依次排列；</li><li>排列好的 NALU，在网络传输的是，要按照 RTMP 包的格式进行包装，RTMP 的包会拆分成 Chunk 进行传输；</li><li>推送到流媒体集群的视频流经过转码和分发，可以被客户端通过 RTMP 协议拉取，然后组合成 NALU，解码成视频格式进行播放。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "直播", 
                    "tagLink": "https://api.zhihu.com/topics/19616004"
                }, 
                {
                    "tag": "流媒体", 
                    "tagLink": "https://api.zhihu.com/topics/19584637"
                }, 
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82741128", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 0, 
            "title": "网络协议 13 - HTTPS 协议", 
            "content": "<p>之前说了 HTTP 协议的各种问题，但是它还是陪伴着互联网、陪伴着我们走过了将近二十年的风风雨雨。现在有很多新的协议尝试去取代它，来解决性能、效率等问题，但它还还能靠着“多年的情分”活的滋润。然而，近些年，因为致命的安全问题，它不得不升级成 HTTPS 了。</p><p>    就拿我们叫外卖来说，我们点外卖的数据包被黑客截获，然后在服务器回复你之前给你回复一个假消息：“好啊，你该付款了，把银行卡号、密码拿来。”，这时如果你真的把卡号和密码发给他，那你的钱包就真的危险了。</p><p>    为了解决这些问题，我们给 HTTP 引入了加密，变成了 HTTPS。大家千万不要以为 HTTPS 是个新的协议，它实际上就是：</p><blockquote> HTTPS = HTTP + SSL 层<br/> </blockquote><p>    这里的 SSL 层的主要工作就是加密。加密方式一般分为两种：<b>对称加密</b>和<b>非对称加密</b>。</p><p>    这两种加密算法，对称加密要比非对称加密的效率要高很多，性能也好很多，所以交互的场景下多用对称加密。</p><h3>对称加密</h3><p>    在对称加密算法中，<b>加密和解密的密钥是相同的</b>。也就是说，加密和解密使用的是同一个密钥。因此，使用者一定要做好保密功能，不能让第三方知道。</p><p>    假设叫外卖的你和第三方约定了一个密钥 A，你发送请求的时候用 A 进行加密，外卖网站也用 A 进行解密，这样就算黑客截获了你们的请求，但是没有正确的密钥，还是破解不了。</p><p>    看起来很好的解决了黑客的问题。但是这里又引入了一个问题，你和外卖网站怎么来约定这个密钥呢？如果这个密钥在互联网上传输，就必须还得用 B 密钥来加密，否则被黑客获取到 A，你们的交互还是不安全，而且，你们又怎么约定 B 呢？所以，只能通过<b>线下传输</b>。</p><p>    线下传输的话，看过《肖申克的救赎》的博友应该知道，安迪越狱前给瑞德约定了一个地点，让他去那里拿一个信封，里面写着他的住处。</p><p>    那我们和外卖网站也可以用这样的骚操作，偷偷约定时间地点，它给你一个纸条，上面写着你们两个的密钥，然后就用这个密钥在互联网定外卖。</p><p>    打住打住，上面这个操作想想都不可思议，如果最初的互联网是这样发展的话，那相信肯定活不久。</p><p>    相信你也发现了，只有对称加密，就会陷入密钥安全问题的死循环里，这时候，就需要非对称加密了。</p><h3>非对称加密</h3><p>    在非对称加密中 ，加密和解密过程中使用两个不相同的密钥。一个是公开的公钥，另一个是谁都不给的私钥。<b>公钥加密的信息，只有私钥才能解密，而私钥加密的信息，也只有公钥才能解密</b>。</p><p>    放到外面上面的叫外卖过程中，非对称加密的私钥由外卖网站保存，不会再网上传输，这样就保证了私钥的私密性。与之对应的公钥是可以在互联网上随意传播的，只要外卖网站把这个公钥给你，你们就可以安全的互通了。</p><p>    还是来看我们点外卖的过程。我们用公钥加密，说“我要豆浆加油条”。黑客在中间截获了这个数据包，但是他没有私钥，没法解密数据，因此可以顺利到达外卖网站。而外卖网站用私钥把这个报文解出来，然后回复，“我知道了，你付款吧，给我卡号和密码”。</p><p>    整个过程好像很安全，再也不怕黑客了。但是，先别太乐观，你的银行卡是安全了，但是外卖网站可还是有危险的。黑客有外卖网站的公钥，可以模拟发送“我要定外卖”这个信息。</p><p>    为了解决这个问题，看来一对公钥私钥是不够的，客户端也需要有自己的公钥和私钥，并且客户端也要把自己的公钥给外卖网站。</p><p>    这样，客户端给外卖网站发送信息的时候，用外卖网站的公钥加密，而外卖网站给客户端发送消息的时候，使用客户端的公钥。这样就算有黑客企图模拟客户端获取一些信息，或者半路截获回复信息，但是由于它没有私钥，这些信息它还是打不开。</p><p>    说了那么多，相信你也发现了，非对称加密也会有同样的问题，如何将不对称加密的公钥给对方？这时有两种可行方式，一种是放在一个公网的地址上，让对方下载，另一种就是在建立连接的时候传给对方。</p><p>    这两种方法也有相同的问题。作为普通网民，你怎么鉴别别人给你的公钥是对方的，而不是被黑客冒充的？要知道，<b>每个人都是可以创建自己的公钥和私钥的</b>，创建过程如下：</p><div class=\"highlight\"><pre><code class=\"language-text\"># bash\n// 创建私钥：\nopenssl genrsa -out httpsprivate.key 1024\n\n// 根据私钥获取公钥\nopenssl rsa -in httpsprivate.key -pubout -out httpspublic.pem</code></pre></div><h3>HTTPS 证书</h3><p>    可以看到，通过工具，我们可以很容易的创建公钥和私钥，那么黑客也是可以创建的，咱们怎么知道外卖网站传过来的公钥是不是真的就是外卖网站的呢？这时候，就需要第三方机构来当这个中间人了。</p><p>    这就像我们的户口本一样，每个人都可以打印出来，说是真的户口本，但是去使用的时候，人家就只认<b>有公安局盖章的户口本</b>。这个由权威部门颁发的称为**证书（Certificate）。</p><p>    HTTPS 证书里面应该有以下内容：</p><ul><li>公钥：这是最重要的；</li><li>所有者：说明证书是属于谁的，就像户口本上的姓名和身份证号，来证明这个户口本是你的；</li><li>证书发布机构：看看你的户口本上有没有某某公安局的字样？</li><li>证书有效时间：这个和咱们身份证有效期是一个意思。</li></ul><p>    说完了证书的内容，就到了下一步，怎么获取证书？这就像家里添了个小公举，去哪里上户口呢？恐怕大家都知道去公安局。与之对应的，HTTPS 也有专门负责派发证书的机构，这个机构我们称为 <b>CA（Certificate Authrity）</b>。而证书则可以通过下面这个命令生成：</p><blockquote> openssl req -key httpsprivate.key -new -out httpscertificate.req<br/> </blockquote><p>    将这个请求发给 CA，CA 会给这个证书“盖”一个章，我们称为<b>签名算法</b>。这个签名用到 CA 的私钥进行签发，来保证签名不被伪造。</p><p>    签名算法大概是这样工作的：一般是对信息做一个 Hash 计算，得到一个 Hash 值，这个过程是不可逆的，也就是说无法通过 Hash 值还原回原来的信息内容。再把信息发出时，把上面得到的 Hash 加密后，作为一个签名和信息一起发出去。CA 给整数签名的命令是：</p><blockquote> openssl x509 -req -in httpscertificate.req -CA cacertificate-pem -CAkey caprivate.key<br/> </blockquote><p>    这个命令会返回 Signature ok，而 httpscertificate.pem 就是签名过的整数。CA 用自己的私钥给外卖网站的公钥签名，这就相当于给外卖网站背书，形成了外卖网站的证书。我们可以通过下面这个命令查看证书内容：</p><blockquote> openssl x509 -in httpscertificate.pem -noout -text<br/> </blockquote><p>    证书会显示以下内容：</p><ul><li>lssuer：证书颁发者；</li><li>Subject：证书颁发给谁；</li><li>Validity：证书期限；</li><li>Public-key：公钥内容；</li><li>Sinature Algorithm：签名算法</li></ul><p>    通过这种方式，我们访问外卖网站时，得到的不再是一个公钥，而是一个整数。这个证书里有发布机构 CA，你只要通过这个 CA 的公钥去解密外卖网站证书的签名，解密成功，Hash 对的上，就说明外卖网站的公钥是真实可信的。</p><p>    上述整个过程中，都有一个前提，CA 是可信的。但是，我们又怎么确定 CA 的公钥就是对的呢？这就像有的人在偏远农村搞了个假公安局一样（应该没人这么干吧），我们怎么知道公安局是不是假的呢？然后我们就会想到，我去县公安局确认下当地公安局的信息不就好了。没错，CA 也是这么干的。</p><p>    CA 的公钥也需要更牛的 CA 给它签名，然后形成 CA 的公钥。要想知道某个 CA 的证书是否可靠，要看 CA 的上级证书的公钥能不能解开这个 CA 的签名。这样追根溯源，直到全球皆知的几大著名 CA，我们称为<b>Root CA</b>，做最后的背书。正是通过这种<b>层层授信背书</b>的形式，保证了非对称加密模式的争吵运转。</p><p>    除此之外，还有一种证书， 称为<b>Self-Signed Certificate</b>，就是自己给自己签名。这个就给人一种“我就是我，不一样的烟火，你爱信不信”的感觉，有兴趣的博友可以自行搜索了解。</p><h3>HTTPS 的工作模式</h3><p>    上面说了对称加密和非对称加密的原理，我们知道了非对称加密在性能上远不如对称加密，那在 HTTP 中，能否将两者结合起来呢？例如，公钥私钥主要用于<b>传输对称加密的密钥</b>，而真正的双方<b>大数据量的通信都是通过对称加密进行</b>。</p><p>    是的，HTTPS 协议的思路就是这样的。如下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-df911263d5a4a50762cb9ba5a76f60dd_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-df911263d5a4a50762cb9ba5a76f60dd_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    图比较长，整个过程最后的目标是<b>生成在后续通信过程中使用的对称密钥，以及约定使用的加密算法</b>。整体过程如下：</p><ol><li>客户端明文发送 TLS 版本信息、加密套件候选列表、压缩算法候选列表等信息，另外还会发送一个随机数，在协商对称密钥的时候使用（你好，我想定外卖，但你要保密我点了什么。这是我的加密套路列表，还有一个随机数 A，你留着）；</li><li>服务器返回 Server Hello 消息，告诉客户端，服务器选择使用的协议版本、加密套件、压缩算法等，还有一个随机数 B，用于后续进行密钥协商（你好，保密没问题，就按套路 2 来吧，我也给你一个随机数 B，你留着）；</li><li>服务器给客户端证书；</li><li>客户端从自己信任的 CA 仓库中，拿 CA 的证书里面的公钥去解密服务器传来的证书。解密成功，说明外卖网站是可信的。这个解密过程，客户端可能胡不断往上追溯 CA、CA 的 CA、CA 的 CA 的 CA，直到一个授信的 CA 为止；</li><li>证书验证可信后，客户端会计算产生随机数字 Pre-master，发送Client Key Exchange，用证书中的公钥加密，再发给服务器；</li></ol><p>    到此时，无论是客户端还是服务端，都有了三个随机数，分别是：A、B、Pre-master。通过这三个随机数，客户端和服务端可以产生相同的对称密钥。</p><p>    约定好对称密钥和加密算法，就可以用对称加密的形式进行加密通信了，后续的通信除了多了一步密钥校验的过程，HTTP 协议里的那些过程都不会少。</p><p>    不过上面的过程中只包含了 HTTPS 的单向认证，也就是客户端验证服务端的证书，这也是最常见的场景。不过在更加严格要求通信安全的情况下，也可以启用双向认证，双方互相验证证书。</p><p>    通过上面的整个过程，我们可以看出，HTTPS 协议并不是一个新的协议，它只是 HTTP 协议与一些加密算法的组合，用来保证通信的安全。</p><p>    虽然上面介绍的非对称加密方式，在现在看来是完美不可解的，但未来谁知道呢？正所谓“道高一尺魔高一丈”，加密安全路上永无尽头。</p><h3>小结</h3><ul><li>加密分<b>对称加密</b>和<b>非对称加密</b>。对称加密效率高，但存在密钥传输的问题；非对称加密可以解决密钥传输的问题，但效率较低。</li><li>非对称加密需要通过<b>证书</b>和<b>权威机构</b>来验证公钥的合法性。</li><li>HTTPS 是综合了对称加密和非对称加密算法的 HTTP 协议。既保证了传输安全，也保证了传输效率。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "协议", 
                    "tagLink": "https://api.zhihu.com/topics/19563217"
                }, 
                {
                    "tag": "HTTPS", 
                    "tagLink": "https://api.zhihu.com/topics/19568367"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82307227", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 0, 
            "title": "网络协议 12 - HTTP 协议", 
            "content": "<p>日常开发中，我们经常会碰到查询网络是否畅通以及域名对应 IP 地址等小需求，这时候用的最多的应该就是 ping 命令了。 那你知道 ping 命令是怎么工作的吗？今天，我们就来一起认识下 ping 命令及其对应的 ICMP 协议。</p><h3>ICMP 协议</h3><p>    ICMP 全称 Internet Control Message Protocol，指<b>互联网控制报文协议</b>。</p><p>    网络本身是不可靠的，数据包在传输过程中，可能会发生很多突发事件并导致数据传输失败。而网络层的 IP 协议是一个无连接的协议，它不会处理网络层的故障，因此，我们需要其它的协议，在数据包传输出现故障时，能将故障信息传回来，这样才能对应处理相关问题。</p><p>    就像在电视剧里看到的古代战争一样，打仗的时候需要通过斥候来传递战局情况，进而更好的控制战局。而 ICMP 报文在网络世界中就充当“斥候”这样的角色。</p><p>    ICMP 报文是封装在 IP 包里面的。因为传输指令的时候，肯定需要源地址和目标地址。它本身格式非常简单，如下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9af6b295657c6ac8e8e15c78db39369c_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-9af6b295657c6ac8e8e15c78db39369c_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    ICMP 报文有很多的类型，不同的类型有不同的代码，<b>最常用的类型是主动请求，代码为 8，主动请求的应答，代码为 0</b>。从大的方面看可以分为 <b>查询报文类型</b>和<b>差错报文类型</b>。</p><h3>查询报文类型</h3><p>    我们经常在电视剧里听到这样的话：来人，前方战事如何？斥候回来没？一有情况，立刻通报。</p><p>    类似这种主帅发起，主动查看敌情的情况，就对应着 <b>ICMP的查询报文类型</b>。例如，常见的 ping 命令就是<b>查询报文，是一种主动请求，并且获得主动应答的 ICMP 协议</b>。因此，ping 命令发出的包也是符合 ICMP 协议格式的，只不过它在后面增加了自己的格式。</p><p>    对 ping 的主动请求，进行网络抓包，称为 <b>ICMP ECHO REQUEST</b>。同理，主动请求的回复，称为<b>ICMP ECHO REPLY</b>。比起原生的 ICMP，这里面多了两个字段，一个是标识符，另一个是序号。这不难理解，大帅派出去两队斥候，一队是找谁要的，一队是侦查战况的，要有个标识才能区分。</p><p>    另一方面，派出去的斥候，都要编个号。如果派出去 10 个，回来 10 个，就说明前方战况不错。如果派出去 10 个，回来 2 个，就说明情况可能不妙。</p><p>    在选项数据中，ping 还会存放发送请求的时间值，来计算往返时间，说明路程的长短。</p><h3>差错报文类型</h3><p>    差错报文主要是用来<b>将发送的出错报文相关信息返回到源设备，以供源设备确定如果更好的重发失败的数据包</b>。</p><p>    还是拿我们的“大帅”举例。</p><p>    当主帅正在大帐中看地图，思考战事时，外面的小兵突然喊到：大帅，不好啦，张将军遭遇埋伏，全军覆没了。</p><p>    这种是异常情况发起的，来报告发生了不好的事情，对应 ICMP 的差错报文。</p><p>    差错报文有以下常用的类型：</p><ul><li>3：终点不可达</li><li>4：源抑制</li><li>5：重定向</li><li>11：超时</li></ul><p><b>第一种情况终点不可达</b>。小兵报告，大帅，送给张将军的粮草没有送到。</p><p>    那大帅肯定会问，为啥没有送到？这就对应 ICMP 中的以下代码了。</p><ul><li>网络不可达代码：0</li><li>主机不可达代码：1</li><li>协议不可达：2</li><li>端口不可达：3</li><li>需要进行分片但设置了不分片：4</li></ul><p>    具体的场景就像这样：</p><ul><li>网络不可达：大帅，找不到地方</li><li>主机不可达：大帅，找到地方，没找到张将军</li><li>协议不可达：大帅，找到地方，也找到人了，但是口令没对上。</li><li>端口不可达：大帅，找到地方，找到了人，也对上了口令，但事情没对上。我去送粮草，人家说在等救兵。</li><li>需要进行分片但设置不分片：大帅，走到一半，山路狭窄，想换瞎扯，但是出发前你下令严禁换小车，就没办法送到了。</li></ul><p><b>第二种是源站抑制</b>。也就是让源站放慢发送速度（小兵：大帅，粮草送的太多了吃不完，你可以慢点送）。</p><p><b>第三种是时间超时</b>。也就是超过网络包的生存时间还是没到目的地（大帅，送粮草的人都把粮食吃完了，还没到地方，已经饿死了）。</p><p><b>第四种是路由重定向</b>。也就是下次发给另一个路由器（大帅，上次送粮草的人本来只要走大王村，一公里就到了，结果非要绕道张家界，多了五公里，下次记得走大王村）。</p><p>    差错报文的结构相对复杂一些。除了前面还是 IP，ICMP 的前 8 个字节不变，后面则跟上出错的那个 IP 包的 IP 头和 IP 正文的前 8 个字节。</p><p>    而且这类斥候特别尽责，不但字节返回来报信，还把一部分遗物带回来。</p><ul><li>斥候：大帅，张将军已经战死沙场，这是他的印信和佩剑。</li><li>大帅：张将军是怎么死的（可以查看 ICMP 的前 8 字节）？没错，这是张将军的剑（IP 数据包的头及正文前 8 字节）。</li></ul><h3>ping：查询报文类型的使用</h3><p>    接下来，我们重点来看 ping 命令的发送和接收过程。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4093a6ce0b7bd6f1887fc8aa99e1cf0e_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-4093a6ce0b7bd6f1887fc8aa99e1cf0e_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    假定主机 A 的 IP 地址是 192.168.1.1，主机 B 的 IP 地址是 192.168.1.2，它们都在同一个子网。那么，当在主机 A 上运行“ping 192.168.1.2” 后，会发生什么呢？</p><ol><li><b>源主机构建 ICMP 请求数据包</b>。这个数据包内包含多个字段。最重要的有两个，一个是<b>类型字段</b>，对应请求数据包而言，该字段为 8。另一个是<b>顺序号</b>，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加 1.为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。</li><li><b>IP 层构建 IP 数据包</b>。ICMP 协议将数据包连同目标 IP 一起交给 IP 层，IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，加上其他控制信息，构建一个 IP 数据包。</li><li><b>加入 MAC 头</b>。找到 192.168.1.2 对应的 MAC 地址，附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。</li></ol><p>    主机 B 收到数据帧后，会进行如下步骤：</p><ol><li><b>检查 MAC 地址，丢弃或接收数据帧，提取 IP 数据包</b>。检查数据包目的 MAC 地址，并与本机 MAC 地址对比。如符合，就接收数据帧，否则就丢弃。接收后检查数据帧，将 IP 数据包从帧中提取处理，交给本机的 IP 层。</li><li><b>IP 层检查IP</b>。检查完成后，提取有用的信息交给 ICMP 协议。</li><li><b>构建 ICMP 应答包</b>。应答数据包的类型字段为 0，顺序号为接收到的请求数据包中的顺序号。</li><li>将应答数据包发给主机 A。</li></ol><p>    在规定的时间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达。</p><p>    如果接收到了应打包，则说明目标主机可达。此时，源主机会检测时间延迟。就是用当前时刻减该数据包从源主机发出去的时刻。</p><p>    当然，这只是最简单的，同个局域网的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等。</p><p>    可以看出，ping 命令是使用了 ICMP 里面的 ECHO REQUEST 和 ECHO REPLY 类型。</p><p>    那其它类型呢？是不是只有真正遇到错误的时候，才能收到？答案是否定的。有一个 Traceroute 命令，它会使用 ICMP 的规则，故意制造一些能够产生错误的场景。</p><h3>Traceroute：差错报文类型的使用</h3><p>    Traceroute 命令有两个比较常用的功能。</p><p>    第一个功能：</p><p><b>通过设置特殊的 TTL，追踪去往目的地时经过的路由器</b></p><p>    Traceroute 的参数执行某个目的 IP 地址，会发送一个 UDP 的数据包。</p><p>    将 TTL 设置成 1 时，表示这个数据包的 MP 为 1，碰到第一个“拦路虎”（通常是路由器或一个其它类型的关卡）就会阵亡了，然后就会返回一个 ICMP 包，这个包就是 <b>网络差错包</b>，类型是<b>时间超时</b>。</p><p>    通过差错包，我们就能得到数据包到第一个关卡时花费的时间及其每个关卡的 IP 地址（有的主机不会响应 ICMP，所以会出现请求时全是 * 的情况）。</p><p>    那怎么知道 UDP 有没有到达目的主机呢？Traceroute 程序会发送一份 UDP 数据包给目的主机，但它会选择一个不可能的值作为 UDP 端口号（大于30000）。当该数据报到达目的主机时，由于找不到对应端口号，所以会返回一个“端口不可达”的错误报文。这样，我们就知道 UDP 是否到达主机了。</p><p>    第二个功能：</p><p><b>设置数据包不分片，确定路径的 MTU</b></p><p>    发送分组，并设置“不分片”标志。发送的第一个分组的长度正好与出口的 MTU 相等。如果中间遇到窄的关卡就会被卡主，返回 ICMP 网络差错包，类型是“需要进行分片但设置了不分片”。就这样，每次收到ICMP“不能分片”差错时就减小分组的长度，从而确定整个路径中的 MTU。</p><h3>总结</h3><ul><li>ICMP 相当于网络世界的侦察兵。常用的有两种类型，主动探查的查询报文和异常报告的差错报文。</li><li>ping 命令使用查询报文，Traceroute 命令使用差错报文。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p><br/> </p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82185799", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 0, 
            "title": "网络协议 11 - Socket 编程（下）", 
            "content": "<p>之前我们基本了解了网络通信里的大部分协议，一直都是在“听”的过程。很多人都会觉得，好像看懂了，但关了页面回忆起来，好像又什么都没懂。这次咱们就“真枪实弹”的码起来，再用一个“神器”-网络分析系统详细跟踪下数据包的生命历程，让我们的理论真实的呈现出来，对网络通信感兴趣的博友，还可以自己拿着系统分析一遍，你一定会大有所获。</p><p>    不多说，直接上代码。有兴趣的博友可以按各编程语言进行相关改写，然后拿着我们的分析系统真实的看看网络通信过程。</p><h3>本机请求转发到网关</h3><p>    代码中的 192.168.1.10 是内网另一台服务器，楼主的 IP 是 192.168.1.73。在本机跑服务器的时候，要做一个路由配置，否则分析系统无法抓取相关的包。window 下可按下面步骤配置：</p><ol><li>管理员身份打开 DOS 窗口；</li><li>route add 本机ip mask 255.255.255.255 网关ip（路由转发，还记得吗？忘记了？<a href=\"https://link.zhihu.com/?target=https%3A//www.cnblogs.com/BeiGuo-FengGuang/p/9990693.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">点我点我点我</a>）；</li></ol><p>    什么？不知道怎么查 IP 和网关？<a href=\"https://link.zhihu.com/?target=https%3A//www.cnblogs.com/BeiGuo-FengGuang/p/9877801.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">点我告诉你</a><br/>    操作完成后记得<b>删除转发规则</b>，否则，你会发现本机的请求，速度会变得很慢、、、<br/>    实例：</p><div class=\"highlight\"><pre><code class=\"language-text\">// 添加路由转发规则\nroute add 192.168.1.73 mask 255.255.255.255 192.168.1.1 \n\n// 删除转发规则\nroute delete 192.168.1.73</code></pre></div><h3>基于 TCP 的 Socket</h3><p>    服务端：</p><div class=\"highlight\"><pre><code class=\"language-text\">&lt;?php\n/**\n * 1. socket_create: 新建 socket\n * 2. socket_bind:   绑定 IP 和 port\n * 3. socket_listen: 监听\n * 4. socket_accept: 接收客户端连接，返回连接 socket\n * 5. socket_read:   读取客户端发送数据\n * 6. socket_write:  返回数据\n * 7. socket_close:  关闭 socket\n */\n\n$ip = &#39;192.168.1.10&#39;;\n$port = 23333;\n// $port = 80;\n$sk = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);\n!$sk &amp;&amp; outInfo(&#39;socket_create error&#39;);\n\n// 绑定 IP\n!socket_bind($sk, $ip, $port) &amp;&amp; outInfo(&#39;socket_bind error&#39;);\n\n// 监听\n!socket_listen($sk) &amp;&amp; outInfo(&#39;sever listen error&#39;);\n\noutInfo(&#34;Success Listen: $ip:$port&#34;, &#39;INFO&#39;);\nwhile (true) {\n    $accept_res = socket_accept($sk);\n    !$accept_res &amp;&amp; outInfo(&#39;sever accept error&#39;);\n    $reqStr = socket_read($accept_res, 1024);\n\n    if (!$reqStr) outInfo(&#39;sever read error&#39;);\n    outInfo(&#34;Server receive client msg: $reqStr&#34;, &#39;INFO&#39;);\n    $response = &#39;Hello A, I am B. you msg is : &#39; . $reqStr . PHP_EOL;\n    if (socket_write($accept_res, $response, strlen($response)) === false) {\n        outInfo(&#39;response error&#39;);\n    }\n\n    socket_close($accept_res);\n}\n\nsocket_close($sk);\n\nfunction outInfo($errMsg, $level = &#39;ERROR&#39;)\n{\n    if ($level === &#39;ERROR&#39;) {\n        $errMsg = &#34;$errMsg, msg: &#34; . socket_strerror(socket_last_error());\n    }\n    echo $errMsg . PHP_EOL;\n    $level === &#39;ERROR&#39; &amp;&amp; die;\n}</code></pre></div><p>    客户端：</p><div class=\"highlight\"><pre><code class=\"language-text\">&lt;?php\n/**\n * 1. socket_create:  新建 socket\n * 2. socket_connect: 连接服务端\n * 3. socket_write:   给服务端发数据\n * 4. socket_read:    读取服务端返回的数据\n * 5. socket_close:   关闭 socket\n */\n\n$ip = &#39;192.168.1.10&#39;;\n$port = 23333;\n$sk = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);\n!$sk &amp;&amp; outInfo(&#39;socket_create error&#39;);\n\n!socket_connect($sk, $ip, $port) &amp;&amp; outInfo(&#39;connect fail&#39;);\n$msg = &#39;hello, I am A&#39;;\n\nif (socket_write($sk, $msg, strlen($msg)) === false) {\n    outInfo(&#39;socket_write fail&#39;);\n}\n\nwhile ($res = socket_read($sk, 1024)) {\n    echo &#39;server return message is:&#39;. PHP_EOL. $res;\n}\n\nsocket_close($sk);//工作完毕，关闭套接流\n\nfunction outInfo($errMsg, $level = &#39;ERROR&#39;)\n{\n    if ($level === &#39;ERROR&#39;) {\n        $errMsg = &#34;$errMsg, msg: &#34; . socket_strerror(socket_last_error());\n    }\n    echo $errMsg . PHP_EOL;\n    $level === &#39;ERROR&#39; &amp;&amp; die;\n}</code></pre></div><p>    上面的代码是基于 PHP 原生 Socket 写的，其它语言也有对应 Socket 操作函数，进行相关的改写即可。主要是下面的分析过程。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f2b8db8755f59fb718a39157b6fa20ce_b.png\" data-size=\"normal\" data-caption=\"\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-caption=\"\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-f2b8db8755f59fb718a39157b6fa20ce_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    如上图，这是我们的分析系统捕捉的所有数据传输过程，你可以真实的看到每一步都发生了什么，以及对应的状态的改变（图片较大，建议右键在新标签页打开看）。</p><p>    在图中上半部分，我们可以看到分析系统将整个 TCP 的生命历程分为了三个阶段：建立连接、交易、关闭连接。这和我们之前了解的理论知识完全相符。<br/>    左下角的交易时序图，则详细记录了客户端和服务端每次通信的详细信息，而右下角部分，则展示了每次通信，数据包的状态等信息。</p><h3>基于 UDP 的Socket</h3><div class=\"highlight\"><pre><code class=\"language-text\">&lt;?php\n/**\n * 1. socket_create:   新建 socket\n * 2. socket_bind:     绑定 IP 和 port\n * 3. socket_recvfrom: 读取客户端发送数据\n * 4. socket_sendto:   返回数据\n * 5. socket_close:    关闭 socket\n */\n\n$ip = &#39;192.168.1.10&#39;;\n$port = 23333;\n$sk = socket_create(AF_INET, SOCK_DGRAM, SOL_UDP);\n!$sk &amp;&amp; outInfo(&#39;socket_create error&#39;);\n\n// 绑定 IP\n!socket_bind($sk, $ip, $port) &amp;&amp; outInfo(&#39;socket_bind error&#39;);\n\noutInfo(&#34;Success Listen: $ip:$port&#34;, &#39;INFO&#39;);\nwhile (true) {\n    $from = &#39;&#39;;\n    $reqPort = 0;\n    if (!socket_recvfrom($sk, $buf, 1024, 0, $from, $reqPort)) {\n        outInfo(&#39;sever socket_recvfrom error&#39;);\n    }\n\n    outInfo(&#34;Received msg $buf from remote address $from:$port&#34;, &#39;INFO&#39;);\n    $response = &#34;Hello $from:$port, I am Server. your msg : &#34; . $buf . PHP_EOL;\n    if (!socket_sendto($sk, $response, strlen($response), 0, $from, $reqPort)) {\n        outInfo(&#39;socket_sendto error&#39;);\n    }\n}\n\nsocket_close($sk);\n\nfunction outInfo($errMsg, $level = &#39;ERROR&#39;)\n{\n    if ($level === &#39;ERROR&#39;) {\n        $errMsg = &#34;$errMsg, msg: &#34; . socket_strerror(socket_last_error());\n    }\n    echo $errMsg . PHP_EOL;\n    $level === &#39;ERROR&#39; &amp;&amp; die;\n}</code></pre></div><p>客户端：</p><div class=\"highlight\"><pre><code class=\"language-text\">&lt;?php\n/**\n * 1. socket_create:  新建 socket\n * 2. socket_write:   给服务端发数据\n * 3. socket_read:    读取服务端返回的数据\n * 4. socket_close:   关闭 socket\n */\n\n$ip = &#39;192.168.1.10&#39;;\n$port = 23333;\n$sk = socket_create(AF_INET, SOCK_DGRAM, SOL_UDP);\n!$sk &amp;&amp; outInfo(&#39;socket_create error&#39;);\n\n$msg = &#39;hello, I am A&#39;;\n\nif (!socket_sendto($sk, $msg, strlen($msg), 0, $ip, $port)) {\n    outInfo(&#39;socket_sendto fail&#39;);\n}\n\n$from = &#39;&#39;;\n$reqPort = 0;\nif (!socket_recvfrom($sk, $buf, 1024, 0, $from, $reqPort)) {\n    outInfo(&#39;server socket_recvfrom error&#39;);\n}\n\noutInfo(&#34;Received $buf from server address $from:$port&#34;, &#39;INFO&#39;);\n\nsocket_close($sk);\n\nfunction outInfo($errMsg, $level = &#39;ERROR&#39;)\n{\n    if ($level === &#39;ERROR&#39;) {\n        $errMsg = &#34;$errMsg, msg: &#34; . socket_strerror(socket_last_error());\n    }\n    echo $errMsg . PHP_EOL;\n    $level === &#39;ERROR&#39; &amp;&amp; die;\n}</code></pre></div><p>UDP 数据包分析图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-f838347c7a24eb08ad88870f04afa306_b.png\" data-size=\"normal\" data-caption=\"\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-caption=\"\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-f838347c7a24eb08ad88870f04afa306_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    如上图，UDP 数据包分析图，明显比 TCP 要简单很多，人家单纯嘛，就不多说了。不过要注意的，写代码的时候，<b>UDP 的服务端，在循环里千万不要关闭 Socket</b>。</p><h3>分析系统介绍</h3><p>    上面用到的分析系统叫：科来网络分析系统，<a href=\"https://link.zhihu.com/?target=http%3A//www.colasoft.com.cn/download/capsa.php\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">点我下载</a>。这个分析系统很良心，提供了一个免费的技术交流版。有兴趣的小伙伴可以下载下来玩玩，很强大。</p><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-size=\"normal\" data-caption=\"\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-caption=\"\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82185665", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 1, 
            "title": "网络协议 10 - Socket 编程（上）", 
            "content": "<p>前面一直在说各种协议，偏理论方面的知识，这次咱们就来认识下基于 TCP 和 UDP 协议这些理论知识的 Socket 编程。</p><p>    说 TCP 和 UDP 的时候，我们是分成客户端和服务端来认识的，那在写 Socket 的时候，我们也这样分。</p><p>    Socket 这个名字很有意思，可以作插口或者插槽讲。我们写程序时，就可以将 Socket 想象为，一头插在客户端，一头插在服务端，然后进行通信。</p><p>    在建立 Socket 的时候，应该设置什么参数呢？Socket 编程进行的是端到端的通信，往往意识不到中间经过多少局域网，多少路由器，因而能够设置的参数，也只能是<b>端到端协议之上网络层和传输层的</b>。</p><p>    对于网络层和传输层，有以下参数需要设置：</p><ul><li>IP协议：IPv4 对应 AF_INEF，IPv6 对应 AF_INET6；</li><li>传输层协议：TCP 与 UDP。TCP 协议基于数据流，其对应值是 SOCKET_STREAM，而 UDP 是基于数据报的，其对应值是 SOCKET_DGRAM。</li></ul><p>    两端创建了 Socket 之后，而后面的过程中，TCP 和 UDP 稍有不同，我们先来看看 TCP。</p><h3>基于 TCP 协议的 Socket</h3><p>    对于 TCP 创建 Socket 的过程，有以下几步走：</p><p><b>1）TCP 调用 bind 函数赋予 Socket IP 地址和端口。</b></p><p>    为什么需要 IP 地址？还记得吗？咱们之前了解过，一台机器会有多个网卡，而每个网卡就有一个 IP 地址，我们可以选择监听所有的网卡，也可以选择监听一个网卡，只有，发给指定网卡的包才会发给你。</p><p>    为什么需要端口？要知道，咱们写的是一个应用程序，当一个网络包来的时候，内核就是要通过 TCP 里面的端口号来找到对应的应用程序，把包给你。</p><p><b>2）调用 listen 函数监听端口。</b> 在 TCP 的状态图了，有一个 listen 状态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。</p><p>    在内核中，为每个 Socket 维护两个队列。一个是已经建立了连接的队列，这里面的连接已经完成三次握手，处于 established 状态；另一个是还没有完全建立连接的队列，这里面的连接还没有完成三次握手，处于 syn_rcvd 状态。</p><p><b>3）服务端调用 accept 函数。</b> 这时候服务端会拿出一个已经完成的连接进行处理，如果还没有已经完成的连接，就要等着。</p><p>    在服务端等待的时候，客户端可以通过 connect 函数发起连接。客户端先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口，一旦握手成功，<b>服务端的 accep 就会返回另一个 Socket</b>。</p><p>    注意，从上面的过程中可以看出，<b>监听的 Socket 和真正用来传数据的 Socket 是不同的两个。</b> 一个叫做<b>监听 Socket</b>，一个叫做<b>已连接 Socket</b>。</p><p>    下图就是基于 TCP 协议的 Socket 函数调用过程：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d3fb54587551056615f4d17bd2afaf19_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-d3fb54587551056615f4d17bd2afaf19_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    连接建立成功之后，双方开始通过 read 和write 函数来读写数据，就像往一个文件流里写东西一样。</p><p>    这里说 TCP 的 Socket 是一个文件流，是非常准确的。因为 Socket 在 linux 中就是以文件的形式存在的。除此之外，还存在<b>文件描述符</b>。写入和读出，也是通过文件描述符。</p><p>    每一个进程都有一个数据结构 task_struct，里面指向一个<b>文件描述符数组</b>，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数索引值，是这个数组的下标。</p><p>    这个数组中的内容是一个指针，指向内核中所有打开的文件列表。而每个文件也会有一个 inode（索引节点）。</p><p>    对于 Socke 而言，它是一个文件，也就有对于的文件描述符。与真正的文件系统不一样的是，Socket 对于的 inode 并不是保存在硬盘上，而是在内存中。在这个 inode 中，指向了 Socket 在内核中的 Socket 结构。</p><p>    在这个机构里面，主要有两个队列。一个发送队列，一个接收队列。这两个队列里面，保存的是一个缓存 sk_buff。这个缓存里能够看到完整的包结构。说到这里，你应该就会发现，数据结构以及和前面了解的收发包的场景联系起来了。</p><p>    上面整个过程说起来稍显混乱，可对比下图加深理解。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5e4a32b7fec4d66c0607b77dbe0c4c1f_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-5e4a32b7fec4d66c0607b77dbe0c4c1f_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>基于 UDP 协议的 Socket</h3><p>    基于 UDP 的 Socket 编程过程和 TCP 有些不同。UDP 是没有连接状态的，所以不需要三次握手，也就不需要调用 listen 和 connect。没有连接状态，也就不需要维护连接状态，因而不需要对每个连接建立一组 Socket，只要建立一组 Socket，就能和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都可以调用 sendto 和 recvfrom 传入 IP 地址和端口。</p><p>    下图是基于 UDP 的 Socket 函数调用过程：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-66b9d3a462e655c03ea14f42d5e33e7a_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-66b9d3a462e655c03ea14f42d5e33e7a_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>服务器最大并发量</h3><p>    了解了基本的 Socket 函数后，就可以写出一个网络交互的程序了。就像上面的过程一样，在建立连接后，进行一个 while 循环，客户端发了收，服务端收了发。</p><p>    很明显，这种一台服务器服务一个客户的方式和我们的实际需要相差甚远。这就相当于老板成立了一个公司，只有自己一个人，自己亲自服务客户，只能干完一家再干下一家。这种方式肯定赚不了钱，这时候，就要想，我最多能接多少项目呢？</p><p>    我们可以先来算下理论最大值，也就是<b>理论最大连接数</b>。系统会用一个四元组来标识一个 TCP 连接：</p><blockquote> {本机 IP，本机端口，对端 IP，对端端口}<br/> </blockquote><p>    服务器通常固定监听某个本地端口，等待客户端连接请求。因此，上面四元组中，可变的项只有<b>对端 IP 和对端端口</b>，也就是<b>客户端 IP 和客户端端口</b>。不难得出：</p><blockquote> 最大 TCP 连接数 = 客户端 IP 数 x 客户端端口数。<br/> </blockquote><p>    对于 IPv4：</p><blockquote> 客户端最大 IP 数 = 2 的 32 次方<br/> </blockquote><p>    对于端口数：</p><blockquote> 客户端最大端口数 = 2 的 16 次方<br/> </blockquote><p>    因此：</p><blockquote> 最大 TCP 连接数 = 2 的 48 次方（估算值）<br/> </blockquote><p>    当然，服务端最大并发 TCP 连接数远不能达到理论最大值。主要有以下原因：</p><ol><li><b>文件描述符限制</b>。按照上面的原理，Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目；</li><li><b>内存限制</b>。按上面的数据结构，每个 TCP 连接都要占用一定的内存，而系统内存是有限的。</li></ol><p>    所以，作为老板，在资源有限的情况下，要想接更多的项目，赚更多的钱，就要<b>降低每个项目消耗的资源数目</b>。</p><p>    本着这个原则，我们可以找到以下几种方式来最可能的降低消耗项目消耗资源。</p><h3>1）将项目外包给其他公司（多进程方式）</h3><p>    这就相当于你是一个代理，监听来的请求，一旦建立一个连接，就会有一个已连接的 Socket，这时候你可以创建一个紫禁城，然后将基于已连接的 Socket 交互交给这个新的子进程来做。就像来了一个新项目，你可以注册一家子公司，招人，然后把项目转包给这就公司做，这样你就又可以去接新的项目了。</p><p>    这里有个问题是，如何创建子公司，并将项目移交给子公司？</p><p>    在 Linux 下，创建子进程使用 fork 函数。通过名字可以看出，这是在父进程的基础上完全拷贝一个子进程。在 Linux 内核中，<b>会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到了哪一行程序的进程。</b></p><p>    这样，复制完成后，父进程和子进程都会记录当前刚刚执行完 fork。这两个进程刚复制完的时候，几乎一模一样，只是根据 fork 的返回值来区分是父进程还是子进程。<b>如果返回值是 0，则是子进程，如果返回值是其他的整数，就是父进程</b>，这里返回的整数，就是<b>子进程的 ID</b>。</p><p>    进程复制过程如下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-17e7ff50aa8a0b504a822b6ff470ff88_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-17e7ff50aa8a0b504a822b6ff470ff88_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的。因此父进程刚才因为 accept 创建的已连接 Socket 也是一个文件描述符，同样也会被子进程获得。</p><p>    接下来，子进程就可以通过这个已连接 Socket 和客户端进行通信了。当通信完成后，就可以退出进程。那父进程如何知道子进程干完了项目要退出呢？父进程中 fork 函数返回的整数就是子进程的 ID，父进程可以通过这个 ID 查看子进程是否完成项目，是否需要退出。</p><h3>2）将项目转包给独立的项目组（多线程方式）</h3><p>    上面这种方式你应该能发现问题，如果每接一个项目，都申请一个新公司，然后干完了，就注销掉，实在是太麻烦了。而且新公司要有新公司的资产、办公家具，每次都买了再卖，不划算。</p><p>    这时候，我们应该已经想到了<b>线程</b>。相比于进程来讲，线程更加轻量级。如果创建进程相当于成立新公司，而创建线程，就相当于在同一个公司成立新的项目组。一个项目做完了，就解散项目组，成立新的项目组，办公家具还可以共用。</p><p>    在 Linux 下，通过 pthread_create 创建一个线程，也是调用 do_fork。不同的是，虽然新的线程在 task 列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，这些还是共享的，只不过多了一个引用而已。</p><p>    下图是线程复制过程：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-30edf53025e818bd247c088207b643f2_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-30edf53025e818bd247c088207b643f2_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    新的线程也可以通过已连接 Socket 处理请求，从而达到并发处理的目的。</p><p>    上面两种方式，无论是基于进程还是线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程。一台机器能创建的进程和线程数是有限的，并不能很好的发挥服务器的性能。著名的<b>C10K问题</b>，就是说一台机器如何维护 1 万了连接。按我们上面的方式，系统就要创建 1 万个进程或者线程，这是操作系统无法承受的。</p><p>    那既然一个线程负责一个 TCP 连接不行，能不能一个进程或线程负责多个 TCP 连接呢？这就引出了下面两种方式。</p><h3>3）一个项目组支撑多个项目（IO 多路复用，一个线程维护多个 Socket）</h3><p>    当一个项目组负责多个项目时，就要有个<b>项目进度墙</b>来把控每个项目的进度，除此之外，还得<b>有个人专门盯着进度墙</b>。</p><p>    上面说过，Socket 是文件描述符，因此某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中，这就是<b>项目进度墙</b>。然后调用 select 函数来监听文件描述符集合是否有变化，一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化。</p><h3>4）一个项目组支撑多个项目（IO 多路复用，从“派人盯着”到“有事通知”）</h3><p>    上面 select 函数还是有问题的，因为每次 Socket 所在的文件描述符集合中有发生变化的时候，都需要通过轮询的方式将所有的 Socket 查看一遍，这大大影响了一个进程或者线程能够支撑的最大连接数量。使用 select，能够同时监听的数量由 FD_SETSIZE 限制。</p><p>    如果改成事件通知的方式，情况就会好很多。项目组不需要通过轮询挨个盯着所有项目，而是当项目进度发生变化的时候，主动通知项目组，然后项目组再根据项目进展情况做相应的操作。</p><p>    而 epoll 函数就能完成事件通知。它在内核中的实现不是通过轮询的方式，而是通过注册 callback 函数的方式，当某个文件描述符发生变化的时候，主动通知。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-60202d7279bd8e8391a39c91ca31a9af_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-60202d7279bd8e8391a39c91ca31a9af_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    如上图所示，假设进程打开了 Socket m、n、x 等多个文件描述符，现在需要通过 epoll 来监听这些 Socket 是否有事件发生。其中 epoll_create 创建一个 epoll 对象，也是一个文件，对应一个文件描述符，同样也对应着打开文件列表中的一项。在这项里面有一个红黑树，在红黑树里，要保存这个 epoll 监听的所有的 Socket。</p><p>    当 epoll_ctl 添加一个 Scoket 的时候，其实就是加入这个红黑树中。同时，红黑树里面的节点指向一个结构，将这个结构挂在被监听的 Socket 的事件列表中。当一个 Socket 发生某个事件时，可以从这个列表中得到 epoll 对象，并调用 call_back 通知它。</p><p>    这种事件通知的方式使得监听的 Socket 数量增加的同时，效率也不会大幅度降低。因此，能够同时监听的 Socket 的数量就非常的多了。上限为系统定义的，进程打开的最大文件描述符个数。因而，<b>epoll 被称为解决 C10K 问题的利器</b>。</p><h3>小结</h3><ul><li>牢记基于 TCP 和 UDP 的 Socket 编程中，客户端和服务端需要调用的函数；</li><li>epoll 机制能够解决 C10K 问题。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82185529", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 3, 
            "title": "网络协议 9 - TCP协议（下）", 
            "content": "<p>上次了解了 TCP 建立连接与断开连接的过程，我们发现，TCP 会通过各种“套路”来保证传输数据的安全。除此之外，我们还大概了解了 TCP 包头格式所对应解决的五个问题：顺序问题、丢包问题、连接维护、流量控制、拥塞控制。今天，我们就来看下 TCP 又是用怎样的套路去解决这五个问题的。</p><p>    在解决问题之前，咱们先来看看 TCP 是怎么成为一个“靠谱”的协议的。</p><h3>“靠谱”协议 TCP</h3><p>    TCP 为了保证顺序性，每个包都有一个 ID。这建立连接的时候，会商定起始 ID 的值，然后按照 ID一个个发送。</p><p>    为了保证不丢包，对于发送的包都要进行应答。但是这个应答不是一个一个来的，而是会应答某个之前的 ID，表示都收到了，这种模式称为<b>累计确认</b>和<b>累计应答</b>。</p><p>为了记录所有发送的包和接收的包，TCP 也需要发送端和接收端分别用缓存来保存这些记录。发送端的缓存里是按照包的 ID 一个个排列，根据处理的情况分成四个部分：</p><ul><li>第一部分：发送且已经确认的；</li><li>第二部分：发送尚未确认的；</li><li>第三部分：没有发送，但是已经等待发送的；</li><li>第四部分：没有发送，并且暂时还不会发送的。</li></ul><p>    于是，发送端需要保持这样的数据结构：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-0d846e24b0c83524e589f13c1541aa6c_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-0d846e24b0c83524e589f13c1541aa6c_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><ul><li>LastByteAcked：第一部分和第二部分的分界线</li><li>LastByteSent：第二部分和第三部分的分界线</li><li>LastByteAcked：第三部分和第四部分的分界线</li></ul><p>对于接收端来讲，它缓存记录的内容要简单一些，分为以下三个部分：</p><ul><li>第一部分：接收且确认过的；</li><li>第二部分：还没接收，但是马上就能接收的；</li><li>第三部分：还没接收，也没空间接收的。</li></ul><p>    对应的数据结构就像这样：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-2f8a5527ad29b0053d803abb1d461f8e_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-2f8a5527ad29b0053d803abb1d461f8e_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><ul><li>MaxRcvBuffer：最大缓存量；</li><li>LastByteRead：这个值之后是已经接收，但是还没被应用层读取的；</li><li>NextByteExpected：第一部分和第二部分的分界线，下一个期待的包 ID。</li></ul><p>    第二部分的窗口有多大呢？</p><p>    NextByteExpected 和 LastByteRead 的差起始是还没被应用层读取的部分占用掉的 MaxRcvBuffer 的量，我们定义为 A，即：A = NextByteExpected - LastByteRead - 1。</p><p>    那么，窗口大小，AdvertisedWindow = MaxRcvBuffer - A。</p><p>    也就是：AdvertisedWindow = MaxRcvBuffer - (NextByteExpected - LastByteRead - 1)</p><p>    而第二部分和三部分的分界线 = NextByteExpected + AdvertisedWindow - 1 = MaxRcvBuffer + LastByteRead。</p><h3>顺序与丢包问题</h3><p>    接下来，我们结合上述图例，用一个例子来看下 TCP 如何处理顺序与丢包问题的。</p><p>还是刚才的图，在发送端看来：</p><ul><li>1、2、3 是已经发送并确认的；</li><li>4、5、6、7、8、9 都是发送未确认的；</li><li>10、11、12 是还没发出的；</li><li>13、14、15 是接收方没有空间，不准备发送的。</li></ul><p>而在接收端看来：</p><ul><li>1、2、3、4、5 是已经完成 ACK，但还没读取的；</li><li>6、7 是等待接收的；</li><li>8、9 是已经接收，但是没有 ACK 的。</li></ul><p>发送端和接收端当前的状态如下：</p><ul><li>1、2、3 没有问题，双方达成了一致；</li><li>4、5 接收方发送 ACK 了，但是发送方还没收到，有可能丢了，有可能还在路上；</li><li>6、7、8、9 肯定都发了，但是 8、9 已经到了，6、7还没打，出现了乱序，于是在缓存中存储，但是没有返回 ACK。</li></ul><p>    根据这个例子，我们可以知道，顺序问题和丢包问题都有了能发送，所以我们先来看<b>确认与重发的机制</b>。<br/>    假设 4 的确认到了，不幸的是，5 的 ACK 丢了，并且 6、7 的数据包也丢了，这时候会怎么处理呢？</p><p>    一种方法是<b>超时重试</b>，也就是对每一个发送了，但是没有 ACK 的包，都有设一个定时器，一旦超过了一定的时间，就重新尝试。这个超时时间不宜过短，时间必须大于往返时间 RTT，否则就会引起不必要的重传也不宜过长，这样超时时间变长，访问就变慢了。</p><p>    估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。</p><p>    除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为<b>自适应重传算法（Adaptive Retransmission Algorithm）</b>。</p><p>    如果过一段时间，5、6、7 都超时了，就会重新发送。接收方发现 5 原来接收过，于是就丢弃5。收到了6，发送 ACK，要求下一个是 7，7 不幸又丢了。</p><p>    当 7 再次超时的时候，如果有需要重传，TCP 的策略就是<b>超时间隔加倍。每当遇到一次超时重传的实时，都会将下一次超时时间间隔设置为先前值的两倍。两次超时，就说明网络环境差，不宜频繁发送。</b></p><p>    可以看出，超时重发存在的问题是，超时周期可能较长。那是不是可以有更快的方式呢？</p><p>    有一个可以<b>快速重传</b>的机制。当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。</p><p>    例如，接收方发现 6、8、9 都已经接收了，但是 7 没来。于是发送三个 6 的 ACK，要求下一个是 7。客户端收到三个，就会发现 7 的确丢了，不等超时，就马上重发。</p><p>    除此之外，还有一种方式称为 <b>Selective Acknowledgment（SACK）</b>。这种方式需要在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发格发送方。例如发送 ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是 7 丢了，然后快速重发。</p><h3>流量控制问题</h3><p>    接下来，我们再来看看流量控制机制。在对于包的确认中，会同时携带一个窗口大小的字段。</p><p>    我们先假设窗口不变的情况，发送端窗口始终为 9。4 的确认来的时候，<b>LastByteAcked 会右移一个</b>，这个时候，第 13 个包就可以发送了。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-83cbc3cc72156ed367007c4c0c13430f_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-83cbc3cc72156ed367007c4c0c13430f_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    这个时候，假设发送端发送过猛，将第三部分中的 10、11、12、13 全部发送，之后就停止发送，则此时未发送可发送部分为 0。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-3460a247ecf4bf6b1cc89e3dbbe306ac_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-3460a247ecf4bf6b1cc89e3dbbe306ac_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    当对于包 5 的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以发送了，例如第 14 个包才可以发送。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-822691443a297906407fbdc5f76bbfc7_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-822691443a297906407fbdc5f76bbfc7_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    如果接收方处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为 0，则发送方将暂时停止发送。</p><p>    我们可以假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包 6 确认后，窗口大小就不会再是 9，而是减少一个变为了 8。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6ed6765e7dc6da2c15ff24e1e4db8f76_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-6ed6765e7dc6da2c15ff24e1e4db8f76_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    为什么会变为 8？你看，下图中，当 6 的确认消息到达发送端的时候，左边的 LastByteAcked 右移一位，而右边的未发送可发送区域因为已经变为 0，因此左边的 LastByteSend 没有移动，因此，窗口大小就从 9 变成了 8。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e7ef2d7c3e8e48e9ccc9756eb9a9cbdf_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-e7ef2d7c3e8e48e9ccc9756eb9a9cbdf_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    而如果接收端一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为 0。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-23c95e362de5aebfe821ca26ece5b776_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-23c95e362de5aebfe821ca26ece5b776_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    当这个窗口大小通过包 14 的确认到达发送端的时候，发送端的窗口也调整为 0，于是，发送端停止发送。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a5df44a50956fff7fabba1bd19fd3a7e_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-a5df44a50956fff7fabba1bd19fd3a7e_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    当发生这样的情况时，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。对于接收方来说，当接收比较慢的时候，要防止低能窗口综合征，别空出一个字节就赶紧告诉发送方，结果又被填满了。可以在窗口太小的时候，不更新窗口大小，直到达到一定大小，或者缓冲区一半为空，才更新窗口大小。</p><p>    这就是我们常说的<b>流量控制</b>。</p><h3>拥塞控制问题</h3><p>    最后，我们来看一下拥塞控制的问题。</p><p>    这个问题，也是靠窗口来解决的。前面的滑动窗口 rwnd 是怕发送方把接收方缓存塞满，而<b>拥塞窗口 cwnd</b>，是怕把网络塞满。</p><p>这里有一个公式：</p><blockquote> LastByteSent - LastByteAcked &lt;= min{cwnd, rwnd}<br/> </blockquote><p>    可以看出，是拥塞窗口和滑动窗口共同控制发送的速度。</p><p>    那发送方怎么判断网络是不是满呢？这其实是个挺难的事情。因为对于 TCP 协议来讲，它压根不知道整个网络路径都会经历什么。TCP 发送包常被比喻为往一个水管里灌水，而 TCP 的拥塞控制就是在不堵塞、不丢包的情况下，尽量发挥带宽。</p><p>    水管有粗细，网络有带宽，也就是每秒钟能够发送多少数据；</p><p>水管有长度，端到端有时延。在理想情况下：</p><blockquote> 水管里的水量 = 水管粗细 x 水管长度<br/> </blockquote><p>而对于网络来讲：</p><blockquote> 通道的容量 = 带宽 x 往返延迟<br/> </blockquote><p>    如果我们设置发送窗口，<b>使得发送但未确认的包的数量为通道的容量</b>，就能够撑满整个管道。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0acbe36ad0f68548cd13d92f78d72181_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-0acbe36ad0f68548cd13d92f78d72181_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>如上图所示：</p><blockquote> 假设往返时间为 8s，去 4s，回 4s，每秒发送一个包，每个包 1024 byte。<br/> </blockquote><p>    那么在 8s 后，就发出去了 8 个包。其中前 4 个包已经到达接收端，但是 ACK 还没有返回，不能算发送成功。而 5-8 后四个包还在路上，没被接收。</p><p>这个时候，整个管道正好撑满。在发送端，已发送未确认的为 8 个包，也就是：</p><blockquote> 带宽 = 1024byte/s x 8s（来回时间）<br/> </blockquote><p>    如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？</p><p>    原来发送一个包，从一端到另一端，假设一共经过四个设备，每个设备处理一个包耗时 1s，所以到达另一端需要耗费 4s。如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这不是我们希望看到的。</p><p>    这个时候，我们可以想其他的办法。例如，这四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的就在队列里面排着，这样包就不会丢失，但是缺点也是显而易见的，增加了时延。这个缓存的包，4s 肯定到达不了接收端，如果时延达到一定程度，就会超时，这也不是我们希望看到的。</p><p>    针对上述两种现象：<b>包丢失</b>和<b>超时重传</b>。一旦出现了这些现象就说明，发送速度太快了，要慢一点。但是一开始，发送端怎么知道速度多快呢？怎么知道把窗口调整到合适大小呢？</p><p>    如果我们通过漏斗往瓶子里灌水，我们就知道，不能一桶水一下子全倒进去，肯定会溢出来。一开始要慢慢的倒，然后发现都能够倒进去，就加快速度。这叫做<b>慢启动</b>。</p><p>一个 TCP 连接开始</p><ul><li>cwnd 设置为一个报文段，一次只能发送 1 个；</li><li>当收到这一个确认的时候，cwnd 加 1，于是一次能够发送 2 个；</li><li>当这两个包的确认到来的时候，每个确认的 cwnd 加 1，两个确认 cwnd 加 2，于是一次能够发送 4 个；</li><li>当这四个的确认到来的时候，每个确认 cwnd 加 1，四个确认 cwnd 加 4，于是一次能够发送 8 个。</li></ul><p>    从上面这个过程可以看出，这是<b>指数性的增长</b>。</p><p>    但是涨到什么时候是个头呢？一个值 ssthresh 为 65535 个字节，当超过这个值的时候，就会将将增长速度降下来。</p><p>    此时，每收到一个确认后，cwnd 增加 1/cwnd。一次发送 8 个，当 8 个确认到来的时候，每个确认增加 1/8，8个确认一共增加 1，于是一次就能够发送 9 个，变成了<b>线性增长</b>。</p><p>    即使增长变成了线性增长，还是会出现“溢出”的情况，出现拥塞。这时候一般就会直接降低倒水的速度，等待溢出的水慢慢渗透下去。</p><p>    拥塞的一种变现形式是丢包，需要超时重传。这个时候，将 ssthresh 设为 cwnd/2，将 cwnd 设为 1，重新开始慢启动。也就是，一旦超时重传，马上“从零开始”。</p><p>    很明显，这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。</p><p>    前面有提过<b>快速重传算法</b>。当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，告诉发送端要赶紧给我发下一个包，别等超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd 变为 cwnd/2，然后 sshthresh = cwnd。当三个包返回的时候，cwnd = sshthresh + 3。</p><p>    可以看出这种情况下降速没有那么激进，cwnd 还是在一个比较高的值，呈线性增长。下图是两者的对比。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c1f2a5217d65166c0ee0468aa36e7336_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-c1f2a5217d65166c0ee0468aa36e7336_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    就像前面说的一样，正是这种知进退，使得时延在很重要的情况下，反而降低了速度。但是，我们仔细想一想，TCP 的拥塞控制主要用来避免的两个现象都是有问题的。</p><p>    第一个问题是丢包。<b>丢包并不一定表示通道满了</b>，也可能是管子本来就”漏水”。就像公网上带宽不满也会丢包，这个时候就认为拥塞，而降低发送速度其实是不对的。</p><p>    第二个问题是 TCP 的拥塞控制要等到将中间设备都填满了，才发送丢包，从而降低速度。但其实，这时候降低速度已经晚了，在将管道填满后，不应该接着填，直到发生丢包才降速。</p><p>    为了优化这两个问题，后来就有了 <b>TCP BBR 拥塞算法</b>。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，<b>在这个平衡点可以很好的达到高带宽和低时延的平衡</b>。</p><p>    下图是 BBR 算法与普通 TCP 的对比：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-f6a507003f49ac4affb64e4a26796b58_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-f6a507003f49ac4affb64e4a26796b58_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>小结</h3><ul><li>顺序问题、丢包问题、流量控制都是通过滑动窗口来解决的。这就相当于领导和员工的备忘录，布置过的工作要有编号，干完了有反馈，活不能派太多，也不能太少；</li><li>拥塞控制是通过拥塞窗口来解决的，相当于往管道里面倒水，快了容易溢出，慢了浪费带宽，要摸着石头过河，找到最优值。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82185391", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 2, 
            "title": "网络协议 8 - TCP协议（上）", 
            "content": "<p>上次说了“性本善”的 UDP 协议，这哥们秉承“网之初，性本善，不丢包，不乱序”的原则，徜徉在网络世界中。</p><p>    与之相对应的，TCP 就像是老大哥一样，了解了社会的残酷，变得复杂而成熟，秉承“性恶论”。它认为网络环境是恶劣的，丢包、乱序、重传、拥塞都是常有的事儿，一言不合可能就会丢包，送达不了，所以从算法层面来保证可靠性。</p><h3>TCP 包头格式</h3><p>    老规矩，咱们先来看看 TCP 头的格式。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-4bd1741b21660e984faf7191d2836f80_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-4bd1741b21660e984faf7191d2836f80_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    从上面这个图可以看出，它比 UDP 要复杂的多。而复杂的地方，也正是它为了解决 UDP 存在的问题所必需的字段。</p><p>    首先，源端口号和目标端口号是两者都有，不可缺少的字段。</p><p>    接下来是<b>包的序号</b>。<b>给包编号就是为了解决乱序的问题</b>。老大哥做事，稳重为主，一件件来，面临再复杂的情况，也临危不乱。</p><p>    除了发送端需要给包编号外，接收方也会回复<b>确认序号</b>。做事靠谱，答应了就要做到，暂时做不到也要给个回复。</p><p>    这里要注意的是，TCP 是个老大哥没错，但不能说他一定会保证传输准确无误的完成。从 IP 层面来讲，如果网络的确那么差，是没有任何可靠性保证的，即使 TCP 老大哥再稳，他也管不了 IP 层丢包，他只能尽可能的保证在他的层面上的可靠性。</p><p>然后是一些<b>状态位</b>。有以下常见状态位：</p><ul><li>SYN（Synchronize Sequence Numbers，同步序列编号）：发起一个连接</li><li>ACK（Acknowledgement，确认字符）：回复</li><li>RST（Connection reset）：重新连接</li><li>FIN：结束连接</li></ul><p>    从这些状态位就可以看出，TCP 基于“性恶论”，警觉性就很高，不像 UDP 和小朋友似的，随便一个不认识的小朋友都能玩到一起，他与别人的信任要经过多次交互才能建立。</p><p>    还有一个<b>窗口大小</b>。这个是 TCP 用来进行流量控制的。通信双方各声明一个窗口，标识自己当前的处理能力，让发送端别发送的太快，要不然撑死接收端。也不能发送的太慢，要不然就饿死接收端了。</p><p>根据上述对 TCP 头的分析，我们知道对于 TCP 协议要重点关注以下几个问题：</p><ul><li>顺序问题，稳重不乱；</li><li>丢包问题，承诺靠谱；</li><li>连接伟豪，有始有终；</li><li>流量控制，把握分寸；</li><li>拥塞控制，知进知退。</li></ul><h3>TCP 的三次握手</h3><p>    了解完 TCP 头，我们就来看下 TCP 建立连接的过程，这就是著名的“<b>三次握手</b>”。</p><p>三次握手，过程是这样子的：</p><ul><li>A：你好，我是 A（<b>SYN</b>）。</li><li>B：你好 A，我是 B（<b>SYN，ACK</b>）。</li><li>A：你好 B（<b>ACK 的 ACK</b>）。</li></ul><p>    着重记忆上述过程，后续很多分析都是基于这个过程来的。</p><p>    记得刚接触三次握手的时候，就一直很纳闷，为啥一定要三次？两次不行吗？四次不行吗？然后很多人就解释，如果是两次，就怎样怎样，四次，又怎样怎样？但这其实都是<b>从结果推原因</b>，没有说明本质。</p><p>    我们应该知道，<b>握手是为了建立稳定的连接</b>，这个是最终目的。而要达到这个目的，就要<b>通信双方的交互形成一个确认的闭环</b>。</p><p>    拿上述 A、B 通信的例子来看，A 给 B 发信息，B 要告诉 A 他收到信息了。这时候，算是一个确认闭环吗？明显不是，因为 B 没有收到来自 A 的确认信息。</p><p>    所以，要达到我们上述的目标，还要 A 给 B 一个确认信息，这样就形成了一个<b>确认闭环</b>。</p><p>    A 给 B 的确认信息发出后，遇到网络不好的情况，也会出现丢包的情况。按理来说，还应该有个回应，但是，我们发现，好像这样下去就没玩没了啦。</p><p>    所以，我们说，只要通信双方形成一个确认闭环后，就认为连接已建立。一旦连接建立，A 会马上发送数据，而 A 发送数据，后续的很多问题都得到了解决。</p><p>    例如 A 发给 B 的确认消息丢了，当 A 后续发送的数据到达的时候，B 可以认为这个连接已经建立。如果 B 直接挂了，A 发送的数据就会报错，说 B 不可达，这样，A 也知道 B 出事情了。</p><p>    三次握手除了通信双方建立连接外，主要还是<b>为了沟通 TCP 包的序号问题</b>。</p><p>    A 要告诉 B，我发起的包的序号起始是从哪个号开始的，B 也要告诉 A，B 发起的包的序号的起始号。</p><p>    TCP 包的序号是会随时间变化的，可以看成一个 32 位的计数器，每 4ms 加一。计算一下，这样到出现重复号，需要 4 个多小时。但是，4 个小时后，还没到达目的地的包早就死翘翘了。这是因为 IP 包头里的 TTL（生存时间）。</p><p>    为什么序号不能从 1 开始呢？因为这样会很容易出现冲突。</p><p>    例如，A 连上 B 之后，发送了 1、2、3 三个包，但是发送 3 的时候，中间丢了，或者绕路了，于是重新发送，后来 A 掉线了，重新连上 B 后，序号又从 1 开始，然后发送 2，但是压根没想发送 3，而如果上次绕路的那个 3 刚好又回来了，发给了 B ，B 自然就认为，这就是下一包，于是发生了错误。</p><p>    就这样，双方历经千辛万苦，终于建立了连接。前面也说过，为了维护这个连接，双方都要维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像下面这样：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-00a23d3eff7cd3b6dce37ec0b1a3b184_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-00a23d3eff7cd3b6dce37ec0b1a3b184_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>整体过程是：</p><ol><li>客户端和服务端都处于 CLOSED 状态；</li><li>服务端主动监听某个端口，处于 LISTEN 状态；</li><li>客户端主动发起连接 SYN，处于 SYN-SENT 状态。</li><li>服务端收到客户端发起的连接，返回 SYN，并且 ACK 客户端的 SYN，处于 SYN-RCVD 状态；</li><li>客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，处于 ESTABLISHED 状态；</li><li>服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态。</li></ol><h3>TCP 的四次挥手</h3><p>    说完了连接，接下来就来了解下 TCP 的“再见模式”。这也常被称为<b>四次挥手</b>。</p><p>还拿 A 和 B 举例，挥手过程：</p><ol><li>A：B 啊，我不想和你玩了。</li><li>B：哦，你不想玩了啊，我知道了。这个时候，还只是 A 不想玩了，就是说 A 不会再发送数据，但是 B 此时还没做完自己的事情，还是可以发送数据的，所以此时的 B 处于<b>半关闭状态</b>。</li><li>B：A啊，好吧，我也不想和你玩了，拜拜。</li><li>A：好的，拜拜。</li></ol><p>    这样这个连接就关闭了。看起来过程很顺利，是的，这是通信双方“和平分手”的场面。</p><p>    A 开始说“不玩了”，B 说“知道了”，这个回合，是没什么问题的，因为在此之前，双方还处于合作的状态。</p><p>    如果 A 说“不玩了”，没有收到回复，那么 A 会重新发送“不玩了”。但是这个回合结束之后，就很可能出现异常情况了，因为有一方率先撕破脸。这种撕破脸有两种情况。</p><p>    一种情况是，A 说完“不玩了”之后，<b>A 直接跑路</b>，这是会有问题的，因为 B 还没有发起结束，而如果 A 直接跑路，B 就算发起结束，也得不到回答，B 就就不知道该怎么办了。</p><p>    另一种情况是，A 说完“不玩了”，<b>B 直接跑路</b>。这样也是有问题的，因为 A 不知道 B 是还有事情要处理，还是过一会发送结束。</p><p>    为了解决这些问题，TCP 专门设计了几个状态来处理这些问题。接下来，我们就来看看断开连接时的<b>状态时序图</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fcc33e3a3e31d4d213e0b7ce9deb5472_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-fcc33e3a3e31d4d213e0b7ce9deb5472_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>整体过程是：</p><ol><li>A 说“不玩了”，就进入 FIN_WAIT_1 状态；</li><li>B 收到 “A 不玩”的消息后，回复“知道了”，就进入 CLOSE_WAIT 状态；</li><li>A 收到“B 说知道了”，进入 FIN_WAIT_2 状态。这时候，如果 <b>B 直接跑路</b>，则 A 将永远在这个状态。TCP 协议里面并没有对这个状态的处理，但是 Linux 有，可以调整 tcp_fin_timeout 这个参数，设置一个超时时间；</li><li>B 没有跑路，发送了“B 也不玩了”的消息，处于 LAST_ACK 状态；</li><li>A 收到“B 说不玩了”的消息，回复“A 知道 B 也不玩了”的消息后，从 FINE_WAIT_2 状态结束。</li></ol><p>    最后一个步骤里，如果 A 直接跑路了，也会出现问题。因为 A 的最后一个回复，B 如果没有收到的话就会重复第 4 步，但是因为 A 已经跑路了，所以 B 会一直重复第 4 步。</p><p>    因此，TCP 协议要求 A 最后要等待一段时间，这个等待时间是 TIME_WAIT，这个时间要足够长，长到如果 B 没收到 A 的回复，B 重发给 A，A 的回复要有足够时间到达 B。</p><p>    A 直接跑路还有一个问题是，A 的端口就空出来了，但是 B 不知道，B 原来发过的很多包可能还在路上，如果 A 的端口被新的应用占用了，这个新的应用会受到上个连接中 B 发过来的包，虽然序列号是重新生成的，但是这里会有一个双保险，防止产生混乱。因此也需要 A 等待足够长的时间，等到 B 发送的所有未到的包都“死翘翘”，再空出端口。</p><p>    这个等待的时间设为 2MSL，MSL 是 <b>Maximum Segment Lifetime，即报文最大生存时间</b>。它是任何报文再网络上存在的最长时间，超过这个时间的报文就会被丢弃。</p><p>    因为 TCP 报文基于 IP 协议，而 IP 头中有一个 TTL 域，是 IP 数据报可以经过的最大路有数，每经过一个处理他的路由器，此值就减 1，当此值为 0 时，数据报就被丢弃，同时发送 ICMP 报文通知源主机。协议规定 MSL 为 2 分钟，实际应用中常用的是 30 秒、1分钟和 2 分钟等。</p><p>    还有一种异常情况，<b>B 超过了 2MS 的时间，依然没有收到它发的 FIN 的 ACK</b>。按照 TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，就表示，我已经等你这么久，算是仁至义尽了，再来的数据包我就不认了，于是直接发送 RST，这样 B 就知道 A 跑路了。</p><h3>TCP 状态机</h3><p>    将连接建立和连接断开的两个时序状态图综合起来，就是著名的 <b>TCP 状态机</b>。我们可以将这个状态机和时序状态机对照看，就会更加明了。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d3dd56971bbe844272aaddff7d1c6e35_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-d3dd56971bbe844272aaddff7d1c6e35_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>图中加黑加粗部分，是上面说到的主要流程，相关说明：</p><ul><li>阿拉伯数字序号：建立连接顺序；</li><li>大写中文数字序号：断开连接顺序；</li><li>加粗实线：客户端 A 的状态变迁；</li><li>加粗虚线：服务端 B 的状态变迁；</li></ul><h3>总结</h3><ul><li>TCP 包头很复杂，主要关注 5 个问题。顺序问题、丢包问题、连接维护、流量控制、拥塞控制；</li><li>建立连接三次握手，断开连接四次挥手，状态图要牢记。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82185285", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 2, 
            "title": "网络协议 7 - UDP 协议", 
            "content": "<p>网络协议五步登天路，我们一路迈过了物理层、链路层，今天终于到了传输层。从这一层开始，很多知识应该都是服务端开发必备的知识了，今天我们就一起来梳理下。</p><p>    其实，讲到 UDP，就少不了 TCP。这俩货简直就是个“连体兄弟”，只要出现一个，另一个肯定就在不远处等着你。</p><p>    博主相信，绝大多数的服务端开发都碰到过“TCP 与 UDP 的区别”这样的面试题，而在实际业务开发中，也会对比 TCP 与 UDP，选择合适的协议进行开发。</p><p>    所以，咱们还是老生常谈，先来看看这俩兄弟的区别。</p><h3>TCP 与 UDP 的区别</h3><p>    相信很多人都知道，TCP 是面向连接的，UDP 是面向无连接的。</p><p>    那么，什么是面向连接，什么是面向无连接呢？</p><p>    在互通之前，面向连接的协议会先建立连接，再进行通信。就像 TCP 会进行三次握手，而 UDP 不会。</p><p>    那为什么会建立连接呢？TCP 进行三次握手，UDP 就不能发三个数据包玩玩，有什么区别呢？</p><p>    其实这里所谓的建立连接，<b>就是通过建立一定的数据结构来维护客户端和服务端交互的状态，用这样的数据结构来保证所谓的面向连接的特性。</b></p><p>    上面这段话中，有一个很重要的词-<b>状态</b>。也就是说，TCP 实质上是一个<b>有状态</b>的服务。这个状态，可以说是它和 UDP 的本质区别。</p><p>    通俗点讲，有状态的 TCP 就是<b>有脑子</b>的，它会记住数据是否已经精确发送了，发到哪里了，应该接收哪个数据，不能容忍一点错误。</p><p>    与之对应的，<b>UDP 就是没脑子的</b>，天真无邪，发出去的数据就发出去，不会考虑网络世界的“恶意”。</p><p>TCP 既然有脑子，那肯定能做到很多 UDP 做不到的事情，例如：</p><ol><li>提供可靠交付。通过 TCP 连接传输的数据，无差错、不丢失、不重复，且按序到达。而 UDP 则是<b>不保证不丢失，不保证按序到达</b>。</li><li>面向字节流。TCP 发送的时候是一个流，没有头尾。而 UDP 是<b>基于数据报，一个个发，一个个收</b>；</li><li>可进行拥塞控制。TCP 意识到包丢弃或者网络环境不好的时候，会调整自己的行为，决定要发快点，还是发慢点。而 UDP 则是<b>应用让我发，我就发，管它洪水滔天</b>。。</li></ol><h3>UDP 包头</h3><p>    发送的 UDP 包到达目标机器后，发现 MAC 地址匹配，于是取下来，然后再交给 IP 层处理，发现 IP 匹配，接下来呢？数据包给谁呢？</p><p>    发送的时候，接收机器怎么知道数据包是 UDP 的包呢？所以在 IP 头里面有个 8 位协议，这里会存放，数据包究竟是 TCP 还是 UDP。</p><p>    处理完传输层的事情，内核的事情基本上就干完了，里面的数据应该交给应用程序自己去处理。可是，一台机器上跑着那么多的应用程序，应该给谁呢？</p><p>    无论应用程序写的是使用 TCP 传呼机，还是 UDP 传数据，都要监听一个端口。正式这个端口，用来区分应用程序。</p><p>    这样，UDP 头里面的内容就都出来了，如下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d025e5f4358f3cc24b123b720371b775_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-d025e5f4358f3cc24b123b720371b775_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    当我们看到 UDP 包头的时候，发现的确有端口号，有源端口号和目标端口号。但是它除了端口号，就再没有其他的，和 TCP 头比起来，简单的一塌糊涂。</p><h3>UDP 三大特点</h3><p>上面提过，UDP 像个小孩子一样，比较简单，有以下特点：</p><ol><li><b>沟通简单</b>。没有花花肠子（大量的数据结构、处理逻辑、包头字段），秉承“性善论”，相信网络通路很容易到达，不容易被丢弃；</li><li><b>轻信他人</b>。不会建立连接，只认端口号，谁都可以给他传数据，他也可以传给任何人数据，甚至可以同时传给多人数据；</li><li><b>愣头青，做事不懂权变</b>。不会根据网络的请求进行拥塞控制，不管网络再差，它该怎么发还怎么发。</li></ol><h3>UDP 使用场景</h3><p>    正所谓“祸兮福所倚”，虽然 UDP 有着很多问题，但也可以在特定场景中发挥更好的作用。</p><p>    第一，<b>需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用</b>。这很好理解，就像你是领导，你会让你们组刚毕业的小伙伴去做一些没有那么难，或者是失败了也能忍受的实验性项目。</p><p>我们之前认识的 <a href=\"https://link.zhihu.com/?target=https%3A//www.cnblogs.com/BeiGuo-FengGuang/p/9877801.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">DHCP</a> 就是基于 UDP 协议的。一般的获取 IP 地址都是内网请求，而且一次获取不到 IP 也没关系，过一会还可以请求获取。</p><p>    第二，<b>不需要建立连接，一对一沟通，而且需要广播的应用</b>。 UDP 的不面向连接的功能，可以承载广播或多播的协议。DHCP 就是一种广播的形式。</p><p>对于多播，我们之前提到的 IP 地址中的 D 类地址，也就是组播地址。使用这个地址，可以将包组播给一批机器。当一台机器上的某个进程想监听某个组播地址时，需要发送 IGMP 包，所在网络的路由器收到这个包，知道有个机器有个进程在监听这个组播地址。当路由器收到这个组播地址的数据包时，就会将包转发给这台机器，这样就实现了跨路由器的组播。</p><p>    第三，<b>需要处理速度快、延时低、可以容忍少数丢包，但是要求即便网络阻塞，也毫不退缩，一往无前的时候</b>。</p><p>    UDP 简单、处理速度快，不像 TCP 那样操那么多的心。并且，TCP 在网络不好出现丢包的时候，它的拥塞策略会主动的降低发送速度，这就相当于本来环境就差，还自断臂膀，用户本来就卡，这下更卡了。</p><p>    当前很多应用都是要求低时延的，他们可不想用 TCP 如此复杂的机制，而是想根据自己的场景，实现自己的可靠和连接保证。例如，如果应用觉得，有的包丢了就丢了，没必要重传了，而有的比较重要的包丢了，则应用自己重传，不依赖 TCP。</p><p>    由于 UDP 十分简单，基本啥都没做，也就给了应用“城会玩”的机会。就像在和平年代，每个人应该有独立的思考和行为，应该可靠且礼让。但是如果在战争年代，往往不太需要过于独立的思考，而需要士兵简单服从命令即可。</p><h3>基于 UDP 的“城会玩”的五个例子</h3><h3>城会玩 一：网页或 APP 的访问</h3><p>    网页和手机 APP 都是基于 HTTP 协议的，而HTTP 协议是基于 TCP 的，建立连接都需要多次交互，对于时延比较大的移动互联网来讲，建立一次连接需要的时间会比较长，而且移动互联网还是在移动中，TCP 可能还会断了重连，这也是很耗时的。</p><p>    除此之外，目前的 HTTP 协议，往往采取多个数据通道共享一个连接的情况这样本来为了加快传输速度，但是 TCP 的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。</p><p>    而 QUIC（Quik UDP Internet Connections，快速 UDP 互联网连接）是 Google 提出的一种基于 UDP 改进的通信协议，其目的是降低网络通信的延迟，提供更好的用户互动体验。</p><p>    QUIC 在应用层会自己实现快速连接建立、减少重传时延，自适应拥塞控制，是应用层“城会玩”的代表。</p><h3>“城会玩” 二：流媒体的协议</h3><p>    直播协议多使用 RTMP，这个协议就是基于 UDP 的。TCP 的严格顺序传输要保证前一个收到了，下一个才能确认。对于直播来讲，这显然是不合适的，因为老的视频帧丢了就丢了，就算再传过来用户也不在意，他们要看新的了，如果一直没来，用户就会一直显示卡顿，新的也看不了。所以，对于直播，实时性比较重要，宁可丢包，也不要卡顿的。</p><p>    另外，对于丢包，其实对于食品播放来讲，有的包可以丢，有的包不能丢，因为视频的连续帧里面，有的包重要，有的包不重要，如果必须要丢包，隔几个帧丢一个，其实看视频的人不会感知，但是如果连续丢帧，用户就会有感知了。因此，在网络不好的情况下，应用希望选择性的丢帧。</p><p>    还有就是，当网络不好的时候，TCP 会主动降低发送速度。这对本来就卡的看视频来讲是要命的，本来应该马上重传，而不是主动让步。因此，很多直播应用，都基于 UDP 实现了自己的视频传输协议。</p><h3>“城会玩” 三：实时游戏</h3><p>    游戏有一个特点，就是实时性比较高。快一秒你干掉别人，慢一秒就被别人爆头，所以很多职业玩家会买非常专业的鼠标和键盘，争分夺秒。</p><p>    因而，实时游戏中客户端和服务端要建立长连接，来保证实时传输，但是游戏玩家很多，服务器却不多，由于维护 TCP 连接需要在内核维护一些数据结构，因而一台机器能够支撑的 TCP 连接数量是有限的。而 UDP 由于是没有连接的，在异步 IO 机制引入之前，常常是应对海量客户端连接的策略。</p><p>    另外还是 TCP 的强顺序问题，对战的游戏，对网络的要求很简单，玩家通过客户端发送给服务器鼠标和键盘行走的位置，服务器会处理每个用户发送过来的所有厂家，处理完再返回给客户端，客户端解析响应，渲染最新的场景展示给玩家。</p><p>    如果出现一个数据包丢失，所有事情都需要停下来等待这个数据包重发。客户端会出现等待接收数据，然而玩家并不关心过期的数据，相信大家玩CF 的时候，如果激战中卡 1 秒，是不是就有拍键盘的冲动？</p><p>    游戏对实时要求较为严格的情况下，采用自定义的 UDP 协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性能造成的影响。</p><h3>“城会玩” 四：IoT物联网</h3><p>    一方面，物联网领域终端资源少，很可能只是内存非常小的嵌入式系统，而维护 TCP 协议代价太大。另一方面，物联网对实时性要求也很高。Google 旗下的 Nest 建立 Thread Group，推出了物联网通信协议 Thread，就是基于 UDP 协议的。</p><h3>“城会玩” 五：移动通信领域</h3><p>    在 4G 网络里，移动流量上网的数据协议 GTP-U 也是基于 UDP 的。因为移动网络协议比较复杂，而 GTP 协议本身就包含复杂的手机上线下线的通信协议。</p><h3>总结</h3><ul><li> 如果把 TCP 比作成熟的社会人，那么 UDP 就是头脑简单的小朋友。TCP 复杂，UDP 简单；TCP 维护连接，UDP 谁都相信；TCP 会知进退，UDP 愣头青一个，勇往直前；<br/> </li><li> UDP 虽然简单，但是它可以用在环境简单、需要多播、应用层自己控制传输的地方。例如 DHCP、QUIC 等。<br/> </li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/81798715", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 1, 
            "title": "网络协议 1 - 概述", 
            "content": "<p>互联网世界中，网络协议的重要性不言而喻。很多人都知道，网络协议中的五层模型或者七层模型，这些在操作系统中，那都是“必考题”。上学的时候，无论是死记硬背，还是各种小抄，总得把下面这个图记下来。踏入工作，走进 web 开发“不归路”，发现还是不能落下它。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8d7599bb974ddc696a5442e7375f99ce_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-8d7599bb974ddc696a5442e7375f99ce_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>协议三要素</h2><ul><li><b><i>语法</i></b>，就是一段内容要符合一定的规则和格式。例如，括号要成对，结束要使用分号等。</li><li><b><i>语义</i></b>，就是这段内容要代表某种意义。例如，数字相减是有意义的，而数字减去文本一般来说就没有意义。</li><li><b><i>顺序</i></b>，就是规定先干什么，后干什么。就像我们常做的，先加某个数值，再减去某个数值等。</li></ul><p>HTTP 协议：</p><div class=\"highlight\"><pre><code class=\"language-text\">HTTP/1.1 200 OK\nDate: Thu, 25 Oct 2018 01:56:12 GMT\nContent-Type: \nContent-Language:\n\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;base href=&#34;http://blog.muzixizao.com/&#34; /&gt;\n&lt;meta charset=&#34;utf-8&#34;/&gt; &lt;title&gt;木子与西早的博客屋 &lt;/title&gt;</code></pre></div><p>我们来看看上面的 HTTP 协议是否符合协议的三要素。</p><p>首先，符合语法，也就是说，只有按照上面那个格式来，浏览器才能解析。例如，上面是状态，然后是首部，最后是内容。</p><p>其次，符合语义，就是要按照约定的意思来。例如，状态 200，表示网页成功返回。如果不成功，就是常见的 404。</p><p>最后，符合顺序，点击浏览器，就是发送一个 HTTP 请求，然后才有上面那串返回的东西。</p><p>浏览器显然按照协议商定好的做了，才能将网页呈现在你面前。</p><h2>常用的网络协议</h2><p>我们面试的时候经常会被问到这样一个问题：</p><blockquote> 在浏览器输入一个地址，然后点击回车，此时到页面加载出来，这个过程发生了什么？<br/> </blockquote><p>我们就用打开博客的过程，看看互联网世界运行过程中，都使用了哪些网络协议。</p><p>当在浏览器里输入 “<a href=\"https://link.zhihu.com/?target=http%3A//blog.muzixizao.com/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">http://blog.muzixizao.com</a>”，这是一个 URL，而浏览器知道它的名字是 blog.muzixizao.com，但是不知道具体的地点，所以浏览器不知道如何访问。</p><p>于是，它<i>打开地址簿去查找</i>。在这个过程中，我们一般使用<i><b>地址簿协议-DNS</b></i>，还可以使用另一种更加精准的地址簿查找协议-<i><b>HTTPDNS</b></i>。</p><p>无论使用哪一种方法查找，最终都可以得到这个地址：47.106.81.116。这个是 IP 地址，可以把它当做是互联网世界的“门牌号”。</p><p>知道了目标地址，浏览器就开始打包它的请求。对于普通的 HTTP 请求，一般会使用 HTTP 协议，但是如果对于购物的请求，往往会进行加密传输，因而会使用 HTTPS 协议。无论是什么协议，里面都会写明“我要看哪篇博文”。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-77550835ff3edbb3b68b582bcc45c308_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-77550835ff3edbb3b68b582bcc45c308_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>DNS、HTTP、HTTPS 所在的层我们成为<b><i>应用层</i></b>。经过应用层封装后，浏览器会将应用层的包交给下一层去完成，通过 socket 编程来实现。下一层是<b><i>传输层</i></b>。传输层有两种协议，一种是无连接的协议 UDP，一种是面向连接的协议 TCP。而所谓的面向连接就是，TCP 会保证这个包能够到达目的地，如果不能到达，就会重新发送，直至到达。</p><p>TCP 协议里面会有两个端口。一个是浏览器监听的端口，一个是博客服务器监听的端口。操作系统往往通过端口来判断，它得到的包应该给哪个 进程。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5ad5872b6b2d608de2e7085a8675ff77_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-5ad5872b6b2d608de2e7085a8675ff77_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>传输层封装完毕后，浏览器会将包交给操作系统的<b><i>网络层</i></b>。网络层的协议是 <b><i>IP 协议</i></b>。在 IP 协议里面会有源 IP 地址和目标 IP 地址，也就是浏览器所在机器的 IP 地址和博客网站所在服务器的 IP 地址。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-915d0f5bbe5e5e19461b90729df38d9a_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-915d0f5bbe5e5e19461b90729df38d9a_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>操作系统既然知道了目标 IP 地址，下一步就是根据这个 IP 找到目标机器。它首先会判断，这个目标 IP 是本地人还是外地人。从 IP 很明显就能看出来，博客服务器不在本地。</p><p>操作系统知道了，要到目标机器，就要要离开本地去远方。那如何去远方呢？这个时候就可以拿出国旅游作类比。我们要去国外，就要经过海关。同样的，操作系统要去远方，也要经过<b><i>网关</i></b>。而操作系统启动的时候，就会被 DHCP 协议配置 IP 地址，以及默认的网关 IP 地址：192.168.1.1。</p><p>操作系统如何将 IP 地址发给网关呢？在本地通信基本靠吼，于是操作系统大吼一声，谁是 192.168.1.1 ？网关会回答它，我就是，我的本地地址在村东头。这个本地地址就是 MAC 地址，而大吼的那一声就是 <b><i>ARP 协议</i></b>。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-dd5c4af7bc1738c02cd9d0a6e3de1eb1_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-dd5c4af7bc1738c02cd9d0a6e3de1eb1_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>操作系统拿到了 MAC 地址，就将 IP 包交给了下一层：MAC 层。网卡再将这个包含 MAC 地址的包发出去。由于这个包里面有网关的 MAC 地址，因而它能够到达网关。</p><p>网关收到包之后，会根据自己的知识，判断下一步应该怎么走。网关往往是一个路由器，到某个 IP 地址应该怎么走，这个叫做<b><i>路由表</i></b>。</p><p>路由器有点像玄奘西行路过的一个个国家的城关。每个城关连接着两个国家，每个国家相当于一个局域网，在每个国家内部，都可以使用本地的地址 MAC 进行通信。</p><p>一旦跨越城关，就需要拿出 IP 头来，里面写着贫僧来自东土大唐（源 IP 地址），想去西天（目标 IP 地址）拜佛求经。路过此地，借宿一晚，明日启行。请问接下来该怎么走？<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-662a07225047a09aec68020622f4c63e_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-662a07225047a09aec68020622f4c63e_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>城关往往是知道这些“知识”的，因为城关和临近的城关也会经常沟通。到哪里应该怎么走，这种沟通的协议称为<b><i>路由协议</i></b>，常用的有 OSPF 和 BGP。</p><p>城关与城关之间是一个国家，当网络包知道了下一步去哪个城关，还是要使用国家内部的 MAC 地址，通过下一个城关的 MAC 地址，找到下一个城关，然后再问下一步的路怎么走，一直到走出最后一个城关。</p><p>最后一个城关知道这个网络包要去的地方，于是，就对着这个国家吼一声（ARP协议），谁是目标 IP ？目标服务器就会回复一个 MAC 地址。网络包过关后，通过这个 MAC 地址就能找到目标服务器。</p><p>目标服务器发现 MAC 地址对上了，取下 MAC 头来，然后发送给操作系统的网络层。网络层发现 IP 也对上了，就取下 IP 头。 IP 头里会写上一层封装的是 TCP 协议，然后将其交给传输层，即 TCP 层。</p><p>在这一层里，对于收到的每个包，都会有一个回复的包说明收到了。这个回复的包不是这次请求的结果，而仅仅是 TCP 层的一个收到回复。这个回复会沿着刚才来的方向走回去，报个平安。</p><p>如果过一段时间，发送端的 TCP 层没有收到平安回复，就会重新发送这个包，重复上面的过程，直到收到平安到达的回复为止。这个重试不是浏览器重新进行请求，对于浏览器而言，只发送一次请求，而 TCP 层在没有收到平安回复时，不断闷头重试。除非 TCP 层出了问题，比如连接断了，才需要浏览器的应用层重新发送请求。</p><p>当网络包平安到达 TCP 层后，TCP 头中有目标端口号，通过这个端口号，可以找到博客网站的进程正在监听这个端口号，假设是 Nginx，于是就将这个包发给 Nginx，进行相关业务处理。处理完成后，将相关数据打包，然后回复给浏览器，显示出博文页。</p><p>下图就是整个HTTP 请求中可能用到的协议。后续会通过从底层到上层的顺序来一一分享。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-79c7da66ee101527f15035e05fccad41_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-79c7da66ee101527f15035e05fccad41_b.png\"/></figure><p><br/> </p><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82185134", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 2, 
            "title": "网络协议 6 - 路由协议：跨网关访问", 
            "content": "<p>前面例子中，我们都是在一个局域网内折腾。今天就让我们扩大范围，在多个局域网甚至到广阔的互联网世界中遨游，看看这中间会发生什么。</p><p>    这个过程中，跨网关访问是我们要了解的第一个内容。</p><h3>跨网关访问</h3><p>    当我们要了解跨网关访问时，就牵扯到 MAC 地址和 IP 地址的变化，因此，我们先来看下 MAC 头和 IP 头的细节。</p><h3>MAC 头和IP 头的细节</h3><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-3ed0eaa8fbbcdcc6ed2ca3b5ddf8102b_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-3ed0eaa8fbbcdcc6ed2ca3b5ddf8102b_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    如图，在 MAC 头里，先是目标 MAC 地址，然后是源 MAC 地址，最后是协议类型。</p><p>    在 IP 头里，最重要的就是源 IP 地址和目标 IP 地址。除此之外，还有版本号，也就是我们常说的 IPv4 和 IPv6、服务类型 TOS（表示数据包优先级）、TTL（数据包生存周期）以及标识协议（TCP 和 UDP）</p><p>    当我们访问博客园时，经过的第一个网关应该就是我们配置的默认网关。当本机访问默认网关时，还是走局域网内部访问的步骤：</p><ol><li>将源地址和目标 IP 地址放入 IP 头；</li><li>通过 ARP 协议获得网关的 MAC 地址；</li><li>将源 MAC 地址和网关的 MAC 地址放入 MAC 头中，发送给网关。</li></ol><p>    而我们的网关，一般就是指<b>家里的路由器，是一个三层转发的设备</b>。它会把 MAC 头和 IP 头都取下来，然后根据里面的内容，看看接下来把数据包转发到哪里。</p><p>    很多情况下，人们把网关叫做路由器。其实并不准备，用这个比喻应该更为恰当些：</p><blockquote> 路由器是一台设备，它有五个网口或者网卡，相当于有五只手，分别连着五个局域网。每只手的 IP 地址都和局域网的 IP 地址有着相同的网段，每只手都是它握住的那个局域网的网关。<br/> </blockquote><p>    任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下 MAC 头和 IP 头，然后根据自己的<b>路由算法</b>，选择另一只手，加上 IP 头和 MAC 头，然后扔出去。</p><p>    注意，在上面这个过程中，有出现<b>路由算法</b>。接下来，我们就来认识下它。</p><h3>路由算法</h3><p>    路由算法，又名选路算法，是提高路由协议功能，尽量减少路由时所带来的开销的算法。</p><p>    路由算法可以根据多个特性来加以区分，找到到达目的地的最佳路由。</p><p>路由算法的区分点有很多，有</p><ul><li>静态与动态</li><li>单路径与多路径</li><li>平坦与分层</li><li>主机智能与路由器智能</li><li>域内与域间</li><li>链接状态与距离向量</li></ul><p>    这里主要介绍<b>静态与动态</b>路由算法。</p><h3>静态路由</h3><p>    静态路由算法，实质上是由网关配置好的映射表。</p><p>    我们家里的路由器，可能会有这样的路由配置</p><blockquote> 访问博客园，从 2 号口出去，下一跳是 IP2；<br/>访问百度，从 3 号口出去，下一跳是 IP3。<br/> </blockquote><p>    类似上述这样的规则就是静态路由，按照一定的语法保存在路由器里。</p><p>    每当要选择从哪个口抛出去的时候，就一条一条的匹配规则，找到符合的规则，就按规则办事，从指定口抛出去，找下一跳 IP。</p><h3>过网关的“变”与“不变”</h3><p>    之前我们了解到，MAC 地址是一个局域网内才有效的地址。因此，MAC 地址只要过网关，就肯定会改变。而 IP 地址在过网关后 ，就不一定会改变了。</p><p>    经过网关 A 后，如果IP 地址没有改变，那 A 就是<b>转发网关</b>，否则，就是<b>NAT网关</b>。</p><h3>转发网关</h3><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4190245de7766a2d06adb41bff8f42a2_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-4190245de7766a2d06adb41bff8f42a2_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    如上图，服务器 A 要访问服务器 B，要经过过程：</p><p><b>1）服务器 A 到 网关 A</b></p><ol><li>检查 B 的网段，发现不在同一个网段，因此发给网关</li><li>由于网关的 IP 地址是已经配置好了，因此发送 ARP 获取网关的 MAC 地址</li><li>发送包</li></ol><p>而最后发送包的内容主要有：</p><ul><li>源 MAC：服务器 A 的 MAC</li><li>模板 MAC：192.168.1.1 网关的 MAC</li><li>源 IP：192.168.1.101</li><li>目标 IP：192.168.4.101</li></ul><p>    数据包到达 192.168.1.1 这个网口后，网口发现 MAC 地址是它的，就将包收进来，然后开始“思考”往哪里转发。</p><p>    这时候，路由器 A 中配置了规则 A1：</p><blockquote> 要访问 192.168.4.0/24，就从 192.168.56.1 这个网口出去，下一跳是 192.168.56.2<br/> </blockquote><p><b>2）网关 A 到 网关 B</b></p><p>    于是，路由器 A 匹配了 A1，要从 192.168.56.1 这个口发出去，发给 192.168.56.2。于是，又开始了这个过程：</p><ol><li>检查 B 的网段，发现在同一个网段， ARP 获取 MAC 地址</li><li>发送包</li></ol><p>数据包的内容是：</p><ul><li>源 MAC：192.168.56.1 的 MAC</li><li>模板 MAC：192.168.56.2 的 MAC</li><li>源 IP：192.168.1.101</li><li>目标 IP：192.168.4.101</li></ul><p>    数据包到达 192 .168.56.2 网口，网口发现 MAC 地址是它的，就将包收进来，然后去检查路由规则。</p><p>    路由器 B 配置以下规则 B1：</p><blockquote> 想访问 192.168.4.0/24，就从 192.168.4.1<br/> </blockquote><p>    而路由器 B 发现，它的右网口就是目标地址网段的，因此就没有下一跳了。</p><p><b>3）网关 B 到 服务器 B</b></p><p>路由器 B 匹配上 B1。从 192.168.4.1 出口，发给 192.168.4.101。数据包内容：</p><ul><li>源 MAC：192.168.4.1 的 MAC</li><li>模板 MAC：192.168.4.101 的 MAC</li><li>源 IP：192.168.1.101</li><li>目标 IP：192.168.4.101</li></ul><p>    服务器 B 收到数据包，发现 MAC 地址是它的，就把包收进来。</p><p>    通过上面的过程可以看出，每到一个新的局域网， MAC 地址都是要变的，而 IP 地址则都不变。在 IP 头里面，不会保存任何网关的 IP 地址。</p><p>    而我们说的下一跳，<b>就是某个 IP 要将这个 IP 地址转换为 MAC 放入 MAC 头</b>。</p><h3>NAT 网关</h3><p>    NAT 网关，也就是 Network Address Translation。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6b0b32b9cf849d9b693a57728bb651aa_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-6b0b32b9cf849d9b693a57728bb651aa_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    由于各个局域网都有各自的网段，很容易出现 IP 冲突的情况。如上图，美国服务器 A 的 IP 地址和 法国服务器 B 的 IP 地址都是 192.168.1.101/24，从 IP 上看，好像是自己访问自己，但实际上从美国的 192.168.1.101 访问法国的 192.168.1.101。</p><p>    如何解决这个问题呢？既然局域网之间没有商量好 IP 分配，各管各的，那到国际上，也就是中间的局域网里面，就需要使用另外的地址，就像出国后，我们要改用护照一样。</p><p>    首先，目标服务器 B 在国际上要有一个<b>国际的身份</b>，我们给它一个 190.168.56.2.在网关 B 上，我们记下来，国际身份 192.168.56.2 对应国内身份 192.168.1.101.凡是要访问 192.168.56.2 的，网关都要转成 192.168.1.101。</p><p>    于是，源服务器 A 要访问目标服务器 B，目标地址就变成国际 IP 地址 192.168.56.2。过程如下：</p><p><b>1）源服务器 A 发数据包到网关 A</b></p><ol><li>检查服务器 B IP，不在同一网段</li><li>ARP 获取网关 MAC 地址</li><li>发送包</li></ol><p>数据包的内容是这样的：</p><ul><li>源 MAC：服务器 A 的 MAC</li><li>目标 MAC：192.168.1.1 这个网口的 MAC</li><li>源 IP：192.168.1.101</li><li>目标 IP：192.168.56.2</li></ul><p>    路由器 A 中 192.168.1.1 这个网口收到数据包后，检查 MAC 地址一致，将包收进来。</p><p>    在路由器 A 中配置了规则：</p><blockquote> 想访问 192.168.56.2/24，就从 192.168.56.1 网口发出去，发给 192.168.56.2，没有下一跳。<br/> </blockquote><p>    由于路由器的右网口（192.168.56.1） IP 地址和目标 IP 地址在同一网段，因此没有下一跳。</p><p><b>2）网关 A 到网关 B</b><br/>当网络包发送到中间的局域网时，服务器 A 也需要有个国际身份。因此，源 IP 地址 192.168.1.101 要改成 192.168.56.1，所以数据包的内容是：</p><ul><li>源 MAC：192.168.56.1 的 MAC</li><li>目标 MAC：192.168.56.2 的 MAC</li><li>源 IP：192.168.56.1</li><li>目标 IP：192.168.56.2</li></ul><p>    包到达 192.168.56.2 这个网口后，发现 MAC 一致，就将包收进来。</p><p>    而路由器 B 是 NAT 网关，它上面配置了，国际身份 192.168.56.2 对应国内的 192.168.1.101，于是目标地址改为 192.168.1.101。</p><p>    同样的，路由器 B 中配置了规则：</p><blockquote> 想访问 192.168.1.101，就从 192.168.1.1 网口出去，没有下一跳。<br/> </blockquote><p>    于是，数据包就从 192.168.1.1 这个网口发给 192.168.1.101。</p><p><b>3）网关 B 到服务器 B</b><br/>数据包从 192.168.1.1 网口发出后，同样经过这些步骤：</p><ol><li>检查服务器 B 的 IP，在同一网段</li><li>ARP 获取服务器 B 的 MAC 地址</li><li>发送包</li></ol><p>这时的数据包就变成了：</p><ul><li>源 MAC：192.168.1.1 的 MAC</li><li>目标 MAC：192.168.1.101 的 MAC</li><li>源 IP：192.168.56.1</li><li>目标 IP：192.168.1.101</li></ul><p>    服务器收到包后，检查 MAC 地址一致，就将数据包收进来。</p><p>    从服务器 B 接收的数据包可以看出，源 IP 为 服务器 A 的国际身份，因而发送返回包的时候，也发给这个国际身份，由路由器 A 做 NAT，转换为国内身份。</p><h3>动态路由</h3><h3>动态路由算法</h3><h3>距离矢量路由算法</h3><p><b>1）基本思路</b></p><blockquote> 基于Bellman-Ford 算法。每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到目标路由器，从哪条线出去，另一个是到目标路由器的距离<br/> </blockquote><p><b>2）存在问题</b></p><p>a. <b>好消息传得块，坏消息传的慢</b>。</p><blockquote> 新加入的路由器能够很快的新路由器信息广播出去。但是如果一个路由器挂了，挂的消息没有广播。每个经过这个宕机节点的路由器，无法得知该节点一宕机，而是试图通过其他的路径访问，直到试过了所有的路径，才发现这个路由器已经宕机了。<br/> </blockquote><p>示例：</p><p>b. <b>每次发送消息，要发送整个全局路由表</b></p><p>    上面的两个问题，限制了<b><i>距离矢量路由</i></b>的网络规模，仅适用于小型网络（小于 15 跳）。</p><h3>链路状态路由算法</h3><p><b>1）基本思路</b></p><blockquote> 基于Dijkstra 算法。当一个路由器加入网络是，首先是发现邻居，给邻居说 hello，邻居都回复。然后计算和邻居的距离，发送一个 echo，要求马上返回，除以 2 就是距离。接着将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。<br/> </blockquote><p>    这种算法中，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用 Dijkstra 算法，找到两点之间的最短路径。</p><p>    不像距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了宽带和 CPU 利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。</p><h3>动态路由协议</h3><h3>基于链路状态路由算法的 OSPF</h3><blockquote> OSPF（Open Shortest Path First, 开放式最短路径优先）协议，广泛应用在<b><i>数据中心</i></b>的协议。由于主要用在数据中心内部，用于路由决策，因此称为<b><i>内部网关协议（Interior Gateway Protocol，简称 IGP）</i></b><br/> </blockquote><p>    内部网关协议的重点就是<b><i>找到最短路径</i></b>。当存在多个最短路径时，可以在这多个路径中进行负载均衡，这常常被称为<b><i>等价路由</i></b>。</p><p>    等价路由不仅可以用来分摊流量，还可以提高容错率，当一条路径不通时，还可以通过另外一条路到达目的地。</p><h3>基于距离矢量路由算法的 BGP</h3><blockquote> 针对网络之间的路由协议，称为<b><i>外网路由协议（Border Gateway Protocol，简称 BGP）</i></b><br/> </blockquote><p>    每个数据中心都有自己的路由配置。例如，哪些外部 IP 可以让内部知晓，哪些内部 IP 可以让外部知晓，哪些可以通过，哪些不能通过。</p><p>    因此，在各个数据中心进行交互时，需要一种协议，通过这种协议，可以知道相邻数据中心的路由配置，从而找到数据中心之间最好的路由。</p><p>    BGP 协议就是这样的协议。它不着眼于发现和计算路由，而在于控制路由的传播和选择最好的路由。</p><h2>总结</h2><ul><li>数据包要离开本局域网，就要经过网关，网关就是路由器的一个网口；</li><li>路由器是一个三层设备，理由有如何寻找下一跳的规则；</li><li>经过路由器之后的 MAC 头肯定会变。如果 IP 不变，就是 <b>转发网关</b>，否则就是 <b>NAT网关</b>；</li><li>路由分静态路由和动态路由，动态路由可以配置复杂的策略路由，控制转发策略；</li><li>动态路由主流算法有两种，距离矢量算法和链路状态算法。基于两种算法产生两种协议，BGP 协议和 OSPF 协议。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82184458", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 0, 
            "title": "网络协议 5 - ICMP 与 Ping", 
            "content": "<p>日常开发中，我们经常会碰到查询网络是否畅通以及域名对应 IP 地址等小需求，这时候用的最多的应该就是 ping 命令了。 那你知道 ping 命令是怎么工作的吗？今天，我们就来一起认识下 ping 命令及其对应的 ICMP 协议。</p><h3>ICMP 协议</h3><p>    ICMP 全称 Internet Control Message Protocol，指<b>互联网控制报文协议</b>。</p><p>    网络本身是不可靠的，数据包在传输过程中，可能会发生很多突发事件并导致数据传输失败。而网络层的 IP 协议是一个无连接的协议，它不会处理网络层的故障，因此，我们需要其它的协议，在数据包传输出现故障时，能将故障信息传回来，这样才能对应处理相关问题。</p><p>    就像在电视剧里看到的古代战争一样，打仗的时候需要通过斥候来传递战局情况，进而更好的控制战局。而 ICMP 报文在网络世界中就充当“斥候”这样的角色。</p><p>    ICMP 报文是封装在 IP 包里面的。因为传输指令的时候，肯定需要源地址和目标地址。它本身格式非常简单，如下图：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9af6b295657c6ac8e8e15c78db39369c_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-9af6b295657c6ac8e8e15c78db39369c_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    ICMP 报文有很多的类型，不同的类型有不同的代码，<b>最常用的类型是主动请求，代码为 8，主动请求的应答，代码为 0</b>。从大的方面看可以分为 <b>查询报文类型</b>和<b>差错报文类型</b>。</p><h3>查询报文类型</h3><p>    我们经常在电视剧里听到这样的话：来人，前方战事如何？斥候回来没？一有情况，立刻通报。</p><p>    类似这种主帅发起，主动查看敌情的情况，就对应着 <b>ICMP的查询报文类型</b>。例如，常见的 ping 命令就是<b>查询报文，是一种主动请求，并且获得主动应答的 ICMP 协议</b>。因此，ping 命令发出的包也是符合 ICMP 协议格式的，只不过它在后面增加了自己的格式。</p><p>    对 ping 的主动请求，进行网络抓包，称为 <b>ICMP ECHO REQUEST</b>。同理，主动请求的回复，称为<b>ICMP ECHO REPLY</b>。比起原生的 ICMP，这里面多了两个字段，一个是标识符，另一个是序号。这不难理解，大帅派出去两队斥候，一队是找谁要的，一队是侦查战况的，要有个标识才能区分。</p><p>    另一方面，派出去的斥候，都要编个号。如果派出去 10 个，回来 10 个，就说明前方战况不错。如果派出去 10 个，回来 2 个，就说明情况可能不妙。</p><p>    在选项数据中，ping 还会存放发送请求的时间值，来计算往返时间，说明路程的长短。</p><h3>差错报文类型</h3><p>    差错报文主要是用来<b>将发送的出错报文相关信息返回到源设备，以供源设备确定如果更好的重发失败的数据包</b>。</p><p>    还是拿我们的“大帅”举例。</p><p>    当主帅正在大帐中看地图，思考战事时，外面的小兵突然喊到：大帅，不好啦，张将军遭遇埋伏，全军覆没了。</p><p>    这种是异常情况发起的，来报告发生了不好的事情，对应 ICMP 的差错报文。</p><p>    差错报文有以下常用的类型：</p><ul><li>3：终点不可达</li><li>4：源抑制</li><li>5：重定向</li><li>11：超时</li></ul><p><b>第一种情况终点不可达</b>。小兵报告，大帅，送给张将军的粮草没有送到。</p><p>    那大帅肯定会问，为啥没有送到？这就对应 ICMP 中的以下代码了。</p><ul><li>网络不可达代码：0</li><li>主机不可达代码：1</li><li>协议不可达：2</li><li>端口不可达：3</li><li>需要进行分片但设置了不分片：4</li></ul><p>    具体的场景就像这样：</p><ul><li>网络不可达：大帅，找不到地方</li><li>主机不可达：大帅，找到地方，没找到张将军</li><li>协议不可达：大帅，找到地方，也找到人了，但是口令没对上。</li><li>端口不可达：大帅，找到地方，找到了人，也对上了口令，但事情没对上。我去送粮草，人家说在等救兵。</li><li>需要进行分片但设置不分片：大帅，走到一半，山路狭窄，想换瞎扯，但是出发前你下令严禁换小车，就没办法送到了。</li></ul><p><b>第二种是源站抑制</b>。也就是让源站放慢发送速度（小兵：大帅，粮草送的太多了吃不完，你可以慢点送）。</p><p><b>第三种是时间超时</b>。也就是超过网络包的生存时间还是没到目的地（大帅，送粮草的人都把粮食吃完了，还没到地方，已经饿死了）。</p><p><b>第四种是路由重定向</b>。也就是下次发给另一个路由器（大帅，上次送粮草的人本来只要走大王村，一公里就到了，结果非要绕道张家界，多了五公里，下次记得走大王村）。</p><p>    差错报文的结构相对复杂一些。除了前面还是 IP，ICMP 的前 8 个字节不变，后面则跟上出错的那个 IP 包的 IP 头和 IP 正文的前 8 个字节。</p><p>    而且这类斥候特别尽责，不但字节返回来报信，还把一部分遗物带回来。</p><ul><li>斥候：大帅，张将军已经战死沙场，这是他的印信和佩剑。</li><li>大帅：张将军是怎么死的（可以查看 ICMP 的前 8 字节）？没错，这是张将军的剑（IP 数据包的头及正文前 8 字节）。</li></ul><h3>ping：查询报文类型的使用</h3><p>    接下来，我们重点来看 ping 命令的发送和接收过程。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4093a6ce0b7bd6f1887fc8aa99e1cf0e_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-4093a6ce0b7bd6f1887fc8aa99e1cf0e_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    假定主机 A 的 IP 地址是 192.168.1.1，主机 B 的 IP 地址是 192.168.1.2，它们都在同一个子网。那么，当在主机 A 上运行“ping 192.168.1.2” 后，会发生什么呢？</p><ol><li><b>源主机构建 ICMP 请求数据包</b>。这个数据包内包含多个字段。最重要的有两个，一个是<b>类型字段</b>，对应请求数据包而言，该字段为 8。另一个是<b>顺序号</b>，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加 1.为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。</li><li><b>IP 层构建 IP 数据包</b>。ICMP 协议将数据包连同目标 IP 一起交给 IP 层，IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，加上其他控制信息，构建一个 IP 数据包。</li><li><b>加入 MAC 头</b>。找到 192.168.1.2 对应的 MAC 地址，附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。</li></ol><p>    主机 B 收到数据帧后，会进行如下步骤：</p><ol><li><b>检查 MAC 地址，丢弃或接收数据帧，提取 IP 数据包</b>。检查数据包目的 MAC 地址，并与本机 MAC 地址对比。如符合，就接收数据帧，否则就丢弃。接收后检查数据帧，将 IP 数据包从帧中提取处理，交给本机的 IP 层。</li><li><b>IP 层检查IP</b>。检查完成后，提取有用的信息交给 ICMP 协议。</li><li><b>构建 ICMP 应答包</b>。应答数据包的类型字段为 0，顺序号为接收到的请求数据包中的顺序号。</li><li>将应答数据包发给主机 A。</li></ol><p>    在规定的时间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达。</p><p>    如果接收到了应打包，则说明目标主机可达。此时，源主机会检测时间延迟。就是用当前时刻减该数据包从源主机发出去的时刻。</p><p>    当然，这只是最简单的，同个局域网的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等。</p><p>    可以看出，ping 命令是使用了 ICMP 里面的 ECHO REQUEST 和 ECHO REPLY 类型。</p><p>    那其它类型呢？是不是只有真正遇到错误的时候，才能收到？答案是否定的。有一个 Traceroute 命令，它会使用 ICMP 的规则，故意制造一些能够产生错误的场景。</p><h3>Traceroute：差错报文类型的使用</h3><p>    Traceroute 命令有两个比较常用的功能。</p><p>    第一个功能：</p><p><b>通过设置特殊的 TTL，追踪去往目的地时经过的路由器</b></p><p>    Traceroute 的参数执行某个目的 IP 地址，会发送一个 UDP 的数据包。</p><p>    将 TTL 设置成 1 时，表示这个数据包的 MP 为 1，碰到第一个“拦路虎”（通常是路由器或一个其它类型的关卡）就会阵亡了，然后就会返回一个 ICMP 包，这个包就是 <b>网络差错包</b>，类型是<b>时间超时</b>。</p><p>    通过差错包，我们就能得到数据包到第一个关卡时花费的时间及其每个关卡的 IP 地址（有的主机不会响应 ICMP，所以会出现请求时全是 * 的情况）。</p><p>    那怎么知道 UDP 有没有到达目的主机呢？Traceroute 程序会发送一份 UDP 数据包给目的主机，但它会选择一个不可能的值作为 UDP 端口号（大于30000）。当该数据报到达目的主机时，由于找不到对应端口号，所以会返回一个“端口不可达”的错误报文。这样，我们就知道 UDP 是否到达主机了。</p><p>    第二个功能：</p><p><b>设置数据包不分片，确定路径的 MTU</b></p><p>    发送分组，并设置“不分片”标志。发送的第一个分组的长度正好与出口的 MTU 相等。如果中间遇到窄的关卡就会被卡主，返回 ICMP 网络差错包，类型是“需要进行分片但设置了不分片”。就这样，每次收到ICMP“不能分片”差错时就减小分组的长度，从而确定整个路径中的 MTU。</p><h3>总结</h3><ul><li>ICMP 相当于网络世界的侦察兵。常用的有两种类型，主动探查的查询报文和异常报告的差错报文。</li><li>ping 命令使用查询报文，Traceroute 命令使用差错报文。</li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p><br/> </p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82184353", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 0, 
            "title": "网络协议 4 - 交换机与 VLAN：拓扑结构", 
            "content": "<p>上一次，我们通过宿舍联网打魔兽的需求，认识了如何通过物理层和链路层组建一个宿舍局域网。今天，让我们切换到稍微复杂点的场景，办公室。</p><p>    在这个场景里，就不像在宿舍那样，搞几根网线，拉一拉，扯一扯就可以了。一个办公室少到数十人，大至上百人，每个人都有一个网口，如果再算上整个楼层楼层、甚至整栋楼，这个网口就更多了。</p><p>    类似办公室这样，这些复杂场景的网络布线就牵扯出一个专业名词-<b>拓扑结构</b>。</p><h3>什么是拓扑结构？</h3><p>    在解释拓扑结构前，我们要先明白什么是拓扑。拓扑是 Topology 的音译，直译是地志学，最早指研究地形、地貌相类似的有关学科。现在是研究几何图形或空间在连续改变形状后还能保持不变的一些性质的一个学科。</p><p>    计算机网络的拓扑结构是引用拓扑学中研究<b>与大小、形状无关的点、线关系的方法</b>，把网络中的计算机和通信设备抽象为一个点，把传输介质抽象为一条线，<b>由点和线组成的几何图形</b>就是计算机网络的<b>拓扑结构</b>。</p><h3>办公室拓扑结构的形成</h3><p>    上面说过，每个办公室会有几十个甚至上百个网口。这个时候，一个交换机肯定不够用，需要多台交换机连接，而多台交换机连接就形成了一个稍微复杂的拓扑结构。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ccf7a4781e94fc566da2a04846ced9ef_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-ccf7a4781e94fc566da2a04846ced9ef_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    我们先来看两台交换机的情形。两台交换机连接着三个局域网，每个局域网上都有多台机器。如果机器 1 只知道机器 4 的 IP 地址，当它想要访问机器 4 时，把包发出去的时候，它必须知道机器 4 的 MAC 地址。我们来看看这个过程：</p><ul><li>机器 1 发起广播，机器 2 和交换机 A 都收到广播。机器 2 收到广播后，知道不是找它的，所以没它什么事。</li><li>交换机 A 一开始是不知道任何拓扑信息的，在它收到这个广播后，采取的策略是，除了广播包来的方向外，它还要转发给其他所有的网口。</li><li>机器 3 和交换机 B 收到了广播信息了，同样的，机器 3 也知道和它没什么关系。</li><li>交换机 B 收到广播信息后，这时候它也不知道任何拓扑信息，所以也进行广播，将包转发到局域网三，也就是机器 4 和机器 5。</li><li>机器 4 收到广播是，它发现是找它的，就主动响应说，这是找我的，我的 MAC 地址是 XXX。</li></ul><p>    在机器 1 收到机器 4 的 MAC 地址后，一个 ARP 请求就成功完成了。</p><p>    在上面过程中，交换机 A 和交换机 B 都是能够学习到这样的信息：</p><ul><li>机器 1 是在左边这个网口。</li></ul><p>    当了解这样的信息后，如果机器 2 访问 机器 1，机器 2 发起一个 ARP 请求获取机器 1 的 MAC 地址，这个广播消息会发给机器 1 和交换机 A。这个时候交换机 A 已经知道机器 1 是在左边的网卡，所以它就不会将请求广播到局域网二和局域网三。</p><p>    就这样，当交换机学习完所有的拓扑信息后，两台交换机工作得会越来越好。</p><p>    但是随着办公室越来越大，交换机数量肯定会越来越多，当整个拓扑结构复杂，这么多网线绕来绕去，不可避免的就会出现一些意料之外的情况，其中最常见的问题就是<b>环路问题</b>。</p><h3>环路与广播风暴</h3><p>    如下图。当两个交换机环路连接两个局域网时，你知道会出现什么结果吗？<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-5777e5991381276bfb62eb34b1cb44d2_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-5777e5991381276bfb62eb34b1cb44d2_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    我们来想象下机器 1 访问机器 2 的过程。</p><ul><li>机器 1 发起 ARP 广播</li><li>机器 2 收到广播，把 MAC 地址返回。</li></ul><p>    咦，整个过程很顺利，没什么问题。</p><p>    但是我们忽略了，两个交换机也是能收到广播包的。我们来看看两个交换机的广播过程：</p><ol><li>交换机 A 开始不知道拓扑信息，于是将广播信息放到局域网二</li><li>消息在局域网二广播，交换机 B 右网卡收到广播消息，于是将信息放到局域网一</li><li>消息在局域网一广播，交换机 A 左网口收到消息，又将广播信息放到局域网二</li><li>......</li></ol><p>    看出来了吗？这样一直广播，就会形成一个环路，最终成为<b>广播风暴</b>，直到网络瘫痪。</p><p>上面过程，可能会有人说，两台交换机逐渐学习到拓扑结构后 ，是不是就可以了？那就让我们来看下它们的学习过程：</p><ol><li>在局域网一，交换机 A、B 收到机器 1 的广播包后，知道机器 1 都是在<b>左网口</b></li><li>当广播放到局域网二后，交换机 B <b>右网口</b>又收到了来自机器 1 的广播包，于是就误会机器 1 换位置了，就记住了机器 1 是在<b>右网口</b>，把之前学习到的信息清理掉</li><li>同理，交换机 A 右网口收到了机器 1 的广播包，同样误会了，于是也学会了，机器 1 在<b>右网口</b>，不是在左网口</li></ol><p>    就这样，两个交换机会不断刷新“三观”，机器 1 是在左网口，过一会，发现不对，机器 1 是在右网口，过了一会，又发现不对，是在左网口。于是，又形成了一个“广播风暴”。</p><p>    那么，有什么方法可以解决环路问题呢？这就到了 STP 协议出场的时候了。</p><h3>STP 协议中那些难以理解的概念</h3><p>    在数据结构中，有一个方法叫作<b>最小生成树</b>。有环的我们常称为<b>图</b>。将图中的环破了，就生成了<b>树</b>。而在计算机网络中，生成树的算法叫作 <b>STP（Spanning Tree Protocol）</b>。</p><p>    STP 协议比较复杂，一开始很难看懂，让我们来通过华山论剑，决出五岳盟主的方式看看生成树的过程。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-874f8dc300a2c8c498a2437c6188f4cf_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-874f8dc300a2c8c498a2437c6188f4cf_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    在 STP 协议里面有很多概念，译名就非常拗口，让我们以门派中的职位来帮助大家理解。</p><ul><li>Root Bridge，也就是<b>根交换机</b>。可以比喻为“掌门”交换机，是某棵树的老大。</li><li>Designated Bridge，也就是<b>指定交换机</b>。这个比较难理解，可以想象成一个“小弟”，对于树来说，就是一棵树的树枝。所谓“指定”的意思是，我拜谁做大哥，其他交换机通过这个交换机到达根交换机，也就相当于拜他做了大哥。这里注意是树枝，不是叶子，因为叶子往往是主机。</li><li>Bridge Protocol Data Units（BPDU），<b>网桥协议数据单元</b>。可以比喻为“相互比较实力“的协议。行走江湖，比的就是武功，拼的就是实力。当两个交换机碰见的时候，也就是相连的时候，就需要互相比比内力。BPDU 只有掌门能发，隶属于某个掌门的交换机只能传达掌门的指示。</li><li>Priority Vector，<b>优先级向量</b>。可以比喻为实力（值越小越牛）。实力是啥？就是一组 ID，[Root Bridge ID, Root Path Cost, Bridge ID, and Port ID]。为什么这样设计呢？这是因为要看怎么来比实力。先看 Root Bridge ID，也就是老大的 ID，发现掌门一样，那就是师兄弟；再比 Root Path Cost，也就是我距离我老大的距离，也就是拿和掌门的关系比，看同一个门派内谁和老大关系铁；最后比 Bridge ID，比我自己的 ID，拿自己的本事比。</li></ul><p>    概念都准备好了，下面我们看看 STP 是怎么工作的。</p><h3>STP 的工作过程</h3><p>    一开始，江湖纷争，异常混乱。大家都觉得自己是掌门，谁也不服谁。于是，所有的交换机都认为自己是掌门，每个网桥都分配了一个 ID。这个 ID 里有管理员分配的优先级，当然管理员指定哪些交换机性能好，就给它们分配高的优先级。这种交换机生下来武功就很高，起步就是乔峰。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e8d7a61c9b5c888efe842a4b8331bd31_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-e8d7a61c9b5c888efe842a4b8331bd31_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    既然都是掌门，互相都连长网线，那就互相发送 BPDU 来比功夫呗。这一比就发现，有人是岳不群，有人是封不平。赢的人接着做掌门，输的就只好做小弟了。当掌门的还会继续发 BPDU，而输的人就没有机会了，它们就只有在收到掌门发的 BPDU 的时候，转发一下，表示服从命令。</p><p>    数字表示优先级。就像上面的图，5 和 6 碰见了，6 的优先级低（数字越小，优先级越高），所以乖乖做小弟。于是，一个小门派形成，5 是掌门，6 是小弟。其他诸如 1-7、2-8、3-4 这样的小门派也诞生了。接着，这些小的门派就好相互合并。</p><p>    合并的过程会出现以下四种情形。</p><h3>情形一：掌门遇见掌门</h3><p>    当 5 碰到了 1，掌门碰见掌门，1 觉得自己是掌门，5 也刚刚跟别人 PK 完，成为掌门。这俩掌门比功夫，最终 1 胜出，于是 5 就率领所有的小弟归顺。结果就是 1 成功大掌门。</p><h3>情形二：同门相遇</h3><p>    同门相遇可以是掌门与自己的小弟相遇，这说明存在“环”了。这个小弟已经通过其他门路拜在你门下，结果你还不认识，还 PK 了一把。结果掌门发现这个小弟功夫不错，不应该级别这么低，就把它招到门下亲自带，那这个小弟就相当于升职了。</p><p>    我们再来看，假如 1 和 6 相遇。6 原来就拜在 1 的门下，只不过 6 的上司是 5，5 的上司是 1。1 发现，6 距离我只有 2，比从 5 这里过来的 5（=4+1）近多了，那 6 就直接向我汇报吧。于是，5 和 6 分别汇报给 1。</p><p>    同门相遇还可以是小弟相遇。这个时候就要比较谁和掌门的关系近。近的当大哥。刚才 5 和 6 同时向 1 汇报，后来 5 和 6 相遇比功夫的时候发现，5 你直接汇报给 1 距离是 4，如果 5 汇报给 6 再汇报给 1 ，距离只有 2+1=3，所以 5 干脆拜 6 为上司。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e8d7a61c9b5c888efe842a4b8331bd31_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-e8d7a61c9b5c888efe842a4b8331bd31_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h3>情形三：掌门与其他帮派小弟相遇</h3><p>    小弟拿本帮掌门和这个掌门比，赢了，这个掌门就拜入门下，输了，就拜入新掌门，并且会主键拉拢和自己连接的兄弟，一起“弃暗投明”。</p><p>    例如，2 和 7 相遇，虽然 7 是小弟，2 是掌门，就个人武功而言，2 比 7 强，但是 7 的掌门是 1，比 2 牛，所以没办法，2 要拜入 7 的门派，并且连同自己的小弟都一起拜入。</p><h3>情形四：不同小弟相遇</h3><p>    各自拿掌门比较，输了的拜入赢的门派，并且逐渐将与自己连接的兄弟拉入新门派。</p><p>    例如，5 和 4 相遇。虽然 4 的武功好于 5，但是 5 的掌门是 1，比 4 牛，于是 4 拜入 5 的门派。后来当 3 和 4 相遇的时候，3 发现 4 已经“叛变”了，4 说我现在老大是 1，比你牛，要不你也来吧，于是 3 也拜入 1。</p><p>    最红，生成一棵树，武林一统，天下太平。但是天下统一久了，也会有相应问题。常见的有<b>广播和安全问题</b>。</p><h3>广播和安全问题</h3><p>    机器多了，交换机也多了，就算交换机比 Hub 智能一些，但是还是难免有广播的问题。一大堆机器，相关的部门、不相关的部门，广播一大堆，性能就下来了。</p><p>    就像一家公司，创业的时候，十来个人，坐在一个会议室，有事情大家讨论下，非常方便。当时如果变成了 50 个，全在一个会议室吵吵，就会乱的不得了。</p><p>    另一方面，一个公司里，有的部门需要保密，比如人事部门，肯定要讨论升职加薪的事情。但是如果在一个广播域里，碰到一个会抓包的程序员，就能看的没有加密的敏感信息。</p><p>    那咋办？能咋办，分部门，分会议室呗，让我们来看看怎么分。</p><p>    有两种分的方法。一个是<b>物理隔离</b>。每个部门设一个单独的会议室，对应到网络方面，就是每个部门有单独的交换机，配置单独的子网。这样部门之间的沟通就需要路由器了。</p><p>    这样的问题在于，有的部门人多，有的部门人少，而且部门的人数也会频繁发生变化，如果每个部门有单独的交换机，网口多了浪费，少了又不够用。</p><p>    这时候，<b>虚拟隔离</b>就出来了。虚拟隔离，就是我们常说的 VLAN，或者叫做<b>虚拟局域网</b>。</p><p>    使用 VLAN，一个交换机上会连属于多个局域网的机器，那交换机是怎么区分哪个机器属于哪个局域网呢？</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b992ecf71f2d805711f7c2a67c405bec_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-b992ecf71f2d805711f7c2a67c405bec_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    我们只需要在原来的二层头上加一个 TAG，里面有个 VLAN ID，共 12 位，可以划分 4096 个 VLAN。对于普通办公室，这个数量应该是够用的。</p><p>    如果我们买的交换机支持 VLAN，当这个交换机把二层的头取下来的时候，就能够识别这个 VLAN ID。这样只有相同的 VLAN 的包，才会互相转发，不同 VLAN 的包，是看不到的。</p><p>    这样，广播和安全问题就能够解决了。</p><p>这样，复杂的办公室网络布线就被我们用交换机与 VALN 搞定了。<br/> </p><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/82184208", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 2, 
            "title": "网络协议 3 - 物理层 和 MAC 层", 
            "content": "<p>在上一篇博文中，我们见证了 IP 地址的诞生，机器一旦有了 IP，就可以在网络的环境里和其他的机器展开沟通了。</p><p>    今天，我们来认识下 <b>物理层</b> 和 <b>MAC</b> 层。</p><p>    日常生活中，身为 90 后的我们，如果不是通信相关专业出身的，应该从来没有接触过物理层和 MAC 层的设备。我们接触最多的，可能就是路由器了。而路由器实际上是第三层-网络层的设备了。</p><p>    那咱们怎么认识物理层呢？就不扯那些深奥的理论了，从宿舍联机打魔兽说起吧。</p><p>    要想宿舍里的几台电脑连接到一个局域网内，第一反应就是买个路由器，大家都连上去就 OK 了。但是在 15 年前，路由器还没有那么普及的时候，你在校园里找个通信专业的学生问，知道怎么组建宿舍局域网吗？他应该会回答你，有三种方式：</p><ol><li>网线连接</li><li>集线器连接</li><li>交换机</li></ol><h3>物理层</h3><p>    上面三种方式中，网线连接和集线器是完全在物理层工作，咱们就先见识下这两种方式。</p><p>网线连接</p><p>    是的，你没看错，是用一根网线连接在两个电脑上。网线水晶头的第 1、2 和第 3、6脚，分别起着发、收信号的作用，要想通过一根网线将两台电脑连接在一个局域网上，需要额外做的操作就是将网线其中一端的 1 号和 3 号线、2 号和 6 号线互换一下位置，这样就能在物理层实现一端发送的信号，另一端成功接收。</p><p>    当然，除了通过网线连接外，我们还需要配置这两台电脑的 IP 地址、子网掩码和默认网关，将这三项配置成为一个网络，否则是不通的。</p><p>    这样，一个宿舍的两台电脑就可以联机打魔兽了。</p><p>    问题来，如果又有一个舍友买了电脑，怎么把三台电脑连一起呢？先别说交换机这高档的东西，对于 15 年前的大学生来说，交换机太贵了，买不起。好在除了交换机外，还有个叫做 Hub 的东西，也就是<b>集线器</b>。</p><p>集线器</p><p>    这种设备有多个口，可以将宿舍里的多台电脑连接起来。和交换机不同的是，集线器很“傻”，它没有大脑，<b>完全在物理层工作</b>，将自己收到的每一个字节，都复制到其它端口上去。</p><p>    这就像，小明想找小红表白，他不知道小红在哪个小区，于是他就找其它小伙伴，让每个小伙伴负责一个小区，去每一户问是不是小红家，找到小红的小伙伴就将表白语告诉小红。</p><h3>数据链路层</h3><p>    上面通过 Hub 实现局域网的方式，你可能已经发现了，Hub 采取的是<b>广播</b>的模式。如果每一台电脑发出的包，局域网内的其它电脑都能收到，那就麻烦了。这就需要解决几个问题：</p><ol><li>这个包是发给谁的？谁接收？</li><li>大家都在发生消息，会不会产生混乱？有没有先后的规则？</li><li>如果发生的时候出错了，怎么办？</li></ol><p>    这几个问题，都是数据链路层，也就是 MAC 层要解决的问题。MAC 的全称是 <b>Medium Access Control</b>，即<b>媒体介质访问控制</b>。这里的控制，其实就是控制在往媒体上发数据时，谁先发、谁后发的问题，也就是<b>防止发生混乱</b>。这就解决了第二个问题。这个问题中的规则，学名叫<b>多路访问</b>。和我们交通管制一样，常见的有下面三种方式：</p><ul><li>方式一：分车道。每个车一个车道，你走你的，我走我的，互不干扰。这在计算机网络中叫做<b>信道划分</b>；</li><li>方式二：今天单号出现，明天双号出现，轮着来。这叫做<b>轮流协议</b>；</li><li>方式三：不管三七二十一，有事先出门，发现很堵，就回去等待 ，错过高峰期再走。这叫做<b>随机接入协议</b>。著名的以太网，用的就是这种方式。</li></ul><p>    要解决第一个问题：发给谁？谁接收？这里用到一个物理地址，叫做<b>链路层地址</b>。但是因为第二层主要解决媒体接入控制的问题，所以它常常被称为 MAC 地址。</p><p>    解决第一个问题就牵扯到第二层的<b>网络包格式</b>。对于以太网，第二层的最开始，就是目标 MAC 地址和源 MAC 地址。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-71dcd93178530731d1b46f72ef90edcc_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-71dcd93178530731d1b46f72ef90edcc_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    接下来是<b>类型</b>。大部分的类型是 IP 数据包，其中 IP 里面包含 TCP、UDP，以及 HTTP 等，这些都是里层封装的事情。</p><p>    有了这个目标 MAC 地址，数据包在链路上广播，MAC 的网卡才能发现，这个包是给它的。MAC 的网卡把包收进来，然后打开 IP 包，发现 IP 地址也是自己的，再打开 TCP 包，发现端口是 80，而 nginx 就是监听 80 端口。</p><p>    于是就将请求提交给 nginx，nginx 返回一个网页，最后再经过层层封装，返回到 MAC 层。因为来的时候有源 MAC 地址，返回的时候，源 MAC 地址就变成了目标 MAC 地址，再返给请求的机器。</p><p>    对于以太网，第二层的最后面是 CRC，也就是<b>循环冗余检测</b>。通过 XOR 异或的算法，来计算整个包是否在发送的过程中出现了错误，这主要解决了第三个问题。</p><p>    这里还有一个没有解决的问题，当源机器知道目标机器的时候，可以将模板地址放入包里。如果不知道呢？一个广播的网络里面接入了 N 台地址，我怎么知道每个 MAC 地址是谁呢？这就是 ARP 协议，也就是已知 IP 地址，求 MAC 地址的协议<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-ea9e5f165cc6070dfb834624f2962ae6_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-ea9e5f165cc6070dfb834624f2962ae6_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    在一个局域网里，如果知道了 IP 地址，不知道 MAC 地址怎么办？这个在<a href=\"https://link.zhihu.com/?target=https%3A//www.cnblogs.com/BeiGuo-FengGuang/p/9848805.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">网络协议-概述</a>中有提过，本地通信靠“吼”。</p><p>    发送一个广播包，广而告之，谁说这个 IP 谁来回答。具体询问和回答的报文就像下面这样：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-bd08548e500e7c145492c2cb0d4a3e36_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-bd08548e500e7c145492c2cb0d4a3e36_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    为了避免每次都用 ARP 协议，机器本地会进行 ARP 缓存。当然，缓存的 MAC 地址会有一个过期时间。</p><p>    上面解决了广播发出的包，局域网内所有机器都能收到的问题。那么 Hub 是采用怎么样的方式？</p><p>    实际上，Hub 不管某个接口是否需要，所有的数据都会发送出去，然后让主机来判断是否需要相关数据。这种方式会有两个问题：</p><ol><li>机器数目大幅增多后，产生冲突的概率就提高了。这很好理解，那么多小伙伴去找小红，发生交通事故的概率要大于，直接去她家表白发生交通事故的概率；</li><li>把大量不需要发送的包发送出去，浪费资源。</li></ol><p>    明显可以看出，要解决上面两个问题，只要我们知道哪个接口对应哪个 MAC 地址就好了。如果目标 MAC 地址不是这台电脑的，这个口就不用转发了。</p><p>    那么，谁能知道目标 MAC 地址是否就是连接某个口的电脑的 MAC 地址呢？这就需要一个能把 MAC 头拿下来，检查一下目标 MAC 地址，然后根据策略转发的设备，也就是我们之前提过的，<b>二层设备-交换机</b>。</p><p>    交换机怎么知道每个口对应的电脑的 MAC 地址呢？这需要交换机<b>能学习</b>。这个也是交换机和 Hub 最明显的区别。</p><p>    一台 MAC1 电脑将一个包发送给另一台 MAC2 电脑，当这个包到达交换机的时候，一开始交换机也不知道 MAC2 电脑再哪个口，所以没办法，它只能将包转发给除了来的那个口之外的其他所有的口。但是，这个时候，交换机会干一件很聪明的事情，就是交换机记住，MAC1 是来自一个明确的口，以后有包的目的地址是 MAC1 的，就直接发送到对应口就可以了。</p><p>    当交换机作为一个关卡一样，过来一段时间后，就有了整个网络的一个结构了。这个时候，基本上不用广播，全部可以准确转发。而交换机学习的结果，我们成为<b>转发表</b>。当然，每台机器的 IP 地址会变，所在的口也会变，所以转发表也是有一个过期时间的。</p><h3>小结</h3><p>上面扯了一大堆，实际上也就是几句话的事：</p><ul><li>MAC 层是用来解决多路访问的堵车问题的</li><li>ARP 是通过“吼”的方式来寻找目标 MAC 地址，之后会记住一段时间，这个叫做 <b>ARP 缓存</b></li><li>交换机是升级版的 Hub，它有 MAC 地址学习能力，学完就能记住每个 MAC 地址对应哪个口，学习的成果叫<b>转发表</b></li></ul><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": [
                {
                    "userName": "PineAndMoon", 
                    "userLink": "https://www.zhihu.com/people/4a2bc6d7892fa4f8b868b9c5c087b28b", 
                    "content": "“交换机是升级版的 Hub”这句话有很大问题，Hub是典型的共享信道。而与交换机连接的信道是独享信道。", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "wei ding", 
                            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
                            "content": "Hub是共享式宽带，设备之间容易产生冲突，交换机更加完善设备的并行通讯打破的冲突域，这是升级版的意思。", 
                            "likes": 0, 
                            "replyToAuthor": "PineAndMoon"
                        }
                    ]
                }, 
                {
                    "userName": "萤火", 
                    "userLink": "https://www.zhihu.com/people/540d3690a31bf6d6803363f2fdc194be", 
                    "content": "<p>讲的挺好~</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/81799591", 
            "userName": "wei ding", 
            "userLink": "https://www.zhihu.com/people/272f67f4b9d0808e59a90fb7ec5e925b", 
            "upvote": 1, 
            "title": "网络协议 2 - IP 地址和 MAC 地址", 
            "content": "<p>了解完网络协议，我们会发现，网络通信的五层模型里，有两个很重要的概念：IP 地址和 MAC 地址。</p><p>那么 IP 地址是怎么来的，又是怎么没的？MAC 地址与 IP 地址又有什么区别？</p><p>这回答上面问题前，先热下身，大家知道如何查看本机的 IP 吗？这个问题，即便是没有专业学过计算机的人，只要折腾过电脑，重装过系统，大多都会知道答案：在 Windows 下是 ipconfig，在 linux 下是 ifconfig。</p><p>在 Windows 下输入 ipconfig，我们会看到这个界面：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-52495937266f7fc23f3f51c445b443eb_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-52495937266f7fc23f3f51c445b443eb_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>在 linux 下输入 ifconfig，我们会看到这个界面：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e348dd6228447806072804c9e8fcfc9d_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-e348dd6228447806072804c9e8fcfc9d_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>IP 地址</h2><p>可以看到，无论是在 Windows 还是在 linux 下，输入相关命令都能显示出这台机器上所有的网卡。大部分的网卡都会有一个 IP 地址。就像 192.168.1.73 ，就是我本机以太网的 IP 地址。</p><blockquote> IP 地址是<b>一个网卡</b>在网络世界中的通讯地址，相当于我们现实世界的门牌号码。<br/> </blockquote><p>注意，IP 地址是网卡的通讯地址，不是一台机器的通讯地址。很多时候，我们会说一个电脑只有一个 IP 地址，这种说法实质上并不正确，准确的来说，应该是：</p><blockquote> 一个网卡在同一时段只能有一个 IP 地址，一台机器可以有多个 IP 地址。<br/> </blockquote><p>就像我们的笔记本，一般都会有线网卡和无线网卡，则有线网卡有一个 IP 地址，无线网卡也有一个 IP 地址。</p><p>一台机器有多个 IP 地址，那 IP 地址会不会重复呢？其实我们应该会碰到 IP 地址重复的情况。有时候我们电脑弹出网络地址冲突，出现无法上网的情况，那多半就是 IP 地址冲突了。</p><h3>格式</h3><p>就像上面输出的结果，192.168.1.73 就是一个 IP 地址。这个地址被点（.）分割为四个部分，每个部分有 8 个 bit，所以 IP 地址总共是 32 位。显然，32 位产生的 IP 地址在当今这个互联网社会，很明显就是&#34;狼多肉少&#34;。于是就有了 IPv6，也就是上面结果中的 fe80::515d:5483:ff4d:6db9/64。这个有 128 位，能满足我们现在的需求了。至于后面会不会出现 IPv8 ，那就看后面互联网世界的发展了。</p><h3>分类</h3><p>我们应该都听说过，IP 地址分为 A、B、C、D、E 五类。对于 A、B、C 类，主要分两部分，前面一部分是网络号，后面一部分是主机号。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-6ef30c8fafd7a8df850e1352933d123a_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-6ef30c8fafd7a8df850e1352933d123a_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>下图是 A、B、C 三类地址所能包含的主机数量。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-60c65ca6cc1cd8156c766103c802ebfa_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-60c65ca6cc1cd8156c766103c802ebfa_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>这里面有个问题，C 类地址包含的主机数量太少，而 B 类地址包含的主机数量又太多，于是就有了一个折中的方式叫做<b>无类型域间选路</b>。</p><h3>无类型域间选路</h3><p>顾名思义，无类型域间选路（CIDR）基本思想是<b>取消地址的分类结构，取而代之的是允许以可变长分界的方式分配网络数</b>。192.168.1.73/24 就是无类型域间选路格式的 IP 地址。这种格式的 IP 地址，将 32 位的 IP 地址一分为二，前面是网络号，后面是主机号。从哪里分呢？如果注意观察的话可以看到，上面地址中有一个斜杠，斜杠后一个数字 24。这个 24 的含义就是，前24 位是网络号，后 8 位是主机号。</p><h3>公有 IP 地址和私有 IP 地址</h3><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9289ea58fe6c837e4f98dc8003419c6a_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic3.zhimg.com/v2-9289ea58fe6c837e4f98dc8003419c6a_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>继续看上面的表格。表格最右列是私有 IP 地址段。平时我们在一个局域网内，看到的 IP 地址都是私有 IP 地址。因为这些地址允许组织内部的 IT 人员自己管理和分配，而且还可以重复。所以会出现你局域网的私有 IP 地址段和我局域网的是一样的。</p><p>就像我们上面说的，小明在自己家里给<b>同单元</b>的小伙伴说自己是五单元 101 号，小伙伴能理解，但是他如果这样和小红说，小红就会问，你是哪个小区的？这里的小区实际上就是公有 IP 地址，而五单元 101 号就是私有 IP 地址。</p><p>表格中的 192.168.0.x 是最常见的私有 IP 地址段。就像我们家里的路由器地址一般是 192.168.0.1 一样。</p><h3>IP 分配与释放</h3><p>IP 分配我们平时应该接触比较少。还记得在大学的时候，刚入学第一件事就是赶紧交网费。交网费时会有一个步骤，网管会让你提供 MAC 地址，然后把 IP 地址和 MAC 地址绑定，这也就是博主在隔壁宿舍无法通过网线上网的原因。</p><p>其实，如果你有相关的知识积累，可以用命令行自己配置 IP 地址。当然，能不能通信就看你的知识储备量了。</p><p>除了命令行配置外，我们平时应该对于 IP 分配应该都是用的 &#34;拿来主义&#34;。无论是在学校还是在办公室，都会有网络管理员把分配好的 IP 给你，直接使用就可以了。但是有时候也会好奇，网管是怎么分配 IP 的呢？难不成通过命令行一个个配置？这时候就要用到<b>动态主机配置协议（DHCP）</b>。</p><p>动态主机配置协议</p><p>这个协议的工作原理是怎样的呢？我们就拿一台机器新加入一个网络为例，来走一遍 DHCP 的工作流程。</p><p>当一台机器新加入一个网络时，肯定一脸懵逼，啥情况也不知道，只知道自己的 MAC 地址。没人理你怎么办？那不管三七二十一，先吼一声，告诉所有人，我来了，有人吗？这时候的沟通基本靠&#34;吼&#34;。这一步，我们称为 DHCP Discover。</p><p>新来的机器使用 IP 地址 0.0.0.0 发送了一个广播包，目的 IP 地址是 255.255.255.255。广播包封装在 UDP 里面，UDP 封装在 BOOTP 里面。在这个广播包里，新人大喊：我是新来的（Boot Request），我的 MAC 地址是 xxx，我还没有 IP，谁能给我个 IP 地址？格式就像下面这样：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-25429158d48b96bc338219d3578bdcd7_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic4.zhimg.com/v2-25429158d48b96bc338219d3578bdcd7_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>这时候，网络里的 DHCP Server 就相当于这个局域网的管理员。他知道来了一个&#34;新人&#34;，需要给它分配一个 IP 地址，这个过程就是 DHCP Offer。同时，DHCP Server 保留为此机器提供的 IP 地址，从而不会再将相同的 IP 地址分配给其它的机器。而 DHCP Offer 的格式就像下图，里面有给新人分配的地址。<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c4ed5537cf7deb998e3ec070ad5de988_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-c4ed5537cf7deb998e3ec070ad5de988_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>DHCP Server 仍然使用广播地址作为目的地址，因为，此时请求分配的新人还没有自己的 IP 地址。如果一个局域网中有多个 DHCP Server，这台新机器会收到多个 DHCP Offer。</p><p>它会选择其中一个 DHCP Offer，一般是最先到达的那个，并且会向网络发送一个 DHCP Request 广播数据表，包中包含客户端的 MAC 地址、接受分配的 IP 地址、提供此 IP 的 DHCP 服务器地址等，并告诉所有的 DHCP Server 它将接受哪一台服务器提供的 IP 地址，告诉其他 DHCP 服务器撤销它们提供的 IP 地址，以便提供给下一个 IP 请求分配者。新人广播包格式如下：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5b2e271be0609d0ebfd55ca93ad6c371_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-5b2e271be0609d0ebfd55ca93ad6c371_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>此时，由于还没有得到 DHCP Server 的最后确认，新机器仍然使用 0.0.0.0 为源 IP 地址、255.255.255.255 为目标地址进行广播。</p><p>当 DHCP Server 接收到新机器的 DHCP Request 之后，会广播返回给新机器一个 DHCP ACK 消息包，表明已经接受新机器的选择，并将这一 IP 地址分配信息和其他配置信息都放入该广播包，发给新机器。DHCP ACK 格式如下：<br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-04a74ca8a5acdc46a422b523722da1fd_b.png\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic2.zhimg.com/v2-04a74ca8a5acdc46a422b523722da1fd_b.png\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>新机器收到 DHCP ACK 后，会检测分配的 IP 地址是否能够适应，如果不能使用，它就会给 DHCP Server 发出 DHCP Decline 消息，通知 DHCP Server 禁用这个 IP 地址，然后新机器就开始新的地址申请过程。</p><p>在新机器使用 IP 租期超过 50% 时，DHCP Client 会以单播形式向 DHCP Server 发送 DHCP Request 报文来续租 IP 地址。如果 DHCP Client 成功收到 DHCP Server 发送的 DHCP ACK 报文，则按相应时间延长 IP 地址租期；如果没有收到 DHCP Server 发送的 DHCP ACK 报文，则 DHCP Client 继续使用这个 IP 地址。</p><p>在新机器使用 IP 租期超过 87.5% 时，DHCP Client 会以广播形式向 DHCP Server 发送 DHCPRequest 报文来续租 IP 地址。如果 DHCP Client 成功收到 DHCP Server 发送的 DHCP ACK 报文，则按相应时间延长 IP 地址租期；如果没有收到 DHCP Server 发送的 DHCP ACK 报文，则 DHCP Client 继续使用这个IP地址，直到 IP 地址使用租期到期时，DHCP Client 才会向 DHCP Server 发送 DHCP Release 报文来释放这个 IP 地址，并开始新的 IP 地址申请过程。</p><h2>MAC 地址</h2><p>在我们查询 IP 地址的输出结果中，有一行：</p><blockquote> Link encap:Ethernet HWaddr 28:d2:44:ce:77:51<br/> </blockquote><p>这个被称为 MAC 地址，是一个网卡的物理地址，用十六进制，6 个 byte 表示。</p><p>MAC 地址是一个很容易让人误解的地址。因为 MAC 地址号称全球唯一，不会存在有相同 MAC 地址的网卡。这就很容易让我们想，既然全球唯一，那网络通信直接用 MAC 地址不行吗？为什么要加个 IP 地址，多封装一层，再去通信呢？</p><p>当然是不行的。我们想把一个网络包从一个地方传到另一个地方，除了有确定的地址外，还需要有<b>定位功能</b>。就像你去广州找博主一样，我只告诉你我的身份证号，你能在广州找到我吗？这种寻找无异于大海捞针。但是如果我告诉你我的详细地址，你就可以直接通过导航找到对应的地址，然后再找到我。</p><p>IP 地址在一定程度上就承担了详细地址这种远程地位的功能。MAC 地址更像是身份证号，是一个唯一的标识。它的唯一性设计是为了组网的时候，不同的网卡放在一个网络里面，不用担心冲突。</p><p>当然，MAC 地址也有一定的定位功能。就像你来到了博主所在的办公室，你可以在办公室喊身份证号是 XXX 的是哪位？博主听到了，就会站起来回答你。但是如果你在博主听不到的地方喊，那肯定不会有人应你。这就说明，MAC 地址的通信范围比较小，仅仅局限在一个子网内。</p><p>欢迎添加个人微信号：Like若所思。</p><p>欢迎关注我的公众号，不仅为你推荐最新的博文，还有更多惊喜和资源在等着你!一起学习共同进步！</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\" data-caption=\"\" data-size=\"normal\" class=\"content_image\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https://pic1.zhimg.com/v2-bba073e2b10fc352a369f2dc67d3dd9c_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "网络协议", 
                    "tagLink": "https://api.zhihu.com/topics/19779985"
                }
            ], 
            "comments": [
                {
                    "userName": "steel", 
                    "userLink": "https://www.zhihu.com/people/6dbbb610fb0fb1b81c84cb403087a074", 
                    "content": "mac地址说白了是给网络内部使用的，ip地址是给网络之间用的", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/c_1154812582790541312"
}

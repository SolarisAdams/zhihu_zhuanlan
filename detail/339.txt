{
    "title": "HiTechLoLife_游戏从业笔记", 
    "description": "", 
    "followers": [
        "https://www.zhihu.com/people/gao-yang-44-44-37", 
        "https://www.zhihu.com/people/sakimask", 
        "https://www.zhihu.com/people/li-hao-35-41", 
        "https://www.zhihu.com/people/visionsmile", 
        "https://www.zhihu.com/people/skrwyndham", 
        "https://www.zhihu.com/people/dgkang", 
        "https://www.zhihu.com/people/ning-74-11", 
        "https://www.zhihu.com/people/yao-yi-zheng-84", 
        "https://www.zhihu.com/people/devilwan-zi", 
        "https://www.zhihu.com/people/roskin", 
        "https://www.zhihu.com/people/tkchu", 
        "https://www.zhihu.com/people/5t5t", 
        "https://www.zhihu.com/people/fei-liu-86-57", 
        "https://www.zhihu.com/people/xiaoxx_5", 
        "https://www.zhihu.com/people/xerphong", 
        "https://www.zhihu.com/people/tian-80-70", 
        "https://www.zhihu.com/people/yun-xin-19-72", 
        "https://www.zhihu.com/people/anyway-53-39", 
        "https://www.zhihu.com/people/jaafar-sys", 
        "https://www.zhihu.com/people/qqing-75-81", 
        "https://www.zhihu.com/people/gary-50-79", 
        "https://www.zhihu.com/people/huang-yu-kang-60", 
        "https://www.zhihu.com/people/rong-yao-de-a-yu", 
        "https://www.zhihu.com/people/siyi-li-30", 
        "https://www.zhihu.com/people/constvar", 
        "https://www.zhihu.com/people/zhou-hao-ran-1-91", 
        "https://www.zhihu.com/people/cai-zhi-fu", 
        "https://www.zhihu.com/people/wa-qia-qia-11", 
        "https://www.zhihu.com/people/richbabe", 
        "https://www.zhihu.com/people/seesea-47", 
        "https://www.zhihu.com/people/zhang-si-yuan-19-87", 
        "https://www.zhihu.com/people/drashnane", 
        "https://www.zhihu.com/people/tian-shi-ai-mei-li-22", 
        "https://www.zhihu.com/people/liang-yu-36-31-11", 
        "https://www.zhihu.com/people/kevin-27-75-59", 
        "https://www.zhihu.com/people/jetthuang", 
        "https://www.zhihu.com/people/zi-xin-xu", 
        "https://www.zhihu.com/people/qrn_1982", 
        "https://www.zhihu.com/people/sky-deng-41", 
        "https://www.zhihu.com/people/ggff-ss", 
        "https://www.zhihu.com/people/moqi-11-77", 
        "https://www.zhihu.com/people/weizilin", 
        "https://www.zhihu.com/people/gui-ling-77-55", 
        "https://www.zhihu.com/people/liu-shen-ming", 
        "https://www.zhihu.com/people/cuipf", 
        "https://www.zhihu.com/people/fool-phoenix", 
        "https://www.zhihu.com/people/panyu-98", 
        "https://www.zhihu.com/people/whisper_chenxu", 
        "https://www.zhihu.com/people/zhen-shi-yin-49-37", 
        "https://www.zhihu.com/people/chen-yi-4-24", 
        "https://www.zhihu.com/people/guo-lei-9-84", 
        "https://www.zhihu.com/people/loki-37", 
        "https://www.zhihu.com/people/noeltoby", 
        "https://www.zhihu.com/people/cingo-li", 
        "https://www.zhihu.com/people/tamaca", 
        "https://www.zhihu.com/people/luo-peng-84-36", 
        "https://www.zhihu.com/people/jn5414", 
        "https://www.zhihu.com/people/shui-bei-yang", 
        "https://www.zhihu.com/people/liu-jun-bin-69", 
        "https://www.zhihu.com/people/matthew-99-66", 
        "https://www.zhihu.com/people/66dream", 
        "https://www.zhihu.com/people/you-wei-98", 
        "https://www.zhihu.com/people/shuang-zhi-an-shang", 
        "https://www.zhihu.com/people/leeszh2018", 
        "https://www.zhihu.com/people/wang-liao-52", 
        "https://www.zhihu.com/people/bruce-wan", 
        "https://www.zhihu.com/people/mo-shun-36", 
        "https://www.zhihu.com/people/yan-zhen-xing-29", 
        "https://www.zhihu.com/people/wu-deng", 
        "https://www.zhihu.com/people/bigcloud", 
        "https://www.zhihu.com/people/yi-zhao-6", 
        "https://www.zhihu.com/people/lemonkiller", 
        "https://www.zhihu.com/people/yang-cheng-9", 
        "https://www.zhihu.com/people/mu-mu-mu-mu-mu-57", 
        "https://www.zhihu.com/people/hengel-15", 
        "https://www.zhihu.com/people/coderkian", 
        "https://www.zhihu.com/people/zirpon", 
        "https://www.zhihu.com/people/jintao-zhao", 
        "https://www.zhihu.com/people/ryan-white-77", 
        "https://www.zhihu.com/people/he-zi-70-62", 
        "https://www.zhihu.com/people/1312-60", 
        "https://www.zhihu.com/people/cai-chai-29", 
        "https://www.zhihu.com/people/csp1223", 
        "https://www.zhihu.com/people/carl-im", 
        "https://www.zhihu.com/people/haha-10-30", 
        "https://www.zhihu.com/people/chan-david-14", 
        "https://www.zhihu.com/people/wang-peng-51", 
        "https://www.zhihu.com/people/yang-wu-shang", 
        "https://www.zhihu.com/people/wildmage", 
        "https://www.zhihu.com/people/chen-wen-zhen-83", 
        "https://www.zhihu.com/people/karmic0412", 
        "https://www.zhihu.com/people/fanflash", 
        "https://www.zhihu.com/people/cbzsaisi", 
        "https://www.zhihu.com/people/jiang-tao-72", 
        "https://www.zhihu.com/people/lu-ren-liang-59", 
        "https://www.zhihu.com/people/duan-de-chao-71", 
        "https://www.zhihu.com/people/musoucrow", 
        "https://www.zhihu.com/people/zhang-wei-wei-67-91", 
        "https://www.zhihu.com/people/hua-hua-80-13", 
        "https://www.zhihu.com/people/bevis-86", 
        "https://www.zhihu.com/people/li-hui-20-35", 
        "https://www.zhihu.com/people/ma-bi-mo-gu", 
        "https://www.zhihu.com/people/jiang_9608", 
        "https://www.zhihu.com/people/aenerv7", 
        "https://www.zhihu.com/people/scarb", 
        "https://www.zhihu.com/people/smallxie-95", 
        "https://www.zhihu.com/people/su-liu-guang-23", 
        "https://www.zhihu.com/people/bing-qi-lin-gou", 
        "https://www.zhihu.com/people/yi-du-31", 
        "https://www.zhihu.com/people/FinalUnreality", 
        "https://www.zhihu.com/people/liu-zhi-bin-80", 
        "https://www.zhihu.com/people/prncsuc", 
        "https://www.zhihu.com/people/spring-star", 
        "https://www.zhihu.com/people/li-jia-xin-39-53", 
        "https://www.zhihu.com/people/li-yi-bin-39-41", 
        "https://www.zhihu.com/people/yang-shuai-18-15", 
        "https://www.zhihu.com/people/yan-hui-60", 
        "https://www.zhihu.com/people/sevenqi-57", 
        "https://www.zhihu.com/people/mordin", 
        "https://www.zhihu.com/people/john-lu-24", 
        "https://www.zhihu.com/people/zhang-gang-86-34", 
        "https://www.zhihu.com/people/zhou-chen-61-60", 
        "https://www.zhihu.com/people/xisailuo", 
        "https://www.zhihu.com/people/aboutdept", 
        "https://www.zhihu.com/people/tinnnnn", 
        "https://www.zhihu.com/people/none-of-persona", 
        "https://www.zhihu.com/people/you-hun-62", 
        "https://www.zhihu.com/people/imllt", 
        "https://www.zhihu.com/people/khorium", 
        "https://www.zhihu.com/people/kyo-tachen", 
        "https://www.zhihu.com/people/zsydeepsky", 
        "https://www.zhihu.com/people/kennel2009", 
        "https://www.zhihu.com/people/niteluo", 
        "https://www.zhihu.com/people/dongch007", 
        "https://www.zhihu.com/people/cslply", 
        "https://www.zhihu.com/people/zhang-xiao-ming-11", 
        "https://www.zhihu.com/people/ou-yang-qing-12", 
        "https://www.zhihu.com/people/kyle-21-26", 
        "https://www.zhihu.com/people/peng-lu-20-18", 
        "https://www.zhihu.com/people/zeng-zhi-an", 
        "https://www.zhihu.com/people/tyung.wu", 
        "https://www.zhihu.com/people/liu-xu-jun-92", 
        "https://www.zhihu.com/people/liaoer", 
        "https://www.zhihu.com/people/faaaarseer", 
        "https://www.zhihu.com/people/yao-lei-7", 
        "https://www.zhihu.com/people/ken07", 
        "https://www.zhihu.com/people/bin-coder", 
        "https://www.zhihu.com/people/zou-pan-pan-76", 
        "https://www.zhihu.com/people/zhang-hui-kang-86", 
        "https://www.zhihu.com/people/jcyongqin", 
        "https://www.zhihu.com/people/rui-kou-75", 
        "https://www.zhihu.com/people/guan-zhuang-14", 
        "https://www.zhihu.com/people/Jackyuu", 
        "https://www.zhihu.com/people/lin-guo-wei", 
        "https://www.zhihu.com/people/liu-fei-94-95", 
        "https://www.zhihu.com/people/stanley_wang", 
        "https://www.zhihu.com/people/shi-ling-64", 
        "https://www.zhihu.com/people/god-six-86", 
        "https://www.zhihu.com/people/feng-cong-cong-78", 
        "https://www.zhihu.com/people/du-yu-71-11", 
        "https://www.zhihu.com/people/jiang-hu-19-44", 
        "https://www.zhihu.com/people/senlinmuyi", 
        "https://www.zhihu.com/people/faker-41-98", 
        "https://www.zhihu.com/people/dong-wo-ming"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/80732458", 
            "userName": "Mobius", 
            "userLink": "https://www.zhihu.com/people/b9d9e6791052a8e0567410a1c0edcdf2", 
            "upvote": 2, 
            "title": "AdvancedLocomotion 拆解笔记 [1]：移动", 
            "content": "<h2>0. 介绍</h2><blockquote><i>在大多数游戏里，移动一个人物跟移动一块砖头并没有什么区别。 </i><br/><i>—— 某知乎大V</i></blockquote><p>在早期的游戏中，角色并不会有太复杂的动作逻辑。比如对于移动的处理，就是播放一个跑步动作，再以一个合适的速度控制角色做匀速直线运动。在Unreal中，依靠非常强大的动作蓝图以及动画工具，可以编辑出非常复杂的动作逻辑和细节。</p><p>「基础动作」，这里指的是站蹲趴、走跑跳这一类最基本的动作。虽然是基础，却也是动作逻辑中最难做好的部分（蛋炒饭？？）。相对于各种怪力乱神花里胡哨的「技能动作」，基础动作是人们平时接触得最多的动作，因此对其中不自然的表现会很敏感。按游戏时长来说，基础动作是玩家使用最多的动作，因此它的表现质量直接关乎游戏的动作表现质量。</p><p><a href=\"https://link.zhihu.com/?target=https%3A//www.unrealengine.com/marketplace/en-US/slug/advanced-locomotion-system-v1\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Advanced Locomotion</a>（简称&#34;ALS&#34;）是一个3A游戏级别的基础动作库，完全由蓝图实现。其表现效果可以参照<a href=\"https://link.zhihu.com/?target=https%3A//youtu.be/yTniZCOCY7o\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">官方油管视频演示</a>。它的功能（或者说表现出来的细节）很多，包括但不限于「锁视角八方向移动」、「起步止步动作」、「速度变化时身体倾斜」、「原地转身」、「落地动作预测」、「脚步IK」、「布娃娃融合」等等。对于刚接触游戏3Cs（Character, Control, Camera）开发的开发者，这是一套非常好的范例。</p><p>下面将按照我自己的划分逻辑，将ALS划分为不同的功能块，逐个拆解其实现细节。经常会涉及一些资源处理，最好是对照着其蓝图来理解。</p><p>角色蓝图（简称&#34;CharBp&#34;）的路径是：</p><p>Content/AdvancedLocomotionV3/Blueprints/ALS_BaseCharacter</p><p>角色的主动画蓝图（简称&#34;AnimBp&#34;）的路径是</p><p>Content/AdvancedLocomotionV3/Characters/Mannequin/Mannequin_AnimBP</p><h2>1. 移动</h2><p>ALS的移动模式很丰富，包括：</p><ul><li>姿态（Stance）：站/蹲</li><li>步调（Gait）：站/走/跑/疾跑</li><li>旋转方式（Rotation Mode）：有锁视角移动/非锁视角移动两种方式</li><li>瞄准模式</li></ul><p>从动作资源的命名规则上可以大致看出其区分维度。</p><p>移动的动画资源目录：Characters/Mannequin/Animations/Locomotion，从动作资源的命名规则上可以大致看出其区分维度。其AnimSequence的命名规则是：</p><ul><li>ALS_[C/-][RF/LF/N]_[Walk/Run/Sprint]_[F/B/R/L/FL/FR/BL/BR]_[Degree]</li><li>ALS_[站蹲姿势][侧身方向]_[Gait步调]_[移动方向]_[角度]</li></ul><h3>1.1 Walk/Run/Sprint（走/跑/疾跑）</h3><p>在ALS中， 有若干个移动的BlendSpace，它们的x轴是&#34;Direction&#34;，y轴是&#34;GaitValue&#34;。其中一个如下图：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-1f34aba103d28fc740c0eff48d17e8a0_b.jpg\" data-size=\"normal\" data-rawwidth=\"520\" data-rawheight=\"670\" class=\"origin_image zh-lightbox-thumb\" width=\"520\" data-original=\"https://pic1.zhimg.com/v2-1f34aba103d28fc740c0eff48d17e8a0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;520&#39; height=&#39;670&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"520\" data-rawheight=\"670\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"520\" data-original=\"https://pic1.zhimg.com/v2-1f34aba103d28fc740c0eff48d17e8a0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-1f34aba103d28fc740c0eff48d17e8a0_b.jpg\"/><figcaption>ALS_N_Locomotion_B_Upper</figcaption></figure><p><b>Direction</b>，是指角色脸朝向与移动方向的顺时针角度，取值范围是[-180, 180]。比如朝右前方跑，Direction就是45；朝左后方跑，Direction就是-135。</p><p><b>GaitValue</b>，「步调」，也就是「走/跑/疾跑」，取值范围是[0, 3]。0表示静止，1是Walk，2是Run，3是Sprint。注意这里与具体速度无关。下面可以来看一下，如何让BlendSpace、动画蓝图与动画资源本身的速度解耦。</p><p>AnimBp中有个CalculateGaitValue函数，就是用来计算GaitValue的。这里是蓝图里的注释：</p><blockquote><i>Set Gait value (ranging 1 to 3) based on current speed in relation to the Walk, Run, and Sprinting speeds (Walk = 1, Run = 2, Sprint = 3). This enables you to change Walk/Run/Sprint speeds while retaining a fully weighted animation within the blendspace.</i></blockquote><p>根据当前速度与Walk/Run/Sprint的「设计速度」的比值，确定GaitValue落在[0, 1.0)、[1, 2.0)、[2.0, 3.0]哪个区间。GaitValue与速度在单区间内是线性关系，但总区间内不是线性关系。这样，就可以做到资源与动作蓝图、BlendSpace解耦。每次资源修改，只需要修改动画蓝图上「设计速度」对应的参数。</p><h3>1.2 快速响应与动作表现</h3><p>基础移动的一个难点，就是要处理好「快速响应」和「动作表现」之间的矛盾。因为「快速响应」要求尽快去到目标姿势，极端情况下像格斗游戏中的「取消」机制，直接由打断上个动作进入下个动作。「动作表现」一般则需要较长的时间来做播放动画，会让玩家手感变得「涩」、「重」。</p><p>在ALS中，这个问题的处理思路是使用了2个Pose，一个是下半身Pose，快速响应；一个是上半身Pose，响应时间较长，保留动作细节。</p><p>比如当改变移动方向、速度时，下半身Pose会用较短的融合时间、直接改变当前动作的播放倍率来快速响应到目标姿势；延后一会，上半身Pose才会融合到对应的摆臂、倾斜姿态，从而有一个较为完整流畅的表现。</p><p>具体到动画蓝图里的实现，可以看看&#34;AnimGraph/MainStateMachine/Locomotion(state)/Locomotion/Moving(state)&#34;，图中&#34;Layered blend per bone&#34;就是混合上下半身Pose的节点，红色框部分的逻辑，输入的是下半身的Pose；绿色框部分的逻辑，输入的上半身的Pose。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-cc4ca5cb8dde1f26d6de19f0f78755f5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"990\" data-rawheight=\"734\" class=\"origin_image zh-lightbox-thumb\" width=\"990\" data-original=\"https://pic2.zhimg.com/v2-cc4ca5cb8dde1f26d6de19f0f78755f5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;990&#39; height=&#39;734&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"990\" data-rawheight=\"734\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"990\" data-original=\"https://pic2.zhimg.com/v2-cc4ca5cb8dde1f26d6de19f0f78755f5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-cc4ca5cb8dde1f26d6de19f0f78755f5_b.jpg\"/></figure><h3>1.3 止步动作</h3><p>AnimGraph/MainStateMachine/Locomotion(state)/Locomotion, XX_Stop </p><p>止步动作处理的重点是，需要根据当前左右脚的关系（左右脚相隔的距离、角度），选择合适的止步动作。这里用了<a href=\"https://link.zhihu.com/?target=https%3A//docs.unrealengine.com/en-us/Engine/Animation/Sequences/Curves\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Animation Curves</a>来获取移动动作（Anim Sequence）的左右脚关系。在每一个移动动作里，都会维护<b>FootPosition</b>（止步位置）、<b>FootDirection</b>（止步方向）两条曲线。在动画蓝图中，角色停止时，会获取FootPosition、FootDirection的值，在BlendSpace中选择对应的止步动画。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e4d75bf7d1d44a906e573f9f3eff245b_b.jpg\" data-size=\"normal\" data-rawwidth=\"1068\" data-rawheight=\"672\" class=\"origin_image zh-lightbox-thumb\" width=\"1068\" data-original=\"https://pic4.zhimg.com/v2-e4d75bf7d1d44a906e573f9f3eff245b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1068&#39; height=&#39;672&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1068\" data-rawheight=\"672\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1068\" data-original=\"https://pic4.zhimg.com/v2-e4d75bf7d1d44a906e573f9f3eff245b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e4d75bf7d1d44a906e573f9f3eff245b_b.jpg\"/><figcaption>ALS_N_Run_BR</figcaption></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-5b59f4b19dd8f8b137c3d44993b28fdd_b.jpg\" data-size=\"normal\" data-rawwidth=\"460\" data-rawheight=\"634\" class=\"origin_image zh-lightbox-thumb\" width=\"460\" data-original=\"https://pic2.zhimg.com/v2-5b59f4b19dd8f8b137c3d44993b28fdd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;460&#39; height=&#39;634&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"460\" data-rawheight=\"634\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"460\" data-original=\"https://pic2.zhimg.com/v2-5b59f4b19dd8f8b137c3d44993b28fdd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-5b59f4b19dd8f8b137c3d44993b28fdd_b.jpg\"/><figcaption>ALS_N_Stop_RF</figcaption></figure><p>利用两个「止步方向」、「止步距离」两个维度做了一个BlendSpace，做到不同方向的止步。「向前 - 向左/右」、「向后 - 向左/右」，这两种方式选择左右移动动作是不同的。</p><h3>加速度与身体倾斜</h3><p>无论是在地面还是空中，角色在变速移动、转向时，身体会有一定幅度的倾斜。加减速时，是前后方向的倾斜；转向时，是左右方向的倾斜。这不仅是一个性价高、能出效果的动作细节，而且在参照物不明显的环境下，身体的倾斜对于玩家输入是一个及时的视觉反馈。</p><p>侧身叠加动画BlandSpace是ALS_N_Lean_Grounded。这个BlendSpace的X轴是左右倾斜表现，Y轴是前后倾斜表现。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-8f74002710bc761d779b4443fd6368e2_b.jpg\" data-size=\"normal\" data-rawwidth=\"462\" data-rawheight=\"640\" class=\"origin_image zh-lightbox-thumb\" width=\"462\" data-original=\"https://pic3.zhimg.com/v2-8f74002710bc761d779b4443fd6368e2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;462&#39; height=&#39;640&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"462\" data-rawheight=\"640\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"462\" data-original=\"https://pic3.zhimg.com/v2-8f74002710bc761d779b4443fd6368e2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-8f74002710bc761d779b4443fd6368e2_b.jpg\"/><figcaption>ALS_N_Lean_Grounded</figcaption></figure><p>侧身角度计算函数是&#34;Mannequin_AnimBP/CalculateGroundedLeaningValues&#34;。这个函数里计算出两个值，<b>LeanRotation</b>、<b>LeanAcceleration</b>。LeanRotation与角色的转向角速度（即偏航角Yaw变化的速度）、速度线性相关，并且映射到[-1, 1]区间。即，角色往左转向越快、当前速度越快，LeanRotation越接近-1；往右转向速度越快、当前速度越快，越接近1。LeanAcceleration则是与加速度、速度线性相关，并映射到[-1, 1]区间。即角色往前加速度越大、速度越大，LeanAcceleration越接近1；往后加速度越大、速度越大，LeanAcceleration越接近-1。</p><p>在CalculateGroundedLeaningValues计算的末端，会有一个RotateVectorAroundAxis的计算。其中Direction是角色朝向与角色速度朝向的差值，而LeanRotation、LeanAcceleration都是通过对速度的计算得出的。因此需要通过Direction，将这2个计算结果组成的向量，转到角色朝向的空间。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4ccc941de3da0dc644f09411fe4434eb_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"674\" data-rawheight=\"364\" class=\"origin_image zh-lightbox-thumb\" width=\"674\" data-original=\"https://pic4.zhimg.com/v2-4ccc941de3da0dc644f09411fe4434eb_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;674&#39; height=&#39;364&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"674\" data-rawheight=\"364\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"674\" data-original=\"https://pic4.zhimg.com/v2-4ccc941de3da0dc644f09411fe4434eb_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4ccc941de3da0dc644f09411fe4434eb_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>下一篇会对ALS的「跳跃」以及「原地转身」机制做一个拆解。</p>", 
            "topic": [
                {
                    "tag": "游戏开发", 
                    "tagLink": "https://api.zhihu.com/topics/19553361"
                }, 
                {
                    "tag": "动作", 
                    "tagLink": "https://api.zhihu.com/topics/19561995"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/35894054", 
            "userName": "Mobius", 
            "userLink": "https://www.zhihu.com/people/b9d9e6791052a8e0567410a1c0edcdf2", 
            "upvote": 30, 
            "title": "论线性颜色空间的重要性（翻译）", 
            "content": "<h2>0 译者记</h2><p>这篇文章翻译自《GPU Gems 3》的第24章  <a href=\"https://link.zhihu.com/?target=https%3A//developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch24.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">The Importance of Being Linear</a> ，讲述了线性颜色空间在游戏渲染中的重要性。从一开始的概念介绍，错误渲染的结果，到解决方案等都做了比较循序渐进的讲解。</p><p>在文章里要注意一下，原文对于“Gamma 校正”和“反 Gamma 校正”有时候会用混用，译文里尽量按照正确的来纠正。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><i>Larry Gritz</i></p><p><i>NVIDIA Corporation</i></p><p><i>Eugene d&#39;Eon</i></p><p><i>NVIDIA Corporation</i></p><h2>1 介绍</h2><p>现代 GPU 已经强大到足够去进行各种实时的真实光照计算。但是在这个计算之前，需要保证获取到的颜色值是在线性颜色空间中。为了这个目的，从图片素材制作（包括拍照、数码绘制）开始，到素材保存、读取、光照计算，到最后读写 Frame Buffer 等各个阶段中，都需要保证是在匹配的颜色空间中做处理。在各种提高实时渲染质量的技术手段中，合适的 Gamma 校正应该算是最简单廉价、最被广泛使用的技术了。</p><h2>2 光照、显示与颜色空间</h2><p>如果你对高质量实时渲染感兴趣，你应该会好奇：一张图片如何保证在不同的显示媒介上显示出近似相同的效果，这些媒介包括 CRT 显示器、LCD 显示器、电影甚至于纸张。在整个图片制作展示的流程中，你可能会对下面几个问题的结果感到意外：</p><ul><li>各种摄录设备（包括相机、扫描仪等）捕获不同颜色的光之后，会将其数值化。那么这个数值是否严格精确地记录了光的强度？如果有2倍的光子达到感光器上，那么记录下来的数值是否也会是原来的2倍？</li><li>一个平面设计师在做数码绘制的时候，每个像素所表达的光的强度（而非颜色）是否是它想要模拟的强度？</li><li>显示器是否精确地将图片还原为光线？如果一个像素的值变为原来的2倍，那么在 CRT 显示器、LCD 显示器等不同显示器上，这个像素点发出的光，是否也是原来的2倍亮度？</li></ul><p>对于这些问题答案是：NO。尤其是，摄录设备（扫描仪、印刷机、数码摄影设备）和显示器（CRT、LCD等）对于颜色的处理都不是一个线性处理过程。因此如果在这两个步骤没有小心处理，那么很可能就会导致不正确、失真的显示效果。</p><p>非线性颜色空间下的渲染处理问题，有时候比较细微，因此会被有意无意地忽略掉，特别是在实时渲染时。但如果一个场景明暗范围跨度较大时，这个问题就会被暴露得较为明显。但这个问题是应该被重视起来的，通过简单的几步就可以处理好。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ad342e76ca4a97a4a6ea2107e097e3a7_b.jpg\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"305\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic4.zhimg.com/v2-ad342e76ca4a97a4a6ea2107e097e3a7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;305&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"305\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic4.zhimg.com/v2-ad342e76ca4a97a4a6ea2107e097e3a7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ad342e76ca4a97a4a6ea2107e097e3a7_b.jpg\"/><figcaption>图-1 正确的 Gamma 校正效果对比</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>2.2 什么是<i>线性</i>？</h2><p>一个<i>线性转换</i>用数学的语言来表达，是指输入和输出满足以下关系：</p><ul><li>多个值相加的和作为输入所得到的输出，等于这些值分别作为输入得到的输出值最后相加。<img src=\"https://www.zhihu.com/equation?tex=f+%28x%2B+y%29+%3D+f+%28x%29+%2B+f+%28y%29\" alt=\"f (x+ y) = f (x) + f (y)\" eeimg=\"1\"/> </li><li>输入值乘以一个因子 k，得到的输出值也相当于原输出值的 k 倍。即 <img src=\"https://www.zhihu.com/equation?tex=f%28kxx%29%3Dkxf%28x%29\" alt=\"f(kxx)=kxf(x)\" eeimg=\"1\"/> 。</li></ul><p>光的传播是线性的。两束光打到同一个地方，得到的亮度是两束光“颜色”相加，而不是相乘、相减或者其他计算方式。 [1]</p><h2>2.3 显示器是非线性颜色空间，渲染是线性颜色空间</h2><p>在CRT 显示器屏幕上，发光单元（像素点）得到的电压值，对应发出的光强度并不是线性关系。而在 LCD 显示器上，虽然不存在这个问题，但是为了继承这个属性，通常也会模拟这个输出关系。</p><p>显示器上电压与亮度的关系曲线类似于一个指数曲线，如 图-2，这个指数称为 <i>gamma</i>。一个典型的 gamma 值 2.2，表示一个像素值在 50% 位置时，其发出的亮度其实不到 100% 亮度的 1/4，而非你所期待的 50%！Gamma 对于不同的显示设备，其具体的值都是不同的，通常在 2.0 - 2.4。根据这个非线性特质去做校正的过程，称之为 <i>gamma 校正</i>。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-174e23868c1f8f37d73e05979fa15f9b_b.jpg\" data-size=\"normal\" data-rawwidth=\"275\" data-rawheight=\"268\" class=\"content_image\" width=\"275\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;275&#39; height=&#39;268&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"275\" data-rawheight=\"268\" class=\"content_image lazy\" width=\"275\" data-actualsrc=\"https://pic4.zhimg.com/v2-174e23868c1f8f37d73e05979fa15f9b_b.jpg\"/><figcaption>图-2 典型的显示器电压亮度关系曲线</figcaption></figure><p>注意，无论指数值是多少， 在&#34;0&#34;和&#34;1&#34;处，得到的数值都是相同的，只有在 (0, 1) 内的值才是需要校正的。</p><p>渲染器、Shader、印刷设备都是针对线性数据做处理的。无论是叠加多个光源的相加操作，或者是将光乘以反射比（反射比可能是一个固定值，也可能是来自漫反射率贴图）。</p><p>但这一切有个隐藏前提，那就是这个反射比与物体表面的反射特性是一个线性关系。也就是说，观看者看到的光照强度，与保存在 Frame Buffer 里的值是成固定比例的。</p><p>这里引出一个关键点：如果你的输入是非线性的，那么渲染器、Shader、印刷设备都会算出一个错误的值，导致跟模拟的真实效果有出入。</p><p>想象一下在你正在进行数码绘图。你所看到的颜色是经过“正确的 Gamma 矫正”的，因此颜色的非线性特性对于你来说是不可见的。绘制的结果在<i>你的</i>显示器看起来是正确的，但是在其他显示器上显示的可能就不一样了。特别的，如果一个 3D 渲染设备，会假设其收到的贴图都是在线性颜色空间中，那么对于你的绘制结果就会显示错误（注意，这里是<i>错误</i>而不是<i>偏差</i>）。同样的，如果你将一个线性的输出直接显示出来，而没有 Gamma 校正，那渲染的结果就会变得太暗。这种“太暗”并不是整体均匀地亮度不足，而是暗部太暗。</p><p>如果你的操作时这样的：在绘制、拍摄是在 Gamma（非线性）颜色空间下进行，然后在线性空间下渲染，最后没有经过 Gamma 校正直接输出。这时，你在这个图像管线两端的处理都是错误的，那么结果<i>可能</i>反而第一眼看起来像是对的。为什么呢？因为 非线性的绘制/拍摄和非线性的显示，会在某种程度上互相抵消。但是这种“第一眼看起来OK”，存在着很多瑕疵，比如颜色的光照处理，Alpha 通道的混合计算，Mipmaps 的计算这些地方都会有问题。进一步地说，任何模拟真实光照处理的计算都是有问题的，比如 HDR（高动态范围成像）、基于图片的光照。</p><p>而且，你渲染结果在不同的显示设备上看到的效果是不同的。因为你的制图/拍摄、显示都是在各自不同的 Gamma 颜色空间中（即 Gamma 值不同）。</p><h2>3 错误渲染的症状</h2><p>如果你不正视处理上述问题，那么你可能会遇到下列的症状表现。</p><h2>3.1 输入贴图在非线性颜色空间中</h2><p>大部分的用户都不会有一个校准过的显示器，也不会听说过什么是 Gamma 校正。因此，很多可视化介质（这里说的是图片格式）可能会做一个<i>预校正</i>。比如，所有的 JPEG 格式文件都会预校正为 Gamma 值为 2.2 的 Gamma颜色空间中。这个值虽然不是精确匹配匹配所有显示器，但可以大致适配大多数显示器。这也意味着，JPEG 图片并不是线性的，无论它是被扫描得到的，还是拍照得到的。它们在被作为 Shader 使用的贴图时不应该被认为是线性的。</p><p>对于在大多数的 CRT、LCD显示器，用这种预校正格式直接显示图片是很方便的。对于8位存储的图片，会有更多的比例的信息是在存储暗的信息。而恰好人眼对于低亮度（黑暗）是更敏感的。尽管如此，这种进行了预校正的图片使用在任何渲染、合并处理前，都需要先做一下反 Gamma 校正，让颜色信息回到线性空间中。</p><h2>3.2 Mipmaps</h2><p>创建 Mipmap 的典型操作就是将原图不断缩小，新一阶的 Mipmap 的尺寸是上一阶的 1/4。那么假设，在一张高分辨率的图上，有一条边（Edge，即周围像素色值相差较大）上有 4 个相邻的像素，值分别是 2 个 1.0，2 个 0.0。那么在低分辨率 Mipmap 上，这四个像素会合并成为 1 个像素，它的值应该是 0.5，对吧？表示刚好是 50% 的亮度，因为 2 个 100% 亮和 2 个100% 暗的像素合并到了一起。这种计算 mipmap 的算法没错吧？哈哈，但这里有一个前提就是，这是一种<i>线性数学</i>。如果你在一个 Gamma 值为 2.0 的非线性颜色空间中，低分辨率 mipmap 上的那个像素值还是 0.5，但最后显示出来的亮度只有最高亮度的 25%。因此，在 Mipmap 上这种计算错误就不再是“瑕疵”了，而是“错误”了。因此会看到随着渲染的物体与 3D 摄像机距离的改变，渲染时切换 mipmap，导致看到的边缘的颜色会有差异。</p><h2>3.3 光照</h2><p>考虑一下这种情况，一个使用简单的 Lambertian 光照模型的球，如 图-3。 如果反射光的强度与 <b>N</b> · <b>L</b> （这里 <b>N</b> 是法线，<b>L</b> 是入射光角度）成比例，那么假设光源 A 的反射角度 <b>L</b> 与 法线 <b>N</b> 成60度，那么反射光的强度应该是原来的一半。也就是说，如果有光源 B 垂直射向球表面，即 <b>L</b> 与 <b>N</b> 夹角为0，那么其反射光的强度时光源 A 反射光强度的 2 倍。如果你把图片展示在一个线性颜色空间的显示器中，那么可以看到的反射属性是与真实相同的。但如果展示在一个 gamma 为 2.0 的显示器上，那么实际上光源 A 的反射光强度只有光源 B 的 1/4。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c6a6db8af520a9f6125ba33294a0ad9b_b.jpg\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"201\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic4.zhimg.com/v2-c6a6db8af520a9f6125ba33294a0ad9b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;201&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"201\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic4.zhimg.com/v2-c6a6db8af520a9f6125ba33294a0ad9b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c6a6db8af520a9f6125ba33294a0ad9b_b.jpg\"/><figcaption>图-3 一张线性颜色图片经过 Gamma 校正和未经过校正对比</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>换句话说，如果只是简单地将线性的计算结果显示到非线性的显示器上，那么 CG（computer-generated，计算机生成）材质和光照是无法匹配的。总的来说会看起来比真实情况暗一些。但是你也不能简单粗暴地将亮度整体调高，因为处于不同亮度范围需要被校正的值是不同的。阴影边缘或者明暗交界处会变得更“锐利”，即从亮到暗的过渡会变得更快。角落的地方会看起来更黑。如果你用上了各种“进阶”的光照技术（比如 HDR、任何种类的全局光照、此表面反射等），那么他们对“用线性颜色进行线性计算”这一点会要求更加严格。</p><h2>3.4 两次错误的叠加不会产生正确结果</h2><p>最常见的一类错误，就是提供给 Shader 的贴图使用了非线性颜色，而且最后输出的时候也没有做 Gamma 校正。这种双重错误造成的结果相比单一错误，会更加隐蔽。因为这两个错误各自所需要的纠正操作是大致相反的。但是，这种情况也会造成很多问题。</p><p>图-4 是使用“真实皮肤 Shader”（Realistic Skin Shader，更多有关皮肤 Shader 的资料，可以参看本书14章，真实皮肤实时渲染的进阶技术，&#34;Advanced Techniques for Realistic Real-Time Skin Rendering.&#34;）做实时渲染的两张对比图。左图将 JPEG 格式的漫反射贴图转化为线性颜色空间，因此光照（包括次表面散射）和 shader 计算都得以正确执行。最后得到的图片也经过了 Gamma 校正。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-2d670c8e7b95ddabfa9dfa3030ae41e8_b.jpg\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"347\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic1.zhimg.com/v2-2d670c8e7b95ddabfa9dfa3030ae41e8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;347&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"347\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic1.zhimg.com/v2-2d670c8e7b95ddabfa9dfa3030ae41e8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-2d670c8e7b95ddabfa9dfa3030ae41e8_b.jpg\"/><figcaption>图-4 正确 Gamma 校正和忽略 Gamma 校正的渲染对比</figcaption></figure><p>右图没有做任何校正，我们可以看看它所暴露出来的问题。由于光照计算没有在线性空间下计算，皮肤的色调被改变了。相比蓝绿通道，红色通道会显得更高。如果往漫反射里加一个白色高光，那么会变成黄色。阴影区域会变得太暗，而次表现反射也会几乎丢失，特别是在阴影区域内的次表面散射。</p><p>在非线性颜色空间中，对光照的调整的反应也是有问题的。还是图 图-4 的两张图，但现在我们把光照强度增大，效果如  图-5，情况会变得更加糟糕。记住一条规则，如果仅仅是调整光照的亮度，但会引起渲染对象的色调变化，那么很大可能性就是因为非线性光照计算，而且需要 Gamma 校正。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b5429e4ab1558c0a4de8cda6e9751748_b.jpg\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"348\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic1.zhimg.com/v2-b5429e4ab1558c0a4de8cda6e9751748_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;348&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"348\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic1.zhimg.com/v2-b5429e4ab1558c0a4de8cda6e9751748_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b5429e4ab1558c0a4de8cda6e9751748_b.jpg\"/><figcaption>图-5 使用正确 Gamma 校正和错误 Gamma 校正的渲染对比</figcaption></figure><p>次表面散射用于在皮肤渲染时，如果没有使用 Gamma 校正，一个常见症状就是：在阴影边缘会有蓝绿光，而且皮肤显得过于苍白，如图 图-6。因为次表面散射如果想显示出那种“皮肤透红”的感觉，需要在红色通道加强“模糊的辉光”（broad blur of irradiance）。这个效果在非线性空间下很难实现，就到导致在亮的区域散射太多而显得苍白；而在阴影边缘区域，红色通道从亮到暗过渡很快，导致留下了蓝绿光。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-146537482d35d920632c115c44779d78_b.jpg\" data-size=\"normal\" data-rawwidth=\"300\" data-rawheight=\"202\" class=\"content_image\" width=\"300\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;300&#39; height=&#39;202&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"300\" data-rawheight=\"202\" class=\"content_image lazy\" width=\"300\" data-actualsrc=\"https://pic1.zhimg.com/v2-146537482d35d920632c115c44779d78_b.jpg\"/><figcaption>图-6 没有 Gamma 校正的次表面散射</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><h2>4 处理方法</h2><p>Gamma 校正是指在图片显示之前，应用一个与显示器颜色变换相反的变换到图片上。也就是说，对于一个像素，先将其色值转换为原来的 1/gamma 次方，接着在被显示的时候，显示器自然就会重新取其 gamma 次方。因此抵消掉之后，就会得到一个线性的颜色输出了。如图 图-2。</p><p>常用的处理方法就是让你的程序使用一份<i>颜色校准表</i>（color-correction <i>lookup tables</i>， LUTs）。校准之后，就可以让渲染、印刷到所有图片处理都使用线性的数学计算，然后正确地显示在屏幕上。</p><p>动画、视觉效果工作室以及任何商业发布机构，都会非常注重这个处理过程。通常都有一个专门的人员去负责他们显示器的色彩管理，印刷流水线，电影或视频检查，以及最后的输出。对于高端使用者，简单的 Gamma 校正还不够，他们会用一份更成熟稳定的 3D 颜色校准表来做校正。这份表对不同的单独的显示设备做精确的测量而得出。相反，游戏开发经常不太在意这个事情，而导致了本文讨论的各种问题。CG 电影为啥看起来就是比游戏好？除了 CG 不是实时渲染的之外，颜色管理也是一个原因。</p><p>非骨灰级玩家一般都不会有个专门经过校正的显示器，我们也无法得知玩家显示器的 Gamma 值是多少。而且玩家也不会希望 Gamma 校正在他的显示器上一直应用着。因为像 JPEG 之类在非线性颜色空间下的图片，经过 Gamma 校正之后再看会显得泛白。（影视工作室的经过校正的显示器，一般就只在乎电影成品在该显示器上的输出效果，而对其他网页之类的内容显示正确与否就不会太在意了。）虽然我们的游戏无法针对每个显示器的 Gamma 值做精确校正，但是我们可以使用一个较为通用的 Gamma 值，去匹配大多数普通的显示器。</p><h2>4.1 输入的图片（扫描、绘制或者数码图片）</h2><p>你通过扫描、数码相机拍摄得到的图片，一般来说都已经经过了 Gamma 校正，特别是是它们以 JPEG 格式保存下来的时候。当然它们就也都是在非线性颜色空间了。（数码相机保存的 JPEG 格式图片通常还会经过锐化，如果不想有这些“惊喜”，可以选择存储格式为 RAW）。如果你在绘制贴图素材的时候，没有使用 gamma LUT，那么绘制出来的贴图的就是出图的显示器所在的颜色空间。如果一张图片用浏览器打开，在你的显示器上看是正确的，那么大概率它已经被 Gamma 校正过，不在线性颜色空间内了。</p><p>任何已经经过 Gamma 校正的贴图如果要参与 Shader 或者印刷，都首先需要还原到线性颜色空间，再去做光照计算。无论是 Alpha 通道、法线贴图、置换贴图等，只要涉及贴图里的像素值参与计算的，都需要在计算之前，保证其在线性颜色空间中。</p><p>所有的现代 GPU 都支持 sRGB 贴图格式。这类格式的图片虽然的像素还是经过 Gamma 校正的，但是文件里还保存了校正的 Gamma 值。作为贴图传给 GPU 时，GPU 的硬件会预先取出这个 Gamma 值，将贴图还原到线性空间中，再传给 Shader 做处理。在 NVIDIA Geforce 8 系列之后的显卡，贴图反锯齿操作中使用的采样，都会保证是在线性空间中进行采样的。这个校正是一个 IEC 标准（IEC 61966-2-1），专门这对 Gamma 值为 2.2做的校正。对于大多数 gamma 值不确切的显示器，取这个值是一个较为保险的值。Alpha 值不参与校正。</p><p>所有 8-bit 格式的贴图都可以支持 sRGB，无论是 OpenGL 还是 DirectX 。这些格式包括包括 RGB、RGBA、luminance、luminance alpha 和 DXT compressed。比如，传<code>GL_SRGB_EXT</code> 而不是<code>GL_RGB</code>给到<code>glTexImage2D</code>。这样，就可以保证 Shader 在访问贴图时，返回的是线性颜色空间下的值。</p><p>sRGB 格式，相对于手动校正（如示例 24-1），首选是更快更廉价的 GPU 自动校正。在手动校正中，会使用的 <code>pow</code> 指令，这个指令在真正执行时会被展开为2个指令。另外，手动校正只能在反锯齿操作之后，那么此前用于反锯齿操作的数据就已经是在非线性空间的了。sRGB 格式可以在加载贴图之前，就选择直接加载数据到线性空间中，而非“加载非线性数据 - 校正”的过程，不仅效率更快，而且避免了转换过程中造成的精度损失。</p><h2>示例-1. 手动转换颜色值到线性空间</h2><p><i>手动读取贴图的颜色值，做反 Gamma 校正，然后将得到的线性值给 Shader 计算。这样当然是可以的。但是使用 sRGB 贴图会更快、有正确的线性反锯齿（GeForce 8 之后），而且不需要额外的 Shader 代码。</i></p><div class=\"highlight\"><pre><code class=\"language-c\"><span class=\"n\">float3</span> <span class=\"n\">diffuseCol</span> <span class=\"o\">=</span> <span class=\"n\">pow</span><span class=\"p\">(</span> <span class=\"n\">f3tex2D</span><span class=\"p\">(</span> <span class=\"n\">diffTex</span><span class=\"p\">,</span> <span class=\"n\">texCoord</span> <span class=\"p\">),</span> <span class=\"mf\">2.2</span><span class=\"p\">);</span>\n<span class=\"c1\">// Or (cheaper, but assuming gamma of 2.0 rather than 2.2)\n</span><span class=\"c1\">// 如果为了更快，这里可以把 gamma 2.2 改为 2.0\n</span><span class=\"c1\"></span><span class=\"n\">float3</span> <span class=\"n\">diffuseCol</span> <span class=\"o\">=</span> <span class=\"n\">f3tex2D</span><span class=\"p\">(</span> <span class=\"n\">diffTex</span><span class=\"p\">,</span> <span class=\"n\">texCoord</span> <span class=\"p\">);</span>\n<span class=\"n\">diffuseCol</span> <span class=\"o\">=</span> <span class=\"n\">diffuseCol</span> <span class=\"o\">*</span> <span class=\"n\">diffuseCol</span><span class=\"p\">;</span></code></pre></div><p>手动去维护各个 Shader 里对于线性、非线性的输入，对于程序员，或者提供贴图的美术人员，都是一件非常繁琐、事倍功半的事情。大多数情况下最简单的解决方案，就是保证所有贴图在用于渲染之前，都是提供线性值的。</p><h2>4.2 输出图片（最后的渲染）</h2><p>最后一步，就是把最后得到像素色值，做一次 gamma 校正。这样得到值，在非线性的显示器上就可以得到“正确”的效果。如果设定了 Frame Buffer 的格式为 sRGB，shader 只需要直接把计算得到的值写进 FrameBuffer 就好了。在写之前，GPU 会自动把值做 Gamma 校正，然后再写到 FrameBuffer（或者 Render-To-Texture Buffer）。更进一步地，在 GeForce 8-class 以后的硬件，如果打开了 Blending，需要取出 FrameBuffer 中的值与当前值做 Blend 计算，那么在取出之前，GPU 也会自动做一个反 Gamma 校正，返回一个线性的值。Alpha 值不需要 Gamma 校正。但是，如果不支持将 Buffer 设置为 sRGB 格式，存入 FrameBuffer 前的 Gamma 校正就需要在 shader 中手撸了，如 24-2。但即使这样，Blending 得到值也不可比避免地会计算错误。</p><h2>示例-2 将最后的输出做 Gamma 校正</h2><p><i>如果无法将 FrameBuffer 设置为 sRGB 格式（或者使用了一个自定义的 gamma 值），那就需要按照下面的方法来做 Gamma 校正</i></p><div class=\"highlight\"><pre><code class=\"language-c\"><span class=\"n\">float3</span> <span class=\"n\">finalCol</span> <span class=\"o\">=</span> <span class=\"n\">do_all_lighting_and_shading</span><span class=\"p\">();</span>\n<span class=\"kt\">float</span> <span class=\"n\">pixelAlpha</span> <span class=\"o\">=</span> <span class=\"n\">compute_pixel_alpha</span><span class=\"p\">();</span>\n<span class=\"k\">return</span> <span class=\"nf\">float4</span><span class=\"p\">(</span><span class=\"n\">pow</span><span class=\"p\">(</span><span class=\"n\">finalCol</span><span class=\"p\">,</span> <span class=\"mf\">1.0</span> <span class=\"o\">/</span> <span class=\"mf\">2.2</span><span class=\"p\">),</span> <span class=\"n\">pixelAlpha</span><span class=\"p\">);</span>\n<span class=\"c1\">// Or (cheaper, but assuming gamma of 2.0 rather than 2.2)\n</span><span class=\"c1\">// 如果为了更快，这里可以把 gamma 2.2 改为 2.0\n</span><span class=\"c1\"></span><span class=\"k\">return</span> <span class=\"nf\">float4</span><span class=\"p\">(</span> <span class=\"n\">sqrt</span><span class=\"p\">(</span> <span class=\"n\">finalCol</span> <span class=\"p\">),</span> <span class=\"n\">pixelAlpha</span> <span class=\"p\">);</span></code></pre></div><h2>4.3 作为中间结果 Color Buffer</h2><p>在线性空间下计算，以非线性空间的值存到 FrameBuffer 里。需要时刻记住去维护这个机制。比如当你做任何后期处理（Post-Processing）的时候，都需要先将值取出来，做一个反 Gmmma 校正，进行后期处理，最后再做一个 Gamma 校正存回去。</p><p>当你需要渲染出一张贴图的时候，你有两种方案选择：</p><ol><li>做 Gamma 校正，这样存入贴图的就是非线性空间的值。</li><li>不做 Gamma 校正，那么贴图里存的就是线性空间的值。</li></ol><p>要记住贴图所保存的值的颜色空间，在对贴图做进一步处理时，就需要针对不同颜色空间有不同的处理方式。用于中间格式的 Color Buffer，如果存成 8-bit 线性空间，相比于非线性空间，在暗的地方会丢失一些精度。因此如果要存成线性空间，可以考虑存成 16-bit 浮点数，或者 sRGB 格式。</p><h2>5 总结</h2><p>无论是 OpenGL 还是 DirectX，Shader 都经常用来对输入的贴图采样值，做各种数学计算、光照计算、材质计算，最后输出为线性值。但是用于作为输入的贴图所存储的值，却很大可能是非线性的。更加可以确定的是，你的玩家所用的显示器不会是专业经过校正的显示器，因此它对输入的颜色值会做一个非线性的转换再显示。在这个描述场景下，会导致各种不精确的渲染瑕疵（光照计算不正确、mipmap 反锯齿计算错误），甚至渲染错误。</p><p>因此我们强烈建议开发者遵循以下几个简单的处理步骤：</p><ol><li>假设绝大多数玩家使用的都是未经校正的非专业显示器，他们的指数相应值是 gamma = 2.2。如果你打算提供更高端的体验，可以提供一个 Gamma 校正表让玩家自己选择 Gamma 值。</li><li>对于在非线性空间中的贴图，需要将其值做一个反 Gamma 校正（即 Gamma 次方），得到一个线性的值，再用于 Shader 的计算。但是对于本身已经是线性空间的贴图，比如某些 HDR 光照图、法线贴图、高度凹凸贴图或者任何非颜色值的贴图，则都<b>不</b>要使用反 Gamma 校正。对于非线性空间的贴图，尽可能存为 sRBG 格式，对于校正效率更高、更省事，还能得到正确的反锯齿效果。</li><li>最终输出的值在用于显示之前，需要做一个 Gamma 校正（即 1/gamma 次方）。使用 sRBG 格式的 FrameBuffer，则可以自动地在硬件级别做这个处理，而且可以有正确的 Blending 值。</li></ol><p>仔细地遵从这些步骤，可以让你的游戏在用 Shader 对光照、材质的渲染时，得到更加精确的效果。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>6 扩展阅读</h2><p>这一章中，我们尽量简洁地阐述了使用线性颜色空间的重要性。如果你想知道更多关于 Gamma 校正的问题，可以看看 Charles Poynton 的页面  <a href=\"https://link.zhihu.com/?target=http%3A//www.poynton.com/GammaFAQ.html\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">poynton.com/GammaFAQ.ht</span><span class=\"invisible\">ml</span><span class=\"ellipsis\"></span></a>。</p><p>Gamma 校正的维基页面对于这块也是写得出奇地好：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E4%25BC%25BD%25E7%2591%25AA%25E6%25A0%25A1%25E6%25AD%25A3\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">zh.wikipedia.org/wiki/%</span><span class=\"invisible\">E4%BC%BD%E7%91%AA%E6%A0%A1%E6%AD%A3</span><span class=\"ellipsis\"></span></a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Gamma_correction\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">en.wikipedia.org/wiki/G</span><span class=\"invisible\">amma_correction</span><span class=\"ellipsis\"></span></a></p><p>对于 sRBG 格式在 OpenGL 和 DirectX 的资料，可以看看这里</p><ul><li><a href=\"https://link.zhihu.com/?target=http%3A//www.nvidia.com/dev_content/nvopenglspecs/GL_EXT_texture_sRGB.txt\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">nvidia.com/dev_content/</span><span class=\"invisible\">nvopenglspecs/GL_EXT_texture_sRGB.txt</span><span class=\"ellipsis\"></span></a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//www.opengl.org/registry/specs/EXT/framebuffer_sRGB.txt\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">opengl.org/registry/spe</span><span class=\"invisible\">cs/EXT/framebuffer_sRGB.txt</span><span class=\"ellipsis\"></span></a></li><li><a href=\"https://link.zhihu.com/?target=http%3A//msdn2.microsoft.com/en-us/library/bb173460.aspx\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">msdn2.microsoft.com/en-</span><span class=\"invisible\">us/library/bb173460.aspx</span><span class=\"ellipsis\"></span></a></li></ul><p><i>多谢 Gary King 和 Mark Kilgard 对于 sRBG 的专业见解和对于此章评论。特别感谢演员 Doug Jones 提供他的肖像画作为渲染对比效果。最后，图24-2 的创作灵感来自与维基页面。</i></p>", 
            "topic": [
                {
                    "tag": "游戏开发", 
                    "tagLink": "https://api.zhihu.com/topics/19553361"
                }, 
                {
                    "tag": "3D 渲染", 
                    "tagLink": "https://api.zhihu.com/topics/20004076"
                }, 
                {
                    "tag": "实时渲染", 
                    "tagLink": "https://api.zhihu.com/topics/20140337"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "“因此我们强烈讲义开发者” 有个错字", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Mobius", 
                            "userLink": "https://www.zhihu.com/people/b9d9e6791052a8e0567410a1c0edcdf2", 
                            "content": "<p>已修改，谢谢指正</p>", 
                            "likes": 0, 
                            "replyToAuthor": "知乎用户"
                        }, 
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "谢谢文章", 
                            "likes": 0, 
                            "replyToAuthor": "Mobius"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/35100455", 
            "userName": "Mobius", 
            "userLink": "https://www.zhihu.com/people/b9d9e6791052a8e0567410a1c0edcdf2", 
            "upvote": 53, 
            "title": "游戏的寻路导航 1：导航网格", 
            "content": "<p>这篇文章，首先会介绍什么是<b>导航网格</b>，它在 3D 游戏中起到了什么样的作用。然后会介绍目前导航寻路最常用的第三方开源库 <b>RecastNavigation</b>。接下来，就是重点讲怎样利用 RecastNavigation 来生成导航网格，并且利用这些导航网格来进行寻路。最后，会讲到 RecastNavigation 的局限性。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>什么是导航网格？</h2><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-88ebadfef13f2ddbbdd7180765167d58_b.jpg\" data-size=\"normal\" data-rawwidth=\"1423\" data-rawheight=\"1097\" class=\"origin_image zh-lightbox-thumb\" width=\"1423\" data-original=\"https://pic1.zhimg.com/v2-88ebadfef13f2ddbbdd7180765167d58_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1423&#39; height=&#39;1097&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1423\" data-rawheight=\"1097\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1423\" data-original=\"https://pic1.zhimg.com/v2-88ebadfef13f2ddbbdd7180765167d58_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-88ebadfef13f2ddbbdd7180765167d58_b.jpg\"/><figcaption>导航网格</figcaption></figure><p>导航网格（Navigation Mesh），也俗称行走面，是一种用于在复杂空间中导航寻路、标记哪些地方可行走的多边形网格数据结构。很多时候，它会被用于承载更多的功能，比如标识该位置的地形、该位置角色应该采用什么动作（行走、游泳、攀爬）。</p><p>一个导航网格是由多个<b>凸多边形（Convex Polygon, Poly Mesh）</b>组成的。为了避免混淆，下文这种专属名词都会用英文单词代替。Poly Mesh 有些时候也会简称为 <b>Poly</b>，即上图中的一个个色块部分。注意，这里的 Poly 专门指的是导航网格的组成单位。在导航网格中的寻路是以 Poly 为单位的。在同个 Poly 中的两点，在忽略地形高度的情况下， 是可以直线到达的；如果两个点位于不同的 Poly，那么就会利用导航网格 + 寻路算法（比如A*算法）算出需要经过的 Poly，再算出具体路径。</p><p>在 Unity 中，有提供专门的工具集 NavMesh 用于寻路导航。但这套工具有个最大的问题就是算法、数据格式不开源，导致了游戏服务端是无法使用，无法和客户端保持一致的导航寻路逻辑。因此，在实际 MMORPG 开发中，一般会使用其他寻路方案。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-a8679d81b7a2425ea29808714ec3e38d_b.jpg\" data-size=\"normal\" data-rawwidth=\"563\" data-rawheight=\"481\" class=\"origin_image zh-lightbox-thumb\" width=\"563\" data-original=\"https://pic2.zhimg.com/v2-a8679d81b7a2425ea29808714ec3e38d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;563&#39; height=&#39;481&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"563\" data-rawheight=\"481\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"563\" data-original=\"https://pic2.zhimg.com/v2-a8679d81b7a2425ea29808714ec3e38d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-a8679d81b7a2425ea29808714ec3e38d_b.jpg\"/><figcaption>Unity 的 NavMesh</figcaption></figure><h2>RecastNavigation</h2><p>目前游戏最常用的导航寻路开源库应该就是 <a href=\"https://link.zhihu.com/?target=https%3A//link.jianshu.com/%3Ft%3Dhttps%253A%252F%252Fgithub.com%252Frecastnavigation%252Frecastnavigation\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">RecastNavigation</a> 了。坊间传说 Unity、Unreal 底层其实也是用的这个库。最初版的作者 <a href=\"https://link.zhihu.com/?target=https%3A//link.jianshu.com/%3Ft%3Dhttps%253A%252F%252Fwww.linkedin.com%252Fin%252Fmikkomononen%252F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Mikko Mononen</a> 多年前曾经是 <a href=\"https://link.zhihu.com/?target=https%3A//link.jianshu.com/%3Ft%3Dhttps%253A%252F%252Fzh.wikipedia.org%252Fwiki%252FCrytek\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Crytek工作室</a> 的 AI 工程师。大名鼎鼎的 <a href=\"https://link.zhihu.com/?target=https%3A//link.jianshu.com/%3Ft%3Dhttps%253A%252F%252Fzh.wikipedia.org%252Fwiki%252FCryENGINE\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">CryEngine</a>、<a href=\"https://link.zhihu.com/?target=https%3A//link.jianshu.com/%3Ft%3Dhttps%253A%252F%252Fzh.wikipedia.org%252Fwiki%252F%2525E6%2525A5%2525B5%2525E5%25259C%2525B0%2525E6%252588%2525B0%2525E5%25259A%25258E\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">孤岛惊魂</a> 就都是 Crytek 工作室开发的。出了 RecastNavigation 之后，这哥们后来又被 Unity 招安了。</p><p>RecastNavigation 是一个的导航寻路工具集，它包括了几个子集：</p><ol><li><b>Recast</b>：负责根据提供的模型生成导航网格。</li><li><b>Detour</b>：利用导航网格做寻路操作。这里的导航网格可以是 Recast 生成的，也可以是其他工具生成的。</li><li><b>DetourCrowd</b>：提供了群体寻路行为的功能。</li><li><b>Recast Demo</b>：一个很完善的 Demo，基本上将 Recast 、 Detour 提供的功能都很好地展现了出来。弄懂了这个 Demo 的功能，基本也就了解了 RecastNavigation 究竟可以干什么事。</li></ol><p>接下来，会重点讲导航网格的生成和如何利用导航网格进行寻路。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>导航网格的生成</h2><p>导航网格的生成依赖于场景模型的设计，有手动生成，有自动生成，有两种方式相结合的方式。如果场景简单，那么可以由场景设计师在构造场景模型时，手动拉一个场景的导航网格。但对于大规模复杂的场景，一般会让设计师剔除大量不可能到达的建筑、装饰物，做出一个简化的逻辑面模型，再根据这个模型去自动化生成导航网格。</p><p>Recast 库就是专门用于自动化生成导航网格的。有一个文章系列 <a href=\"https://link.zhihu.com/?target=https%3A//link.jianshu.com/%3Ft%3Dhttp%253A%252F%252Fwww.critterai.org%252Fprojects%252Fnmgen_study\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Study: Navigation Mesh Generation</a>，图文并茂详细地介绍了 Recast 生成导航网格的过程，非常推荐阅读。我在这里就根据这个系列，简要地罗列一下导航网格生成的相关概念和流程。</p><p>导航网格的生成会分为下面几个步骤：</p><ol><li>场景模型体素化（Voxelization），或者叫“栅格化”（Rasterization）。</li><li>过滤出<b>可行走面（Walkable Suface）</b></li><li>生成 <b>Region</b></li><li>生成 <b>Contour（边缘）</b></li><li>生成 <b>Poly Mesh</b></li><li>生成 <b>Detailed Mesh</b></li></ol><p class=\"ztext-empty-paragraph\"><br/></p><p>第一步，体素化。顾名思义，就是将整个场景模型，都转化为<b>体素（Voxel）</b>。</p><p>这一步处理和 GPU 渲染管线的光栅化流程概念是一样的，都是将矢量的模型信息（三角形），转化为点阵信息（像素或者体素）。开个脑洞， 假设将来有个全息显示器，可以在一个空间内渲染出制定的模型内容，渲染的最基本单位是体素而不是像素。那么到时的“显卡”很可能就是采取类似的模型体素化过程。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-b9c9e36d76c89ac83175231adb8cc6b8_b.jpg\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"800\" class=\"origin_image zh-lightbox-thumb\" width=\"1120\" data-original=\"https://pic1.zhimg.com/v2-b9c9e36d76c89ac83175231adb8cc6b8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1120&#39; height=&#39;800&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1120\" data-rawheight=\"800\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1120\" data-original=\"https://pic1.zhimg.com/v2-b9c9e36d76c89ac83175231adb8cc6b8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-b9c9e36d76c89ac83175231adb8cc6b8_b.jpg\"/><figcaption>场景模型体素化</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>第二步，根据哪些体素顶部有足够的空间可供行走，以及根据设置的参数，剔除过滤掉一些不符合要求的体素，初步计算出行走面。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c232b8ebdca95fc4d68d9736d6d3c430_b.jpg\" data-size=\"normal\" data-rawwidth=\"1423\" data-rawheight=\"1081\" class=\"origin_image zh-lightbox-thumb\" width=\"1423\" data-original=\"https://pic1.zhimg.com/v2-c232b8ebdca95fc4d68d9736d6d3c430_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1423&#39; height=&#39;1081&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1423\" data-rawheight=\"1081\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1423\" data-original=\"https://pic1.zhimg.com/v2-c232b8ebdca95fc4d68d9736d6d3c430_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-c232b8ebdca95fc4d68d9736d6d3c430_b.jpg\"/><figcaption>基础行走面</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>第三步，生成 Region。根据计算出来的行走面，使用特定算法，将这些可行走面切分为一个个尽量大的、连续的、<b>不重叠的</b>、<b>中间没有“洞”</b>的“区域”，这个区域就叫 <b>Region</b>。由于不重叠，也就不再需要高度信息，因此在这一步就把问题从三维空间转换到了二维空间。这一步的算法，Recast 提供了三种算法：</p><ul><li><a href=\"https://link.zhihu.com/?target=https%3A//link.jianshu.com/%3Ft%3Dhttps%253A%252F%252Fbaike.baidu.com%252Fitem%252F%2525E5%252588%252586%2525E6%2525B0%2525B4%2525E5%2525B2%2525AD%2525E7%2525AE%252597%2525E6%2525B3%252595%253Ffr%253Daladdin\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">分水岭算法（Watershed partitioning）</a>：最经典、效果最好，但处理比较慢，一般用于离线处理。</li><li><a href=\"https://link.zhihu.com/?target=https%3A//link.jianshu.com/%3Ft%3Dhttps%253A%252F%252Fcs.gmu.edu%252F%257Ejmlien%252Fteaching%252Fcs499-GC%252Fuploads%252FMain%252Fnote03.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Monotone partioning</a>：最快且可以保证生成的是不重叠、没有洞的 Region，但是生成的 Region 可能会又细又长，效果不好。</li><li>[Layer partitoining][Layer partitoining]：速度、效果都介乎分水岭算法和 Monotone partioning 之间，比较依赖于初始数据。</li></ul><p>Region 虽然是不重叠且没有洞的区域，但仍然有可能是凹多边形，无法保证 Region 内任意两点在二维平面可以直线到达。因此，接下来的步骤，就是为了将每个 Region 拆分为多个凸多边形。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e227fb82a1ea86d4427152aaf450f9dd_b.jpg\" data-size=\"normal\" data-rawwidth=\"1430\" data-rawheight=\"1090\" class=\"origin_image zh-lightbox-thumb\" width=\"1430\" data-original=\"https://pic2.zhimg.com/v2-e227fb82a1ea86d4427152aaf450f9dd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1430&#39; height=&#39;1090&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1430\" data-rawheight=\"1090\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1430\" data-original=\"https://pic2.zhimg.com/v2-e227fb82a1ea86d4427152aaf450f9dd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e227fb82a1ea86d4427152aaf450f9dd_b.jpg\"/><figcaption>Region</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>第四步，生成 Contour。</p><p>在这一步中，根据体素化信息和 Region，首先构建出描绘 Region 的 Detailed Contours（精确轮廓）。由于 Detailed Contour 以体素为单位构建边缘的，因此是锯齿状的。<br/>接着，再将 Detailed Contours 简化为 Simplified Contours（简化轮廓），方便后面的做三角形化（Triangulation）。在这一步之后，体素化数据就不再会被使用了。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-abe08459a821822386ff787f419ad8f1_b.jpg\" data-size=\"normal\" data-rawwidth=\"1412\" data-rawheight=\"1092\" class=\"origin_image zh-lightbox-thumb\" width=\"1412\" data-original=\"https://pic2.zhimg.com/v2-abe08459a821822386ff787f419ad8f1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1412&#39; height=&#39;1092&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1412\" data-rawheight=\"1092\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1412\" data-original=\"https://pic2.zhimg.com/v2-abe08459a821822386ff787f419ad8f1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-abe08459a821822386ff787f419ad8f1_b.jpg\"/><figcaption>Contour</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>第五步，生成 Polygon Mesh。</p><p>由于大多数算法处理需要基于凸多边形，因此这一步就是将 Simplified Contours 切分为多个凸多边形。凸多边形在代码中会简称为 Polygon 或 Poly。</p><p>在一个 Polygon 中，任意两个点在二维平面内都是可以直线到达的。因此，Polygon 是 Detour 的基本寻路单元。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-99dbae9d8d14d7928050cb31146a8d5b_b.jpg\" data-size=\"normal\" data-rawwidth=\"1406\" data-rawheight=\"1079\" class=\"origin_image zh-lightbox-thumb\" width=\"1406\" data-original=\"https://pic4.zhimg.com/v2-99dbae9d8d14d7928050cb31146a8d5b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1406&#39; height=&#39;1079&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1406\" data-rawheight=\"1079\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1406\" data-original=\"https://pic4.zhimg.com/v2-99dbae9d8d14d7928050cb31146a8d5b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-99dbae9d8d14d7928050cb31146a8d5b_b.jpg\"/><figcaption>Polygon Mesh</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>第六步，就是把 Polygon 继续做三角形化，生成了 Detailed Mesh。</p><p>如果把场景的拓扑结构看成一个无向图，其中每个 Polygon 是一个顶点。那么 Polygon 只是在拓扑结构上解决了寻路问题，但是为了在具体寻路过程中，让角色更加贴合地面地行走，需要一些更精确的地形信息（比如高度）。因此还需要将 Polygon 拆分为更贴近地表形状的 Detailed Mesh。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-88ebadfef13f2ddbbdd7180765167d58_b.jpg\" data-size=\"normal\" data-rawwidth=\"1423\" data-rawheight=\"1097\" class=\"origin_image zh-lightbox-thumb\" width=\"1423\" data-original=\"https://pic1.zhimg.com/v2-88ebadfef13f2ddbbdd7180765167d58_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1423&#39; height=&#39;1097&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"1423\" data-rawheight=\"1097\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1423\" data-original=\"https://pic1.zhimg.com/v2-88ebadfef13f2ddbbdd7180765167d58_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-88ebadfef13f2ddbbdd7180765167d58_b.jpg\"/><figcaption>Detailed Mesh</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>至此，导航网格的生成就结束了，Poly Mesh 和 Detailed Mesh 是最终需要的数据，需要存盘。其他都是属于中间数据，是可以被释放掉的。在实际应用中，可能会保存某些中间数据（比如体素化数据），做其它的用途。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>利用导航网格做寻路</h2><p>有了 Poly Mesh 和 Detailed Mesh 之后，使用 Detour 寻路就变得很简单了。构建一个 dtNavMeshQuery 实例，既可支持在 Poly Mesh 颗粒度的寻路，返回结果是路径途径的 Poly 数组；也可以支持在 Detailed Mesh 寻路，返回的是一个坐标点数组形式的路径。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>RecastNavigation 的局限性</h2><p>在 RecastNavigation 中，一个用于寻路的单位称为 <b>Agent（代理）</b>。 作者 Mikko Mononen 曾经在 RecastNavigation 的 <a href=\"https://link.zhihu.com/?target=https%3A//link.jianshu.com/%3Ft%3Dhttps%253A%252F%252Fgroups.google.com%252Fforum%252F%2523%2521forum%252Frecastnavigation\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Google 讨论组</a>中提到项目的一些设计前提：</p><ol><li>假设 Agent 都是在地面行走且收到重力影响的。</li><li>假设 Agent 始终保持直立姿态的，即平行于重力方向。</li></ol><p>Agent 不能飞，甚至不能跳。即使“走”在一些斜坡上，也始终应该是直立姿态，而不能是垂直于地表（即地表法线方向）。有了这些设计前提，才可以更方便地简化体素化时的数据结构，简化 Walking Surface 的计算生成。</p><p>因此，现在国产武侠类 MMORPG 里大行其道的轻功、甚至御剑飞行，是无法只单纯依赖 RecastNavigation 的数据去实现的。特别是对于某些具有层次错落结构的地形，就非常容易出现掉到两片导航网格的夹缝里的情况。这类机制的实现需要其他场景数据的支持。</p><p>而像《塞尔达传说：旷野之息》的爬山、《忍者龙剑传》的踩墙这种机制，则会在生成导航网格的阶段就会遇到麻烦。因为设计前提2的存在，RecastNavigation 是无法对与地面夹角小于或等于90°的墙面生成导航网格的。因此需要从另外的机制、设计上去规避或处理。不过，貌似 Unity 2017 已经可以支持了在各种角度的墙面生成导航网格了：<a href=\"https://link.zhihu.com/?target=https%3A//link.jianshu.com/%3Ft%3Dhttps%253A%252F%252Funity3d.college%252F2017%252F05%252F09%252Fceiling-wall-navigation-unity3d%252F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Ceiling and Wall Navigation in Unity3D</a>。</p><p>RecastNavigation 的另外的一个局限性则是，对于开放地图并不友好。如果需要判断远距离的两个点是否互相可到达，则需要将这个范围内的所有导航网格加载完，才可计算出路径，才可以判断是否可达到。即，“计算A点是否可走到B点” 和 “计算从A点到B点的具体路径”，这两个问题是等价的。因此，当长距离寻路时，玩家如果中途取消，则后续路径的计算量就会被浪费。</p><p>基于这一点，下一篇我们就来聊聊《游戏的寻路导航2：开放地图的导航》。</p>", 
            "topic": [
                {
                    "tag": "游戏编程", 
                    "tagLink": "https://api.zhihu.com/topics/19672960"
                }, 
                {
                    "tag": "游戏引擎", 
                    "tagLink": "https://api.zhihu.com/topics/19556258"
                }, 
                {
                    "tag": "A星寻路", 
                    "tagLink": "https://api.zhihu.com/topics/20137051"
                }
            ], 
            "comments": [
                {
                    "userName": "花流水", 
                    "userLink": "https://www.zhihu.com/people/7adcb00a8777b750ae90ac030b608e04", 
                    "content": "很期待你的第二篇文章！", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "Mobius", 
                            "userLink": "https://www.zhihu.com/people/b9d9e6791052a8e0567410a1c0edcdf2", 
                            "content": "<p>谢谢支持~</p>", 
                            "likes": 0, 
                            "replyToAuthor": "花流水"
                        }
                    ]
                }, 
                {
                    "userName": "champon", 
                    "userLink": "https://www.zhihu.com/people/5a9d9b973db174aec1d42989e58d2407", 
                    "content": "<p>第二篇在哪里</p><p></p>", 
                    "likes": 1, 
                    "childComments": []
                }, 
                {
                    "userName": "李辉", 
                    "userLink": "https://www.zhihu.com/people/176cc6310762e1e86d525153b09b34d2", 
                    "content": "第二篇在哪里", 
                    "likes": 1, 
                    "childComments": []
                }, 
                {
                    "userName": "林咖啡", 
                    "userLink": "https://www.zhihu.com/people/0f2b3172f6cbc289673c0cf671ec4d39", 
                    "content": "<p>期待您的第二篇文章</p>", 
                    "likes": 1, 
                    "childComments": []
                }, 
                {
                    "userName": "聊聊夜未央", 
                    "userLink": "https://www.zhihu.com/people/b1c28aa579593af8cf66c037055c2621", 
                    "content": "<p>第二篇在哪里？催更</p>", 
                    "likes": 1, 
                    "childComments": []
                }, 
                {
                    "userName": "話不多先森", 
                    "userLink": "https://www.zhihu.com/people/f7746f6e6c3be11bcefe41f7f3c9e926", 
                    "content": "<p>催更第二篇</p><a class=\"comment_sticker\" href=\"https://pic4.zhimg.com/v2-ba306425d0a7aee2c7260381f1bf7b97.gif\" data-width=\"\" data-height=\"\">[欢呼]</a>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "路人liang", 
                    "userLink": "https://www.zhihu.com/people/f3b0686769a6ffa4dba2fa7336274904", 
                    "content": "<p>说好的第二篇呢 ..</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/HiTechLoLife"
}

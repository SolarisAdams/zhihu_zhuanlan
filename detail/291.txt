{
    "title": "啊黎的NLP成长之路", 
    "description": "", 
    "followers": [
        "https://www.zhihu.com/people/knockknockwang", 
        "https://www.zhihu.com/people/liang-xx-79", 
        "https://www.zhihu.com/people/liu-fei-94-95", 
        "https://www.zhihu.com/people/piao-xue-10-34", 
        "https://www.zhihu.com/people/feng-yu-he-an-liu-65", 
        "https://www.zhihu.com/people/xiao-pu-pu-48", 
        "https://www.zhihu.com/people/cheng-xu-yuan-66", 
        "https://www.zhihu.com/people/tsangkk", 
        "https://www.zhihu.com/people/xianlong-chen", 
        "https://www.zhihu.com/people/wanghaihe", 
        "https://www.zhihu.com/people/sanfei-48", 
        "https://www.zhihu.com/people/shuangxinie", 
        "https://www.zhihu.com/people/xiao-ni-ren-er", 
        "https://www.zhihu.com/people/lai-ge-tu-zi", 
        "https://www.zhihu.com/people/moxiu2012", 
        "https://www.zhihu.com/people/elliott-54-86-6", 
        "https://www.zhihu.com/people/jk123124", 
        "https://www.zhihu.com/people/tiffany-jing", 
        "https://www.zhihu.com/people/lin-chu-hai-41", 
        "https://www.zhihu.com/people/dan-yiyi-5", 
        "https://www.zhihu.com/people/_nop", 
        "https://www.zhihu.com/people/xierry-41", 
        "https://www.zhihu.com/people/lee-sam-98", 
        "https://www.zhihu.com/people/zhang-wen-ling-27", 
        "https://www.zhihu.com/people/chaihahaha", 
        "https://www.zhihu.com/people/moxiaomo33", 
        "https://www.zhihu.com/people/milach", 
        "https://www.zhihu.com/people/wangcheny91", 
        "https://www.zhihu.com/people/huang-zhao-kai-17", 
        "https://www.zhihu.com/people/zhang-hang-70", 
        "https://www.zhihu.com/people/xiao-liu-41-24", 
        "https://www.zhihu.com/people/wang-zhi-yi-86-29", 
        "https://www.zhihu.com/people/tiao-wu-de-da-mao", 
        "https://www.zhihu.com/people/mai-zi-24-40", 
        "https://www.zhihu.com/people/zhong-bin-92-28", 
        "https://www.zhihu.com/people/zhao-yu-fan-29", 
        "https://www.zhihu.com/people/Turiny", 
        "https://www.zhihu.com/people/z-1222", 
        "https://www.zhihu.com/people/fa-fa-fa-fa-fa-36", 
        "https://www.zhihu.com/people/arbegla-56", 
        "https://www.zhihu.com/people/josephzxy", 
        "https://www.zhihu.com/people/zuochongyan", 
        "https://www.zhihu.com/people/nk522", 
        "https://www.zhihu.com/people/zhangrong888", 
        "https://www.zhihu.com/people/dou-dou-jun-64-36", 
        "https://www.zhihu.com/people/luo-mu-qing-han-65", 
        "https://www.zhihu.com/people/act22333", 
        "https://www.zhihu.com/people/luz-48-37", 
        "https://www.zhihu.com/people/lin-hao-xing-57", 
        "https://www.zhihu.com/people/wang-xian-sen-72-96", 
        "https://www.zhihu.com/people/hu-li-404", 
        "https://www.zhihu.com/people/ru-jack-48", 
        "https://www.zhihu.com/people/ijasmine-chan", 
        "https://www.zhihu.com/people/xiao-echo-53", 
        "https://www.zhihu.com/people/houlei666", 
        "https://www.zhihu.com/people/si-wen-bai-lei-73-51", 
        "https://www.zhihu.com/people/weilling-ha", 
        "https://www.zhihu.com/people/li-ping-22-37", 
        "https://www.zhihu.com/people/yishan-kop", 
        "https://www.zhihu.com/people/xuwei0221", 
        "https://www.zhihu.com/people/wu-tong-57-75", 
        "https://www.zhihu.com/people/sp-liu", 
        "https://www.zhihu.com/people/shenyinian", 
        "https://www.zhihu.com/people/lan-bo-23-69", 
        "https://www.zhihu.com/people/hao-hao-dang-dang-lich", 
        "https://www.zhihu.com/people/li-qiang-72-93-69", 
        "https://www.zhihu.com/people/pi-zhao-zhu-pi-de-lang-76", 
        "https://www.zhihu.com/people/powertyuui", 
        "https://www.zhihu.com/people/dang-liu-xing-hua-guo-ni-de-bi-an", 
        "https://www.zhihu.com/people/yang-hai-hong", 
        "https://www.zhihu.com/people/fang-hui-98", 
        "https://www.zhihu.com/people/tong-jin-le", 
        "https://www.zhihu.com/people/wzj-59-47", 
        "https://www.zhihu.com/people/gillsee", 
        "https://www.zhihu.com/people/mo-ming-18-89", 
        "https://www.zhihu.com/people/xie-bo-92-5", 
        "https://www.zhihu.com/people/li-zhe-shen", 
        "https://www.zhihu.com/people/qinkang-69", 
        "https://www.zhihu.com/people/le-tian-41-71", 
        "https://www.zhihu.com/people/hzx-88", 
        "https://www.zhihu.com/people/500ying-li", 
        "https://www.zhihu.com/people/young-frank-73-94", 
        "https://www.zhihu.com/people/xiaojidan", 
        "https://www.zhihu.com/people/feng-xia-chong-90", 
        "https://www.zhihu.com/people/lan-lan-lan-lan-96-82", 
        "https://www.zhihu.com/people/ideas-yd", 
        "https://www.zhihu.com/people/min-da-39", 
        "https://www.zhihu.com/people/feiox", 
        "https://www.zhihu.com/people/lvxiucheng", 
        "https://www.zhihu.com/people/lizhengxian", 
        "https://www.zhihu.com/people/tian-yu-8-57", 
        "https://www.zhihu.com/people/xugenpeng", 
        "https://www.zhihu.com/people/fan-te-xi-34", 
        "https://www.zhihu.com/people/xing-hui-80-80", 
        "https://www.zhihu.com/people/gumpleo", 
        "https://www.zhihu.com/people/qinlibo_nlp", 
        "https://www.zhihu.com/people/zheng-xin-yi-89", 
        "https://www.zhihu.com/people/nicknerd", 
        "https://www.zhihu.com/people/xie-pan-33-24", 
        "https://www.zhihu.com/people/hao-xuan-58-70", 
        "https://www.zhihu.com/people/li-yi-heng-60-80", 
        "https://www.zhihu.com/people/lxww301", 
        "https://www.zhihu.com/people/zhu-zhi-yuan-92", 
        "https://www.zhihu.com/people/lucchen", 
        "https://www.zhihu.com/people/lincoln-ricardo", 
        "https://www.zhihu.com/people/li-mu-zhi-15", 
        "https://www.zhihu.com/people/xu-yan-gen-99", 
        "https://www.zhihu.com/people/zhang-zi-yi-31-40", 
        "https://www.zhihu.com/people/totoro-lxy", 
        "https://www.zhihu.com/people/aprilvkuo", 
        "https://www.zhihu.com/people/bai-bai-87-80-88", 
        "https://www.zhihu.com/people/stevenberg", 
        "https://www.zhihu.com/people/spirit-soul", 
        "https://www.zhihu.com/people/zhong-er-cheng-xu-yuan", 
        "https://www.zhihu.com/people/skadiizhi-yan", 
        "https://www.zhihu.com/people/ren-wo-xing-59-44", 
        "https://www.zhihu.com/people/zhao-jun-83-21-53", 
        "https://www.zhihu.com/people/hong-alex", 
        "https://www.zhihu.com/people/moni-gg", 
        "https://www.zhihu.com/people/cattigers", 
        "https://www.zhihu.com/people/jianjianshu", 
        "https://www.zhihu.com/people/lu-feng-70-56", 
        "https://www.zhihu.com/people/spirit-22-32", 
        "https://www.zhihu.com/people/qing-mu-10-60", 
        "https://www.zhihu.com/people/bigpotatoc", 
        "https://www.zhihu.com/people/yang-troy-89", 
        "https://www.zhihu.com/people/qichao-tang", 
        "https://www.zhihu.com/people/gao-zi-hang-25", 
        "https://www.zhihu.com/people/gcbanana", 
        "https://www.zhihu.com/people/MrBayes", 
        "https://www.zhihu.com/people/luo-man-di-ke-39", 
        "https://www.zhihu.com/people/Micro-Kun", 
        "https://www.zhihu.com/people/homer-wong-33", 
        "https://www.zhihu.com/people/wei-yuan-88-25", 
        "https://www.zhihu.com/people/jxz-2-51", 
        "https://www.zhihu.com/people/mai-zhen-sheng", 
        "https://www.zhihu.com/people/bayron-pan", 
        "https://www.zhihu.com/people/linyk3", 
        "https://www.zhihu.com/people/peng-jia-wei-78", 
        "https://www.zhihu.com/people/hjuinj", 
        "https://www.zhihu.com/people/lifeissocool", 
        "https://www.zhihu.com/people/li-bin-3-10", 
        "https://www.zhihu.com/people/jcsyl", 
        "https://www.zhihu.com/people/HWGuderian1994", 
        "https://www.zhihu.com/people/robert.peng", 
        "https://www.zhihu.com/people/yang-zhao-yu-90", 
        "https://www.zhihu.com/people/donald-chen-4", 
        "https://www.zhihu.com/people/wanggehao147"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/40115734", 
            "userName": "啊黎", 
            "userLink": "https://www.zhihu.com/people/fc041681e59a65c527e708d2c2ebdecc", 
            "upvote": 1, 
            "title": "李纪为论文集(4) - GAN for Dialog Gen", 
            "content": "<p>现在怎么标题限制长度了。。。</p><h2><b>李纪为论文集(4)  - Adversarial Learning for Neural Dialogue Generation论文浅析</b></h2><p class=\"ztext-empty-paragraph\"><br/></p><p><b>背景</b></p><p>好的机器对话生成应该是与人类生成的是难于区分的，因此本文引入GAN的套路，结合RL来做自然对话生成任务。</p><p>本文提出了基于GAN框架的自然语言对话生成模型，包括generator（一个SEQ2SEQ模型），定义了生成对话句子的概率模型；和一个discriminator，用以判别该句子是由机器生成的还是由人类生成的。同时把任务转换成reinforcement learning任务，discriminator的输出作为generator的reward，去惩罚generator生成的那些异于常人生成的句子。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>Adversarial Training for Dialogue Generation</b></p><p><b>概念定义</b></p><p>policy model ： encoder-decoder RNN</p><p>action ： 生成的下一个单词</p><p>state ： 当前已生成的单词序列</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>模型定义</b></p><p>Generative model ： 一个简单的SEQ2SEQ模型，输入为上文x，输出为下文y。</p><p>Discriminator model ： 输入为{x,y}，通过hierarchical encoder编码得到hidden state的，最终输出为一个概率值的模型，判断是机器生成（或人类生成）的概率。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>Reward for Every Generation Step (REGS)</b></p><p>传统的RL模型，对一句话中所有的token都反馈一样的reward，(比如 I, don&#39;t, know)，本文希望 I 的reward是中立的，而其他两个token的reward是负面的，因此定义这种按token的reward叫做REGS。</p><p>然而，discriminator针对的是完整的一个句子的reward，并不能对一部分的句子提供reward，因此本文提出了两种方法：（1）用蒙特卡洛搜索的方法，（2）判别器针对局部的句子来训练</p><ol><li><b>Monte Carlo search</b></li></ol><p>MC策略，对于当前的一个已生成的部分文本，剩下的部分采用随机采样的方法采样到结束。  重复N=5次。N个一样前缀的，剩下的用随机采样方法生成的句子丢到判别器，得到的<b>平均分数作为前缀部分的reward</b>。</p><p>缺点是，要重复采样很多次，时间成本高。</p><p><b>2. 直接针对生成的部分的句子来训练判别器</b></p><p>目的是想让判别器对每个部分都直接给reward。因此在针对判别器进行训练的时候，先用生成器生成一系列完整的句子，定义为负样本；再定义真实人生成的句子为正样本。因此输入判别器的正负样本分别是<b>相同时刻t长度的正负样本的对应前缀部分，也就是从两个集合中各抽取1:t的前缀作为discriminator的正负样本。</b></p><p>缺点是，由于discriminator接受了部分的句子输入，导致discriminator不够准确。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>整个训练的过程是：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-10133de867e7772b96e92ec60e7a2519_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"561\" data-rawheight=\"712\" class=\"origin_image zh-lightbox-thumb\" width=\"561\" data-original=\"https://pic2.zhimg.com/v2-10133de867e7772b96e92ec60e7a2519_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;561&#39; height=&#39;712&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"561\" data-rawheight=\"712\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"561\" data-original=\"https://pic2.zhimg.com/v2-10133de867e7772b96e92ec60e7a2519_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-10133de867e7772b96e92ec60e7a2519_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>Teacher Forcing</b></p><p>实际上，直接通过RL或者REGS来训练generator会非常不稳定。主要原因是通过reward来反馈generator生成的句子，不能直接反馈到真实的目标回复。也就是<b>generator知道自己生成的句子很烂，但是并不知道好的生成应该是怎样的，discriminator没有告诉它。</b></p><p>为了缓和这种情况，本文加入了teacher forcing的约束的两种方法：</p><ol><li>在generator更新的时候，不仅惩罚差的生成的句子，对于真实的句子在generator上的生成概率，通过令reward=1的回报也去更新。其实换个角度就是跟SEQ2SEQ一样，加入真实的MLE loss。</li><li>discriminator对真实的Y打分，当reward超过了threshold，再更新generator。对比第一种方法，其优点是可以对不同的真实Y有不同的reward。</li></ol><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>训练细节</b></h2><p>训练SEQ2SEQ的时候用了gradient clipping, mini-batch and learning rate decay 等参考<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1409.3215\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Sutskever论文</a>的实现细节。</p><p>关于增强数据方面：</p><ol><li>设定长度阈值=5，小于该长度的数据扔掉</li><li>用平均tf-idf score来给每一个样本算个样本权重</li><li>参考<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1611.08562\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">作者自己的另一篇论文</a>的方法重排序</li><li>惩罚那些已经生成过的单词（停用词除外）</li></ol><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>实验效果</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-60b18a4d39b94b7b45c20bdeb02f86c7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1131\" data-rawheight=\"556\" class=\"origin_image zh-lightbox-thumb\" width=\"1131\" data-original=\"https://pic4.zhimg.com/v2-60b18a4d39b94b7b45c20bdeb02f86c7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1131&#39; height=&#39;556&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1131\" data-rawheight=\"556\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1131\" data-original=\"https://pic4.zhimg.com/v2-60b18a4d39b94b7b45c20bdeb02f86c7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-60b18a4d39b94b7b45c20bdeb02f86c7_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-66bbaa376ac8cbe94d8f2013dfc7f394_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"555\" data-rawheight=\"300\" class=\"origin_image zh-lightbox-thumb\" width=\"555\" data-original=\"https://pic1.zhimg.com/v2-66bbaa376ac8cbe94d8f2013dfc7f394_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;555&#39; height=&#39;300&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"555\" data-rawheight=\"300\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"555\" data-original=\"https://pic1.zhimg.com/v2-66bbaa376ac8cbe94d8f2013dfc7f394_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-66bbaa376ac8cbe94d8f2013dfc7f394_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><p>总结</p><p>本文提出了GAN+RL的对话生成模型，并且得到了SOTA的效果。</p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/39794564", 
            "userName": "啊黎", 
            "userLink": "https://www.zhihu.com/people/fc041681e59a65c527e708d2c2ebdecc", 
            "upvote": 1, 
            "title": "Elementwise Attention Gate RNN", 
            "content": "<p>刚看到一篇新发布到arxiv上的文章，本文提出了一个在RNN单元上通用的attention gate结构，而且结构也简单，效果还挺明显的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6357b635e9b5ba4ec3dcca6de2675825_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"483\" data-rawheight=\"370\" class=\"origin_image zh-lightbox-thumb\" width=\"483\" data-original=\"https://pic2.zhimg.com/v2-6357b635e9b5ba4ec3dcca6de2675825_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;483&#39; height=&#39;370&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"483\" data-rawheight=\"370\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"483\" data-original=\"https://pic2.zhimg.com/v2-6357b635e9b5ba4ec3dcca6de2675825_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6357b635e9b5ba4ec3dcca6de2675825_b.jpg\"/></figure><p>其中：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4ada6c3666b58ade5d2cbe0f30fc0656_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"554\" data-rawheight=\"70\" class=\"origin_image zh-lightbox-thumb\" width=\"554\" data-original=\"https://pic3.zhimg.com/v2-4ada6c3666b58ade5d2cbe0f30fc0656_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;554&#39; height=&#39;70&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"554\" data-rawheight=\"70\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"554\" data-original=\"https://pic3.zhimg.com/v2-4ada6c3666b58ade5d2cbe0f30fc0656_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-4ada6c3666b58ade5d2cbe0f30fc0656_b.jpg\"/></figure><p>用sigmoid来做attention gate，那么attention更新后的 <img src=\"https://www.zhihu.com/equation?tex=x_t\" alt=\"x_t\" eeimg=\"1\"/> 作为新的输入：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-871b78dbde345c4c41b9920e0b4143bd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"279\" data-rawheight=\"75\" class=\"content_image\" width=\"279\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;279&#39; height=&#39;75&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"279\" data-rawheight=\"75\" class=\"content_image lazy\" width=\"279\" data-actualsrc=\"https://pic2.zhimg.com/v2-871b78dbde345c4c41b9920e0b4143bd_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><p>实验部分</p><p>用的是三维骨架数据集，所以也不知道对NLP的效果如何。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9a7b22373e015c6c6d76142a8b0ae6ca_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1095\" data-rawheight=\"296\" class=\"origin_image zh-lightbox-thumb\" width=\"1095\" data-original=\"https://pic3.zhimg.com/v2-9a7b22373e015c6c6d76142a8b0ae6ca_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1095&#39; height=&#39;296&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1095\" data-rawheight=\"296\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1095\" data-original=\"https://pic3.zhimg.com/v2-9a7b22373e015c6c6d76142a8b0ae6ca_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9a7b22373e015c6c6d76142a8b0ae6ca_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-dc0b93bef445ef93c75d30e2f749cdc2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1124\" data-rawheight=\"459\" class=\"origin_image zh-lightbox-thumb\" width=\"1124\" data-original=\"https://pic3.zhimg.com/v2-dc0b93bef445ef93c75d30e2f749cdc2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1124&#39; height=&#39;459&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1124\" data-rawheight=\"459\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1124\" data-original=\"https://pic3.zhimg.com/v2-dc0b93bef445ef93c75d30e2f749cdc2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-dc0b93bef445ef93c75d30e2f749cdc2_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-47ec256440b1e107c260afddbe353aff_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1099\" data-rawheight=\"436\" class=\"origin_image zh-lightbox-thumb\" width=\"1099\" data-original=\"https://pic4.zhimg.com/v2-47ec256440b1e107c260afddbe353aff_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1099&#39; height=&#39;436&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1099\" data-rawheight=\"436\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1099\" data-original=\"https://pic4.zhimg.com/v2-47ec256440b1e107c260afddbe353aff_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-47ec256440b1e107c260afddbe353aff_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><p>总结</p><p>简单而有效的attention gate，但是没有在NLP领域做实验，有需要的可以自行尝试。。。</p>", 
            "topic": [
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }
            ], 
            "comments": [
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>这玩意你随便拿份RNN，LSTM等相关的代码，改几行代码就可以尝试了吧。简单是很简单，但是这种有效性真的说得通吗？拿上一个time step的hidden state和output vector，能attention什么？有比较有说服力的可视化效果吗😂？</p>", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "知乎用户", 
                    "userLink": "https://www.zhihu.com/people/0", 
                    "content": "<p>这玩意你随便拿份RNN，LSTM等相关的代码，改几行代码就可以尝试了吧。简单是很简单，但是这种有效性真的说得通吗？拿上一个time step的hidden state和output vector，能attention什么？有比较有说服力的可视化效果吗😂？</p>", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "啊黎", 
                            "userLink": "https://www.zhihu.com/people/fc041681e59a65c527e708d2c2ebdecc", 
                            "content": "并没有，我也觉得有问题。而且效果加这么多，有点假。我也是为了水篇分享而已，别慌。", 
                            "likes": 1, 
                            "replyToAuthor": "知乎用户"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/39790104", 
            "userName": "啊黎", 
            "userLink": "https://www.zhihu.com/people/fc041681e59a65c527e708d2c2ebdecc", 
            "upvote": 3, 
            "title": "Simple Word-Embedding Model", 
            "content": "<p>在paperweekly上看到一篇挺有意思的文章，是ACL2018的paper，写一下自己的笔记。</p><p>参考链接：<a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.09843\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">arxiv地址</a>，<a href=\"https://link.zhihu.com/?target=https%3A//www.paperweekly.site/papers/notes/418\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">paperweekly笔记</a></p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>模型简介</b></h2><p>这篇文章关注自然语言处理中最为简单的模型的有效性：简单的word embedding + simple pooling。该文章主要提出了四种最为简单常见的模型，SWEM：Simple Word-Embedding Model，包括：</p><ul><li><b>SWEM-AVG</b>：基于word embeddings 的 average pooling，作为hidden state。</li><li><b>SWEM-MAX</b>：基于word embeddings 的 max pooling，作为hidden state。</li><li><b>SWEM-CONCAT</b>：将SWEM-AVG和SWEM-MAX concat后，作为hidden state。</li><li><b>SWEM-HIER</b>：将word embeddings分窗口进行avg pool，之后再整体的max pooling，作为hidden state。</li></ul><p>对比的baseline models分别为简单的 <b>LSTM</b> 和 <b>CNN+max-pool</b> 。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>对比试验</b></h2><p>在embedding初始化中，所有的模型都使用GloVe300来初始化，其实这个对SWEM就会比较友好，因为在LSTM/CNN模型中，随机初始化的embeddings效果可能也不会很差，因为在LSTM/CNN模型训练中，embedding也会随之被训练更新。<b>文章也没有验证全部随机初始化的效果对比。</b></p><p>首先简单的SWEM模型的复杂度必定是要比baseline models要低的了：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-efa56dec29d03146d263f3a1f2411771_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"550\" data-rawheight=\"268\" class=\"origin_image zh-lightbox-thumb\" width=\"550\" data-original=\"https://pic2.zhimg.com/v2-efa56dec29d03146d263f3a1f2411771_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;550&#39; height=&#39;268&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"550\" data-rawheight=\"268\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"550\" data-original=\"https://pic2.zhimg.com/v2-efa56dec29d03146d263f3a1f2411771_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-efa56dec29d03146d263f3a1f2411771_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>其次，就是看各大NLP任务的效果评估对比了：</p><ul><li>长文本分类：<b>基本超越baseline models的效果</b>，因为只是baseline，LSTM和CNN的结构也并没有很复杂，baseline models也是16年前的效果。不过SWEM-MAX是可以表达出最能对分类进行影响的top单词。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0f7d3b90f7e1c97730f83a3da9695d23_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1140\" data-rawheight=\"449\" class=\"origin_image zh-lightbox-thumb\" width=\"1140\" data-original=\"https://pic4.zhimg.com/v2-0f7d3b90f7e1c97730f83a3da9695d23_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1140&#39; height=&#39;449&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1140\" data-rawheight=\"449\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1140\" data-original=\"https://pic4.zhimg.com/v2-0f7d3b90f7e1c97730f83a3da9695d23_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0f7d3b90f7e1c97730f83a3da9695d23_b.jpg\"/></figure><ul><li>语言模型方面：基本能达到baseline models的效果，部分数据集甚至超过了baseline。<b>不过我觉得在LM的表现上面，更重要的是decoder的表达能力，所以这个实验结果并没有分类等直接的任务有说服力。</b>而且本文还提到单词顺序对LM的影响，通过用源句子和打乱的句子输入到LSTM中，结果表明了好像单词顺序对LM的影响并没有想象中的那么大。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-2c58536f32998c05c6ee3c77ecbb898d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1096\" data-rawheight=\"388\" class=\"origin_image zh-lightbox-thumb\" width=\"1096\" data-original=\"https://pic2.zhimg.com/v2-2c58536f32998c05c6ee3c77ecbb898d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1096&#39; height=&#39;388&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1096\" data-rawheight=\"388\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1096\" data-original=\"https://pic2.zhimg.com/v2-2c58536f32998c05c6ee3c77ecbb898d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-2c58536f32998c05c6ee3c77ecbb898d_b.jpg\"/></figure><ul><li>短文本分类：短文本中的实验结果就没有长文本那么好的，但是效率高啊~</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-a6de3ff1a333e5db9b32c94e33f7964b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1059\" data-rawheight=\"381\" class=\"origin_image zh-lightbox-thumb\" width=\"1059\" data-original=\"https://pic4.zhimg.com/v2-a6de3ff1a333e5db9b32c94e33f7964b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1059&#39; height=&#39;381&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1059\" data-rawheight=\"381\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1059\" data-original=\"https://pic4.zhimg.com/v2-a6de3ff1a333e5db9b32c94e33f7964b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-a6de3ff1a333e5db9b32c94e33f7964b_b.jpg\"/></figure><ul><li>序列标注：在序列标注上，文章也提到了效果并没有LSTM/CNN的好，主要分析是因为序列标注对语义顺序要求很高。</li></ul><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>总结</b></h2><p>其实这种验证探索性的文章对工程来说意义更大，在平时工程上面要求效果差不多，效率优先的时候，本文就有非常重要的意义，而且能为我们提供一个更加快捷的有效的新的baseline model。而且在目前学术界各种拼凑模型的氛围上，反其道而行，提出并验证了，其实最简单的模型在NLP方面的表现也是可以很好的，在追求复杂模型上提升的效果而导致效率的成倍下降往往是需要衡量的。</p>", 
            "topic": [
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "文本分类", 
                    "tagLink": "https://api.zhihu.com/topics/19576060"
                }, 
                {
                    "tag": "神经网络", 
                    "tagLink": "https://api.zhihu.com/topics/19607065"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/35616565", 
            "userName": "啊黎", 
            "userLink": "https://www.zhihu.com/people/fc041681e59a65c527e708d2c2ebdecc", 
            "upvote": 3, 
            "title": "李纪为论文集(3) - A Persona-Based Neural Conversation Model论文浅析", 
            "content": "<h2><b>背景</b></h2><p>    传统的数据驱动的对话系统倾向于产生高似然度的回复，这就导致了生成的回复虽然是正确的，但是意义不大，尤其是在多轮对话中，问同样意思的问题生成的回复不一样导致上下矛盾的情况出现，如图1所示。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-82374cd562afd9675cb636eb92a3b58b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"535\" data-rawheight=\"562\" class=\"origin_image zh-lightbox-thumb\" width=\"535\" data-original=\"https://pic4.zhimg.com/v2-82374cd562afd9675cb636eb92a3b58b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;535&#39; height=&#39;562&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"535\" data-rawheight=\"562\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"535\" data-original=\"https://pic4.zhimg.com/v2-82374cd562afd9675cb636eb92a3b58b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-82374cd562afd9675cb636eb92a3b58b_b.jpg\"/></figure><p>    为了解决这个回复一致性问题，令数据驱动的对话系统能像人类一样，有自己的“人格（persona）”，本文提出了一个Persona-Based Neural Conversation Model。本文把“人格”解释为一系列的个人特性，比如个人简历背景、说话习惯、与人交互方式等，从而基于Seq2Seq框架提出了两个persona models：<b>(1) a single Speaker Model 和 (2) a dyadic Speaker-Addressee Model</b>。<b>Speaker Model引入了speaker-level vector representation，来学习speaker的属性。</b>而类似地，<b>Speaker-Addressee Model通过建模speaker与addressee两者的vector representation，来构造interaction representation学习面对不同的addressee，speaker不同的属性</b>。实验证明了persona-based model 比 baseline model 在Twitter对话数据集上BLEU超越20%，perplexity超越12%。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>Base Seq2Seq Models</b></h2><p>    传统的seq2seq是基于LSTM的encoder-decoder框架，LSTM表示为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-13fb13b27bdeb38ea5d59f15adf2437f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"273\" class=\"origin_image zh-lightbox-thumb\" width=\"474\" data-original=\"https://pic4.zhimg.com/v2-13fb13b27bdeb38ea5d59f15adf2437f_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;474&#39; height=&#39;273&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"273\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"474\" data-original=\"https://pic4.zhimg.com/v2-13fb13b27bdeb38ea5d59f15adf2437f_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-13fb13b27bdeb38ea5d59f15adf2437f_b.jpg\"/></figure><p>    其中 <img src=\"https://www.zhihu.com/equation?tex=h_%7Bt-1%7D\" alt=\"h_{t-1}\" eeimg=\"1\"/> 表示上一时刻LSTM的输出， <img src=\"https://www.zhihu.com/equation?tex=e%5Es_t\" alt=\"e^s_t\" eeimg=\"1\"/> 表示句子中当前时刻输入词的embedding。在最后的输出还要过一层 <img src=\"https://www.zhihu.com/equation?tex=softmax\" alt=\"softmax\" eeimg=\"1\"/> 函数，来得到预测词表的概率分布：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-e5174f39d3c546a102da72795ec94547_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"506\" data-rawheight=\"172\" class=\"origin_image zh-lightbox-thumb\" width=\"506\" data-original=\"https://pic4.zhimg.com/v2-e5174f39d3c546a102da72795ec94547_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;506&#39; height=&#39;172&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"506\" data-rawheight=\"172\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"506\" data-original=\"https://pic4.zhimg.com/v2-e5174f39d3c546a102da72795ec94547_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-e5174f39d3c546a102da72795ec94547_b.jpg\"/></figure><h2><b>Speaker Model</b></h2><p>    Speaker Model只在回复上进行建模，模型把每一个单独的speaker都映射到一个独立的embedding，用以编码该speaker特有的信息（比如说话方式习惯、年龄性别、个人信息等）。这些特有信息都是没有被明确标注的，而是本文在训练中会对回复中一些特征信息进行用户聚类（但训练的时候应该是没有用到聚类的信息或其他约束）。Speaker Model在传统Seq2Seq模型的decoder部分引入了speaker embedding <img src=\"https://www.zhihu.com/equation?tex=v_i\" alt=\"v_i\" eeimg=\"1\"/> ：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7d71bd9a465d96bf165757129362fd0b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"488\" data-rawheight=\"236\" class=\"origin_image zh-lightbox-thumb\" width=\"488\" data-original=\"https://pic4.zhimg.com/v2-7d71bd9a465d96bf165757129362fd0b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;488&#39; height=&#39;236&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"488\" data-rawheight=\"236\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"488\" data-original=\"https://pic4.zhimg.com/v2-7d71bd9a465d96bf165757129362fd0b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-7d71bd9a465d96bf165757129362fd0b_b.jpg\"/></figure><p><b><img src=\"https://www.zhihu.com/equation?tex=v_i\" alt=\"v_i\" eeimg=\"1\"/> 是在每一时刻都作为输入的一部分引入到decoder中，从实现上来讲，我们把 <img src=\"https://www.zhihu.com/equation?tex=v_i\" alt=\"v_i\" eeimg=\"1\"/> 与 <img src=\"https://www.zhihu.com/equation?tex=e%5Es_t\" alt=\"e^s_t\" eeimg=\"1\"/> concat之后，再输入到LSTM中即可，无须修改LSTM结构</b>。Speaker在有相近的speaker embedding时会产生相似的responses，所以在训练的时候那些来自不同speaker的相似的responses会促使模型学习出这些speaker embedding在向量空间中更加靠近。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>Speaker-Addressee Model</b></h2><p>    speaker model把人特有的一些信息成功建模了，然而在更常见的情况是，同一个人可能对不同的说话者会有不同的说话方式和内容，因此把speaker model扩展成speaker-addressee model，<b>把对话双方的speaker embedding组合构造出interactive embedding，来表示speaker在面对addressee下的一些交互风格等特性：</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-026afda8eb247ba7d266d3d46bc24dc2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"469\" data-rawheight=\"74\" class=\"origin_image zh-lightbox-thumb\" width=\"469\" data-original=\"https://pic3.zhimg.com/v2-026afda8eb247ba7d266d3d46bc24dc2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;469&#39; height=&#39;74&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"469\" data-rawheight=\"74\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"469\" data-original=\"https://pic3.zhimg.com/v2-026afda8eb247ba7d266d3d46bc24dc2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-026afda8eb247ba7d266d3d46bc24dc2_b.jpg\"/></figure><p>    然后与speaker model一样，作为decoder输入的一部分：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-7cea21af539e920b3480196c8750fb64_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"453\" data-rawheight=\"136\" class=\"origin_image zh-lightbox-thumb\" width=\"453\" data-original=\"https://pic1.zhimg.com/v2-7cea21af539e920b3480196c8750fb64_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;453&#39; height=&#39;136&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"453\" data-rawheight=\"136\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"453\" data-original=\"https://pic1.zhimg.com/v2-7cea21af539e920b3480196c8750fb64_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-7cea21af539e920b3480196c8750fb64_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-2b1b92c423a8b9819033b71be45214bf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"396\" data-rawheight=\"86\" class=\"content_image\" width=\"396\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;396&#39; height=&#39;86&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"396\" data-rawheight=\"86\" class=\"content_image lazy\" width=\"396\" data-actualsrc=\"https://pic4.zhimg.com/v2-2b1b92c423a8b9819033b71be45214bf_b.jpg\"/></figure><p>    实现上与speaker model一样，<b>把 <img src=\"https://www.zhihu.com/equation?tex=V_%7Bij%7D\" alt=\"V_{ij}\" eeimg=\"1\"/> 与 <img src=\"https://www.zhihu.com/equation?tex=e%5Es_t\" alt=\"e^s_t\" eeimg=\"1\"/> concat作为LSTM的输入即可</b>。虽然想要构造大量的符合speaker-addressee model的训练数据非常困难，但是得益于speaker embedding，即使同一组speaker和addressee的数量非常少，但是相似的对话组还是能学习到相近的speaker embedding，从而使interactive embedding有意义。即使 speakers <img src=\"https://www.zhihu.com/equation?tex=i\" alt=\"i\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=j\" alt=\"j\" eeimg=\"1\"/> 从来没有在训练集中交互过，但是在测试的时候相近的 <img src=\"https://www.zhihu.com/equation?tex=i%27\" alt=\"i&#39;\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=j%27\" alt=\"j&#39;\" eeimg=\"1\"/> 可以提供有用的信息，使得模型work。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>模型结构图</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9b5706b087e203da3277c91d3354a3fe_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1128\" data-rawheight=\"555\" class=\"origin_image zh-lightbox-thumb\" width=\"1128\" data-original=\"https://pic3.zhimg.com/v2-9b5706b087e203da3277c91d3354a3fe_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1128&#39; height=&#39;555&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1128\" data-rawheight=\"555\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1128\" data-original=\"https://pic3.zhimg.com/v2-9b5706b087e203da3277c91d3354a3fe_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9b5706b087e203da3277c91d3354a3fe_b.jpg\"/></figure><h2>Decoding and Reranking</h2><ul><li>用beam-search来decode，B=200，最后candidate list大小取20。</li><li>用类似<a href=\"https://zhuanlan.zhihu.com/p/35496909\" class=\"internal\">MMI</a>的方法来进行rerank，每个候选句子的得分计算如下， <img src=\"https://www.zhihu.com/equation?tex=p%28M%7CR%29\" alt=\"p(M|R)\" eeimg=\"1\"/> 是一个预训练的无speaker-information的反向的seq2seq模型， <img src=\"https://www.zhihu.com/equation?tex=%7CR%7C\" alt=\"|R|\" eeimg=\"1\"/> 表示句子长度。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fec051ff0835cd9a07fa462b4a4f3a1a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"501\" data-rawheight=\"60\" class=\"origin_image zh-lightbox-thumb\" width=\"501\" data-original=\"https://pic3.zhimg.com/v2-fec051ff0835cd9a07fa462b4a4f3a1a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;501&#39; height=&#39;60&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"501\" data-rawheight=\"60\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"501\" data-original=\"https://pic3.zhimg.com/v2-fec051ff0835cd9a07fa462b4a4f3a1a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fec051ff0835cd9a07fa462b4a4f3a1a_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>Training Details</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-41558fcdd357c7fa656f169b34c81f67_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"478\" data-rawheight=\"97\" class=\"origin_image zh-lightbox-thumb\" width=\"478\" data-original=\"https://pic4.zhimg.com/v2-41558fcdd357c7fa656f169b34c81f67_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;478&#39; height=&#39;97&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"478\" data-rawheight=\"97\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"478\" data-original=\"https://pic4.zhimg.com/v2-41558fcdd357c7fa656f169b34c81f67_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-41558fcdd357c7fa656f169b34c81f67_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9073da62b2d3c272727cbc63b1e4f364_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"513\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb\" width=\"513\" data-original=\"https://pic1.zhimg.com/v2-9073da62b2d3c272727cbc63b1e4f364_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;513&#39; height=&#39;222&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"513\" data-rawheight=\"222\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"513\" data-original=\"https://pic1.zhimg.com/v2-9073da62b2d3c272727cbc63b1e4f364_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-9073da62b2d3c272727cbc63b1e4f364_b.jpg\"/></figure><p>    更详细见论文。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>实验结果</b></h2><ul><li>Twitter Sordoni dataset</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-d57043f449245704900a571492002a5d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"523\" data-rawheight=\"385\" class=\"origin_image zh-lightbox-thumb\" width=\"523\" data-original=\"https://pic2.zhimg.com/v2-d57043f449245704900a571492002a5d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;523&#39; height=&#39;385&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"523\" data-rawheight=\"385\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"523\" data-original=\"https://pic2.zhimg.com/v2-d57043f449245704900a571492002a5d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-d57043f449245704900a571492002a5d_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><ul><li>Twitter Persona dataset</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-a0a941d489cbd3207259cd0cd97fce96_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"532\" data-rawheight=\"434\" class=\"origin_image zh-lightbox-thumb\" width=\"532\" data-original=\"https://pic3.zhimg.com/v2-a0a941d489cbd3207259cd0cd97fce96_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;532&#39; height=&#39;434&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"532\" data-rawheight=\"434\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"532\" data-original=\"https://pic3.zhimg.com/v2-a0a941d489cbd3207259cd0cd97fce96_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-a0a941d489cbd3207259cd0cd97fce96_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><ul><li>TV series dataset</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c51a430827cfcf0a41b985558aca1e0d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"872\" data-rawheight=\"308\" class=\"origin_image zh-lightbox-thumb\" width=\"872\" data-original=\"https://pic2.zhimg.com/v2-c51a430827cfcf0a41b985558aca1e0d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;872&#39; height=&#39;308&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"872\" data-rawheight=\"308\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"872\" data-original=\"https://pic2.zhimg.com/v2-c51a430827cfcf0a41b985558aca1e0d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c51a430827cfcf0a41b985558aca1e0d_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>    模型在指标上面的突破对比baseline很明显，虽然在对比<a href=\"https://zhuanlan.zhihu.com/p/35496909\" class=\"internal\">MMI</a>的提升没有很明显，但是是有所提升的，而且本文的理论贡献很有意义。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>生成的对话</b></h2><ul><li>这份生成的对话说明了不同的speaker生成的对话是存在一定的多样性。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c0dbfc347895193847451137bbecaf77_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"276\" data-rawheight=\"489\" class=\"content_image\" width=\"276\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;276&#39; height=&#39;489&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"276\" data-rawheight=\"489\" class=\"content_image lazy\" width=\"276\" data-actualsrc=\"https://pic4.zhimg.com/v2-c0dbfc347895193847451137bbecaf77_b.jpg\"/></figure><ul><li>这份生成的对话说明了speaker-addressee的生成是达到了预期的效果</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-33dbc19d6bfaa221e9af71a077b1cfc0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"541\" data-rawheight=\"534\" class=\"origin_image zh-lightbox-thumb\" width=\"541\" data-original=\"https://pic1.zhimg.com/v2-33dbc19d6bfaa221e9af71a077b1cfc0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;541&#39; height=&#39;534&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"541\" data-rawheight=\"534\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"541\" data-original=\"https://pic1.zhimg.com/v2-33dbc19d6bfaa221e9af71a077b1cfc0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-33dbc19d6bfaa221e9af71a077b1cfc0_b.jpg\"/></figure><ul><li>即使在多轮对话中，speaker model仍然可以保持speaker的属性。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c015f5e688ac2fb17f2031026376e445_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"368\" data-rawheight=\"590\" class=\"content_image\" width=\"368\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;368&#39; height=&#39;590&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"368\" data-rawheight=\"590\" class=\"content_image lazy\" width=\"368\" data-actualsrc=\"https://pic2.zhimg.com/v2-c015f5e688ac2fb17f2031026376e445_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>总结</b></h2><p>    本文提出了两个persona-based response generation models，(1)Speaker Model生成的对话更具有人格特性，也就是同一个speaker在面对相似问题时可以回复一致；(2)Speaker-Address Model在同一个speaker面对不同的addressee时，会有多样化的interactive style。本文在实现上非常简单，但是效果非常显著，而且persona-based dialog system的实用性也是非常广。</p>", 
            "topic": [
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "对话系统", 
                    "tagLink": "https://api.zhihu.com/topics/20141243"
                }, 
                {
                    "tag": "人工智能", 
                    "tagLink": "https://api.zhihu.com/topics/19551275"
                }
            ], 
            "comments": [
                {
                    "userName": "麦小彤", 
                    "userLink": "https://www.zhihu.com/people/2384fb338f5c9db04f5b0b43811e38c4", 
                    "content": "还是没懂如何训练speaker embedding", 
                    "likes": 0, 
                    "childComments": [
                        {
                            "userName": "啊黎", 
                            "userLink": "https://www.zhihu.com/people/fc041681e59a65c527e708d2c2ebdecc", 
                            "content": "<p>我们传统的LSTM输入只是当前时刻的e_t(word embedding)，还有框架已经实现好的hidden state。。而在论文的实现中，我们把LSTM的输入的e_t变成[e_t || v_i]，就可以训练v_i了。。。</p>", 
                            "likes": 0, 
                            "replyToAuthor": "麦小彤"
                        }, 
                        {
                            "userName": "知乎用户", 
                            "userLink": "https://www.zhihu.com/people/0", 
                            "content": "<p>你好，最近我也在调研这篇文章，所以也对spaeker embedding这个问题很困惑。所以，你们实现的方法是在训练网络的过程中获得speaker embedding，而不是事先训练出spaeaker embedding送进去吗？</p>", 
                            "likes": 0, 
                            "replyToAuthor": "啊黎"
                        }
                    ]
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/35571411", 
            "userName": "啊黎", 
            "userLink": "https://www.zhihu.com/people/fc041681e59a65c527e708d2c2ebdecc", 
            "upvote": 2, 
            "title": "李纪为论文集(2) - Deep Reinforcement Learning for Dialogue Generation论文浅析", 
            "content": "<h2><b>背景</b></h2><p>  当前的对话生成往往都只针对前一轮的对话来进行，非常不利于对话的延续。而且这些对话系统在生成回复的时候通常会生成那些无意义的通用的回复，也会导致对话无法顺利进行下去，而且有时会出现循环的情况，比如图1左边部分所示。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-008e0c5972e1bcacc37c5c24ff930f2d_b.jpg\" data-size=\"normal\" data-rawwidth=\"746\" data-rawheight=\"495\" class=\"origin_image zh-lightbox-thumb\" width=\"746\" data-original=\"https://pic2.zhimg.com/v2-008e0c5972e1bcacc37c5c24ff930f2d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;746&#39; height=&#39;495&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"746\" data-rawheight=\"495\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"746\" data-original=\"https://pic2.zhimg.com/v2-008e0c5972e1bcacc37c5c24ff930f2d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-008e0c5972e1bcacc37c5c24ff930f2d_b.jpg\"/><figcaption>图 1</figcaption></figure><p>  为了解决这些问题，使得对话生成更加有利于话题或对话的延续(long term goals)，本文提出了结合增强学习（reinforcement learning, RL）的Seq2Seq对话生成网络，为RL定义了三种rewards：(1) 有前瞻性（forward looking）或者是有相互作用的（interactive）的对话，(2) 有益的回复，和 (3) 相关的（coherent）回复。实验证明了RL+Seq2Seq比基于传统MLE loss的Seq2Seq（<b>又一次针对了MLE loss</b>）生成的回复更能促进对话的进行。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>RL+SEQ2SEQ</h2><p>   定义 <img src=\"https://www.zhihu.com/equation?tex=p\" alt=\"p\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=q\" alt=\"q\" eeimg=\"1\"/> 是两个对话的agents，他们的对话表示为： <img src=\"https://www.zhihu.com/equation?tex=p_1%2Cq_1%2Cp_2%2Cq_2%2C...%2Cp_i%2Cq_i\" alt=\"p_1,q_1,p_2,q_2,...,p_i,q_i\" eeimg=\"1\"/> ，下面定义RL的一些变量：</p><p><b>Action</b></p><p>   Action <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 是对话系统生成的对话。Action的值空间是无穷的，因为生成句子的长度是任意的。</p><p><b>State</b></p><p>   State定义为上一轮的对话 <img src=\"https://www.zhihu.com/equation?tex=%5Bp_i%2Cq_i%5D\" alt=\"[p_i,q_i]\" eeimg=\"1\"/> 。 <img src=\"https://www.zhihu.com/equation?tex=p_i\" alt=\"p_i\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=q_i\" alt=\"q_i\" eeimg=\"1\"/> 均为Seq2Seq中encoder输出的vector representation，并concat到一起。</p><p><b>Policy</b></p><p>   Policy定义为基于encoder-decoder的模型（ <img src=\"https://www.zhihu.com/equation?tex=p_%7BRL%7D%28p_%7Bi%2B1%7D%7Cp_i%2Cq_i%29\" alt=\"p_{RL}(p_{i+1}|p_i,q_i)\" eeimg=\"1\"/> ），本文具体定义为给定State产生Actions的概率分布的模型。</p><p><b>Reward</b></p><p>   Reward定义为每一个action之后对应的回报，本文提出了三个重要的reward部分：</p><ul><li><b>Ease of Answering</b>：这部分是为了减缓对话系统生成那些无聊的回复，<b>本文构造了一组dull responses <img src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/> ，用seq2seq模型来对生成这组dull responses计算negative log-likelihood（NLL）值作为reward。</b>dull responses list只需要构造少量的dull responses，不仅因为大部分的dull responses形式和向量空间表示都基本差不多，还可以减少计算量。 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bseq2seq%7D\" alt=\"p_{seq2seq}\" eeimg=\"1\"/> 是在训练集中用MLE loss预训练的模型，但是<b>有点不理解的是，为什么是给定action <img src=\"https://www.zhihu.com/equation?tex=a\" alt=\"a\" eeimg=\"1\"/> 生成dull response <img src=\"https://www.zhihu.com/equation?tex=s\" alt=\"s\" eeimg=\"1\"/> 的NLL值，而不是给定state <img src=\"https://www.zhihu.com/equation?tex=%5Bp_i%2Cq_i%5D\" alt=\"[p_i,q_i]\" eeimg=\"1\"/> 。</b></li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-0b591cf16010bea72b1319c927831ba3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"493\" data-rawheight=\"87\" class=\"origin_image zh-lightbox-thumb\" width=\"493\" data-original=\"https://pic4.zhimg.com/v2-0b591cf16010bea72b1319c927831ba3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;493&#39; height=&#39;87&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"493\" data-rawheight=\"87\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"493\" data-original=\"https://pic4.zhimg.com/v2-0b591cf16010bea72b1319c927831ba3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-0b591cf16010bea72b1319c927831ba3_b.jpg\"/></figure><ul><li><b>Information Flow</b>：作者希望每次生成的句子都能引入新的信息和话题，而不是重复上一次的信息。<b>因此定义了一个衡量上一次生成的句子和当前生成句子的cosine相似度的惩罚项reward</b>。 <img src=\"https://www.zhihu.com/equation?tex=h_%7Bp_i%7D\" alt=\"h_{p_i}\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=h_%7Bp_%7Bi%2B1%7D%7D\" alt=\"h_{p_{i+1}}\" eeimg=\"1\"/> 表示sentence representation，是 <img src=\"https://www.zhihu.com/equation?tex=p_i\" alt=\"p_i\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bi%2B1%7D\" alt=\"p_{i+1}\" eeimg=\"1\"/> 输入到encoder的最后时刻的输出。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fbefef28956616f807ef4a2068c530aa_b.jpg\" data-size=\"normal\" data-rawwidth=\"523\" data-rawheight=\"104\" class=\"origin_image zh-lightbox-thumb\" width=\"523\" data-original=\"https://pic3.zhimg.com/v2-fbefef28956616f807ef4a2068c530aa_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;523&#39; height=&#39;104&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"523\" data-rawheight=\"104\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"523\" data-original=\"https://pic3.zhimg.com/v2-fbefef28956616f807ef4a2068c530aa_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fbefef28956616f807ef4a2068c530aa_b.jpg\"/><figcaption>Information Flow Reward</figcaption></figure><ul><li><b>Semantic Coherence</b>：作者希望生成的回复是语意相关的，避免生成那些不符合语法的或者是不相关的句子，因此引入<a href=\"https://zhuanlan.zhihu.com/p/35496909?group_id=967066537383919616\" class=\"internal\">互信息</a>来衡量此情况。<b>本文考虑当前action与历史信息之间的互信息作为reward，来确保生成回复是语意相关的</b>。与上一篇文章一样的定义， <img src=\"https://www.zhihu.com/equation?tex=p_%7Bseq2seq%7D%28a%7Cp_i%2Cq_i%29\" alt=\"p_{seq2seq}(a|p_i,q_i)\" eeimg=\"1\"/> 表示正向的回复生成的模型， <img src=\"https://www.zhihu.com/equation?tex=p%5E%7Bbackward%7D_%7Bseq2seq%7D%28q_i%7Ca%29\" alt=\"p^{backward}_{seq2seq}(q_i|a)\" eeimg=\"1\"/> 则表示反向的相关性部分的模型。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-11b5b4fe09054707e936a2e990198f49_b.jpg\" data-size=\"normal\" data-rawwidth=\"522\" data-rawheight=\"104\" class=\"origin_image zh-lightbox-thumb\" width=\"522\" data-original=\"https://pic2.zhimg.com/v2-11b5b4fe09054707e936a2e990198f49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;522&#39; height=&#39;104&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"522\" data-rawheight=\"104\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"522\" data-original=\"https://pic2.zhimg.com/v2-11b5b4fe09054707e936a2e990198f49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-11b5b4fe09054707e936a2e990198f49_b.jpg\"/><figcaption>Semantic Coherence Reward</figcaption></figure><ul><li>最后总的reward由这三部分加权得到：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-6f48492501147d2017a3b27d69504bf4_b.jpg\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"165\" class=\"origin_image zh-lightbox-thumb\" width=\"514\" data-original=\"https://pic1.zhimg.com/v2-6f48492501147d2017a3b27d69504bf4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;514&#39; height=&#39;165&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"165\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"514\" data-original=\"https://pic1.zhimg.com/v2-6f48492501147d2017a3b27d69504bf4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-6f48492501147d2017a3b27d69504bf4_b.jpg\"/><figcaption>Final Reward</figcaption></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>模型训练（仿真）</b></h2><p>    本文的训练方法是用同样的模型来构造两个agent来互相对话，从而训练学习得对话选择策略 <img src=\"https://www.zhihu.com/equation?tex=p_%7BRL%7D%28p_%7Bi%2B1%7D%7Cp_i%2Cq_i%29\" alt=\"p_{RL}(p_{i+1}|p_i,q_i)\" eeimg=\"1\"/> 。<b>本文使用policy gradient的方法来进行RL训练，不用Q-learning是因为(1)不需要建模学习reward函数，reward可以直接给出，(2)模型可以用SEQ2SEQ来预先初始化，直接学习policy network更加方面直接</b>。</p><p><b>Mutual Information 模型训练部分</b></p><p>    训练集训练seq2seq模型（with attention）。然后用训练完成的seq2seq模型参数初始化policy model <img src=\"https://www.zhihu.com/equation?tex=p_%7BRL%7D\" alt=\"p_{RL}\" eeimg=\"1\"/> ，给定输入的state <img src=\"https://www.zhihu.com/equation?tex=%5Bp_i%2Cq_i%5D\" alt=\"[p_i,q_i]\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=p_%7BRL%7D\" alt=\"p_{RL}\" eeimg=\"1\"/> 生成一组候选回复 <img src=\"https://www.zhihu.com/equation?tex=A%3D%5C%7B%5Chat%7Ba%7D%7C%5Chat%7Ba%7D%5Csim+p_%7BRL%7D%5C%7D\" alt=\"A=\\{\\hat{a}|\\hat{a}\\sim p_{RL}\\}\" eeimg=\"1\"/> ，对于每一个候选回复，通过与训练的模型 <img src=\"https://www.zhihu.com/equation?tex=p_%7Bseq2seq%7D%28%5Chat%7Ba%7D%7Cp_i%2Cq_i%29\" alt=\"p_{seq2seq}(\\hat{a}|p_i,q_i)\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=p%5E%7Bbackward%7D_%7Bseq2seq%7D%28q_i%7C%5Chat%7Ba%7D%29\" alt=\"p^{backward}_{seq2seq}(q_i|\\hat{a})\" eeimg=\"1\"/> 计算其互信息得分 <img src=\"https://www.zhihu.com/equation?tex=m%28%5Chat%7Ba%7D%2C%5Bp_i%2Cq_i%5D%29\" alt=\"m(\\hat{a},[p_i,q_i])\" eeimg=\"1\"/> 。所以reward的期望为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-9467f81c2567392fef8d19c6aa42a17c_b.jpg\" data-size=\"normal\" data-rawwidth=\"407\" data-rawheight=\"72\" class=\"content_image\" width=\"407\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;407&#39; height=&#39;72&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"407\" data-rawheight=\"72\" class=\"content_image lazy\" width=\"407\" data-actualsrc=\"https://pic1.zhimg.com/v2-9467f81c2567392fef8d19c6aa42a17c_b.jpg\"/><figcaption>Policy model Loss</figcaption></figure><p>可以通过梯度下降来训练policy model：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-6f4ef2162f79a5f2d2d7eccb98ad0a49_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"432\" data-rawheight=\"55\" class=\"origin_image zh-lightbox-thumb\" width=\"432\" data-original=\"https://pic2.zhimg.com/v2-6f4ef2162f79a5f2d2d7eccb98ad0a49_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;432&#39; height=&#39;55&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"432\" data-rawheight=\"55\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"432\" data-original=\"https://pic2.zhimg.com/v2-6f4ef2162f79a5f2d2d7eccb98ad0a49_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-6f4ef2162f79a5f2d2d7eccb98ad0a49_b.jpg\"/></figure><p>特别的，对每个长度为 <img src=\"https://www.zhihu.com/equation?tex=T\" alt=\"T\" eeimg=\"1\"/> 的句子前 <img src=\"https://www.zhihu.com/equation?tex=L\" alt=\"L\" eeimg=\"1\"/> 个tokens用MLE loss来建模而后 <img src=\"https://www.zhihu.com/equation?tex=T-L\" alt=\"T-L\" eeimg=\"1\"/> 个tokens用reinforcement algorithm， <img src=\"https://www.zhihu.com/equation?tex=L\" alt=\"L\" eeimg=\"1\"/> 不断退化到0。</p><p><b>仿真交互对话策略选择训练部分</b></p><p>    先训练上一部分基于mutual information的 <img src=\"https://www.zhihu.com/equation?tex=p_%7BRL%7D\" alt=\"p_{RL}\" eeimg=\"1\"/> 的参数，然后通过policy gradient方法来找到最好的参数来最大化reward：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-40af802ee0e1e6f384000a4099ac7f39_b.jpg\" data-size=\"normal\" data-rawwidth=\"463\" data-rawheight=\"88\" class=\"origin_image zh-lightbox-thumb\" width=\"463\" data-original=\"https://pic2.zhimg.com/v2-40af802ee0e1e6f384000a4099ac7f39_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;463&#39; height=&#39;88&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"463\" data-rawheight=\"88\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"463\" data-original=\"https://pic2.zhimg.com/v2-40af802ee0e1e6f384000a4099ac7f39_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-40af802ee0e1e6f384000a4099ac7f39_b.jpg\"/><figcaption>Policy Gradient Loss</figcaption></figure><p>因此策略的梯度为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-c00f3d4c9084ae17bfdad10c4f8ac16b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"105\" class=\"origin_image zh-lightbox-thumb\" width=\"514\" data-original=\"https://pic4.zhimg.com/v2-c00f3d4c9084ae17bfdad10c4f8ac16b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;514&#39; height=&#39;105&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"105\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"514\" data-original=\"https://pic4.zhimg.com/v2-c00f3d4c9084ae17bfdad10c4f8ac16b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-c00f3d4c9084ae17bfdad10c4f8ac16b_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>实验结果</h2><ul><li>对话的轮数有明显提升：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-1426d0047b861baa4b4e73a784dd501a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"520\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb\" width=\"520\" data-original=\"https://pic3.zhimg.com/v2-1426d0047b861baa4b4e73a784dd501a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;520&#39; height=&#39;238&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"520\" data-rawheight=\"238\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"520\" data-original=\"https://pic3.zhimg.com/v2-1426d0047b861baa4b4e73a784dd501a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-1426d0047b861baa4b4e73a784dd501a_b.jpg\"/></figure><ul><li>在生成的多样性方面也是有所提升：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-07ee09784d6546e63592fc7eb554170c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"224\" class=\"origin_image zh-lightbox-thumb\" width=\"524\" data-original=\"https://pic1.zhimg.com/v2-07ee09784d6546e63592fc7eb554170c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;524&#39; height=&#39;224&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"524\" data-rawheight=\"224\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"524\" data-original=\"https://pic1.zhimg.com/v2-07ee09784d6546e63592fc7eb554170c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-07ee09784d6546e63592fc7eb554170c_b.jpg\"/></figure><ul><li>仿真方面的回复也比baseline要好：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-5da901852da4c87863b0cb4f39938da7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1065\" data-rawheight=\"316\" class=\"origin_image zh-lightbox-thumb\" width=\"1065\" data-original=\"https://pic4.zhimg.com/v2-5da901852da4c87863b0cb4f39938da7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1065&#39; height=&#39;316&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1065\" data-rawheight=\"316\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1065\" data-original=\"https://pic4.zhimg.com/v2-5da901852da4c87863b0cb4f39938da7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-5da901852da4c87863b0cb4f39938da7_b.jpg\"/></figure><ul><li>当然也有一些bad case，比如虽然有避免循环的reward来限制循环对话，但是还是会出现这样的case：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-fe90899778b0f7e75cec0609f7b97b6c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"538\" data-rawheight=\"344\" class=\"origin_image zh-lightbox-thumb\" width=\"538\" data-original=\"https://pic1.zhimg.com/v2-fe90899778b0f7e75cec0609f7b97b6c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;538&#39; height=&#39;344&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"538\" data-rawheight=\"344\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"538\" data-original=\"https://pic1.zhimg.com/v2-fe90899778b0f7e75cec0609f7b97b6c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-fe90899778b0f7e75cec0609f7b97b6c_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>总结</b></h2><p>    本文提出了通过RL+SEQ2SEQ的模型来捕获未来性的reward和全局的信息，保证对话不会陷入循环或者无意义的回复，从而保持良好的可持续的交谈。创新性地提出了三种评估对话生成reward，并通过policy gradient的方法来训练policy model。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2>参考文献</h2><p><a href=\"https://zhuanlan.zhihu.com/p/27699682\" class=\"internal\">荐译一篇通俗易懂的策略梯度方法讲解 - 知乎</a> </p><p><a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1606.01541\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Jiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, Jianfeng Gao: Deep Reinforcement Learning for Dialogue Generation. EMNLP 2016: 1192-1202</a></p>", 
            "topic": [
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "强化学习 (Reinforcement Learning)", 
                    "tagLink": "https://api.zhihu.com/topics/20039099"
                }, 
                {
                    "tag": "对话系统", 
                    "tagLink": "https://api.zhihu.com/topics/20141243"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/35496909", 
            "userName": "啊黎", 
            "userLink": "https://www.zhihu.com/people/fc041681e59a65c527e708d2c2ebdecc", 
            "upvote": 4, 
            "title": "李纪为论文集(1) - A Diversity-Promoting Objective Function for Neural Conversation Models论文浅析", 
            "content": "<p><a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1510.03055v3\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">A Diversity-Promoting Objective Function for Neural Conversation Models</a> 这篇论文应该是李纪为大大的第一篇文章。<b>本文提出了一个新的目标函数MMI来建模Seq2Seq，使得生成的回复能更具多样性。</b></p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>背景</b></h2><p>   在对话系统中，传统的Seq2Seq模型通常会倾向于产生一些“安全的”和“平常的”回复，比如“I don&#39;t know”或者“I&#39;m OK”之类的句子，并不能使得产生的回复多元化。虽然那些有意义的回复或者特别的回复都能产生在候选的list里面，但是其得分排名往往很低。出现这种情况的原因在于模型的Loss的优化方向会使得这些经常出现的句子的likelihood非常高，为了解决这个Loss问题，本文提出了用最大互信息（Maximum Mutual Information, MMI）来代替传统Seq2Seq的NLL Loss。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>主要贡献</b></h2><p>   传统的Seq2Seq的标准的目标函数是用log-likelihood来建模：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-166f70139d9a6a13ef42960aa5d7756a_b.jpg\" data-size=\"normal\" data-rawwidth=\"320\" data-rawheight=\"83\" class=\"content_image\" width=\"320\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;320&#39; height=&#39;83&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"320\" data-rawheight=\"83\" class=\"content_image lazy\" width=\"320\" data-actualsrc=\"https://pic3.zhimg.com/v2-166f70139d9a6a13ef42960aa5d7756a_b.jpg\"/><figcaption>公式(1)</figcaption></figure><p>   这个loss会导致统计决策的问题出现，也就是在训练集中出现得越多的T（平常的回复），在测试生成的时候生成这些T的概率就会越高。</p><p class=\"ztext-empty-paragraph\"><br/></p><p>   因此针对这个基于熵的loss进行改进，使用互信息来衡量生成句子的优劣。用MMI来代替NLL，作为Seq2Seq的新的目标函数。最大化互信息（Maximum Mutual Information, MMI）的定义如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-0f14e5d44f7149c95abf518bd22ace3d_b.jpg\" data-size=\"normal\" data-rawwidth=\"218\" data-rawheight=\"84\" class=\"content_image\" width=\"218\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;218&#39; height=&#39;84&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"218\" data-rawheight=\"84\" class=\"content_image lazy\" width=\"218\" data-actualsrc=\"https://pic2.zhimg.com/v2-0f14e5d44f7149c95abf518bd22ace3d_b.jpg\"/><figcaption>公式(2)</figcaption></figure><p>   MMI避免了那些常见的句子产生高概率的情况，取而代之的是与S相关的T能得到更大的分数。</p><p>   公式（2）可以等价变换成：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-7ead64ead7f0d78af0119c431bf66e23_b.jpg\" data-size=\"normal\" data-rawwidth=\"497\" data-rawheight=\"84\" class=\"origin_image zh-lightbox-thumb\" width=\"497\" data-original=\"https://pic4.zhimg.com/v2-7ead64ead7f0d78af0119c431bf66e23_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;497&#39; height=&#39;84&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"497\" data-rawheight=\"84\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"497\" data-original=\"https://pic4.zhimg.com/v2-7ead64ead7f0d78af0119c431bf66e23_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-7ead64ead7f0d78af0119c431bf66e23_b.jpg\"/><figcaption>公式(3)</figcaption></figure><p>   公式（3）很明显地看出，<b>互信息对比与likelihood的区别在于，多了一项 <img src=\"https://www.zhihu.com/equation?tex=%5Clog+p%28T%29\" alt=\"\\log p(T)\" eeimg=\"1\"/> 的惩罚项，这个惩罚项的意义在于，对于在训练集中经常出现的回复T， 其语言模型 <img src=\"https://www.zhihu.com/equation?tex=p%28T%29\" alt=\"p(T)\" eeimg=\"1\"/> 的概率会高于其他回复，减去这个惩罚项可以使得这些经常出现的T的得分下降。</b>其思想与IDF的设定类似。</p><p>   MMI Loss通常在应用中会加入一个超参 <img src=\"https://www.zhihu.com/equation?tex=%5Clambda\" alt=\"\\lambda\" eeimg=\"1\"/> 来控制惩罚项：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-294353338d9c1ceaaa36562597b2f143_b.jpg\" data-size=\"normal\" data-rawwidth=\"435\" data-rawheight=\"74\" class=\"origin_image zh-lightbox-thumb\" width=\"435\" data-original=\"https://pic4.zhimg.com/v2-294353338d9c1ceaaa36562597b2f143_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;435&#39; height=&#39;74&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"435\" data-rawheight=\"74\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"435\" data-original=\"https://pic4.zhimg.com/v2-294353338d9c1ceaaa36562597b2f143_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-294353338d9c1ceaaa36562597b2f143_b.jpg\"/><figcaption>公式(4)</figcaption></figure><p>   利用Bayes定理对公式（3）中的惩罚项进行变换，得到：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-9b03d37cd5d453fe7085993f32773a42_b.jpg\" data-size=\"normal\" data-rawwidth=\"486\" data-rawheight=\"65\" class=\"origin_image zh-lightbox-thumb\" width=\"486\" data-original=\"https://pic3.zhimg.com/v2-9b03d37cd5d453fe7085993f32773a42_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;486&#39; height=&#39;65&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"486\" data-rawheight=\"65\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"486\" data-original=\"https://pic3.zhimg.com/v2-9b03d37cd5d453fe7085993f32773a42_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-9b03d37cd5d453fe7085993f32773a42_b.jpg\"/><figcaption>公式(5)</figcaption></figure><p>   结合（4）和（5）得到：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-fdc12a2010e3797984892fcc5cb561e2_b.jpg\" data-size=\"normal\" data-rawwidth=\"521\" data-rawheight=\"157\" class=\"origin_image zh-lightbox-thumb\" width=\"521\" data-original=\"https://pic3.zhimg.com/v2-fdc12a2010e3797984892fcc5cb561e2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;521&#39; height=&#39;157&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"521\" data-rawheight=\"157\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"521\" data-original=\"https://pic3.zhimg.com/v2-fdc12a2010e3797984892fcc5cb561e2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-fdc12a2010e3797984892fcc5cb561e2_b.jpg\"/><figcaption>公式(6)</figcaption></figure><p>   MMI可以表示成两种形式，称为 <b>(1) MMI-antiLM (公式4)和 (2) MMI-bidi (公式6)</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>MMI-antiLM</b></h2><p><img src=\"https://www.zhihu.com/equation?tex=%5Chat%7BT%7D%3D%5Cmathop%7B%5Carg+%5Cmax%7D_%7BT%7D+%5C%7B+%5Clog+p%28T%7CS%29+-+%5Clambda+%5Clog+p%28T%29+%5C%7D+\" alt=\"\\hat{T}=\\mathop{\\arg \\max}_{T} \\{ \\log p(T|S) - \\lambda \\log p(T) \\} \" eeimg=\"1\"/> 中的惩罚项称作anti-language model，它不仅惩罚了那些高频的通用的回复，同时也惩罚了那些通顺的句子（因为language model中通顺的句子的得分也会高），会导致一些不符合语法的句子被生成。</p><p><b>   因此使用截断式的语言模型</b> <img src=\"https://www.zhihu.com/equation?tex=U%28T%29+%3D+%5Cprod_%7Bi%3D1%7D%5E%7BN_t%7Dp%28t_k%7Ct_1%2Ct_2%2C...%2Ct_%7Bk-1%7D%29+%5Ccdot+g%28k%29\" alt=\"U(T) = \\prod_{i=1}^{N_t}p(t_k|t_1,t_2,...,t_{k-1}) \\cdot g(k)\" eeimg=\"1\"/> <b>来代替完整的语言模型</b> <img src=\"https://www.zhihu.com/equation?tex=p%28T%29+%3D+%5Cprod_%7Bi%3D1%7D%5E%7BN_t%7Dp%28t_k%7Ct_1%2Ct_2%2C...%2Ct_%7Bk-1%7D%29\" alt=\"p(T) = \\prod_{i=1}^{N_t}p(t_k|t_1,t_2,...,t_{k-1})\" eeimg=\"1\"/> ，<b>其中 </b><img src=\"https://www.zhihu.com/equation?tex=g%28k%29%3D%5Cleft%5C%7B+%5Cbegin%7Baligned%7D+1~~~%5Ctext%7Bif%7D+~~k+%5Cle+r+%5C%5C+0~~~%5Ctext%7Bif%7D+~~k+%5Cgt+r+%5Cend%7Baligned%7D+%5Cright.+\" alt=\"g(k)=\\left\\{ \\begin{aligned} 1~~~\\text{if} ~~k \\le r \\\\ 0~~~\\text{if} ~~k \\gt r \\end{aligned} \\right. \" eeimg=\"1\"/> 。</p><p>   因为本文发现对于<b>先生成的单词进行惩罚对生成多样化的句子更加有效</b>，而且<b>通常不符合语法的部分容易出现在句子的后半部分，特别是长句子</b>。所以使用阶段是的语言模型针对句子的前半部分的单词进行惩罚会更有效。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>MMI-bidi</b></h2><p><img src=\"https://www.zhihu.com/equation?tex=%5Chat%7BT%7D%3D%5Cmathop%7B%5Carg+%5Cmax%7D_%7BT%7D+%5C%7B+%281-%5Clambda%29+%5Clog+p%28T%7CS%29+%2B+%5Clambda+%5Clog%28S%7CT%29%29%5C%7D+\" alt=\"\\hat{T}=\\mathop{\\arg \\max}_{T} \\{ (1-\\lambda) \\log p(T|S) + \\lambda \\log(S|T))\\} \" eeimg=\"1\"/> 称为MMI-Direct decoding。用这个目标函数可以更加方便地操作：</p><ul><li>用训练集中的数据分别训练 <img src=\"https://www.zhihu.com/equation?tex=p%28T%7CS%29\" alt=\"p(T|S)\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=p%28S%7CT%29\" alt=\"p(S|T)\" eeimg=\"1\"/> 两个Seq2Seq模型。</li><li>在生成的时候，先用 <img src=\"https://www.zhihu.com/equation?tex=p%28T%7CS%29\" alt=\"p(T|S)\" eeimg=\"1\"/> 生成N-best的候选句子。</li><li>然后用 <img src=\"https://www.zhihu.com/equation?tex=p%28S%7CT%29\" alt=\"p(S|T)\" eeimg=\"1\"/> 对这N-best的候选句子进行rerank。</li></ul><p class=\"ztext-empty-paragraph\"><br/></p><p>   无论是MMI-antiLM还是MMI-bidi，在实践中的效果都很好，生成了有意义的而且多样化的回复。</p><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>实验结果</b></h2><p><b>生成方面：</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-c0478e8d757cd045d136822477b345ba_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1050\" data-rawheight=\"463\" class=\"origin_image zh-lightbox-thumb\" width=\"1050\" data-original=\"https://pic3.zhimg.com/v2-c0478e8d757cd045d136822477b345ba_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1050&#39; height=&#39;463&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1050\" data-rawheight=\"463\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1050\" data-original=\"https://pic3.zhimg.com/v2-c0478e8d757cd045d136822477b345ba_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-c0478e8d757cd045d136822477b345ba_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-112a4f1c4540f15233ebedf6fdcd77a3_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1052\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb\" width=\"1052\" data-original=\"https://pic4.zhimg.com/v2-112a4f1c4540f15233ebedf6fdcd77a3_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1052&#39; height=&#39;369&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1052\" data-rawheight=\"369\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1052\" data-original=\"https://pic4.zhimg.com/v2-112a4f1c4540f15233ebedf6fdcd77a3_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-112a4f1c4540f15233ebedf6fdcd77a3_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-3dbb3acb56ca8143cda76458235058de_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"526\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb\" width=\"526\" data-original=\"https://pic3.zhimg.com/v2-3dbb3acb56ca8143cda76458235058de_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;526&#39; height=&#39;374&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"526\" data-rawheight=\"374\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"526\" data-original=\"https://pic3.zhimg.com/v2-3dbb3acb56ca8143cda76458235058de_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-3dbb3acb56ca8143cda76458235058de_b.jpg\"/></figure><p>   可以看到在生成的句子中，多样性和相关性都能达到预期，而且比Seq2Seq要好很多。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>指标方面：</b></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-6e1cc97f3db15353ef503a4daff9f6a8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1062\" data-rawheight=\"258\" class=\"origin_image zh-lightbox-thumb\" width=\"1062\" data-original=\"https://pic1.zhimg.com/v2-6e1cc97f3db15353ef503a4daff9f6a8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1062&#39; height=&#39;258&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1062\" data-rawheight=\"258\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1062\" data-original=\"https://pic1.zhimg.com/v2-6e1cc97f3db15353ef503a4daff9f6a8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-6e1cc97f3db15353ef503a4daff9f6a8_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d9a238c4e3790780ec6494ccbb835b3e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"534\" data-rawheight=\"247\" class=\"origin_image zh-lightbox-thumb\" width=\"534\" data-original=\"https://pic3.zhimg.com/v2-d9a238c4e3790780ec6494ccbb835b3e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;534&#39; height=&#39;247&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"534\" data-rawheight=\"247\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"534\" data-original=\"https://pic3.zhimg.com/v2-d9a238c4e3790780ec6494ccbb835b3e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d9a238c4e3790780ec6494ccbb835b3e_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-20b15ff324be365e7d1e45d0322b276e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"532\" data-rawheight=\"264\" class=\"origin_image zh-lightbox-thumb\" width=\"532\" data-original=\"https://pic3.zhimg.com/v2-20b15ff324be365e7d1e45d0322b276e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;532&#39; height=&#39;264&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"532\" data-rawheight=\"264\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"532\" data-original=\"https://pic3.zhimg.com/v2-20b15ff324be365e7d1e45d0322b276e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-20b15ff324be365e7d1e45d0322b276e_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>   在指标评估方面，MMI也获得的了不错的效果。毕竟生成这件事效果好坏还真的是见仁见智，目前都没有比较好的指标来评估生成效果。</p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "对话系统", 
                    "tagLink": "https://api.zhihu.com/topics/20141243"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/34828874", 
            "userName": "啊黎", 
            "userLink": "https://www.zhihu.com/people/fc041681e59a65c527e708d2c2ebdecc", 
            "upvote": 14, 
            "title": "Sequence Labeling的发展史（DNNs+CRF）", 
            "content": "<p>   上文说到，传统机器学习的序列标注模型存在着两个非常明显的<b>缺点</b>：</p><ul><li>特征向量稀疏而且维度庞大，导致内存和计算资源的浪费。</li><li>特征的定义是领域特定的，不利于任务的迁移。</li></ul><p>   为了解决特征工程的这些缺点和问题，深度学习作为自动学习和提取深度特征的有效工具，使用深度神经网络来代替传统机器学习CRF的人工特征工程模型在这两年不断被提出，在本文中会主要介绍近年来DL+CRF的一些模型演变过程，并且选择最具有代表性的两篇文章较为详细分析。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b><a href=\"https://link.zhihu.com/?target=http%3A//www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Natural Language Processing (Almost) from Scratch</a></b> </p><ul><li>最早提出<b>用CNN对序列标注任务来自动提取特征的模型</b>，通过CNN自动获得深度特征，结构图如下：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-7e06de20e30d6179c13ac4c2ad6bc4d4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"405\" data-rawheight=\"576\" class=\"content_image\" width=\"405\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;405&#39; height=&#39;576&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"405\" data-rawheight=\"576\" class=\"content_image lazy\" width=\"405\" data-actualsrc=\"https://pic1.zhimg.com/v2-7e06de20e30d6179c13ac4c2ad6bc4d4_b.jpg\"/></figure><ul><li>系统完整地介绍了DNN如果应用到序列标注中来，在通过深度特征得到单词到标签的概率分布（或者得分）时，介绍了多种序列标注的Loss选择策略：</li><li>word-level log-likelihood：也就是每一时刻的标签都用softmax来计算在标签集上的概率分布，贪心地求解最大的概率。</li><li>sentence-level log-likelihood：求解全局的golden path在所有可能的path上面的概率分布，可以认为是句子级别的softmax，通常使用前向算法来求，也就是CRF的loss。</li><li>本人对模型的图其实有点疑问，图在convolution后用了max_pool，一般情况下我们需要对每一时刻的单词都得到对应的标签集的分布的话是不需要max_pool的，max_pool一般用在句子分类中，一直没搞懂。</li></ul><p class=\"ztext-empty-paragraph\"><br/></p><p><b><a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1508.01991.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Bidirectional LSTM-CRF Models for Sequence Tagging</a></b> </p><ul><li>来自百度2016年的作品，目前中文序列标注最常用的模型，BiLSTM-CRF。</li><li>顾名思义，模型就是<b>用BiLSTM来自动提取序列中的特征，再输入到CRF框架中去求解序列标注问题</b>。BiLSTM相比于CNN的好处是能保留到远端的上下文信息，也符合文本的建模，实现了非领域特定的序列标注模型：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-e63a362d01ce99bb03ebb5dbdb005e95_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"476\" data-rawheight=\"282\" class=\"origin_image zh-lightbox-thumb\" width=\"476\" data-original=\"https://pic2.zhimg.com/v2-e63a362d01ce99bb03ebb5dbdb005e95_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;476&#39; height=&#39;282&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"476\" data-rawheight=\"282\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"476\" data-original=\"https://pic2.zhimg.com/v2-e63a362d01ce99bb03ebb5dbdb005e95_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-e63a362d01ce99bb03ebb5dbdb005e95_b.jpg\"/></figure><ul><li>其公式归纳如下，其中 <img src=\"https://www.zhihu.com/equation?tex=%5BA%5D\" alt=\"[A]\" eeimg=\"1\"/> 表示标签到标签的概率转移矩阵， <img src=\"https://www.zhihu.com/equation?tex=%5Bf_%5Ctheta%5D\" alt=\"[f_\\theta]\" eeimg=\"1\"/> 则表示BiLSTM模型输出结果。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-ac8fc51fb360184886121f4e78ef8de5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"429\" data-rawheight=\"70\" class=\"origin_image zh-lightbox-thumb\" width=\"429\" data-original=\"https://pic2.zhimg.com/v2-ac8fc51fb360184886121f4e78ef8de5_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;429&#39; height=&#39;70&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"429\" data-rawheight=\"70\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"429\" data-original=\"https://pic2.zhimg.com/v2-ac8fc51fb360184886121f4e78ef8de5_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-ac8fc51fb360184886121f4e78ef8de5_b.jpg\"/></figure><ul><li>最后训练的loss也是与CRF的sentence-level log-likelihood一样。其理论贡献和实验结果都是非常好的，从此序列标注进入了DNN+CRF的时代。(ー△ー；)</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-51eb7a31bcc10712aee63a98e40a80cd_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"856\" data-rawheight=\"359\" class=\"origin_image zh-lightbox-thumb\" width=\"856\" data-original=\"https://pic2.zhimg.com/v2-51eb7a31bcc10712aee63a98e40a80cd_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;856&#39; height=&#39;359&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"856\" data-rawheight=\"359\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"856\" data-original=\"https://pic2.zhimg.com/v2-51eb7a31bcc10712aee63a98e40a80cd_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-51eb7a31bcc10712aee63a98e40a80cd_b.jpg\"/></figure><ul><li>不过文章有比较多tricks，比如在英文单词上面的实验加入了很多spelling features，还有Feature connect tricks（highway network），而且实验也证明了这些tricks的提升还是蛮有效的。。。但是论文从另一个角度去说这个问题，论文说BiLSTM-CRF去除engineering features后的效果降低比例要低于CRF，从而证明了其鲁棒性。。。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-938598ae53f80418d837d4c6cab02457_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"777\" data-rawheight=\"213\" class=\"origin_image zh-lightbox-thumb\" width=\"777\" data-original=\"https://pic4.zhimg.com/v2-938598ae53f80418d837d4c6cab02457_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;777&#39; height=&#39;213&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"777\" data-rawheight=\"213\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"777\" data-original=\"https://pic4.zhimg.com/v2-938598ae53f80418d837d4c6cab02457_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-938598ae53f80418d837d4c6cab02457_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1603.01354.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</a> </p><ul><li>如果说前面百度的paper是中文序列标注最常用的方法，那么这篇就是英文序列标注最常用的方法了，其思想也是由上面的论文继续演变过来的。</li><li>BiLSTM-CRF用了不少spelling tricks，且证明了这些tricks的有效性，<b>那么这些关于单词本身拼写的特征（比如大小写，前后缀等等）能不能也用DNN来建模呢，答案是是的。</b>BiLSTM-CNN-CRF完全摆脱了人工特征的构造，实现了真正的end-to-end的序列标注模型。</li><li><b>BiLSTM-CNN-CRF使用了CNN来对每个单词本身的每个字母进行建模，单词中每个字母对应一个char-embedding，通过CNN+max_pooling得到整个单词的char-level feature representation</b>：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5e6b8cd1f9174733d6c6b567019d17d0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"536\" class=\"origin_image zh-lightbox-thumb\" width=\"514\" data-original=\"https://pic1.zhimg.com/v2-5e6b8cd1f9174733d6c6b567019d17d0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;514&#39; height=&#39;536&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"514\" data-rawheight=\"536\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"514\" data-original=\"https://pic1.zhimg.com/v2-5e6b8cd1f9174733d6c6b567019d17d0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5e6b8cd1f9174733d6c6b567019d17d0_b.jpg\"/></figure><ul><li>把这些char-level feature representation拼接到word-level feature上面，接下来就是与BiLSTM-CRF一样的套路了。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-06c1e1ef583f0149c3b61af57555a15d_b.jpg\" data-size=\"normal\" data-rawwidth=\"425\" data-rawheight=\"571\" class=\"origin_image zh-lightbox-thumb\" width=\"425\" data-original=\"https://pic2.zhimg.com/v2-06c1e1ef583f0149c3b61af57555a15d_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;425&#39; height=&#39;571&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"425\" data-rawheight=\"571\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"425\" data-original=\"https://pic2.zhimg.com/v2-06c1e1ef583f0149c3b61af57555a15d_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-06c1e1ef583f0149c3b61af57555a15d_b.jpg\"/><figcaption>BiLSTM-CNN-CRF</figcaption></figure><ul><li>文章有两个值得参考和注意的点分别是</li><ul><li>矩阵的初始化用了<a href=\"https://link.zhihu.com/?target=http%3A//pytorch.org/docs/0.3.1/nn.html%3Fhighlight%3Dxavier%23torch.nn.init.xavier_uniform\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Xavier_uniform</a>的初始化方法，对于效果有较为明显的提升。</li><li>在计算Char-CNN的时候，输入维度为 <img src=\"https://www.zhihu.com/equation?tex=%5BB%2AS%2AW%2AE_c%5D\" alt=\"[B*S*W*E_c]\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=B\" alt=\"B\" eeimg=\"1\"/> 为batch_size， <img src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/> 是句子长度， <img src=\"https://www.zhihu.com/equation?tex=W\" alt=\"W\" eeimg=\"1\"/> 为单词的长度， <img src=\"https://www.zhihu.com/equation?tex=E_c\" alt=\"E_c\" eeimg=\"1\"/> 是char-embedding的维度。需要先把前两个维度合并起来计算 <img src=\"https://www.zhihu.com/equation?tex=%5B%28B%2AS%29%2AW%2AE_c%5D\" alt=\"[(B*S)*W*E_c]\" eeimg=\"1\"/> ，然后再并行地计算，会比循环要快很多。</li></ul><li>BiLSTM-CNN-CRF是目前end-to-end的无额外资源的SOTA模型：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-e12cd56b8486315605a8cfea7d45bc64_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"770\" data-rawheight=\"350\" class=\"origin_image zh-lightbox-thumb\" width=\"770\" data-original=\"https://pic1.zhimg.com/v2-e12cd56b8486315605a8cfea7d45bc64_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;770&#39; height=&#39;350&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"770\" data-rawheight=\"350\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"770\" data-original=\"https://pic1.zhimg.com/v2-e12cd56b8486315605a8cfea7d45bc64_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-e12cd56b8486315605a8cfea7d45bc64_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b><a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1705.00108.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Semi-supervised sequence tagging with bidirectional language models</a></b> </p><ul><li><b>结合sequence labeling和language model的multi-task模型</b>，讲道理应该不算半监督吧。</li><li>把language model学到的单词的hidden state，作为额外特征拼接到sequence labeling上，sequence labeling用的是BiLSTM-CNN-CRF模型。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-bc286473b974e32abd6d5d0050243fc4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"944\" data-rawheight=\"586\" class=\"origin_image zh-lightbox-thumb\" width=\"944\" data-original=\"https://pic1.zhimg.com/v2-bc286473b974e32abd6d5d0050243fc4_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;944&#39; height=&#39;586&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"944\" data-rawheight=\"586\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"944\" data-original=\"https://pic1.zhimg.com/v2-bc286473b974e32abd6d5d0050243fc4_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-bc286473b974e32abd6d5d0050243fc4_b.jpg\"/></figure><ul><li>结果也是挺不错的：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-5561d285362d9f8f4efea5b6f6e8bc58_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"588\" class=\"origin_image zh-lightbox-thumb\" width=\"474\" data-original=\"https://pic1.zhimg.com/v2-5561d285362d9f8f4efea5b6f6e8bc58_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;474&#39; height=&#39;588&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"474\" data-rawheight=\"588\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"474\" data-original=\"https://pic1.zhimg.com/v2-5561d285362d9f8f4efea5b6f6e8bc58_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-5561d285362d9f8f4efea5b6f6e8bc58_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b><a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1709.04109.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Empower Sequence Labeling with Task-Aware Neural Language Model</a></b> </p><ul><li>也是结合language model和sequence labeling的multi-task模型，与上面不同的是，<b>language model是建模在char-level上</b>的，其他的模型部分基本没有变化。</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-839ecb48f00ed00c8e7cf2f655ff0bce_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1151\" data-rawheight=\"529\" class=\"origin_image zh-lightbox-thumb\" width=\"1151\" data-original=\"https://pic3.zhimg.com/v2-839ecb48f00ed00c8e7cf2f655ff0bce_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1151&#39; height=&#39;529&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1151\" data-rawheight=\"529\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1151\" data-original=\"https://pic3.zhimg.com/v2-839ecb48f00ed00c8e7cf2f655ff0bce_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-839ecb48f00ed00c8e7cf2f655ff0bce_b.jpg\"/></figure><ul><li>其实验效果也是很好的</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-e40c1f5c46b0a272633a509c8b33ba2e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"576\" data-rawheight=\"582\" class=\"origin_image zh-lightbox-thumb\" width=\"576\" data-original=\"https://pic3.zhimg.com/v2-e40c1f5c46b0a272633a509c8b33ba2e_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;576&#39; height=&#39;582&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"576\" data-rawheight=\"582\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"576\" data-original=\"https://pic3.zhimg.com/v2-e40c1f5c46b0a272633a509c8b33ba2e_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-e40c1f5c46b0a272633a509c8b33ba2e_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b><a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1601.01530.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Leveraging Sentence-level Information with Encoder LSTM for Semantic Slot </a></b></p><p><b><a href=\"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1601.01530.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Filling</a></b> </p><ul><li>这篇文章另辟蹊径，把<b>sequence labeling当做encoder-decoder</b>来做，也是非常的有意思：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-d7b6758c9f88c4bff6a5ac500254fcec_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1119\" data-rawheight=\"344\" class=\"origin_image zh-lightbox-thumb\" width=\"1119\" data-original=\"https://pic1.zhimg.com/v2-d7b6758c9f88c4bff6a5ac500254fcec_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1119&#39; height=&#39;344&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1119\" data-rawheight=\"344\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1119\" data-original=\"https://pic1.zhimg.com/v2-d7b6758c9f88c4bff6a5ac500254fcec_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-d7b6758c9f88c4bff6a5ac500254fcec_b.jpg\"/></figure><ul><li>提出了很多种模型：</li></ul><ol><li>Labeler LSTM(W)：就是用LSTM来提取特征，然后做word-level的label decode，不考虑label直接的约束性。其实就时用LSTM自动提取特征，然后放到最大熵模型框架中求解。输入为词向量，经过LSTM和MLP+softmax，得到每个词对应的slot labels的概率分布，训练的时候loss为NLL loss，测试的时候取当前时刻最大概率对应的标签。</li><li>Labeler LSTM(W+L)：同样是最大熵的框架，只不过LSTM的输入编程了当前的词加上上一时刻的标签，在训练时用上一时刻的golden label，而测试的时候用beam search来decode。</li><li>Encoder-decoder LSTM：用Encoder-LSTM来对句子进行编码，得到sentence-level的特征向量，然后再输入到Decoder-LSTM进行解码，Decoder-LSTM是完全建模在label上的decoder，输入上一时刻的标签，输出是当前时刻标签对应的概率分布（softmax后的值），其训练跟测试过程与Encoder-Decoder框架一致。</li><li>Encoder-labeler LSTM(W)：同样用Encoder-LSTM来对句子进行编码，得到sentence-level的特征向量，用该特征向量作为Labeler LSTM的初始状态，然后继续1的工作。</li><li>Encoder-labeler LSTM(W+L)：与4一样的套路。</li></ol><ul><li>文章的主要任务是slot filling，其效果其实并不是很惊艳，但是提出了一个新的角度来看问题（没有传统NER, CHUNKING或POS Tagging的实验）：</li></ul><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-eead22fc535f6ecb3901a8e48eafc125_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"538\" data-rawheight=\"509\" class=\"origin_image zh-lightbox-thumb\" width=\"538\" data-original=\"https://pic2.zhimg.com/v2-eead22fc535f6ecb3901a8e48eafc125_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;538&#39; height=&#39;509&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"538\" data-rawheight=\"509\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"538\" data-original=\"https://pic2.zhimg.com/v2-eead22fc535f6ecb3901a8e48eafc125_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-eead22fc535f6ecb3901a8e48eafc125_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>   我认为Sequence labeling模型一般分为<b>特征提取层</b>和<b>序列标注层</b>，在传统机器学习模型中，学者更加关注的是序列标注层的建模，从HMM-&gt;MEMM-&gt;CRF的发展历程使得sequence labeling任务的效果可以真正被工业界所用。但是传统机器学习模型的特征提取层往往就是人工模板特征，具有task-specific特点，不利于迁移和泛化。</p><p>   随着深度学习的兴起，DNN逐渐被发现具有强大的自动特征提取的能力，因此业界开始使用DNN（如CNN or RNN及其变种）来取代传统人工特征提取层，并且取得了令人满意的效果。</p><p>   总的来说，DNN+CRF的工作其实已经快要饱满了，因为DNN是为了解决传统CRF特征提取的缺点而提出来的，而且在对特征建模方面基本都涵盖了，BiLSTM学习contextual features， CNN学习char-level spelling features，language model multi-task学习semantic features。不过真正在工业上面的广泛使用和调优还是得继续努力，思考和尝试。</p>", 
            "topic": [
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }, 
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }
            ], 
            "comments": [
                {
                    "userName": "神存在老张", 
                    "userLink": "https://www.zhihu.com/people/7296e74a1f3f9503c8c136e833121d01", 
                    "content": "<p>写的真好，感谢</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/34736498", 
            "userName": "啊黎", 
            "userLink": "https://www.zhihu.com/people/fc041681e59a65c527e708d2c2ebdecc", 
            "upvote": 13, 
            "title": "Sequence Labeling的发展史（HMM,MEMM,CRF）", 
            "content": "<p> 在机器学习领域，序列标注问题通常使用概率图模型来建模。本文主要介绍sequence labeling在机器学习领域的演变过程中最有代表性的三个模型：隐马尔科夫模型（HMM），最大熵马尔科夫模型（MEMM）和条件随机场（CRF）。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>序列标注的定义</b></h2><p> 典型的序列标注任务可以被公式化地建模。假设输入的句子为 <img src=\"https://www.zhihu.com/equation?tex=%5Cbm%7Bx%7D%3D%28x_1%2Cx_2%2C...%2Cx_l%29\" alt=\"\\bm{x}=(x_1,x_2,...,x_l)\" eeimg=\"1\"/> ，其中 <img src=\"https://www.zhihu.com/equation?tex=x_i\" alt=\"x_i\" eeimg=\"1\"/> 表示句子中第 <img src=\"https://www.zhihu.com/equation?tex=i\" alt=\"i\" eeimg=\"1\"/> 个元素，可能是字或者词，<img src=\"https://www.zhihu.com/equation?tex=l\" alt=\"l\" eeimg=\"1\"/>表示句子<b><img src=\"https://www.zhihu.com/equation?tex=%5Cbm%7Bx%7D\" alt=\"\\bm{x}\" eeimg=\"1\"/></b> 的长度。而标签序列则用 <img src=\"https://www.zhihu.com/equation?tex=%5Cbm%7By%7D%3D%28y_1%2Cy_2%2C...%2Cy_l%29\" alt=\"\\bm{y}=(y_1,y_2,...,y_l)\" eeimg=\"1\"/> 来表示， 其中 <img src=\"https://www.zhihu.com/equation?tex=y_i%3Dj\" alt=\"y_i=j\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=j\" alt=\"j\" eeimg=\"1\"/> 的值取自一个事先定义好的有限标签集 <img src=\"https://www.zhihu.com/equation?tex=Y\" alt=\"Y\" eeimg=\"1\"/> ，表示第 <img src=\"https://www.zhihu.com/equation?tex=j\" alt=\"j\" eeimg=\"1\"/> 种标签。因此，序列标注问题可以形式化地表示为：  </p><p><img src=\"https://www.zhihu.com/equation?tex=y%2A%3Dargmax_%7By%7DF%28%5Cbm%7Bx%7D%2C%5Cbm%7By%7D%2C%5Ctheta%29\" alt=\"y*=argmax_{y}F(\\bm{x},\\bm{y},\\theta)\" eeimg=\"1\"/>  。</p><p> 这里 <img src=\"https://www.zhihu.com/equation?tex=F\" alt=\"F\" eeimg=\"1\"/> 是模型函数，<img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/>是模型的参数。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>隐马尔科夫模型（Hidden Markov Model, HMM）</b></h2><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-76fef3b0611ede735224325d1ad4c765_b.jpg\" data-size=\"normal\" data-rawwidth=\"281\" data-rawheight=\"181\" class=\"content_image\" width=\"281\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;281&#39; height=&#39;181&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"281\" data-rawheight=\"181\" class=\"content_image lazy\" width=\"281\" data-actualsrc=\"https://pic2.zhimg.com/v2-76fef3b0611ede735224325d1ad4c765_b.jpg\"/><figcaption>HMM结构</figcaption></figure><p> 隐马尔科夫模型主要包括五个主要部分， <img src=\"https://www.zhihu.com/equation?tex=%5Cmu%3D%28S%2CK%2CA%2CB%2C%5Cpi%29\" alt=\"\\mu=(S,K,A,B,\\pi)\" eeimg=\"1\"/> ，其中 <img src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/> 表示状态的集合， <img src=\"https://www.zhihu.com/equation?tex=K\" alt=\"K\" eeimg=\"1\"/> 表示输出的集合，<img src=\"https://www.zhihu.com/equation?tex=%5Cpi%2CA%2CB\" alt=\"\\pi,A,B\" eeimg=\"1\"/> 是隐马尔科夫模型的参数，分别表示<b>初始状态的概率分布</b>，<b>状态之间的转移概率矩阵</b>和<b>状态到输出的发射概率矩阵</b>。</p><p> 如图，HMM把序列标注任务建模成了输入句子 <img src=\"https://www.zhihu.com/equation?tex=%5Cbm%7Bx%7D\" alt=\"\\bm{x}\" eeimg=\"1\"/> 是观察序列，而 <img src=\"https://www.zhihu.com/equation?tex=%5Cbm%7By%7D\" alt=\"\\bm{y}\" eeimg=\"1\"/> 是隐藏状态序列。</p><p> 为了区分两种矩阵中的元素，状态转移矩阵<img src=\"https://www.zhihu.com/equation?tex=A\" alt=\"A\" eeimg=\"1\"/> 中从第 <img src=\"https://www.zhihu.com/equation?tex=i\" alt=\"i\" eeimg=\"1\"/> 种状态到第 <img src=\"https://www.zhihu.com/equation?tex=j\" alt=\"j\" eeimg=\"1\"/> 种状态的转移概率表示为 <img src=\"https://www.zhihu.com/equation?tex=a_%7Bij%7D\" alt=\"a_{ij}\" eeimg=\"1\"/> ；发射概率矩阵<img src=\"https://www.zhihu.com/equation?tex=B\" alt=\"B\" eeimg=\"1\"/> 中从第 <img src=\"https://www.zhihu.com/equation?tex=i\" alt=\"i\" eeimg=\"1\"/> 种状态发射到第 <img src=\"https://www.zhihu.com/equation?tex=k\" alt=\"k\" eeimg=\"1\"/> 种输出的发射概率表示为 <img src=\"https://www.zhihu.com/equation?tex=b_i%28k%29\" alt=\"b_i(k)\" eeimg=\"1\"/> 。</p><p> 隐马尔科夫模型是产生式模型，假设给定模型 <img src=\"https://www.zhihu.com/equation?tex=%5Cmu%3D%28S%2CK%2CA%2CB%2C%5Cpi%29\" alt=\"\\mu=(S,K,A,B,\\pi)\" eeimg=\"1\"/> ，观察序列 <img src=\"https://www.zhihu.com/equation?tex=O%3D%28O_1%2CO_2%2C...%2CO_t%29\" alt=\"O=(O_1,O_2,...,O_t)\" eeimg=\"1\"/> 的由隐藏状态序列 <img src=\"https://www.zhihu.com/equation?tex=Q%3D%28Q_1%2CQ_2%2C...%2CQ_t%29\" alt=\"Q=(Q_1,Q_2,...,Q_t)\" eeimg=\"1\"/> 生成过程如下， <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 表示时刻：</p><ol><li>在 <img src=\"https://www.zhihu.com/equation?tex=t%3D0\" alt=\"t=0\" eeimg=\"1\"/> 的时候，根据初始状态的概率分布 <img src=\"https://www.zhihu.com/equation?tex=%5Cpi\" alt=\"\\pi\" eeimg=\"1\"/> ，采样得到一个初始的状态 <img src=\"https://www.zhihu.com/equation?tex=q_1%3Ds_i\" alt=\"q_1=s_i\" eeimg=\"1\"/> ， <img src=\"https://www.zhihu.com/equation?tex=s_i\" alt=\"s_i\" eeimg=\"1\"/> 表示状态集合 <img src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/> 中的第 <img src=\"https://www.zhihu.com/equation?tex=i\" alt=\"i\" eeimg=\"1\"/> 种状态。</li><li>根据状态 <img src=\"https://www.zhihu.com/equation?tex=s_i\" alt=\"s_i\" eeimg=\"1\"/> 的发射概率分布 <img src=\"https://www.zhihu.com/equation?tex=b_i%28%2A%29\" alt=\"b_i(*)\" eeimg=\"1\"/> ，采样得到输出 <img src=\"https://www.zhihu.com/equation?tex=O_t%3Dv_k\" alt=\"O_t=v_k\" eeimg=\"1\"/> 。</li><li>然后根据状态转移概率分布 <img src=\"https://www.zhihu.com/equation?tex=a_%7Bi%2A%7D\" alt=\"a_{i*}\" eeimg=\"1\"/> ，采样得到下一时刻的新的状态 <img src=\"https://www.zhihu.com/equation?tex=q_%7Bt%2B1%7D%3Ds_j\" alt=\"q_{t+1}=s_j\" eeimg=\"1\"/> 。</li><li>如果当前时刻 <img src=\"https://www.zhihu.com/equation?tex=t%3ET\" alt=\"t&gt;T\" eeimg=\"1\"/> ，  为最终时刻，则结束生成；否则重复3和4步骤。</li></ol><p> HMM定义了序列标注任务的三个基本问题：<b>概率计算问题</b>，<b>解码问题</b>和<b>参数估计问题</b>。下面将介绍前两个问题，因为这两个问题会涉及到序列标注最常用的两大算法：<b>前向算法</b>和<b>viterbi算法</b>，参数估计问题用EM算法求解，展开介绍需要很长篇幅，因此不作详细介绍，想深入了解推荐移步<a href=\"https://zhuanlan.zhihu.com/p/28565654\" class=\"internal\">EM算法学习</a>，<a href=\"https://link.zhihu.com/?target=http%3A//blog.csdn.net/abcjennifer/article/details/27346787\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Rachel大大的博客</a>学习~</p><p><b>概率计算问题</b></p><p> 概率计算问题的定义是给定一个观察序列 <img src=\"https://www.zhihu.com/equation?tex=O%3D%28O_1%2CO_2%2C...%2CO_t%29\" alt=\"O=(O_1,O_2,...,O_t)\" eeimg=\"1\"/> 和HMM模型 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta%3D%28A%2CB%2C%5Cpi%29\" alt=\"\\theta=(A,B,\\pi)\" eeimg=\"1\"/> ，计算出给定 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta\" alt=\"\\theta\" eeimg=\"1\"/> 的情况下观察序列 <img src=\"https://www.zhihu.com/equation?tex=O\" alt=\"O\" eeimg=\"1\"/> 的概率 <img src=\"https://www.zhihu.com/equation?tex=P%28O%7C%5Ctheta%29\" alt=\"P(O|\\theta)\" eeimg=\"1\"/> 。</p><p> 对于概率 <img src=\"https://www.zhihu.com/equation?tex=P%28O%7C%5Ctheta%29\" alt=\"P(O|\\theta)\" eeimg=\"1\"/> 的计算，最直观的方法就是穷尽所有可能的隐藏状态序列概率连乘即可： <img src=\"https://www.zhihu.com/equation?tex=P%28O%7C%5Ctheta%29+%3D+%5Csum_QP%28O%7CQ%2C%5Ctheta%29P%28Q%7C%5Ctheta%29+%5C%5C+%3D%5Csum_%7Bq%5Cin%7BQ%7D%7D%5Cpi_%7Bq1%7Db_%7Bq1%7D%28O1%29%5Cprod_%7Bt%3D1%7D%5E%7BT%7Da_%28q_tq_%7Bt%2B1%7D%29b_%7Bq_%7Bt%2B1%7D%7D%28O_%7Bt%2B1%7D%29\" alt=\"P(O|\\theta) = \\sum_QP(O|Q,\\theta)P(Q|\\theta) \\\\ =\\sum_{q\\in{Q}}\\pi_{q1}b_{q1}(O1)\\prod_{t=1}^{T}a_(q_tq_{t+1})b_{q_{t+1}}(O_{t+1})\" eeimg=\"1\"/> </p><p> 其复杂度极其庞大，需要穷尽所有可能的 <img src=\"https://www.zhihu.com/equation?tex=q\" alt=\"q\" eeimg=\"1\"/> ，也就是每一时刻都有 <img src=\"https://www.zhihu.com/equation?tex=N\" alt=\"N\" eeimg=\"1\"/> 种可能的隐藏状态，总共的时间长度为 <img src=\"https://www.zhihu.com/equation?tex=T\" alt=\"T\" eeimg=\"1\"/> ，那么就会有 <img src=\"https://www.zhihu.com/equation?tex=N%5ET\" alt=\"N^T\" eeimg=\"1\"/> 个可能的状态序列。因此需通过动态规划的方法来计算，称作<b>前向算法（forward procedure）</b>：</p><p> 定义前向变量</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Calpha_t%28i%29%3DP%28O_1%2CO_2%2C...%2CO_t%2Cq_t%3Ds_i%7C%5Ctheta%29\" alt=\"\\alpha_t(i)=P(O_1,O_2,...,O_t,q_t=s_i|\\theta)\" eeimg=\"1\"/> </p><p> 表示在时间 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> ，输出序列 <img src=\"https://www.zhihu.com/equation?tex=O%3D%28O_1%2CO_2%2C...%2CO_t%29\" alt=\"O=(O_1,O_2,...,O_t)\" eeimg=\"1\"/> ，并且位于状态 <img src=\"https://www.zhihu.com/equation?tex=s_i\" alt=\"s_i\" eeimg=\"1\"/> 的概率。</p><p> 那么</p><p><img src=\"https://www.zhihu.com/equation?tex=P%28O%7C%5Ctheta%29%3D%5Csum_%7Bs_i%7DP%28O_1%2CO_2%2C...%2CO_T%2Cq_T%3Ds_i%7C%5Ctheta%29%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%5Calpha_T%28i%29\" alt=\"P(O|\\theta)=\\sum_{s_i}P(O_1,O_2,...,O_T,q_T=s_i|\\theta)=\\sum_{i=1}^{N}\\alpha_T(i)\" eeimg=\"1\"/> 。</p><p> 前向变量可以通过动态规划的方法递归计算：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Calpha_%7Bt%2B1%7D%28j%29%3D%28%5Csum_%7Bi%3D1%7D%5E%7BN%7D%5Calpha_t%28i%29a_%7Bij%7D%29b_j%28O_%7Bt%2B1%7D%29\" alt=\"\\alpha_{t+1}(j)=(\\sum_{i=1}^{N}\\alpha_t(i)a_{ij})b_j(O_{t+1})\" eeimg=\"1\"/> 。</p><p> 初始条件为：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Calpha_1%28i%29%3D%5Cpi_ib_i%28O_1%29\" alt=\"\\alpha_1(i)=\\pi_ib_i(O_1)\" eeimg=\"1\"/> 。</p><p> 前向算法其复杂度降低到了 <img src=\"https://www.zhihu.com/equation?tex=O%28N%5E2T%29\" alt=\"O(N^2T)\" eeimg=\"1\"/> 。</p><p> 前向算法其实非常容易理解， <img src=\"https://www.zhihu.com/equation?tex=%5Calpha_t%28i%29\" alt=\"\\alpha_t(i)\" eeimg=\"1\"/> 表示在时间 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> ，HMM输出序列 <img src=\"https://www.zhihu.com/equation?tex=O%3DO_1O_2...O_t\" alt=\"O=O_1O_2...O_t\" eeimg=\"1\"/> ，并且位于状态 <img src=\"https://www.zhihu.com/equation?tex=s_i\" alt=\"s_i\" eeimg=\"1\"/> ，<b>那么在时间 <img src=\"https://www.zhihu.com/equation?tex=t%2B1\" alt=\"t+1\" eeimg=\"1\"/> 时，输出序列为 <img src=\"https://www.zhihu.com/equation?tex=O%3DO_1O_2...O_tO_%7Bt%2B1%7D\" alt=\"O=O_1O_2...O_tO_{t+1}\" eeimg=\"1\"/> 并且状态为 <img src=\"https://www.zhihu.com/equation?tex=s_j\" alt=\"s_j\" eeimg=\"1\"/> 就应该是所有的状态 <img src=\"https://www.zhihu.com/equation?tex=s_i\" alt=\"s_i\" eeimg=\"1\"/> 都转移到 <img src=\"https://www.zhihu.com/equation?tex=s_j\" alt=\"s_j\" eeimg=\"1\"/> ，而且 <img src=\"https://www.zhihu.com/equation?tex=s_j\" alt=\"s_j\" eeimg=\"1\"/> 发射出状态 <img src=\"https://www.zhihu.com/equation?tex=O_%7Bt%2B1%7D\" alt=\"O_{t+1}\" eeimg=\"1\"/></b> 。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>解码问题</b></p><p>其目的是对于一个给定的观察序列 <img src=\"https://www.zhihu.com/equation?tex=O%3DO_1O_2...O_T\" alt=\"O=O_1O_2...O_T\" eeimg=\"1\"/> 和模型 <img src=\"https://www.zhihu.com/equation?tex=%5Ctheta%3D%28A%2CB%2C%5Cpi%29\" alt=\"\\theta=(A,B,\\pi)\" eeimg=\"1\"/> ，求解出“最优”的隐状态序列 <img src=\"https://www.zhihu.com/equation?tex=Q%3Dq_1q_2...q_T\" alt=\"Q=q_1q_2...q_T\" eeimg=\"1\"/> 。最优的隐状态序列不是由每一时刻 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 的发射出观察状态 <img src=\"https://www.zhihu.com/equation?tex=O_t\" alt=\"O_t\" eeimg=\"1\"/> 的隐状态 <img src=\"https://www.zhihu.com/equation?tex=q_t\" alt=\"q_t\" eeimg=\"1\"/> 组成，而是需要考虑隐状态之间的概率转移关系，考虑序列性的约束，确保序列性的最优。因此Andrew J. Viterbi提出了一种动态规划的快速计算算法，Viterbi算法，其思想跟前向算法类似。</p><p> 定义维特比变量</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cdelta_t%28i%29%3Dmax_%7Bq_1q_2...q_%7Bt-1%7D%7DP%28q_1q_2...q_t%3Ds_i%2CO%3DO_1O_2...O_t%7C%5Ctheta%29\" alt=\"\\delta_t(i)=max_{q_1q_2...q_{t-1}}P(q_1q_2...q_t=s_i,O=O_1O_2...O_t|\\theta)\" eeimg=\"1\"/> </p><p> 为在时间 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 隐状态为 <img src=\"https://www.zhihu.com/equation?tex=s_t\" alt=\"s_t\" eeimg=\"1\"/> ，并且输出观察序列为 <img src=\"https://www.zhihu.com/equation?tex=O%3DO_1O_2...O_T\" alt=\"O=O_1O_2...O_T\" eeimg=\"1\"/> 的最大概率。</p><p> 递归计算：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cdelta_t%28j%29%3Dmax_i%5B%5Cdelta_%7Bt-1%7Da_%7Bij%7D%5Db_j%28O_j%28Ot%29%29\" alt=\"\\delta_t(j)=max_i[\\delta_{t-1}a_{ij}]b_j(O_j(Ot))\" eeimg=\"1\"/> </p><p> 同时记录最优路径：</p><p><img src=\"https://www.zhihu.com/equation?tex=p_t%28j%29%3Dargmax_i%5B%5Cdelta_%7Bt-1%7D%28i%29a_%7Bij%7D%5Db_j%28O_t%29\" alt=\"p_t(j)=argmax_i[\\delta_{t-1}(i)a_{ij}]b_j(O_t)\" eeimg=\"1\"/> </p><p> 其初始条件为：</p><p><img src=\"https://www.zhihu.com/equation?tex=%5Cdelta_1%28i%29%3D%5Cpi_ib_i%28O_1%29\" alt=\"\\delta_1(i)=\\pi_ib_i(O_1)\" eeimg=\"1\"/> </p><p><img src=\"https://www.zhihu.com/equation?tex=p_1%28i%29%3D0\" alt=\"p_1(i)=0\" eeimg=\"1\"/> </p><p> 终止条件为递归计算到 <img src=\"https://www.zhihu.com/equation?tex=T\" alt=\"T\" eeimg=\"1\"/>  时刻：</p><p><img src=\"https://www.zhihu.com/equation?tex=q_T%3Dargmax_i%5B%5Cdelta_T%28i%29%5D\" alt=\"q_T=argmax_i[\\delta_T(i)]\" eeimg=\"1\"/> </p><p> 状态回溯求解最优路径：</p><p><img src=\"https://www.zhihu.com/equation?tex=q_t%3Dp_%7Bt%2B1%7D%28q_%7Bt%2B1%7D%29\" alt=\"q_t=p_{t+1}(q_{t+1})\" eeimg=\"1\"/> </p><p> Viterbi算法的时间复杂度与前向算法一样，为 <img src=\"https://www.zhihu.com/equation?tex=O%28N%5E2T%29\" alt=\"O(N^2T)\" eeimg=\"1\"/> 。</p><h2><b>最大熵马尔科夫模型（Maximum-Entropy Markov Model, MEMM）</b></h2><p> 由于HMM是产生式模型，[<a href=\"https://link.zhihu.com/?target=http%3A//www.ai.mit.edu/courses/6.891-nlp/READINGS/maxent.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">McCallum et al., 2000</a>]认为这样的建模方式存在两个问题：</p><ul><li>在很多序列标注任务重，需要用大量的特征来刻画观察序列。（比如命名实体识别中的英文大小写，位置，上下文等等）</li><li>很多问题是在已知观察序列的情况下求解状态序列。（也就是人为理解的序列标注应该是句子（观察序列）决定标签（状态序列））</li></ul><p> 因此直接采用<b>最大熵条件概率模型</b>结合<b>马尔科夫模型</b>来建模序列标注。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c49ed42a59e755e265049a41f4317598_b.jpg\" data-size=\"normal\" data-rawwidth=\"282\" data-rawheight=\"180\" class=\"content_image\" width=\"282\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;282&#39; height=&#39;180&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"282\" data-rawheight=\"180\" class=\"content_image lazy\" width=\"282\" data-actualsrc=\"https://pic1.zhimg.com/v2-c49ed42a59e755e265049a41f4317598_b.jpg\"/><figcaption>MEMM结构</figcaption></figure><p> MEMM的序列标注问题定义为，已知观察序列 <img src=\"https://www.zhihu.com/equation?tex=O%3DO_1O_2...O_T\" alt=\"O=O_1O_2...O_T\" eeimg=\"1\"/> ，求解状态序列 <img src=\"https://www.zhihu.com/equation?tex=S%3DS_1S_2...S_T\" alt=\"S=S_1S_2...S_T\" eeimg=\"1\"/> ，并使得条件概率 <img src=\"https://www.zhihu.com/equation?tex=P%28S%3DS_1S_2...S_T%7CO%3DO_1O_2...O_T%29\" alt=\"P(S=S_1S_2...S_T|O=O_1O_2...O_T)\" eeimg=\"1\"/> 最大，而且该条件概率满足马尔科夫假设，也就是条件概率依赖于当前时刻的观察状态和前一时刻的标签状态：</p><p><img src=\"https://www.zhihu.com/equation?tex=P%28S%7CO%29%3D%5Cprod_%7Bt%3D1%7D%5E%7BT%7DP%28S_t%7CS_%7Bt-1%7D%2CO_t%29\" alt=\"P(S|O)=\\prod_{t=1}^{T}P(S_t|S_{t-1},O_t)\" eeimg=\"1\"/> </p><p> 因此可以用最大熵分类器来建模基于前一时刻标签状态 <img src=\"https://www.zhihu.com/equation?tex=S_%7Bt-1%7D%3Ds%27\" alt=\"S_{t-1}=s&#39;\" eeimg=\"1\"/> 和当前时刻的观察输出 <img src=\"https://www.zhihu.com/equation?tex=O_t%3Do\" alt=\"O_t=o\" eeimg=\"1\"/> 的当前标签状态 <img src=\"https://www.zhihu.com/equation?tex=S_t%3Ds\" alt=\"S_t=s\" eeimg=\"1\"/> 的概率：</p><p><img src=\"https://www.zhihu.com/equation?tex=P%28s%7Cs%27%2Co%29%3D%5Cfrac%7B1%7D%7BZ%28s%27%2Co%29%7Dexp%28%5Csum_a%5Clambda_%7Ba%7Df_%7Ba%7D%28o%2Cs%27%2Cs%29%29\" alt=\"P(s|s&#39;,o)=\\frac{1}{Z(s&#39;,o)}exp(\\sum_a\\lambda_{a}f_{a}(o,s&#39;,s))\" eeimg=\"1\"/> </p><p> 其中 <img src=\"https://www.zhihu.com/equation?tex=Z%28s%27%2Co%29\" alt=\"Z(s&#39;,o)\" eeimg=\"1\"/> 为归一化因子， <img src=\"https://www.zhihu.com/equation?tex=f_a%28o%2Cs%27%2Cs%29\" alt=\"f_a(o,s&#39;,s)\" eeimg=\"1\"/>  为特征函数， <img src=\"https://www.zhihu.com/equation?tex=%5Clambda_a\" alt=\"\\lambda_a\" eeimg=\"1\"/> 为该特征函数对应的权重，是需要学习的参数。<b>我认为从神经网络的角度看，最大熵模型就是由一层最简单的前向神经网络加上softmax激活函数构成的一个分类模型</b>。通常的 <img src=\"https://www.zhihu.com/equation?tex=f_a%28o%2Cs%27%2Cs%29\" alt=\"f_a(o,s&#39;,s)\" eeimg=\"1\"/> 为二值函数，表示是否当前状态三元组 <img src=\"https://www.zhihu.com/equation?tex=%28o%2Cs%27%2Cs%29\" alt=\"(o,s&#39;,s)\" eeimg=\"1\"/> 属于某特征定义。由大量经验得知，定义的特征函数越多，最大熵模型的效果越好。因此对于一个特定的状态三元组 <img src=\"https://www.zhihu.com/equation?tex=%28o%2Cs%27%2Cs%29\" alt=\"(o,s&#39;,s)\" eeimg=\"1\"/> ，特征表示通常很高维而且很稀疏。</p><p> MEMM的概率求解问题和解码问题都很简单：</p><p> 对于一个标签状态序列的概率为 <img src=\"https://www.zhihu.com/equation?tex=P%28S%7CO%2C%5Ctheta%29%3D%5Cprod_iP_i%28s%7Cs%27%2Co%29\" alt=\"P(S|O,\\theta)=\\prod_iP_i(s|s&#39;,o)\" eeimg=\"1\"/> 。</p><p> 对于解码问题，MEMM贪心地取当前时刻概率分布中最大对应的标签作为当前时刻的解码标签： <img src=\"https://www.zhihu.com/equation?tex=%5Chat%7Bs%7D_t%3Dargmax_iP%28s%7Cs%27%2Co%29\" alt=\"\\hat{s}_t=argmax_iP(s|s&#39;,o)\" eeimg=\"1\"/> 。</p><p class=\"ztext-empty-paragraph\"><br/></p><h2><b>条件随机场（Conditional Random Field, CRF）</b></h2><p> 最大熵马尔科夫模型虽然结合了隐马尔科夫模型和最大熵模型的最大特点，但是仍然忽略了标签之间的约束关系，只求在当前时刻的最大条件概率。举个例子，在命名实体识别中，I-LOC不可能是在B-PER的后一个标签，但是MEMM会解码出这样的标签序列。这种问题称为标注偏置问题。因此基于MEMM的基础上，加入标签之间的约束的条件随机场被提出。条件随机场也是一个基于条件概率的判别模型，定义为 <img src=\"https://www.zhihu.com/equation?tex=P%28Y%7CX%29%3DP%28S%7CO%29\" alt=\"P(Y|X)=P(S|O)\" eeimg=\"1\"/> ，用 <img src=\"https://www.zhihu.com/equation?tex=X\" alt=\"X\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=Y\" alt=\"Y\" eeimg=\"1\"/> 代替前面的 <img src=\"https://www.zhihu.com/equation?tex=O\" alt=\"O\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"/> ，分别表示输入观察序列和标签序列。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-4ecab79f6ab8af99deddfe973ebccc91_b.jpg\" data-size=\"normal\" data-rawwidth=\"281\" data-rawheight=\"180\" class=\"content_image\" width=\"281\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;281&#39; height=&#39;180&#39;&gt;&lt;/svg&gt;\" data-size=\"normal\" data-rawwidth=\"281\" data-rawheight=\"180\" class=\"content_image lazy\" width=\"281\" data-actualsrc=\"https://pic2.zhimg.com/v2-4ecab79f6ab8af99deddfe973ebccc91_b.jpg\"/><figcaption>CRF结构</figcaption></figure><p> 条件随机场的定义基本与MEMM一样：</p><p><img src=\"https://www.zhihu.com/equation?tex=P%28y_t%7Cy_%7Bt-1%7D%2Cx%29%3D1%3D%5Cfrac%7B1%7D%7BZ%28y_%7Bt-1%7D%2Cx%29%7Dexp%28%5Csum_j%5Clambda_jt_j%28y_%7Bt-1%7D%2Cy_t%2CX%2Ct%29%2B%5Csum_k%5Cmu_ks_k%28y_t%2CX%2Ct%29%29\" alt=\"P(y_t|y_{t-1},x)=1=\\frac{1}{Z(y_{t-1},x)}exp(\\sum_j\\lambda_jt_j(y_{t-1},y_t,X,t)+\\sum_k\\mu_ks_k(y_t,X,t))\" eeimg=\"1\"/> </p><p> 其中 <img src=\"https://www.zhihu.com/equation?tex=t_j%28y_%7Bt-1%7D%2Cy_t%2CX%2Ct%29\" alt=\"t_j(y_{t-1},y_t,X,t)\" eeimg=\"1\"/>是转移函数，表示对于观察序列 <img src=\"https://www.zhihu.com/equation?tex=X\" alt=\"X\" eeimg=\"1\"/> 的标注序列在 <img src=\"https://www.zhihu.com/equation?tex=t-1\" alt=\"t-1\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 时刻上的标记的转移概率， <img src=\"https://www.zhihu.com/equation?tex=s_k%28y_t%2CX%2Ct%29\" alt=\"s_k(y_t,X,t)\" eeimg=\"1\"/> 是状态函数，表示对于观察序列 <img src=\"https://www.zhihu.com/equation?tex=X\" alt=\"X\" eeimg=\"1\"/> 其 <img src=\"https://www.zhihu.com/equation?tex=t\" alt=\"t\" eeimg=\"1\"/> 时刻的标记概率， <img src=\"https://www.zhihu.com/equation?tex=%5Clambda_j\" alt=\"\\lambda_j\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=s_k\" alt=\"s_k\" eeimg=\"1\"/> 分别是 <img src=\"https://www.zhihu.com/equation?tex=t_j%28y_%7Bt-1%7D%2Cy_t%2CX%2Ct%29\" alt=\"t_j(y_{t-1},y_t,X,t)\" eeimg=\"1\"/> 和 <img src=\"https://www.zhihu.com/equation?tex=s_k%28y_t%2CX%2Ct%29\" alt=\"s_k(y_t,X,t)\" eeimg=\"1\"/> 的权重，需要经过训练更新得到。同样CRF也拥有HMM的优点和属性，其概率求解问题和解码问题跟HMM一样，都是使用前馈算法和viterbi算法求解即可。</p><p class=\"ztext-empty-paragraph\"><br/></p><p> CRF模型除了序列标注层的约束对于序列标注的效果提升的很重要以外，还有另外一部分也很重要，那就是特征函数的定义。CRF的特征函数定义其实跟MEMM的几乎一样，通常都是二值函数：</p><p> 观察序列的特征 <img src=\"https://www.zhihu.com/equation?tex=s_k%28y_t%2CX%2Ct%29\" alt=\"s_k(y_t,X,t)\" eeimg=\"1\"/> 可以定义为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-a0da37c1cafae3420b2dcf7a6e6b7790_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"465\" data-rawheight=\"81\" class=\"origin_image zh-lightbox-thumb\" width=\"465\" data-original=\"https://pic1.zhimg.com/v2-a0da37c1cafae3420b2dcf7a6e6b7790_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;465&#39; height=&#39;81&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"465\" data-rawheight=\"81\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"465\" data-original=\"https://pic1.zhimg.com/v2-a0da37c1cafae3420b2dcf7a6e6b7790_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-a0da37c1cafae3420b2dcf7a6e6b7790_b.jpg\"/></figure><p> 转移函数可以定义为：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-ff609013f6f15a5ce4be51f777d491db_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"608\" data-rawheight=\"76\" class=\"origin_image zh-lightbox-thumb\" width=\"608\" data-original=\"https://pic4.zhimg.com/v2-ff609013f6f15a5ce4be51f777d491db_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;608&#39; height=&#39;76&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"608\" data-rawheight=\"76\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"608\" data-original=\"https://pic4.zhimg.com/v2-ff609013f6f15a5ce4be51f777d491db_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-ff609013f6f15a5ce4be51f777d491db_b.jpg\"/></figure><p> 实际上CRF或MEMM在实际应用中存在着两个非常明显的<b>缺点：</b></p><ul><li>在实际应用中  <img src=\"https://www.zhihu.com/equation?tex=%5BX_t%3D%E7%89%B9%E5%AE%9A%E8%AF%8D%EF%BC%8Cy_t%3D%E6%9F%90%E6%A0%87%E7%AD%BE%5D\" alt=\"[X_t=特定词，y_t=某标签]\" eeimg=\"1\"/> 通常会在词集合和标签集合中排列组合构造，因此其特征数量随着词集合和标签集合的数量增加而指数增加，常常会导致人工特征维度达到亿级别。更不用说 <img src=\"https://www.zhihu.com/equation?tex=%5BX_t%3D%E7%89%B9%E5%AE%9A%E8%AF%8D%EF%BC%8Cy_%7Bt-1%7D%3D%E6%9F%90%E6%A0%87%E7%AD%BE%EF%BC%8Cy_t%3D%E6%9F%90%E6%A0%87%E7%AD%BE%5D\" alt=\"[X_t=特定词，y_{t-1}=某标签，y_t=某标签]\" eeimg=\"1\"/> 这种更复杂的组合了。因此在实际的代码实现中，我们通常会忽略三元组特征的 <img src=\"https://www.zhihu.com/equation?tex=X_t\" alt=\"X_t\" eeimg=\"1\"/>  属性，单纯只考虑 <img src=\"https://www.zhihu.com/equation?tex=%5By_%7Bt-1%7D%3D%E6%9F%90%E6%A0%87%E7%AD%BE%EF%BC%8Cy_t%3D%E6%9F%90%E6%A0%87%E7%AD%BE%5D\" alt=\"[y_{t-1}=某标签，y_t=某标签]\" eeimg=\"1\"/> 的特征，也就是只考虑一个全局的标签概率转移矩阵。</li><li>另一方面特征的定义是领域特定的，意思是命名实体识别任务所定义的特征函数不能迁移到词性标注任务中使用，不同任务又必须定义不同的特征函数。</li></ul><p class=\"ztext-empty-paragraph\"><br/></p><p> 为了解决特征工程的这些缺点和问题，深度学习作为自动学习和提取深度特征的有效工具，使用深度神经网络来代替传统机器学习CRF的人工特征工程模型在这两年不断被提出，在下一篇文章中会主要介绍近年来DL+CRF的一些模型演变过程。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>主要参考文献</b></p><blockquote><a href=\"https://link.zhihu.com/?target=https%3A//book.douban.com/subject/25746399/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">宗成庆. 统计自然语言处理 [M]. 清华大学出版社, 2013.</a></blockquote>", 
            "topic": [
                {
                    "tag": "机器学习", 
                    "tagLink": "https://api.zhihu.com/topics/19559450"
                }, 
                {
                    "tag": "深度学习（Deep Learning）", 
                    "tagLink": "https://api.zhihu.com/topics/19813032"
                }, 
                {
                    "tag": "自然语言处理", 
                    "tagLink": "https://api.zhihu.com/topics/19560026"
                }
            ], 
            "comments": []
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/c_172120170"
}

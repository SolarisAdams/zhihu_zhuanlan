{
    "title": "浅入浅出TensorFlow", 
    "description": "Tensorflow入门资料，初学者适用", 
    "followers": [
        "https://www.zhihu.com/people/chang-lu-man-man-13", 
        "https://www.zhihu.com/people/xcm-52", 
        "https://www.zhihu.com/people/BruceWDZ", 
        "https://www.zhihu.com/people/li-yan-32-23", 
        "https://www.zhihu.com/people/leo-85-52", 
        "https://www.zhihu.com/people/yang-xuan-85-84", 
        "https://www.zhihu.com/people/zhang-yao-xing-6688", 
        "https://www.zhihu.com/people/lin-zhong-lu-16-88", 
        "https://www.zhihu.com/people/liuchengwu-28", 
        "https://www.zhihu.com/people/er-qi-58", 
        "https://www.zhihu.com/people/wo-bu-shi-ma-lao-shi", 
        "https://www.zhihu.com/people/wgb-62-38", 
        "https://www.zhihu.com/people/bvegas", 
        "https://www.zhihu.com/people/will-32-88-4", 
        "https://www.zhihu.com/people/chen-xiang-yu-37-51", 
        "https://www.zhihu.com/people/mjfly-17", 
        "https://www.zhihu.com/people/x1993", 
        "https://www.zhihu.com/people/yang-troy-89", 
        "https://www.zhihu.com/people/ren-feng-lei-61", 
        "https://www.zhihu.com/people/xqf-virtual", 
        "https://www.zhihu.com/people/18001671003", 
        "https://www.zhihu.com/people/belle-56-75", 
        "https://www.zhihu.com/people/fanny-64", 
        "https://www.zhihu.com/people/cheng-lin-7-52", 
        "https://www.zhihu.com/people/kim-74-51", 
        "https://www.zhihu.com/people/..A..q..", 
        "https://www.zhihu.com/people/michaellee826", 
        "https://www.zhihu.com/people/an-yu-78-48", 
        "https://www.zhihu.com/people/yidian-dian-50-61", 
        "https://www.zhihu.com/people/lian-lian-feng-chen-2-78", 
        "https://www.zhihu.com/people/jerron-36", 
        "https://www.zhihu.com/people/luorixiangyang", 
        "https://www.zhihu.com/people/kz1973", 
        "https://www.zhihu.com/people/bao-zou-huan-you-61", 
        "https://www.zhihu.com/people/he-yuan-hong-18", 
        "https://www.zhihu.com/people/sun-tian-yue", 
        "https://www.zhihu.com/people/wizardforcel", 
        "https://www.zhihu.com/people/peter-29-74", 
        "https://www.zhihu.com/people/xu-gao-72", 
        "https://www.zhihu.com/people/gan-jue-jie-hun", 
        "https://www.zhihu.com/people/fen-dou-qing-chun-1-26", 
        "https://www.zhihu.com/people/monkeyip", 
        "https://www.zhihu.com/people/yarggo", 
        "https://www.zhihu.com/people/si-tu-jian-nan-81", 
        "https://www.zhihu.com/people/lsw19840519", 
        "https://www.zhihu.com/people/adlm", 
        "https://www.zhihu.com/people/jim-green-88", 
        "https://www.zhihu.com/people/huluobu-77", 
        "https://www.zhihu.com/people/sophiemaple", 
        "https://www.zhihu.com/people/zhao-patrick-66", 
        "https://www.zhihu.com/people/zhang-yun-ming-14", 
        "https://www.zhihu.com/people/axe-68-7", 
        "https://www.zhihu.com/people/fang-ze-hua-56", 
        "https://www.zhihu.com/people/shi-yu-fei-51-35", 
        "https://www.zhihu.com/people/zhi-li-fang-3", 
        "https://www.zhihu.com/people/fendoudexiaoniao", 
        "https://www.zhihu.com/people/nan-yu-meng-76", 
        "https://www.zhihu.com/people/a-a-11-36-66", 
        "https://www.zhihu.com/people/zhang-chao-50-88", 
        "https://www.zhihu.com/people/chevson", 
        "https://www.zhihu.com/people/wang-tian-zhu-55-3", 
        "https://www.zhihu.com/people/yashanwu", 
        "https://www.zhihu.com/people/bis-sea", 
        "https://www.zhihu.com/people/jiang-nan-94-80", 
        "https://www.zhihu.com/people/cathycheny", 
        "https://www.zhihu.com/people/jst-25-67", 
        "https://www.zhihu.com/people/xueye-80", 
        "https://www.zhihu.com/people/hiwjcn", 
        "https://www.zhihu.com/people/600m", 
        "https://www.zhihu.com/people/peng-jian-bo-77", 
        "https://www.zhihu.com/people/qia-fu-qia-de-shen-yin", 
        "https://www.zhihu.com/people/zqcleo", 
        "https://www.zhihu.com/people/vzh-4", 
        "https://www.zhihu.com/people/mao-mi-96-60-24", 
        "https://www.zhihu.com/people/xie-xiao-feng-78-12", 
        "https://www.zhihu.com/people/yingshan-bai", 
        "https://www.zhihu.com/people/han-fei-21-64", 
        "https://www.zhihu.com/people/qiang-sen-61", 
        "https://www.zhihu.com/people/zhou-kevin-94", 
        "https://www.zhihu.com/people/qiu-zhao-xin-25", 
        "https://www.zhihu.com/people/shadow-32-57", 
        "https://www.zhihu.com/people/ceng-chang-50", 
        "https://www.zhihu.com/people/storypad", 
        "https://www.zhihu.com/people/huang-fred-44", 
        "https://www.zhihu.com/people/miao-miao-27-48", 
        "https://www.zhihu.com/people/wang-dong-90-96", 
        "https://www.zhihu.com/people/superpermutation", 
        "https://www.zhihu.com/people/seabiscuit-23", 
        "https://www.zhihu.com/people/henrywood", 
        "https://www.zhihu.com/people/silhouette-", 
        "https://www.zhihu.com/people/wang-yan-shu-26-4", 
        "https://www.zhihu.com/people/luo-feng-42", 
        "https://www.zhihu.com/people/deathwatch-24", 
        "https://www.zhihu.com/people/zerg-duan", 
        "https://www.zhihu.com/people/xiao-long-29-28-56", 
        "https://www.zhihu.com/people/li-ling-7-16", 
        "https://www.zhihu.com/people/zhang-qian-qian-12-91", 
        "https://www.zhihu.com/people/ceng-yi-3-10", 
        "https://www.zhihu.com/people/wang-kang-60-6", 
        "https://www.zhihu.com/people/microboss", 
        "https://www.zhihu.com/people/weiweisun-75", 
        "https://www.zhihu.com/people/refresher", 
        "https://www.zhihu.com/people/a-liu-26-40", 
        "https://www.zhihu.com/people/wtzhang95", 
        "https://www.zhihu.com/people/chen-ming-28-97", 
        "https://www.zhihu.com/people/chillschiller", 
        "https://www.zhihu.com/people/hu-gui-feng-45", 
        "https://www.zhihu.com/people/muyuexc", 
        "https://www.zhihu.com/people/gu-wei-65-54-86", 
        "https://www.zhihu.com/people/leoxiao", 
        "https://www.zhihu.com/people/jicen", 
        "https://www.zhihu.com/people/11iceage", 
        "https://www.zhihu.com/people/zoupython", 
        "https://www.zhihu.com/people/nan-ye-feng-xun", 
        "https://www.zhihu.com/people/yukio-2", 
        "https://www.zhihu.com/people/zhu-forrest", 
        "https://www.zhihu.com/people/yang-qian-92-41-50", 
        "https://www.zhihu.com/people/song-yu-3-63", 
        "https://www.zhihu.com/people/luzheng136710", 
        "https://www.zhihu.com/people/qi-che-ren-82", 
        "https://www.zhihu.com/people/licko", 
        "https://www.zhihu.com/people/p5sd2", 
        "https://www.zhihu.com/people/id01", 
        "https://www.zhihu.com/people/zehaoc", 
        "https://www.zhihu.com/people/benson-27-40", 
        "https://www.zhihu.com/people/zhaodl-15", 
        "https://www.zhihu.com/people/yu-xue-86", 
        "https://www.zhihu.com/people/li-bai-78-17-21", 
        "https://www.zhihu.com/people/qq-h-ii", 
        "https://www.zhihu.com/people/nian-nian-nian-75", 
        "https://www.zhihu.com/people/wang-zhen-li-57", 
        "https://www.zhihu.com/people/mh-lv", 
        "https://www.zhihu.com/people/feng-ying-42-39", 
        "https://www.zhihu.com/people/xian-shou-17", 
        "https://www.zhihu.com/people/steveweiwang", 
        "https://www.zhihu.com/people/xiao-cao-66-85", 
        "https://www.zhihu.com/people/zhao-chuan-yu-27-32", 
        "https://www.zhihu.com/people/fei-zhou-xiao-zhu-13", 
        "https://www.zhihu.com/people/li-hua-42-57", 
        "https://www.zhihu.com/people/jensen502", 
        "https://www.zhihu.com/people/dong-chen-59-89", 
        "https://www.zhihu.com/people/yu-pan-5-19", 
        "https://www.zhihu.com/people/wu-bing-7-30", 
        "https://www.zhihu.com/people/gao-sheng-78-55", 
        "https://www.zhihu.com/people/a-luo-fei", 
        "https://www.zhihu.com/people/hong-jun-53-66", 
        "https://www.zhihu.com/people/gyuansh", 
        "https://www.zhihu.com/people/wang-si-bo-18-84", 
        "https://www.zhihu.com/people/feng-xie-mu-se-23", 
        "https://www.zhihu.com/people/zhao-ming-9-48", 
        "https://www.zhihu.com/people/meng-xiao-27-20", 
        "https://www.zhihu.com/people/psycho-ws", 
        "https://www.zhihu.com/people/wang-yan-sheng-28", 
        "https://www.zhihu.com/people/feng-si-yu-88", 
        "https://www.zhihu.com/people/rainforc-michael", 
        "https://www.zhihu.com/people/wang-jia-wei-35-29", 
        "https://www.zhihu.com/people/wang-sen-96-55", 
        "https://www.zhihu.com/people/yue-lucifer", 
        "https://www.zhihu.com/people/wjr-92-35", 
        "https://www.zhihu.com/people/hei-an-zhu-zai-33", 
        "https://www.zhihu.com/people/bu-zhi-dao-5-46-7", 
        "https://www.zhihu.com/people/zhao-wen-bo-21-78", 
        "https://www.zhihu.com/people/lin-gan-bi-91", 
        "https://www.zhihu.com/people/yongwzj-81", 
        "https://www.zhihu.com/people/fengsibo", 
        "https://www.zhihu.com/people/AI_Technology", 
        "https://www.zhihu.com/people/jiang-ji-bing-69", 
        "https://www.zhihu.com/people/hou-wen-bo-16-69", 
        "https://www.zhihu.com/people/zhu-kong-ming-45", 
        "https://www.zhihu.com/people/wen-wei-50-65", 
        "https://www.zhihu.com/people/jia-si-ji-43", 
        "https://www.zhihu.com/people/rain-74-89", 
        "https://www.zhihu.com/people/xiao-shun-shi-da-ye", 
        "https://www.zhihu.com/people/yuan-xu-peng-41", 
        "https://www.zhihu.com/people/liang-jia-le-75", 
        "https://www.zhihu.com/people/tom-77-88", 
        "https://www.zhihu.com/people/cr777-37", 
        "https://www.zhihu.com/people/liujian-41-26", 
        "https://www.zhihu.com/people/lov1n-66", 
        "https://www.zhihu.com/people/shi-zhi-xiang-3", 
        "https://www.zhihu.com/people/long-long-ago-28", 
        "https://www.zhihu.com/people/caanyee", 
        "https://www.zhihu.com/people/chybhao666", 
        "https://www.zhihu.com/people/chen-zhi-46", 
        "https://www.zhihu.com/people/haoyuachen", 
        "https://www.zhihu.com/people/zhang-xiao-hua-77", 
        "https://www.zhihu.com/people/de-guo-yin-xiang", 
        "https://www.zhihu.com/people/hai-lan-xin", 
        "https://www.zhihu.com/people/kua-guang-nian-de-oj", 
        "https://www.zhihu.com/people/amusi1994", 
        "https://www.zhihu.com/people/qiong-shou-yong-dou", 
        "https://www.zhihu.com/people/yu-draco", 
        "https://www.zhihu.com/people/an-zi-91-34", 
        "https://www.zhihu.com/people/yao-hu-ting-song", 
        "https://www.zhihu.com/people/lin-xiao-qian-50-70", 
        "https://www.zhihu.com/people/ge-bi-lao-li-6", 
        "https://www.zhihu.com/people/ling-jian-95-63", 
        "https://www.zhihu.com/people/mu-bai-3-78", 
        "https://www.zhihu.com/people/guolihua-77", 
        "https://www.zhihu.com/people/fantasy91", 
        "https://www.zhihu.com/people/xinikaola", 
        "https://www.zhihu.com/people/yuan-feng-qu-liao", 
        "https://www.zhihu.com/people/mao-yan-an-88", 
        "https://www.zhihu.com/people/ben-ben-90-55-15", 
        "https://www.zhihu.com/people/zhong-yuan-shuai", 
        "https://www.zhihu.com/people/gao-hang-21", 
        "https://www.zhihu.com/people/leo-17-74", 
        "https://www.zhihu.com/people/ting-yu-94-48", 
        "https://www.zhihu.com/people/wu-hai-ming-74", 
        "https://www.zhihu.com/people/yang-xu-dong-3", 
        "https://www.zhihu.com/people/chao-chao-19-90-41", 
        "https://www.zhihu.com/people/general-89-97", 
        "https://www.zhihu.com/people/chen-shu-qing-92", 
        "https://www.zhihu.com/people/li-dan-dan-32-20", 
        "https://www.zhihu.com/people/yuan-hui-zhen-8", 
        "https://www.zhihu.com/people/nightmare-18", 
        "https://www.zhihu.com/people/xie-zhe-han", 
        "https://www.zhihu.com/people/shi-jue-cai-niao", 
        "https://www.zhihu.com/people/zhou-xiao-bo-81", 
        "https://www.zhihu.com/people/kan-qing-shi-jie-73", 
        "https://www.zhihu.com/people/wu-shang-kun-96", 
        "https://www.zhihu.com/people/utopia823", 
        "https://www.zhihu.com/people/andyflyto", 
        "https://www.zhihu.com/people/chen-huo-83-62", 
        "https://www.zhihu.com/people/zhu-xiao-fei-60", 
        "https://www.zhihu.com/people/lph0729", 
        "https://www.zhihu.com/people/jarry-20-76", 
        "https://www.zhihu.com/people/yi-wu-suo-zhi-de-xiao-bai-97", 
        "https://www.zhihu.com/people/yinxinwang", 
        "https://www.zhihu.com/people/jh-zhang-65", 
        "https://www.zhihu.com/people/wenxiaopi0214", 
        "https://www.zhihu.com/people/zhukovasky", 
        "https://www.zhihu.com/people/jie-yin-65", 
        "https://www.zhihu.com/people/ji-ju-66", 
        "https://www.zhihu.com/people/sui-bian-qi-de-9", 
        "https://www.zhihu.com/people/xiaomi-chen-48", 
        "https://www.zhihu.com/people/zhang-zu-kui-54", 
        "https://www.zhihu.com/people/wer0392kong", 
        "https://www.zhihu.com/people/zhe-ye-65-17-18", 
        "https://www.zhihu.com/people/wo-xin-fei-xiang-14-8", 
        "https://www.zhihu.com/people/hu-yang-lin-74", 
        "https://www.zhihu.com/people/hhb-63", 
        "https://www.zhihu.com/people/elasine", 
        "https://www.zhihu.com/people/hui-se-tian-kong-4", 
        "https://www.zhihu.com/people/liu-tao-cheng-42", 
        "https://www.zhihu.com/people/bbtsww1103", 
        "https://www.zhihu.com/people/bai-dong-tian", 
        "https://www.zhihu.com/people/wo-shi-yige-xiao-ya-xiao-cai-niao", 
        "https://www.zhihu.com/people/fenggege", 
        "https://www.zhihu.com/people/nemofeng95", 
        "https://www.zhihu.com/people/mr-che-43-65", 
        "https://www.zhihu.com/people/baishixian", 
        "https://www.zhihu.com/people/cbb-75-31", 
        "https://www.zhihu.com/people/song-ding-ding-34", 
        "https://www.zhihu.com/people/ha-yi-ya-duo", 
        "https://www.zhihu.com/people/dax0min", 
        "https://www.zhihu.com/people/dancerlzy", 
        "https://www.zhihu.com/people/liu-tian-ming-1", 
        "https://www.zhihu.com/people/falg", 
        "https://www.zhihu.com/people/carlos-guo", 
        "https://www.zhihu.com/people/xiang-xue-zhang", 
        "https://www.zhihu.com/people/lu-jie-85-71", 
        "https://www.zhihu.com/people/jiang-tao-27-57", 
        "https://www.zhihu.com/people/zhang-san-de-ge-3-71", 
        "https://www.zhihu.com/people/jiao-yishan", 
        "https://www.zhihu.com/people/lin-64-71", 
        "https://www.zhihu.com/people/wang-ying-37", 
        "https://www.zhihu.com/people/lillian-37-9", 
        "https://www.zhihu.com/people/shui-ling-guang-91", 
        "https://www.zhihu.com/people/fpga-97", 
        "https://www.zhihu.com/people/yang-bing-xu-58", 
        "https://www.zhihu.com/people/zhou-yang-ping-88", 
        "https://www.zhihu.com/people/kakaxi0605", 
        "https://www.zhihu.com/people/lin-yan-tai", 
        "https://www.zhihu.com/people/in-chen", 
        "https://www.zhihu.com/people/mtfu", 
        "https://www.zhihu.com/people/da-jia-hao-61-5", 
        "https://www.zhihu.com/people/rand-liu-55", 
        "https://www.zhihu.com/people/riddle-49", 
        "https://www.zhihu.com/people/hu-lin-65", 
        "https://www.zhihu.com/people/stm8s", 
        "https://www.zhihu.com/people/yu-xuan-33-40-18", 
        "https://www.zhihu.com/people/xiao-zhou-78-10-85", 
        "https://www.zhihu.com/people/bu-ru-gui-qu-22-63", 
        "https://www.zhihu.com/people/xiao-k-64-61", 
        "https://www.zhihu.com/people/bao-bao-56-95", 
        "https://www.zhihu.com/people/song-wei-74-59", 
        "https://www.zhihu.com/people/steven-62-63-84", 
        "https://www.zhihu.com/people/xing-fu-lei-95", 
        "https://www.zhihu.com/people/crazyvr", 
        "https://www.zhihu.com/people/su-bi-ke-71", 
        "https://www.zhihu.com/people/boblee-34", 
        "https://www.zhihu.com/people/lang-zi-hui-95", 
        "https://www.zhihu.com/people/lu-ni-ge-81", 
        "https://www.zhihu.com/people/meng-xiang-18-77-22", 
        "https://www.zhihu.com/people/zone-26-42", 
        "https://www.zhihu.com/people/netlab7"
    ], 
    "article": [
        {
            "url": "https://zhuanlan.zhihu.com/p/33447496", 
            "userName": "linolzhang", 
            "userLink": "https://www.zhihu.com/people/aa20b95b0383ebd8de05ac61798ec9ce", 
            "upvote": 4, 
            "title": "浅入浅出TensorFlow 9 - 代码框架解析", 
            "content": "<p><b>一. TensorFlow 源码</b></p><p>      截止到目前为止，TensorFlow 在 【<a href=\"https://link.zhihu.com/?target=https%3A//github.com/tensorflow/tensorflow\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Github</a>】 的 Contributors 已经接近900人，Fork 30000次。</p><p>      学习这么庞大的开源项目，首先必须要搞清楚其代码组织形式，我们先来看目录结构：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-85ac43ef86d73f54fb60b937df19f5a1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"993\" data-rawheight=\"787\" class=\"origin_image zh-lightbox-thumb\" width=\"993\" data-original=\"https://pic2.zhimg.com/v2-85ac43ef86d73f54fb60b937df19f5a1_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;993&#39; height=&#39;787&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"993\" data-rawheight=\"787\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"993\" data-original=\"https://pic2.zhimg.com/v2-85ac43ef86d73f54fb60b937df19f5a1_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-85ac43ef86d73f54fb60b937df19f5a1_b.jpg\"/></figure><p>      Project 目录分为4个：</p><blockquote><b>1）tensorflow</b><br/>    核心代码目录，图中可以看到其子目录结构，后面我们会展开讲解。<br/><b>2）third_party</b><br/>    第三方库，包括：eigen3，fft2d，hadoop，mkl，probuf 等。<br/><b>3）tools</b><br/>    只有两个文件 bazel.rc 和 tf_env_collect.sh。<br/><b>4）util/python</b><br/>    存放用到的 python 工具。<br/>另外一个比较重要的文件是 configure，用于配置 tensorflow 的安装环境。</blockquote><p>      对于 tensorflow 核心目录，里面比较关键的几个模块：</p><blockquote><b>1.1）core</b><br/>       这是 tensorflow 的核心代码模块.<br/><b>1.2）tensorboard</b><br/>       不用解释，应该都清楚，这是可视化工具 tensorboard 的代码目录。<br/><b>1.3）stream_executor</b><br/>       tensorflow 流图的并行计算执行，核心代码。<br/><b>1.4）go，java，python</b><br/>       主要的第三方 API。<br/><b>1.5）contrib</b><br/>       存放有其他项目贡献者添加的相关贡献代码，非核心官方代码，有具体方向的应用可以参考这里面的模块。</blockquote><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-11248f105a512ab37626e40d8648c860_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"483\" data-rawheight=\"395\" class=\"origin_image zh-lightbox-thumb\" width=\"483\" data-original=\"https://pic1.zhimg.com/v2-11248f105a512ab37626e40d8648c860_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;483&#39; height=&#39;395&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"483\" data-rawheight=\"395\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"483\" data-original=\"https://pic1.zhimg.com/v2-11248f105a512ab37626e40d8648c860_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-11248f105a512ab37626e40d8648c860_b.jpg\"/></figure><p><b>二. 核心代码目录 Core</b></p><p>      Core 目录是代码最核心的部分，包含 框架、图、会话、runtime 最核心的部分，主要模块包括：</p><blockquote><b>● common_runtime：</b>公共运行库，包含 会话（session）、线程（thread），内存管理（memory）, 设备调度（device）等基本运行库。<br/><b>● distributed_runtime：</b>分布式运行库，与上面类似，作为分布式情况下的运行库，提供运行支撑。<br/><b>● framework：</b>框架基础模块定义，主要是通用组件的结构格式定义；<br/><b>● graph：</b>计算流图相关基础操作（类结构），包括 拆分、合并、执行 等操作，被外面的 executor 调用；<br/><b>● kernels：</b>核心操作定义，像常用的运算 matmul，sigmoid 等操作；<br/><b>● lib：</b>基础库用于内部调用，包括 hash、io、jpeg、math 等；<br/><b>● ops：</b>对 kernel 下的op进行注册和对外声明；<br/><b>● protobuf：</b>Google 的传输交换模块，用于传输时的数据序列化；</blockquote><p class=\"ztext-empty-paragraph\"><br/></p><p><b>三. Graph 与 Session</b></p><p>      关于 Graph 和 Session 前面已经有篇幅讲过，概念上可能大家并没有完全理解，本篇再讲一下。</p><p><b>● Graph</b></p><p>      首先搞清一个概念，Graph 是 Tensorflow 必须要存在的，是灵魂核心，你所看到的任何一个 图都是通过 Graph来组织的。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-83e6a45b6b11a14b5318199753ad72d4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"384\" data-rawheight=\"340\" class=\"content_image\" width=\"384\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;384&#39; height=&#39;340&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"384\" data-rawheight=\"340\" class=\"content_image lazy\" width=\"384\" data-actualsrc=\"https://pic1.zhimg.com/v2-83e6a45b6b11a14b5318199753ad72d4_b.jpg\"/></figure><p>      再来看一段你已经很熟悉的代码：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"kn\">as</span> <span class=\"nn\">tf</span>    \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"s2\">&#34;Hello World!&#34;</span><span class=\"p\">)</span>    \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">se</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Session</span><span class=\"p\">()</span>    \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">print</span> <span class=\"n\">se</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">)</span>  </code></pre></div><p>    没看到 Graph 的创建对不对？ 实际上在你创建 Session 的时候，系统自动为你创建了一个 默认Graph，用于接下来所有 OP 的组织和存放。</p><p>    某些情况下，你可以同时维护两个以上的 Graph，比如我们经常会遇到这样一句，  <b>tf.Graph.as_default()</b></p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">curr_graph</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Graph</span><span class=\"p\">()</span>  \n<span class=\"k\">with</span> <span class=\"n\">curr_graph</span><span class=\"o\">.</span><span class=\"n\">as_default</span><span class=\"p\">():</span>   \n    <span class=\"n\">c_val</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">1.0</span><span class=\"p\">)</span>  \n    <span class=\"k\">assert</span> <span class=\"n\">c_val</span><span class=\"o\">.</span><span class=\"n\">graph</span> <span class=\"ow\">is</span> <span class=\"n\">curr_graph</span> </code></pre></div><p>     在定义 OP 操作的时候可以选择Graph 作为 default，那么你所创建的 OP 就建立在对应 Graph 下面了。</p><p><b>● Session</b></p><p>      TensorFlow 的 Session 用法你可能比较熟了，来回顾一下：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"c1\"># method 1  </span>\n<span class=\"n\">sess</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Session</span><span class=\"p\">()</span>  \n<span class=\"k\">print</span> <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"err\">…</span><span class=\"p\">)</span>  \n<span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>  \n  \n<span class=\"c1\"># method 2  </span>\n<span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Session</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">sess</span><span class=\"p\">:</span>  \n   <span class=\"k\">print</span> <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"err\">…</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># method 3 - 仅用于交互式环境  </span>\n<span class=\"n\">sess</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">InteractiveSession</span><span class=\"p\">()</span>  \n<span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">1.0</span><span class=\"p\">)</span>  \n<span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">2.0</span><span class=\"p\">)</span>  \n<span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">a</span> <span class=\"o\">+</span> <span class=\"n\">b</span>  \n<span class=\"c1\"># 我们直接使用&#39;c.eval()&#39; 而不是&#39;sess.run&#39;  </span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"o\">.</span><span class=\"nb\">eval</span><span class=\"p\">())</span>  \n<span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>  </code></pre></div><p>       对于 Graph 和 Session 的关系，需要记住，Graph 可以在对应多个 Session 中执行。</p><p></p>", 
            "topic": [
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/33447374", 
            "userName": "linolzhang", 
            "userLink": "https://www.zhihu.com/people/aa20b95b0383ebd8de05ac61798ec9ce", 
            "upvote": 4, 
            "title": "浅入浅出TensorFlow 8 - 行人分割", 
            "content": "<p><b>一. 环境准备</b></p><p>      本文介绍如何通过 Mask-RCNN 来实现行人检测，假设你已经对 SSD、YOLO、Faster RCNN 等框架有所了解。</p><p><b>1. 准备 TensorFlow 环境</b></p><p>    Tensorflow (&gt;= 1.0.0)</p><p>    Numpy</p><p><b>2. Gtihub 代码</b></p><p><b>    代码下载：</b>【<a href=\"https://link.zhihu.com/?target=https%3A//github.com/CharlesShang/FastMaskRCNN\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Github</a>】</p><p><b>3. 下载CoCo数据</b></p><p>     下载地址：<a href=\"https://link.zhihu.com/?target=http%3A//mscoco.org/dataset/%23download\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">mscoco.org/dataset/#</span><span class=\"invisible\">download</span><span class=\"ellipsis\"></span></a></p><p>     Web下载比较慢，可以从我的网盘下载：【<a href=\"https://link.zhihu.com/?target=http%3A//pan.baidu.com/s/1jHJdlVg\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">百度网盘</a>】</p><p><b>4. 下载 ReNet50</b></p><div class=\"highlight\"><pre><code class=\"language-bash\">wget http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz  </code></pre></div><p>     解压得到  resnet_v1_50.ckpt</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>二. 代码编译运行</b></p><p>      代码编译可以参考 Github 说明，这里也给出如下流程：</p><p><b>1. make coco工具</b></p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"nb\">cd</span> ./libs/datasets/pycocotools  \nmake </code></pre></div><p><b>2. 将下载的 COCO 数据放到 ./data 目录下，将数据转换成 tf 所需格式；</b></p><p>   按照说明文件：</p><p>       a）在 data下建一个 coco 文件夹，将指定的5个文件 copy到该目录；</p><p>       b）将zip文件解压缩；</p><p>       c）在根目录下建立 output/mask_rcnn 文件夹，用于存放 log；</p><p>       d）执行格式转换脚本（大概会花一小时）；</p><div class=\"highlight\"><pre><code class=\"language-bash\">python download_and_convert_data.py </code></pre></div><p>    可能会提示Python某些库错误，没关系，安装一下就好了，可以将pip源换成国内的，pip install  -i <a href=\"https://link.zhihu.com/?target=https%3A//pypi.tuna.tsinghua.edu.cn/simple\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pypi.tuna.tsinghua.edu.cn</span><span class=\"invisible\">/simple</span><span class=\"ellipsis\"></span></a>  pil</p><div class=\"highlight\"><pre><code class=\"language-bash\">sudo pip install pil   <span class=\"c1\"># or python -m pip install Pillow</span>  \nsudo pip install scikit-image  \nsudo apt-get install python3-tk </code></pre></div><p><b>3. 提前训练好的 Resnet模型</b></p><p>   在data下新建 pretrained_models 目录，将 resnet_v1_50.ckpt 放到目录下。</p><p><b>4. Make编译</b> </p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"nb\">cd</span> ./libs  \nmake </code></pre></div><p><b>5. 训练数据</b></p><div class=\"highlight\"><pre><code class=\"language-bash\">python ../train/train.py </code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-d65b80789cc6f29ee9be52da20d2edc2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"468\" data-rawheight=\"260\" class=\"origin_image zh-lightbox-thumb\" width=\"468\" data-original=\"https://pic3.zhimg.com/v2-d65b80789cc6f29ee9be52da20d2edc2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;468&#39; height=&#39;260&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"468\" data-rawheight=\"260\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"468\" data-original=\"https://pic3.zhimg.com/v2-d65b80789cc6f29ee9be52da20d2edc2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-d65b80789cc6f29ee9be52da20d2edc2_b.jpg\"/></figure><p>当你观察到Loss的时候，说明训练过程已经成功开始了，不要着急，等着Loss慢慢减少吧，原作者训练 8-GPU 花了32个小时。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>三. 训练效果</b></p><p>      根据训练生成的 Log文件，存放在 output里面：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-9369644e337dac913f60499b71877359_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"358\" data-rawheight=\"82\" class=\"content_image\" width=\"358\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;358&#39; height=&#39;82&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"358\" data-rawheight=\"82\" class=\"content_image lazy\" width=\"358\" data-actualsrc=\"https://pic2.zhimg.com/v2-9369644e337dac913f60499b71877359_b.jpg\"/></figure><p>      设置 TensorBoard 的logdir，来看一下训练效果：   </p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-9c05c7c7a99a8454a47c8d69c4553463_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"387\" data-rawheight=\"662\" class=\"content_image\" width=\"387\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;387&#39; height=&#39;662&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"387\" data-rawheight=\"662\" class=\"content_image lazy\" width=\"387\" data-actualsrc=\"https://pic4.zhimg.com/v2-9c05c7c7a99a8454a47c8d69c4553463_b.jpg\"/></figure><p>      可以看到整个的 loss 的变化情况，还是很有成就感的，需要说明一下，在训练过程中可能 loss 会有震荡的情况，没有关系，等到逐渐下降就好了。</p><p>      看一下生成的 Graphs：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-dfab8b12d44a8737e40ba478082998f6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1502\" data-rawheight=\"565\" class=\"origin_image zh-lightbox-thumb\" width=\"1502\" data-original=\"https://pic3.zhimg.com/v2-dfab8b12d44a8737e40ba478082998f6_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1502&#39; height=&#39;565&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1502\" data-rawheight=\"565\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1502\" data-original=\"https://pic3.zhimg.com/v2-dfab8b12d44a8737e40ba478082998f6_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-dfab8b12d44a8737e40ba478082998f6_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>四. Demo 运行</b></p><p>      Github 上未给出 Demo 运行方法，需要我们自己找脚本来实现。</p><p>      可以参考上一篇 demo.py 自己来写，这里作者就不给出具体 code 了，请自行发挥。</p>", 
            "topic": [
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/33447160", 
            "userName": "linolzhang", 
            "userLink": "https://www.zhihu.com/people/aa20b95b0383ebd8de05ac61798ec9ce", 
            "upvote": 6, 
            "title": "浅入浅出TensorFlow 7 - 行人检测之Faster-RCNN", 
            "content": "<p><b>一. 环境准备 </b></p><p>      本文通过 TensorFlow 实现基于 Faster-RCNN 的行人检测，网络模型基于 VGG16 or ResNet。</p><p><b>1. 准备 TensorFlow 环境</b></p><p>    Tensorflow (&gt;= 1.0.0) </p><p>    安装对应 python 库：</p><div class=\"highlight\"><pre><code class=\"language-bash\">sudo apt-get install cython python-opencv python-tk python-scipy python-yaml  \nsudo pip install easydict  \nsudo pip install matplotlib  \nsudo python -m pip install Pillow </code></pre></div><p><b>2. Gtihub 代码</b></p><p>   代码下载：【<a href=\"https://link.zhihu.com/?target=https%3A//github.com/CharlesShang/TFFRCNN\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Github</a>】</p><p><b>3. 下载训练好的网络</b> </p><p>   在 TFFRCNN-master 下新建文件夹 model，存放要下载入的 net（参考 Github 下载地址），推荐下载：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//drive.google.com/file/d/0B_xFdh9onPagX0JWRlR0cTZ5OGc/view\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">2.VGG16 - TFFRCNN (0.689 mAP on VOC07)</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//drive.google.com/file/d/0B_xFdh9onPagVmt5VHlCU25vUEE/view\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">3.VGG16 - TFFRCNN (0.748 mAP on VOC07)</a></p><p><a href=\"https://link.zhihu.com/?target=https%3A//drive.google.com/file/d/0B_xFdh9onPagbXk1b0FIeDRJaU0/view\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">5.Resnet50 - TFFRCNN (0.712 mAP on VOC07)</a></p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>二. 编译运行</b></p><p>      编译代码，并利用训练好的模型运行测试样例。</p><p>      模型是基于 VGG16 在 PASCAL VOC 2007 上的训练结果做的检测。</p><p><b>1. 编译</b></p><p>    打开 lib文件夹下的 make.sh，根据提示修改，如果是 binary版本的 TensorFlow，需要关闭 D_GLIBCXX_USE_CXX11_ABI：</p><div class=\"highlight\"><pre><code class=\"language-make\"><span class=\"c\">## if you install tf using already-built binary, or gcc version 4.x, uncomment the two lines below  \n</span><span class=\"c\"></span><span class=\"err\">g++</span> -std<span class=\"o\">=</span>c++11 -shared -D_GLIBCXX_USE_CXX11_ABI<span class=\"o\">=</span><span class=\"m\">0</span> -o roi_pooling.so roi_pooling_op.cc <span class=\"se\">\\ </span> \n    roi_pooling_op.cu.o -I <span class=\"nv\">$TF_INC</span> -fPIC -lcudart -L <span class=\"nv\">$CUDA_PATH</span>/lib64  \n  \n<span class=\"c\"># for gcc5-built tf  \n</span><span class=\"c\">#g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=1 -o roi_pooling.so roi_pooling_op.cc \\  \n</span><span class=\"c\">#   roi_pooling_op.cu.o -I $TF_INC -fPIC -lcudart -L $CUDA_PATH/lib64  \n</span><span class=\"c\"></span><span class=\"err\">cd</span> ..  \n  \n  \n<span class=\"c\"># add building psroi_pooling layer  \n</span><span class=\"c\"></span><span class=\"err\">cd</span> psroi_pooling_layer  \n<span class=\"err\">nvcc</span> -std<span class=\"o\">=</span>c++11 -c -o psroi_pooling_op.cu.o psroi_pooling_op_gpu.cu.cc <span class=\"se\">\\ </span> \n    -I <span class=\"nv\">$TF_INC</span> -D <span class=\"nv\">GOOGLE_CUDA</span><span class=\"o\">=</span><span class=\"m\">1</span> -x cu -Xcompiler -fPIC -arch<span class=\"o\">=</span>sm_52  \n  \n<span class=\"c\">#g++ -std=c++11 -shared -o psroi_pooling.so psroi_pooling_op.cc \\  \n</span><span class=\"c\">#   psroi_pooling_op.cu.o -I $TF_INC -fPIC -lcudart -L $CUDA_PATH/lib64  \n</span><span class=\"c\"></span>  \n<span class=\"c\">## if you install tf using already-built binary, or gcc version 4.x, uncomment the two lines below  \n</span><span class=\"c\"></span><span class=\"err\">g++</span> -std<span class=\"o\">=</span>c++11 -shared -D_GLIBCXX_USE_CXX11_ABI<span class=\"o\">=</span><span class=\"m\">0</span> -o psroi_pooling.so psroi_pooling_op.cc <span class=\"se\">\\ </span> \n    psroi_pooling_op.cu.o -I <span class=\"nv\">$TF_INC</span> -fPIC -lcudart -L <span class=\"nv\">$CUDA_PATH</span>/lib64 \n</code></pre></div><p>    执行命令行 make：</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"nb\">cd</span> ./lib  \nmake <span class=\"c1\"># compile cython and roi_pooling_op, you may need to modify make.sh for your platform</span>  </code></pre></div><p><b>2. 运行</b></p><p>   将 faster_rcnn/ 文件夹下的 demo.py copy到根目录下，执行如下命令：</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"nb\">cd</span> ..  \npython demo.py --model model/VGGnet_fast_rcnn_iter_150000.ckpt    <span class=\"c1\"># your model path</span></code></pre></div><p>  看一下测试效果（0.748 的 mAP，远端检测效果还是很不错的）：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-551bad3bfbba6616a0c67ecefb068085_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"798\" data-rawheight=\"597\" class=\"origin_image zh-lightbox-thumb\" width=\"798\" data-original=\"https://pic2.zhimg.com/v2-551bad3bfbba6616a0c67ecefb068085_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;798&#39; height=&#39;597&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"798\" data-rawheight=\"597\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"798\" data-original=\"https://pic2.zhimg.com/v2-551bad3bfbba6616a0c67ecefb068085_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-551bad3bfbba6616a0c67ecefb068085_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>三. 训练公网数据</b></p><p>      需要下载 PASCAL VOC 数据集，训练过程也比较简单（也可以参考 Github 对应的说明流程）：</p><p><b>1. 下载数据集</b></p><p>   下载 VOC 数据集，用于下一步数据训练：</p><div class=\"highlight\"><pre><code class=\"language-bash\">wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\nwget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\nwget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCdevkit_08-Jun-2007.tar  </code></pre></div><p>    新建 VOCdevkit 文件夹，并将下载的 tar 文件放到文件夹内，并解压缩：</p><div class=\"highlight\"><pre><code class=\"language-bash\">tar xvf VOCtrainval_06-Nov-2007.tar  \ntar xvf VOCtest_06-Nov-2007.tar  \ntar xvf VOCdevkit_08-Jun-2007.tar</code></pre></div><p>     将数据格式按照下面的格式存放：</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"nv\">$VOCdevkit</span>/                           <span class=\"c1\"># development kit</span>  \n<span class=\"nv\">$VOCdevkit</span>/VOCcode/                   <span class=\"c1\"># VOC utility code</span>  \n<span class=\"nv\">$VOCdevkit</span>/VOC2007                    <span class=\"c1\"># image sets, annotations, etc.</span>  \n<span class=\"c1\"># ... and several other directories ...</span>  </code></pre></div><p><b>2. 下载 VGG16 的预训练数据</b></p><p>   下载地址：【<a href=\"https://link.zhihu.com/?target=https%3A//drive.google.com/file/d/0ByuDEGFYmWsbNVF5eExySUtMZmM/view\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">VGG16 Pretrained</a>】</p><p>    放到指定文件夹下：./data/pretrain_model/VGG_imagenet.npy</p><p><b>3. 训练</b></p><p>    运行如下脚本：</p><div class=\"highlight\"><pre><code class=\"language-bash\">python ./faster_rcnn/train_net.py --gpu <span class=\"m\">0</span> --weights ./data/pretrain_model/VGG_imagenet.npy --imdb voc_2007_trainval --iters <span class=\"m\">70000</span> --cfg  ./experiments/cfgs/faster_rcnn_end2end.yml --network VGGnet_train --set EXP_DIR exp_dir </code></pre></div><p><b>4. 查看结果</b></p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"c1\"># install a visualization tool</span>  \nsudo apt-get install graphviz    \n./experiments/profiling/run_profiling.sh   \n<span class=\"c1\"># generate an image ./experiments/profiling/profile.png</span></code></pre></div><p></p>", 
            "topic": [
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }
            ], 
            "comments": [
                {
                    "userName": "waves", 
                    "userLink": "https://www.zhihu.com/people/f84e1eebb0b61dcb05a4507996c3dff1", 
                    "content": "<p>请问你运行demo出没出现过roi_pooling.so: undefined symbol: _ZTIN10tensorflow8OpKernelE这种错误</p>", 
                    "likes": 1, 
                    "childComments": [
                        {
                            "userName": "陶莎", 
                            "userLink": "https://www.zhihu.com/people/6f1992dac739b920901392673f4cfc0b", 
                            "content": "<p>你好，跟你出现同样的问题，请问您解决了吗</p><p></p>", 
                            "likes": 0, 
                            "replyToAuthor": "waves"
                        }
                    ]
                }, 
                {
                    "userName": "青喵", 
                    "userLink": "https://www.zhihu.com/people/73b466dd0cc57696f160c2aa3b3433d5", 
                    "content": "你好。我用的服务器只能上内网，所以库需要下载源码安装，但是清华网没有easydict，请问有其他办法吗？", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/33446913", 
            "userName": "linolzhang", 
            "userLink": "https://www.zhihu.com/people/aa20b95b0383ebd8de05ac61798ec9ce", 
            "upvote": 3, 
            "title": "浅入浅出TensorFlow 6 - 实现经典网络", 
            "content": "<p><b>一. 经典网络介绍</b></p><p>      首先介绍目前比较主流的几种经典网络，AlexNet［2012］、VGG16［2014］、GoogLeNet［2014］、ResNet［2015］。</p><p>      这几种网络都是在 ILSVRC 比赛中脱颖而出的，越往后网络越复杂， ResNet 为152层结构，测试错误率为 3.57%。</p><p>      为了能给大家一个更宏观的视图，作者将目前CNN在多个领域的应用整理了一张图来说明：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-0bdb9921bd8bbe732373f380491fa682_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"848\" data-rawheight=\"556\" class=\"origin_image zh-lightbox-thumb\" width=\"848\" data-original=\"https://pic3.zhimg.com/v2-0bdb9921bd8bbe732373f380491fa682_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;848&#39; height=&#39;556&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"848\" data-rawheight=\"556\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"848\" data-original=\"https://pic3.zhimg.com/v2-0bdb9921bd8bbe732373f380491fa682_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-0bdb9921bd8bbe732373f380491fa682_b.jpg\"/></figure><p>      下面我们重点关注和讲解的仍是之前提到的四种主流模型，主要应用聚焦在分类，当然其他方向的应用都是以此为基础，希望有时间可以在后续的文章中展开。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>二. AlexNet</b></p><p>      在 LeNet 基础上，AlexNet 加入了ReLU层和DropOut，有效解决了大规模数据训练的震荡问题，因此也开启了一个里程碑，AlexNet 可以看作是深度学习的一个起点，网络分为<b>5个卷积层+3个全连接层</b>，来看网络结构图（这张结构图比较经典，双GPU实现）：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4ac468283131bda0d26665ace4d8ee6b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"708\" data-rawheight=\"252\" class=\"origin_image zh-lightbox-thumb\" width=\"708\" data-original=\"https://pic4.zhimg.com/v2-4ac468283131bda0d26665ace4d8ee6b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;708&#39; height=&#39;252&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"708\" data-rawheight=\"252\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"708\" data-original=\"https://pic4.zhimg.com/v2-4ac468283131bda0d26665ace4d8ee6b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-4ac468283131bda0d26665ace4d8ee6b_b.jpg\"/></figure><p>      AlexNet 贡献是非常大的，描述为以下几点：</p><blockquote><b>● 采用 ReLU 替代了sigmoid，提高了网络的非线性；</b><br/><b>● 引入Dropout 训练方式，增强了网络的健壮性；</b><br/><b>● 通过 LRN（Local Responce Normalization）提高了网络适应性；</b><br/>      目前LRN已经不怎么使用，基本被BN取代<br/><b>● 通过Data Augmentation 证明了大量数据对于模型的作用。</b></blockquote><p>      来看 AlexNet 在 TensorFlow 下的时间评测代码：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"c1\">#coding=utf-8  </span>\n<span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">math</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">time</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"kn\">as</span> <span class=\"nn\">tf</span>  \n  \n<span class=\"n\">batch_size</span> <span class=\"o\">=</span> <span class=\"mi\">32</span>  \n<span class=\"n\">num_batches</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>  \n  \n<span class=\"c1\"># define print shape  </span>\n<span class=\"k\">def</span> <span class=\"nf\">print_activations</span><span class=\"p\">(</span><span class=\"n\">t</span><span class=\"p\">):</span>  \n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">t</span><span class=\"o\">.</span><span class=\"n\">op</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">,</span><span class=\"s1\">&#39; &#39;</span><span class=\"p\">,</span><span class=\"n\">t</span><span class=\"o\">.</span><span class=\"n\">get_shape</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">as_list</span><span class=\"p\">())</span>  \n  \n<span class=\"c1\"># conv1  </span>\n<span class=\"k\">def</span> <span class=\"nf\">inference</span><span class=\"p\">(</span><span class=\"n\">images</span><span class=\"p\">):</span>  \n    <span class=\"n\">parameters</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>  \n  \n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;conv1&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">scope</span><span class=\"p\">:</span>  \n        <span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">truncated_normal</span><span class=\"p\">([</span><span class=\"mi\">11</span><span class=\"p\">,</span><span class=\"mi\">11</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">64</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">1e-1</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;weights&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">conv2d</span><span class=\"p\">(</span><span class=\"n\">images</span><span class=\"p\">,</span><span class=\"n\">kernel</span><span class=\"p\">,[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">biases</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">64</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span><span class=\"n\">trainable</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;biases&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx_add_b</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">bias_add</span><span class=\"p\">(</span><span class=\"n\">wx</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">)</span>  \n        <span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">wx_add_b</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">scope</span><span class=\"p\">)</span>  \n        <span class=\"n\">parameters</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">kernel</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">]</span>  \n    <span class=\"n\">print_activations</span><span class=\"p\">(</span><span class=\"n\">conv1</span><span class=\"p\">)</span>  \n  \n    <span class=\"n\">lrn1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">lrn</span><span class=\"p\">(</span><span class=\"n\">conv1</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">,</span><span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"o\">/</span><span class=\"mi\">9</span><span class=\"p\">,</span><span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">0.75</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;lrn1&#39;</span><span class=\"p\">)</span>  \n    <span class=\"n\">pool1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">lrn1</span><span class=\"p\">,</span><span class=\"n\">ksize</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">strides</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;VALID&#39;</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;pool1&#39;</span><span class=\"p\">)</span>  \n    <span class=\"n\">print_activations</span><span class=\"p\">(</span><span class=\"n\">pool1</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># conv2  </span>\n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;conv2&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">scope</span><span class=\"p\">:</span>  \n        <span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">truncated_normal</span><span class=\"p\">([</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">64</span><span class=\"p\">,</span><span class=\"mi\">192</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">1e-1</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;weights&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">conv2d</span><span class=\"p\">(</span><span class=\"n\">pool1</span><span class=\"p\">,</span><span class=\"n\">kernel</span><span class=\"p\">,[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">biases</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">192</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span><span class=\"n\">trainable</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;biases&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx_add_b</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">bias_add</span><span class=\"p\">(</span><span class=\"n\">wx</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">)</span>  \n        <span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">wx_add_b</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">scope</span><span class=\"p\">)</span>  \n        <span class=\"n\">parameters</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">kernel</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">]</span>  \n    <span class=\"n\">print_activations</span><span class=\"p\">(</span><span class=\"n\">conv2</span><span class=\"p\">)</span>  \n          \n    <span class=\"n\">lrn2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">lrn</span><span class=\"p\">(</span><span class=\"n\">conv2</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">,</span><span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"o\">/</span><span class=\"mi\">9</span><span class=\"p\">,</span><span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">0.75</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;lrn2&#39;</span><span class=\"p\">)</span>  \n    <span class=\"n\">pool2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">lrn2</span><span class=\"p\">,</span><span class=\"n\">ksize</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">strides</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;VALID&#39;</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;pool2&#39;</span><span class=\"p\">)</span>  \n    <span class=\"n\">print_activations</span><span class=\"p\">(</span><span class=\"n\">pool2</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># conv3  </span>\n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;conv3&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">scope</span><span class=\"p\">:</span>  \n        <span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">truncated_normal</span><span class=\"p\">([</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">192</span><span class=\"p\">,</span><span class=\"mi\">384</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">1e-1</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;weights&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">conv2d</span><span class=\"p\">(</span><span class=\"n\">pool2</span><span class=\"p\">,</span><span class=\"n\">kernel</span><span class=\"p\">,[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">biases</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">384</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span><span class=\"n\">trainable</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;biases&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx_add_b</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">bias_add</span><span class=\"p\">(</span><span class=\"n\">wx</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">)</span>  \n        <span class=\"n\">conv3</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">wx_add_b</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">scope</span><span class=\"p\">)</span>  \n        <span class=\"n\">parameters</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">kernel</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">]</span>  \n    <span class=\"n\">print_activations</span><span class=\"p\">(</span><span class=\"n\">conv3</span><span class=\"p\">)</span>  \n          \n<span class=\"c1\"># conv4  </span>\n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;conv4&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">scope</span><span class=\"p\">:</span>  \n        <span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">truncated_normal</span><span class=\"p\">([</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">384</span><span class=\"p\">,</span><span class=\"mi\">256</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">1e-1</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;weights&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">conv2d</span><span class=\"p\">(</span><span class=\"n\">conv3</span><span class=\"p\">,</span><span class=\"n\">kernel</span><span class=\"p\">,[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">biases</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">256</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span><span class=\"n\">trainable</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;biases&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx_add_b</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">bias_add</span><span class=\"p\">(</span><span class=\"n\">wx</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">)</span>  \n        <span class=\"n\">conv4</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">wx_add_b</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">scope</span><span class=\"p\">)</span>  \n        <span class=\"n\">parameters</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">kernel</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">]</span>  \n    <span class=\"n\">print_activations</span><span class=\"p\">(</span><span class=\"n\">conv4</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># conv5  </span>\n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;conv5&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">scope</span><span class=\"p\">:</span>  \n        <span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">truncated_normal</span><span class=\"p\">([</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">256</span><span class=\"p\">,</span><span class=\"mi\">256</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">1e-1</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;weights&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">conv2d</span><span class=\"p\">(</span><span class=\"n\">conv4</span><span class=\"p\">,</span><span class=\"n\">kernel</span><span class=\"p\">,[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">biases</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">256</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span><span class=\"n\">trainable</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;biases&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx_add_b</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">bias_add</span><span class=\"p\">(</span><span class=\"n\">wx</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">)</span>  \n        <span class=\"n\">conv5</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">wx_add_b</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">scope</span><span class=\"p\">)</span>  \n        <span class=\"n\">parameters</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">kernel</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">]</span>  \n    <span class=\"n\">print_activations</span><span class=\"p\">(</span><span class=\"n\">conv5</span><span class=\"p\">)</span>  \n          \n    <span class=\"n\">pool5</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">conv5</span><span class=\"p\">,</span><span class=\"n\">ksize</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">strides</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;VALID&#39;</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;pool5&#39;</span><span class=\"p\">)</span>  \n    <span class=\"n\">print_activations</span><span class=\"p\">(</span><span class=\"n\">pool5</span><span class=\"p\">)</span>  \n    <span class=\"k\">return</span> <span class=\"n\">pool5</span><span class=\"p\">,</span><span class=\"n\">parameters</span>  \n  \n<span class=\"c1\"># define time run  </span>\n<span class=\"k\">def</span> <span class=\"nf\">time_tensorflow_run</span><span class=\"p\">(</span><span class=\"n\">session</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"p\">,</span><span class=\"n\">info_string</span><span class=\"p\">):</span>  \n    <span class=\"n\">num_steps_burn_in</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>  \n    <span class=\"n\">total_duration</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>  \n    <span class=\"n\">total_duration_squared</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>  \n  \n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_batches</span> <span class=\"o\">+</span> <span class=\"n\">num_steps_burn_in</span><span class=\"p\">):</span>  \n       <span class=\"n\">start_time</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>  \n       <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">session</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">)</span>  \n       <span class=\"n\">duration</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span> <span class=\"o\">-</span> <span class=\"n\">start_time</span>  \n       <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">&gt;=</span> <span class=\"n\">num_steps_burn_in</span><span class=\"p\">:</span>  \n           <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">i</span> <span class=\"o\">%</span> <span class=\"mi\">10</span><span class=\"p\">:</span>  \n               <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;</span><span class=\"si\">%s</span><span class=\"s1\">: step </span><span class=\"si\">%d</span><span class=\"s1\">, duration = </span><span class=\"si\">%.3f</span><span class=\"s1\">&#39;</span> <span class=\"o\">%</span><span class=\"p\">(</span><span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">now</span><span class=\"p\">(),</span><span class=\"n\">i</span><span class=\"o\">-</span><span class=\"n\">num_steps_burn_in</span><span class=\"p\">,</span><span class=\"n\">duration</span><span class=\"p\">))</span>  \n               <span class=\"n\">total_duration</span> <span class=\"o\">+=</span> <span class=\"n\">duration</span>  \n               <span class=\"n\">total_duration_squared</span> <span class=\"o\">+=</span> <span class=\"n\">duration</span> <span class=\"o\">*</span> <span class=\"n\">duration</span>  \n  \n    <span class=\"n\">mn</span> <span class=\"o\">=</span> <span class=\"n\">total_duration</span> <span class=\"o\">/</span> <span class=\"n\">num_batches</span>  \n    <span class=\"n\">vr</span> <span class=\"o\">=</span> <span class=\"n\">total_duration_squared</span> <span class=\"o\">/</span> <span class=\"n\">num_batches</span> <span class=\"o\">-</span> <span class=\"n\">mn</span> <span class=\"o\">*</span><span class=\"n\">mn</span>  \n    <span class=\"n\">sd</span> <span class=\"o\">=</span> <span class=\"n\">math</span><span class=\"o\">.</span><span class=\"n\">sqrt</span><span class=\"p\">(</span><span class=\"n\">vr</span><span class=\"p\">)</span>  \n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;</span><span class=\"si\">%s</span><span class=\"s1\">: </span><span class=\"si\">%s</span><span class=\"s1\"> across </span><span class=\"si\">%d</span><span class=\"s1\"> steps, </span><span class=\"si\">%.3f</span><span class=\"s1\"> +/- </span><span class=\"si\">%.3f</span><span class=\"s1\"> sec / batch&#39;</span> <span class=\"o\">%</span><span class=\"p\">(</span><span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">now</span><span class=\"p\">(),</span><span class=\"n\">info_string</span><span class=\"p\">,</span><span class=\"n\">num_batches</span><span class=\"p\">,</span><span class=\"n\">mn</span><span class=\"p\">,</span><span class=\"n\">sd</span><span class=\"p\">))</span>  \n  \n<span class=\"c1\"># main fun  </span>\n<span class=\"k\">def</span> <span class=\"nf\">run_benchmark</span><span class=\"p\">():</span>  \n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Graph</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">as_default</span><span class=\"p\">():</span>  \n        <span class=\"n\">image_size</span> <span class=\"o\">=</span> <span class=\"mi\">224</span>  \n        <span class=\"n\">images</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">random_normal</span><span class=\"p\">([</span><span class=\"n\">batch_size</span><span class=\"p\">,</span><span class=\"n\">image_size</span><span class=\"p\">,</span><span class=\"n\">image_size</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">1e-1</span><span class=\"p\">))</span>  \n        <span class=\"n\">pool5</span><span class=\"p\">,</span> <span class=\"n\">parameters</span> <span class=\"o\">=</span> <span class=\"n\">inference</span><span class=\"p\">(</span><span class=\"n\">images</span><span class=\"p\">)</span>  \n  \n        <span class=\"n\">init</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">global_variables_initializer</span><span class=\"p\">()</span>  \n        <span class=\"n\">sess</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Session</span><span class=\"p\">()</span>  \n        <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">init</span><span class=\"p\">)</span>  \n  \n        <span class=\"c1\"># time  </span>\n        <span class=\"n\">time_tensorflow_run</span><span class=\"p\">(</span><span class=\"n\">sess</span><span class=\"p\">,</span><span class=\"n\">pool5</span><span class=\"p\">,</span><span class=\"s2\">&#34;Forward&#34;</span><span class=\"p\">)</span>  \n        <span class=\"n\">objective</span> <span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">l2_loss</span><span class=\"p\">(</span><span class=\"n\">pool5</span><span class=\"p\">)</span>  \n        <span class=\"n\">grad</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">gradients</span><span class=\"p\">(</span><span class=\"n\">objective</span><span class=\"p\">,</span><span class=\"n\">parameters</span><span class=\"p\">)</span>  \n        <span class=\"n\">time_tensorflow_run</span><span class=\"p\">(</span><span class=\"n\">sess</span><span class=\"p\">,</span><span class=\"n\">grad</span><span class=\"p\">,</span><span class=\"s2\">&#34;Forward-backward&#34;</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># run  </span>\n<span class=\"n\">run_benchmark</span><span class=\"p\">()</span>  </code></pre></div><p><b>三. VGG16</b></p><p>     人们相信，网络层数越多，对应的参数越复杂，所能描述的网络越准确，基于这个假设，将 AlexNet 网络进行扩充，得到了 VGG16/19，这是在当时的条件下能控制住网络震荡最好的网络（预知更多的层，请看之后的分解 ^v^）。</p><p>     VGG16 的叫法来自于 网络包含 16 层卷积，包括 13层的卷积+3层的全连接。</p><p>     VGG的网络结构图 【<a href=\"https://link.zhihu.com/?target=http%3A//ethereon.github.io/netscope/%23/gist/dc5003de6943ea5a6b8b\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">点击查看详图</a>】：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-111192f60607c336efc833b8a94c9d06_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"693\" data-rawheight=\"366\" class=\"origin_image zh-lightbox-thumb\" width=\"693\" data-original=\"https://pic3.zhimg.com/v2-111192f60607c336efc833b8a94c9d06_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;693&#39; height=&#39;366&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"693\" data-rawheight=\"366\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"693\" data-original=\"https://pic3.zhimg.com/v2-111192f60607c336efc833b8a94c9d06_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-111192f60607c336efc833b8a94c9d06_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>      VGG19 是在 conv3、conv4、conv5 三个Group各添加一层卷积（上图红色框）。</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"c1\">#coding=utf-8  </span>\n<span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">math</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">time</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"kn\">as</span> <span class=\"nn\">tf</span>  \n  \n<span class=\"n\">batch_size</span> <span class=\"o\">=</span> <span class=\"mi\">32</span>  \n<span class=\"n\">num_batches</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>  \n  \n<span class=\"c1\"># define conv  </span>\n<span class=\"k\">def</span> <span class=\"nf\">conv</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"p\">):</span>  \n    <span class=\"n\">n_in</span> <span class=\"o\">=</span> <span class=\"nb\">input</span><span class=\"o\">.</span><span class=\"n\">get_shape</span><span class=\"p\">()[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">value</span>  \n  \n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">scope</span><span class=\"p\">:</span>  \n        <span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">get_variable</span><span class=\"p\">(</span><span class=\"n\">scope</span><span class=\"o\">+</span><span class=\"s2\">&#34;w&#34;</span><span class=\"p\">,</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">kh</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"p\">,</span><span class=\"n\">n_in</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span><span class=\"n\">initializer</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">contrib</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">xavier_initializer_conv2d</span><span class=\"p\">())</span>  \n        <span class=\"n\">conv</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">conv2d</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">,</span><span class=\"n\">kernel</span><span class=\"p\">,[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">bias_init_val</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">n_out</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>  \n        <span class=\"n\">biases</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">bias_init_val</span><span class=\"p\">,</span> <span class=\"n\">trainable</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;biases&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">wx_add_b</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">bias_add</span><span class=\"p\">(</span><span class=\"n\">conv</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">)</span>  \n        <span class=\"n\">relu</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">wx_add_b</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">scope</span><span class=\"p\">)</span>  \n        <span class=\"n\">p</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">kernel</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">]</span>  \n        <span class=\"k\">return</span> <span class=\"n\">relu</span>  \n  \n<span class=\"c1\"># define fc  </span>\n<span class=\"k\">def</span> <span class=\"nf\">fc</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"p\">):</span>  \n    <span class=\"n\">n_in</span> <span class=\"o\">=</span> <span class=\"nb\">input</span><span class=\"o\">.</span><span class=\"n\">get_shape</span><span class=\"p\">()[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">value</span>  \n  \n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">scope</span><span class=\"p\">:</span>  \n        <span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">get_variable</span><span class=\"p\">(</span><span class=\"n\">scope</span><span class=\"o\">+</span><span class=\"s2\">&#34;w&#34;</span><span class=\"p\">,</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">n_in</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span><span class=\"n\">initializer</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">contrib</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">xavier_initializer</span><span class=\"p\">())</span>  \n        <span class=\"n\">biases</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.1</span><span class=\"p\">,</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">n_out</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;biases&#34;</span><span class=\"p\">)</span>  \n        <span class=\"n\">relu</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu_layer</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">,</span><span class=\"n\">kernel</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">,</span> <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">scope</span><span class=\"p\">)</span>  \n        <span class=\"n\">p</span> <span class=\"o\">+=</span> <span class=\"p\">[</span><span class=\"n\">kernel</span><span class=\"p\">,</span><span class=\"n\">biases</span><span class=\"p\">]</span>  \n        <span class=\"k\">return</span> <span class=\"n\">relu</span>  \n  \n<span class=\"c1\"># define pool  </span>\n<span class=\"k\">def</span> <span class=\"nf\">max_pool</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"p\">):</span>  \n    <span class=\"k\">return</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">,</span><span class=\"n\">ksize</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">strides</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">name</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># define inference  </span>\n<span class=\"k\">def</span> <span class=\"nf\">inference</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">,</span><span class=\"n\">keep_prob</span><span class=\"p\">):</span>  \n    <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>  \n    <span class=\"n\">conv1_1</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv1_1&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">conv1_2</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">conv1_1</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv1_2&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">pool1</span> <span class=\"o\">=</span> <span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">conv1_2</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;pool1&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>  \n  \n    <span class=\"n\">conv2_1</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">pool1</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv2_1&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">conv2_2</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">conv2_1</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv2_2&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">pool2</span> <span class=\"o\">=</span> <span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">conv2_2</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;pool2&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>  \n  \n    <span class=\"n\">conv3_1</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">pool2</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv3_1&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">256</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">conv3_2</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">conv3_1</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv3_2&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">256</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">conv3_3</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">conv3_2</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv3_3&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">256</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">pool3</span> <span class=\"o\">=</span> <span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">conv3_3</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;pool3&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>  \n  \n    <span class=\"n\">conv4_1</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">pool3</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv4_1&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">conv4_2</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">conv4_1</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv4_2&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">conv4_3</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">conv4_2</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv4_3&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">pool4</span> <span class=\"o\">=</span> <span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">conv4_3</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;pool4&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>  \n  \n  \n    <span class=\"n\">conv5_1</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">pool4</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv5_1&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">conv5_2</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">conv5_1</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv5_2&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">conv5_3</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">conv5_2</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;conv5_3&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">pool5</span> <span class=\"o\">=</span> <span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">conv5_3</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;pool5&#34;</span><span class=\"p\">,</span><span class=\"n\">kh</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">kw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">dw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">dh</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>  \n  \n    <span class=\"n\">shp</span> <span class=\"o\">=</span> <span class=\"n\">pool5</span><span class=\"o\">.</span><span class=\"n\">get_shape</span><span class=\"p\">()</span>  \n    <span class=\"n\">flattened_shape</span> <span class=\"o\">=</span> <span class=\"n\">shp</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">value</span> <span class=\"o\">*</span> <span class=\"n\">shp</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">value</span> <span class=\"o\">*</span> <span class=\"n\">shp</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">value</span>  \n    <span class=\"n\">resh1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">pool5</span><span class=\"p\">,[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">flattened_shape</span><span class=\"p\">],</span> <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">&#34;resh1&#34;</span><span class=\"p\">)</span>  \n  \n    <span class=\"n\">fc6</span> <span class=\"o\">=</span> <span class=\"n\">fc</span><span class=\"p\">(</span><span class=\"n\">resh1</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;fc6&#34;</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">4096</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">fc6_drop</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">dropout</span><span class=\"p\">(</span><span class=\"n\">fc6</span><span class=\"p\">,</span><span class=\"n\">keep_prob</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;fc6_drop&#34;</span><span class=\"p\">)</span>  \n  \n    <span class=\"n\">fc7</span> <span class=\"o\">=</span> <span class=\"n\">fc</span><span class=\"p\">(</span><span class=\"n\">fc6_drop</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;fc7&#34;</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">4096</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">fc7_drop</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">dropout</span><span class=\"p\">(</span><span class=\"n\">fc7</span><span class=\"p\">,</span><span class=\"n\">keep_prob</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;fc7_drop&#34;</span><span class=\"p\">)</span>  \n  \n    <span class=\"n\">fc8</span> <span class=\"o\">=</span> <span class=\"n\">fc</span><span class=\"p\">(</span><span class=\"n\">fc7_drop</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">&#34;fc8&#34;</span><span class=\"p\">,</span><span class=\"n\">n_out</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n    <span class=\"n\">softmax</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">fc8</span><span class=\"p\">)</span>  \n  \n    <span class=\"n\">predit</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">softmax</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">)</span>  \n    <span class=\"k\">return</span> <span class=\"n\">predit</span><span class=\"p\">,</span><span class=\"n\">softmax</span><span class=\"p\">,</span><span class=\"n\">fc8</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"p\">;</span>  \n  \n<span class=\"c1\"># define time run  </span>\n<span class=\"k\">def</span> <span class=\"nf\">time_tensorflow_run</span><span class=\"p\">(</span><span class=\"n\">session</span><span class=\"p\">,</span><span class=\"n\">target</span><span class=\"p\">,</span><span class=\"n\">feed</span><span class=\"p\">,</span><span class=\"n\">info_string</span><span class=\"p\">):</span>  \n    <span class=\"n\">num_steps_burn_in</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>  \n    <span class=\"n\">total_duration</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>  \n    <span class=\"n\">total_duration_squared</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>  \n  \n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_batches</span> <span class=\"o\">+</span> <span class=\"n\">num_steps_burn_in</span><span class=\"p\">):</span>  \n       <span class=\"n\">start_time</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>  \n       <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">session</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">feed_dict</span><span class=\"o\">=</span><span class=\"n\">feed</span><span class=\"p\">)</span>  \n       <span class=\"n\">duration</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span> <span class=\"o\">-</span> <span class=\"n\">start_time</span>  \n       <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">&gt;=</span> <span class=\"n\">num_steps_burn_in</span><span class=\"p\">:</span>  \n           <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">i</span> <span class=\"o\">%</span> <span class=\"mi\">10</span><span class=\"p\">:</span>  \n               <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;</span><span class=\"si\">%s</span><span class=\"s1\">: step </span><span class=\"si\">%d</span><span class=\"s1\">, duration = </span><span class=\"si\">%.3f</span><span class=\"s1\">&#39;</span> <span class=\"o\">%</span><span class=\"p\">(</span><span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">now</span><span class=\"p\">(),</span><span class=\"n\">i</span><span class=\"o\">-</span><span class=\"n\">num_steps_burn_in</span><span class=\"p\">,</span><span class=\"n\">duration</span><span class=\"p\">))</span>  \n               <span class=\"n\">total_duration</span> <span class=\"o\">+=</span> <span class=\"n\">duration</span>  \n               <span class=\"n\">total_duration_squared</span> <span class=\"o\">+=</span> <span class=\"n\">duration</span> <span class=\"o\">*</span> <span class=\"n\">duration</span>  \n  \n    <span class=\"n\">mn</span> <span class=\"o\">=</span> <span class=\"n\">total_duration</span> <span class=\"o\">/</span> <span class=\"n\">num_batches</span>  \n    <span class=\"n\">vr</span> <span class=\"o\">=</span> <span class=\"n\">total_duration_squared</span> <span class=\"o\">/</span> <span class=\"n\">num_batches</span> <span class=\"o\">-</span> <span class=\"n\">mn</span> <span class=\"o\">*</span><span class=\"n\">mn</span>  \n    <span class=\"n\">sd</span> <span class=\"o\">=</span> <span class=\"n\">math</span><span class=\"o\">.</span><span class=\"n\">sqrt</span><span class=\"p\">(</span><span class=\"n\">vr</span><span class=\"p\">)</span>  \n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;</span><span class=\"si\">%s</span><span class=\"s1\">: </span><span class=\"si\">%s</span><span class=\"s1\"> across </span><span class=\"si\">%d</span><span class=\"s1\"> steps, </span><span class=\"si\">%.3f</span><span class=\"s1\"> +/- </span><span class=\"si\">%.3f</span><span class=\"s1\"> sec / batch&#39;</span> <span class=\"o\">%</span><span class=\"p\">(</span><span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">now</span><span class=\"p\">(),</span><span class=\"n\">info_string</span><span class=\"p\">,</span><span class=\"n\">num_batches</span><span class=\"p\">,</span><span class=\"n\">mn</span><span class=\"p\">,</span><span class=\"n\">sd</span><span class=\"p\">))</span>  \n  \n<span class=\"c1\"># main func  </span>\n<span class=\"k\">def</span> <span class=\"nf\">run_benchmark</span><span class=\"p\">():</span>  \n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Graph</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">as_default</span><span class=\"p\">():</span>  \n        <span class=\"n\">image_size</span> <span class=\"o\">=</span> <span class=\"mi\">224</span>  \n        <span class=\"n\">images</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">random_normal</span><span class=\"p\">([</span><span class=\"n\">batch_size</span><span class=\"p\">,</span><span class=\"n\">image_size</span><span class=\"p\">,</span><span class=\"n\">image_size</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">],</span><span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">1e-1</span><span class=\"p\">))</span>  \n        <span class=\"n\">keep_prob</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">placeholder</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>  \n        <span class=\"n\">predictions</span><span class=\"p\">,</span><span class=\"n\">softmax</span><span class=\"p\">,</span><span class=\"n\">fc8</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">inference</span><span class=\"p\">(</span><span class=\"n\">images</span><span class=\"p\">,</span><span class=\"n\">keep_prob</span><span class=\"p\">)</span>  \n  \n        <span class=\"n\">init</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">global_variables_initializer</span><span class=\"p\">()</span>  \n        <span class=\"n\">sess</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Session</span><span class=\"p\">()</span>  \n        <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">init</span><span class=\"p\">)</span>  \n  \n        <span class=\"c1\"># time  </span>\n        <span class=\"n\">time_tensorflow_run</span><span class=\"p\">(</span><span class=\"n\">sess</span><span class=\"p\">,</span><span class=\"n\">predictions</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"n\">keep_prob</span><span class=\"p\">:</span><span class=\"mf\">1.0</span><span class=\"p\">},</span> <span class=\"s2\">&#34;Forward&#34;</span><span class=\"p\">)</span>  \n        <span class=\"n\">objective</span> <span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">l2_loss</span><span class=\"p\">(</span><span class=\"n\">fc8</span><span class=\"p\">)</span>  \n        <span class=\"n\">grad</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">gradients</span><span class=\"p\">(</span><span class=\"n\">objective</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"p\">)</span>  \n        <span class=\"n\">time_tensorflow_run</span><span class=\"p\">(</span><span class=\"n\">sess</span><span class=\"p\">,</span><span class=\"n\">grad</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"n\">keep_prob</span><span class=\"p\">:</span><span class=\"mf\">0.5</span><span class=\"p\">},</span> <span class=\"s2\">&#34;Forward-backward&#34;</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># run  </span>\n<span class=\"n\">run_benchmark</span><span class=\"p\">()</span> </code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><p><b>四. GoogLeNet</b></p><p>      VGG16 以来，深度网络面临的问题比较突出：</p><blockquote><b>1. 深度网络规模越来越大，一味的加深层数使得网络震荡，结果难以收敛，对精度提升并没有作用；</b><br/><b>2. 网络深度增加导致参数也越来越多，容易产生过拟合的问题；</b><br/><b>3. 网络层数的提高带来计算量增加，严重影响网络性能；</b></blockquote><p>      针对上述问题，Google 提出了一个22层的深度网络 GoogLeNet，将 Top5 错误率降低到 6.67%，获得了2014年 ILSVRC 的冠军。</p><p>          （PS：为了纪念 LeNet，Google 搞了个大写）。</p><p>      这是一个 Inception module的概念，采用不同尺度的卷积核进行特征提取（对应下面左图的1*1，3*3，5*5），增加单层网络的特征提取能力；另外，通过 1*1 的卷积核（对应右图）进行降维，如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-3a9161b0eb8f487258a5ac4eb6dd3ed7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"826\" data-rawheight=\"214\" class=\"origin_image zh-lightbox-thumb\" width=\"826\" data-original=\"https://pic4.zhimg.com/v2-3a9161b0eb8f487258a5ac4eb6dd3ed7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;826&#39; height=&#39;214&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"826\" data-rawheight=\"214\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"826\" data-original=\"https://pic4.zhimg.com/v2-3a9161b0eb8f487258a5ac4eb6dd3ed7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-3a9161b0eb8f487258a5ac4eb6dd3ed7_b.jpg\"/></figure><p>      完整的 GoogLeNet 是多个 Inception Module 的组合，如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-2ad0ab807181ce794fca0e2a7dd7a68b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1023\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb\" width=\"1023\" data-original=\"https://pic4.zhimg.com/v2-2ad0ab807181ce794fca0e2a7dd7a68b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1023&#39; height=&#39;372&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1023\" data-rawheight=\"372\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1023\" data-original=\"https://pic4.zhimg.com/v2-2ad0ab807181ce794fca0e2a7dd7a68b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-2ad0ab807181ce794fca0e2a7dd7a68b_b.jpg\"/></figure><p>      TensorFlow 实现 Google Inception V3 可以参考 Tensorflow 的开源实现，代码量比较大，这里就不再贴出来了。</p><p>      Github地址：<a href=\"https://link.zhihu.com/?target=https%3A//github.com/tensorflow/models/blob/master/slim/nets/inception_v3.py\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/tensorflow/m</span><span class=\"invisible\">odels/blob/master/slim/nets/inception_v3.py</span><span class=\"ellipsis\"></span></a></p>", 
            "topic": [
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/33446676", 
            "userName": "linolzhang", 
            "userLink": "https://www.zhihu.com/people/aa20b95b0383ebd8de05ac61798ec9ce", 
            "upvote": 6, 
            "title": "浅入浅出TensorFlow 5 - 可视化工具TensorBoard", 
            "content": "<p><b>一. TensorBoard 介绍</b></p><p>     TensorFlow 可视化可以借助 Python 的 matplotlib 进行，也可以使用 TensorFlow 自带的 TensorBoard，推荐大家使用 TensorBoard 进行可视化，这样可以不依赖于TensorFLow 的 Python 接口。</p><p>     可视化内容包括：</p><p><b>Event：训练过程中的统计数据，主要包括 Loss、Accuracy等</b></p><p><b>Image：记录的图像数据</b></p><p><b>Graphs：网络结构图</b></p><p><b>Audio：记录的音频数据</b></p><p><b>Histogram：直方图描述的统计结果</b></p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>二. 生成过程</b></p><p>     理解 TensorBoard 使用最关键的一点就是 Summary，Summary对应流程也就是我们的使用流程：</p><p><b>a）调用 TensorFlow API中的summary接口</b></p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">scalar_summary</span><span class=\"p\">(</span><span class=\"n\">tags</span><span class=\"p\">,</span> <span class=\"n\">values</span><span class=\"p\">,</span> <span class=\"n\">collections</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">)</span>              <span class=\"c1\"># 标量数据  </span>\n<span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">histogram_summary</span><span class=\"p\">(</span><span class=\"n\">tag</span><span class=\"p\">,</span> <span class=\"n\">values</span><span class=\"p\">,</span> <span class=\"n\">collections</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">)</span>            <span class=\"c1\"># 直方图数据  </span>\n<span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">image_summary</span><span class=\"p\">(</span><span class=\"n\">tag</span><span class=\"p\">,</span> <span class=\"n\">tensor</span><span class=\"p\">,</span> <span class=\"n\">max_images</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">collections</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">)</span>  <span class=\"c1\"># 图像数据</span></code></pre></div><p>   上面 summay 得到的输出为包含对应数据的 ProtoBuf，通常的做法是先将这些数据合并，然后再写入。</p><p><b>b）将Summary信息汇总</b></p><p>     将上面函数输出的 protobuf 数据进行合并，提供两种接口（通常我们用第二个就可以了）：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">merged_summary_op</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">merge_summary</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">collections</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">)</span>  \n<span class=\"n\">merged_summary_op</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">merge_all_summaries</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"o\">=</span><span class=\"s1\">&#39;summaries&#39;</span><span class=\"p\">)</span> </code></pre></div><p><b>c）指定写入路径</b></p><p>     关键类：tf.train.SummaryWriter，在该目录下，生成对应event文件</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">train_writer</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">SummaryWriter</span><span class=\"p\">(</span><span class=\"n\">summary_dir</span> <span class=\"o\">+</span> <span class=\"s1\">&#39;/train&#39;</span><span class=\"p\">,</span><span class=\"n\">session</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"p\">)</span>\n<span class=\"n\">test_writer</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">SummaryWriter</span><span class=\"p\">(</span><span class=\"n\">summary_dir</span> <span class=\"o\">+</span> <span class=\"s1\">&#39;/test&#39;</span><span class=\"p\">)</span>  </code></pre></div><p><b>d）Training调用及单步写出</b></p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"n\">total_step</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>  \n<span class=\"k\">while</span> <span class=\"n\">training</span><span class=\"p\">:</span>  \n  <span class=\"n\">total_step</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>  \n  <span class=\"n\">session</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">training_op</span><span class=\"p\">)</span>   <span class=\"c1\"># 执行一次Training  </span>\n  <span class=\"k\">if</span> <span class=\"n\">total_step</span> <span class=\"o\">%</span> <span class=\"mi\">100</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>  \n    <span class=\"n\">summary_step</span> <span class=\"o\">=</span> <span class=\"n\">session</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">merged_summary_op</span><span class=\"p\">)</span>         <span class=\"c1\"># 运行summary_op，统计一次  </span>\n    <span class=\"n\">summary_writer</span><span class=\"o\">.</span><span class=\"n\">add_summary</span><span class=\"p\">(</span><span class=\"n\">summary_step</span><span class=\"p\">,</span> <span class=\"n\">total_step</span><span class=\"p\">)</span>  <span class=\"c1\"># 写出一个step,写出到event</span></code></pre></div><p><b>三. 可视化展示</b></p><p>     TensorFLow 主要对网络和参数进行可视化，通过读取运行过程中生成的 Log文件 进行可视化，输入参数为 日志文件路径。</p><div class=\"highlight\"><pre><code class=\"language-bash\">tensorboard --logdir<span class=\"o\">=</span><span class=\"s2\">&#34;/…&#34;</span>  <span class=\"c1\"># logfile dir</span> </code></pre></div><p>      TensorBoard 读取日志文件，并生成本地服务（默认6006端口），通过访问本地 回环地址 127.0.0.1:6006 查看可视化结果，如下图所示：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-78b3f7d11767fdfe57a1cdc955ace75c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"970\" data-rawheight=\"126\" class=\"origin_image zh-lightbox-thumb\" width=\"970\" data-original=\"https://pic1.zhimg.com/v2-78b3f7d11767fdfe57a1cdc955ace75c_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;970&#39; height=&#39;126&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"970\" data-rawheight=\"126\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"970\" data-original=\"https://pic1.zhimg.com/v2-78b3f7d11767fdfe57a1cdc955ace75c_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-78b3f7d11767fdfe57a1cdc955ace75c_b.jpg\"/></figure><p><b>四. 代码示例</b> </p><p>     下面通过实例代码进行 TensorBoard 的使用展示，里面 with tf.name_scope() 需要理解一下，主要是做层级划分（与c++的namespace类似），比如：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;hidden&#39;</span><span class=\"p\">):</span>  \n<span class=\"o\">&lt;</span><span class=\"n\">span</span> <span class=\"n\">style</span><span class=\"o\">=</span><span class=\"s2\">&#34;white-space:pre;&#34;</span><span class=\"o\">&gt;</span> <span class=\"o\">&lt;/</span><span class=\"n\">span</span><span class=\"o\">&gt;</span><span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;alpha&#39;</span><span class=\"p\">)</span>  \n<span class=\"o\">&lt;</span><span class=\"n\">span</span> <span class=\"n\">style</span><span class=\"o\">=</span><span class=\"s2\">&#34;white-space:pre;&#34;</span><span class=\"o\">&gt;</span> <span class=\"o\">&lt;/</span><span class=\"n\">span</span><span class=\"o\">&gt;</span><span class=\"n\">W</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">random_uniform</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"o\">-</span><span class=\"mf\">1.0</span><span class=\"p\">,</span> <span class=\"mf\">1.0</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;weights&#39;</span><span class=\"p\">)</span>  \n<span class=\"o\">&lt;</span><span class=\"n\">span</span> <span class=\"n\">style</span><span class=\"o\">=</span><span class=\"s2\">&#34;white-space:pre;&#34;</span><span class=\"o\">&gt;</span> <span class=\"o\">&lt;/</span><span class=\"n\">span</span><span class=\"o\">&gt;</span><span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">]),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;biases&#39;</span><span class=\"p\">)</span>  </code></pre></div><p>     形成结点的层次关系描述（可以参考 Tensorflow中文手册v1.2）：</p><p><b>• hidden/alpha</b></p><p><b>• hidden/weights</b></p><p><b>• hidden/biases</b></p><p>     完整的 MNIST训练示例：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"c1\">#coding=utf-8  </span>\n<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"kn\">as</span> <span class=\"nn\">tf</span>  \n<span class=\"kn\">from</span> <span class=\"nn\">tensorflow.examples.tutorials.mnist</span> <span class=\"kn\">import</span> <span class=\"n\">input_data</span>  \n  \n<span class=\"c1\"># define W &amp; b  </span>\n<span class=\"k\">def</span> <span class=\"nf\">weight_variable</span><span class=\"p\">(</span><span class=\"n\">para</span><span class=\"p\">):</span>  \n    <span class=\"c1\"># 采用截断的正态分布，标准差stddev＝0.1  </span>\n    <span class=\"n\">initial</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">truncated_normal</span><span class=\"p\">(</span><span class=\"n\">para</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>  \n    <span class=\"k\">return</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">initial</span><span class=\"p\">)</span>  \n  \n<span class=\"k\">def</span> <span class=\"nf\">bias_variable</span><span class=\"p\">(</span><span class=\"n\">para</span><span class=\"p\">):</span>  \n    <span class=\"n\">initial</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"n\">para</span><span class=\"p\">)</span>  \n    <span class=\"k\">return</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">initial</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 定义变量汇总  </span>\n<span class=\"k\">def</span> <span class=\"nf\">variable_summaries</span><span class=\"p\">(</span><span class=\"n\">var</span><span class=\"p\">):</span>  \n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;summaries&#39;</span><span class=\"p\">):</span>  <span class=\"c1\"># 定义的scope范围  </span>\n        <span class=\"n\">mean</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_mean</span><span class=\"p\">(</span><span class=\"n\">var</span><span class=\"p\">)</span>  \n        <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">scalar</span><span class=\"p\">(</span><span class=\"s1\">&#39;mean&#39;</span><span class=\"p\">,</span><span class=\"n\">mean</span><span class=\"p\">)</span>  \n        <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;stddev&#39;</span><span class=\"p\">):</span>  \n            <span class=\"n\">stddev</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">sqrt</span><span class=\"p\">(</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_mean</span><span class=\"p\">(</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_mean</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">square</span><span class=\"p\">(</span><span class=\"n\">var</span><span class=\"o\">-</span><span class=\"n\">mean</span><span class=\"p\">))</span> <span class=\"p\">)</span> <span class=\"p\">)</span>  \n        <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">scalar</span><span class=\"p\">(</span><span class=\"s1\">&#39;stddev&#39;</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"p\">)</span>  \n        <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">scalar</span><span class=\"p\">(</span><span class=\"s1\">&#39;max&#39;</span><span class=\"p\">,</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_max</span><span class=\"p\">(</span><span class=\"n\">var</span><span class=\"p\">))</span>  \n        <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">scalar</span><span class=\"p\">(</span><span class=\"s1\">&#39;min&#39;</span><span class=\"p\">,</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_min</span><span class=\"p\">(</span><span class=\"n\">var</span><span class=\"p\">))</span>  <span class=\"c1\"># 记录变量var的 均值、标准差、最大值、最小值  </span>\n        <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">histogram</span><span class=\"p\">(</span><span class=\"s1\">&#39;histogram&#39;</span><span class=\"p\">,</span><span class=\"n\">var</span><span class=\"p\">)</span>        <span class=\"c1\"># 记录变量var的直方图 - histogram  </span>\n  \n<span class=\"c1\"># 定义卷积层 - 定义输入数据、维度  </span>\n<span class=\"c1\">#          - 定义输出数据、维度  </span>\n<span class=\"c1\">#          - 默认激活函数采用relu  </span>\n<span class=\"k\">def</span> <span class=\"nf\">nn_layer</span><span class=\"p\">(</span><span class=\"n\">in_data</span><span class=\"p\">,</span><span class=\"n\">in_dim</span><span class=\"p\">,</span><span class=\"n\">out_dim</span><span class=\"p\">,</span><span class=\"n\">layer_name</span><span class=\"p\">,</span> <span class=\"n\">act</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">):</span>  \n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"n\">layer_name</span><span class=\"p\">):</span>      <span class=\"c1\"># 针对每一层，记录数据  </span>\n        <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;weights&#39;</span><span class=\"p\">):</span>  \n            <span class=\"n\">weights</span> <span class=\"o\">=</span> <span class=\"n\">weight_variable</span><span class=\"p\">([</span><span class=\"n\">in_dim</span><span class=\"p\">,</span><span class=\"n\">out_dim</span><span class=\"p\">])</span>  <span class=\"c1\"># 调用函数，生成权值  </span>\n            <span class=\"n\">variable_summaries</span><span class=\"p\">(</span><span class=\"n\">weights</span><span class=\"p\">)</span>                  <span class=\"c1\"># 记录每一层的权值  </span>\n        <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;biases&#39;</span><span class=\"p\">):</span>  \n            <span class=\"n\">biases</span> <span class=\"o\">=</span> <span class=\"n\">bias_variable</span><span class=\"p\">([</span><span class=\"n\">out_dim</span><span class=\"p\">])</span>            <span class=\"c1\"># 调用函数，生成biases  </span>\n            <span class=\"n\">variable_summaries</span><span class=\"p\">(</span><span class=\"n\">biases</span><span class=\"p\">)</span>                   <span class=\"c1\"># 记录每一层的biases  </span>\n        <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;Wx_plus_b&#39;</span><span class=\"p\">):</span>  \n            <span class=\"n\">Wx_plus_b</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">in_data</span><span class=\"p\">,</span><span class=\"n\">weights</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">biases</span>  <span class=\"c1\"># 计算 wx＋b  </span>\n            <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">histogram</span><span class=\"p\">(</span><span class=\"s1\">&#39;Wx_plus_b&#39;</span><span class=\"p\">,</span><span class=\"n\">Wx_plus_b</span><span class=\"p\">)</span>      <span class=\"c1\"># 记录wx＋b结果 - histogram  </span>\n        <span class=\"n\">activations</span> <span class=\"o\">=</span> <span class=\"n\">act</span><span class=\"p\">(</span><span class=\"n\">Wx_plus_b</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;activation&#39;</span><span class=\"p\">)</span>    <span class=\"c1\"># 激活  </span>\n        <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">histogram</span><span class=\"p\">(</span><span class=\"s1\">&#39;activations&#39;</span><span class=\"p\">,</span><span class=\"n\">activations</span><span class=\"p\">)</span>      <span class=\"c1\"># 记录激活层结果 - histogram  </span>\n        <span class=\"k\">return</span> <span class=\"n\">activations</span>  \n  \n  \n<span class=\"c1\"># 准备训练数据，创建session   </span>\n<span class=\"n\">mnist</span> <span class=\"o\">=</span> <span class=\"n\">input_data</span><span class=\"o\">.</span><span class=\"n\">read_data_sets</span><span class=\"p\">(</span><span class=\"s2\">&#34;MNIST_data/&#34;</span><span class=\"p\">,</span> <span class=\"n\">one_hot</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>  \n<span class=\"n\">sess</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">InteractiveSession</span><span class=\"p\">()</span>  \n  \n<span class=\"c1\"># 定义原始数据输入  </span>\n<span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;input&#39;</span><span class=\"p\">):</span>  \n    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">placeholder</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"bp\">None</span><span class=\"p\">,</span><span class=\"mi\">784</span><span class=\"p\">],</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;x_input&#39;</span><span class=\"p\">)</span>   <span class=\"c1\"># 28*28=784 dim，添加了一个name属性，用于显示  </span>\n    <span class=\"n\">y_</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">placeholder</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"bp\">None</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">],</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;x_input&#39;</span><span class=\"p\">)</span>  <span class=\"c1\"># label - 10 dim  </span>\n  \n<span class=\"c1\"># 原始数据reshape  </span>\n<span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;input_reshape&#39;</span><span class=\"p\">):</span>  \n    <span class=\"n\">x_shaped</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">28</span><span class=\"p\">,</span><span class=\"mi\">28</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">])</span>  <span class=\"c1\"># reshape for conv, -1表示不固定数量，1为通道数  </span>\n    <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">image</span><span class=\"p\">(</span><span class=\"s1\">&#39;input&#39;</span><span class=\"p\">,</span><span class=\"n\">x_shaped</span><span class=\"p\">,</span><span class=\"mi\">10</span><span class=\"p\">)</span>   <span class=\"c1\"># 记录input数据，显示 - image  </span>\n  \n<span class=\"c1\"># 创建第一层layer  </span>\n<span class=\"n\">layer1</span> <span class=\"o\">=</span> <span class=\"n\">nn_layer</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"mi\">784</span><span class=\"p\">,</span><span class=\"mi\">500</span><span class=\"p\">,</span><span class=\"s1\">&#39;layer1&#39;</span><span class=\"p\">)</span>  \n  \n<span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;dropout&#39;</span><span class=\"p\">):</span>              <span class=\"c1\"># layer1 后面follow一层dropout  </span>\n    <span class=\"n\">keep_prob</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">placeholder</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>  \n    <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">scalar</span><span class=\"p\">(</span><span class=\"s1\">&#39;dropout_keep_probability&#39;</span><span class=\"p\">,</span><span class=\"n\">keep_prob</span><span class=\"p\">)</span>  \n    <span class=\"n\">dropped</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">dropout</span><span class=\"p\">(</span><span class=\"n\">layer1</span><span class=\"p\">,</span><span class=\"n\">keep_prob</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 创建第二层layer  </span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">nn_layer</span><span class=\"p\">(</span><span class=\"n\">dropped</span><span class=\"p\">,</span><span class=\"mi\">500</span><span class=\"p\">,</span><span class=\"mi\">10</span><span class=\"p\">,</span><span class=\"s1\">&#39;layer2&#39;</span><span class=\"p\">,</span><span class=\"n\">act</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">identity</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># softmax  </span>\n<span class=\"c1\"># 计算交叉熵cross_entropy  </span>\n<span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;cross_entropy&#39;</span><span class=\"p\">):</span>  \n    <span class=\"n\">diff</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">softmax_cross_entropy_with_logits</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"o\">=</span><span class=\"n\">y</span><span class=\"p\">,</span><span class=\"n\">labels</span><span class=\"o\">=</span><span class=\"n\">y_</span><span class=\"p\">)</span>  <span class=\"c1\"># diff  </span>\n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;total&#39;</span><span class=\"p\">):</span>  \n        <span class=\"n\">cross_entropy</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_mean</span><span class=\"p\">(</span><span class=\"n\">diff</span><span class=\"p\">)</span>  \n<span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">scalar</span><span class=\"p\">(</span><span class=\"s1\">&#39;cross_entropy&#39;</span><span class=\"p\">,</span><span class=\"n\">cross_entropy</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># training  </span>\n<span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;train&#39;</span><span class=\"p\">):</span>  \n    <span class=\"n\">train_step</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">AdamOptimizer</span><span class=\"p\">(</span><span class=\"mf\">0.001</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">minimize</span><span class=\"p\">(</span><span class=\"n\">cross_entropy</span><span class=\"p\">)</span>  \n<span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;accuracy&#39;</span><span class=\"p\">):</span>  \n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;correct_prediction&#39;</span><span class=\"p\">):</span>  \n        <span class=\"n\">correct_prediction</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">equal</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">),</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">y_</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">))</span>  \n    <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">name_scope</span><span class=\"p\">(</span><span class=\"s1\">&#39;accuracy&#39;</span><span class=\"p\">):</span>  \n        <span class=\"n\">accuracy_op</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_mean</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">cast</span><span class=\"p\">(</span><span class=\"n\">correct_prediction</span><span class=\"p\">,</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>  \n<span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">scalar</span><span class=\"p\">(</span><span class=\"s1\">&#39;accuracy&#39;</span><span class=\"p\">,</span><span class=\"n\">accuracy_op</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 汇总所有summary  </span>\n<span class=\"n\">merge_op</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">merge_all</span><span class=\"p\">()</span>  \n<span class=\"n\">train_writer</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">FileWriter</span><span class=\"p\">(</span><span class=\"s1\">&#39;./logs/mnist/train&#39;</span><span class=\"p\">,</span><span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"p\">)</span>  <span class=\"c1\"># 保存log文件路径  </span>\n<span class=\"n\">test_writer</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">FileWriter</span><span class=\"p\">(</span><span class=\"s1\">&#39;./logs/mnist/test&#39;</span><span class=\"p\">,</span><span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"p\">)</span>  <span class=\"c1\"># 保存log文件路径  </span>\n  \n<span class=\"c1\"># 开始训练  </span>\n<span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">global_variables_initializer</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>  <span class=\"c1\"># 初始化所有变量  </span>\n  \n<span class=\"c1\"># 使用tf.train.Saver()创建模型的保存器  </span>\n<span class=\"n\">saver</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">Saver</span><span class=\"p\">()</span>  \n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">):</span>  \n    <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">%</span> <span class=\"mi\">10</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>  <span class=\"c1\"># for test，每10个step保存一次  </span>\n        <span class=\"c1\"># 读入数据  </span>\n        <span class=\"n\">xs</span><span class=\"p\">,</span> <span class=\"n\">ys</span> <span class=\"o\">=</span> <span class=\"n\">mnist</span><span class=\"o\">.</span><span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">images</span><span class=\"p\">,</span> <span class=\"n\">mnist</span><span class=\"o\">.</span><span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">labels</span>  \n        <span class=\"c1\"># 执行merge_op(数据汇总) 和 accuracy_op(准确率测试)  </span>\n        <span class=\"n\">summary</span><span class=\"p\">,</span> <span class=\"n\">acc</span> <span class=\"o\">=</span> <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">([</span><span class=\"n\">merge_op</span><span class=\"p\">,</span> <span class=\"n\">accuracy_op</span><span class=\"p\">],</span> <span class=\"n\">feed_dict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"n\">x</span><span class=\"p\">:</span><span class=\"n\">xs</span><span class=\"p\">,</span><span class=\"n\">y_</span><span class=\"p\">:</span><span class=\"n\">ys</span><span class=\"p\">,</span><span class=\"n\">keep_prob</span><span class=\"p\">:</span><span class=\"mf\">1.0</span><span class=\"p\">})</span>  \n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Accuracy at step </span><span class=\"si\">%s</span><span class=\"s1\">: </span><span class=\"si\">%s</span><span class=\"s1\">&#39;</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">acc</span><span class=\"p\">))</span>  <span class=\"c1\"># 打印输出结果  </span>\n  \n    <span class=\"k\">else</span><span class=\"p\">:</span>   <span class=\"c1\"># for train  </span>\n        <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">==</span> <span class=\"mi\">99</span><span class=\"p\">:</span>   \n            <span class=\"c1\"># tf.RunOption定义运行选项，  </span>\n            <span class=\"c1\"># tf.RunMetadata()定义运行的元数据信息，描述运算时间和内存占用等  </span>\n            <span class=\"n\">run_options</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">RunOptions</span><span class=\"p\">(</span><span class=\"n\">trace_level</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">RunOptions</span><span class=\"o\">.</span><span class=\"n\">FULL_TRACE</span><span class=\"p\">)</span>  \n            <span class=\"n\">run_metadata_op</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">RunMetadata</span><span class=\"p\">()</span>  \n            <span class=\"n\">xs</span><span class=\"p\">,</span> <span class=\"n\">ys</span> <span class=\"o\">=</span> <span class=\"n\">mnist</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">next_batch</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">)</span>  \n            <span class=\"n\">summary</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">([</span><span class=\"n\">merge_op</span><span class=\"p\">,</span> <span class=\"n\">train_step</span><span class=\"p\">],</span> <span class=\"n\">feed_dict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"n\">x</span><span class=\"p\">:</span><span class=\"n\">xs</span><span class=\"p\">,</span><span class=\"n\">y_</span><span class=\"p\">:</span><span class=\"n\">ys</span><span class=\"p\">,</span><span class=\"n\">keep_prob</span><span class=\"p\">:</span><span class=\"mf\">0.6</span><span class=\"p\">},</span>  \n                                    <span class=\"n\">options</span><span class=\"o\">=</span><span class=\"n\">run_options</span><span class=\"p\">,</span> <span class=\"n\">run_metadata</span><span class=\"o\">=</span><span class=\"n\">run_metadata_op</span><span class=\"p\">)</span>  \n            <span class=\"n\">train_writer</span><span class=\"o\">.</span><span class=\"n\">add_run_metadata</span><span class=\"p\">(</span><span class=\"n\">run_metadata_op</span><span class=\"p\">,</span><span class=\"s1\">&#39;step </span><span class=\"si\">% 03d</span><span class=\"s1\">&#39;</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span>  \n            <span class=\"n\">train_writer</span><span class=\"o\">.</span><span class=\"n\">add_summary</span><span class=\"p\">(</span><span class=\"n\">summary</span><span class=\"p\">,</span><span class=\"n\">i</span><span class=\"p\">)</span>  \n            <span class=\"n\">saver</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"n\">sess</span><span class=\"p\">,</span><span class=\"s1\">&#39;./logs/model.ckpt&#39;</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span>  \n            <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;Adding run metadata for&#39;</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span>  \n        <span class=\"k\">else</span><span class=\"p\">:</span>  \n            <span class=\"n\">xs</span><span class=\"p\">,</span> <span class=\"n\">ys</span> <span class=\"o\">=</span> <span class=\"n\">mnist</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">next_batch</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">)</span>  \n            <span class=\"c1\"># 执行merged_op和train_step，记录summary   </span>\n            <span class=\"n\">summary</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">([</span><span class=\"n\">merge_op</span><span class=\"p\">,</span> <span class=\"n\">train_step</span><span class=\"p\">],</span> <span class=\"n\">feed_dict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"n\">x</span><span class=\"p\">:</span><span class=\"n\">xs</span><span class=\"p\">,</span><span class=\"n\">y_</span><span class=\"p\">:</span><span class=\"n\">ys</span><span class=\"p\">,</span><span class=\"n\">keep_prob</span><span class=\"p\">:</span><span class=\"mf\">0.6</span><span class=\"p\">})</span>  \n            <span class=\"n\">train_writer</span><span class=\"o\">.</span><span class=\"n\">add_summary</span><span class=\"p\">(</span><span class=\"n\">summary</span><span class=\"p\">,</span><span class=\"n\">i</span><span class=\"p\">)</span>  \n<span class=\"c1\"># 训练完毕，关闭writer  </span>\n<span class=\"n\">train_writer</span><span class=\"o\">.</span><span class=\"n\">close</span>  \n<span class=\"n\">test_writer</span><span class=\"o\">.</span><span class=\"n\">close</span> </code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><p><b>四. 劳动成果</b></p><p>     好了按照上面的命令，输入：</p><div class=\"highlight\"><pre><code class=\"language-bash\">tensorboard --logdir<span class=\"o\">=</span>./logs/mnist/train  \nStarting TensorBoard <span class=\"m\">47</span> at http://0.0.0.0:6006  \n<span class=\"o\">(</span>Press CTRL+C to quit<span class=\"o\">)</span>  </code></pre></div><p>     根据提示的IP地址进行浏览（注：用Chrome浏览器，IE或者Safri因兼容问题可能会出现空白问题）：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-4bde24b87afa671ff171c4f193533166_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"300\" data-rawheight=\"370\" class=\"content_image\" width=\"300\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;300&#39; height=&#39;370&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"300\" data-rawheight=\"370\" class=\"content_image lazy\" width=\"300\" data-actualsrc=\"https://pic3.zhimg.com/v2-4bde24b87afa671ff171c4f193533166_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-122ae9361c3e7f58f6b604c454be8e7b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"359\" data-rawheight=\"370\" class=\"content_image\" width=\"359\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;359&#39; height=&#39;370&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"359\" data-rawheight=\"370\" class=\"content_image lazy\" width=\"359\" data-actualsrc=\"https://pic4.zhimg.com/v2-122ae9361c3e7f58f6b604c454be8e7b_b.jpg\"/></figure><p></p>", 
            "topic": [
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }
            ], 
            "comments": [
                {
                    "userName": "牛奋", 
                    "userLink": "https://www.zhihu.com/people/6c8622b196d40fc86a10b44b6eeb54c0", 
                    "content": "tensorboard支持实时可视化训练过程中日志吗", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/33446574", 
            "userName": "linolzhang", 
            "userLink": "https://www.zhihu.com/people/aa20b95b0383ebd8de05ac61798ec9ce", 
            "upvote": 2, 
            "title": "浅入浅出TensorFlow 4 - 训练CIFAR数据", 
            "content": "<p><b>一.  CIFAR数据集</b></p><p>     CIFAR数据集是一个经典的数据集，提供两个版本的分类样本，CIFAR-10和CIFAR-100。</p><p>     CIFAR-10 提供10类标注数据，每类6000张（32*32），其中5000张用于训练，1000张用于测试。</p><p>  获取数据集的方法：</p><div class=\"highlight\"><pre><code class=\"language-bash\">git clone https://github.com/tensorflow/models.git  \n<span class=\"nb\">cd</span> models/tutorials/image/cifar10  </code></pre></div><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-addfb487767a9b71b6efc239d9249d7b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"98\" class=\"origin_image zh-lightbox-thumb\" width=\"500\" data-original=\"https://pic4.zhimg.com/v2-addfb487767a9b71b6efc239d9249d7b_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;500&#39; height=&#39;98&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"500\" data-rawheight=\"98\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"500\" data-original=\"https://pic4.zhimg.com/v2-addfb487767a9b71b6efc239d9249d7b_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-addfb487767a9b71b6efc239d9249d7b_b.jpg\"/></figure><p>     可以看一下我们从github上down下来的数据，外面不看了，直接进 tutorials/image，教程专用，看来是基础的不能再基础了。</p><p>     里面提供了几个典型的数据集的 下载、训练等接口，方便直接在python里调用。</p><p>     进入cifar10，能够看到：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-8ce30694ad80bbb7258a2f79c45f7083_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"136\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic4.zhimg.com/v2-8ce30694ad80bbb7258a2f79c45f7083_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;600&#39; height=&#39;136&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"136\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"600\" data-original=\"https://pic4.zhimg.com/v2-8ce30694ad80bbb7258a2f79c45f7083_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-8ce30694ad80bbb7258a2f79c45f7083_b.jpg\"/></figure><p>    其中文件 cifar10.py 和 cifar10_input.py 就是接下来我们要 import 的。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>二.  代码实现</b></p><p>     撸一段 Python 代码，可以View里面的注释讲解：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"c1\">#coding=utf-8  </span>\n<span class=\"kn\">import</span> <span class=\"nn\">cifar10</span><span class=\"o\">,</span><span class=\"nn\">cifar10_input</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"kn\">as</span> <span class=\"nn\">tf</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"kn\">as</span> <span class=\"nn\">np</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">time</span>  \n  \n<span class=\"c1\"># define max_iter_step  batch_size  </span>\n<span class=\"n\">max_iter_step</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span>  \n<span class=\"n\">batch_size</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>  \n  \n<span class=\"c1\"># define variable_with_weight_loss  </span>\n<span class=\"c1\"># 和之前定义的weight有所不同，   </span>\n<span class=\"c1\"># 这里定义附带loss的weight，通过权重惩罚避免部分权重系数过大，导致overfitting   </span>\n<span class=\"k\">def</span> <span class=\"nf\">variable_with_weight_loss</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"p\">,</span><span class=\"n\">w1</span><span class=\"p\">):</span>  \n    <span class=\"n\">var</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">truncated_normal</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"n\">stddev</span><span class=\"p\">))</span>  \n    <span class=\"k\">if</span> <span class=\"n\">w1</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"bp\">None</span><span class=\"p\">:</span>  \n        <span class=\"n\">weight_loss</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">multiply</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">l2_loss</span><span class=\"p\">(</span><span class=\"n\">var</span><span class=\"p\">),</span><span class=\"n\">w1</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;weight_loss&#39;</span><span class=\"p\">)</span>  \n        <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">add_to_collection</span><span class=\"p\">(</span><span class=\"s1\">&#39;losses&#39;</span><span class=\"p\">,</span><span class=\"n\">weight_loss</span><span class=\"p\">)</span>  \n    <span class=\"k\">return</span> <span class=\"n\">var</span>  \n  \n<span class=\"c1\"># 下载数据集 － 调用cifar10函数下载并解压  </span>\n<span class=\"n\">cifar10</span><span class=\"o\">.</span><span class=\"n\">maybe_download_and_extract</span><span class=\"p\">()</span>  \n  \n<span class=\"n\">cifar_dir</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;/tmp/cifar10_data/cifar-10-batches-bin&#39;</span>  \n  \n<span class=\"c1\"># 采用 data augmentation进行数据处理  </span>\n<span class=\"c1\"># 生成训练数据，训练数据通过cifar10_input的distort变化   </span>\n<span class=\"n\">images_train</span><span class=\"p\">,</span> <span class=\"n\">labels_train</span> <span class=\"o\">=</span> <span class=\"n\">cifar10_input</span><span class=\"o\">.</span><span class=\"n\">distorted_inputs</span><span class=\"p\">(</span><span class=\"n\">data_dir</span><span class=\"o\">=</span><span class=\"n\">cifar_dir</span><span class=\"p\">,</span><span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">)</span>  \n<span class=\"c1\"># 测试数据（eval_data 测试数据）  </span>\n<span class=\"n\">images_test</span><span class=\"p\">,</span><span class=\"n\">labels_test</span> <span class=\"o\">=</span> <span class=\"n\">cifar10_input</span><span class=\"o\">.</span><span class=\"n\">inputs</span><span class=\"p\">(</span><span class=\"n\">eval_data</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span><span class=\"n\">data_dir</span><span class=\"o\">=</span><span class=\"n\">cifar_dir</span><span class=\"p\">,</span><span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 创建输入数据，采用 placeholder  </span>\n<span class=\"n\">x_input</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">placeholder</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,[</span><span class=\"n\">batch_size</span><span class=\"p\">,</span><span class=\"mi\">24</span><span class=\"p\">,</span><span class=\"mi\">24</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">])</span>  \n<span class=\"n\">y_input</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">placeholder</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">int32</span><span class=\"p\">,[</span><span class=\"n\">batch_size</span><span class=\"p\">])</span>  \n  \n<span class=\"c1\"># 创建第一个卷积层 input:3(channel) kernel:64 size:5*5  </span>\n<span class=\"n\">weight1</span> <span class=\"o\">=</span> <span class=\"n\">variable_with_weight_loss</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">64</span><span class=\"p\">],</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">5e-2</span><span class=\"p\">,</span><span class=\"n\">w1</span><span class=\"o\">=</span><span class=\"mf\">0.0</span><span class=\"p\">)</span>  \n<span class=\"n\">bias1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">64</span><span class=\"p\">]))</span>  \n<span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">conv2d</span><span class=\"p\">(</span><span class=\"n\">x_input</span><span class=\"p\">,</span><span class=\"n\">weight1</span><span class=\"p\">,[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n<span class=\"n\">relu1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">bias_add</span><span class=\"p\">(</span><span class=\"n\">conv1</span><span class=\"p\">,</span><span class=\"n\">bias1</span><span class=\"p\">))</span>  \n<span class=\"n\">pool1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">conv1</span><span class=\"p\">,</span><span class=\"n\">ksize</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">strides</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n<span class=\"n\">norm1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">lrn</span><span class=\"p\">(</span><span class=\"n\">pool1</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">,</span><span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"o\">/</span><span class=\"mf\">9.0</span><span class=\"p\">,</span><span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">0.75</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 创建第二个卷积层 input:64 kernel:64 size:5*5  </span>\n<span class=\"n\">weight2</span> <span class=\"o\">=</span> <span class=\"n\">variable_with_weight_loss</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">64</span><span class=\"p\">,</span><span class=\"mi\">64</span><span class=\"p\">],</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">5e-2</span><span class=\"p\">,</span><span class=\"n\">w1</span><span class=\"o\">=</span><span class=\"mf\">0.0</span><span class=\"p\">)</span>  \n<span class=\"n\">bias2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">64</span><span class=\"p\">]))</span>  \n<span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">conv2d</span><span class=\"p\">(</span><span class=\"n\">norm1</span><span class=\"p\">,</span><span class=\"n\">weight2</span><span class=\"p\">,[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n<span class=\"n\">relu2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">bias_add</span><span class=\"p\">(</span><span class=\"n\">conv2</span><span class=\"p\">,</span><span class=\"n\">bias2</span><span class=\"p\">))</span>  \n<span class=\"n\">norm2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">lrn</span><span class=\"p\">(</span><span class=\"n\">relu2</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">,</span><span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"o\">/</span><span class=\"mf\">9.0</span><span class=\"p\">,</span><span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">0.75</span><span class=\"p\">)</span>  \n<span class=\"n\">pool2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">norm2</span><span class=\"p\">,</span><span class=\"n\">ksize</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">strides</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 创建第三个层－全连接层  output:384  </span>\n<span class=\"n\">reshape</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">pool2</span><span class=\"p\">,[</span><span class=\"n\">batch_size</span><span class=\"p\">,</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">])</span>  \n<span class=\"n\">dim</span> <span class=\"o\">=</span> <span class=\"n\">reshape</span><span class=\"o\">.</span><span class=\"n\">get_shape</span><span class=\"p\">()[</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">value</span>  \n<span class=\"n\">weight3</span> <span class=\"o\">=</span> <span class=\"n\">variable_with_weight_loss</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">dim</span><span class=\"p\">,</span><span class=\"mi\">384</span><span class=\"p\">],</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">0.04</span><span class=\"p\">,</span><span class=\"n\">w1</span><span class=\"o\">=</span><span class=\"mf\">0.004</span><span class=\"p\">)</span>  \n<span class=\"n\">bias3</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.1</span><span class=\"p\">,</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">384</span><span class=\"p\">]))</span>  \n<span class=\"n\">local3</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">reshape</span><span class=\"p\">,</span><span class=\"n\">weight3</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"n\">bias3</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 创建第四个层－全连接层  output:192  </span>\n<span class=\"n\">weight4</span> <span class=\"o\">=</span> <span class=\"n\">variable_with_weight_loss</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">384</span><span class=\"p\">,</span><span class=\"mi\">192</span><span class=\"p\">],</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">0.04</span><span class=\"p\">,</span><span class=\"n\">w1</span><span class=\"o\">=</span><span class=\"mf\">0.004</span><span class=\"p\">)</span>  \n<span class=\"n\">bias4</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.1</span><span class=\"p\">,</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">192</span><span class=\"p\">]))</span>  \n  \n<span class=\"c1\"># 最后一层  output:10  </span>\n<span class=\"n\">weight5</span> <span class=\"o\">=</span> <span class=\"n\">variable_with_weight_loss</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">192</span><span class=\"p\">,</span><span class=\"mi\">10</span><span class=\"p\">],</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"o\">/</span><span class=\"mf\">192.0</span><span class=\"p\">,</span><span class=\"n\">w1</span><span class=\"o\">=</span><span class=\"mf\">0.0</span><span class=\"p\">)</span>  \n<span class=\"n\">bias5</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">,</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">]))</span>  \n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">local4</span><span class=\"p\">,</span><span class=\"n\">weight5</span><span class=\"p\">),</span><span class=\"n\">bias5</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 定义loss  </span>\n<span class=\"k\">def</span> <span class=\"nf\">loss</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"p\">,</span><span class=\"n\">labels</span><span class=\"p\">):</span>  \n    <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">cast</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"p\">,</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">int64</span><span class=\"p\">)</span>  \n    <span class=\"n\">cross_entropy</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">sparse_softmax_cross_entropy_with_logits</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"o\">=</span><span class=\"n\">results</span><span class=\"p\">,</span><span class=\"n\">labels</span><span class=\"o\">=</span><span class=\"n\">labels</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;cross_entropy_per_example&#39;</span><span class=\"p\">)</span>  \n    <span class=\"n\">cross_entropy_mean</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_mean</span><span class=\"p\">(</span><span class=\"n\">cross_entropy</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;cross_entropy&#39;</span><span class=\"p\">)</span>  \n    <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">add_to_collection</span><span class=\"p\">(</span><span class=\"s1\">&#39;losses&#39;</span><span class=\"p\">,</span><span class=\"n\">cross_entropy_mean</span><span class=\"p\">)</span>  \n    <span class=\"k\">return</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">add_n</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">get_collection</span><span class=\"p\">(</span><span class=\"s1\">&#39;losses&#39;</span><span class=\"p\">),</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;total_loss&#39;</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 计算loss  </span>\n<span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">loss</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"p\">,</span><span class=\"n\">y_input</span><span class=\"p\">)</span>  \n  \n<span class=\"n\">train_op</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">AdamOptimizer</span><span class=\"p\">(</span><span class=\"mf\">1e-3</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">minimize</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">)</span>  <span class=\"c1\"># Adam  </span>\n<span class=\"n\">top_k_op</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">in_top_k</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"p\">,</span><span class=\"n\">y_input</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">)</span>  <span class=\"c1\"># top1 准确率  </span>\n  \n<span class=\"n\">sess</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">InteractiveSession</span><span class=\"p\">()</span>         <span class=\"c1\"># 创建session  </span>\n<span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">global_variable_initializer</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span> <span class=\"c1\"># 初始化全部模型  </span>\n  \n<span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">start_queue_runners</span><span class=\"p\">()</span>  <span class=\"c1\"># 启动多线程加速  </span>\n  \n<span class=\"c1\"># 开始训练  </span>\n<span class=\"k\">for</span> <span class=\"n\">step</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">max_steps</span><span class=\"p\">):</span>  \n    <span class=\"n\">start_time</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span>  \n    <span class=\"n\">image_batch</span><span class=\"p\">,</span><span class=\"n\">label_batch</span> <span class=\"o\">=</span> <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">([</span><span class=\"n\">images_train</span><span class=\"p\">,</span><span class=\"n\">labels_train</span><span class=\"p\">])</span>  \n    <span class=\"n\">_</span><span class=\"p\">,</span><span class=\"n\">loss_value</span> <span class=\"o\">=</span> <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">([</span><span class=\"n\">train_op</span><span class=\"p\">,</span><span class=\"n\">loss</span><span class=\"p\">],</span>  \n        <span class=\"n\">feed_dict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"n\">x_input</span><span class=\"p\">:</span><span class=\"n\">image_batch</span><span class=\"p\">,</span> <span class=\"n\">y_input</span><span class=\"p\">:</span><span class=\"n\">label_batch</span><span class=\"p\">})</span>  \n    <span class=\"n\">duration</span> <span class=\"o\">=</span> <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">time</span><span class=\"p\">()</span> <span class=\"o\">-</span> <span class=\"n\">start_time</span>  \n    <span class=\"k\">if</span> <span class=\"n\">step</span> <span class=\"o\">%</span> <span class=\"mi\">10</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>  \n        <span class=\"n\">examples_per_sec</span> <span class=\"o\">=</span> <span class=\"n\">batch_size</span><span class=\"o\">/</span><span class=\"n\">duration</span>  \n        <span class=\"n\">sec_per_batch</span> <span class=\"o\">=</span> <span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">duration</span><span class=\"p\">)</span>  \n  \n        <span class=\"n\">format_str</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">&#39;step </span><span class=\"si\">%d</span><span class=\"s1\">,loss=</span><span class=\"si\">%.2f</span><span class=\"s1\"> (</span><span class=\"si\">%.1f</span><span class=\"s1\"> examples/sec; </span><span class=\"si\">%.3f</span><span class=\"s1\"> sec/batch&#39;</span><span class=\"p\">)</span>  \n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">format_str</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">step</span><span class=\"p\">,</span><span class=\"n\">loss_value</span><span class=\"p\">,</span><span class=\"n\">examples_per_sec</span><span class=\"p\">,</span><span class=\"n\">sec_per_batch</span><span class=\"p\">))</span>  \n  \n<span class=\"c1\"># 评测模型在测试集上的准确度  </span>\n<span class=\"n\">num_examples</span> <span class=\"o\">=</span> <span class=\"mi\">10000</span>  \n<span class=\"kn\">import</span> <span class=\"nn\">math</span>  \n<span class=\"n\">num_iter</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">math</span><span class=\"o\">.</span><span class=\"n\">ceil</span><span class=\"p\">(</span><span class=\"n\">num_examples</span><span class=\"o\">/</span><span class=\"n\">batch_size</span><span class=\"p\">))</span>  \n<span class=\"n\">true_count</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>  \n<span class=\"n\">total_sample_count</span> <span class=\"o\">=</span> <span class=\"n\">num_iter</span> <span class=\"o\">*</span> <span class=\"n\">batch_size</span>  \n<span class=\"n\">step</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>  \n<span class=\"k\">while</span> <span class=\"n\">step</span> <span class=\"o\">&lt;</span> <span class=\"n\">num_iter</span><span class=\"p\">:</span>  \n    <span class=\"n\">image_batch</span><span class=\"p\">,</span><span class=\"n\">label_batch</span> <span class=\"o\">=</span> <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">([</span><span class=\"n\">images_test</span><span class=\"p\">,</span><span class=\"n\">labels_test</span><span class=\"p\">])</span>  \n    <span class=\"n\">predictions</span> <span class=\"o\">=</span> <span class=\"n\">sess</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">([</span><span class=\"n\">top_k_op</span><span class=\"p\">],</span><span class=\"n\">feed_dict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"n\">x_input</span><span class=\"p\">:</span><span class=\"n\">image_batch</span><span class=\"p\">,</span><span class=\"n\">y_input</span><span class=\"p\">:</span><span class=\"n\">label_batch</span><span class=\"p\">})</span>  \n    <span class=\"n\">true_count</span> <span class=\"o\">+=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">predictions</span><span class=\"p\">)</span>  \n    <span class=\"n\">step</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>  \n  \n<span class=\"c1\"># 打印结果  </span>\n<span class=\"n\">precision</span> <span class=\"o\">=</span> <span class=\"n\">true_count</span> <span class=\"o\">/</span> <span class=\"n\">total_sample_count</span>  \n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s1\">&#39;precision @ 1 = </span><span class=\"si\">%.3f</span><span class=\"s1\">&#39;</span> <span class=\"o\">%</span> <span class=\"n\">precision</span><span class=\"p\">)</span></code></pre></div><p>     注意，这里与前面不一样的地方在于引入了权值惩罚，另外，top_k的用法也是第一次，将代码另存为 .py文件，copy到models/tutorials/image/cifar10目录下调用，观察下载数据及训练过程，然后再Review代码，相信会有新的收获！</p>", 
            "topic": [
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/33446477", 
            "userName": "linolzhang", 
            "userLink": "https://www.zhihu.com/people/aa20b95b0383ebd8de05ac61798ec9ce", 
            "upvote": 9, 
            "title": "浅入浅出TensorFlow 3 - MNIST手写体识别", 
            "content": "<p>     MNIST 手写体识别通常是神经网络入门的一个例子，每个deep框架 都无例外。</p><p><b>一. MNIST数据</b></p><p>     MNISt 为 0-9的手写阿拉伯数字，提供了6万的 <b>训练集数据（mnist.train）</b>  和 1万的 <b>测试集数据（mnist.test）</b>。</p><p>     下载地址：<a href=\"https://link.zhihu.com/?target=http%3A//yann.lecun.com/exdb/mnist/index.html\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">yann.lecun.com/exdb/mni</span><span class=\"invisible\">st/index.html</span><span class=\"ellipsis\"></span></a></p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-c46eb9492ae4cbbab150bd55acc1aa6c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"353\" data-rawheight=\"83\" class=\"content_image\" width=\"353\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;353&#39; height=&#39;83&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"353\" data-rawheight=\"83\" class=\"content_image lazy\" width=\"353\" data-actualsrc=\"https://pic1.zhimg.com/v2-c46eb9492ae4cbbab150bd55acc1aa6c_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>     如上图所示，数据格式为 28*28的灰度图，图片表示为矩阵形式（有填充的地方为正值，无填充为0）：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-c7518d4f5a4585df7f63c900c28da4e9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"590\" data-rawheight=\"233\" class=\"origin_image zh-lightbox-thumb\" width=\"590\" data-original=\"https://pic2.zhimg.com/v2-c7518d4f5a4585df7f63c900c28da4e9_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;590&#39; height=&#39;233&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"590\" data-rawheight=\"233\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"590\" data-original=\"https://pic2.zhimg.com/v2-c7518d4f5a4585df7f63c900c28da4e9_r.jpg\" data-actualsrc=\"https://pic2.zhimg.com/v2-c7518d4f5a4585df7f63c900c28da4e9_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p>      每个数据均包含对应标签 Label（Ground Truth），标签结果是一个10维的float数组，对应每个数字的概率：</p><p>        0 -&gt; [1,0,0,0,0,0,0,0,0,0 ]</p><p>        5 -&gt; [ 0,0,0,0,0,1,0,0,0,0 ]</p><p>      即对应位的概率为 1，其他位为 0。</p><p>      这样我们就得到了一组对应的 输入-输出，即 输入为 28*28=784维向量，输出为10维向量：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-31db283bb3c05c75d24a8c840119fcb7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"585\" data-rawheight=\"499\" class=\"origin_image zh-lightbox-thumb\" width=\"585\" data-original=\"https://pic4.zhimg.com/v2-31db283bb3c05c75d24a8c840119fcb7_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;585&#39; height=&#39;499&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"585\" data-rawheight=\"499\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"585\" data-original=\"https://pic4.zhimg.com/v2-31db283bb3c05c75d24a8c840119fcb7_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-31db283bb3c05c75d24a8c840119fcb7_b.jpg\"/></figure><p><b>二. MNIST网络结构</b></p><p>     MNIST 采用LeNet-5，因Lecun而命名，该网络拓扑图结构（caffe结构图，看着比Tensor的清晰一些）：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-0158dc15c2de936febbe521acea62ef8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2755\" data-rawheight=\"275\" class=\"origin_image zh-lightbox-thumb\" width=\"2755\" data-original=\"https://pic1.zhimg.com/v2-0158dc15c2de936febbe521acea62ef8_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2755&#39; height=&#39;275&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2755\" data-rawheight=\"275\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2755\" data-original=\"https://pic1.zhimg.com/v2-0158dc15c2de936febbe521acea62ef8_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-0158dc15c2de936febbe521acea62ef8_b.jpg\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>数据层 Data -&gt; 隐层 Layer1 -&gt; 隐层 Layer2 -&gt; 全连接层 FC1 -&gt; 全连接层 FC2 -&gt;  Loss | Accuracy</b></p><p>                            conv1               conv2                innerProduct      innerProduct         Softmax</p><p>                            pool1                pool2</p><p>     激活层根据需要添加，一般放在 Pooling层后面，这个就根据需要了。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>三. TensorFlow运行</b></p><p>     TensorFlow提供了MNIST 的例子，我们直接上Python代码，可以自己测试运行：</p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"c1\">#coding=utf-8  </span>\n<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"kn\">as</span> <span class=\"nn\">tf</span>  \n<span class=\"kn\">from</span> <span class=\"nn\">tensorflow.examples.tutorials.mnist</span> <span class=\"kn\">import</span> <span class=\"n\">input_data</span>  \n  \n<span class=\"n\">mnist</span> <span class=\"o\">=</span> <span class=\"n\">input_data</span><span class=\"o\">.</span><span class=\"n\">read_data_sets</span><span class=\"p\">(</span><span class=\"s2\">&#34;MNIST_data/&#34;</span><span class=\"p\">,</span> <span class=\"n\">one_hot</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>  \n<span class=\"n\">sess</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">InteractiveSession</span><span class=\"p\">()</span>  \n  \n<span class=\"c1\"># define W &amp; b  </span>\n<span class=\"k\">def</span> <span class=\"nf\">weight_variable</span><span class=\"p\">(</span><span class=\"n\">para</span><span class=\"p\">):</span>  \n    <span class=\"c1\"># 采用截断的正态分布，标准差stddev＝0.1  </span>\n    <span class=\"n\">initial</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">truncated_normal</span><span class=\"p\">(</span><span class=\"n\">para</span><span class=\"p\">,</span><span class=\"n\">stddev</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>  \n    <span class=\"k\">return</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">initial</span><span class=\"p\">)</span>  \n  \n<span class=\"k\">def</span> <span class=\"nf\">bias_variable</span><span class=\"p\">(</span><span class=\"n\">para</span><span class=\"p\">):</span>  \n    <span class=\"n\">initial</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">constant</span><span class=\"p\">(</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"n\">para</span><span class=\"p\">)</span>  \n    <span class=\"k\">return</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span><span class=\"n\">initial</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># define conv &amp; pooling  </span>\n<span class=\"k\">def</span> <span class=\"nf\">conv2d</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">W</span><span class=\"p\">):</span>  \n    <span class=\"k\">return</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">conv2d</span><span class=\"p\">(</span> <span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">W</span><span class=\"p\">,</span><span class=\"n\">strides</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span> <span class=\"p\">)</span>  \n  \n<span class=\"k\">def</span> <span class=\"nf\">max_pool_2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>  \n    <span class=\"k\">return</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">max_pool</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">ksize</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">strides</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span><span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"s1\">&#39;SAME&#39;</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># define using data  </span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">placeholder</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"bp\">None</span><span class=\"p\">,</span><span class=\"mi\">784</span><span class=\"p\">])</span>        <span class=\"c1\"># 28*28=784 dim  </span>\n  \n<span class=\"n\">x_input</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">28</span><span class=\"p\">,</span><span class=\"mi\">28</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">])</span>             <span class=\"c1\"># reshape for conv, -1表示不固定数量，1为通道数  </span>\n<span class=\"n\">y_label</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">placeholder</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"bp\">None</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">])</span>  <span class=\"c1\"># label - 10 dim  </span>\n  \n<span class=\"c1\"># define layer1  </span>\n<span class=\"n\">W_conv1</span> <span class=\"o\">=</span> <span class=\"n\">weight_variable</span><span class=\"p\">([</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">32</span><span class=\"p\">])</span> <span class=\"c1\"># Weight in:1  out:32  </span>\n<span class=\"n\">b_conv1</span> <span class=\"o\">=</span> <span class=\"n\">bias_variable</span><span class=\"p\">([</span><span class=\"mi\">32</span><span class=\"p\">])</span>         <span class=\"c1\"># bias  </span>\n<span class=\"n\">h_relu1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">conv2d</span><span class=\"p\">(</span><span class=\"n\">x_input</span><span class=\"p\">,</span><span class=\"n\">W_conv1</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">b_conv1</span><span class=\"p\">)</span> <span class=\"c1\"># relu  </span>\n<span class=\"n\">h_pool1</span> <span class=\"o\">=</span> <span class=\"n\">max_pool_2</span><span class=\"p\">(</span><span class=\"n\">h_relu1</span><span class=\"p\">)</span>         <span class=\"c1\"># pool after relu1  </span>\n  \n<span class=\"c1\"># define layer2  </span>\n<span class=\"n\">W_conv2</span> <span class=\"o\">=</span> <span class=\"n\">weight_variable</span><span class=\"p\">([</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">32</span><span class=\"p\">,</span><span class=\"mi\">64</span><span class=\"p\">])</span> <span class=\"c1\"># Weight in:32  out:64  </span>\n<span class=\"n\">b_conv2</span> <span class=\"o\">=</span> <span class=\"n\">bias_variable</span><span class=\"p\">([</span><span class=\"mi\">64</span><span class=\"p\">])</span>          <span class=\"c1\"># bias for 64 kernel  </span>\n<span class=\"n\">h_relu2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">conv2d</span><span class=\"p\">(</span><span class=\"n\">h_pool1</span><span class=\"p\">,</span><span class=\"n\">W_conv2</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">b_conv2</span><span class=\"p\">)</span> <span class=\"c1\"># relu  </span>\n<span class=\"n\">h_pool2</span> <span class=\"o\">=</span> <span class=\"n\">max_pool_2</span><span class=\"p\">(</span><span class=\"n\">h_relu2</span><span class=\"p\">)</span>          <span class=\"c1\"># pool after relu2  </span>\n  \n<span class=\"c1\"># define full connection layer1  </span>\n<span class=\"n\">W_fc1</span> <span class=\"o\">=</span> <span class=\"n\">weight_variable</span><span class=\"p\">([</span><span class=\"mi\">7</span><span class=\"o\">*</span><span class=\"mi\">7</span><span class=\"o\">*</span><span class=\"mi\">64</span><span class=\"p\">,</span><span class=\"mi\">1024</span><span class=\"p\">])</span> <span class=\"c1\"># Weight in:7*7res*64  out:1024  </span>\n<span class=\"n\">b_fc1</span> <span class=\"o\">=</span> <span class=\"n\">bias_variable</span><span class=\"p\">([</span><span class=\"mi\">1024</span><span class=\"p\">])</span>          <span class=\"c1\"># bias for 1024  </span>\n<span class=\"n\">h_pool2_flat</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">h_pool2</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">7</span><span class=\"o\">*</span><span class=\"mi\">7</span><span class=\"o\">*</span><span class=\"mi\">64</span><span class=\"p\">])</span>  \n<span class=\"n\">h_fc1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">h_pool2_flat</span><span class=\"p\">,</span> <span class=\"n\">W_fc1</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">b_fc1</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 添加Drop Out层，预防过拟合，通过keep_prob传入需要保持（不Drop）的样本比率  </span>\n<span class=\"n\">keep_prob</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">placeholder</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>  \n<span class=\"n\">drop_fc1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">dropout</span><span class=\"p\">(</span><span class=\"n\">h_fc1</span><span class=\"p\">,</span><span class=\"n\">keep_prob</span><span class=\"p\">)</span>  \n  \n<span class=\"c1\"># 第二个全连接层，采用softmax执行回归  </span>\n<span class=\"n\">W_fc2</span> <span class=\"o\">=</span> <span class=\"n\">weight_variable</span><span class=\"p\">([</span><span class=\"mi\">1024</span><span class=\"p\">,</span><span class=\"mi\">10</span><span class=\"p\">])</span> <span class=\"c1\"># Weight in:1024  out:10  </span>\n<span class=\"n\">b_fc2</span> <span class=\"o\">=</span> <span class=\"n\">bias_variable</span><span class=\"p\">([</span><span class=\"mi\">10</span><span class=\"p\">])</span>        <span class=\"c1\"># bias for 10, 10类划分  </span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">drop_fc1</span><span class=\"p\">,</span><span class=\"n\">W_fc2</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">b_fc2</span><span class=\"p\">)</span> <span class=\"c1\"># 计算结果  </span>\n  \n<span class=\"c1\"># 定义loss  </span>\n<span class=\"n\">cross_entropy</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_mean</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_sum</span><span class=\"p\">(</span><span class=\"n\">y_label</span><span class=\"o\">*</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">),</span><span class=\"n\">reduction_indices</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]))</span>  \n<span class=\"n\">train_step</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">AdamOptimizer</span><span class=\"p\">(</span><span class=\"mf\">0.001</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">minimize</span><span class=\"p\">(</span><span class=\"n\">cross_entropy</span><span class=\"p\">)</span>  <span class=\"c1\"># Adam 替代SGD  </span>\n  \n<span class=\"c1\"># 定义准确率  </span>\n<span class=\"n\">correct_pred</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">equal</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">y_label</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">))</span>  \n<span class=\"n\">accuracy</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_mean</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">cast</span><span class=\"p\">(</span><span class=\"n\">correct_pred</span><span class=\"p\">,</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>  \n  \n<span class=\"c1\"># 执行训练  </span>\n<span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">global_variables_initializer</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>  \n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">20000</span><span class=\"p\">):</span>  \n    <span class=\"n\">batch</span> <span class=\"o\">=</span> <span class=\"n\">mnist</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">next_batch</span><span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">)</span> <span class=\"c1\"># 每50个一个batch  </span>\n    <span class=\"k\">if</span> <span class=\"n\">i</span><span class=\"o\">%</span><span class=\"mi\">100</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>  \n        <span class=\"c1\"># eval执行过程－训练精度  </span>\n        <span class=\"n\">train_accuracy</span> <span class=\"o\">=</span> <span class=\"n\">accuracy</span><span class=\"o\">.</span><span class=\"nb\">eval</span><span class=\"p\">(</span><span class=\"n\">feed_dict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"n\">x</span><span class=\"p\">:</span><span class=\"n\">batch</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">y_label</span><span class=\"p\">:</span><span class=\"n\">batch</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">keep_prob</span><span class=\"p\">:</span><span class=\"mf\">1.0</span><span class=\"p\">})</span>  \n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;step </span><span class=\"si\">%d</span><span class=\"s2\">, training accuracy </span><span class=\"si\">%g</span><span class=\"s2\">&#34;</span><span class=\"o\">%</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">train_accuracy</span><span class=\"p\">))</span>  \n    <span class=\"n\">train_step</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">feed_dict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"n\">x</span><span class=\"p\">:</span><span class=\"n\">batch</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">y_label</span><span class=\"p\">:</span><span class=\"n\">batch</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">keep_prob</span><span class=\"p\">:</span><span class=\"mf\">0.5</span><span class=\"p\">})</span>  \n  \n<span class=\"c1\"># 测试数据精度  </span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s2\">&#34;test accuracy </span><span class=\"si\">%g</span><span class=\"s2\">&#34;</span><span class=\"o\">%</span><span class=\"n\">accuracy</span><span class=\"o\">.</span><span class=\"nb\">eval</span><span class=\"p\">(</span><span class=\"n\">feed_dict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"n\">x</span><span class=\"p\">:</span><span class=\"n\">mnist</span><span class=\"o\">.</span><span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">images</span><span class=\"p\">,</span> <span class=\"n\">y_label</span><span class=\"p\">:</span><span class=\"n\">mnist</span><span class=\"o\">.</span><span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">keep_prob</span><span class=\"p\">:</span><span class=\"mf\">1.0</span><span class=\"p\">}))</span> </code></pre></div><p>       过程不再多说，还是很简单的，可以直接看注释。</p>", 
            "topic": [
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }
            ], 
            "comments": []
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/33445799", 
            "userName": "linolzhang", 
            "userLink": "https://www.zhihu.com/people/aa20b95b0383ebd8de05ac61798ec9ce", 
            "upvote": 3, 
            "title": "浅入浅出TensorFlow 2 - 零基础安装", 
            "content": "<p>对一个框架的熟悉过程是从安装开始，今天就带大家熟悉这里面的 第一道坎 - <b>安装</b>。</p><p>    TensorFlow 安装方式总结为：</p><p><b>一. Pip安装步骤： </b></p><p><b>  1）安装 Pip</b></p><p>       Pip是目前使用最多的Python包管理工具。通常Linux和Mac是自带Python环境的（2.X版本，附带pip），如果系统没有安装Python环境，或者你需要使用Python3，可以参考下面的安装步骤：</p><p>       不同的平台下的安装方式有所区别，常用的平台安装命令：</p><p><b>● Ubuntu 64-bit</b></p><div class=\"highlight\"><pre><code class=\"language-bash\">$ sudo apt-get install python-pip python-dev   <span class=\"c1\"># for python</span>  \n$ sudo apt-get install python3-pip python3-dev <span class=\"c1\"># for python3</span></code></pre></div><p>有时会提醒pip升级，处理方法如下：</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"c1\"># You are using pip version 7.1.0, however version 9.0.1 is available.</span>  \n<span class=\"c1\"># You should consider upgrading via the &#39;pip install --upgrade pip&#39; command.</span>  \n$ sudo pip install --upgrade pip          <span class=\"c1\"># for python</span>  \n$ sudo pip3 install --upgrade pip         <span class=\"c1\"># for python3</span>  </code></pre></div><p><b>● CentOS, Fedora, RHEL</b></p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"c1\"># for python</span>  \n$ python --version   <span class=\"c1\">#  自带Python 2.6.6 和 pip</span>  \n$ sudo yum install python-pip python-devel <span class=\"c1\"># 命令安装</span>  \n  \n<span class=\"c1\"># for python3</span>  \n$ sudo yum install epel-release python34 <span class=\"c1\"># Python 3.4.5</span>  \n$ wget --no-check-certificate https://bootstrap.pypa.io/get-pip.py  \n$ sudo python3 get-pip.py  <span class=\"c1\"># 未自带pip3，从官网安装</span>  </code></pre></div><p><b>● MAC OS</b></p><p>  mac 自带 python2.7 和 pip，如果没有的话，可以通过 下面的方式快速安装：</p><div class=\"highlight\"><pre><code class=\"language-bash\">$ sudo easy_install pip</code></pre></div><p>需要安装3.X版本的话，推荐用home-brew安装：</p><div class=\"highlight\"><pre><code class=\"language-bash\">$ /usr/bin/ruby -e <span class=\"s2\">&#34;</span><span class=\"k\">$(</span>curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install<span class=\"k\">)</span><span class=\"s2\">&#34;</span>  \n<span class=\"c1\"># 1.可能需要修改权限</span>  \n$ sudo chown -R <span class=\"k\">$(</span>whoami<span class=\"k\">)</span> /usr/local/Cellar  \n<span class=\"c1\"># 2.可能遇到下面错误，需要删掉对应路径，然后update</span>  \n<span class=\"c1\"># Error: Could not link: /usr/local/etc/bash_completion.d/brew</span>  \n$ rm -rf /usr/local/etc/bash_completion.d/brew  \n$ brew update  \n  \n$ brew install python3  \n$ pip3 -V  </code></pre></div><p><b>● Window</b></p><p>   a）下载Python安装包  .exe（3.5.3版本）</p><p>        地址： <a href=\"https://link.zhihu.com/?target=https%3A//www.python.org/downloads/windows/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://www.</span><span class=\"visible\">python.org/downloads/wi</span><span class=\"invisible\">ndows/</span><span class=\"ellipsis\"></span></a></p><p>                  Download Windows x86-64 executable installer</p><p>  b）双击自定义安装       需要修改默认安装位置，配置环境变量 - 选择 &#34;Add Python 3.5 to PATH&#34; 选项。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-98027bd2f4ba2e95450a52c86e9e4f6a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"466\" data-rawheight=\"264\" class=\"origin_image zh-lightbox-thumb\" width=\"466\" data-original=\"https://pic3.zhimg.com/v2-98027bd2f4ba2e95450a52c86e9e4f6a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;466&#39; height=&#39;264&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"466\" data-rawheight=\"264\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"466\" data-original=\"https://pic3.zhimg.com/v2-98027bd2f4ba2e95450a52c86e9e4f6a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-98027bd2f4ba2e95450a52c86e9e4f6a_b.jpg\"/></figure><p>   c）高级选项，选择安装位置，勾选 install for all users</p><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-433c93657c9a494dcfa62a617bbb9d07_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"464\" data-rawheight=\"265\" class=\"origin_image zh-lightbox-thumb\" width=\"464\" data-original=\"https://pic4.zhimg.com/v2-433c93657c9a494dcfa62a617bbb9d07_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;464&#39; height=&#39;265&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"464\" data-rawheight=\"265\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"464\" data-original=\"https://pic4.zhimg.com/v2-433c93657c9a494dcfa62a617bbb9d07_r.jpg\" data-actualsrc=\"https://pic4.zhimg.com/v2-433c93657c9a494dcfa62a617bbb9d07_b.jpg\"/></figure><p>   注：windows下也可以考虑 采用 Anaconda 安装，点击查看 <a href=\"https://link.zhihu.com/?target=http%3A//download.csdn.net/detail/linolzhang/9824018\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">安装方法</a>。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>2）安装 CUDA</b></p><p>       在Ubuntu下安装 CUDA 和 cudnn过程（其他版本类似）：</p><p><b>a）安装 NVIDIA驱动</b></p><p>   官网下载地址：<a href=\"https://link.zhihu.com/?target=http%3A//www.nvidia.com/Download/index.aspx%3Flang%3Den-us\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://www.</span><span class=\"visible\">nvidia.com/Download/ind</span><span class=\"invisible\">ex.aspx?lang=en-us</span><span class=\"ellipsis\"></span></a></p><p>   执行命令安装：</p><div class=\"highlight\"><pre><code class=\"language-bash\">sudo add-apt-repository ppa:graphics-drivers/ppa  \nsudo apt-get update  \nsudo apt-get install nvidia-375  \nsudo apt-get install mesa-common-dev  \nsudo apt-get install freeglut3-dev </code></pre></div><p>查询安装结果：</p><div class=\"highlight\"><pre><code class=\"language-bash\">sudo reboot  <span class=\"c1\"># 重启</span>  \nnvidia-smi </code></pre></div><p><b>b）安装 CUDA</b></p><p>   官网下载地址：<a href=\"https://link.zhihu.com/?target=https%3A//developer.nvidia.com/cuda-downloads\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">developer.nvidia.com/cu</span><span class=\"invisible\">da-downloads</span><span class=\"ellipsis\"></span></a></p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-200cfc7c8fbb57bd121c7eb9902239d2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"656\" data-rawheight=\"417\" class=\"origin_image zh-lightbox-thumb\" width=\"656\" data-original=\"https://pic3.zhimg.com/v2-200cfc7c8fbb57bd121c7eb9902239d2_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;656&#39; height=&#39;417&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"656\" data-rawheight=\"417\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"656\" data-original=\"https://pic3.zhimg.com/v2-200cfc7c8fbb57bd121c7eb9902239d2_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-200cfc7c8fbb57bd121c7eb9902239d2_b.jpg\"/></figure><p>   执行下载的 CUDA安装包（.Run文件）进行安装：</p><div class=\"highlight\"><pre><code class=\"language-bash\">sudo sh cuda_8.0.61_375.26_linux.run  </code></pre></div><p>   按空格 读完声明文件，Accept 接受安装，除了 驱动（已装完）选 no 之外，其他均选择默认。 </p><p><b>c）添加 CUDA 系统路径</b> </p><p>   添加环境变量，可以加到 profile里，也可以加到 bashrc，在最后加入：</p><p>   修改 profile 文件，在末尾处添加（不要有空格)</p><div class=\"highlight\"><pre><code class=\"language-bash\">sudo gedit /etc/profile   <span class=\"c1\">#or gedit ~/.bashrc</span>  \n<span class=\"nb\">export</span> <span class=\"nv\">PATH</span><span class=\"o\">=</span>/usr/local/cuda-8.0/bin:<span class=\"nv\">$PATH</span>  \n<span class=\"nb\">export</span> <span class=\"nv\">LD_LIBRARY_PATH</span><span class=\"o\">=</span>/usr/local/cuda-8.0/lib64<span class=\"nv\">$LD_LIBRARY_PATH</span>  \n<span class=\"nb\">source</span> /etc/profile  <span class=\"c1\"># save config(or sudo ldconfig)</span></code></pre></div><p>    通过命令查看CUDA安装是否成功？</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"nb\">cd</span> /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery  \nsudo make  \n./deviceQuery  </code></pre></div><p><b>d）安装 cudnn</b></p><p>   官网下载地址：<a href=\"https://link.zhihu.com/?target=https%3A//developer.nvidia.com/cudnn\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">developer.nvidia.com/cu</span><span class=\"invisible\">dnn</span><span class=\"ellipsis\"></span></a></p><p>   解压， Copy到对应 CUDA 目录，并建立软链接。</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"c1\"># 复制头文件和lib文件</span>  \nsudo cp include/cudnn.h /usr/local/cuda/include/  \nsudo cp lib64/lib* /usr/local/cuda/lib64/  \n  \n<span class=\"c1\"># 链接动态库</span>  \n<span class=\"nb\">cd</span> /usr/local/cuda/lib64/  \nsudo rm -rf libcudnn.so libcudnn.so.5  \nsudo ln -s libcudnn.so.5.x.x libcudnn.so.5  \nsudo ln -s libcudnn.so.5 libcudnn.so  </code></pre></div><p><b>3）安装 TensorFlow</b></p><p>       根据你所选择的Python版本，下载对应的TensorFlow描述文件，进行安装：</p><p><a href=\"https://link.zhihu.com/?target=https%3A//storage.googleapis.com/tensorflow/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">storage.googleapis.com/</span><span class=\"invisible\">tensorflow/</span><span class=\"ellipsis\"></span></a></p><p>       这是个XML文件，搜索1.1.0版本（截止到目前最新版本）对应的whl文件：</p><p><b>操作系统对应.Whl文件</b></p><p>@<b>Linux</b></p><p><b>    CPU版本</b><br/>           -- linux/cpu/tensorflow-1.1.0rc0-cp27-none-linux_x86_64.whl<br/>   # 33|34|35|36  替换下面的cp33-cp33<br/>           -- linux/cpu/tensorflow-1.1.0rc0-cp33-cp33m-linux_x86_64.whl<br/>    <b>GPU版本</b><br/>           -- linux/gpu/tensorflow_gpu-1.1.0rc2-cp27-none-linux_x86_64.whl<br/>   # 33|34|35|36<br/>          --  linux/gpu/tensorflow_gpu-1.1.0rc2-cp33-cp33m-linux_x86_64.whl</p><p>   Debian<b> CPU版本（only）</b><br/>        -- linux/cpu/debian/jessie/tensorflow-1.1.0rc1-cp27-none-linux_x86_64.whl </p><p>  云版本Cloudml</p><p><b>    CPU版本</b><br/>        -- linux/cpu/cloudml/tensorflow-1.1.0rc0-cp27-none-linux_x86_64.whl<br/>    <b>GPU版本（最高版本是1.0.0）</b><br/>        -- linux/gpu/cloudml/avx2_fma/tensorflow_gpu-1.0.0-cp27-none-linux_x86_64.whl</p><p>@<b>Mac</b></p><p><b>   CPU版本</b><br/>        -- mac/cpu/tensorflow-1.1.0rc2-py2-none-any.whl<br/>        -- mac/cpu/tensorflow-1.1.0rc2-py3-none-any.whl<br/>  <b>GPU version稳定的release（rc0）</b><br/>        -- mac/gpu/tensorflow_gpu-1.1.0rc0-py2-none-any.whl<br/>        -- mac/gpu/tensorflow_gpu-1.1.0rc0-py3-none-any.whl</p><p>@<b>Windows</b> 目前仅支持Python 3.5<br/>    <b>CPU版本</b><br/>        -- windows/cpu/tensorflow-1.1.0rc2-cp35-cp35m-win_amd64.whl<br/>    <b>GPU版本</b><br/>        -- windows/gpu/tensorflow_gpu-1.1.0rc2-cp35-cp35m-win_amd64.whl</p><p class=\"ztext-empty-paragraph\"><br/></p><p>       通过URL将对应的 whl 文件下载到本地， 比如作者采用 Py3.4（ubuntu14对应版本），Linux下对应的CPU版本：</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"c1\"># Python 3</span>  \n$ sudo pip3 install --upgrade tensorflow-1.1.0rc2-cp34-cp34m-manylinux1_x86_64.whl </code></pre></div><p>       也可以根据自己需要，直接配置URL在线 whl 进行安装：</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"c1\"># Python3 version, GPU</span>  \n$ sudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.1.0rc2-cp35-cp35m-linux_x86_64.whl  \n  \n<span class=\"c1\"># Python3 version, CPU</span>  \n$ sudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.1.0rc0-cp34-cp34m-linux_x86_64.whl  \n  \n<span class=\"c1\"># python2.X version, Linux with GPU</span>  \n$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.1.0rc2-cp27-none-linux_x86_64.whl  </code></pre></div><p>      需要注意：可能会遇到安装失败的情况，是网络问题，需要多试几次！</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>二. Docker安装：</b></p><p>     在云上部署的情况下常用Docker安装，关于Docker安装作者并不推荐，Docker的学习成本相对较高。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>三. Make编译：</b></p><p>     1.下载源码</p><div class=\"highlight\"><pre><code class=\"language-bash\">Git clone --recurse-submodules https://github.com/tensorflow/tensorflow</code></pre></div><p>     2. 安装Bazel</p><p>         可以参考官网安装方法：<a href=\"https://link.zhihu.com/?target=https%3A//bazel.build/versions/master/docs/install.html\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">bazel.build/versions/ma</span><span class=\"invisible\">ster/docs/install.html</span><span class=\"ellipsis\"></span></a></p><p>     3. 安装tensorflow依赖库</p><div class=\"highlight\"><pre><code class=\"language-bash\">sudo apt-get install Python-numpy swig python-dev python-wheel   </code></pre></div><p>     4. 配置tensorflow，需要你指定相应文件的安装目录</p><p>         cd进tensorflow源文件。sudo ./configure</p><p>     5. 使用Bazel编译构建</p><div class=\"highlight\"><pre><code class=\"language-bash\">bazel build -c opt --config<span class=\"o\">=</span>cuda //tensorflow/cc:tutorials_example_trainer \nbazel-bin/tensorflow/cc/tutorials_example_trainer--use_gpu</code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><p><b>四. 测试安装：</b></p><p>     安装完成，下面要测试安装是否成功，命令行环境测试（注意python 和 python3的语法稍有不同）：</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"c1\"># 进入python命令行</span>  \n$ python  <span class=\"c1\"># or python3</span>  \n&gt;&gt;&gt; import tensorflow as tf  \n&gt;&gt;&gt; <span class=\"nv\">str</span> <span class=\"o\">=</span> tf.constant<span class=\"o\">(</span><span class=\"s2\">&#34;Hello World!&#34;</span><span class=\"o\">)</span>  \n&gt;&gt;&gt; <span class=\"nv\">se</span> <span class=\"o\">=</span> tf.Session<span class=\"o\">()</span>  \n&gt;&gt;&gt; print se.run<span class=\"o\">(</span>str<span class=\"o\">)</span>  <span class=\"c1\"># or print (se.run(str))</span> </code></pre></div><p>     当出现预料中的 Hello World！ 时，恭喜你，TensorFlow 环境安装成功了，折腾了那边久终于松了一口气，满满的成就感吧。</p><p>     CentOS下如果出现错误提示：  ImportError: /lib64/libc.so.6: version `GLIBC_2.14&#39; not found</p><p>                                                     Failed to load the native TensorFlow runtime.</p><p>     不用担心，这是你的GLIB版本过低（操作系统版本有点老），解决方法如下：</p><p>1. 到 <a href=\"https://link.zhihu.com/?target=http%3A//ftp.gnu.org/gnu/glibc/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">ftp.gnu.org/gnu/glibc/</span><span class=\"invisible\"></span></a></p><p>       下载 glibc-2.14.tar.gz  以及 对应插件 glibc-ports-2.14.tar.gz</p><p>       注：安装 glib2.17以上版本不需要 ports 插件，步骤一样。</p><p>2. 编译安装</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"o\">[</span>user@localhost ~<span class=\"o\">]</span>$ tar -xzvf glibc-2.14.tar.gz  \n<span class=\"o\">[</span>user@localhost ~<span class=\"o\">]</span>$ tar -xzvf glibc-ports-2.14.tar.gz  \n<span class=\"o\">[</span>user@localhost ~<span class=\"o\">]</span>$ mv glibc-ports-2.14 glibc-2.14/ports  \n<span class=\"o\">[</span>user@localhost ~<span class=\"o\">]</span>$ <span class=\"nb\">cd</span> glibc-2.14  \n<span class=\"o\">[</span>user@localhost glibc-2.14<span class=\"o\">]</span>$ mkdir build  \n<span class=\"o\">[</span>user@localhost glibc-2.14<span class=\"o\">]</span>$ <span class=\"nb\">cd</span> build  \n<span class=\"o\">[</span>user@localhost build<span class=\"o\">]</span>$ ../configure --prefix<span class=\"o\">=</span>/usr --disable-profile --enable-add-ons --with-headers<span class=\"o\">=</span>/usr/include --with-binutils<span class=\"o\">=</span>/usr/bin  \n<span class=\"o\">[</span>user@localhost build<span class=\"o\">]</span>$ make -j4  \n<span class=\"o\">[</span>user@localhost build<span class=\"o\">]</span>$ su  \n<span class=\"o\">[</span>root@localhost build<span class=\"o\">]</span><span class=\"c1\"># make install</span>  </code></pre></div><p>3. 替换文件，建立软连接</p><p>  注：2.17以上版本不需要下面操作，install已经完成了替换。</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"o\">[</span>root@localhost build<span class=\"o\">]</span><span class=\"c1\"># cp libc.so /lib64/libc-2.14.so  # copy</span>  \n<span class=\"o\">[</span>root@localhost build<span class=\"o\">]</span><span class=\"c1\"># rm -rf /lib64/libc.so.6          # 删除原文件</span>  \n<span class=\"o\">[</span>root@localhost build<span class=\"o\">]</span><span class=\"c1\"># LD_PRELOAD=/lib64/libc-2.14.so ln -s /lib64/libc-2.14.so /lib64/libc.so.6   # 建立软连接</span>  \n<span class=\"o\">[</span>root@localhost build<span class=\"o\">]</span><span class=\"c1\"># strings /lib64/libc.so.6 | grep GLIBC    # 查看是否安装成功</span>  </code></pre></div><p><b>libstdc++ 版本问题：</b></p><p>   对应 libstdc++ 报错，处理方式与上面一致，安装新版本gcc即可，具体方式可以配置YUM源，也可以下载文件编译安装，或者下载库替换，这里不再介绍。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>五. 配置集成环境：</b></p><p>      配置集成环境是大多数情况下开发大型软件必做的一步，很多人都不喜欢用命令行，可以理解，在Linux下我们推荐Eclipse，Windows下推荐VS。</p><p><b>Eclipse配置：</b></p><p>   1）配置 java环境</p><p>       下载并安装 jdk1.8， 配置环境，打开～/.bashrc，加入一行：</p><div class=\"highlight\"><pre><code class=\"language-bash\"><span class=\"nb\">export</span> <span class=\"nv\">JAVA_HOME</span><span class=\"o\">=</span>/your path/jdk/jdk1.8  \n<span class=\"nb\">export</span> <span class=\"nv\">CLASSPATH</span><span class=\"o\">=</span><span class=\"si\">${</span><span class=\"nv\">JAVA_HOME</span><span class=\"si\">}</span>/libexport <span class=\"nv\">PATH</span><span class=\"o\">=</span><span class=\"si\">${</span><span class=\"nv\">JAVA_HOME</span><span class=\"si\">}</span>/bin:<span class=\"nv\">$PATH</span>  \n<span class=\"nb\">source</span> ~./bashrc   \njava -version  <span class=\"c1\"># 查看版本</span> </code></pre></div><p>   2）安装 Eclipse</p><p>   3）在 Eclipse 中安装pydev插件</p><p>         Help -&gt; Install New Software... 在弹出的对话框中，点Add 按钮。 Name选择 <a href=\"https://link.zhihu.com/?target=http%3A//pydev.org/updates\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">pydev.org/updates</span><span class=\"invisible\"></span></a></p><p>   4）配置 pydev 解释器</p><p>        在Eclipse菜单栏，点击Windows -&gt;Preferences。</p><p>        选择左侧列表 PyDev-&gt;Interpreter - Python，进入配置。</p><p>        点击右上角 New按钮， 选择 python.exe的路径，配置完成</p><p><b>VS2015 配置：</b></p><p>     Windows下的IDE 推荐2015，因为免费又好用，VS2015集成了Python开发环境，具体配置和使用方法这里就不讲了，自己试一下。</p><p>    OK，还等什么，新建一个Project，开始你的旅程吧。</p>", 
            "topic": [
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }
            ], 
            "comments": [
                {
                    "userName": "小白Licko", 
                    "userLink": "https://www.zhihu.com/people/160e8c366df2dc17b5ac380093a68381", 
                    "content": "全面，好文！", 
                    "likes": 0, 
                    "childComments": []
                }, 
                {
                    "userName": "Jerron", 
                    "userLink": "https://www.zhihu.com/people/8c9e523fe3eb2704128ab639cd47262c", 
                    "content": "<p>在pydev里你能用ipython显示图片吗？比如</p><p>from IPython.display import display, Image</p><p>img=Image(filename=image_file)</p><p>display(img)</p><p><br></p><p>我只能看到&lt;IPython.core.display.Image object&gt;的文字，看不到图</p>", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }, 
        {
            "url": "https://zhuanlan.zhihu.com/p/33445657", 
            "userName": "linolzhang", 
            "userLink": "https://www.zhihu.com/people/aa20b95b0383ebd8de05ac61798ec9ce", 
            "upvote": 12, 
            "title": "浅入浅出TensorFlow 1 - 初识TensorFlow", 
            "content": "<p><b>一. TensorFlow 的发展历程</b></p><p>    OpenCV 可能是多数人都很熟悉的计算机视觉库，参考下图机器学习库的发展轴线。</p><p>    近几年，随着深度学习技术的快速发展，诞生了 Torch、Theano、Caffe、MxNet 等一批深度学习库，而 TensorFlow 正是这些框架中的佼佼者，得益于其 优秀的架构设计理念及工程实现，以及丰富的学习资料，目前 TensorFlow 已经超越 Caffe（目前已经不怎么更新了） 成为使用率最高的DL框架，大有成为机器学习领域的Android之势。</p><figure data-size=\"normal\"><noscript><img src=\"https://pic1.zhimg.com/v2-7c5936b9b4fe15edc0ba3b0eb59196b0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"923\" data-rawheight=\"269\" class=\"origin_image zh-lightbox-thumb\" width=\"923\" data-original=\"https://pic1.zhimg.com/v2-7c5936b9b4fe15edc0ba3b0eb59196b0_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;923&#39; height=&#39;269&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"923\" data-rawheight=\"269\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"923\" data-original=\"https://pic1.zhimg.com/v2-7c5936b9b4fe15edc0ba3b0eb59196b0_r.jpg\" data-actualsrc=\"https://pic1.zhimg.com/v2-7c5936b9b4fe15edc0ba3b0eb59196b0_b.jpg\"/></figure><p>    TensorFlow 优势在于强大的分布式计算能力，相较于 Caffe 等传统单机版系统有不可比拟的优势，这得益于Google在分布式计算层面的技术优势。另外，对于Android系统的原生支持 也给 TensorFlow 带来了庞大的用户量。</p><p>    TensorFlow 由Google 工程大神 <b>Jeff Dean</b> 领衔开发。字面意思来看，Tensor（张量）表示N维数组，Flow（流）意味着基于数据流图的计算，TensorFlow 为张量从流图的一端流动到另一端计算过程。</p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>二. TensorFlow 版本、SDK</b></p><p>    TensorFlow 目前版本为 1.1.0，之前第一个正式版本是 1.0.0。</p><p>    主要支持 python/C++ 接口，1.0版本加入了Java API，另外也可以选择 R、Go 语言API（需要第三方支持） 以及 Keras，不作为讨论内容。</p><p><b>官网地址：</b><a href=\"https://link.zhihu.com/?target=https%3A//www.tensorflow.org/versions/r1.0/\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://www.</span><span class=\"visible\">tensorflow.org/versions</span><span class=\"invisible\">/r1.0/</span><span class=\"ellipsis\"></span></a></p><p><b>GitHub：</b><a href=\"https://link.zhihu.com/?target=https%3A//github.com/tensorflow/tensorflow/releases\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">github.com/tensorflow/t</span><span class=\"invisible\">ensorflow/releases</span><span class=\"ellipsis\"></span></a> </p><p class=\"ztext-empty-paragraph\"><br/></p><p><b>三. 模块结构</b></p><p>    TensorFlow 分为 <b>Front End</b> 和 <b>Exec System</b>，<b>Front End</b>是指 API接口，<b>Exec System </b>对应Work执行。层次结构图示意如下：</p><figure data-size=\"normal\"><noscript><img src=\"https://pic3.zhimg.com/v2-30b6816579537670f0d107f46465560a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"677\" data-rawheight=\"386\" class=\"origin_image zh-lightbox-thumb\" width=\"677\" data-original=\"https://pic3.zhimg.com/v2-30b6816579537670f0d107f46465560a_r.jpg\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;677&#39; height=&#39;386&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"677\" data-rawheight=\"386\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"677\" data-original=\"https://pic3.zhimg.com/v2-30b6816579537670f0d107f46465560a_r.jpg\" data-actualsrc=\"https://pic3.zhimg.com/v2-30b6816579537670f0d107f46465560a_b.jpg\"/></figure><p>     对应模块描述为：</p><blockquote><b>模块组成功能说明备注 Client</b>  主要用于计算图构造，并调用后端的Runtime，进行计算图的执行； <b> Runtime  Master</b> 负责总体计算任务分配及合并，包括：<br/>     A） 接收前端Session数据，优化计算图（消除冗余计算，常量折叠等）；<br/>     B） 拆分任务，将计算图分裂为子图，发送给Work；<br/>     C） 协同任务，得到计算结果；<br/><b> Worker</b><br/>     A） 根据图节点的依赖，调用Kernel完成计算；<br/>     B） 将计算结果发送到其他Worker；<br/>     C） 接受来自其他Worker的计算结果；  执行实际计算<b> Kernel</b>    根据当前可用的硬件环境(GPU/CPU)，执行OP计算<br/>   OP计算是指对不同硬件的统一封装调用，属于一种多态应用技术。CPU, GPU, Arm, X86<b> Device  设备网络层</b><br/>     支持硬件封装 - CPU  GPU  Android  IOS<br/>     支持网络通信 - gRPC  RDMA </blockquote><p class=\"ztext-empty-paragraph\"><br/></p><p><b>四. 认识数据流图</b></p><p>    TensorFlow 通过数据流图进行计算，何为数据流图？ 来看个例子（左图是一个典型的计算图，右图描述计算过程）：</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><noscript><img src=\"https://pic2.zhimg.com/v2-9c5f787974f1ded410343296e553fe09_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"285\" data-rawheight=\"426\" class=\"content_image\" width=\"285\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;285&#39; height=&#39;426&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"285\" data-rawheight=\"426\" class=\"content_image lazy\" width=\"285\" data-actualsrc=\"https://pic2.zhimg.com/v2-9c5f787974f1ded410343296e553fe09_b.jpg\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://pic4.zhimg.com/v2-4a67e12961d71d510c83c2aa35a8febb_b.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"252\" data-rawheight=\"448\" data-thumbnail=\"https://pic4.zhimg.com/v2-4a67e12961d71d510c83c2aa35a8febb_b.jpg\" class=\"content_image\" width=\"252\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;252&#39; height=&#39;448&#39;&gt;&lt;/svg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"252\" data-rawheight=\"448\" data-thumbnail=\"https://pic4.zhimg.com/v2-4a67e12961d71d510c83c2aa35a8febb_b.jpg\" class=\"content_image lazy\" width=\"252\" data-actualsrc=\"https://pic4.zhimg.com/v2-4a67e12961d71d510c83c2aa35a8febb_b.gif\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p><b>数据流图</b> 是 用 <b>Node（结点）</b>和 <b>Edge(边)</b> 的有向图来描述数学计算：</p><p><b>Node</b> 用来表示 <b>输入/输出 数据</b>（对应 <b>起始终止点</b>），也就是<b>Tensor - 张量</b>，对应左图圆形；</p><p>             也用来表示 <b>数学操作</b>，对应左图矩形。</p><p><b>Edge</b> 表示 <b>Node</b>之间的输入/输出关系，计算过程即 <b>数据流动过程 - Flow</b>。</p><p>    左图公式对应TensorFlow代码（先熟悉一下）： </p><div class=\"highlight\"><pre><code class=\"language-python\"><span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"kn\">as</span> <span class=\"nn\">tf</span>  \n  \n<span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">([</span><span class=\"mi\">100</span><span class=\"p\">])</span> <span class=\"p\">)</span>                       <span class=\"c1\"># 100-d vector, init to 0  </span>\n<span class=\"n\">W</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Variable</span><span class=\"p\">(</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">random_uniform</span><span class=\"p\">([</span><span class=\"mi\">784</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">],</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"p\">)</span>     <span class=\"c1\"># 784*100 matrix W/rnd vals  </span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">matmul</span><span class=\"p\">(</span><span class=\"n\">W</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">b</span><span class=\"p\">)</span>                      <span class=\"c1\"># Relu(W * x +b)  </span>\n<span class=\"n\">C</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"o\">...</span><span class=\"p\">]</span>                                                <span class=\"c1\">#Const computed as a function  </span>\n  \n<span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">Session</span><span class=\"p\">()</span>   \n<span class=\"k\">for</span> <span class=\"n\">step</span> <span class=\"ow\">in</span> <span class=\"nb\">xrange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">):</span>  \n    <span class=\"nb\">input</span> <span class=\"o\">=</span> <span class=\"o\">...</span><span class=\"n\">construct</span> <span class=\"mi\">100</span><span class=\"o\">-</span><span class=\"n\">D</span> <span class=\"nb\">input</span> <span class=\"n\">array</span> <span class=\"o\">...</span>           <span class=\"c1\"># Create 100-d vector for input  </span>\n    <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">,</span> <span class=\"n\">feed_dict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"nb\">input</span><span class=\"p\">}</span> <span class=\"p\">)</span>             <span class=\"c1\"># Fetch cost,feeding x=input  </span>\n    <span class=\"k\">print</span> <span class=\"n\">step</span><span class=\"p\">,</span> <span class=\"n\">result</span>  </code></pre></div><p class=\"ztext-empty-paragraph\"><br/></p><p><b>五. TensorFlow 的学习步骤</b></p><p>    大多数Blog 只是人云亦云，以转载抄袭为主，参考价值不大，作者在整理资料的同时（<b>Blog仅作为本人学习和备忘，请勿转载</b>），给初学者的学习思路如下：</p><blockquote><b>1）看书 or 少数有价值的Blog</b><br/>     市场上很多书都是骗钱的，某某号称TensorFlow工程总监推荐，销量榜很高，作为菜鸟级的初步了解尚可，实际用作用不大，当然这个也根据个人实际情况，做好甄别和筛选。<br/>     另外Blog 也不少，一搜一大把，凑热闹的居多，不置可否。<br/><b>2）教程</b><br/>    个人认为最好的入门工具还是官方的白皮书，不需要花钱，很多书和教程都是由此而来，有的改都没改。<br/><b>下载：</b><a href=\"https://link.zhihu.com/?target=http%3A//download.csdn.net/download/linolzhang/9817585\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">TensorFlow 官方文档中文版 v1.2</a> <a href=\"https://link.zhihu.com/?target=http%3A//download.csdn.net/download/linolzhang/9817632\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">TensorFlow 技术白皮书</a><br/>    莫烦的视频教程作为初学者可以看一下，毕竟有人对视频教程很有偏好，<a href=\"https://link.zhihu.com/?target=http%3A//list.youku.com/albumlist/show%3Fid%3D27327189%26asce\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">优酷视频</a> 。<br/><b>3）代码</b><br/>    代码是学习最好的帮手，这个不需要质疑，Github上Down下来代码，自己Run例子。<br/>    你需要了解里面的 模块结构 和 类划分，这对于理解框架以及熟练使用是很有帮助的。<br/><b>4）学好工具的使用</b><br/>    一定要熟练掌握 TensorFlow 的工具，特别是可视化工具 TensorBoard，作者会在后面拿出一章进行讲解。<br/>   另外，要掌握相关调试方法（后续也会介绍）。</blockquote>", 
            "topic": [
                {
                    "tag": "TensorFlow", 
                    "tagLink": "https://api.zhihu.com/topics/20032249"
                }
            ], 
            "comments": [
                {
                    "userName": "小白Licko", 
                    "userLink": "https://www.zhihu.com/people/160e8c366df2dc17b5ac380093a68381", 
                    "content": "你好，有优质blog的推荐吗？", 
                    "likes": 0, 
                    "childComments": []
                }
            ]
        }
    ], 
    "url": "https://zhuanlan.zhihu.com/tensor"
}
